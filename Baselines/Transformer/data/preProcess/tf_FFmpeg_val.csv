review,sentiment
"void ff_put_h264_qpel8_mc13_msa ( uint8_t * dst , const uint8_t * src , ptrdiff_t stride ) { avc_luma_hv_qrt_8w_msa ( src + stride - 2 , src - ( stride * 2 ) , stride , dst , stride , 8 ) ; }",0
"int float_near_ulp ( float a , float b , unsigned max_ulp ) { union av_intfloat32 x , y ; x . f = a ; y . f = b ; if ( is_negative ( x ) ! = is_negative ( y ) ) { // handle - 0 . 0 == + 0 . 0 return a == b ; } if ( abs ( x . i - y . i ) < = max_ulp ) return 1 ; return 0 ; }",0
"static av_cold int roq_dpcm_encode_init ( AVCodecContext * avctx ) { ROQDPCMContext * context = avctx - > priv_data ; if ( avctx - > channels > 2 ) { av_log ( avctx , AV_LOG_ERROR , Audio must be mono or stereo\n ) ; return - 1 ; } if ( avctx - > sample_rate ! = 22050 ) { av_log ( avctx , AV_LOG_ERROR , Audio must be 22050 Hz\n ) ; return - 1 ; } if ( avctx - > sample_fmt ! = AV_SAMPLE_FMT_S16 ) { av_log ( avctx , AV_LOG_ERROR , Audio must be signed 16 - bit\n ) ; return - 1 ; } avctx - > frame_size = ROQ_FIRST_FRAME_SIZE ; context - > lastSample[0] = context - > lastSample[1] = 0 ; avctx - > coded_frame= avcodec_alloc_frame ( ) ; return 0 ; }",1
"static void xvid_idct_add ( uint8_t * dest , ptrdiff_t line_size , int16_t * block ) { ff_xvid_idct ( block ) ; ff_add_pixels_clamped ( block , dest , line_size ) ; }",1
"static int rv30_decode_mb_info ( RV34DecContext * r ) { static const int rv30_p_types[6] = { RV34_MB_SKIP , RV34_MB_P_16x16 , RV34_MB_P_8x8 , - 1 , RV34_MB_TYPE_INTRA , RV34_MB_TYPE_INTRA16x16 } ; static const int rv30_b_types[6] = { RV34_MB_SKIP , RV34_MB_B_DIRECT , RV34_MB_B_FORWARD , RV34_MB_B_BACKWARD , RV34_MB_TYPE_INTRA , RV34_MB_TYPE_INTRA16x16 } ; MpegEncContext * s = & r - > s ; GetBitContext * gb = & s - > gb ; int code = svq3_get_ue_golomb ( gb ) ; if ( code > 11 ) { av_log ( s - > avctx , AV_LOG_ERROR , Incorrect MB type code\n ) ; return - 1 ; } if ( code > 5 ) { av_log ( s - > avctx , AV_LOG_ERROR , dquant needed\n ) ; code - = 6 ; } if ( s - > pict_type ! = AV_PICTURE_TYPE_B ) return rv30_p_types[code] ; else return rv30_b_types[code] ; }",1
"static av_cold int j2kenc_init ( AVCodecContext * avctx ) { int i , ret ; Jpeg2000EncoderContext * s = avctx - > priv_data ; Jpeg2000CodingStyle * codsty = & s - > codsty ; Jpeg2000QuantStyle * qntsty = & s - > qntsty ; s - > avctx = avctx ; av_log ( s - > avctx , AV_LOG_DEBUG , init\n ) ; // defaults : // TODO : implement setting non - standard precinct size memset ( codsty - > log2_prec_widths , 15 , sizeof ( codsty - > log2_prec_widths ) ) ; memset ( codsty - > log2_prec_heights , 15 , sizeof ( codsty - > log2_prec_heights ) ) ; codsty - > nreslevels2decode= codsty - > nreslevels = 7 ; codsty - > log2_cblk_width = 4 ; codsty - > log2_cblk_height = 4 ; codsty - > transform = avctx - > prediction_method ? FF_DWT53 : FF_DWT97_INT ; qntsty - > nguardbits = 1 ; s - > tile_width = 256 ; s - > tile_height = 256 ; if ( codsty - > transform == FF_DWT53 ) qntsty - > quantsty = JPEG2000_QSTY_NONE ; else qntsty - > quantsty = JPEG2000_QSTY_SE ; s - > width = avctx - > width ; s - > height = avctx - > height ; for ( i = 0 ; i < 3 ; i + + ) s - > cbps[i] = 8 ; if ( avctx - > pix_fmt == AV_PIX_FMT_RGB24 ) { s - > ncomponents = 3 ; } else if ( avctx - > pix_fmt == AV_PIX_FMT_GRAY8 ) { s - > ncomponents = 1 ; } else { // planar YUV s - > planar = 1 ; s - > ncomponents = 3 ; avcodec_get_chroma_sub_sample ( avctx - > pix_fmt , s - > chroma_shift , s - > chroma_shift + 1 ) ; } ff_jpeg2000_init_tier1_luts ( ) ; ff_mqc_init_context_tables ( ) ; init_luts ( ) ; init_quantization ( s ) ; if ( ret=init_tiles ( s ) ) return ret ; av_log ( s - > avctx , AV_LOG_DEBUG , after init\n ) ; return 0 ; }",1
"void ff_release_unused_pictures ( MpegEncContext * s , int remove_current ) { int i ; / * release non reference frames * / for ( i=0 ; i < s - > picture_count ; i + + ) { if ( s - > picture[i] . data[0] & & ! s - > picture[i] . reference & & s - > picture[i] . owner2 == s & & ( remove_current || & s - > picture[i] ! = s - > current_picture_ptr ) / * & & s - > picture[i] . type ! =FF_BUFFER_TYPE_SHARED * / ) { free_frame_buffer ( s , & s - > picture[i] ) ; } } }",1
"static int mov_read_stsc ( MOVContext * c , ByteIOContext * pb , MOV_atom_t atom ) { AVStream * st = c - > fc - > streams[c - > fc - > nb_streams - 1] ; MOVStreamContext * sc = ( MOVStreamContext * ) st - > priv_data ; int entries , i ; print_atom ( stsc , atom ) ; get_byte ( pb ) ; / * version * / get_byte ( pb ) ; get_byte ( pb ) ; get_byte ( pb ) ; / * flags * / entries = get_be32 ( pb ) ; ifdef DEBUG av_log ( NULL , AV_LOG_DEBUG , track[%i] . stsc . entries = %i\n , c - > fc - > nb_streams - 1 , entries ) ; endif sc - > sample_to_chunk_sz = entries ; sc - > sample_to_chunk = ( MOV_sample_to_chunk_tbl * ) av_malloc ( entries * sizeof ( MOV_sample_to_chunk_tbl ) ) ; if ( ! sc - > sample_to_chunk ) return - 1 ; for ( i=0 ; i < entries ; i + + ) { sc - > sample_to_chunk[i] . first = get_be32 ( pb ) ; sc - > sample_to_chunk[i] . count = get_be32 ( pb ) ; sc - > sample_to_chunk[i] . id = get_be32 ( pb ) ; ifdef DEBUG / * av_log ( NULL , AV_LOG_DEBUG , sample_to_chunk first=%ld count=%ld , id=%ld\n , sc - > sample_to_chunk[i] . first , sc - > sample_to_chunk[i] . count , sc - > sample_to_chunk[i] . id ) ; * / endif } return 0 ; }",1
"av_cold int ff_MPV_common_init ( MpegEncContext * s ) { int i ; int nb_slices = ( HAVE_THREADS & & s - > avctx - > active_thread_type & FF_THREAD_SLICE ) ? s - > avctx - > thread_count : 1 ; if ( s - > encoding & & s - > avctx - > slices ) nb_slices = s - > avctx - > slices ; if ( s - > codec_id == AV_CODEC_ID_MPEG2VIDEO & & ! s - > progressive_sequence ) s - > mb_height = ( s - > height + 31 ) / 32 * 2 ; else s - > mb_height = ( s - > height + 15 ) / 16 ; if ( s - > avctx - > pix_fmt == AV_PIX_FMT_NONE ) { av_log ( s - > avctx , AV_LOG_ERROR , decoding to AV_PIX_FMT_NONE is not supported . \n ) ; return - 1 ; } if ( nb_slices > MAX_THREADS || ( nb_slices > s - > mb_height & & s - > mb_height ) ) { int max_slices ; if ( s - > mb_height ) max_slices = FFMIN ( MAX_THREADS , s - > mb_height ) ; else max_slices = MAX_THREADS ; av_log ( s - > avctx , AV_LOG_WARNING , too many threads/slices ( %d ) , reducing to %d\n , nb_slices , max_slices ) ; nb_slices = max_slices ; } if ( ( s - > width || s - > height ) & & av_image_check_size ( s - > width , s - > height , 0 , s - > avctx ) ) return - 1 ; ff_dct_common_init ( s ) ; s - > flags = s - > avctx - > flags ; s - > flags2 = s - > avctx - > flags2 ; / * set chroma shifts * / av_pix_fmt_get_chroma_sub_sample ( s - > avctx - > pix_fmt , & s - > chroma_x_shift , & s - > chroma_y_shift ) ; / * convert fourcc to upper case * / s - > codec_tag = avpriv_toupper4 ( s - > avctx - > codec_tag ) ; s - > stream_codec_tag = avpriv_toupper4 ( s - > avctx - > stream_codec_tag ) ; FF_ALLOCZ_OR_GOTO ( s - > avctx , s - > picture , MAX_PICTURE_COUNT * sizeof ( Picture ) , fail ) ; for ( i = 0 ; i < MAX_PICTURE_COUNT ; i + + ) { av_frame_unref ( & s - > picture[i] . f ) ; } memset ( & s - > next_picture , 0 , sizeof ( s - > next_picture ) ) ; memset ( & s - > last_picture , 0 , sizeof ( s - > last_picture ) ) ; memset ( & s - > current_picture , 0 , sizeof ( s - > current_picture ) ) ; av_frame_unref ( & s - > next_picture . f ) ; av_frame_unref ( & s - > last_picture . f ) ; av_frame_unref ( & s - > current_picture . f ) ; if ( s - > width & & s - > height ) { if ( init_context_frame ( s ) ) goto fail ; s - > parse_context . state = - 1 ; } s - > context_initialized = 1 ; s - > thread_context[0] = s ; if ( s - > width & & s - > height ) { if ( nb_slices > 1 ) { for ( i = 1 ; i < nb_slices ; i + + ) { s - > thread_context[i] = av_malloc ( sizeof ( MpegEncContext ) ) ; memcpy ( s - > thread_context[i] , s , sizeof ( MpegEncContext ) ) ; } for ( i = 0 ; i < nb_slices ; i + + ) { if ( init_duplicate_context ( s - > thread_context[i] ) < 0 ) goto fail ; s - > thread_context[i] - > start_mb_y = ( s - > mb_height * ( i ) + nb_slices / 2 ) / nb_slices ; s - > thread_context[i] - > end_mb_y = ( s - > mb_height * ( i + 1 ) + nb_slices / 2 ) / nb_slices ; } } else { if ( init_duplicate_context ( s ) < 0 ) goto fail ; s - > start_mb_y = 0 ; s - > end_mb_y = s - > mb_height ; } s - > slice_context_count = nb_slices ; } return 0 ; fail : ff_MPV_common_end ( s ) ; return - 1 ; }",1
"static void clear_context ( MpegEncContext * s ) { int i , j , k ; memset ( & s - > next_picture , 0 , sizeof ( s - > next_picture ) ) ; memset ( & s - > last_picture , 0 , sizeof ( s - > last_picture ) ) ; memset ( & s - > current_picture , 0 , sizeof ( s - > current_picture ) ) ; memset ( & s - > new_picture , 0 , sizeof ( s - > new_picture ) ) ; memset ( s - > thread_context , 0 , sizeof ( s - > thread_context ) ) ; s - > me . map = NULL ; s - > me . score_map = NULL ; s - > dct_error_sum = NULL ; s - > block = NULL ; s - > blocks = NULL ; memset ( s - > pblocks , 0 , sizeof ( s - > pblocks ) ) ; s - > ac_val_base = NULL ; s - > ac_val[0] = s - > ac_val[1] = s - > ac_val[2] =NULL ; s - > sc . edge_emu_buffer = NULL ; s - > me . scratchpad = NULL ; s - > me . temp = s - > sc . rd_scratchpad = s - > sc . b_scratchpad = s - > sc . obmc_scratchpad = NULL ; s - > parse_context . buffer = NULL ; s - > parse_context . buffer_size = 0 ; s - > bitstream_buffer = NULL ; s - > allocated_bitstream_buffer_size = 0 ; s - > picture = NULL ; s - > mb_type = NULL ; s - > p_mv_table_base = NULL ; s - > b_forw_mv_table_base = NULL ; s - > b_back_mv_table_base = NULL ; s - > b_bidir_forw_mv_table_base = NULL ; s - > b_bidir_back_mv_table_base = NULL ; s - > b_direct_mv_table_base = NULL ; s - > p_mv_table = NULL ; s - > b_forw_mv_table = NULL ; s - > b_back_mv_table = NULL ; s - > b_bidir_forw_mv_table = NULL ; s - > b_bidir_back_mv_table = NULL ; s - > b_direct_mv_table = NULL ; for ( i = 0 ; i < 2 ; i + + ) { for ( j = 0 ; j < 2 ; j + + ) { for ( k = 0 ; k < 2 ; k + + ) { s - > b_field_mv_table_base[i][j][k] = NULL ; s - > b_field_mv_table[i][j][k] = NULL ; } s - > b_field_select_table[i][j] = NULL ; s - > p_field_mv_table_base[i][j] = NULL ; s - > p_field_mv_table[i][j] = NULL ; } s - > p_field_select_table[i] = NULL ; } s - > dc_val_base = NULL ; s - > coded_block_base = NULL ; s - > mbintra_table = NULL ; s - > cbp_table = NULL ; s - > pred_dir_table = NULL ; s - > mbskip_table = NULL ; s - > er . error_status_table = NULL ; s - > er . er_temp_buffer = NULL ; s - > mb_index2xy = NULL ; s - > lambda_table = NULL ; s - > cplx_tab = NULL ; s - > bits_tab = NULL ; }",1
"static int blend_frames ( AVFilterContext * ctx , int interpolate ) { FrameRateContext * s = ctx - > priv ; AVFilterLink * outlink = ctx - > outputs[0] ; double interpolate_scene_score = 0 ; if ( ( s - > flags & FRAMERATE_FLAG_SCD ) ) { if ( s - > score > = 0 . 0 ) interpolate_scene_score = s - > score ; else interpolate_scene_score = s - > score = get_scene_score ( ctx , s - > f0 , s - > f1 ) ; ff_dlog ( ctx , blend_frames ( ) interpolate scene score : %f\n , interpolate_scene_score ) ; } // decide if the shot - change detection allows us to blend two frames if ( interpolate_scene_score < s - > scene_score ) { ThreadData td ; td . copy_src1 = s - > f0 ; td . copy_src2 = s - > f1 ; td . src2_factor = interpolate ; td . src1_factor = s - > max - td . src2_factor ; // get work - space for output frame s - > work = ff_get_video_buffer ( outlink , outlink - > w , outlink - > h ) ; if ( ! s - > work ) return AVERROR ( ENOMEM ) ; av_frame_copy_props ( s - > work , s - > f0 ) ; ff_dlog ( ctx , blend_frames ( ) INTERPOLATE to create work frame\n ) ; ctx - > internal - > execute ( ctx , filter_slice , & td , NULL , FFMIN ( outlink - > h , ff_filter_get_nb_threads ( ctx ) ) ) ; return 1 ; } return 0 ; }",1
"static int rac_get_model256_sym ( RangeCoder * c , Model256 * m ) { int prob , prob2 , helper , val ; int start , end ; int ssym ; prob2 = c - > range ; c - > range > > = MODEL_SCALE ; helper = c - > low / c - > range ; ssym = helper > > MODEL256_SEC_SCALE ; val = m - > secondary[ssym] ; end = start = m - > secondary[ssym + 1] + 1 ; while ( end > val + 1 ) { ssym = ( end + val ) > > 1 ; if ( m - > freqs[ssym] < = helper ) { end = start ; val = ssym ; } else { end = ( end + val ) > > 1 ; start = ssym ; } } prob = m - > freqs[val] * c - > range ; if ( val ! = 255 ) prob2 = m - > freqs[val + 1] * c - > range ; c - > low - = prob ; c - > range = prob2 - prob ; if ( c - > range < RAC_BOTTOM ) rac_normalise ( c ) ; model256_update ( m , val ) ; return val ; }",1
"static void test_function ( const TestStruct test_sample ) { int ret , i ; void * * output_data = NULL ; AVAudioFifo * afifo = av_audio_fifo_alloc ( test_sample . format , test_sample . nb_ch , test_sample . nb_samples_pch ) ; if ( ! afifo ) { ERROR ( ERROR : av_audio_fifo_alloc returned NULL ! ) ; } ret = write_samples_to_audio_fifo ( afifo , test_sample , test_sample . nb_samples_pch , 0 ) ; if ( ret < 0 ) { ERROR ( ERROR : av_audio_fifo_write failed ! ) ; } printf ( written : %d\n , ret ) ; ret = write_samples_to_audio_fifo ( afifo , test_sample , test_sample . nb_samples_pch , 0 ) ; if ( ret < 0 ) { ERROR ( ERROR : av_audio_fifo_write failed ! ) ; } printf ( written : %d\n , ret ) ; printf ( remaining samples in audio_fifo : %d\n\n , av_audio_fifo_size ( afifo ) ) ; ret = read_samples_from_audio_fifo ( afifo , & output_data , test_sample . nb_samples_pch ) ; if ( ret < 0 ) { ERROR ( ERROR : av_audio_fifo_read failed ! ) ; } printf ( read : %d\n , ret ) ; print_audio_bytes ( & test_sample , output_data , ret ) ; printf ( remaining samples in audio_fifo : %d\n\n , av_audio_fifo_size ( afifo ) ) ; / * test av_audio_fifo_peek * / ret = av_audio_fifo_peek ( afifo , output_data , afifo - > nb_samples ) ; if ( ret < 0 ) { ERROR ( ERROR : av_audio_fifo_peek failed ! ) ; } printf ( peek : \n ) ; print_audio_bytes ( & test_sample , output_data , ret ) ; printf ( \n ) ; / * test av_audio_fifo_peek_at * / printf ( peek_at : \n ) ; for ( i = 0 ; i < afifo - > nb_samples ; + + i ) { ret = av_audio_fifo_peek_at ( afifo , output_data , 1 , i ) ; if ( ret < 0 ) { ERROR ( ERROR : av_audio_fifo_peek_at failed ! ) ; } printf ( %d : \n , i ) ; print_audio_bytes ( & test_sample , output_data , ret ) ; } printf ( \n ) ; / * test av_audio_fifo_drain * / ret = av_audio_fifo_drain ( afifo , afifo - > nb_samples ) ; if ( ret < 0 ) { ERROR ( ERROR : av_audio_fifo_drain failed ! ) ; } if ( afifo - > nb_samples ) { ERROR ( drain failed to flush all samples in audio_fifo ! ) ; } / * deallocate * / for ( i = 0 ; i < afifo - > nb_buffers ; + + i ) { av_freep ( & output_data[i] ) ; } av_freep ( & output_data ) ; av_audio_fifo_free ( afifo ) ; }",1
"static int parse_bintree ( Indeo3DecodeContext * ctx , AVCodecContext * avctx , Plane * plane , int code , Cell * ref_cell , const int depth , const int strip_width ) { Cell curr_cell ; int bytes_used ; if ( depth < = 0 ) { av_log ( avctx , AV_LOG_ERROR , Stack overflow ( corrupted binary tree ) ! \n ) ; return AVERROR_INVALIDDATA ; // unwind recursion } curr_cell = * ref_cell ; // clone parent cell if ( code == H_SPLIT ) { SPLIT_CELL ( ref_cell - > height , curr_cell . height ) ; ref_cell - > ypos + = curr_cell . height ; ref_cell - > height - = curr_cell . height ; } else if ( code == V_SPLIT ) { if ( curr_cell . width > strip_width ) { / * split strip * / curr_cell . width = ( curr_cell . width < = ( strip_width < < 1 ) ? 1 : 2 ) * strip_width ; } else SPLIT_CELL ( ref_cell - > width , curr_cell . width ) ; ref_cell - > xpos + = curr_cell . width ; ref_cell - > width - = curr_cell . width ; } while ( get_bits_left ( & ctx - > gb ) > = 2 ) { / * loop until return * / RESYNC_BITSTREAM ; switch ( code = get_bits ( & ctx - > gb , 2 ) ) { case H_SPLIT : case V_SPLIT : if ( parse_bintree ( ctx , avctx , plane , code , & curr_cell , depth - 1 , strip_width ) ) return AVERROR_INVALIDDATA ; break ; case INTRA_NULL : if ( ! curr_cell . tree ) { / * MC tree INTRA code * / curr_cell . mv_ptr = 0 ; / * mark the current strip as INTRA * / curr_cell . tree = 1 ; / * enter the VQ tree * / } else { / * VQ tree NULL code * / RESYNC_BITSTREAM ; code = get_bits ( & ctx - > gb , 2 ) ; if ( code > = 2 ) { av_log ( avctx , AV_LOG_ERROR , Invalid VQ_NULL code : %d\n , code ) ; return AVERROR_INVALIDDATA ; } if ( code == 1 ) av_log ( avctx , AV_LOG_ERROR , SkipCell procedure not implemented yet ! \n ) ; CHECK_CELL if ( ! curr_cell . mv_ptr ) return AVERROR_INVALIDDATA ; copy_cell ( ctx , plane , & curr_cell ) ; return 0 ; } break ; case INTER_DATA : if ( ! curr_cell . tree ) { / * MC tree INTER code * / / * get motion vector index and setup the pointer to the mv set * / if ( ! ctx - > need_resync ) ctx - > next_cell_data = & ctx - > gb . buffer[ ( get_bits_count ( & ctx - > gb ) + 7 ) > > 3] ; curr_cell . mv_ptr = & ctx - > mc_vectors[ * ( ctx - > next_cell_data + + ) < < 1] ; curr_cell . tree = 1 ; / * enter the VQ tree * / UPDATE_BITPOS ( 8 ) ; } else { / * VQ tree DATA code * / if ( ! ctx - > need_resync ) ctx - > next_cell_data = & ctx - > gb . buffer[ ( get_bits_count ( & ctx - > gb ) + 7 ) > > 3] ; CHECK_CELL bytes_used = decode_cell ( ctx , avctx , plane , & curr_cell , ctx - > next_cell_data , ctx - > last_byte ) ; if ( bytes_used < 0 ) return AVERROR_INVALIDDATA ; UPDATE_BITPOS ( bytes_used < < 3 ) ; ctx - > next_cell_data + = bytes_used ; return 0 ; } break ; } } //while return AVERROR_INVALIDDATA ; }",1
"static int parse_chunks ( AVFormatContext * s , int mode , int64_t seekts , int * len_ptr ) { WtvContext * wtv = s - > priv_data ; ByteIOContext * pb = wtv - > pb ; while ( ! url_feof ( pb ) ) { ff_asf_guid g ; int len , sid , consumed ; ff_get_guid ( pb , & g ) ; len = get_le32 ( pb ) ; if ( len < 32 ) break ; sid = get_le32 ( pb ) & 0x7FFF ; url_fskip ( pb , 8 ) ; consumed = 32 ; if ( ! ff_guidcmp ( g , stream_guid ) ) { if ( ff_find_stream_index ( s , sid ) < 0 ) { ff_asf_guid mediatype , subtype , formattype ; int size ; consumed + = 20 ; url_fskip ( pb , 16 ) ; if ( get_le32 ( pb ) ) { url_fskip ( pb , 8 ) ; ff_get_guid ( pb , & mediatype ) ; ff_get_guid ( pb , & subtype ) ; url_fskip ( pb , 12 ) ; ff_get_guid ( pb , & formattype ) ; size = get_le32 ( pb ) ; parse_media_type ( s , 0 , sid , mediatype , subtype , formattype , size ) ; consumed + = 72 + size ; } } } else if ( ! ff_guidcmp ( g , stream2_guid ) ) { int stream_index = ff_find_stream_index ( s , sid ) ; if ( stream_index > = 0 & & ! ( ( WtvStream * ) s - > streams[stream_index] - > priv_data ) - > seen_data ) { ff_asf_guid mediatype , subtype , formattype ; int size ; url_fskip ( pb , 12 ) ; ff_get_guid ( pb , & mediatype ) ; ff_get_guid ( pb , & subtype ) ; url_fskip ( pb , 12 ) ; ff_get_guid ( pb , & formattype ) ; size = get_le32 ( pb ) ; parse_media_type ( s , s - > streams[stream_index] , sid , mediatype , subtype , formattype , size ) ; consumed + = 76 + size ; } } else if ( ! ff_guidcmp ( g , EVENTID_AudioDescriptorSpanningEvent ) || ! ff_guidcmp ( g , EVENTID_CtxADescriptorSpanningEvent ) || ! ff_guidcmp ( g , EVENTID_CSDescriptorSpanningEvent ) || ! ff_guidcmp ( g , EVENTID_StreamIDSpanningEvent ) || ! ff_guidcmp ( g , EVENTID_SubtitleSpanningEvent ) || ! ff_guidcmp ( g , EVENTID_TeletextSpanningEvent ) ) { int stream_index = ff_find_stream_index ( s , sid ) ; if ( stream_index > = 0 ) { AVStream * st = s - > streams[stream_index] ; uint8_t buf[258] ; const uint8_t * pbuf = buf ; int buf_size ; url_fskip ( pb , 8 ) ; consumed + = 8 ; if ( ! ff_guidcmp ( g , EVENTID_CtxADescriptorSpanningEvent ) || ! ff_guidcmp ( g , EVENTID_CSDescriptorSpanningEvent ) ) { url_fskip ( pb , 6 ) ; consumed + = 6 ; } buf_size = FFMIN ( len - consumed , sizeof ( buf ) ) ; get_buffer ( pb , buf , buf_size ) ; consumed + = buf_size ; ff_parse_mpeg2_descriptor ( s , st , 0 , & pbuf , buf + buf_size , 0 , 0 , 0 , 0 ) ; } } else if ( ! ff_guidcmp ( g , EVENTID_DVBScramblingControlSpanningEvent ) ) { int stream_index = ff_find_stream_index ( s , sid ) ; if ( stream_index > = 0 ) { url_fskip ( pb , 12 ) ; if ( get_le32 ( pb ) ) av_log ( s , AV_LOG_WARNING , DVB scrambled stream detected ( st : %d ) , decoding will likely fail\n , stream_index ) ; consumed + = 16 ; } } else if ( ! ff_guidcmp ( g , EVENTID_LanguageSpanningEvent ) ) { int stream_index = ff_find_stream_index ( s , sid ) ; if ( stream_index > = 0 ) { AVStream * st = s - > streams[stream_index] ; uint8_t language[4] ; url_fskip ( pb , 12 ) ; get_buffer ( pb , language , 3 ) ; if ( language[0] ) { language[3] = 0 ; av_metadata_set2 ( & st - > metadata , language , language , 0 ) ; } consumed + = 15 ; } } else if ( ! ff_guidcmp ( g , timestamp_guid ) ) { int stream_index = ff_find_stream_index ( s , sid ) ; if ( stream_index > = 0 ) { url_fskip ( pb , 8 ) ; wtv - > pts = get_le64 ( pb ) ; consumed + = 16 ; if ( wtv - > pts == - 1 ) wtv - > pts = AV_NOPTS_VALUE ; else { wtv - > last_valid_pts = wtv - > pts ; if ( wtv - > epoch == AV_NOPTS_VALUE || wtv - > pts < wtv - > epoch ) wtv - > epoch = wtv - > pts ; if ( mode == SEEK_TO_PTS & & wtv - > pts > = seekts ) { define WTV_PAD8 ( x ) ( ( ( x ) + 7 ) & 7 ) url_fskip ( pb , WTV_PAD8 ( len ) - consumed ) ; return 0 ; } } } } else if ( ! ff_guidcmp ( g , data_guid ) ) { int stream_index = ff_find_stream_index ( s , sid ) ; if ( mode == SEEK_TO_DATA & & stream_index > = 0 ) { WtvStream * wst = s - > streams[stream_index] - > priv_data ; wst - > seen_data = 1 ; if ( len_ptr ) { * len_ptr = len ; } return stream_index ; } } else if ( ! ff_guidcmp ( g , / * DSATTRIB_CAPTURE_STREAMTIME * / ( const ff_asf_guid ) { 0x14 , 0x56 , 0x1A , 0x0C , 0xCD , 0x30 , 0x40 , 0x4F , 0xBC , 0xBF , 0xD0 , 0x3E , 0x52 , 0x30 , 0x62 , 0x07 } ) || ! ff_guidcmp ( g , / * DSATTRIB_PicSampleSeq * / ( const ff_asf_guid ) { 0x02 , 0xAE , 0x5B , 0x2F , 0x8F , 0x7B , 0x60 , 0x4F , 0x82 , 0xD6 , 0xE4 , 0xEA , 0x2F , 0x1F , 0x4C , 0x99 } ) || ! ff_guidcmp ( g , / * DSATTRIB_TRANSPORT_PROPERTIES * / ( const ff_asf_guid ) { 0x12 , 0xF6 , 0x22 , 0xB6 , 0xAD , 0x47 , 0x71 , 0x46 , 0xAD , 0x6C , 0x05 , 0xA9 , 0x8E , 0x65 , 0xDE , 0x3A } ) || ! ff_guidcmp ( g , / * dvr_ms_vid_frame_rep_data * / ( const ff_asf_guid ) { 0xCC , 0x32 , 0x64 , 0xDD , 0x29 , 0xE2 , 0xDB , 0x40 , 0x80 , 0xF6 , 0xD2 , 0x63 , 0x28 , 0xD2 , 0x76 , 0x1F } ) || ! ff_guidcmp ( g , / * EVENTID_AudioTypeSpanningEvent * / ( const ff_asf_guid ) { 0xBE , 0xBF , 0x1C , 0x50 , 0x49 , 0xB8 , 0xCE , 0x42 , 0x9B , 0xE9 , 0x3D , 0xB8 , 0x69 , 0xFB , 0x82 , 0xB3 } ) || ! ff_guidcmp ( g , / * EVENTID_ChannelChangeSpanningEvent *",0
"int ff_replaygain_export ( AVStream * st , AVDictionary * metadata ) { const AVDictionaryEntry * tg , * tp , * ag , * ap ; tg = av_dict_get ( metadata , REPLAYGAIN_TRACK_GAIN , NULL , 0 ) ; tp = av_dict_get ( metadata , REPLAYGAIN_TRACK_PEAK , NULL , 0 ) ; ag = av_dict_get ( metadata , REPLAYGAIN_ALBUM_GAIN , NULL , 0 ) ; ap = av_dict_get ( metadata , REPLAYGAIN_ALBUM_PEAK , NULL , 0 ) ; return replaygain_export ( st , tg ? tg - > value : NULL , tp ? tp - > value : NULL , ag ? ag - > value : NULL , ap ? ap - > value : NULL ) ; }",0
"static void ac3_decode_transform_coeffs_ch ( AC3DecodeContext * s , int ch_index , mant_groups * m ) { int start_freq = s - > start_freq[ch_index] ; int end_freq = s - > end_freq[ch_index] ; uint8_t * baps = s - > bap[ch_index] ; int8_t * exps = s - > dexps[ch_index] ; int32_t * coeffs = s - > fixed_coeffs[ch_index] ; int dither = ( ch_index == CPL_CH ) || s - > dither_flag[ch_index] ; GetBitContext * gbc = & s - > gbc ; int freq ; for ( freq = start_freq ; freq < end_freq ; freq + + ) { int bap = baps[freq] ; int mantissa ; switch ( bap ) { case 0 : / * random noise with approximate range of - 0 . 707 to 0 . 707 * / if ( dither ) mantissa = ( ( ( av_lfg_get ( & s - > dith_state ) > > 8 ) * 181 ) > > 8 ) - 5931008 ; else mantissa = 0 ; break ; case 1 : if ( m - > b1 ) { m - > b1 - - ; mantissa = m - > b1_mant[m - > b1] ; } else { int bits = get_bits ( gbc , 5 ) ; mantissa = b1_mantissas[bits][0] ; m - > b1_mant[1] = b1_mantissas[bits][1] ; m - > b1_mant[0] = b1_mantissas[bits][2] ; m - > b1 = 2 ; break ; case 2 : if ( m - > b2 ) { m - > b2 - - ; mantissa = m - > b2_mant[m - > b2] ; } else { int bits = get_bits ( gbc , 7 ) ; mantissa = b2_mantissas[bits][0] ; m - > b2_mant[1] = b2_mantissas[bits][1] ; m - > b2_mant[0] = b2_mantissas[bits][2] ; m - > b2 = 2 ; break ; case 3 : mantissa = b3_mantissas[get_bits ( gbc , 3 ) ] ; break ; case 4 : if ( m - > b4 ) { m - > b4 = 0 ; mantissa = m - > b4_mant ; } else { int bits = get_bits ( gbc , 7 ) ; mantissa = b4_mantissas[bits][0] ; m - > b4_mant = b4_mantissas[bits][1] ; m - > b4 = 1 ; break ; case 5 : mantissa = b5_mantissas[get_bits ( gbc , 4 ) ] ; break ; default : / * 6 to 15 * / / * Shift mantissa and sign - extend it . * / mantissa = get_sbits ( gbc , quantization_tab[bap] ) ; mantissa < < = 24 - quantization_tab[bap] ; break ; coeffs[freq] = mantissa > > exps[freq] ;",1
"static void draw_bar ( TestSourceContext * test , const uint8_t color[4] , unsigned x , unsigned y , unsigned w , unsigned h , AVFrame * frame ) { const AVPixFmtDescriptor * desc = av_pix_fmt_desc_get ( frame - > format ) ; uint8_t * p , * p0 ; int plane ; x = FFMIN ( x , test - > w - 1 ) ; y = FFMIN ( y , test - > h - 1 ) ; w = FFMIN ( w , test - > w - x ) ; h = FFMIN ( h , test - > h - y ) ; av_assert0 ( x + w < = test - > w ) ; av_assert0 ( y + h < = test - > h ) ; for ( plane = 0 ; frame - > data[plane] ; plane + + ) { const int c = color[plane] ; const int linesize = frame - > linesize[plane] ; int i , px , py , pw , ph ; if ( plane == 1 || plane == 2 ) { px = x > > desc - > log2_chroma_w ; pw = w > > desc - > log2_chroma_w ; py = y > > desc - > log2_chroma_h ; ph = h > > desc - > log2_chroma_h ; } else { px = x ; pw = w ; py = y ; ph = h ; } p0 = p = frame - > data[plane] + py * linesize + px ; memset ( p , c , pw ) ; p + = linesize ; for ( i = 1 ; i < ph ; i + + , p + = linesize ) memcpy ( p , p0 , pw ) ; } }",1
"static inline int64_t gb_get_v ( GetBitContext * gb ) { int64_t v = 0 ; int bits = 0 ; while ( get_bits1 ( gb ) & & bits < 64 - 7 ) { v < < = 7 ; v |= get_bits ( gb , 7 ) ; bits + = 7 ; } v < < = 7 ; v |= get_bits ( gb , 7 ) ; return v ; }",1
"static void ff_wmv2_idct_put_c ( uint8_t * dest , int line_size , DCTELEM * block ) { ff_wmv2_idct_c ( block ) ; put_pixels_clamped_c ( block , dest , line_size ) ; }",1
"static int unpack_vlcs ( Vp3DecodeContext * s , GetBitContext * gb , VLC * table , int coeff_index , int plane , int eob_run ) { int i , j = 0 ; int token ; int zero_run = 0 ; DCTELEM coeff = 0 ; int bits_to_get ; int blocks_ended ; int coeff_i = 0 ; int num_coeffs = s - > num_coded_frags[plane][coeff_index] ; int16_t * dct_tokens = s - > dct_tokens[plane][coeff_index] ; / * local references to structure members to avoid repeated deferences * / int * coded_fragment_list = s - > coded_fragment_list[plane] ; Vp3Fragment * all_fragments = s - > all_fragments ; VLC_TYPE ( * vlc_table ) [2] = table - > table ; if ( num_coeffs < 0 ) av_log ( s - > avctx , AV_LOG_ERROR , Invalid number of coefficents at level %d\n , coeff_index ) ; if ( eob_run > num_coeffs ) { coeff_i = blocks_ended = num_coeffs ; eob_run - = num_coeffs ; } else { coeff_i = blocks_ended = eob_run ; eob_run = 0 ; } // insert fake EOB token to cover the split between planes or zzi if ( blocks_ended ) dct_tokens[j + + ] = blocks_ended < < 2 ; while ( coeff_i < num_coeffs & & get_bits_left ( gb ) > 0 ) { / * decode a VLC into a token * / token = get_vlc2 ( gb , vlc_table , 11 , 3 ) ; / * use the token to get a zero run , a coefficient , and an eob run * / if ( token < = 6 ) { eob_run = eob_run_base[token] ; if ( eob_run_get_bits[token] ) eob_run + = get_bits ( gb , eob_run_get_bits[token] ) ; // record only the number of blocks ended in this plane , // any spill will be recorded in the next plane . if ( eob_run > num_coeffs - coeff_i ) { dct_tokens[j + + ] = TOKEN_EOB ( num_coeffs - coeff_i ) ; blocks_ended + = num_coeffs - coeff_i ; eob_run - = num_coeffs - coeff_i ; coeff_i = num_coeffs ; } else { dct_tokens[j + + ] = TOKEN_EOB ( eob_run ) ; blocks_ended + = eob_run ; coeff_i + = eob_run ; eob_run = 0 ; } } else { bits_to_get = coeff_get_bits[token] ; if ( bits_to_get ) bits_to_get = get_bits ( gb , bits_to_get ) ; coeff = coeff_tables[token][bits_to_get] ; zero_run = zero_run_base[token] ; if ( zero_run_get_bits[token] ) zero_run + = get_bits ( gb , zero_run_get_bits[token] ) ; if ( zero_run ) { dct_tokens[j + + ] = TOKEN_ZERO_RUN ( coeff , zero_run ) ; } else { // Save DC into the fragment structure . DC prediction is // done in raster order , so the actual DC can ' t be in with // other tokens . We still need the token in dct_tokens[] // however , or else the structure collapses on itself . if ( ! coeff_index ) all_fragments[coded_fragment_list[coeff_i]] . dc = coeff ; dct_tokens[j + + ] = TOKEN_COEFF ( coeff ) ; } if ( coeff_index + zero_run > 64 ) { av_log ( s - > avctx , AV_LOG_DEBUG , Invalid zero run of %d with %d coeffs left\n , zero_run , 64 - coeff_index ) ; zero_run = 64 - coeff_index ; } // zero runs code multiple coefficients , // so don ' t try to decode coeffs for those higher levels for ( i = coeff_index + 1 ; i < = coeff_index + zero_run ; i + + ) s - > num_coded_frags[plane][i] - - ; coeff_i + + ; } } if ( blocks_ended > s - > num_coded_frags[plane][coeff_index] ) av_log ( s - > avctx , AV_LOG_ERROR , More blocks ended than coded ! \n ) ; // decrement the number of blocks that have higher coeffecients for each // EOB run at this level if ( blocks_ended ) for ( i = coeff_index + 1 ; i < 64 ; i + + ) s - > num_coded_frags[plane][i] - = blocks_ended ; // setup the next buffer if ( plane < 2 ) s - > dct_tokens[plane + 1][coeff_index] = dct_tokens + j ; else if ( coeff_index < 63 ) s - > dct_tokens[0][coeff_index + 1] = dct_tokens + j ; return eob_run ; }",1
"int ff_copy_whitelists ( AVFormatContext * dst , AVFormatContext * src ) { av_assert0 ( ! dst - > codec_whitelist & & ! dst - > format_whitelist ) ; dst - > codec_whitelist = av_strdup ( src - > codec_whitelist ) ; dst - > format_whitelist = av_strdup ( src - > format_whitelist ) ; if ( ( src - > codec_whitelist & & ! dst - > codec_whitelist ) || ( src - > format_whitelist & & ! dst - > format_whitelist ) ) { av_log ( dst , AV_LOG_ERROR , Failed to duplicate whitelist\n ) ; return AVERROR ( ENOMEM ) ; } return 0 ; }",0
"static void init_dequant4_coeff_table ( H264Context * h ) { int i , j , q , x ; const int transpose = ( h - > h264dsp . h264_idct_add ! = ff_h264_idct_add_c ) ; //FIXME ugly for ( i=0 ; i < 6 ; i + + ) { h - > dequant4_coeff[i] = h - > dequant4_buffer[i] ; for ( j=0 ; j < i ; j + + ) { if ( ! memcmp ( h - > pps . scaling_matrix4[j] , h - > pps . scaling_matrix4[i] , 16 * sizeof ( uint8_t ) ) ) { h - > dequant4_coeff[i] = h - > dequant4_buffer[j] ; break ; } } if ( j < i ) continue ; for ( q=0 ; q < 52 ; q + + ) { int shift = div6[q] + 2 ; int idx = rem6[q] ; for ( x=0 ; x < 16 ; x + + ) h - > dequant4_coeff[i][q][transpose ? ( x > > 2 ) | ( ( x < < 2 ) & 0xF ) : x] = ( ( uint32_t ) dequant4_coeff_init[idx][ ( x & 1 ) + ( ( x > > 2 ) & 1 ) ] * h - > pps . scaling_matrix4[i][x] ) < < shift ; } } }",0
"static int mpeg_mux_write_packet ( AVFormatContext * ctx , AVPacket * pkt ) { MpegMuxContext * s = ctx - > priv_data ; int stream_index= pkt - > stream_index ; int size= pkt - > size ; uint8_t * buf= pkt - > data ; AVStream * st = ctx - > streams[stream_index] ; StreamInfo * stream = st - > priv_data ; int64_t pts , dts , new_start_pts , new_start_dts ; int len , avail_size ; //XXX/FIXME this is and always was broken // compute_pts_dts ( st , & pts , & dts , pkt - > pts ) ; pts= pkt - > pts ; dts= pkt - > dts ; if ( s - > is_svcd ) { / * offset pts and dts slightly into the future to be able to do the compatibility fix below . * / pts = ( pts + 2 ) & ( ( 1LL < < 33 ) - 1 ) ; dts = ( dts + 2 ) & ( ( 1LL < < 33 ) - 1 ) ; if ( stream - > packet_number == 0 & & dts == pts ) / * For the very first packet we want to force the DTS to be included . This increases compatibility with lots of DVD players . Since the MPEG - 2 standard mandates that DTS is only written when it is different from PTS we have to move it slightly into the past . * / dts = ( dts - 2 ) & ( ( 1LL < < 33 ) - 1 ) ; } if ( s - > is_vcd ) { / * We have to offset the PTS , so that it is consistent with the SCR . SCR starts at 36000 , but the first two packs contain only padding and the first pack from the other stream , respectively , may also have been written before . So the real data starts at SCR 36000 + 3 * 1200 . * / pts = ( pts + 36000 + 3600 ) & ( ( 1LL < < 33 ) - 1 ) ; dts = ( dts + 36000 + 3600 ) & ( ( 1LL < < 33 ) - 1 ) ; } if 0 update_scr ( ctx , stream_index , pts ) ; printf ( %d : pts=%0 . 3f dts=%0 . 3f scr=%0 . 3f\n , stream_index , pts / 90000 . 0 , dts / 90000 . 0 , s - > last_scr / 90000 . 0 ) ; endif / * we assume here that pts ! = AV_NOPTS_VALUE * / new_start_pts = stream - > start_pts ; new_start_dts = stream - > start_dts ; if ( stream - > start_pts == AV_NOPTS_VALUE ) { new_start_pts = pts ; new_start_dts = dts ; } avail_size = get_packet_payload_size ( ctx , stream_index , new_start_pts , new_start_dts ) ; if ( stream - > buffer_ptr > = avail_size ) { update_scr ( ctx , stream_index , stream - > start_pts ) ; / * unlikely case : outputing the pts or dts increase the packet size so that we cannot write the start of the next packet . In this case , we must flush the current packet with padding . Note : this always happens for the first audio and video packet in a VCD file , since they do not carry any data . * / flush_packet ( ctx , stream_index , stream - > start_pts , stream - > start_dts , s - > last_scr ) ; stream - > buffer_ptr = 0 ; } stream - > start_pts = new_start_pts ; stream - > start_dts = new_start_dts ; stream - > nb_frames + + ; if ( stream - > frame_start_offset == 0 ) stream - > frame_start_offset = stream - > buffer_ptr ; while ( size > 0 ) { avail_size = get_packet_payload_size ( ctx , stream_index , stream - > start_pts , stream - > start_dts ) ; len = avail_size - stream - > buffer_ptr ; if ( len > size ) len = size ; memcpy ( stream - > buffer + stream - > buffer_ptr , buf , len ) ; stream - > buffer_ptr + = len ; buf + = len ; size - = len ; if ( stream - > buffer_ptr > = avail_size ) { update_scr ( ctx , stream_index , stream - > start_pts ) ; / * if packet full , we send it now * / flush_packet ( ctx , stream_index , stream - > start_pts , stream - > start_dts , s - > last_scr ) ; stream - > buffer_ptr = 0 ; if ( s - > is_vcd ) { / * Write one or more padding sectors , if necessary , to reach the constant overall bitrate . * / int vcd_pad_bytes ; while ( ( vcd_pad_bytes = get_vcd_padding_size ( ctx , stream - > start_pts ) ) > = s - > packet_size ) put_vcd_padding_sector ( ctx ) ; } / * Make sure only the FIRST pes packet for this frame has a timestamp * / stream - > start_pts = AV_NOPTS_VALUE ; stream - > start_dts = AV_NOPTS_VALUE ; } } return 0 ; }",0
"static int decode_end ( AVCodecContext * avctx ) { KmvcContext * const c = ( KmvcContext * ) avctx - > priv_data ; if ( c - > frm0 ) av_free ( c - > frm0 ) ; if ( c - > frm1 ) av_free ( c - > frm1 ) ; if ( c - > pic . data[0] ) avctx - > release_buffer ( avctx , & c - > pic ) ; return 0 ; }",0
"SwsFilter * sws_getDefaultFilter ( float lumaGBlur , float chromaGBlur , float lumaSharpen , float chromaSharpen , float chromaHShift , float chromaVShift , int verbose ) { SwsFilter * filter = av_malloc ( sizeof ( SwsFilter ) ) ; if ( ! filter ) return NULL ; if ( lumaGBlur ! = 0 . 0 ) { filter - > lumH = sws_getGaussianVec ( lumaGBlur , 3 . 0 ) ; filter - > lumV = sws_getGaussianVec ( lumaGBlur , 3 . 0 ) ; } else { filter - > lumH = sws_getIdentityVec ( ) ; filter - > lumV = sws_getIdentityVec ( ) ; } if ( chromaGBlur ! = 0 . 0 ) { filter - > chrH = sws_getGaussianVec ( chromaGBlur , 3 . 0 ) ; filter - > chrV = sws_getGaussianVec ( chromaGBlur , 3 . 0 ) ; } else { filter - > chrH = sws_getIdentityVec ( ) ; filter - > chrV = sws_getIdentityVec ( ) ; } if ( ! filter - > lumH || ! filter - > lumV || ! filter - > chrH || ! filter - > chrV ) { sws_freeVec ( filter - > lumH ) ; sws_freeVec ( filter - > lumV ) ; sws_freeVec ( filter - > chrH ) ; sws_freeVec ( filter - > chrV ) ; av_freep ( & filter ) ; return NULL ; } if ( chromaSharpen ! = 0 . 0 ) { SwsVector * id = sws_getIdentityVec ( ) ; sws_scaleVec ( filter - > chrH , - chromaSharpen ) ; sws_scaleVec ( filter - > chrV , - chromaSharpen ) ; sws_addVec ( filter - > chrH , id ) ; sws_addVec ( filter - > chrV , id ) ; sws_freeVec ( id ) ; } if ( lumaSharpen ! = 0 . 0 ) { SwsVector * id = sws_getIdentityVec ( ) ; sws_scaleVec ( filter - > lumH , - lumaSharpen ) ; sws_scaleVec ( filter - > lumV , - lumaSharpen ) ; sws_addVec ( filter - > lumH , id ) ; sws_addVec ( filter - > lumV , id ) ; sws_freeVec ( id ) ; } if ( chromaHShift ! = 0 . 0 ) sws_shiftVec ( filter - > chrH , ( int ) ( chromaHShift + 0 . 5 ) ) ; if ( chromaVShift ! = 0 . 0 ) sws_shiftVec ( filter - > chrV , ( int ) ( chromaVShift + 0 . 5 ) ) ; sws_normalizeVec ( filter - > chrH , 1 . 0 ) ; sws_normalizeVec ( filter - > chrV , 1 . 0 ) ; sws_normalizeVec ( filter - > lumH , 1 . 0 ) ; sws_normalizeVec ( filter - > lumV , 1 . 0 ) ; if ( verbose ) sws_printVec2 ( filter - > chrH , NULL , AV_LOG_DEBUG ) ; if ( verbose ) sws_printVec2 ( filter - > lumH , NULL , AV_LOG_DEBUG ) ; return filter ; }",0
"static int decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; MPADecodeContext * s = avctx - > priv_data ; uint32_t header ; int out_size ; OUT_INT * out_samples = data ; if ( buf_size < HEADER_SIZE ) return AVERROR_INVALIDDATA ; header = AV_RB32 ( buf ) ; if ( ff_mpa_check_header ( header ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , Header missing\n ) ; return AVERROR_INVALIDDATA ; } if ( avpriv_mpegaudio_decode_header ( ( MPADecodeHeader * ) s , header ) == 1 ) { / * free format : prepare to compute frame size * / s - > frame_size = - 1 ; return AVERROR_INVALIDDATA ; } / * update codec info * / avctx - > channels = s - > nb_channels ; avctx - > channel_layout = s - > nb_channels == 1 ? AV_CH_LAYOUT_MONO : AV_CH_LAYOUT_STEREO ; if ( ! avctx - > bit_rate ) avctx - > bit_rate = s - > bit_rate ; avctx - > sub_id = s - > layer ; if ( * data_size < 1152 * avctx - > channels * sizeof ( OUT_INT ) ) return AVERROR ( EINVAL ) ; * data_size = 0 ; if ( s - > frame_size < = 0 || s - > frame_size > buf_size ) { av_log ( avctx , AV_LOG_ERROR , incomplete frame\n ) ; return AVERROR_INVALIDDATA ; } else if ( s - > frame_size < buf_size ) { av_log ( avctx , AV_LOG_ERROR , incorrect frame size\n ) ; buf_size= s - > frame_size ; } out_size = mp_decode_frame ( s , out_samples , buf , buf_size ) ; if ( out_size > = 0 ) { * data_size = out_size ; avctx - > sample_rate = s - > sample_rate ; //FIXME maybe move the other codec info stuff from above here too } else { av_log ( avctx , AV_LOG_ERROR , Error while decoding MPEG audio frame . \n ) ; / * Only return an error if the bad frame makes up the whole packet . If there is more data in the packet , just consume the bad frame instead of returning an error , which would discard the whole packet . * / if ( buf_size == avpkt - > size ) return out_size ; } s - > frame_size = 0 ; return buf_size ; }",0
"static void decode_interframe_v4 ( AVCodecContext * avctx , uint8_t * src , uint32_t size ) { Hnm4VideoContext * hnm = avctx - > priv_data ; GetByteContext gb ; uint32_t writeoffset = 0 , count , left , offset ; uint8_t tag , previous , backline , backward , swap ; bytestream2_init ( & gb , src , size ) ; while ( bytestream2_tell ( & gb ) < size ) { count = bytestream2_peek_byte ( & gb ) & 0x1F ; if ( count == 0 ) { tag = bytestream2_get_byte ( & gb ) & 0xE0 ; tag = tag > > 5 ; if ( tag == 0 ) { hnm - > current[writeoffset + + ] = bytestream2_get_byte ( & gb ) ; hnm - > current[writeoffset + + ] = bytestream2_get_byte ( & gb ) ; } else if ( tag == 1 ) { writeoffset + = bytestream2_get_byte ( & gb ) * 2 ; } else if ( tag == 2 ) { count = bytestream2_get_le16 ( & gb ) ; count * = 2 ; writeoffset + = count ; } else if ( tag == 3 ) { count = bytestream2_get_byte ( & gb ) * 2 ; while ( count > 0 ) { hnm - > current[writeoffset + + ] = bytestream2_peek_byte ( & gb ) ; count - - ; } bytestream2_skip ( & gb , 1 ) ; } else { break ; } } else { previous = bytestream2_peek_byte ( & gb ) & 0x20 ; backline = bytestream2_peek_byte ( & gb ) & 0x40 ; backward = bytestream2_peek_byte ( & gb ) & 0x80 ; bytestream2_skip ( & gb , 1 ) ; swap = bytestream2_peek_byte ( & gb ) & 0x01 ; offset = bytestream2_get_le16 ( & gb ) ; offset = ( offset > > 1 ) & 0x7FFF ; offset = writeoffset + ( offset * 2 ) - 0x8000 ; left = count ; if ( ! backward & & offset + count > = hnm - > width * hnm - > height ) { av_log ( avctx , AV_LOG_ERROR , Attempting to read out of bounds ) ; break ; } else if ( backward & & offset > = hnm - > width * hnm - > height ) { av_log ( avctx , AV_LOG_ERROR , Attempting to read out of bounds ) ; break ; } else if ( writeoffset + count > = hnm - > width * hnm - > height ) { av_log ( avctx , AV_LOG_ERROR , Attempting to write out of bounds ) ; break ; } if ( previous ) { while ( left > 0 ) { if ( backline ) { hnm - > current[writeoffset + + ] = hnm - > previous[offset - ( 2 * hnm - > width ) + 1] ; hnm - > current[writeoffset + + ] = hnm - > previous[offset + + ] ; offset + + ; } else { hnm - > current[writeoffset + + ] = hnm - > previous[offset + + ] ; hnm - > current[writeoffset + + ] = hnm - > previous[offset + + ] ; } if ( backward ) offset - = 4 ; left - - ; } } else { while ( left > 0 ) { if ( backline ) { hnm - > current[writeoffset + + ] = hnm - > current[offset - ( 2 * hnm - > width ) + 1] ; hnm - > current[writeoffset + + ] = hnm - > current[offset + + ] ; offset + + ; } else { hnm - > current[writeoffset + + ] = hnm - > current[offset + + ] ; hnm - > current[writeoffset + + ] = hnm - > current[offset + + ] ; } if ( backward ) offset - = 4 ; left - - ; } } if ( swap ) { left = count ; writeoffset - = count * 2 ; while ( left > 0 ) { swap = hnm - > current[writeoffset] ; hnm - > current[writeoffset] = hnm - > current[writeoffset + 1] ; hnm - > current[writeoffset + 1] = swap ; left - - ; writeoffset + = 2 ; } } } } }",0
"static void ff_h264_idct_add16_mmx2 ( uint8_t * dst , const int * block_offset , DCTELEM * block , int stride , const uint8_t nnzc[6 * 8] ) { int i ; for ( i=0 ; i < 16 ; i + + ) { int nnz = nnzc[ scan8[i] ] ; if ( nnz ) { if ( nnz==1 & & block[i * 16] ) ff_h264_idct_dc_add_mmx2 ( dst + block_offset[i] , block + i * 16 , stride ) ; else ff_h264_idct_add_mmx ( dst + block_offset[i] , block + i * 16 , stride ) ; } } }",0
"static void check_cpu_flag ( const char * name , int flag ) { int old_cpu_flag = state . cpu_flag ; flag |= old_cpu_flag ; av_set_cpu_flags_mask ( flag ) ; state . cpu_flag = av_get_cpu_flags ( ) ; if ( ! flag || state . cpu_flag ! = old_cpu_flag ) { int i ; state . cpu_flag_name = name ; for ( i = 0 ; tests[i] . func ; i + + ) { state . current_test_name = tests[i] . name ; tests[i] . func ( ) ; } } }",0
static av_cold int pcx_encode_close ( AVCodecContext * avctx ) { av_frame_free ( & avctx - > coded_frame ) ; return 0 ; },0
"static void fill_double_array ( AVLFG * lfg , double * a , int len ) { int i ; double bmg[2] , stddev = 10 . 0 , mean = 0 . 0 ; for ( i = 0 ; i < len ; i + = 2 ) { av_bmg_get ( lfg , bmg ) ; a[i] = bmg[0] * stddev + mean ; a[i + 1] = bmg[1] * stddev + mean ; } }",0
"static void init_input_filter ( FilterGraph * fg , AVFilterInOut * in ) { InputStream * ist = NULL ; enum AVMediaType type = avfilter_pad_get_type ( in - > filter_ctx - > input_pads , in - > pad_idx ) ; int i ; // TODO : support other filter types if ( type ! = AVMEDIA_TYPE_VIDEO & & type ! = AVMEDIA_TYPE_AUDIO ) { av_log ( NULL , AV_LOG_FATAL , Only video and audio filters supported currently . \n ) ; exit ( 1 ) ; } if ( in - > name ) { AVFormatContext * s ; AVStream * st = NULL ; char * p ; int file_idx = strtol ( in - > name , & p , 0 ) ; if ( file_idx < 0 || file_idx > = nb_input_files ) { av_log ( NULL , AV_LOG_FATAL , Invalid file index %d in filtegraph description %s . \n , file_idx , fg - > graph_desc ) ; exit ( 1 ) ; } s = input_files[file_idx] - > ctx ; for ( i = 0 ; i < s - > nb_streams ; i + + ) { if ( s - > streams[i] - > codecpar - > codec_type ! = type ) continue ; if ( check_stream_specifier ( s , s - > streams[i] , * p == ' : ' ? p + 1 : p ) == 1 ) { st = s - > streams[i] ; break ; } } if ( ! st ) { av_log ( NULL , AV_LOG_FATAL , Stream specifier ' %s ' in filtergraph description %s matches no streams . \n , p , fg - > graph_desc ) ; exit ( 1 ) ; } ist = input_streams[input_files[file_idx] - > ist_index + st - > index] ; } else { / * find the first unused stream of corresponding type * / for ( i = 0 ; i < nb_input_streams ; i + + ) { ist = input_streams[i] ; if ( ist - > dec_ctx - > codec_type == type & & ist - > discard ) break ; } if ( i == nb_input_streams ) { av_log ( NULL , AV_LOG_FATAL , Cannot find a matching stream for unlabeled input pad %d on filter %s\n , in - > pad_idx , in - > filter_ctx - > name ) ; exit ( 1 ) ; } } av_assert0 ( ist ) ; ist - > discard = 0 ; ist - > decoding_needed = 1 ; ist - > st - > discard = AVDISCARD_NONE ; GROW_ARRAY ( fg - > inputs , fg - > nb_inputs ) ; if ( ! ( fg - > inputs[fg - > nb_inputs - 1] = av_mallocz ( sizeof ( * fg - > inputs[0] ) ) ) ) exit ( 1 ) ; fg - > inputs[fg - > nb_inputs - 1] - > ist = ist ; fg - > inputs[fg - > nb_inputs - 1] - > graph = fg ; fg - > inputs[fg - > nb_inputs - 1] - > format = - 1 ; fg - > inputs[fg - > nb_inputs - 1] - > frame_queue = av_fifo_alloc ( 8 * sizeof ( AVFrame * ) ) ; if ( ! fg - > inputs[fg - > nb_inputs - 1] ) exit_program ( 1 ) ; GROW_ARRAY ( ist - > filters , ist - > nb_filters ) ; ist - > filters[ist - > nb_filters - 1] = fg - > inputs[fg - > nb_inputs - 1] ; }",0
"static void derive_spatial_merge_candidates ( HEVCContext * s , int x0 , int y0 , int nPbW , int nPbH , int log2_cb_size , int singleMCLFlag , int part_idx , int merge_idx , struct MvField mergecandlist[] ) { HEVCLocalContext * lc = & s - > HEVClc ; RefPicList * refPicList = s - > ref - > refPicList ; MvField * tab_mvf = s - > ref - > tab_mvf ; const int min_pu_width = s - > sps - > min_pu_width ; const int cand_bottom_left = lc - > na . cand_bottom_left ; const int cand_left = lc - > na . cand_left ; const int cand_up_left = lc - > na . cand_up_left ; const int cand_up = lc - > na . cand_up ; const int cand_up_right = lc - > na . cand_up_right_sap ; const int xA1 = x0 - 1 ; const int yA1 = y0 + nPbH - 1 ; const int xA1_pu = xA1 > > s - > sps - > log2_min_pu_size ; const int yA1_pu = yA1 > > s - > sps - > log2_min_pu_size ; const int xB1 = x0 + nPbW - 1 ; const int yB1 = y0 - 1 ; const int xB1_pu = xB1 > > s - > sps - > log2_min_pu_size ; const int yB1_pu = yB1 > > s - > sps - > log2_min_pu_size ; const int xB0 = x0 + nPbW ; const int yB0 = y0 - 1 ; const int xB0_pu = xB0 > > s - > sps - > log2_min_pu_size ; const int yB0_pu = yB0 > > s - > sps - > log2_min_pu_size ; const int xA0 = x0 - 1 ; const int yA0 = y0 + nPbH ; const int xA0_pu = xA0 > > s - > sps - > log2_min_pu_size ; const int yA0_pu = yA0 > > s - > sps - > log2_min_pu_size ; const int xB2 = x0 - 1 ; const int yB2 = y0 - 1 ; const int xB2_pu = xB2 > > s - > sps - > log2_min_pu_size ; const int yB2_pu = yB2 > > s - > sps - > log2_min_pu_size ; const int nb_refs = ( s - > sh . slice_type == P_SLICE ) ? s - > sh . nb_refs[0] : FFMIN ( s - > sh . nb_refs[0] , s - > sh . nb_refs[1] ) ; int check_MER = 1 ; int check_MER_1 = 1 ; int zero_idx = 0 ; int nb_merge_cand = 0 ; int nb_orig_merge_cand = 0 ; int is_available_a0 ; int is_available_a1 ; int is_available_b0 ; int is_available_b1 ; int is_available_b2 ; int check_B0 ; int check_A0 ; //first left spatial merge candidate is_available_a1 = AVAILABLE ( cand_left , A1 ) ; if ( ! singleMCLFlag & & part_idx == 1 & & ( lc - > cu . part_mode == PART_Nx2N || lc - > cu . part_mode == PART_nLx2N || lc - > cu . part_mode == PART_nRx2N ) || isDiffMER ( s , xA1 , yA1 , x0 , y0 ) ) { is_available_a1 = 0 ; } if ( is_available_a1 ) { mergecandlist[0] = TAB_MVF_PU ( A1 ) ; if ( merge_idx == 0 ) return ; nb_merge_cand + + ; } // above spatial merge candidate is_available_b1 = AVAILABLE ( cand_up , B1 ) ; if ( ! singleMCLFlag & & part_idx == 1 & & ( lc - > cu . part_mode == PART_2NxN || lc - > cu . part_mode == PART_2NxnU || lc - > cu . part_mode == PART_2NxnD ) || isDiffMER ( s , xB1 , yB1 , x0 , y0 ) ) { is_available_b1 = 0 ; } if ( is_available_a1 & & is_available_b1 ) check_MER = ! COMPARE_MV_REFIDX ( B1 , A1 ) ; if ( is_available_b1 & & check_MER ) mergecandlist[nb_merge_cand + + ] = TAB_MVF_PU ( B1 ) ; // above right spatial merge candidate check_MER = 1 ; check_B0 = PRED_BLOCK_AVAILABLE ( B0 ) ; is_available_b0 = check_B0 & & AVAILABLE ( cand_up_right , B0 ) ; if ( isDiffMER ( s , xB0 , yB0 , x0 , y0 ) ) is_available_b0 = 0 ; if ( is_available_b1 & & is_available_b0 ) check_MER = ! COMPARE_MV_REFIDX ( B0 , B1 ) ; if ( is_available_b0 & & check_MER ) { mergecandlist[nb_merge_cand] = TAB_MVF_PU ( B0 ) ; if ( merge_idx == nb_merge_cand ) return ; nb_merge_cand + + ; } // left bottom spatial merge candidate check_MER = 1 ; check_A0 = PRED_BLOCK_AVAILABLE ( A0 ) ; is_available_a0 = check_A0 & & AVAILABLE ( cand_bottom_left , A0 ) ; if ( isDiffMER ( s , xA0 , yA0 , x0 , y0 ) ) is_available_a0 = 0 ; if ( is_available_a1 & & is_available_a0 ) check_MER = ! COMPARE_MV_REFIDX ( A0 , A1 ) ; if ( is_available_a0 & & check_MER ) { mergecandlist[nb_merge_cand] = TAB_MVF_PU ( A0 ) ; if ( merge_idx == nb_merge_cand ) return ; nb_merge_cand + + ; } // above left spatial merge candidate check_MER = 1 ; is_available_b2 = AVAILABLE ( cand_up_left , B2 ) ; if ( isDiffMER ( s , xB2 , yB2 , x0 , y0 ) ) is_available_b2 = 0 ; if ( is_available_a1 & & is_available_b2 ) check_MER = ! COMPARE_MV_REFIDX ( B2 , A1 ) ; if ( is_available_b1 & & is_available_b2 ) check_MER_1 = ! COMPARE_MV_REFIDX ( B2 , B1 ) ; if ( is_available_b2 & & check_MER & & check_MER_1 & & nb_merge_cand ! = 4 ) { mergecandlist[nb_merge_cand] = TAB_MVF_PU ( B2 ) ; if ( merge_idx == nb_merge_cand ) return ; nb_merge_cand + + ; } // temporal motion vector candidate if ( s - > sh . slice_temporal_mvp_enabled_flag & & nb_merge_cand < s - > sh . max_num_merge_cand ) { Mv mv_l0_col , mv_l1_col ; int available_l0 = temporal_luma_motion_vector ( s , x0 , y0 , nPbW , nPbH , 0 , & mv_l0_col , 0 ) ; int available_l1 = ( s - > sh . slice_type == B_SLICE ) ? temporal_luma_motion_vector ( s , x0 , y0 , nPbW , nPbH , 0 , & mv_l1_col , 1 ) : 0 ; if ( available_l0 || available_l1 ) { mergecandlist[nb_merge_cand] . is_intra = 0 ; mergecandlist[nb_merge_cand] . pred_flag[0] = available_l0 ; mergecandlist[nb_merge_cand] . pred_flag[1] = available_l1 ; AV_ZERO16 ( mergecandlist[nb_merge_cand] . ref_idx ) ; mergecandlist[nb_merge_cand] . mv[0] = mv_l0_col ; mergecandlist[nb_merge_cand] . mv[1] = mv_l1_col ; if ( merge_idx == nb_merge_cand ) return ; nb_merge_cand + + ; } } nb_orig_merge_cand = nb_merge_cand ; // combined bi - predictive merge candidates ( applies for B slices ) if ( s - > sh . slice_type == B_SLICE & & nb_orig_merge_cand > 1 & & nb_orig_merge_cand < s - > sh . max_num_merge_cand ) { int comb_idx ; for ( comb_idx = 0 ; nb_merge_cand < s - > sh . max_num_merge_cand & & comb_idx < nb_orig_merge_cand * ( nb_orig_merge_cand - 1 ) ; comb_idx + + ) { int l0_cand_idx = l0_l1_cand_idx[comb_idx][0] ; int l1_cand_idx = l0_l1_cand_idx[comb_idx][1] ; MvField l0_cand = mergecandlist[l0_cand_idx] ; MvField l1_cand =",0
"void ff_avg_h264_qpel4_mc12_msa ( uint8_t * dst , const uint8_t * src , ptrdiff_t stride ) { avc_luma_midh_qrt_and_aver_dst_4w_msa ( src - ( 2 * stride ) - 2 , stride , dst , stride , 4 , 0 ) ; }",0
"static void decode_postinit ( H264Context * h , int setup_finished ) { const SPS * sps = h - > ps . sps ; H264Picture * out = h - > cur_pic_ptr ; H264Picture * cur = h - > cur_pic_ptr ; int i , pics , out_of_order , out_idx ; int invalid = 0 , cnt = 0 ; h - > cur_pic_ptr - > f - > pict_type = h - > pict_type ; if ( h - > next_output_pic ) return ; if ( cur - > field_poc[0] == INT_MAX || cur - > field_poc[1] == INT_MAX ) { / * FIXME : if we have two PAFF fields in one packet , we can ' t start * the next thread here . If we have one field per packet , we can . * The check in decode_nal_units ( ) is not good enough to find this * yet , so we assume the worst for now . * / // if ( setup_finished ) // ff_thread_finish_setup ( h - > avctx ) ; return ; } cur - > f - > interlaced_frame = 0 ; cur - > f - > repeat_pict = 0 ; / * Signal interlacing information externally . * / / * Prioritize picture timing SEI information over used * decoding process if it exists . * / if ( sps - > pic_struct_present_flag ) { H264SEIPictureTiming * pt = & h - > sei . picture_timing ; switch ( pt - > pic_struct ) { case SEI_PIC_STRUCT_FRAME : break ; case SEI_PIC_STRUCT_TOP_FIELD : case SEI_PIC_STRUCT_BOTTOM_FIELD : cur - > f - > interlaced_frame = 1 ; break ; case SEI_PIC_STRUCT_TOP_BOTTOM : case SEI_PIC_STRUCT_BOTTOM_TOP : if ( FIELD_OR_MBAFF_PICTURE ( h ) ) cur - > f - > interlaced_frame = 1 ; else // try to flag soft telecine progressive cur - > f - > interlaced_frame = h - > prev_interlaced_frame ; break ; case SEI_PIC_STRUCT_TOP_BOTTOM_TOP : case SEI_PIC_STRUCT_BOTTOM_TOP_BOTTOM : / * Signal the possibility of telecined film externally * ( pic_struct 5 , 6 ) . From these hints , let the applications * decide if they apply deinterlacing . * / cur - > f - > repeat_pict = 1 ; break ; case SEI_PIC_STRUCT_FRAME_DOUBLING : cur - > f - > repeat_pict = 2 ; break ; case SEI_PIC_STRUCT_FRAME_TRIPLING : cur - > f - > repeat_pict = 4 ; break ; } if ( ( pt - > ct_type & 3 ) & & pt - > pic_struct < = SEI_PIC_STRUCT_BOTTOM_TOP ) cur - > f - > interlaced_frame = ( pt - > ct_type & ( 1 < < 1 ) ) ! = 0 ; } else { / * Derive interlacing flag from used decoding process . * / cur - > f - > interlaced_frame = FIELD_OR_MBAFF_PICTURE ( h ) ; } h - > prev_interlaced_frame = cur - > f - > interlaced_frame ; if ( cur - > field_poc[0] ! = cur - > field_poc[1] ) { / * Derive top_field_first from field pocs . * / cur - > f - > top_field_first = cur - > field_poc[0] < cur - > field_poc[1] ; } else { if ( cur - > f - > interlaced_frame || sps - > pic_struct_present_flag ) { / * Use picture timing SEI information . Even if it is a * information of a past frame , better than nothing . * / if ( h - > sei . picture_timing . pic_struct == SEI_PIC_STRUCT_TOP_BOTTOM || h - > sei . picture_timing . pic_struct == SEI_PIC_STRUCT_TOP_BOTTOM_TOP ) cur - > f - > top_field_first = 1 ; else cur - > f - > top_field_first = 0 ; } else { / * Most likely progressive * / cur - > f - > top_field_first = 0 ; } } if ( h - > sei . frame_packing . present & & h - > sei . frame_packing . arrangement_type > = 0 & & h - > sei . frame_packing . arrangement_type < = 6 & & h - > sei . frame_packing . content_interpretation_type > 0 & & h - > sei . frame_packing . content_interpretation_type < 3 ) { H264SEIFramePacking * fp = & h - > sei . frame_packing ; AVStereo3D * stereo = av_stereo3d_create_side_data ( cur - > f ) ; if ( ! stereo ) return ; switch ( fp - > arrangement_type ) { case 0 : stereo - > type = AV_STEREO3D_CHECKERBOARD ; break ; case 1 : stereo - > type = AV_STEREO3D_COLUMNS ; break ; case 2 : stereo - > type = AV_STEREO3D_LINES ; break ; case 3 : if ( fp - > quincunx_subsampling ) stereo - > type = AV_STEREO3D_SIDEBYSIDE_QUINCUNX ; else stereo - > type = AV_STEREO3D_SIDEBYSIDE ; break ; case 4 : stereo - > type = AV_STEREO3D_TOPBOTTOM ; break ; case 5 : stereo - > type = AV_STEREO3D_FRAMESEQUENCE ; break ; case 6 : stereo - > type = AV_STEREO3D_2D ; break ; } if ( fp - > content_interpretation_type == 2 ) stereo - > flags = AV_STEREO3D_FLAG_INVERT ; } if ( h - > sei . display_orientation . present & & ( h - > sei . display_orientation . anticlockwise_rotation || h - > sei . display_orientation . hflip || h - > sei . display_orientation . vflip ) ) { H264SEIDisplayOrientation * o = & h - > sei . display_orientation ; double angle = o - > anticlockwise_rotation * 360 / ( double ) ( 1 < < 16 ) ; AVFrameSideData * rotation = av_frame_new_side_data ( cur - > f , AV_FRAME_DATA_DISPLAYMATRIX , sizeof ( int32_t ) * 9 ) ; if ( ! rotation ) return ; av_display_rotation_set ( ( int32_t * ) rotation - > data , angle ) ; av_display_matrix_flip ( ( int32_t * ) rotation - > data , o - > hflip , o - > vflip ) ; } if ( h - > sei . afd . present ) { AVFrameSideData * sd = av_frame_new_side_data ( cur - > f , AV_FRAME_DATA_AFD , sizeof ( uint8_t ) ) ; if ( ! sd ) return ; * sd - > data = h - > sei . afd . active_format_description ; h - > sei . afd . present = 0 ; } if ( h - > sei . a53_caption . a53_caption ) { H264SEIA53Caption * a53 = & h - > sei . a53_caption ; AVFrameSideData * sd = av_frame_new_side_data ( cur - > f , AV_FRAME_DATA_A53_CC , a53 - > a53_caption_size ) ; if ( ! sd ) return ; memcpy ( sd - > data , a53 - > a53_caption , a53 - > a53_caption_size ) ; av_freep ( & a53 - > a53_caption ) ; a53 - > a53_caption_size = 0 ; } // FIXME do something with unavailable reference frames / * Sort B - frames into display order * / if ( sps - > bitstream_restriction_flag || h - > avctx - > strict_std_compliance > = FF_COMPLIANCE_NORMAL ) { h - > avctx - >",0
"static int g2m_load_cursor ( AVCodecContext * avctx , G2MContext * c , GetByteContext * gb ) { int i , j , k ; uint8_t * dst ; uint32_t bits ; uint32_t cur_size , cursor_w , cursor_h , cursor_stride ; uint32_t cursor_hot_x , cursor_hot_y ; int cursor_fmt ; uint8_t * tmp ; cur_size = bytestream2_get_be32 ( gb ) ; cursor_w = bytestream2_get_byte ( gb ) ; cursor_h = bytestream2_get_byte ( gb ) ; cursor_hot_x = bytestream2_get_byte ( gb ) ; cursor_hot_y = bytestream2_get_byte ( gb ) ; cursor_fmt = bytestream2_get_byte ( gb ) ; cursor_stride = FFALIGN ( cursor_w , c - > cursor_fmt==1 ? 32 : 1 ) * 4 ; if ( cursor_w < 1 || cursor_w > 256 || cursor_h < 1 || cursor_h > 256 ) { av_log ( avctx , AV_LOG_ERROR , Invalid cursor dimensions %dx%d\n , cursor_w , cursor_h ) ; return AVERROR_INVALIDDATA ; } if ( cursor_hot_x > cursor_w || cursor_hot_y > cursor_h ) { av_log ( avctx , AV_LOG_WARNING , Invalid hotspot position %d , %d\n , cursor_hot_x , cursor_hot_y ) ; cursor_hot_x = FFMIN ( cursor_hot_x , cursor_w - 1 ) ; cursor_hot_y = FFMIN ( cursor_hot_y , cursor_h - 1 ) ; } if ( cur_size - 9 > bytestream2_get_bytes_left ( gb ) || c - > cursor_w * c - > cursor_h / 4 > cur_size ) { av_log ( avctx , AV_LOG_ERROR , Invalid cursor data size %d/%d\n , cur_size , bytestream2_get_bytes_left ( gb ) ) ; return AVERROR_INVALIDDATA ; } if ( cursor_fmt ! = 1 & & cursor_fmt ! = 32 ) { avpriv_report_missing_feature ( avctx , Cursor format %d , cursor_fmt ) ; return AVERROR_PATCHWELCOME ; } tmp = av_realloc ( c - > cursor , cursor_stride * cursor_h ) ; if ( ! tmp ) { av_log ( avctx , AV_LOG_ERROR , Cannot allocate cursor buffer\n ) ; return AVERROR ( ENOMEM ) ; } c - > cursor = tmp ; c - > cursor_w = cursor_w ; c - > cursor_h = cursor_h ; c - > cursor_hot_x = cursor_hot_x ; c - > cursor_hot_y = cursor_hot_y ; c - > cursor_fmt = cursor_fmt ; c - > cursor_stride = cursor_stride ; dst = c - > cursor ; switch ( c - > cursor_fmt ) { case 1 : // old monochrome for ( j = 0 ; j < c - > cursor_h ; j + + ) { for ( i = 0 ; i < c - > cursor_w ; i + = 32 ) { bits = bytestream2_get_be32 ( gb ) ; for ( k = 0 ; k < 32 ; k + + ) { dst[0] = ! ! ( bits & 0x80000000 ) ; dst + = 4 ; bits < < = 1 ; } } } dst = c - > cursor ; for ( j = 0 ; j < c - > cursor_h ; j + + ) { for ( i = 0 ; i < c - > cursor_w ; i + = 32 ) { bits = bytestream2_get_be32 ( gb ) ; for ( k = 0 ; k < 32 ; k + + ) { int mask_bit = ! ! ( bits & 0x80000000 ) ; switch ( dst[0] * 2 + mask_bit ) { case 0 : dst[0] = 0xFF ; dst[1] = 0x00 ; dst[2] = 0x00 ; dst[3] = 0x00 ; break ; case 1 : dst[0] = 0xFF ; dst[1] = 0xFF ; dst[2] = 0xFF ; dst[3] = 0xFF ; break ; default : dst[0] = 0x00 ; dst[1] = 0x00 ; dst[2] = 0x00 ; dst[3] = 0x00 ; } dst + = 4 ; bits < < = 1 ; } } } break ; case 32 : // full colour / * skip monochrome version of the cursor and decode RGBA instead * / bytestream2_skip ( gb , c - > cursor_h * ( FFALIGN ( c - > cursor_w , 32 ) > > 3 ) ) ; for ( j = 0 ; j < c - > cursor_h ; j + + ) { for ( i = 0 ; i < c - > cursor_w ; i + + ) { int val = bytestream2_get_be32 ( gb ) ; * dst + + = val > > 0 ; * dst + + = val > > 8 ; * dst + + = val > > 16 ; * dst + + = val > > 24 ; } } break ; default : return AVERROR_PATCHWELCOME ; } return 0 ; }",0
static int has_duration ( AVFormatContext * ic ) { int i ; AVStream * st ; for ( i = 0 ; i < ic - > nb_streams ; i + + ) { st = ic - > streams[i] ; if ( st - > duration ! = AV_NOPTS_VALUE ) return 1 ; } if ( ic - > duration ) return 1 ; return 0 ; },0
"static int tta_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; TTAContext * s = avctx - > priv_data ; int i ; init_get_bits ( & s - > gb , buf , buf_size * 8 ) ; { int cur_chan = 0 , framelen = s - > frame_length ; int32_t * p ; if ( * data_size < ( framelen * s - > channels * 2 ) ) { av_log ( avctx , AV_LOG_ERROR , Output buffer size is too small . \n ) ; return - 1 ; } // FIXME : seeking s - > total_frames - - ; if ( ! s - > total_frames & & s - > last_frame_length ) framelen = s - > last_frame_length ; // init per channel states for ( i = 0 ; i < s - > channels ; i + + ) { s - > ch_ctx[i] . predictor = 0 ; ttafilter_init ( & s - > ch_ctx[i] . filter , ttafilter_configs[s - > bps - 1][0] , ttafilter_configs[s - > bps - 1][1] ) ; rice_init ( & s - > ch_ctx[i] . rice , 10 , 10 ) ; } for ( p = s - > decode_buffer ; p < s - > decode_buffer + ( framelen * s - > channels ) ; p + + ) { int32_t * predictor = & s - > ch_ctx[cur_chan] . predictor ; TTAFilter * filter = & s - > ch_ctx[cur_chan] . filter ; TTARice * rice = & s - > ch_ctx[cur_chan] . rice ; uint32_t unary , depth , k ; int32_t value ; unary = tta_get_unary ( & s - > gb ) ; if ( unary == 0 ) { depth = 0 ; k = rice - > k0 ; } else { depth = 1 ; k = rice - > k1 ; unary - - ; } if ( get_bits_left ( & s - > gb ) < k ) return - 1 ; if ( k ) { if ( k > MIN_CACHE_BITS ) return - 1 ; value = ( unary < < k ) + get_bits ( & s - > gb , k ) ; } else value = unary ; // FIXME : copy paste from original switch ( depth ) { case 1 : rice - > sum1 + = value - ( rice - > sum1 > > 4 ) ; if ( rice - > k1 > 0 & & rice - > sum1 < shift_16[rice - > k1] ) rice - > k1 - - ; else if ( rice - > sum1 > shift_16[rice - > k1 + 1] ) rice - > k1 + + ; value + = shift_1[rice - > k0] ; default : rice - > sum0 + = value - ( rice - > sum0 > > 4 ) ; if ( rice - > k0 > 0 & & rice - > sum0 < shift_16[rice - > k0] ) rice - > k0 - - ; else if ( rice - > sum0 > shift_16[rice - > k0 + 1] ) rice - > k0 + + ; } // extract coded value define UNFOLD ( x ) ( ( ( x ) & 1 ) ? ( + + ( x ) > > 1 ) : ( - ( x ) > > 1 ) ) * p = UNFOLD ( value ) ; // run hybrid filter ttafilter_process ( filter , p , 0 ) ; // fixed order prediction define PRED ( x , k ) ( int32_t ) ( ( ( ( uint64_t ) x < < k ) - x ) > > k ) switch ( s - > bps ) { case 1 : * p + = PRED ( * predictor , 4 ) ; break ; case 2 : case 3 : * p + = PRED ( * predictor , 5 ) ; break ; case 4 : * p + = * predictor ; break ; } * predictor = * p ; // flip channels if ( cur_chan < ( s - > channels - 1 ) ) cur_chan + + ; else { // decorrelate in case of stereo integer if ( s - > channels > 1 ) { int32_t * r = p - 1 ; for ( * p + = * r / 2 ; r > p - s - > channels ; r - - ) * r = * ( r + 1 ) - * r ; } cur_chan = 0 ; } } if ( get_bits_left ( & s - > gb ) < 32 ) return - 1 ; skip_bits ( & s - > gb , 32 ) ; // frame crc // convert to output buffer switch ( s - > bps ) { case 2 : { uint16_t * samples = data ; for ( p = s - > decode_buffer ; p < s - > decode_buffer + ( framelen * s - > channels ) ; p + + ) { * samples + + = * p ; } * data_size = ( uint8_t * ) samples - ( uint8_t * ) data ; break ; } default : av_log ( s - > avctx , AV_LOG_ERROR , Error , only 16bit samples supported ! \n ) ; } } return buf_size ; }",0
"static inline void RENAME ( rgb16to15 ) ( const uint8_t * src , uint8_t * dst , unsigned src_size ) { register const uint8_t * s=src ; register uint8_t * d=dst ; register const uint8_t * end ; const uint8_t * mm_end ; end = s + src_size ; ifdef HAVE_MMX __asm __volatile ( PREFETCH %0 : : m ( * s ) ) ; __asm __volatile ( movq %0 , %%mm7 : : m ( mask15rg ) ) ; __asm __volatile ( movq %0 , %%mm6 : : m ( mask15b ) ) ; mm_end = end - 15 ; while ( s < mm_end ) { __asm __volatile ( PREFETCH 32%1\n\t movq %1 , %%mm0\n\t movq 8%1 , %%mm2\n\t movq %%mm0 , %%mm1\n\t movq %%mm2 , %%mm3\n\t psrlq 1 , %%mm0\n\t psrlq 1 , %%mm2\n\t pand %%mm7 , %%mm0\n\t pand %%mm7 , %%mm2\n\t pand %%mm6 , %%mm1\n\t pand %%mm6 , %%mm3\n\t por %%mm1 , %%mm0\n\t por %%mm3 , %%mm2\n\t MOVNTQ %%mm0 , %0\n\t MOVNTQ %%mm2 , 8%0 : =m ( * d ) : m ( * s ) ) ; d + =16 ; s + =16 ; } __asm __volatile ( SFENCE : : : memory ) ; __asm __volatile ( EMMS : : : memory ) ; endif mm_end = end - 3 ; while ( s < mm_end ) { register uint32_t x= * ( ( uint32_t * ) s ) ; * ( ( uint32_t * ) d ) = ( ( x > > 1 ) & 0x7FE07FE0 ) | ( x & 0x001F001F ) ; s + =4 ; d + =4 ; } if ( s < end ) { register uint16_t x= * ( ( uint16_t * ) s ) ; * ( ( uint16_t * ) d ) = ( ( x > > 1 ) & 0x7FE0 ) | ( x & 0x001F ) ; s + =2 ; d + =2 ; } }",1
"static int aiff_read_packet ( AVFormatContext * s , AVPacket * pkt ) { AVStream * st = s - > streams[0] ; AIFFInputContext * aiff = s - > priv_data ; int64_t max_size ; int res , size ; / * calculate size of remaining data * / max_size = aiff - > data_end - avio_tell ( s - > pb ) ; if ( max_size < = 0 ) return AVERROR_EOF ; / * Now for that packet * / switch ( st - > codecpar - > codec_id ) { case AV_CODEC_ID_ADPCM_IMA_QT : case AV_CODEC_ID_GSM : case AV_CODEC_ID_QDM2 : case AV_CODEC_ID_QCELP : size = st - > codecpar - > block_align ; break ; default : size = st - > codecpar - > block_align ? ( MAX_SIZE / st - > codecpar - > block_align ) * st - > codecpar - > block_align : MAX_SIZE ; size = FFMIN ( max_size , size ) ; res = av_get_packet ( s - > pb , pkt , size ) ; if ( res < 0 ) return res ; if ( size > = st - > codecpar - > block_align ) pkt - > flags & = AV_PKT_FLAG_CORRUPT ; / * Only one stream in an AIFF file * / pkt - > stream_index = 0 ; pkt - > duration = ( res / st - > codecpar - > block_align ) * aiff - > block_duration ; return 0 ;",1
"void write_video_frame ( AVFormatContext * oc , AVStream * st ) { int x , y , i , out_size ; AVCodecContext * c ; c = & st - > codec ; / * prepare a dummy image * / / * Y * / i = frame_count + + ; for ( y=0 ; y < c - > height ; y + + ) { for ( x=0 ; x < c - > width ; x + + ) { picture - > data[0][y * picture - > linesize[0] + x] = x + y + i * 3 ; } } / * Cb and Cr * / for ( y=0 ; y < c - > height/2 ; y + + ) { for ( x=0 ; x < c - > width/2 ; x + + ) { picture - > data[1][y * picture - > linesize[1] + x] = 128 + y + i * 2 ; picture - > data[2][y * picture - > linesize[2] + x] = 64 + x + i * 5 ; } } / * encode the image * / out_size = avcodec_encode_video ( c , video_outbuf , video_outbuf_size , picture ) ; / * write the compressed frame in the media file * / if ( av_write_frame ( oc , st - > index , video_outbuf , out_size ) ! = 0 ) { fprintf ( stderr , Error while writing video frame\n ) ; exit ( 1 ) ; } }",1
"av_cold int MPV_encode_init ( AVCodecContext * avctx ) { MpegEncContext * s = avctx - > priv_data ; int i ; int chroma_h_shift , chroma_v_shift ; MPV_encode_defaults ( s ) ; switch ( avctx - > codec_id ) { case CODEC_ID_MPEG2VIDEO : if ( avctx - > pix_fmt ! = PIX_FMT_YUV420P & & avctx - > pix_fmt ! = PIX_FMT_YUV422P ) { av_log ( avctx , AV_LOG_ERROR , only YUV420 and YUV422 are supported\n ) ; return - 1 ; } break ; case CODEC_ID_LJPEG : if ( avctx - > pix_fmt ! = PIX_FMT_YUVJ420P & & avctx - > pix_fmt ! = PIX_FMT_YUVJ422P & & avctx - > pix_fmt ! = PIX_FMT_YUVJ444P & & avctx - > pix_fmt ! = PIX_FMT_RGB32 & & ( ( avctx - > pix_fmt ! = PIX_FMT_YUV420P & & avctx - > pix_fmt ! = PIX_FMT_YUV422P & & avctx - > pix_fmt ! = PIX_FMT_YUV444P ) || avctx - > strict_std_compliance > FF_COMPLIANCE_UNOFFICIAL ) ) { av_log ( avctx , AV_LOG_ERROR , colorspace not supported in LJPEG\n ) ; return - 1 ; } break ; case CODEC_ID_MJPEG : if ( avctx - > pix_fmt ! = PIX_FMT_YUVJ420P & & avctx - > pix_fmt ! = PIX_FMT_YUVJ422P & & ( ( avctx - > pix_fmt ! = PIX_FMT_YUV420P & & avctx - > pix_fmt ! = PIX_FMT_YUV422P ) || avctx - > strict_std_compliance > FF_COMPLIANCE_UNOFFICIAL ) ) { av_log ( avctx , AV_LOG_ERROR , colorspace not supported in jpeg\n ) ; return - 1 ; } break ; default : if ( avctx - > pix_fmt ! = PIX_FMT_YUV420P ) { av_log ( avctx , AV_LOG_ERROR , only YUV420 is supported\n ) ; return - 1 ; } } switch ( avctx - > pix_fmt ) { case PIX_FMT_YUVJ422P : case PIX_FMT_YUV422P : s - > chroma_format = CHROMA_422 ; break ; case PIX_FMT_YUVJ420P : case PIX_FMT_YUV420P : default : s - > chroma_format = CHROMA_420 ; break ; } s - > bit_rate = avctx - > bit_rate ; s - > width = avctx - > width ; s - > height = avctx - > height ; if ( avctx - > gop_size > 600 & & avctx - > strict_std_compliance > FF_COMPLIANCE_EXPERIMENTAL ) { av_log ( avctx , AV_LOG_ERROR , Warning keyframe interval too large ! reducing it . . . \n ) ; avctx - > gop_size=600 ; } s - > gop_size = avctx - > gop_size ; s - > avctx = avctx ; s - > flags= avctx - > flags ; s - > flags2= avctx - > flags2 ; s - > max_b_frames= avctx - > max_b_frames ; s - > codec_id= avctx - > codec - > id ; s - > luma_elim_threshold = avctx - > luma_elim_threshold ; s - > chroma_elim_threshold= avctx - > chroma_elim_threshold ; s - > strict_std_compliance= avctx - > strict_std_compliance ; s - > data_partitioning= avctx - > flags & CODEC_FLAG_PART ; s - > quarter_sample= ( avctx - > flags & CODEC_FLAG_QPEL ) ! =0 ; s - > mpeg_quant= avctx - > mpeg_quant ; s - > rtp_mode= ! ! avctx - > rtp_payload_size ; s - > intra_dc_precision= avctx - > intra_dc_precision ; s - > user_specified_pts = AV_NOPTS_VALUE ; if ( s - > gop_size < = 1 ) { s - > intra_only = 1 ; s - > gop_size = 12 ; } else { s - > intra_only = 0 ; } s - > me_method = avctx - > me_method ; / * Fixed QSCALE * / s - > fixed_qscale = ! ! ( avctx - > flags & CODEC_FLAG_QSCALE ) ; s - > adaptive_quant= ( s - > avctx - > lumi_masking || s - > avctx - > dark_masking || s - > avctx - > temporal_cplx_masking || s - > avctx - > spatial_cplx_masking || s - > avctx - > p_masking || s - > avctx - > border_masking || ( s - > flags & CODEC_FLAG_QP_RD ) ) & & ! s - > fixed_qscale ; s - > obmc= ! ! ( s - > flags & CODEC_FLAG_OBMC ) ; s - > loop_filter= ! ! ( s - > flags & CODEC_FLAG_LOOP_FILTER ) ; s - > alternate_scan= ! ! ( s - > flags & CODEC_FLAG_ALT_SCAN ) ; s - > intra_vlc_format= ! ! ( s - > flags2 & CODEC_FLAG2_INTRA_VLC ) ; s - > q_scale_type= ! ! ( s - > flags2 & CODEC_FLAG2_NON_LINEAR_QUANT ) ; if ( avctx - > rc_max_rate & & ! avctx - > rc_buffer_size ) { av_log ( avctx , AV_LOG_ERROR , a vbv buffer size is needed , for encoding with a maximum bitrate\n ) ; return - 1 ; } if ( avctx - > rc_min_rate & & avctx - > rc_max_rate ! = avctx - > rc_min_rate ) { av_log ( avctx , AV_LOG_INFO , Warning min_rate > 0 but min_rate ! = max_rate isn ' t recommended ! \n ) ; } if ( avctx - > rc_min_rate & & avctx - > rc_min_rate > avctx - > bit_rate ) { av_log ( avctx , AV_LOG_ERROR , bitrate below min bitrate\n ) ; return - 1 ; } if ( avctx - > rc_max_rate & & avctx - > rc_max_rate < avctx - > bit_rate ) { av_log ( avctx , AV_LOG_INFO , bitrate above max bitrate\n ) ; return - 1 ; } if ( avctx - > rc_max_rate & & avctx - > rc_max_rate == avctx - > bit_rate & & avctx - > rc_max_rate ! = avctx - > rc_min_rate ) { av_log ( avctx , AV_LOG_INFO , impossible bitrate constraints , this will fail\n ) ; } if ( avctx - > rc_buffer_size & & avctx - > bit_rate * ( int64_t ) avctx - > time_base . num > avctx - > rc_buffer_size * ( int64_t ) avctx - > time_base . den ) { av_log ( avctx , AV_LOG_ERROR , VBV buffer too small for bitrate\n ) ; return - 1 ; } if ( ! s - > fixed_qscale & & avctx - > bit_rate * av_q2d ( avctx - > time_base ) > avctx - > bit_rate_tolerance ) { av_log ( avctx , AV_LOG_ERROR , bitrate tolerance too small for bitrate\n ) ; return - 1 ; } if ( s - > avctx - > rc_max_rate & & s - > avctx - > rc_min_rate == s - > avctx - > rc_max_rate & & ( s - > codec_id == CODEC_ID_MPEG1VIDEO || s - > codec_id == CODEC_ID_MPEG2VIDEO ) & & 90000LL * ( avctx - > rc_buffer_size - 1 ) > s - > avctx - > rc_max_rate * 0xFFFFLL ) { av_log ( avctx , AV_LOG_INFO , Warning vbv_delay will be set to 0xFFFF ( =VBR ) as the specified vbv buffer is too large for the given bitrate ! \n ) ; } if ( ( s - > flags & CODEC_FLAG_4MV ) & & s - > codec_id ! = CODEC_ID_MPEG4 & & s - > codec_id ! = CODEC_ID_H263 & & s -",1
"static int inline get_mb_score ( MpegEncContext * s , int mx , int my , int src_index , int ref_index ) { // const int check_luma= s - > dsp . me_sub_cmp ! = s - > dsp . mb_cmp ; MotionEstContext * const c= & s - > me ; const int size= 0 ; const int h= 16 ; const int penalty_factor= c - > mb_penalty_factor ; const int flags= c - > mb_flags ; const int qpel= flags & FLAG_QPEL ; const int mask= 1 + 2 * qpel ; me_cmp_func cmp_sub , chroma_cmp_sub ; int d ; LOAD_COMMON //FIXME factorize cmp_sub= s - > dsp . mb_cmp[size] ; chroma_cmp_sub= s - > dsp . mb_cmp[size + 1] ; assert ( ! c - > skip ) ; assert ( c - > avctx - > me_sub_cmp ! = c - > avctx - > mb_cmp ) ; d= cmp ( s , mx > > ( qpel + 1 ) , my > > ( qpel + 1 ) , mx & mask , my & mask , size , h , ref_index , src_index , cmp_sub , chroma_cmp_sub , flags ) ; //FIXME check cbp before adding penalty for ( 0 , 0 ) vector if ( mx || my || size > 0 ) d + = ( mv_penalty[mx - pred_x] + mv_penalty[my - pred_y] ) * penalty_factor ; return d ; }",0
av_cold void ff_dcadsp_init ( DCADSPContext * s ) { s - > lfe_fir[0] = dca_lfe_fir0_c ; s - > lfe_fir[1] = dca_lfe_fir1_c ; s - > qmf_32_subbands = dca_qmf_32_subbands ; s - > int8x8_fmul_int32 = int8x8_fmul_int32_c ; if ( ARCH_ARM ) ff_dcadsp_init_arm ( s ) ; if ( ARCH_X86 ) ff_dcadsp_init_x86 ( s ) ; },0
"static int decode_packet ( AVCodecContext * avctx , void * data , int * got_frame_ptr , AVPacket * avpkt ) { WMAProDecodeCtx * s = avctx - > priv_data ; GetBitContext * gb = & s - > pgb ; const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; int num_bits_prev_frame ; int packet_sequence_number ; * got_frame_ptr = 0 ; if ( s - > packet_done || s - > packet_loss ) { s - > packet_done = 0 ; / * * sanity check for the buffer length * / if ( buf_size < avctx - > block_align ) return 0 ; s - > next_packet_start = buf_size - avctx - > block_align ; buf_size = avctx - > block_align ; s - > buf_bit_size = buf_size < < 3 ; / * * parse packet header * / init_get_bits ( gb , buf , s - > buf_bit_size ) ; packet_sequence_number = get_bits ( gb , 4 ) ; skip_bits ( gb , 2 ) ; / * * get number of bits that need to be added to the previous frame * / num_bits_prev_frame = get_bits ( gb , s - > log2_frame_size ) ; av_dlog ( avctx , packet[%d] : nbpf %x\n , avctx - > frame_number , num_bits_prev_frame ) ; / * * check for packet loss * / if ( ! s - > packet_loss & & ( ( s - > packet_sequence_number + 1 ) & 0xF ) ! = packet_sequence_number ) { s - > packet_loss = 1 ; av_log ( avctx , AV_LOG_ERROR , Packet loss detected ! seq %x vs %x\n , s - > packet_sequence_number , packet_sequence_number ) ; } s - > packet_sequence_number = packet_sequence_number ; if ( num_bits_prev_frame > 0 ) { int remaining_packet_bits = s - > buf_bit_size - get_bits_count ( gb ) ; if ( num_bits_prev_frame > = remaining_packet_bits ) { num_bits_prev_frame = remaining_packet_bits ; s - > packet_done = 1 ; } / * * append the previous frame data to the remaining data from the previous packet to create a full frame * / save_bits ( s , gb , num_bits_prev_frame , 1 ) ; av_dlog ( avctx , accumulated %x bits of frame data\n , s - > num_saved_bits - s - > frame_offset ) ; / * * decode the cross packet frame if it is valid * / if ( ! s - > packet_loss ) decode_frame ( s , data , got_frame_ptr ) ; } else if ( s - > num_saved_bits - s - > frame_offset ) { av_dlog ( avctx , ignoring %x previously saved bits\n , s - > num_saved_bits - s - > frame_offset ) ; } if ( s - > packet_loss ) { / * * reset number of saved bits so that the decoder does not start to decode incomplete frames in the s - > len_prefix == 0 case * / s - > num_saved_bits = 0 ; s - > packet_loss = 0 ; } } else { int frame_size ; s - > buf_bit_size = ( avpkt - > size - s - > next_packet_start ) < < 3 ; init_get_bits ( gb , avpkt - > data , s - > buf_bit_size ) ; skip_bits ( gb , s - > packet_offset ) ; if ( s - > len_prefix & & remaining_bits ( s , gb ) > s - > log2_frame_size & & ( frame_size = show_bits ( gb , s - > log2_frame_size ) ) & & frame_size < = remaining_bits ( s , gb ) ) { save_bits ( s , gb , frame_size , 0 ) ; s - > packet_done = ! decode_frame ( s , data , got_frame_ptr ) ; } else if ( ! s - > len_prefix & & s - > num_saved_bits > get_bits_count ( & s - > gb ) ) { / * * when the frames do not have a length prefix , we don ' t know the compressed length of the individual frames however , we know what part of a new packet belongs to the previous frame therefore we save the incoming packet first , then we append the previous frame data from the next packet so that we get a buffer that only contains full frames * / s - > packet_done = ! decode_frame ( s , data , got_frame_ptr ) ; } else s - > packet_done = 1 ; } if ( s - > packet_done & & ! s - > packet_loss & & remaining_bits ( s , gb ) > 0 ) { / * * save the rest of the data so that it can be decoded with the next packet * / save_bits ( s , gb , remaining_bits ( s , gb ) , 0 ) ; } s - > packet_offset = get_bits_count ( gb ) & 7 ; if ( s - > packet_loss ) return AVERROR_INVALIDDATA ; return get_bits_count ( gb ) > > 3 ; }",0
"yuv2mono_1_c_template ( SwsContext * c , const uint16_t * buf0 , const uint16_t * ubuf0 , const uint16_t * ubuf1 , const uint16_t * vbuf0 , const uint16_t * vbuf1 , const uint16_t * abuf0 , uint8_t * dest , int dstW , int uvalpha , enum PixelFormat dstFormat , int flags , int y , enum PixelFormat target ) { const uint8_t * const d128 = dither_8x8_220[y & 7] ; uint8_t * g = c - > table_gU[128] + c - > table_gV[128] ; int i ; for ( i = 0 ; i < dstW - 7 ; i + = 8 ) { int acc = g[ ( buf0[i ] > > 7 ) + d128[0]] ; acc + = acc + g[ ( buf0[i + 1] > > 7 ) + d128[1]] ; acc + = acc + g[ ( buf0[i + 2] > > 7 ) + d128[2]] ; acc + = acc + g[ ( buf0[i + 3] > > 7 ) + d128[3]] ; acc + = acc + g[ ( buf0[i + 4] > > 7 ) + d128[4]] ; acc + = acc + g[ ( buf0[i + 5] > > 7 ) + d128[5]] ; acc + = acc + g[ ( buf0[i + 6] > > 7 ) + d128[6]] ; acc + = acc + g[ ( buf0[i + 7] > > 7 ) + d128[7]] ; output_pixel ( * dest + + , acc ) ; } }",0
"static void apply_tns_filter ( float * out , float * in , int order , int direction , float * tns_coefs , int ltp_used , int w , int filt , int start_i , int len ) { int i , j , inc , start = start_i ; float tmp[TNS_MAX_ORDER + 1] ; if ( direction ) { inc = - 1 ; start = ( start + len ) - 1 ; } else { inc = 1 ; } if ( ! ltp_used ) { / * AR filter * / for ( i = 0 ; i < len ; i + + , start + = inc ) out[i] = in[start] ; for ( j = 1 ; j < = FFMIN ( i , order ) ; j + + ) out[i] + = tns_coefs[j] * in[start - j * inc] ; } else { / * MA filter * / for ( i = 0 ; i < len ; i + + , start + = inc ) { tmp[0] = out[i] = in[start] ; for ( j = 1 ; j < = FFMIN ( i , order ) ; j + + ) out[i] + = tmp[j] * tns_coefs[j] ; for ( j = order ; j > 0 ; j - - ) tmp[j] = tmp[j - 1] ; } } }",0
"static int decode_cabac_mb_dqp ( H264Context * h ) { MpegEncContext * const s = & h - > s ; int mbn_xy ; int ctx = 0 ; int val = 0 ; if ( s - > mb_x > 0 ) mbn_xy = s - > mb_x + s - > mb_y * s - > mb_stride - 1 ; else mbn_xy = s - > mb_width - 1 + ( s - > mb_y - 1 ) * s - > mb_stride ; if ( h - > last_qscale_diff ! = 0 ) ctx + + ; while ( get_cabac ( & h - > cabac , & h - > cabac_state[60 + ctx] ) ) { if ( ctx < 2 ) ctx = 2 ; else ctx = 3 ; val + + ; if ( val > 102 ) //prevent infinite loop return INT_MIN ; } if ( val & 0x01 ) return ( val + 1 ) /2 ; else return - ( val + 1 ) /2 ; }",0
"static int mkv_write_ass_blocks ( AVFormatContext * s , AVIOContext * pb , AVPacket * pkt ) { MatroskaMuxContext * mkv = s - > priv_data ; int i , layer = 0 , max_duration = 0 , size , line_size , data_size = pkt - > size ; uint8_t * start , * end , * data = pkt - > data ; ebml_master blockgroup ; char buffer[2048] ; while ( data_size ) { int duration = ass_get_duration ( data ) ; max_duration = FFMAX ( duration , max_duration ) ; end = memchr ( data , ' \n ' , data_size ) ; size = line_size = end ? end - data + 1 : data_size ; size - = end ? ( end[ - 1] == ' \r ' ) + 1 : 0 ; start = data ; for ( i = 0 ; i < 3 ; i + + , start + + ) if ( ! ( start = memchr ( start , ' , ' , size - ( start - data ) ) ) ) return max_duration ; size - = start - data ; sscanf ( data , Dialogue : %d , , & layer ) ; i = snprintf ( buffer , sizeof ( buffer ) , % PRId64 , %d , , s - > streams[pkt - > stream_index] - > nb_frames , layer ) ; size = FFMIN ( i + size , sizeof ( buffer ) ) ; memcpy ( buffer + i , start , size - i ) ; av_log ( s , AV_LOG_DEBUG , Writing block at offset % PRIu64 , size %d , pts % PRId64 , duration %d\n , avio_tell ( pb ) , size , pkt - > pts , duration ) ; blockgroup = start_ebml_master ( pb , MATROSKA_ID_BLOCKGROUP , mkv_blockgroup_size ( size ) ) ; put_ebml_id ( pb , MATROSKA_ID_BLOCK ) ; put_ebml_num ( pb , size + 4 , 0 ) ; // this assumes stream_index is less than 126 avio_w8 ( pb , 0x80 | ( pkt - > stream_index + 1 ) ) ; avio_wb16 ( pb , pkt - > pts - mkv - > cluster_pts ) ; avio_w8 ( pb , 0 ) ; avio_write ( pb , buffer , size ) ; put_ebml_uint ( pb , MATROSKA_ID_BLOCKDURATION , duration ) ; end_ebml_master ( pb , blockgroup ) ; data + = line_size ; data_size - = line_size ; } return max_duration ; }",0
"static uint8_t get_sot ( Jpeg2000DecoderContext * s , int n ) { Jpeg2000TilePart * tp ; uint16_t Isot ; uint32_t Psot ; uint8_t TPsot ; if ( s - > buf_end - s - > buf < 4 ) return AVERROR ( EINVAL ) ; Isot = bytestream_get_be16 ( & s - > buf ) ; // Isot if ( Isot ) { av_log ( s - > avctx , AV_LOG_ERROR , Not a DCINEMA JP2K file : more than one tile\n ) ; return - 1 ; } Psot = bytestream_get_be32 ( & s - > buf ) ; // Psot TPsot = bytestream_get_byte ( & s - > buf ) ; // TPsot / * Read TNSot but not used * / bytestream_get_byte ( & s - > buf ) ; // TNsot tp = s - > tile[s - > curtileno] . tile_part + TPsot ; tp - > tile_index = Isot ; tp - > tp_len = Psot ; tp - > tp_idx = TPsot ; / * Start of bit stream . Pointer to SOD marker * Check SOD marker is present . * / if ( JPEG2000_SOD == bytestream_get_be16 ( & s - > buf ) ) tp - > tp_start_bstrm = s - > buf ; else { av_log ( s - > avctx , AV_LOG_ERROR , SOD marker not found \n ) ; return - 1 ; } / * End address of bit stream = * start address + ( Psot - size of SOT HEADER ( n ) * - size of SOT MARKER ( 2 ) - size of SOD marker ( 2 ) * / tp - > tp_end_bstrm = s - > buf + ( tp - > tp_len - n - 4 ) ; // set buffer pointer to end of tile part header s - > buf = tp - > tp_end_bstrm ; return 0 ; }",0
static int xa_probe ( AVProbeData * p ) { switch ( AV_RL32 ( p - > buf ) ) { case XA00_TAG : case XAI0_TAG : case XAJ0_TAG : return AVPROBE_SCORE_MAX ; } return 0 ; },1
"void av_vlog ( void * avcl , int level , const char * fmt , va_list vl ) { if ( av_log_callback ) av_log_callback ( avcl , level , fmt , vl ) ; }",1
"static int read_packet ( AVFormatContext * s , AVPacket * pkt ) { ASSContext * ass = s - > priv_data ; uint8_t * p , * end ; if ( ass - > event_index > = ass - > event_count ) return AVERROR ( EIO ) ; p = ass - > event[ass - > event_index] ; end = strchr ( p , ' \n ' ) ; av_new_packet ( pkt , end ? end - p + 1 : strlen ( p ) ) ; pkt - > flags |= AV_PKT_FLAG_KEY ; pkt - > pos = p - ass - > event_buffer + s - > streams[0] - > codec - > extradata_size ; pkt - > pts = pkt - > dts = get_pts ( p ) ; memcpy ( pkt - > data , p , pkt - > size ) ; ass - > event_index + + ; return 0 ; }",0
static av_cold int xwd_encode_close ( AVCodecContext * avctx ) { av_freep ( & avctx - > coded_frame ) ; return 0 ; },0
"av_cold void ff_idctdsp_init_x86 ( IDCTDSPContext * c , AVCodecContext * avctx , unsigned high_bit_depth ) { int cpu_flags = av_get_cpu_flags ( ) ; if ( INLINE_MMX ( cpu_flags ) ) { if ( ! high_bit_depth & & avctx - > lowres == 0 & & ( avctx - > idct_algo == FF_IDCT_AUTO || avctx - > idct_algo == FF_IDCT_SIMPLEAUTO || avctx - > idct_algo == FF_IDCT_SIMPLEMMX ) ) { c - > idct_put = ff_simple_idct_put_mmx ; c - > idct_add = ff_simple_idct_add_mmx ; c - > idct = ff_simple_idct_mmx ; c - > perm_type = FF_IDCT_PERM_SIMPLE ; } } if ( EXTERNAL_MMX ( cpu_flags ) ) { c - > put_signed_pixels_clamped = ff_put_signed_pixels_clamped_mmx ; c - > put_pixels_clamped = ff_put_pixels_clamped_mmx ; c - > add_pixels_clamped = ff_add_pixels_clamped_mmx ; } if ( EXTERNAL_SSE2 ( cpu_flags ) ) { c - > put_signed_pixels_clamped = ff_put_signed_pixels_clamped_sse2 ; c - > put_pixels_clamped = ff_put_pixels_clamped_sse2 ; c - > add_pixels_clamped = ff_add_pixels_clamped_sse2 ; } if ( ARCH_X86_64 & & avctx - > bits_per_raw_sample == 10 & & avctx - > lowres == 0 & & ( avctx - > idct_algo == FF_IDCT_AUTO || avctx - > idct_algo == FF_IDCT_SIMPLEAUTO || avctx - > idct_algo == FF_IDCT_SIMPLE ) ) { if ( EXTERNAL_SSE2 ( cpu_flags ) ) { c - > idct_put = ff_simple_idct10_put_sse2 ; c - > idct_add = NULL ; c - > idct = ff_simple_idct10_sse2 ; c - > perm_type = FF_IDCT_PERM_TRANSPOSE ; } if ( EXTERNAL_AVX ( cpu_flags ) ) { c - > idct_put = ff_simple_idct10_put_avx ; c - > idct_add = NULL ; c - > idct = ff_simple_idct10_avx ; c - > perm_type = FF_IDCT_PERM_TRANSPOSE ; } } }",1
"static void render_slice ( Vp3DecodeContext * s , int slice ) { int x , y , i , j , fragment ; LOCAL_ALIGNED_16 ( DCTELEM , block , [64] ) ; int motion_x = 0xdeadbeef , motion_y = 0xdeadbeef ; int motion_halfpel_index ; uint8_t * motion_source ; int plane , first_pixel ; if ( slice > = s - > c_superblock_height ) return ; for ( plane = 0 ; plane < 3 ; plane + + ) { uint8_t * output_plane = s - > current_frame . data [plane] + s - > data_offset[plane] ; uint8_t * last_plane = s - > last_frame . data [plane] + s - > data_offset[plane] ; uint8_t * golden_plane = s - > golden_frame . data [plane] + s - > data_offset[plane] ; int stride = s - > current_frame . linesize[plane] ; int plane_width = s - > width > > ( plane & & s - > chroma_x_shift ) ; int plane_height = s - > height > > ( plane & & s - > chroma_y_shift ) ; int8_t ( * motion_val ) [2] = s - > motion_val[ ! ! plane] ; int sb_x , sb_y = slice < < ( ! plane & & s - > chroma_y_shift ) ; int slice_height = sb_y + 1 + ( ! plane & & s - > chroma_y_shift ) ; int slice_width = plane ? s - > c_superblock_width : s - > y_superblock_width ; int fragment_width = s - > fragment_width[ ! ! plane] ; int fragment_height = s - > fragment_height[ ! ! plane] ; int fragment_start = s - > fragment_start[plane] ; int do_await = ! plane & & HAVE_THREADS & & ( s - > avctx - > active_thread_type & FF_THREAD_FRAME ) ; if ( ! s - > flipped_image ) stride = - stride ; if ( CONFIG_GRAY & & plane & & ( s - > avctx - > flags & CODEC_FLAG_GRAY ) ) continue ; / * for each superblock row in the slice ( both of them ) . . . * / for ( ; sb_y < slice_height ; sb_y + + ) { / * for each superblock in a row . . . * / for ( sb_x = 0 ; sb_x < slice_width ; sb_x + + ) { / * for each block in a superblock . . . * / for ( j = 0 ; j < 16 ; j + + ) { x = 4 * sb_x + hilbert_offset[j][0] ; y = 4 * sb_y + hilbert_offset[j][1] ; fragment = y * fragment_width + x ; i = fragment_start + fragment ; // bounds check if ( x > = fragment_width || y > = fragment_height ) continue ; first_pixel = 8 * y * stride + 8 * x ; if ( do_await & & s - > all_fragments[i] . coding_method ! = MODE_INTRA ) await_reference_row ( s , & s - > all_fragments[i] , motion_val[fragment][1] , ( 16 * y ) > > s - > chroma_y_shift ) ; / * transform if this block was coded * / if ( s - > all_fragments[i] . coding_method ! = MODE_COPY ) { if ( ( s - > all_fragments[i] . coding_method == MODE_USING_GOLDEN ) || ( s - > all_fragments[i] . coding_method == MODE_GOLDEN_MV ) ) motion_source= golden_plane ; else motion_source= last_plane ; motion_source + = first_pixel ; motion_halfpel_index = 0 ; / * sort out the motion vector if this fragment is coded * using a motion vector method * / if ( ( s - > all_fragments[i] . coding_method > MODE_INTRA ) & & ( s - > all_fragments[i] . coding_method ! = MODE_USING_GOLDEN ) ) { int src_x , src_y ; motion_x = motion_val[fragment][0] ; motion_y = motion_val[fragment][1] ; src_x= ( motion_x > > 1 ) + 8 * x ; src_y= ( motion_y > > 1 ) + 8 * y ; motion_halfpel_index = motion_x & 0x01 ; motion_source + = ( motion_x > > 1 ) ; motion_halfpel_index |= ( motion_y & 0x01 ) < < 1 ; motion_source + = ( ( motion_y > > 1 ) * stride ) ; if ( src_x < 0 || src_y < 0 || src_x + 9 > = plane_width || src_y + 9 > = plane_height ) { uint8_t * temp= s - > edge_emu_buffer ; if ( stride < 0 ) temp - = 8 * stride ; s - > dsp . emulated_edge_mc ( temp , motion_source , stride , 9 , 9 , src_x , src_y , plane_width , plane_height ) ; motion_source= temp ; } } / * first , take care of copying a block from either the * previous or the golden frame * / if ( s - > all_fragments[i] . coding_method ! = MODE_INTRA ) { / * Note , it is possible to implement all MC cases with put_no_rnd_pixels_l2 which would look more like the VP3 source but this would be slower as put_no_rnd_pixels_tab is better optimzed * / if ( motion_halfpel_index ! = 3 ) { s - > dsp . put_no_rnd_pixels_tab[1][motion_halfpel_index] ( output_plane + first_pixel , motion_source , stride , 8 ) ; } else { int d= ( motion_x motion_y ) > > 31 ; // d is 0 if motion_x and _y have the same sign , else - 1 s - > dsp . put_no_rnd_pixels_l2[1] ( output_plane + first_pixel , motion_source - d , motion_source + stride + 1 + d , stride , 8 ) ; } } s - > dsp . clear_block ( block ) ; / * invert DCT and place ( or add ) in final output * / if ( s - > all_fragments[i] . coding_method == MODE_INTRA ) { int index ; index = vp3_dequant ( s , s - > all_fragments + i , plane , 0 , block ) ; if ( index > 63 ) continue ; if ( s - > avctx - > idct_algo ! =FF_IDCT_VP3 ) block[0] + = 128 < < 3 ; s - > dsp . idct_put ( output_plane + first_pixel , stride , block ) ; } else { int index = vp3_dequant ( s , s - > all_fragments + i , plane , 1 , block ) ; if ( index > 63 ) continue ; if ( index > 0 ) { s - > dsp . idct_add ( output_plane + first_pixel , stride , block ) ; } else { s - > dsp . vp3_idct_dc_add ( output_plane + first_pixel , stride , block ) ; } } } else { / * copy directly from the previous frame * / s - > dsp . put_pixels_tab[1][0] ( output_plane + first_pixel , last_plane + first_pixel , stride , 8 ) ; } } } // Filter up to the last row in the superblock row if ( ! s - > skip_loop_filter ) apply_loop_filter ( s , plane , 4 * sb_y - ! ! sb_y , FFMIN ( 4 * sb_y + 3 , fragment_height - 1 ) ) ;",1
"static int context_init ( H264Context * h ) { MpegEncContext * const s = & h - > s ; CHECKED_ALLOCZ ( h - > top_borders[0] , h - > s . mb_width * ( 16 + 8 + 8 ) * sizeof ( uint8_t ) ) CHECKED_ALLOCZ ( h - > top_borders[1] , h - > s . mb_width * ( 16 + 8 + 8 ) * sizeof ( uint8_t ) ) // edge emu needs blocksize + filter length - 1 ( =17x17 for halfpel / 21x21 for h264 ) CHECKED_ALLOCZ ( s - > allocated_edge_emu_buffer , ( s - > width + 64 ) * 2 * 21 * 2 ) ; // ( width + edge + align ) * interlaced * MBsize * tolerance s - > edge_emu_buffer= s - > allocated_edge_emu_buffer + ( s - > width + 64 ) * 2 * 21 ; return 0 ; fail : return - 1 ; // free_tables will clean up for us }",1
"int ff_MPV_encode_picture ( AVCodecContext * avctx , AVPacket * pkt , AVFrame * pic_arg , int * got_packet ) { MpegEncContext * s = avctx - > priv_data ; int i , stuffing_count , ret ; int context_count = s - > slice_context_count ; s - > picture_in_gop_number + + ; if ( load_input_picture ( s , pic_arg ) < 0 ) return - 1 ; if ( select_input_picture ( s ) < 0 ) { return - 1 ; } / * output ? * / if ( s - > new_picture . f . data[0] ) { if ( ( ret = ff_alloc_packet2 ( avctx , pkt , s - > mb_width * s - > mb_height * ( MAX_MB_BYTES + 100 ) + 10000 ) ) < 0 ) return ret ; if ( s - > mb_info ) { s - > mb_info_ptr = av_packet_new_side_data ( pkt , AV_PKT_DATA_H263_MB_INFO , s - > mb_width * s - > mb_height * 12 ) ; s - > prev_mb_info = s - > last_mb_info = s - > mb_info_size = 0 ; } for ( i = 0 ; i < context_count ; i + + ) { int start_y = s - > thread_context[i] - > start_mb_y ; int end_y = s - > thread_context[i] - > end_mb_y ; int h = s - > mb_height ; uint8_t * start = pkt - > data + ( size_t ) ( ( ( int64_t ) pkt - > size ) * start_y / h ) ; uint8_t * end = pkt - > data + ( size_t ) ( ( ( int64_t ) pkt - > size ) * end_y / h ) ; init_put_bits ( & s - > thread_context[i] - > pb , start , end - start ) ; } s - > pict_type = s - > new_picture . f . pict_type ; //emms_c ( ) ; //printf ( qs : %f %f %d\n , s - > new_picture . quality , // s - > current_picture . quality , s - > qscale ) ; ff_MPV_frame_start ( s , avctx ) ; vbv_retry : if ( encode_picture ( s , s - > picture_number ) < 0 ) return - 1 ; avctx - > header_bits = s - > header_bits ; avctx - > mv_bits = s - > mv_bits ; avctx - > misc_bits = s - > misc_bits ; avctx - > i_tex_bits = s - > i_tex_bits ; avctx - > p_tex_bits = s - > p_tex_bits ; avctx - > i_count = s - > i_count ; // FIXME f/b_count in avctx avctx - > p_count = s - > mb_num - s - > i_count - s - > skip_count ; avctx - > skip_count = s - > skip_count ; ff_MPV_frame_end ( s ) ; if ( CONFIG_MJPEG_ENCODER & & s - > out_format == FMT_MJPEG ) ff_mjpeg_encode_picture_trailer ( s ) ; if ( avctx - > rc_buffer_size ) { RateControlContext * rcc = & s - > rc_context ; int max_size = rcc - > buffer_index * avctx - > rc_max_available_vbv_use ; if ( put_bits_count ( & s - > pb ) > max_size & & s - > lambda < s - > avctx - > lmax ) { s - > next_lambda = FFMAX ( s - > lambda + 1 , s - > lambda * ( s - > qscale + 1 ) / s - > qscale ) ; if ( s - > adaptive_quant ) { int i ; for ( i = 0 ; i < s - > mb_height * s - > mb_stride ; i + + ) s - > lambda_table[i] = FFMAX ( s - > lambda_table[i] + 1 , s - > lambda_table[i] * ( s - > qscale + 1 ) / s - > qscale ) ; } s - > mb_skipped = 0 ; // done in MPV_frame_start ( ) // done in encode_picture ( ) so we must undo it if ( s - > pict_type == AV_PICTURE_TYPE_P ) { if ( s - > flipflop_rounding || s - > codec_id == CODEC_ID_H263P || s - > codec_id == CODEC_ID_MPEG4 ) s - > no_rounding = 1 ; } if ( s - > pict_type ! = AV_PICTURE_TYPE_B ) { s - > time_base = s - > last_time_base ; s - > last_non_b_time = s - > time - s - > pp_time ; } //av_log ( NULL , AV_LOG_ERROR , R : %d , s - > next_lambda ) ; for ( i = 0 ; i < context_count ; i + + ) { PutBitContext * pb = & s - > thread_context[i] - > pb ; init_put_bits ( pb , pb - > buf , pb - > buf_end - pb - > buf ) ; } goto vbv_retry ; } assert ( s - > avctx - > rc_max_rate ) ; } if ( s - > flags & CODEC_FLAG_PASS1 ) ff_write_pass1_stats ( s ) ; for ( i = 0 ; i < 4 ; i + + ) { s - > current_picture_ptr - > f . error[i] = s - > current_picture . f . error[i] ; avctx - > error[i] + = s - > current_picture_ptr - > f . error[i] ; } if ( s - > flags & CODEC_FLAG_PASS1 ) assert ( avctx - > header_bits + avctx - > mv_bits + avctx - > misc_bits + avctx - > i_tex_bits + avctx - > p_tex_bits == put_bits_count ( & s - > pb ) ) ; flush_put_bits ( & s - > pb ) ; s - > frame_bits = put_bits_count ( & s - > pb ) ; stuffing_count = ff_vbv_update ( s , s - > frame_bits ) ; if ( stuffing_count ) { if ( s - > pb . buf_end - s - > pb . buf - ( put_bits_count ( & s - > pb ) > > 3 ) < stuffing_count + 50 ) { av_log ( s - > avctx , AV_LOG_ERROR , stuffing too large\n ) ; return - 1 ; } switch ( s - > codec_id ) { case CODEC_ID_MPEG1VIDEO : case CODEC_ID_MPEG2VIDEO : while ( stuffing_count - - ) { put_bits ( & s - > pb , 8 , 0 ) ; } break ; case CODEC_ID_MPEG4 : put_bits ( & s - > pb , 16 , 0 ) ; put_bits ( & s - > pb , 16 , 0x1C3 ) ; stuffing_count - = 4 ; while ( stuffing_count - - ) { put_bits ( & s - > pb , 8 , 0xFF ) ; } break ; default : av_log ( s - > avctx , AV_LOG_ERROR , vbv buffer overflow\n ) ; } flush_put_bits ( & s - > pb ) ; s - > frame_bits = put_bits_count ( & s - > pb ) ; } / * update mpeg1/2 vbv_delay for CBR * / if ( s - > avctx - > rc_max_rate & & s -",1
"static int check_slice_end ( RV34DecContext * r , MpegEncContext * s ) { int bits ; if ( s - > mb_y > = s - > mb_height ) return 1 ; if ( ! s - > mb_num_left ) return 1 ; if ( r - > s . mb_skip_run > 1 ) return 0 ; bits = get_bits_left ( & s - > gb ) ; if ( bits < 0 || ( bits < 8 & & ! show_bits ( & s - > gb , bits ) ) ) return 1 ; return 0 ; }",0
"static int alloc_frame_buffer ( AVCodecContext * avctx , Picture * pic , MotionEstContext * me , ScratchpadContext * sc , int chroma_x_shift , int chroma_y_shift , int linesize , int uvlinesize ) { int edges_needed = av_codec_is_encoder ( avctx - > codec ) ; int r , ret ; pic - > tf . f = pic - > f ; if ( avctx - > codec_id ! = AV_CODEC_ID_WMV3IMAGE & & avctx - > codec_id ! = AV_CODEC_ID_VC1IMAGE & & avctx - > codec_id ! = AV_CODEC_ID_MSS2 ) { if ( edges_needed ) { pic - > f - > width = avctx - > width + 2 * EDGE_WIDTH ; pic - > f - > height = avctx - > height + 2 * EDGE_WIDTH ; } r = ff_thread_get_buffer ( avctx , & pic - > tf , pic - > reference ? AV_GET_BUFFER_FLAG_REF : 0 ) ; } else { pic - > f - > width = avctx - > width ; pic - > f - > height = avctx - > height ; pic - > f - > format = avctx - > pix_fmt ; r = avcodec_default_get_buffer2 ( avctx , pic - > f , 0 ) ; } if ( r < 0 || ! pic - > f - > buf[0] ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed ( %d %p ) \n , r , pic - > f - > data[0] ) ; return - 1 ; } if ( edges_needed ) { int i ; for ( i = 0 ; pic - > f - > data[i] ; i + + ) { int offset = ( EDGE_WIDTH > > ( i ? chroma_y_shift : 0 ) ) * pic - > f - > linesize[i] + ( EDGE_WIDTH > > ( i ? chroma_x_shift : 0 ) ) ; pic - > f - > data[i] + = offset ; } pic - > f - > width = avctx - > width ; pic - > f - > height = avctx - > height ; } if ( avctx - > hwaccel ) { assert ( ! pic - > hwaccel_picture_private ) ; if ( avctx - > hwaccel - > frame_priv_data_size ) { pic - > hwaccel_priv_buf = av_buffer_allocz ( avctx - > hwaccel - > frame_priv_data_size ) ; if ( ! pic - > hwaccel_priv_buf ) { av_log ( avctx , AV_LOG_ERROR , alloc_frame_buffer ( ) failed ( hwaccel private data allocation ) \n ) ; return - 1 ; } pic - > hwaccel_picture_private = pic - > hwaccel_priv_buf - > data ; } } if ( linesize & & ( linesize ! = pic - > f - > linesize[0] || uvlinesize ! = pic - > f - > linesize[1] ) ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed ( stride changed ) \n ) ; ff_mpeg_unref_picture ( avctx , pic ) ; return - 1 ; } if ( pic - > f - > linesize[1] ! = pic - > f - > linesize[2] ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed ( uv stride mismatch ) \n ) ; ff_mpeg_unref_picture ( avctx , pic ) ; return - 1 ; } if ( ! sc - > edge_emu_buffer & & ( ret = ff_mpeg_framesize_alloc ( avctx , me , sc , pic - > f - > linesize[0] ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed to allocate context scratch buffers . \n ) ; ff_mpeg_unref_picture ( avctx , pic ) ; return ret ; } return 0 ; }",0
"void ff_avg_h264_qpel4_mc32_msa ( uint8_t * dst , const uint8_t * src , ptrdiff_t stride ) { avc_luma_midh_qrt_and_aver_dst_4w_msa ( src - ( 2 * stride ) - 2 , stride , dst , stride , 4 , 1 ) ; }",0
"static void draw_bar_yuv ( AVFrame * out , const float * h , const float * rcp_h , const ColorFloat * c , int bar_h ) { int x , y , yh , w = out - > width ; float mul , ht , rcp_bar_h = 1 . 0f / bar_h ; uint8_t * vy = out - > data[0] , * vu = out - > data[1] , * vv = out - > data[2] ; uint8_t * lpy , * lpu , * lpv ; int lsy = out - > linesize[0] , lsu = out - > linesize[1] , lsv = out - > linesize[2] ; int fmt = out - > format ; for ( y = 0 ; y < bar_h ; y + = 2 ) { yh = ( fmt == AV_PIX_FMT_YUV420P ) ? y / 2 : y ; ht = ( bar_h - y ) * rcp_bar_h ; lpy = vy + y * lsy ; lpu = vu + yh * lsu ; lpv = vv + yh * lsv ; for ( x = 0 ; x < w ; x + = 2 ) { if ( h[x] < = ht ) { * lpy + + = 16 ; * lpu + + = 128 ; * lpv + + = 128 ; } else { mul = ( h[x] - ht ) * rcp_h[x] ; * lpy + + = mul * c[x] . yuv . y + ( 1 . 0f - mul ) * 16 . 0f + 0 . 5f ; * lpu + + = mul * c[x] . yuv . u + ( 1 . 0f - mul ) * 128 . 0f + 0 . 5f ; * lpv + + = mul * c[x] . yuv . v + ( 1 . 0f - mul ) * 128 . 0f + 0 . 5f ; } / * u and v are skipped on yuv422p and yuv420p * / if ( fmt == AV_PIX_FMT_YUV444P ) { if ( h[x + 1] < = ht ) { * lpy + + = 16 ; * lpu + + = 128 ; * lpv + + = 128 ; } else { mul = ( h[x + 1] - ht ) * rcp_h[x + 1] ; * lpy + + = mul * c[x + 1] . yuv . y + ( 1 . 0f - mul ) * 16 . 0f + 0 . 5f ; * lpu + + = mul * c[x + 1] . yuv . u + ( 1 . 0f - mul ) * 128 . 0f + 0 . 5f ; * lpv + + = mul * c[x + 1] . yuv . v + ( 1 . 0f - mul ) * 128 . 0f + 0 . 5f ; } } else { if ( h[x + 1] < = ht ) { * lpy + + = 16 ; } else { mul = ( h[x + 1] - ht ) * rcp_h[x + 1] ; * lpy + + = mul * c[x + 1] . yuv . y + ( 1 . 0f - mul ) * 16 . 0f + 0 . 5f ; } } } ht = ( bar_h - ( y + 1 ) ) * rcp_bar_h ; lpy = vy + ( y + 1 ) * lsy ; lpu = vu + ( y + 1 ) * lsu ; lpv = vv + ( y + 1 ) * lsv ; for ( x = 0 ; x < w ; x + = 2 ) { / * u and v are skipped on yuv420p * / if ( fmt ! = AV_PIX_FMT_YUV420P ) { if ( h[x] < = ht ) { * lpy + + = 16 ; * lpu + + = 128 ; * lpv + + = 128 ; } else { mul = ( h[x] - ht ) * rcp_h[x] ; * lpy + + = mul * c[x] . yuv . y + ( 1 . 0f - mul ) * 16 . 0f + 0 . 5f ; * lpu + + = mul * c[x] . yuv . u + ( 1 . 0f - mul ) * 128 . 0f + 0 . 5f ; * lpv + + = mul * c[x] . yuv . v + ( 1 . 0f - mul ) * 128 . 0f + 0 . 5f ; } } else { if ( h[x] < = ht ) { * lpy + + = 16 ; } else { mul = ( h[x] - ht ) * rcp_h[x] ; * lpy + + = mul * c[x] . yuv . y + ( 1 . 0f - mul ) * 16 . 0f + 0 . 5f ; } } / * u and v are skipped on yuv422p and yuv420p * / if ( out - > format == AV_PIX_FMT_YUV444P ) { if ( h[x + 1] < = ht ) { * lpy + + = 16 ; * lpu + + = 128 ; * lpv + + = 128 ; } else { mul = ( h[x + 1] - ht ) * rcp_h[x + 1] ; * lpy + + = mul * c[x + 1] . yuv . y + ( 1 . 0f - mul ) * 16 . 0f + 0 . 5f ; * lpu + + = mul * c[x + 1] . yuv . u + ( 1 . 0f - mul ) * 128 . 0f + 0 . 5f ; * lpv + + = mul * c[x + 1] . yuv . v + ( 1 . 0f - mul ) * 128 . 0f + 0 . 5f ; } } else { if ( h[x + 1] < = ht ) { * lpy + + = 16 ; } else { mul = ( h[x + 1] - ht ) * rcp_h[x + 1] ; * lpy + + = mul * c[x + 1] . yuv . y + ( 1 . 0f - mul ) * 16 . 0f + 0 . 5f ; } } } } }",0
"static void show_programs ( WriterContext * w , AVFormatContext * fmt_ctx ) { int i ; writer_print_section_header ( w , SECTION_ID_PROGRAMS ) ; for ( i = 0 ; i < fmt_ctx - > nb_programs ; i + + ) { AVProgram * program = fmt_ctx - > programs[i] ; if ( ! program ) continue ; show_program ( w , fmt_ctx , program ) ; } writer_print_section_footer ( w ) ; }",0
"static int put_flac_codecpriv ( AVFormatContext * s , AVIOContext * pb , AVCodecContext * codec ) { int write_comment = ( codec - > channel_layout & & ! ( codec - > channel_layout & 0x3ffffULL ) & & ! ff_flac_is_native_layout ( codec - > channel_layout ) ) ; int ret = ff_flac_write_header ( pb , codec - > extradata , codec - > extradata_size , ! write_comment ) ; if ( ret < 0 ) return ret ; if ( write_comment ) { const char * vendor = ( s - > flags & AVFMT_FLAG_BITEXACT ) ? Lavf : LIBAVFORMAT_IDENT ; AVDictionary * dict = NULL ; uint8_t buf[32] , * data , * p ; int len ; snprintf ( buf , sizeof ( buf ) , 0x% PRIx64 , codec - > channel_layout ) ; av_dict_set ( & dict , WAVEFORMATEXTENSIBLE_CHANNEL_MASK , buf , 0 ) ; len = ff_vorbiscomment_length ( dict , vendor ) ; data = av_malloc ( len + 4 ) ; if ( ! data ) { av_dict_free ( & dict ) ; return AVERROR ( ENOMEM ) ; } data[0] = 0x84 ; AV_WB24 ( data + 1 , len ) ; p = data + 4 ; ff_vorbiscomment_write ( & p , & dict , vendor ) ; avio_write ( pb , data , len + 4 ) ; av_freep ( & data ) ; av_dict_free ( & dict ) ; } return 0 ; }",0
"static int avi_read_packet ( AVFormatContext * s , AVPacket * pkt ) { AVIContext * avi = s - > priv_data ; ByteIOContext * pb = & s - > pb ; int n , d[8] , size ; offset_t i ; void * dstr ; memset ( d , - 1 , sizeof ( int ) * 8 ) ; if ( avi - > dv_demux ) { size = dv_get_packet ( avi - > dv_demux , pkt ) ; if ( size > = 0 ) return size ; } for ( i=url_ftell ( pb ) ; ! url_feof ( pb ) ; i + + ) { int j ; if ( i > = avi - > movi_end ) { if ( avi - > is_odml ) { url_fskip ( pb , avi - > riff_end - i ) ; avi - > riff_end = avi - > movi_end = url_filesize ( url_fileno ( pb ) ) ; } else break ; } for ( j=0 ; j < 7 ; j + + ) d[j]= d[j + 1] ; d[7]= get_byte ( pb ) ; size= d[4] + ( d[5] < < 8 ) + ( d[6] < < 16 ) + ( d[7] < < 24 ) ; //parse ix n= ( d[2] - ' 0 ' ) * 10 + ( d[3] - ' 0 ' ) ; if ( d[2] > = ' 0 ' & & d[2] < = ' 9 ' & & d[3] > = ' 0 ' & & d[3] < = ' 9 ' & & d[0] == ' i ' & & d[1] == ' x ' & & n < s - > nb_streams & & i + size < = avi - > movi_end ) { url_fskip ( pb , size ) ; } //parse JUNK if ( d[0] == ' J ' & & d[1] == ' U ' & & d[2] == ' N ' & & d[3] == ' K ' & & i + size < = avi - > movi_end ) { url_fskip ( pb , size ) ; } //parse dc/ wb n= ( d[0] - ' 0 ' ) * 10 + ( d[1] - ' 0 ' ) ; if ( d[0] > = ' 0 ' & & d[0] < = ' 9 ' & & d[1] > = ' 0 ' & & d[1] < = ' 9 ' & & ( ( d[2] == ' d ' & & d[3] == ' c ' ) || ( d[2] == ' w ' & & d[3] == ' b ' ) || ( d[2] == ' d ' & & d[3] == ' b ' ) || ( d[2] == ' _ ' & & d[3] == ' _ ' ) ) & & n < s - > nb_streams & & i + size < = avi - > movi_end ) { av_new_packet ( pkt , size ) ; get_buffer ( pb , pkt - > data , size ) ; if ( size & 1 ) { get_byte ( pb ) ; size + + ; } if ( avi - > dv_demux ) { dstr = pkt - > destruct ; size = dv_produce_packet ( avi - > dv_demux , pkt , pkt - > data , pkt - > size ) ; pkt - > destruct = dstr ; pkt - > flags |= PKT_FLAG_KEY ; } else { AVStream * st ; AVIStream * ast ; st = s - > streams[n] ; ast = st - > priv_data ; / * XXX : how to handle B frames in avi ? * / pkt - > dts = ast - > frame_offset ; // pkt - > dts + = ast - > start ; if ( ast - > sample_size ) pkt - > dts /= ast - > sample_size ; //av_log ( NULL , AV_LOG_DEBUG , dts : %Ld offset : %d %d/%d smpl_siz : %d base : %d st : %d size : %d\n , pkt - > dts , ast - > frame_offset , ast - > scale , ast - > rate , ast - > sample_size , AV_TIME_BASE , n , size ) ; pkt - > stream_index = n ; / * FIXME : We really should read index for that * / if ( st - > codec . codec_type == CODEC_TYPE_VIDEO ) { if ( ast - > frame_offset < ast - > nb_index_entries ) { if ( ast - > index_entries[ast - > frame_offset] . flags & AVIIF_INDEX ) pkt - > flags |= PKT_FLAG_KEY ; } else { / * if no index , better to say that all frames are key frames * / pkt - > flags |= PKT_FLAG_KEY ; } } else { pkt - > flags |= PKT_FLAG_KEY ; } if ( ast - > sample_size ) ast - > frame_offset + = pkt - > size ; else ast - > frame_offset + + ; } return size ; } } return - 1 ; }",0
"static int rscc_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { RsccContext * ctx = avctx - > priv_data ; GetByteContext * gbc = & ctx - > gbc ; GetByteContext tiles_gbc ; AVFrame * frame = data ; const uint8_t * pixels , * raw ; uint8_t * inflated_tiles = NULL ; int tiles_nb , packed_size , pixel_size = 0 ; int i , ret = 0 ; bytestream2_init ( gbc , avpkt - > data , avpkt - > size ) ; / * Size check * / if ( bytestream2_get_bytes_left ( gbc ) < 12 ) { av_log ( avctx , AV_LOG_ERROR , Packet too small ( %d ) \n , avpkt - > size ) ; return AVERROR_INVALIDDATA ; / * Read number of tiles , and allocate the array * / tiles_nb = bytestream2_get_le16 ( gbc ) ; av_fast_malloc ( & ctx - > tiles , & ctx - > tiles_size , tiles_nb * sizeof ( * ctx - > tiles ) ) ; if ( ! ctx - > tiles ) { ret = AVERROR ( ENOMEM ) ; av_log ( avctx , AV_LOG_DEBUG , Frame with %d tiles . \n , tiles_nb ) ; / * When there are more than 5 tiles , they are packed together with * a size header . When that size does not match the number of tiles * times the tile size , it means it needs to be inflated as well * / if ( tiles_nb > 5 ) { uLongf packed_tiles_size ; if ( tiles_nb < 32 ) packed_tiles_size = bytestream2_get_byte ( gbc ) ; else packed_tiles_size = bytestream2_get_le16 ( gbc ) ; ff_dlog ( avctx , packed tiles of size %lu . \n , packed_tiles_size ) ; / * If necessary , uncompress tiles , and hijack the bytestream reader * / if ( packed_tiles_size ! = tiles_nb * TILE_SIZE ) { uLongf length = tiles_nb * TILE_SIZE ; inflated_tiles = av_malloc ( length ) ; if ( ! inflated_tiles ) { ret = AVERROR ( ENOMEM ) ; ret = uncompress ( inflated_tiles , & length , gbc - > buffer , packed_tiles_size ) ; if ( ret ) { av_log ( avctx , AV_LOG_ERROR , Tile deflate error %d . \n , ret ) ; ret = AVERROR_UNKNOWN ; / * Skip the compressed tile section in the main byte reader , * and point it to read the newly uncompressed data * / bytestream2_skip ( gbc , packed_tiles_size ) ; bytestream2_init ( & tiles_gbc , inflated_tiles , length ) ; gbc = & tiles_gbc ; / * Fill in array of tiles , keeping track of how many pixels are updated * / for ( i = 0 ; i < tiles_nb ; i + + ) { ctx - > tiles[i] . x = bytestream2_get_le16 ( gbc ) ; ctx - > tiles[i] . w = bytestream2_get_le16 ( gbc ) ; ctx - > tiles[i] . y = bytestream2_get_le16 ( gbc ) ; ctx - > tiles[i] . h = bytestream2_get_le16 ( gbc ) ; pixel_size + = ctx - > tiles[i] . w * ctx - > tiles[i] . h * ctx - > component_size ; ff_dlog ( avctx , tile %d orig ( %d , %d ) %dx%d . \n , i , ctx - > tiles[i] . x , ctx - > tiles[i] . y , ctx - > tiles[i] . w , ctx - > tiles[i] . h ) ; if ( ctx - > tiles[i] . w == 0 || ctx - > tiles[i] . h == 0 ) { av_log ( avctx , AV_LOG_ERROR , invalid tile %d at ( %d . %d ) with size %dx%d . \n , i , ctx - > tiles[i] . x , ctx - > tiles[i] . y , ctx - > tiles[i] . w , ctx - > tiles[i] . h ) ; } else if ( ctx - > tiles[i] . x + ctx - > tiles[i] . w > avctx - > width || ctx - > tiles[i] . y + ctx - > tiles[i] . h > avctx - > height ) { av_log ( avctx , AV_LOG_ERROR , out of bounds tile %d at ( %d . %d ) with size %dx%d . \n , i , ctx - > tiles[i] . x , ctx - > tiles[i] . y , ctx - > tiles[i] . w , ctx - > tiles[i] . h ) ; / * Reset the reader in case it had been modified before * / gbc = & ctx - > gbc ; / * Extract how much pixel data the tiles contain * / if ( pixel_size < 0x100 ) packed_size = bytestream2_get_byte ( gbc ) ; else if ( pixel_size < 0x10000 ) packed_size = bytestream2_get_le16 ( gbc ) ; else if ( pixel_size < 0x1000000 ) packed_size = bytestream2_get_le24 ( gbc ) ; else packed_size = bytestream2_get_le32 ( gbc ) ; ff_dlog ( avctx , pixel_size %d packed_size %d . \n , pixel_size , packed_size ) ; if ( packed_size < 0 ) { av_log ( avctx , AV_LOG_ERROR , Invalid tile size %d\n , packed_size ) ; / * Get pixels buffer , it may be deflated or just raw * / if ( pixel_size == packed_size ) { if ( bytestream2_get_bytes_left ( gbc ) < pixel_size ) { av_log ( avctx , AV_LOG_ERROR , Insufficient input for %d\n , pixel_size ) ; pixels = gbc - > buffer ; } else { uLongf len = ctx - > inflated_size ; ret = uncompress ( ctx - > inflated_buf , & len , gbc - > buffer , packed_size ) ; if ( ret ) { av_log ( avctx , AV_LOG_ERROR , Pixel deflate error %d . \n , ret ) ; ret = AVERROR_UNKNOWN ; pixels = ctx - > inflated_buf ; / * Allocate when needed * / ret = ff_reget_buffer ( avctx , ctx - > reference ) ; if ( ret < 0 ) / * Pointer to actual pixels , will be updated when data is consumed * / raw = pixels ; for ( i = 0 ; i < tiles_nb ; i + + ) { uint8_t * dst = ctx - > reference - > data[0] + ctx - > reference - > linesize[0] * ( avctx - > height - ctx - > tiles[i] . y - 1 ) + ctx - > tiles[i] . x * ctx - > component_size ; av_image_copy_plane ( dst , - 1 * ctx - > reference - > linesize[0] , raw , ctx - > tiles[i] . w * ctx - > component_size , ctx - > tiles[i] . w * ctx - > component_size , ctx - > tiles[i] . h ) ; raw + = ctx - > tiles[i] . w * ctx - > component_size * ctx - > tiles[i] . h ; / * Frame is ready to be output * / ret = av_frame_ref ( frame , ctx - > reference",1
"static int64_t wrap_timestamp ( AVStream * st , int64_t timestamp ) { if ( st - > pts_wrap_behavior ! = AV_PTS_WRAP_IGNORE & & st - > pts_wrap_bits < 64 & & st - > pts_wrap_reference ! = AV_NOPTS_VALUE & & timestamp ! = AV_NOPTS_VALUE ) { if ( st - > pts_wrap_behavior == AV_PTS_WRAP_ADD_OFFSET & & timestamp < st - > pts_wrap_reference ) return timestamp + ( 1LL < < st - > pts_wrap_bits ) ; else if ( st - > pts_wrap_behavior == AV_PTS_WRAP_SUB_OFFSET & & timestamp > = st - > pts_wrap_reference ) return timestamp - ( 1LL < < st - > pts_wrap_bits ) ; } return timestamp ; }",1
"static void write_section_data ( AVFormatContext * s , MpegTSFilter * tss1 , const uint8_t * buf , int buf_size , int is_start ) { MpegTSContext * ts = s - > priv_data ; MpegTSSectionFilter * tss = & tss1 - > u . section_filter ; int len ; if ( is_start ) { memcpy ( tss - > section_buf , buf , buf_size ) ; tss - > section_index = buf_size ; tss - > section_h_size = - 1 ; tss - > end_of_section_reached = 0 ; } else { if ( tss - > end_of_section_reached ) return ; len = 4096 - tss - > section_index ; if ( buf_size < len ) len = buf_size ; memcpy ( tss - > section_buf + tss - > section_index , buf , len ) ; tss - > section_index + = len ; } / * compute section length if possible * / if ( tss - > section_h_size == - 1 & & tss - > section_index > = 3 ) { len = ( AV_RB16 ( tss - > section_buf + 1 ) & 0xfff ) + 3 ; if ( len > 4096 ) return ; tss - > section_h_size = len ; } if ( tss - > section_h_size ! = - 1 & & tss - > section_index > = tss - > section_h_size ) { int crc_valid = 1 ; tss - > end_of_section_reached = 1 ; if ( tss - > check_crc ) { crc_valid = ! av_crc ( av_crc_get_table ( AV_CRC_32_IEEE ) , - 1 , tss - > section_buf , tss - > section_h_size ) ; if ( crc_valid ) { ts - > crc_validity[ tss1 - > pid ] = 100 ; } else if ( ts - > crc_validity[ tss1 - > pid ] > - 10 ) { ts - > crc_validity[ tss1 - > pid ] - - ; } else crc_valid = 2 ; } if ( crc_valid ) tss - > section_cb ( tss1 , tss - > section_buf , tss - > section_h_size ) ; } }",1
"static int dpcm_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame_ptr , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; const uint8_t * buf_end = buf + buf_size ; DPCMContext * s = avctx - > priv_data ; int out = 0 , ret ; int predictor[2] ; int ch = 0 ; int stereo = s - > channels - 1 ; int16_t * output_samples ; / * calculate output size * / switch ( avctx - > codec - > id ) { case CODEC_ID_ROQ_DPCM : out = buf_size - 8 ; break ; case CODEC_ID_INTERPLAY_DPCM : out = buf_size - 6 - s - > channels ; break ; case CODEC_ID_XAN_DPCM : out = buf_size - 2 * s - > channels ; break ; case CODEC_ID_SOL_DPCM : if ( avctx - > codec_tag ! = 3 ) out = buf_size * 2 ; else out = buf_size ; break ; } if ( out < = 0 ) { av_log ( avctx , AV_LOG_ERROR , packet is too small\n ) ; return AVERROR ( EINVAL ) ; } / * get output buffer * / s - > frame . nb_samples = out / s - > channels ; if ( ( ret = avctx - > get_buffer ( avctx , & s - > frame ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed\n ) ; return ret ; } output_samples = ( int16_t * ) s - > frame . data[0] ; switch ( avctx - > codec - > id ) { case CODEC_ID_ROQ_DPCM : buf + = 6 ; if ( stereo ) { predictor[1] = ( int16_t ) ( bytestream_get_byte ( & buf ) < < 8 ) ; predictor[0] = ( int16_t ) ( bytestream_get_byte ( & buf ) < < 8 ) ; } else { predictor[0] = ( int16_t ) bytestream_get_le16 ( & buf ) ; } / * decode the samples * / while ( buf < buf_end ) { predictor[ch] + = s - > roq_square_array[ * buf + + ] ; predictor[ch] = av_clip_int16 ( predictor[ch] ) ; * output_samples + + = predictor[ch] ; / * toggle channel * / ch = stereo ; } break ; case CODEC_ID_INTERPLAY_DPCM : buf + = 6 ; / * skip over the stream mask and stream length * / for ( ch = 0 ; ch < s - > channels ; ch + + ) { predictor[ch] = ( int16_t ) bytestream_get_le16 ( & buf ) ; * output_samples + + = predictor[ch] ; } ch = 0 ; while ( buf < buf_end ) { predictor[ch] + = interplay_delta_table[ * buf + + ] ; predictor[ch] = av_clip_int16 ( predictor[ch] ) ; * output_samples + + = predictor[ch] ; / * toggle channel * / ch = stereo ; } break ; case CODEC_ID_XAN_DPCM : { int shift[2] = { 4 , 4 } ; for ( ch = 0 ; ch < s - > channels ; ch + + ) predictor[ch] = ( int16_t ) bytestream_get_le16 ( & buf ) ; ch = 0 ; while ( buf < buf_end ) { uint8_t n = * buf + + ; int16_t diff = ( n & 0xFC ) < < 8 ; if ( ( n & 0x03 ) == 3 ) shift[ch] + + ; else shift[ch] - = ( 2 * ( n & 3 ) ) ; / * saturate the shifter to a lower limit of 0 * / if ( shift[ch] < 0 ) shift[ch] = 0 ; diff > > = shift[ch] ; predictor[ch] + = diff ; predictor[ch] = av_clip_int16 ( predictor[ch] ) ; * output_samples + + = predictor[ch] ; / * toggle channel * / ch = stereo ; } break ; } case CODEC_ID_SOL_DPCM : if ( avctx - > codec_tag ! = 3 ) { uint8_t * output_samples_u8 = data ; while ( buf < buf_end ) { uint8_t n = * buf + + ; s - > sample[0] + = s - > sol_table[n > > 4] ; s - > sample[0] = av_clip_uint8 ( s - > sample[0] ) ; * output_samples_u8 + + = s - > sample[0] ; s - > sample[stereo] + = s - > sol_table[n & 0x0F] ; s - > sample[stereo] = av_clip_uint8 ( s - > sample[stereo] ) ; * output_samples_u8 + + = s - > sample[stereo] ; } } else { while ( buf < buf_end ) { uint8_t n = * buf + + ; if ( n & 0x80 ) s - > sample[ch] - = sol_table_16[n & 0x7F] ; else s - > sample[ch] + = sol_table_16[n & 0x7F] ; s - > sample[ch] = av_clip_int16 ( s - > sample[ch] ) ; * output_samples + + = s - > sample[ch] ; / * toggle channel * / ch = stereo ; } } break ; } * got_frame_ptr = 1 ; * ( AVFrame * ) data = s - > frame ; return buf_size ; }",1
"static int decode_dds1 ( GetByteContext * gb , uint8_t * frame , int width , int height ) { const uint8_t * frame_start = frame ; const uint8_t * frame_end = frame + width * height ; int mask = 0x10000 , bitbuf = 0 ; int i , v , offset , count , segments ; segments = bytestream2_get_le16 ( gb ) ; while ( segments - - ) { if ( bytestream2_get_bytes_left ( gb ) < 2 ) return AVERROR_INVALIDDATA ; if ( mask == 0x10000 ) { bitbuf = bytestream2_get_le16u ( gb ) ; mask = 1 ; } if ( bitbuf & mask ) { v = bytestream2_get_le16 ( gb ) ; offset = ( v & 0x1FFF ) < < 2 ; count = ( ( v > > 13 ) + 2 ) < < 1 ; if ( frame - frame_start < offset || frame_end - frame < count * 2 + width ) return AVERROR_INVALIDDATA ; for ( i = 0 ; i < count ; i + + ) { frame[0] = frame[1] = frame[width] = frame[width + 1] = frame[ - offset] ; frame + = 2 ; } } else if ( bitbuf & ( mask < < 1 ) ) { v = bytestream2_get_le16 ( gb ) * 2 ; if ( frame - frame_end < v ) return AVERROR_INVALIDDATA ; frame + = v ; } else { if ( frame_end - frame < width + 3 ) return AVERROR_INVALIDDATA ; frame[0] = frame[1] = frame[width] = frame[width + 1] = bytestream2_get_byte ( gb ) ; frame + = 2 ; frame[0] = frame[1] = frame[width] = frame[width + 1] = bytestream2_get_byte ( gb ) ; frame + = 2 ; } mask < < = 2 ; } return 0 ; }",1
"int ff_hevc_decode_short_term_rps ( GetBitContext * gb , AVCodecContext * avctx , ShortTermRPS * rps , const HEVCSPS * sps , int is_slice_header ) { uint8_t rps_predict = 0 ; int delta_poc ; int k0 = 0 ; int k1 = 0 ; int k = 0 ; int i ; if ( rps ! = sps - > st_rps & & sps - > nb_st_rps ) rps_predict = get_bits1 ( gb ) ; if ( rps_predict ) { const ShortTermRPS * rps_ridx ; int delta_rps ; unsigned abs_delta_rps ; uint8_t use_delta_flag = 0 ; uint8_t delta_rps_sign ; if ( is_slice_header ) { unsigned int delta_idx = get_ue_golomb_long ( gb ) + 1 ; if ( delta_idx > sps - > nb_st_rps ) { Invalid value of delta_idx in slice header RPS : %d > %d . \n , delta_idx , sps - > nb_st_rps ) ; rps_ridx = & sps - > st_rps[sps - > nb_st_rps - delta_idx] ; rps - > rps_idx_num_delta_pocs = rps_ridx - > num_delta_pocs ; } else rps_ridx = & sps - > st_rps[rps - sps - > st_rps - 1] ; delta_rps_sign = get_bits1 ( gb ) ; abs_delta_rps = get_ue_golomb_long ( gb ) + 1 ; if ( abs_delta_rps < 1 || abs_delta_rps > 32768 ) { Invalid value of abs_delta_rps : %d\n , abs_delta_rps ) ; delta_rps = ( 1 - ( delta_rps_sign < < 1 ) ) * abs_delta_rps ; for ( i = 0 ; i < = rps_ridx - > num_delta_pocs ; i + + ) { int used = rps - > used[k] = get_bits1 ( gb ) ; if ( ! used ) use_delta_flag = get_bits1 ( gb ) ; if ( used || use_delta_flag ) { if ( i < rps_ridx - > num_delta_pocs ) delta_poc = delta_rps + rps_ridx - > delta_poc[i] ; else delta_poc = delta_rps ; rps - > delta_poc[k] = delta_poc ; if ( delta_poc < 0 ) k0 + + ; else k1 + + ; k + + ; if ( k > = FF_ARRAY_ELEMS ( rps - > used ) ) { Invalid num_delta_pocs : %d\n , k ) ; rps - > num_delta_pocs = k ; rps - > num_negative_pics = k0 ; // sort in increasing order ( smallest first ) if ( rps - > num_delta_pocs ! = 0 ) { int used , tmp ; for ( i = 1 ; i < rps - > num_delta_pocs ; i + + ) { delta_poc = rps - > delta_poc[i] ; used = rps - > used[i] ; for ( k = i - 1 ; k > = 0 ; k - - ) { tmp = rps - > delta_poc[k] ; if ( delta_poc < tmp ) { rps - > delta_poc[k + 1] = tmp ; rps - > used[k + 1] = rps - > used[k] ; rps - > delta_poc[k] = delta_poc ; rps - > used[k] = used ; if ( ( rps - > num_negative_pics > > 1 ) ! = 0 ) { int used ; k = rps - > num_negative_pics - 1 ; // flip the negative values to largest first for ( i = 0 ; i < rps - > num_negative_pics > > 1 ; i + + ) { delta_poc = rps - > delta_poc[i] ; used = rps - > used[i] ; rps - > delta_poc[i] = rps - > delta_poc[k] ; rps - > used[i] = rps - > used[k] ; rps - > delta_poc[k] = delta_poc ; rps - > used[k] = used ; k - - ; } else { unsigned int prev , nb_positive_pics ; rps - > num_negative_pics = get_ue_golomb_long ( gb ) ; nb_positive_pics = get_ue_golomb_long ( gb ) ; if ( rps - > num_negative_pics > = HEVC_MAX_REFS || nb_positive_pics > = HEVC_MAX_REFS ) { av_log ( avctx , AV_LOG_ERROR , Too many refs in a short term RPS . \n ) ; rps - > num_delta_pocs = rps - > num_negative_pics + nb_positive_pics ; if ( rps - > num_delta_pocs ) { prev = 0 ; for ( i = 0 ; i < rps - > num_negative_pics ; i + + ) { delta_poc = get_ue_golomb_long ( gb ) + 1 ; prev - = delta_poc ; rps - > delta_poc[i] = prev ; rps - > used[i] = get_bits1 ( gb ) ; prev = 0 ; for ( i = 0 ; i < nb_positive_pics ; i + + ) { delta_poc = get_ue_golomb_long ( gb ) + 1 ; prev + = delta_poc ; rps - > delta_poc[rps - > num_negative_pics + i] = prev ; rps - > used[rps - > num_negative_pics + i] = get_bits1 ( gb ) ; return 0 ;",1
"static int flac_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , uint8_t * buf , int buf_size ) { FLACContext * s = avctx - > priv_data ; int metadata_last , metadata_type , metadata_size ; int tmp = 0 , i , j = 0 , input_buf_size = 0 ; int16_t * samples = data ; if ( s - > max_framesize == 0 ) { s - > max_framesize= 8192 ; // should hopefully be enough for the first header s - > bitstream= av_fast_realloc ( s - > bitstream , & s - > allocated_bitstream_size , s - > max_framesize ) ; } if ( 1 & & s - > max_framesize ) { //FIXME truncated buf_size= FFMIN ( buf_size , s - > max_framesize - s - > bitstream_size ) ; input_buf_size= buf_size ; if ( s - > bitstream_index + s - > bitstream_size + buf_size > s - > allocated_bitstream_size ) { // printf ( memmove\n ) ; memmove ( s - > bitstream , & s - > bitstream[s - > bitstream_index] , s - > bitstream_size ) ; s - > bitstream_index=0 ; } memcpy ( & s - > bitstream[s - > bitstream_index + s - > bitstream_size] , buf , buf_size ) ; buf= & s - > bitstream[s - > bitstream_index] ; buf_size + = s - > bitstream_size ; s - > bitstream_size= buf_size ; if ( buf_size < s - > max_framesize ) { // printf ( wanna more data . . . \n ) ; return input_buf_size ; } } init_get_bits ( & s - > gb , buf , buf_size * 8 ) ; / * fLaC signature ( be ) * / if ( show_bits_long ( & s - > gb , 32 ) == bswap_32 ( ff_get_fourcc ( fLaC ) ) ) { skip_bits ( & s - > gb , 32 ) ; av_log ( s - > avctx , AV_LOG_DEBUG , STREAM HEADER\n ) ; do { metadata_last = get_bits ( & s - > gb , 1 ) ; metadata_type = get_bits ( & s - > gb , 7 ) ; metadata_size = get_bits_long ( & s - > gb , 24 ) ; av_log ( s - > avctx , AV_LOG_DEBUG , metadata block : flag = %d , type = %d , size = %d\n , metadata_last , metadata_type , metadata_size ) ; if ( metadata_size ) { switch ( metadata_type ) { case METADATA_TYPE_STREAMINFO : { int bits_count= get_bits_count ( & s - > gb ) ; metadata_streaminfo ( s ) ; buf= & s - > bitstream[s - > bitstream_index] ; init_get_bits ( & s - > gb , buf , buf_size * 8 ) ; skip_bits ( & s - > gb , bits_count ) ; dump_headers ( s ) ; break ; } default : for ( i=0 ; i < metadata_size ; i + + ) skip_bits ( & s - > gb , 8 ) ; } } } while ( ! metadata_last ) ; } else { tmp = show_bits ( & s - > gb , 16 ) ; if ( tmp ! = 0xFFF8 ) { av_log ( s - > avctx , AV_LOG_ERROR , FRAME HEADER not here\n ) ; while ( get_bits_count ( & s - > gb ) /8 + 2 < buf_size & & show_bits ( & s - > gb , 16 ) ! = 0xFFF8 ) skip_bits ( & s - > gb , 8 ) ; goto end ; // we may not have enough bits left to decode a frame , so try next time } skip_bits ( & s - > gb , 16 ) ; if ( decode_frame ( s ) < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , decode_frame ( ) failed\n ) ; s - > bitstream_size=0 ; s - > bitstream_index=0 ; return - 1 ; } } if 0 / * fix the channel order here * / if ( s - > order == MID_SIDE ) { short * left = samples ; short * right = samples + s - > blocksize ; for ( i = 0 ; i < s - > blocksize ; i + = 2 ) { uint32_t x = s - > decoded[0][i] ; uint32_t y = s - > decoded[0][i + 1] ; right[i] = x - ( y / 2 ) ; left[i] = right[i] + y ; } * data_size = 2 * s - > blocksize ; } else { for ( i = 0 ; i < s - > channels ; i + + ) { switch ( s - > order ) { case INDEPENDENT : for ( j = 0 ; j < s - > blocksize ; j + + ) samples[ ( s - > blocksize * i ) + j] = s - > decoded[i][j] ; break ; case LEFT_SIDE : case RIGHT_SIDE : if ( i == 0 ) for ( j = 0 ; j < s - > blocksize ; j + + ) samples[ ( s - > blocksize * i ) + j] = s - > decoded[0][j] ; else for ( j = 0 ; j < s - > blocksize ; j + + ) samples[ ( s - > blocksize * i ) + j] = s - > decoded[0][j] - s - > decoded[i][j] ; break ; // case MID_SIDE : // av_log ( s - > avctx , AV_LOG_DEBUG , mid - side unsupported\n ) ; } * data_size + = s - > blocksize ; } } else switch ( s - > decorrelation ) { case INDEPENDENT : for ( j = 0 ; j < s - > blocksize ; j + + ) { for ( i = 0 ; i < s - > channels ; i + + ) * ( samples + + ) = s - > decoded[i][j] ; } break ; case LEFT_SIDE : assert ( s - > channels == 2 ) ; for ( i = 0 ; i < s - > blocksize ; i + + ) { * ( samples + + ) = s - > decoded[0][i] ; * ( samples + + ) = s - > decoded[0][i] - s - > decoded[1][i] ; } break ; case RIGHT_SIDE : assert ( s - > channels == 2 ) ; for ( i = 0 ; i < s - > blocksize ; i + + ) { * ( samples + + ) = s - > decoded[0][i] + s - > decoded[1][i] ; * ( samples + + ) = s - > decoded[1][i] ; } break ; case MID_SIDE : assert ( s - > channels == 2 ) ; for ( i = 0 ; i < s - > blocksize ; i + + ) { int mid , side ; mid = s - > decoded[0][i] ; side = s - > decoded[1][i] ;",1
"static void dump_video_param ( AVCodecContext * avctx , QSVEncContext * q , mfxExtBuffer * * coding_opts ) { mfxInfoMFX * info = & q - > param . mfx ; mfxExtCodingOption * co = ( mfxExtCodingOption * ) coding_opts[0] ; if QSV_HAVE_CO2 mfxExtCodingOption2 * co2 = ( mfxExtCodingOption2 * ) coding_opts[1] ; endif if QSV_HAVE_CO3 mfxExtCodingOption3 * co3 = ( mfxExtCodingOption3 * ) coding_opts[2] ; endif av_log ( avctx , AV_LOG_VERBOSE , profile : %s ; level : % PRIu16 \n , print_profile ( info - > CodecProfile ) , info - > CodecLevel ) ; av_log ( avctx , AV_LOG_VERBOSE , GopPicSize : % PRIu16 ; GopRefDist : % PRIu16 ; GopOptFlag : , info - > GopPicSize , info - > GopRefDist ) ; if ( info - > GopOptFlag & MFX_GOP_CLOSED ) av_log ( avctx , AV_LOG_VERBOSE , closed ) ; if ( info - > GopOptFlag & MFX_GOP_STRICT ) av_log ( avctx , AV_LOG_VERBOSE , strict ) ; av_log ( avctx , AV_LOG_VERBOSE , ; IdrInterval : % PRIu16 \n , info - > IdrInterval ) ; av_log ( avctx , AV_LOG_VERBOSE , TargetUsage : % PRIu16 ; RateControlMethod : %s\n , info - > TargetUsage , print_ratecontrol ( info - > RateControlMethod ) ) ; if ( info - > RateControlMethod == MFX_RATECONTROL_CBR || info - > RateControlMethod == MFX_RATECONTROL_VBR if QSV_HAVE_VCM || info - > RateControlMethod == MFX_RATECONTROL_VCM endif ) { av_log ( avctx , AV_LOG_VERBOSE , InitialDelayInKB : % PRIu16 ; TargetKbps : % PRIu16 ; MaxKbps : % PRIu16 \n , info - > InitialDelayInKB , info - > TargetKbps , info - > MaxKbps ) ; } else if ( info - > RateControlMethod == MFX_RATECONTROL_CQP ) { av_log ( avctx , AV_LOG_VERBOSE , QPI : % PRIu16 ; QPP : % PRIu16 ; QPB : % PRIu16 \n , info - > QPI , info - > QPP , info - > QPB ) ; } else if ( info - > RateControlMethod == MFX_RATECONTROL_AVBR ) { av_log ( avctx , AV_LOG_VERBOSE , TargetKbps : % PRIu16 ; Accuracy : % PRIu16 ; Convergence : % PRIu16 \n , info - > TargetKbps , info - > Accuracy , info - > Convergence ) ; } if QSV_HAVE_LA else if ( info - > RateControlMethod == MFX_RATECONTROL_LA if QSV_HAVE_LA_HRD || info - > RateControlMethod == MFX_RATECONTROL_LA_HRD endif ) { av_log ( avctx , AV_LOG_VERBOSE , TargetKbps : % PRIu16 ; LookAheadDepth : % PRIu16 \n , info - > TargetKbps , co2 - > LookAheadDepth ) ; } endif if QSV_HAVE_ICQ else if ( info - > RateControlMethod == MFX_RATECONTROL_ICQ ) { av_log ( avctx , AV_LOG_VERBOSE , ICQQuality : % PRIu16 \n , info - > ICQQuality ) ; } else if ( info - > RateControlMethod == MFX_RATECONTROL_LA_ICQ ) { av_log ( avctx , AV_LOG_VERBOSE , ICQQuality : % PRIu16 ; LookAheadDepth : % PRIu16 \n , info - > ICQQuality , co2 - > LookAheadDepth ) ; } endif if QSV_HAVE_QVBR else if ( info - > RateControlMethod == MFX_RATECONTROL_QVBR ) { av_log ( avctx , AV_LOG_VERBOSE , QVBRQuality : % PRIu16 \n , co3 - > QVBRQuality ) ; } endif av_log ( avctx , AV_LOG_VERBOSE , NumSlice : % PRIu16 ; NumRefFrame : % PRIu16 \n , info - > NumSlice , info - > NumRefFrame ) ; av_log ( avctx , AV_LOG_VERBOSE , RateDistortionOpt : %s\n , print_threestate ( co - > RateDistortionOpt ) ) ; if QSV_HAVE_CO2 av_log ( avctx , AV_LOG_VERBOSE , RecoveryPointSEI : %s IntRefType : % PRIu16 ; IntRefCycleSize : % PRIu16 ; IntRefQPDelta : % PRId16 \n , print_threestate ( co - > RecoveryPointSEI ) , co2 - > IntRefType , co2 - > IntRefCycleSize , co2 - > IntRefQPDelta ) ; av_log ( avctx , AV_LOG_VERBOSE , MaxFrameSize : % PRIu16 ; , co2 - > MaxFrameSize ) ; if QSV_VERSION_ATLEAST ( 1 , 9 ) av_log ( avctx , AV_LOG_VERBOSE , MaxSliceSize : % PRIu16 ; , co2 - > MaxSliceSize ) ; endif av_log ( avctx , AV_LOG_VERBOSE , \n ) ; av_log ( avctx , AV_LOG_VERBOSE , BitrateLimit : %s ; MBBRC : %s ; ExtBRC : %s\n , print_threestate ( co2 - > BitrateLimit ) , print_threestate ( co2 - > MBBRC ) , print_threestate ( co2 - > ExtBRC ) ) ; if QSV_HAVE_TRELLIS av_log ( avctx , AV_LOG_VERBOSE , Trellis : ) ; if ( co2 - > Trellis & MFX_TRELLIS_OFF ) { av_log ( avctx , AV_LOG_VERBOSE , off ) ; } else if ( ! co2 - > Trellis ) { av_log ( avctx , AV_LOG_VERBOSE , auto ) ; } else { if ( co2 - > Trellis & MFX_TRELLIS_I ) av_log ( avctx , AV_LOG_VERBOSE , I ) ; if ( co2 - > Trellis & MFX_TRELLIS_P ) av_log ( avctx , AV_LOG_VERBOSE , P ) ; if ( co2 - > Trellis & MFX_TRELLIS_B ) av_log ( avctx , AV_LOG_VERBOSE , B ) ; } av_log ( avctx , AV_LOG_VERBOSE , \n ) ; endif if QSV_VERSION_ATLEAST ( 1 , 8 ) av_log ( avctx , AV_LOG_VERBOSE , RepeatPPS : %s ; NumMbPerSlice : % PRIu16 ; LookAheadDS : , print_threestate ( co2 - > RepeatPPS ) , co2 - > NumMbPerSlice ) ; switch ( co2 - > LookAheadDS ) { case MFX_LOOKAHEAD_DS_OFF : av_log ( avctx , AV_LOG_VERBOSE , off ) ; break ; case MFX_LOOKAHEAD_DS_2x : av_log ( avctx , AV_LOG_VERBOSE , 2x ) ; break ; case MFX_LOOKAHEAD_DS_4x : av_log ( avctx , AV_LOG_VERBOSE , 4x ) ; break ; default : av_log ( avctx , AV_LOG_VERBOSE , unknown ) ; break ; } av_log ( avctx , AV_LOG_VERBOSE , \n ) ; av_log ( avctx , AV_LOG_VERBOSE , AdaptiveI : %s ; AdaptiveB : %s ; BRefType : , print_threestate ( co2 - > AdaptiveI ) , print_threestate ( co2 - > AdaptiveB ) ) ; switch ( co2 - > BRefType ) { case MFX_B_REF_OFF : av_log ( avctx , AV_LOG_VERBOSE , off ) ; break ; case MFX_B_REF_PYRAMID : av_log ( avctx , AV_LOG_VERBOSE , pyramid ) ; break ; default : av_log ( avctx , AV_LOG_VERBOSE , auto ) ; break ; } av_log ( avctx , AV_LOG_VERBOSE , \n ) ; endif if QSV_VERSION_ATLEAST ( 1 , 9 ) av_log ( avctx , AV_LOG_VERBOSE , MinQPI : % PRIu8 ; MaxQPI : % PRIu8 ; MinQPP : % PRIu8 ; MaxQPP : % PRIu8 ; MinQPB : % PRIu8 ; MaxQPB : % PRIu8 \n , co2 - > MinQPI , co2 - > MaxQPI , co2 - > MinQPP , co2 - > MaxQPP , co2 - > MinQPB , co2 - > MaxQPB ) ; endif endif if ( avctx - > codec_id == AV_CODEC_ID_H264 ) { av_log ( avctx , AV_LOG_VERBOSE , Entropy coding : %s ; MaxDecFrameBuffering : % PRIu16 \n , co - > CAVLC == MFX_CODINGOPTION_ON ? CAVLC : CABAC , co - > MaxDecFrameBuffering ) ; av_log ( avctx , AV_LOG_VERBOSE , NalHrdConformance : %s ; SingleSeiNalUnit : %s ; VuiVclHrdParameters : %s VuiNalHrdParameters : %s\n , print_threestate ( co -",0
"static void * alloc_buffer ( FFVAContext * vactx , int type , unsigned int size , uint32_t * buf_id ) { void * data = NULL ; * buf_id = 0 ; if ( vaCreateBuffer ( vactx - > display , vactx - > context_id , type , size , 1 , NULL , buf_id ) == VA_STATUS_SUCCESS ) vaMapBuffer ( vactx - > display , * buf_id , & data ) ; return data ; }",0
"static int decode_slice ( struct AVCodecContext * avctx , void * arg ) { H264Context * h = * ( void * * ) arg ; MpegEncContext * const s = & h - > s ; const int part_mask= s - > partitioned_frame ? ( AC_END|AC_ERROR ) : 0x7F ; int lf_x_start = s - > mb_x ; s - > mb_skip_run= - 1 ; h - > is_complex = FRAME_MBAFF || s - > picture_structure ! = PICT_FRAME || s - > codec_id ! = CODEC_ID_H264 || ( CONFIG_GRAY & & ( s - > flags & CODEC_FLAG_GRAY ) ) ; if ( h - > pps . cabac ) { / * realign * / align_get_bits ( & s - > gb ) ; / * init cabac * / ff_init_cabac_states ( & h - > cabac ) ; ff_init_cabac_decoder ( & h - > cabac , s - > gb . buffer + get_bits_count ( & s - > gb ) /8 , ( get_bits_left ( & s - > gb ) + 7 ) /8 ) ; ff_h264_init_cabac_states ( h ) ; for ( ; ; ) { //START_TIMER int ret = ff_h264_decode_mb_cabac ( h ) ; int eos ; //STOP_TIMER ( decode_mb_cabac ) if ( ret > =0 ) ff_h264_hl_decode_mb ( h ) ; if ( ret > = 0 & & FRAME_MBAFF ) { //FIXME optimal ? or let mb_decode decode 16x32 ? s - > mb_y + + ; ret = ff_h264_decode_mb_cabac ( h ) ; if ( ret > =0 ) ff_h264_hl_decode_mb ( h ) ; s - > mb_y - - ; } eos = get_cabac_terminate ( & h - > cabac ) ; if ( ( s - > workaround_bugs & FF_BUG_TRUNCATED ) & & h - > cabac . bytestream > h - > cabac . bytestream_end + 2 ) { ff_er_add_slice ( s , s - > resync_mb_x , s - > resync_mb_y , s - > mb_x - 1 , s - > mb_y , ( AC_END|DC_END|MV_END ) & part_mask ) ; if ( s - > mb_x > = lf_x_start ) loop_filter ( h , lf_x_start , s - > mb_x + 1 ) ; return 0 ; } if ( ret < 0 || h - > cabac . bytestream > h - > cabac . bytestream_end + 2 ) { av_log ( h - > s . avctx , AV_LOG_ERROR , error while decoding MB %d %d , bytestream ( %td ) \n , s - > mb_x , s - > mb_y , h - > cabac . bytestream_end - h - > cabac . bytestream ) ; ff_er_add_slice ( s , s - > resync_mb_x , s - > resync_mb_y , s - > mb_x , s - > mb_y , ( AC_ERROR|DC_ERROR|MV_ERROR ) & part_mask ) ; return - 1 ; } if ( + + s - > mb_x > = s - > mb_width ) { loop_filter ( h , lf_x_start , s - > mb_x ) ; s - > mb_x = lf_x_start = 0 ; decode_finish_row ( h ) ; + + s - > mb_y ; if ( FIELD_OR_MBAFF_PICTURE ) { + + s - > mb_y ; if ( FRAME_MBAFF & & s - > mb_y < s - > mb_height ) predict_field_decoding_flag ( h ) ; } } if ( eos || s - > mb_y > = s - > mb_height ) { tprintf ( s - > avctx , slice end %d %d\n , get_bits_count ( & s - > gb ) , s - > gb . size_in_bits ) ; ff_er_add_slice ( s , s - > resync_mb_x , s - > resync_mb_y , s - > mb_x - 1 , s - > mb_y , ( AC_END|DC_END|MV_END ) & part_mask ) ; if ( s - > mb_x > lf_x_start ) loop_filter ( h , lf_x_start , s - > mb_x ) ; return 0 ; } } } else { for ( ; ; ) { int ret = ff_h264_decode_mb_cavlc ( h ) ; if ( ret > =0 ) ff_h264_hl_decode_mb ( h ) ; if ( ret > =0 & & FRAME_MBAFF ) { //FIXME optimal ? or let mb_decode decode 16x32 ? s - > mb_y + + ; ret = ff_h264_decode_mb_cavlc ( h ) ; if ( ret > =0 ) ff_h264_hl_decode_mb ( h ) ; s - > mb_y - - ; } if ( ret < 0 ) { av_log ( h - > s . avctx , AV_LOG_ERROR , error while decoding MB %d %d\n , s - > mb_x , s - > mb_y ) ; ff_er_add_slice ( s , s - > resync_mb_x , s - > resync_mb_y , s - > mb_x , s - > mb_y , ( AC_ERROR|DC_ERROR|MV_ERROR ) & part_mask ) ; return - 1 ; } if ( + + s - > mb_x > = s - > mb_width ) { loop_filter ( h , lf_x_start , s - > mb_x ) ; s - > mb_x = lf_x_start = 0 ; decode_finish_row ( h ) ; + + s - > mb_y ; if ( FIELD_OR_MBAFF_PICTURE ) { + + s - > mb_y ; if ( FRAME_MBAFF & & s - > mb_y < s - > mb_height ) predict_field_decoding_flag ( h ) ; } if ( s - > mb_y > = s - > mb_height ) { tprintf ( s - > avctx , slice end %d %d\n , get_bits_count ( & s - > gb ) , s - > gb . size_in_bits ) ; if ( get_bits_count ( & s - > gb ) == s - > gb . size_in_bits ) { ff_er_add_slice ( s , s - > resync_mb_x , s - > resync_mb_y , s - > mb_x - 1 , s - > mb_y , ( AC_END|DC_END|MV_END ) & part_mask ) ; return 0 ; } else { ff_er_add_slice ( s , s - > resync_mb_x , s - > resync_mb_y , s - > mb_x , s - > mb_y , ( AC_END|DC_END|MV_END ) & part_mask ) ; return - 1 ; } } } if ( get_bits_count ( & s - > gb ) > = s - > gb . size_in_bits & & s - > mb_skip_run < =0 ) { tprintf ( s - > avctx , slice end %d %d\n , get_bits_count ( & s - > gb ) , s - > gb . size_in_bits ) ; if ( get_bits_count ( & s - > gb ) == s - > gb . size_in_bits ) { ff_er_add_slice ( s , s - > resync_mb_x , s - > resync_mb_y , s - > mb_x - 1 , s - > mb_y , ( AC_END|DC_END|MV_END ) & part_mask ) ; if ( s - > mb_x > lf_x_start ) loop_filter ( h , lf_x_start , s - > mb_x ) ; return 0 ; } else { ff_er_add_slice ( s , s - > resync_mb_x , s - > resync_mb_y , s - > mb_x , s - >",0
"void ff_http_auth_handle_header ( HTTPAuthState * state , const char * key , const char * value ) { if ( ! strcmp ( key , WWW - Authenticate ) || ! strcmp ( key , Proxy - Authenticate ) ) { const char * p ; if ( av_stristart ( value , Basic , & p ) & & state - > auth_type < = HTTP_AUTH_BASIC ) { state - > auth_type = HTTP_AUTH_BASIC ; state - > realm[0] = 0 ; state - > stale = 0 ; ff_parse_key_value ( p , ( ff_parse_key_val_cb ) handle_basic_params , state ) ; } else if ( av_stristart ( value , Digest , & p ) & & state - > auth_type < = HTTP_AUTH_DIGEST ) { state - > auth_type = HTTP_AUTH_DIGEST ; memset ( & state - > digest_params , 0 , sizeof ( DigestParams ) ) ; state - > realm[0] = 0 ; state - > stale = 0 ; ff_parse_key_value ( p , ( ff_parse_key_val_cb ) handle_digest_params , state ) ; choose_qop ( state - > digest_params . qop , sizeof ( state - > digest_params . qop ) ) ; if ( ! av_strcasecmp ( state - > digest_params . stale , true ) ) state - > stale = 1 ; } } else if ( ! strcmp ( key , Authentication - Info ) ) { ff_parse_key_value ( value , ( ff_parse_key_val_cb ) handle_digest_update , state ) ; } }",0
"void ff_thread_report_progress ( ThreadFrame * f , int n , int field ) { PerThreadContext * p ; atomic_int * progress = f - > progress ? ( atomic_int * ) f - > progress - > data : NULL ; if ( ! progress || atomic_load_explicit ( & progress[field] , memory_order_acquire ) > = n ) return ; p = f - > owner - > internal - > thread_ctx ; if ( f - > owner - > debug & FF_DEBUG_THREADS ) av_log ( f - > owner , AV_LOG_DEBUG , %p finished %d field %d\n , progress , n , field ) ; pthread_mutex_lock ( & p - > progress_mutex ) ; atomic_store ( & progress[field] , n ) ; pthread_cond_broadcast ( & p - > progress_cond ) ; pthread_mutex_unlock ( & p - > progress_mutex ) ; }",0
"static void mxf_write_system_item ( AVFormatContext * s ) { MXFContext * mxf = s - > priv_data ; AVIOContext * pb = s - > pb ; unsigned frame ; uint32_t time_code ; frame = mxf - > last_indexed_edit_unit + mxf - > edit_units_count ; // write system metadata pack avio_write ( pb , system_metadata_pack_key , 16 ) ; klv_encode_ber4_length ( pb , 57 ) ; avio_w8 ( pb , 0x5c ) ; // UL , user date/time stamp , picture and sound item present avio_w8 ( pb , 0x04 ) ; // content package rate avio_w8 ( pb , 0x00 ) ; // content package type avio_wb16 ( pb , 0x00 ) ; // channel handle avio_wb16 ( pb , mxf - > tc . start + frame ) ; // continuity count if ( mxf - > essence_container_count > 1 ) avio_write ( pb , multiple_desc_ul , 16 ) ; else { MXFStreamContext * sc = s - > streams[0] - > priv_data ; avio_write ( pb , mxf_essence_container_uls[sc - > index] . container_ul , 16 ) ; } avio_w8 ( pb , 0 ) ; avio_wb64 ( pb , 0 ) ; avio_wb64 ( pb , 0 ) ; // creation date/time stamp avio_w8 ( pb , 0x81 ) ; // SMPTE 12M time code time_code = av_timecode_get_smpte_from_framenum ( & mxf - > tc , frame ) ; avio_wb32 ( pb , time_code ) ; avio_wb32 ( pb , 0 ) ; // binary group data avio_wb64 ( pb , 0 ) ; // write system metadata package set avio_write ( pb , system_metadata_package_set_key , 16 ) ; klv_encode_ber4_length ( pb , 35 ) ; avio_w8 ( pb , 0x83 ) ; // UMID avio_wb16 ( pb , 0x20 ) ; mxf_write_umid ( s , 1 ) ; }",1
static av_cold int aac_encode_end ( AVCodecContext * avctx ) { AACEncContext * s = avctx - > priv_data ; ff_mdct_end ( & s - > mdct1024 ) ; ff_mdct_end ( & s - > mdct128 ) ; ff_psy_end ( & s - > psy ) ; ff_psy_preprocess_end ( s - > psypp ) ; av_freep ( & s - > samples ) ; av_freep ( & s - > cpe ) ; return 0 ; },1
"void updateMMXDitherTables ( SwsContext * c , int dstY , int lumBufIndex , int chrBufIndex , int lastInLumBuf , int lastInChrBuf ) { const int dstH= c - > dstH ; const int flags= c - > flags ; int16_t * * lumPixBuf= c - > lumPixBuf ; int16_t * * chrUPixBuf= c - > chrUPixBuf ; int16_t * * alpPixBuf= c - > alpPixBuf ; const int vLumBufSize= c - > vLumBufSize ; const int vChrBufSize= c - > vChrBufSize ; int16_t * vLumFilterPos= c - > vLumFilterPos ; int16_t * vChrFilterPos= c - > vChrFilterPos ; int16_t * vLumFilter= c - > vLumFilter ; int16_t * vChrFilter= c - > vChrFilter ; int32_t * lumMmxFilter= c - > lumMmxFilter ; int32_t * chrMmxFilter= c - > chrMmxFilter ; int32_t av_unused * alpMmxFilter= c - > alpMmxFilter ; const int vLumFilterSize= c - > vLumFilterSize ; const int vChrFilterSize= c - > vChrFilterSize ; const int chrDstY= dstY > > c - > chrDstVSubSample ; const int firstLumSrcY= vLumFilterPos[dstY] ; //First line needed as input const int firstChrSrcY= vChrFilterPos[chrDstY] ; //First line needed as input c - > blueDither= ff_dither8[dstY & 1] ; if ( c - > dstFormat == PIX_FMT_RGB555 || c - > dstFormat == PIX_FMT_BGR555 ) c - > greenDither= ff_dither8[dstY & 1] ; else c - > greenDither= ff_dither4[dstY & 1] ; c - > redDither= ff_dither8[ ( dstY + 1 ) & 1] ; if ( dstY < dstH - 2 ) { const int16_t * * lumSrcPtr= ( const int16_t * * ) lumPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize ; const int16_t * * chrUSrcPtr= ( const int16_t * * ) chrUPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize ; const int16_t * * alpSrcPtr= ( CONFIG_SWSCALE_ALPHA & & alpPixBuf ) ? ( const int16_t * * ) alpPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize : NULL ; int i ; if ( flags & SWS_ACCURATE_RND ) { int s= APCK_SIZE / 8 ; for ( i=0 ; i < vLumFilterSize ; i + =2 ) { * ( const void * * ) & lumMmxFilter[s * i ]= lumSrcPtr[i ] ; * ( const void * * ) & lumMmxFilter[s * i + APCK_PTR2/4 ]= lumSrcPtr[i + ( vLumFilterSize > 1 ) ] ; lumMmxFilter[s * i + APCK_COEF/4 ]= lumMmxFilter[s * i + APCK_COEF/4 + 1]= vLumFilter[dstY * vLumFilterSize + i ] + ( vLumFilterSize > 1 ? vLumFilter[dstY * vLumFilterSize + i + 1] < < 16 : 0 ) ; if ( CONFIG_SWSCALE_ALPHA & & alpPixBuf ) { * ( const void * * ) & alpMmxFilter[s * i ]= alpSrcPtr[i ] ; * ( const void * * ) & alpMmxFilter[s * i + APCK_PTR2/4 ]= alpSrcPtr[i + ( vLumFilterSize > 1 ) ] ; alpMmxFilter[s * i + APCK_COEF/4 ]= alpMmxFilter[s * i + APCK_COEF/4 + 1]= lumMmxFilter[s * i + APCK_COEF/4 ] ; for ( i=0 ; i < vChrFilterSize ; i + =2 ) { * ( const void * * ) & chrMmxFilter[s * i ]= chrUSrcPtr[i ] ; * ( const void * * ) & chrMmxFilter[s * i + APCK_PTR2/4 ]= chrUSrcPtr[i + ( vChrFilterSize > 1 ) ] ; chrMmxFilter[s * i + APCK_COEF/4 ]= chrMmxFilter[s * i + APCK_COEF/4 + 1]= vChrFilter[chrDstY * vChrFilterSize + i ] + ( vChrFilterSize > 1 ? vChrFilter[chrDstY * vChrFilterSize + i + 1] < < 16 : 0 ) ; } else { for ( i=0 ; i < vLumFilterSize ; i + + ) { * ( const void * * ) & lumMmxFilter[4 * i + 0]= lumSrcPtr[i] ; lumMmxFilter[4 * i + 2]= lumMmxFilter[4 * i + 3]= ( ( uint16_t ) vLumFilter[dstY * vLumFilterSize + i] ) * 0x10001 ; if ( CONFIG_SWSCALE_ALPHA & & alpPixBuf ) { * ( const void * * ) & alpMmxFilter[4 * i + 0]= alpSrcPtr[i] ; alpMmxFilter[4 * i + 2]= alpMmxFilter[4 * i + 3]= lumMmxFilter[4 * i + 2] ; for ( i=0 ; i < vChrFilterSize ; i + + ) { * ( const void * * ) & chrMmxFilter[4 * i + 0]= chrUSrcPtr[i] ; chrMmxFilter[4 * i + 2]= chrMmxFilter[4 * i + 3]= ( ( uint16_t ) vChrFilter[chrDstY * vChrFilterSize + i] ) * 0x10001 ;",1
"static int rice_count_exact ( int32_t * res , int n , int k ) { int i ; int count = 0 ; for ( i = 0 ; i < n ; i + + ) { int32_t v = - 2 * res[i] - 1 ; v = v > > 31 ; count + = ( v > > k ) + 1 + k ; } return count ; }",1
"int ff_h264_fill_default_ref_list ( H264Context * h , H264SliceContext * sl ) { int i , len ; if ( sl - > slice_type_nos == AV_PICTURE_TYPE_B ) { H264Picture * sorted[32] ; int cur_poc , list ; int lens[2] ; if ( FIELD_PICTURE ( h ) ) cur_poc = h - > cur_pic_ptr - > field_poc[h - > picture_structure == PICT_BOTTOM_FIELD] ; else cur_poc = h - > cur_pic_ptr - > poc ; for ( list = 0 ; list < 2 ; list + + ) { len = add_sorted ( sorted , h - > short_ref , h - > short_ref_count , cur_poc , 1 list ) ; len + = add_sorted ( sorted + len , h - > short_ref , h - > short_ref_count , cur_poc , 0 list ) ; av_assert0 ( len < = 32 ) ; len = build_def_list ( h - > default_ref_list[list] , FF_ARRAY_ELEMS ( h - > default_ref_list[0] ) , sorted , len , 0 , h - > picture_structure ) ; len + = build_def_list ( h - > default_ref_list[list] + len , FF_ARRAY_ELEMS ( h - > default_ref_list[0] ) - len , h - > long_ref , 16 , 1 , h - > picture_structure ) ; av_assert0 ( len < = 32 ) ; if ( len < sl - > ref_count[list] ) memset ( & h - > default_ref_list[list][len] , 0 , sizeof ( H264Ref ) * ( sl - > ref_count[list] - len ) ) ; lens[list] = len ; } if ( lens[0] == lens[1] & & lens[1] > 1 ) { for ( i = 0 ; i < lens[0] & & h - > default_ref_list[0][i] . parent - > f . buf[0] - > buffer == h - > default_ref_list[1][i] . parent - > f . buf[0] - > buffer ; i + + ) ; if ( i == lens[0] ) { FFSWAP ( H264Ref , h - > default_ref_list[1][0] , h - > default_ref_list[1][1] ) ; } } } else { len = build_def_list ( h - > default_ref_list[0] , FF_ARRAY_ELEMS ( h - > default_ref_list[0] ) , h - > short_ref , h - > short_ref_count , 0 , h - > picture_structure ) ; len + = build_def_list ( h - > default_ref_list[0] + len , FF_ARRAY_ELEMS ( h - > default_ref_list[0] ) - len , h - > long_ref , 16 , 1 , h - > picture_structure ) ; av_assert0 ( len < = 32 ) ; if ( len < sl - > ref_count[0] ) memset ( & h - > default_ref_list[0][len] , 0 , sizeof ( H264Ref ) * ( sl - > ref_count[0] - len ) ) ; } ifdef TRACE for ( i = 0 ; i < sl - > ref_count[0] ; i + + ) { tprintf ( h - > avctx , List0 : %s fn : %d 0x%p\n , ( h - > default_ref_list[0][i] . parent - > long_ref ? LT : ST ) , h - > default_ref_list[0][i] . pic_id , h - > default_ref_list[0][i] . parent - > f . data[0] ) ; } if ( sl - > slice_type_nos == AV_PICTURE_TYPE_B ) { for ( i = 0 ; i < sl - > ref_count[1] ; i + + ) { tprintf ( h - > avctx , List1 : %s fn : %d 0x%p\n , ( h - > default_ref_list[1][i] . parent - > long_ref ? LT : ST ) , h - > default_ref_list[1][i] . pic_id , h - > default_ref_list[1][i] . parent - > f . data[0] ) ; } } endif return 0 ; }",1
"static inline int mix_core ( uint32_t multbl[][256] , int a , int b , int c , int d ) { if CONFIG_SMALL define ROT ( x , s ) ( ( x < < s ) | ( x > > ( 32 - s ) ) ) return multbl[0][a] ROT ( multbl[0][b] , 8 ) ROT ( multbl[0][c] , 16 ) ROT ( multbl[0][d] , 24 ) ; else return multbl[0][a] multbl[1][b] multbl[2][c] multbl[3][d] ; endif }",1
void ff_generate_sliding_window_mmcos ( H264Context * h ) { MpegEncContext * const s = & h - > s ; assert ( h - > long_ref_count + h - > short_ref_count < = h - > sps . ref_frame_count ) ; h - > mmco_index= 0 ; if ( h - > short_ref_count & & h - > long_ref_count + h - > short_ref_count == h - > sps . ref_frame_count & & ! ( FIELD_PICTURE & & ! s - > first_field & & s - > current_picture_ptr - > f . reference ) ) { h - > mmco[0] . opcode= MMCO_SHORT2UNUSED ; h - > mmco[0] . short_pic_num= h - > short_ref[ h - > short_ref_count - 1 ] - > frame_num ; h - > mmco_index= 1 ; if ( FIELD_PICTURE ) { h - > mmco[0] . short_pic_num * = 2 ; h - > mmco[1] . opcode= MMCO_SHORT2UNUSED ; h - > mmco[1] . short_pic_num= h - > mmco[0] . short_pic_num + 1 ; h - > mmco_index= 2 ; } } },1
static int mpc8_probe ( AVProbeData * p ) { const uint8_t * bs = p - > buf + 4 ; const uint8_t * bs_end = bs + p - > buf_size ; int64_t size ; if ( p - > buf_size < 16 ) return 0 ; if ( AV_RL32 ( p - > buf ) ! = TAG_MPCK ) return 0 ; while ( bs < bs_end + 3 ) { int header_found = ( bs[0] == ' S ' & & bs[1] == ' H ' ) ; if ( bs[0] < ' A ' || bs[0] > ' Z ' || bs[1] < ' A ' || bs[1] > ' Z ' ) return 0 ; bs + = 2 ; size = bs_get_v ( & bs ) ; if ( size < 2 ) return 0 ; if ( bs + size - 2 > = bs_end ) return AVPROBE_SCORE_EXTENSION - 1 ; // seems to be valid MPC but no header yet if ( header_found ) { if ( size < 11 || size > 28 ) return 0 ; if ( ! AV_RL32 ( bs ) ) //zero CRC is invalid return 0 ; return AVPROBE_SCORE_MAX ; } else { bs + = size - 2 ; } } return 0 ; },1
"static int decode_block ( MJpegDecodeContext * s , DCTELEM * block , int component , int dc_index , int ac_index , int16_t * quant_matrix ) { int code , i , j , level , val ; VLC * ac_vlc ; / * DC coef * / val = mjpeg_decode_dc ( s , dc_index ) ; if ( val == 0xffff ) { dprintf ( error dc\n ) ; return - 1 ; } val = val * quant_matrix[0] + s - > last_dc[component] ; s - > last_dc[component] = val ; block[0] = val ; / * AC coefs * / ac_vlc = & s - > vlcs[1][ac_index] ; i = 0 ; { OPEN_READER ( re , & s - > gb ) for ( ; ; ) { UPDATE_CACHE ( re , & s - > gb ) ; GET_VLC ( code , re , & s - > gb , s - > vlcs[1][ac_index] . table , 9 , 2 ) / * EOB * / if ( code == 0x10 ) break ; if ( code == 0x100 ) { i + = 16 ; } else { i + = ( ( unsigned ) code ) > > 4 ; code & = 0xf ; if ( code > MIN_CACHE_BITS - 16 ) { UPDATE_CACHE ( re , & s - > gb ) } { int cache=GET_CACHE ( re , gb ) ; int sign= ( cache ) > > 31 ; level = ( NEG_USR32 ( sign cache , code ) sign ) - sign ; } LAST_SKIP_BITS ( re , & s - > gb , code ) if ( i > = 63 ) { if ( i == 63 ) { j = s - > scantable . permutated[63] ; block[j] = level * quant_matrix[j] ; break ; } dprintf ( error count : %d\n , i ) ; return - 1 ; } j = s - > scantable . permutated[i] ; block[j] = level * quant_matrix[j] ; } } CLOSE_READER ( re , & s - > gb ) } return 0 ; }",0
"static void mp3_parse_vbr_tags ( AVFormatContext * s , AVStream * st , int64_t base ) { uint32_t v , spf ; int frames = - 1 ; / * Total number of frames in file * / const int64_t xing_offtbl[2][2] = { { 32 , 17 } , { 17 , 9 } } ; MPADecodeContext c ; v = get_be32 ( s - > pb ) ; if ( ff_mpa_check_header ( v ) < 0 ) return ; ff_mpegaudio_decode_header ( & c , v ) ; if ( c . layer ! = 3 ) return ; / * Check for Xing / Info tag * / url_fseek ( s - > pb , xing_offtbl[c . lsf == 1][c . nb_channels == 1] , SEEK_CUR ) ; v = get_be32 ( s - > pb ) ; if ( v == MKBETAG ( ' X ' , ' i ' , ' n ' , ' g ' ) || v == MKBETAG ( ' I ' , ' n ' , ' f ' , ' o ' ) ) { v = get_be32 ( s - > pb ) ; if ( v & 0x1 ) frames = get_be32 ( s - > pb ) ; } / * Check for VBRI tag ( always 32 bytes after end of mpegaudio header ) * / url_fseek ( s - > pb , base + 4 + 32 , SEEK_SET ) ; v = get_be32 ( s - > pb ) ; if ( v == MKBETAG ( ' V ' , ' B ' , ' R ' , ' I ' ) ) { / * Check tag version * / if ( get_be16 ( s - > pb ) == 1 ) { / * skip delay , quality and total bytes * / url_fseek ( s - > pb , 8 , SEEK_CUR ) ; frames = get_be32 ( s - > pb ) ; } } if ( frames < 0 ) return ; spf = c . lsf ? 576 : 1152 ; / * Samples per frame , layer 3 * / st - > duration = av_rescale_q ( frames , ( AVRational ) { spf , c . sample_rate } , st - > time_base ) ; }",0
"static int gif_read_image ( GifState * s , AVFrame * frame ) { int left , top , width , height , bits_per_pixel , code_size , flags ; int is_interleaved , has_local_palette , y , pass , y1 , linesize , n , i ; uint8_t * ptr , * spal , * palette , * ptr1 ; left = bytestream_get_le16 ( & s - > bytestream ) ; top = bytestream_get_le16 ( & s - > bytestream ) ; width = bytestream_get_le16 ( & s - > bytestream ) ; height = bytestream_get_le16 ( & s - > bytestream ) ; flags = bytestream_get_byte ( & s - > bytestream ) ; is_interleaved = flags & 0x40 ; has_local_palette = flags & 0x80 ; bits_per_pixel = ( flags & 0x07 ) + 1 ; av_dlog ( s - > avctx , gif : image x=%d y=%d w=%d h=%d\n , left , top , width , height ) ; if ( has_local_palette ) { bytestream_get_buffer ( & s - > bytestream , s - > local_palette , 3 * ( 1 < < bits_per_pixel ) ) ; palette = s - > local_palette ; } else { palette = s - > global_palette ; bits_per_pixel = s - > bits_per_pixel ; } / * verify that all the image is inside the screen dimensions * / if ( left + width > s - > screen_width || top + height > s - > screen_height ) return AVERROR ( EINVAL ) ; / * build the palette * / n = ( 1 < < bits_per_pixel ) ; spal = palette ; for ( i = 0 ; i < n ; i + + ) { s - > image_palette[i] = ( 0xffu < < 24 ) | AV_RB24 ( spal ) ; spal + = 3 ; } for ( ; i < 256 ; i + + ) s - > image_palette[i] = ( 0xffu < < 24 ) ; / * handle transparency * / if ( s - > transparent_color_index > = 0 ) s - > image_palette[s - > transparent_color_index] = 0 ; / * now get the image data * / code_size = bytestream_get_byte ( & s - > bytestream ) ; ff_lzw_decode_init ( s - > lzw , code_size , s - > bytestream , s - > bytestream_end - s - > bytestream , FF_LZW_GIF ) ; / * read all the image * / linesize = frame - > linesize[0] ; ptr1 = frame - > data[0] + top * linesize + left ; ptr = ptr1 ; pass = 0 ; y1 = 0 ; for ( y = 0 ; y < height ; y + + ) { ff_lzw_decode ( s - > lzw , ptr , width ) ; if ( is_interleaved ) { switch ( pass ) { default : case 0 : case 1 : y1 + = 8 ; ptr + = linesize * 8 ; if ( y1 > = height ) { y1 = pass ? 2 : 4 ; ptr = ptr1 + linesize * y1 ; pass + + ; } break ; case 2 : y1 + = 4 ; ptr + = linesize * 4 ; if ( y1 > = height ) { y1 = 1 ; ptr = ptr1 + linesize ; pass + + ; } break ; case 3 : y1 + = 2 ; ptr + = linesize * 2 ; break ; } } else { ptr + = linesize ; } } / * read the garbage data until end marker is found * / ff_lzw_decode_tail ( s - > lzw ) ; s - > bytestream = ff_lzw_cur_ptr ( s - > lzw ) ; return 0 ; }",0
"const uint8_t * ff_h263_find_resync_marker ( const uint8_t * av_restrict p , const uint8_t * av_restrict end ) { av_assert2 ( p < end ) ; end - =2 ; p + + ; for ( ; p < end ; p + =2 ) { if ( ! * p ) { if ( ! p[ - 1] & & p[1] ) return p - 1 ; else if ( ! p[ 1] & & p[2] ) return p ; } } return end + 2 ; }",0
"static int parse_fade ( struct sbg_parser * p , struct sbg_fade * fr ) { struct sbg_fade f ; if ( lex_char ( p , ' < ' ) ) f . in = SBG_FADE_SILENCE ; else if ( lex_char ( p , ' - ' ) ) f . in = SBG_FADE_SAME ; else if ( lex_char ( p , ' = ' ) ) f . in = SBG_FADE_ADAPT ; else return 0 ; if ( lex_char ( p , ' > ' ) ) f . out = SBG_FADE_SILENCE ; else if ( lex_char ( p , ' - ' ) ) f . out = SBG_FADE_SAME ; else if ( lex_char ( p , ' = ' ) ) f . out = SBG_FADE_ADAPT ; else return AVERROR_INVALIDDATA ; * fr = f ; return 1 ; }",1
"int ff_hevc_decode_short_term_rps ( HEVCContext * s , ShortTermRPS * rps , const HEVCSPS * sps , int is_slice_header ) { HEVCLocalContext * lc = s - > HEVClc ; uint8_t rps_predict = 0 ; int delta_poc ; int k0 = 0 ; int k1 = 0 ; int k = 0 ; int i ; GetBitContext * gb = & lc - > gb ; if ( rps ! = sps - > st_rps & & sps - > nb_st_rps ) rps_predict = get_bits1 ( gb ) ; if ( rps_predict ) { const ShortTermRPS * rps_ridx ; int delta_rps , abs_delta_rps ; uint8_t use_delta_flag = 0 ; uint8_t delta_rps_sign ; if ( is_slice_header ) { unsigned int delta_idx = get_ue_golomb_long ( gb ) + 1 ; if ( delta_idx > sps - > nb_st_rps ) { av_log ( s - > avctx , AV_LOG_ERROR , Invalid value of delta_idx in slice header RPS : %d > %d . \n , delta_idx , sps - > nb_st_rps ) ; return AVERROR_INVALIDDATA ; } rps_ridx = & sps - > st_rps[sps - > nb_st_rps - delta_idx] ; } else rps_ridx = & sps - > st_rps[rps - sps - > st_rps - 1] ; delta_rps_sign = get_bits1 ( gb ) ; abs_delta_rps = get_ue_golomb_long ( gb ) + 1 ; delta_rps = ( 1 - ( delta_rps_sign < < 1 ) ) * abs_delta_rps ; for ( i = 0 ; i < = rps_ridx - > num_delta_pocs ; i + + ) { int used = rps - > used[k] = get_bits1 ( gb ) ; if ( ! used ) use_delta_flag = get_bits1 ( gb ) ; if ( used || use_delta_flag ) { if ( i < rps_ridx - > num_delta_pocs ) delta_poc = delta_rps + rps_ridx - > delta_poc[i] ; else delta_poc = delta_rps ; rps - > delta_poc[k] = delta_poc ; if ( delta_poc < 0 ) k0 + + ; else k1 + + ; k + + ; } } rps - > num_delta_pocs = k ; rps - > num_negative_pics = k0 ; // sort in increasing order ( smallest first ) if ( rps - > num_delta_pocs ! = 0 ) { int used , tmp ; for ( i = 1 ; i < rps - > num_delta_pocs ; i + + ) { delta_poc = rps - > delta_poc[i] ; used = rps - > used[i] ; for ( k = i - 1 ; k > = 0 ; k - - ) { tmp = rps - > delta_poc[k] ; if ( delta_poc < tmp ) { rps - > delta_poc[k + 1] = tmp ; rps - > used[k + 1] = rps - > used[k] ; rps - > delta_poc[k] = delta_poc ; rps - > used[k] = used ; } } } } if ( ( rps - > num_negative_pics > > 1 ) ! = 0 ) { int used ; k = rps - > num_negative_pics - 1 ; // flip the negative values to largest first for ( i = 0 ; i < rps - > num_negative_pics > > 1 ; i + + ) { delta_poc = rps - > delta_poc[i] ; used = rps - > used[i] ; rps - > delta_poc[i] = rps - > delta_poc[k] ; rps - > used[i] = rps - > used[k] ; rps - > delta_poc[k] = delta_poc ; rps - > used[k] = used ; k - - ; } } } else { unsigned int prev , nb_positive_pics ; rps - > num_negative_pics = get_ue_golomb_long ( gb ) ; nb_positive_pics = get_ue_golomb_long ( gb ) ; if ( rps - > num_negative_pics > = MAX_REFS || nb_positive_pics > = MAX_REFS ) { av_log ( s - > avctx , AV_LOG_ERROR , Too many refs in a short term RPS . \n ) ; return AVERROR_INVALIDDATA ; } rps - > num_delta_pocs = rps - > num_negative_pics + nb_positive_pics ; if ( rps - > num_delta_pocs ) { prev = 0 ; for ( i = 0 ; i < rps - > num_negative_pics ; i + + ) { delta_poc = get_ue_golomb_long ( gb ) + 1 ; prev - = delta_poc ; rps - > delta_poc[i] = prev ; rps - > used[i] = get_bits1 ( gb ) ; } prev = 0 ; for ( i = 0 ; i < nb_positive_pics ; i + + ) { delta_poc = get_ue_golomb_long ( gb ) + 1 ; prev + = delta_poc ; rps - > delta_poc[rps - > num_negative_pics + i] = prev ; rps - > used[rps - > num_negative_pics + i] = get_bits1 ( gb ) ; } } } return 0 ; }",1
"int ff_tls_open_underlying ( TLSShared * c , URLContext * parent , const char * uri , AVDictionary * * options ) { int port ; const char * p ; char buf[200] , opts[50] = ; struct addrinfo hints = { 0 } , * ai = NULL ; const char * proxy_path ; int use_proxy ; set_options ( c , uri ) ; if ( c - > listen ) snprintf ( opts , sizeof ( opts ) , ? listen=1 ) ; av_url_split ( NULL , 0 , NULL , 0 , c - > host , sizeof ( c - > host ) , & port , NULL , 0 , uri ) ; p = strchr ( uri , ' ? ' ) ; if ( ! p ) { p = opts ; } else { if ( av_find_info_tag ( opts , sizeof ( opts ) , listen , p ) ) c - > listen = 1 ; } ff_url_join ( buf , sizeof ( buf ) , tcp , NULL , c - > host , port , %s , p ) ; hints . ai_flags = AI_NUMERICHOST ; if ( ! getaddrinfo ( c - > host , NULL , & hints , & ai ) ) { c - > numerichost = 1 ; freeaddrinfo ( ai ) ; } proxy_path = getenv ( http_proxy ) ; use_proxy = ! ff_http_match_no_proxy ( getenv ( no_proxy ) , c - > host ) & & proxy_path & & av_strstart ( proxy_path , http : // , NULL ) ; if ( use_proxy ) { char proxy_host[200] , proxy_auth[200] , dest[200] ; int proxy_port ; av_url_split ( NULL , 0 , proxy_auth , sizeof ( proxy_auth ) , proxy_host , sizeof ( proxy_host ) , & proxy_port , NULL , 0 , proxy_path ) ; ff_url_join ( dest , sizeof ( dest ) , NULL , NULL , c - > host , port , NULL ) ; ff_url_join ( buf , sizeof ( buf ) , httpproxy , proxy_auth , proxy_host , proxy_port , /%s , dest ) ; } return ffurl_open ( & c - > tcp , buf , AVIO_FLAG_READ_WRITE , & parent - > interrupt_callback , options ) ; }",1
"static inline int clamp ( int value , int min , int max ) { if ( value < min ) return min ; else if ( value > max ) return max ; else return value ; }",0
"static int faac_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , uint8_t * buf , int buf_size ) { FAACContext * s = ( FAACContext * ) avctx - > priv_data ; ifndef FAAD2_VERSION unsigned long bytesconsumed ; short * sample_buffer = NULL ; unsigned long samples ; int out ; else faacDecFrameInfo frame_info ; void * out ; endif if ( buf_size == 0 ) return 0 ; ifndef FAAD2_VERSION out = s - > faacDecDecode ( s - > faac_handle , ( unsigned char * ) buf , & bytesconsumed , data , & samples ) ; samples * = s - > sample_size ; if ( data_size ) * data_size = samples ; return ( buf_size < ( int ) bytesconsumed ) ? buf_size : ( int ) bytesconsumed ; else if ( ! s - > init ) { unsigned long srate ; unsigned char channels ; int r = s - > faacDecInit ( s - > faac_handle , buf , buf_size , & srate , & channels ) ; if ( r < 0 ) { av_log ( avctx , AV_LOG_ERROR , faac : codec init failed : %s\n , s - > faacDecGetErrorMessage ( frame_info . error ) ) ; return 0 ; } avctx - > sample_rate = srate ; avctx - > channels = channels ; s - > init = 1 ; } out = s - > faacDecDecode ( s - > faac_handle , & frame_info , ( unsigned char * ) buf , ( unsigned long ) buf_size ) ; if ( frame_info . error > 0 ) { av_log ( avctx , AV_LOG_ERROR , faac : frame decoding failed : %s\n , s - > faacDecGetErrorMessage ( frame_info . error ) ) ; return 0 ; } frame_info . samples * = s - > sample_size ; memcpy ( data , out , frame_info . samples ) ; // CHECKME - can we cheat this one if ( data_size ) * data_size = frame_info . samples ; return ( buf_size < ( int ) frame_info . bytesconsumed ) ? buf_size : ( int ) frame_info . bytesconsumed ; endif }",0
"static void mdct512 ( int32_t * out , int16_t * in ) { int i , re , im , re1 , im1 ; int16_t rot[MDCT_SAMPLES] ; IComplex x[MDCT_SAMPLES/4] ; / * shift to simplify computations * / for ( i = 0 ; i < MDCT_SAMPLES/4 ; i + + ) rot[i] = - in[i + 3 * MDCT_SAMPLES/4] ; for ( ; i < MDCT_SAMPLES ; i + + ) rot[i] = in[i - MDCT_SAMPLES/4] ; / * pre rotation * / for ( i = 0 ; i < MDCT_SAMPLES/4 ; i + + ) { re = ( ( int ) rot[ 2 * i] - ( int ) rot[MDCT_SAMPLES - 1 - 2 * i] ) > > 1 ; im = - ( ( int ) rot[MDCT_SAMPLES/2 + 2 * i] - ( int ) rot[MDCT_SAMPLES/2 - 1 - 2 * i] ) > > 1 ; CMUL ( x[i] . re , x[i] . im , re , im , - xcos1[i] , xsin1[i] ) ; } fft ( x , MDCT_NBITS - 2 ) ; / * post rotation * / for ( i = 0 ; i < MDCT_SAMPLES/4 ; i + + ) { re = x[i] . re ; im = x[i] . im ; CMUL ( re1 , im1 , re , im , xsin1[i] , xcos1[i] ) ; out[ 2 * i] = im1 ; out[MDCT_SAMPLES/2 - 1 - 2 * i] = re1 ; } }",0
"av_cold int ff_rv34_decode_init ( AVCodecContext * avctx ) { RV34DecContext * r = avctx - > priv_data ; MpegEncContext * s = & r - > s ; MPV_decode_defaults ( s ) ; s - > avctx= avctx ; s - > out_format = FMT_H263 ; s - > codec_id= avctx - > codec_id ; s - > width = avctx - > width ; s - > height = avctx - > height ; r - > s . avctx = avctx ; avctx - > flags |= CODEC_FLAG_EMU_EDGE ; r - > s . flags |= CODEC_FLAG_EMU_EDGE ; avctx - > pix_fmt = PIX_FMT_YUV420P ; avctx - > has_b_frames = 1 ; s - > low_delay = 0 ; if ( MPV_common_init ( s ) < 0 ) return - 1 ; ff_h264_pred_init ( & r - > h , CODEC_ID_RV40 ) ; r - > intra_types_hist = av_malloc ( s - > b4_stride * 4 * 2 * sizeof ( * r - > intra_types_hist ) ) ; r - > intra_types = r - > intra_types_hist + s - > b4_stride * 4 ; r - > mb_type = av_mallocz ( r - > s . mb_stride * r - > s . mb_height * sizeof ( * r - > mb_type ) ) ; r - > cbp_luma = av_malloc ( r - > s . mb_stride * r - > s . mb_height * sizeof ( * r - > cbp_luma ) ) ; r - > cbp_chroma = av_malloc ( r - > s . mb_stride * r - > s . mb_height * sizeof ( * r - > cbp_chroma ) ) ; r - > deblock_coefs = av_malloc ( r - > s . mb_stride * r - > s . mb_height * sizeof ( * r - > deblock_coefs ) ) ; if ( ! intra_vlcs[0] . cbppattern[0] . bits ) rv34_init_tables ( ) ; return 0 ; }",0
"static inline void mix_2f_2r_to_stereo ( AC3DecodeContext * ctx ) { int i ; float ( * output ) [256] = ctx - > audio_block . block_output ; for ( i = 0 ; i < 256 ; i + + ) { output[1][i] + = output[3][i] ; output[2][i] + = output[4][i] ; } memset ( output[3] , 0 , sizeof ( output[3] ) ) ; memset ( output[4] , 0 , sizeof ( output[4] ) ) ; }",0
"static int segment_start ( AVFormatContext * s ) { SegmentContext * seg = s - > priv_data ; AVFormatContext * oc = seg - > avf ; int err = 0 ; if ( seg - > wrap ) seg - > number %= seg - > wrap ; if ( av_get_frame_filename ( oc - > filename , sizeof ( oc - > filename ) , s - > filename , seg - > number + + ) < 0 ) return AVERROR ( EINVAL ) ; if ( ( err = avio_open2 ( & oc - > pb , oc - > filename , AVIO_FLAG_WRITE , & s - > interrupt_callback , NULL ) ) < 0 ) return err ; if ( ! oc - > priv_data & & oc - > oformat - > priv_data_size > 0 ) { oc - > priv_data = av_mallocz ( oc - > oformat - > priv_data_size ) ; if ( ! oc - > priv_data ) { avio_close ( oc - > pb ) ; return AVERROR ( ENOMEM ) ; } if ( oc - > oformat - > priv_class ) { * ( const AVClass * * ) oc - > priv_data = oc - > oformat - > priv_class ; av_opt_set_defaults ( oc - > priv_data ) ; } } if ( ( err = oc - > oformat - > write_header ( oc ) ) < 0 ) { goto fail ; } return 0 ; fail : av_log ( oc , AV_LOG_ERROR , Failure occurred when starting segment ' %s ' \n , oc - > filename ) ; avio_close ( oc - > pb ) ; av_freep ( & oc - > priv_data ) ; return err ; }",0
"static int put_image ( struct vf_instance * vf , mp_image_t * mpi , double pts ) { mp_image_t * dmpi ; if ( vf - > priv - > in . fmt == vf - > priv - > out . fmt ) { //nothing to do dmpi = mpi ; } else { int out_off_left , out_off_right ; int in_off_left = vf - > priv - > in . row_left * mpi - > stride[0] + vf - > priv - > in . off_left ; int in_off_right = vf - > priv - > in . row_right * mpi - > stride[0] + vf - > priv - > in . off_right ; dmpi = ff_vf_get_image ( vf - > next , IMGFMT_RGB24 , MP_IMGTYPE_TEMP , MP_IMGFLAG_ACCEPT_STRIDE , vf - > priv - > out . width , vf - > priv - > out . height ) ; out_off_left = vf - > priv - > out . row_left * dmpi - > stride[0] + vf - > priv - > out . off_left ; out_off_right = vf - > priv - > out . row_right * dmpi - > stride[0] + vf - > priv - > out . off_right ; switch ( vf - > priv - > out . fmt ) { case SIDE_BY_SIDE_LR : case SIDE_BY_SIDE_RL : case SIDE_BY_SIDE_2_LR : case SIDE_BY_SIDE_2_RL : case ABOVE_BELOW_LR : case ABOVE_BELOW_RL : case ABOVE_BELOW_2_LR : case ABOVE_BELOW_2_RL : case INTERLEAVE_ROWS_LR : case INTERLEAVE_ROWS_RL : memcpy_pic2 ( dmpi - > planes[0] + out_off_left , mpi - > planes[0] + in_off_left , 3 * vf - > priv - > width , vf - > priv - > height , dmpi - > stride[0] * vf - > priv - > row_step , mpi - > stride[0] * vf - > priv - > row_step , vf - > priv - > row_step ! = 1 ) ; memcpy_pic2 ( dmpi - > planes[0] + out_off_right , mpi - > planes[0] + in_off_right , 3 * vf - > priv - > width , vf - > priv - > height , dmpi - > stride[0] * vf - > priv - > row_step , mpi - > stride[0] * vf - > priv - > row_step , vf - > priv - > row_step ! = 1 ) ; break ; case MONO_L : case MONO_R : memcpy_pic ( dmpi - > planes[0] , mpi - > planes[0] + in_off_left , 3 * vf - > priv - > width , vf - > priv - > height , dmpi - > stride[0] , mpi - > stride[0] ) ; break ; case ANAGLYPH_RC_GRAY : case ANAGLYPH_RC_HALF : case ANAGLYPH_RC_COLOR : case ANAGLYPH_RC_DUBOIS : case ANAGLYPH_GM_GRAY : case ANAGLYPH_GM_HALF : case ANAGLYPH_GM_COLOR : case ANAGLYPH_YB_GRAY : case ANAGLYPH_YB_HALF : case ANAGLYPH_YB_COLOR : { int i , x , y , il , ir , o ; unsigned char * source = mpi - > planes[0] ; unsigned char * dest = dmpi - > planes[0] ; unsigned int out_width = vf - > priv - > out . width ; int * ana_matrix[3] ; for ( i = 0 ; i < 3 ; i + + ) ana_matrix[i] = vf - > priv - > ana_matrix[i] ; for ( y = 0 ; y < vf - > priv - > out . height ; y + + ) { o = dmpi - > stride[0] * y ; il = in_off_left + y * mpi - > stride[0] ; ir = in_off_right + y * mpi - > stride[0] ; for ( x = 0 ; x < out_width ; x + + ) { dest[o ] = ana_convert ( ana_matrix[0] , source + il , source + ir ) ; //red out dest[o + 1] = ana_convert ( ana_matrix[1] , source + il , source + ir ) ; //green out dest[o + 2] = ana_convert ( ana_matrix[2] , source + il , source + ir ) ; //blue out il + = 3 ; ir + = 3 ; o + = 3 ; } } break ; } default : ff_mp_msg ( MSGT_VFILTER , MSGL_WARN , [stereo3d] stereo format of output is not supported\n ) ; return 0 ; break ; } } return ff_vf_next_put_image ( vf , dmpi , pts ) ; }",0
"int ff_MPV_frame_start ( MpegEncContext * s , AVCodecContext * avctx ) { int i , ret ; Picture * pic ; s - > mb_skipped = 0 ; if ( ! ff_thread_can_start_frame ( avctx ) ) { av_log ( avctx , AV_LOG_ERROR , Attempt to start a frame outside SETUP state\n ) ; return - 1 ; } / * mark & release old frames * / if ( s - > pict_type ! = AV_PICTURE_TYPE_B & & s - > last_picture_ptr & & s - > last_picture_ptr ! = s - > next_picture_ptr & & s - > last_picture_ptr - > f . buf[0] ) { ff_mpeg_unref_picture ( s , s - > last_picture_ptr ) ; } / * release forgotten pictures * / / * if ( mpeg124/h263 ) * / for ( i = 0 ; i < MAX_PICTURE_COUNT ; i + + ) { if ( & s - > picture[i] ! = s - > last_picture_ptr & & & s - > picture[i] ! = s - > next_picture_ptr & & s - > picture[i] . reference & & ! s - > picture[i] . needs_realloc ) { if ( ! ( avctx - > active_thread_type & FF_THREAD_FRAME ) ) av_log ( avctx , AV_LOG_ERROR , releasing zombie picture\n ) ; ff_mpeg_unref_picture ( s , & s - > picture[i] ) ; } } ff_mpeg_unref_picture ( s , & s - > current_picture ) ; release_unused_pictures ( s ) ; if ( s - > current_picture_ptr & & s - > current_picture_ptr - > f . buf[0] == NULL ) { // we already have a unused image // ( maybe it was set before reading the header ) pic = s - > current_picture_ptr ; } else { i = ff_find_unused_picture ( s , 0 ) ; if ( i < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , no frame buffer available\n ) ; return i ; } pic = & s - > picture[i] ; } pic - > reference = 0 ; if ( ! s - > droppable ) { if ( s - > pict_type ! = AV_PICTURE_TYPE_B ) pic - > reference = 3 ; } pic - > f . coded_picture_number = s - > coded_picture_number + + ; if ( ff_alloc_picture ( s , pic , 0 ) < 0 ) return - 1 ; s - > current_picture_ptr = pic ; // FIXME use only the vars from current_pic s - > current_picture_ptr - > f . top_field_first = s - > top_field_first ; if ( s - > codec_id == AV_CODEC_ID_MPEG1VIDEO || s - > codec_id == AV_CODEC_ID_MPEG2VIDEO ) { if ( s - > picture_structure ! = PICT_FRAME ) s - > current_picture_ptr - > f . top_field_first = ( s - > picture_structure == PICT_TOP_FIELD ) == s - > first_field ; } s - > current_picture_ptr - > f . interlaced_frame = ! s - > progressive_frame & & ! s - > progressive_sequence ; s - > current_picture_ptr - > field_picture = s - > picture_structure ! = PICT_FRAME ; s - > current_picture_ptr - > f . pict_type = s - > pict_type ; // if ( s - > flags & & CODEC_FLAG_QSCALE ) // s - > current_picture_ptr - > quality = s - > new_picture_ptr - > quality ; s - > current_picture_ptr - > f . key_frame = s - > pict_type == AV_PICTURE_TYPE_I ; if ( ( ret = ff_mpeg_ref_picture ( s , & s - > current_picture , s - > current_picture_ptr ) ) < 0 ) return ret ; if ( s - > pict_type ! = AV_PICTURE_TYPE_B ) { s - > last_picture_ptr = s - > next_picture_ptr ; if ( ! s - > droppable ) s - > next_picture_ptr = s - > current_picture_ptr ; } av_dlog ( s - > avctx , L%p N%p C%p L%p N%p C%p type : %d drop : %d\n , s - > last_picture_ptr , s - > next_picture_ptr , s - > current_picture_ptr , s - > last_picture_ptr ? s - > last_picture_ptr - > f . data[0] : NULL , s - > next_picture_ptr ? s - > next_picture_ptr - > f . data[0] : NULL , s - > current_picture_ptr ? s - > current_picture_ptr - > f . data[0] : NULL , s - > pict_type , s - > droppable ) ; if ( ( s - > last_picture_ptr == NULL || s - > last_picture_ptr - > f . buf[0] == NULL ) & & ( s - > pict_type ! = AV_PICTURE_TYPE_I || s - > picture_structure ! = PICT_FRAME ) ) { int h_chroma_shift , v_chroma_shift ; av_pix_fmt_get_chroma_sub_sample ( s - > avctx - > pix_fmt , & h_chroma_shift , & v_chroma_shift ) ; if ( s - > pict_type == AV_PICTURE_TYPE_B & & s - > next_picture_ptr & & s - > next_picture_ptr - > f . buf[0] ) av_log ( avctx , AV_LOG_DEBUG , allocating dummy last picture for B frame\n ) ; else if ( s - > pict_type ! = AV_PICTURE_TYPE_I ) av_log ( avctx , AV_LOG_ERROR , warning : first frame is no keyframe\n ) ; else if ( s - > picture_structure ! = PICT_FRAME ) av_log ( avctx , AV_LOG_DEBUG , allocate dummy last picture for field based first keyframe\n ) ; / * Allocate a dummy frame * / i = ff_find_unused_picture ( s , 0 ) ; if ( i < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , no frame buffer available\n ) ; return i ; } s - > last_picture_ptr = & s - > picture[i] ; s - > last_picture_ptr - > reference = 3 ; s - > last_picture_ptr - > f . key_frame = 0 ; s - > last_picture_ptr - > f . pict_type = AV_PICTURE_TYPE_P ; if ( ff_alloc_picture ( s , s - > last_picture_ptr , 0 ) < 0 ) { s - > last_picture_ptr = NULL ; return - 1 ; } memset ( s - > last_picture_ptr - > f . data[0] , 0x80 , avctx - > height * s - > last_picture_ptr - > f . linesize[0] ) ; memset ( s - > last_picture_ptr - > f . data[1] , 0x80 , ( avctx - > height > > v_chroma_shift ) * s - > last_picture_ptr - > f . linesize[1] ) ; memset ( s - > last_picture_ptr - > f . data[2] , 0x80 , ( avctx - > height > > v_chroma_shift ) * s - > last_picture_ptr - > f . linesize[2] ) ; if ( s - > codec_id == AV_CODEC_ID_FLV1 || s - > codec_id == AV_CODEC_ID_H263 ) { for ( i=0 ; i < avctx - > height ; i + + ) memset ( s - > last_picture_ptr - > f . data[0] + s - > last_picture_ptr - > f . linesize[0] * i , 16 , avctx - > width ) ; } ff_thread_report_progress ( & s - > last_picture_ptr - > tf",0
"static int udp_open ( URLContext * h , const char * uri , int flags ) { char hostname[1024] , localaddr[1024] = ; int port , udp_fd = - 1 , tmp , bind_ret = - 1 ; UDPContext * s = h - > priv_data ; int is_output ; const char * p ; char buf[256] ; struct sockaddr_storage my_addr ; int len ; int reuse_specified = 0 ; int i , include = 0 , num_sources = 0 ; char * sources[32] ; h - > is_streamed = 1 ; h - > max_packet_size = 1472 ; is_output = ! ( flags & AVIO_FLAG_READ ) ; s - > ttl = 16 ; s - > buffer_size = is_output ? UDP_TX_BUF_SIZE : UDP_MAX_PKT_SIZE ; s - > circular_buffer_size = 7 * 188 * 4096 ; p = strchr ( uri , ' ? ' ) ; if ( p ) { if ( av_find_info_tag ( buf , sizeof ( buf ) , reuse , p ) ) { char * endptr = NULL ; s - > reuse_socket = strtol ( buf , & endptr , 10 ) ; / * assume if no digits were found it is a request to enable it * / if ( buf == endptr ) s - > reuse_socket = 1 ; reuse_specified = 1 ; } if ( av_find_info_tag ( buf , sizeof ( buf ) , overrun_nonfatal , p ) ) { char * endptr = NULL ; s - > overrun_nonfatal = strtol ( buf , & endptr , 10 ) ; / * assume if no digits were found it is a request to enable it * / if ( buf == endptr ) s - > overrun_nonfatal = 1 ; } if ( av_find_info_tag ( buf , sizeof ( buf ) , ttl , p ) ) { s - > ttl = strtol ( buf , NULL , 10 ) ; } if ( av_find_info_tag ( buf , sizeof ( buf ) , localport , p ) ) { s - > local_port = strtol ( buf , NULL , 10 ) ; } if ( av_find_info_tag ( buf , sizeof ( buf ) , pkt_size , p ) ) { h - > max_packet_size = strtol ( buf , NULL , 10 ) ; } if ( av_find_info_tag ( buf , sizeof ( buf ) , buffer_size , p ) ) { s - > buffer_size = strtol ( buf , NULL , 10 ) ; } if ( av_find_info_tag ( buf , sizeof ( buf ) , connect , p ) ) { s - > is_connected = strtol ( buf , NULL , 10 ) ; } if ( av_find_info_tag ( buf , sizeof ( buf ) , fifo_size , p ) ) { s - > circular_buffer_size = strtol ( buf , NULL , 10 ) * 188 ; ' circular_buffer_size ' option was set but it is not supported } if ( av_find_info_tag ( buf , sizeof ( buf ) , localaddr , p ) ) { av_strlcpy ( localaddr , buf , sizeof ( localaddr ) ) ; } if ( av_find_info_tag ( buf , sizeof ( buf ) , sources , p ) ) include = 1 ; if ( include || av_find_info_tag ( buf , sizeof ( buf ) , block , p ) ) { char * source_start ; source_start = buf ; while ( 1 ) { char * next = strchr ( source_start , ' , ' ) ; if ( next ) * next = ' \0 ' ; sources[num_sources] = av_strdup ( source_start ) ; if ( ! sources[num_sources] ) goto fail ; source_start = next + 1 ; num_sources + + ; if ( num_sources > = FF_ARRAY_ELEMS ( sources ) || ! next ) break ; } } } / * fill the dest addr * / av_url_split ( NULL , 0 , NULL , 0 , hostname , sizeof ( hostname ) , & port , NULL , 0 , uri ) ; / * XXX : fix av_url_split * / if ( hostname[0] == ' \0 ' || hostname[0] == ' ? ' ) { / * only accepts null hostname if input * / if ( ! ( flags & AVIO_FLAG_READ ) ) goto fail ; } else { if ( ff_udp_set_remote_url ( h , uri ) < 0 ) goto fail ; } if ( ( s - > is_multicast || ! s - > local_port ) & & ( h - > flags & AVIO_FLAG_READ ) ) s - > local_port = port ; udp_fd = udp_socket_create ( s , & my_addr , & len , localaddr ) ; if ( udp_fd < 0 ) goto fail ; / * Follow the requested reuse option , unless it ' s multicast in which * case enable reuse unless explicitly disabled . * / if ( s - > reuse_socket || ( s - > is_multicast & & ! reuse_specified ) ) { s - > reuse_socket = 1 ; if ( setsockopt ( udp_fd , SOL_SOCKET , SO_REUSEADDR , & ( s - > reuse_socket ) , sizeof ( s - > reuse_socket ) ) ! = 0 ) goto fail ; } / * If multicast , try binding the multicast address first , to avoid * receiving UDP packets from other sources aimed at the same UDP * port . This fails on windows . This makes sending to the same address * using sendto ( ) fail , so only do it if we ' re opened in read - only mode . * / if ( s - > is_multicast & & ! ( h - > flags & AVIO_FLAG_WRITE ) ) { bind_ret = bind ( udp_fd , ( struct sockaddr * ) & s - > dest_addr , len ) ; } / * bind to the local address if not multicast or if the multicast * bind failed * / / * the bind is needed to give a port to the socket now * / if ( bind_ret < 0 & & bind ( udp_fd , ( struct sockaddr * ) & my_addr , len ) < 0 ) { log_net_error ( h , AV_LOG_ERROR , bind failed ) ; goto fail ; } len = sizeof ( my_addr ) ; getsockname ( udp_fd , ( struct sockaddr * ) & my_addr , & len ) ; s - > local_port = udp_port ( & my_addr , len ) ; if ( s - > is_multicast ) { if ( h - > flags & AVIO_FLAG_WRITE ) { / * output * / if ( udp_set_multicast_ttl ( udp_fd , s - > ttl , ( struct sockaddr * ) & s - > dest_addr ) < 0 ) goto fail ; } if ( h - > flags & AVIO_FLAG_READ ) { / * input * / if ( num_sources == 0 || ! include ) { if ( udp_join_multicast_group ( udp_fd , ( struct sockaddr * ) & s - > dest_addr ) < 0 )",1
"static int vc1_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size , n_slices = 0 , i ; VC1Context * v = avctx - > priv_data ; MpegEncContext * s = & v - > s ; AVFrame * pict = data ; uint8_t * buf2 = NULL ; const uint8_t * buf_start = buf ; int mb_height , n_slices1 ; struct { uint8_t * buf ; GetBitContext gb ; int mby_start ; } * slices = NULL , * tmp ; / * no supplementary picture * / if ( buf_size == 0 || ( buf_size == 4 & & AV_RB32 ( buf ) == VC1_CODE_ENDOFSEQ ) ) { / * special case for last picture * / if ( s - > low_delay == 0 & & s - > next_picture_ptr ) { * pict = s - > next_picture_ptr - > f ; s - > next_picture_ptr = NULL ; * data_size = sizeof ( AVFrame ) ; } return 0 ; } if ( s - > avctx - > codec - > capabilities & CODEC_CAP_HWACCEL_VDPAU ) { if ( v - > profile < PROFILE_ADVANCED ) avctx - > pix_fmt = AV_PIX_FMT_VDPAU_WMV3 ; else avctx - > pix_fmt = AV_PIX_FMT_VDPAU_VC1 ; } //for advanced profile we may need to parse and unescape data if ( avctx - > codec_id == AV_CODEC_ID_VC1 || avctx - > codec_id == AV_CODEC_ID_VC1IMAGE ) { int buf_size2 = 0 ; buf2 = av_mallocz ( buf_size + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( IS_MARKER ( AV_RB32 ( buf ) ) ) { / * frame starts with marker and needs to be parsed * / const uint8_t * start , * end , * next ; int size ; next = buf ; for ( start = buf , end = buf + buf_size ; next < end ; start = next ) { next = find_next_marker ( start + 4 , end ) ; size = next - start - 4 ; if ( size < = 0 ) continue ; switch ( AV_RB32 ( start ) ) { case VC1_CODE_FRAME : if ( avctx - > hwaccel || s - > avctx - > codec - > capabilities & CODEC_CAP_HWACCEL_VDPAU ) buf_start = start ; buf_size2 = vc1_unescape_buffer ( start + 4 , size , buf2 ) ; break ; case VC1_CODE_FIELD : { int buf_size3 ; tmp = av_realloc ( slices , sizeof ( * slices ) * ( n_slices + 1 ) ) ; if ( ! tmp ) goto err ; slices = tmp ; slices[n_slices] . buf = av_mallocz ( buf_size + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! slices[n_slices] . buf ) goto err ; buf_size3 = vc1_unescape_buffer ( start + 4 , size , slices[n_slices] . buf ) ; init_get_bits ( & slices[n_slices] . gb , slices[n_slices] . buf , buf_size3 < < 3 ) ; / * assuming that the field marker is at the exact middle , hope it ' s correct * / slices[n_slices] . mby_start = s - > mb_height > > 1 ; n_slices1 = n_slices - 1 ; // index of the last slice of the first field n_slices + + ; break ; } case VC1_CODE_ENTRYPOINT : / * it should be before frame data * / buf_size2 = vc1_unescape_buffer ( start + 4 , size , buf2 ) ; init_get_bits ( & s - > gb , buf2 , buf_size2 * 8 ) ; ff_vc1_decode_entry_point ( avctx , v , & s - > gb ) ; break ; case VC1_CODE_SLICE : { int buf_size3 ; tmp = av_realloc ( slices , sizeof ( * slices ) * ( n_slices + 1 ) ) ; if ( ! tmp ) goto err ; slices = tmp ; slices[n_slices] . buf = av_mallocz ( buf_size + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! slices[n_slices] . buf ) goto err ; buf_size3 = vc1_unescape_buffer ( start + 4 , size , slices[n_slices] . buf ) ; init_get_bits ( & slices[n_slices] . gb , slices[n_slices] . buf , buf_size3 < < 3 ) ; slices[n_slices] . mby_start = get_bits ( & slices[n_slices] . gb , 9 ) ; n_slices + + ; break ; } } } } else if ( v - > interlace & & ( ( buf[0] & 0xC0 ) == 0xC0 ) ) { / * WVC1 interlaced stores both fields divided by marker * / const uint8_t * divider ; int buf_size3 ; divider = find_next_marker ( buf , buf + buf_size ) ; if ( ( divider == ( buf + buf_size ) ) || AV_RB32 ( divider ) ! = VC1_CODE_FIELD ) { av_log ( avctx , AV_LOG_ERROR , Error in WVC1 interlaced frame\n ) ; goto err ; } else { // found field marker , unescape second field tmp = av_realloc ( slices , sizeof ( * slices ) * ( n_slices + 1 ) ) ; if ( ! tmp ) goto err ; slices = tmp ; slices[n_slices] . buf = av_mallocz ( buf_size + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! slices[n_slices] . buf ) goto err ; buf_size3 = vc1_unescape_buffer ( divider + 4 , buf + buf_size - divider - 4 , slices[n_slices] . buf ) ; init_get_bits ( & slices[n_slices] . gb , slices[n_slices] . buf , buf_size3 < < 3 ) ; slices[n_slices] . mby_start = s - > mb_height > > 1 ; n_slices1 = n_slices - 1 ; n_slices + + ; } buf_size2 = vc1_unescape_buffer ( buf , divider - buf , buf2 ) ; } else { buf_size2 = vc1_unescape_buffer ( buf , buf_size , buf2 ) ; } init_get_bits ( & s - > gb , buf2 , buf_size2 * 8 ) ; } else init_get_bits ( & s - > gb , buf , buf_size * 8 ) ; if ( v - > res_sprite ) { v - > new_sprite = ! get_bits1 ( & s - > gb ) ; v - > two_sprites = get_bits1 ( & s - > gb ) ; / * res_sprite means a Windows Media Image stream , AV_CODEC_ID_ * IMAGE means we ' re using the sprite compositor . These are intentionally kept separate so you can get the raw sprites by using the wmv3 decoder for WMVP or the vc1 one for WVP2 * / if ( avctx - > codec_id == AV_CODEC_ID_WMV3IMAGE || avctx - > codec_id == AV_CODEC_ID_VC1IMAGE ) { if ( v - > new_sprite ) { // switch AVCodecContext parameters to those of the sprites avctx - > width = avctx - > coded_width = v - > sprite_width ; avctx - > height = avctx - > coded_height = v - > sprite_height ; } else { goto image ; } } } if ( s - > context_initialized & & ( s - > width ! = avctx - > coded_width || s - > height ! = avctx - > coded_height ) ) { ff_vc1_decode_end (",1
"int ff_h263_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; MpegEncContext * s = avctx - > priv_data ; int ret ; AVFrame * pict = data ; s - > flags= avctx - > flags ; s - > flags2= avctx - > flags2 ; / * no supplementary picture * / if ( buf_size == 0 ) { / * special case for last picture * / if ( s - > low_delay==0 & & s - > next_picture_ptr ) { if ( ( ret = av_frame_ref ( pict , & s - > next_picture_ptr - > f ) ) < 0 ) return ret ; s - > next_picture_ptr= NULL ; * got_frame = 1 ; } return 0 ; } if ( s - > flags & CODEC_FLAG_TRUNCATED ) { int next ; if ( CONFIG_MPEG4_DECODER & & s - > codec_id==AV_CODEC_ID_MPEG4 ) { next= ff_mpeg4_find_frame_end ( & s - > parse_context , buf , buf_size ) ; } else if ( CONFIG_H263_DECODER & & s - > codec_id==AV_CODEC_ID_H263 ) { next= ff_h263_find_frame_end ( & s - > parse_context , buf , buf_size ) ; } else if ( CONFIG_H263P_DECODER & & s - > codec_id==AV_CODEC_ID_H263P ) { next= ff_h263_find_frame_end ( & s - > parse_context , buf , buf_size ) ; } else { av_log ( s - > avctx , AV_LOG_ERROR , this codec does not support truncated bitstreams\n ) ; return AVERROR ( EINVAL ) ; } if ( ff_combine_frame ( & s - > parse_context , next , ( const uint8_t * * ) & buf , & buf_size ) < 0 ) return buf_size ; } retry : if ( s - > divx_packed & & s - > bitstream_buffer_size ) { int i ; for ( i=0 ; i < buf_size - 3 ; i + + ) { if ( buf[i]==0 & & buf[i + 1]==0 & & buf[i + 2]==1 ) { if ( buf[i + 3]==0xB0 ) { av_log ( s - > avctx , AV_LOG_WARNING , Discarding excessive bitstream in packed xvid\n ) ; s - > bitstream_buffer_size=0 ; } break ; } } } if ( s - > bitstream_buffer_size & & ( s - > divx_packed || buf_size < 20 ) ) { //divx 5 . 01 + /xvid frame reorder init_get_bits ( & s - > gb , s - > bitstream_buffer , s - > bitstream_buffer_size * 8 ) ; } else init_get_bits ( & s - > gb , buf , buf_size * 8 ) ; s - > bitstream_buffer_size=0 ; if ( ! s - > context_initialized ) { if ( ( ret = ff_MPV_common_init ( s ) ) < 0 ) //we need the idct permutaton for reading a custom matrix return ret ; } / * We need to set current_picture_ptr before reading the header , * otherwise we cannot store anyting in there * / if ( s - > current_picture_ptr == NULL || s - > current_picture_ptr - > f . data[0] ) { int i= ff_find_unused_picture ( s , 0 ) ; if ( i < 0 ) return i ; s - > current_picture_ptr= & s - > picture[i] ; } / * let ' s go : - ) * / if ( CONFIG_WMV2_DECODER & & s - > msmpeg4_version==5 ) { ret= ff_wmv2_decode_picture_header ( s ) ; } else if ( CONFIG_MSMPEG4_DECODER & & s - > msmpeg4_version ) { ret = ff_msmpeg4_decode_picture_header ( s ) ; } else if ( CONFIG_MPEG4_DECODER & & s - > h263_pred ) { if ( s - > avctx - > extradata_size & & s - > picture_number==0 ) { GetBitContext gb ; init_get_bits ( & gb , s - > avctx - > extradata , s - > avctx - > extradata_size * 8 ) ; ret = ff_mpeg4_decode_picture_header ( s , & gb ) ; } ret = ff_mpeg4_decode_picture_header ( s , & s - > gb ) ; } else if ( CONFIG_H263I_DECODER & & s - > codec_id == AV_CODEC_ID_H263I ) { ret = ff_intel_h263_decode_picture_header ( s ) ; } else if ( CONFIG_FLV_DECODER & & s - > h263_flv ) { ret = ff_flv_decode_picture_header ( s ) ; } else { ret = ff_h263_decode_picture_header ( s ) ; } if ( ret < 0 || ret==FRAME_SKIPPED ) { if ( s - > width ! = avctx - > coded_width || s - > height ! = avctx - > coded_height ) { av_log ( s - > avctx , AV_LOG_WARNING , Reverting picture dimensions change due to header decoding failure\n ) ; s - > width = avctx - > coded_width ; s - > height= avctx - > coded_height ; } } if ( ret==FRAME_SKIPPED ) return get_consumed_bytes ( s , buf_size ) ; / * skip if the header was thrashed * / if ( ret < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , header damaged\n ) ; return ret ; } avctx - > has_b_frames= ! s - > low_delay ; if ( s - > xvid_build== - 1 & & s - > divx_version== - 1 & & s - > lavc_build== - 1 ) { if ( s - > stream_codec_tag == AV_RL32 ( XVID ) || s - > codec_tag == AV_RL32 ( XVID ) || s - > codec_tag == AV_RL32 ( XVIX ) || s - > codec_tag == AV_RL32 ( RMP4 ) || s - > codec_tag == AV_RL32 ( ZMP4 ) || s - > codec_tag == AV_RL32 ( SIPP ) ) s - > xvid_build= 0 ; if 0 if ( s - > codec_tag == AV_RL32 ( DIVX ) & & s - > vo_type==0 & & s - > vol_control_parameters==1 & & s - > padding_bug_score > 0 & & s - > low_delay ) // XVID with modified fourcc s - > xvid_build= 0 ; endif } if ( s - > xvid_build== - 1 & & s - > divx_version== - 1 & & s - > lavc_build== - 1 ) { if ( s - > codec_tag == AV_RL32 ( DIVX ) & & s - > vo_type==0 & & s - > vol_control_parameters==0 ) s - > divx_version= 400 ; //divx 4 } if ( s - > xvid_build > =0 & & s - > divx_version > =0 ) { s - > divx_version= s - > divx_build= - 1 ; } if ( s - > workaround_bugs & FF_BUG_AUTODETECT ) { if ( s - > codec_tag == AV_RL32 ( XVIX ) ) s - > workaround_bugs|= FF_BUG_XVID_ILACE ; if ( s - > codec_tag == AV_RL32 ( UMP4 ) ) { s - > workaround_bugs|= FF_BUG_UMP4 ; } if ( s - > divx_version > =500 & & s - > divx_build < 1814 ) { s - > workaround_bugs|= FF_BUG_QPEL_CHROMA ; } if ( s - > divx_version > 502 & & s - >",1
void avcodec_free_context ( AVCodecContext * * pavctx ) { AVCodecContext * avctx = * pavctx ; if ( ! avctx ) return ; avcodec_close ( avctx ) ; av_freep ( & avctx - > extradata ) ; av_freep ( & avctx - > subtitle_header ) ; av_freep ( pavctx ) ; },1
"void ff_mpeg_flush ( AVCodecContext * avctx ) { int i ; MpegEncContext * s = avctx - > priv_data ; if ( s==NULL || s - > picture==NULL ) return ; for ( i=0 ; i < MAX_PICTURE_COUNT ; i + + ) { if ( s - > picture[i] . data[0] & & ( s - > picture[i] . type == FF_BUFFER_TYPE_INTERNAL || s - > picture[i] . type == FF_BUFFER_TYPE_USER ) ) avctx - > release_buffer ( avctx , ( AVFrame * ) & s - > picture[i] ) ; } s - > current_picture_ptr = s - > last_picture_ptr = s - > next_picture_ptr = NULL ; s - > mb_x= s - > mb_y= 0 ; s - > parse_context . state= - 1 ; s - > parse_context . frame_start_found= 0 ; s - > parse_context . overread= 0 ; s - > parse_context . overread_index= 0 ; s - > parse_context . index= 0 ; s - > parse_context . last_index= 0 ; s - > bitstream_buffer_size=0 ; }",1
"static int decode_frame_ilbm ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { IffContext * s = avctx - > priv_data ; const uint8_t * buf = avpkt - > size > = 2 ? avpkt - > data + AV_RB16 ( avpkt - > data ) : NULL ; const int buf_size = avpkt - > size > = 2 ? avpkt - > size - AV_RB16 ( avpkt - > data ) : 0 ; const uint8_t * buf_end = buf + buf_size ; int y , plane , res ; if ( ( res = extract_header ( avctx , avpkt ) ) < 0 ) return res ; if ( s - > init ) { if ( ( res = avctx - > reget_buffer ( avctx , & s - > frame ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , reget_buffer ( ) failed\n ) ; return res ; } } else if ( ( res = avctx - > get_buffer ( avctx , & s - > frame ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed\n ) ; return res ; } else if ( avctx - > bits_per_coded_sample < = 8 & & avctx - > pix_fmt ! = PIX_FMT_GRAY8 ) { if ( ( res = ff_cmap_read_palette ( avctx , ( uint32_t * ) s - > frame . data[1] ) ) < 0 ) return res ; } s - > init = 1 ; if ( avctx - > codec_tag == MKTAG ( ' A ' , ' C ' , ' B ' , ' M ' ) ) { if ( avctx - > pix_fmt == PIX_FMT_PAL8 || avctx - > pix_fmt == PIX_FMT_GRAY8 ) { memset ( s - > frame . data[0] , 0 , avctx - > height * s - > frame . linesize[0] ) ; for ( plane = 0 ; plane < s - > bpp ; plane + + ) { for ( y = 0 ; y < avctx - > height & & buf < buf_end ; y + + ) { uint8_t * row = & s - > frame . data[0][ y * s - > frame . linesize[0] ] ; decodeplane8 ( row , buf , FFMIN ( s - > planesize , buf_end - buf ) , plane ) ; buf + = s - > planesize ; } } } else if ( s - > ham ) { // HAM to PIX_FMT_BGR32 memset ( s - > frame . data[0] , 0 , avctx - > height * s - > frame . linesize[0] ) ; for ( y = 0 ; y < avctx - > height ; y + + ) { uint8_t * row = & s - > frame . data[0][y * s - > frame . linesize[0]] ; memset ( s - > ham_buf , 0 , s - > planesize * 8 ) ; for ( plane = 0 ; plane < s - > bpp ; plane + + ) { const uint8_t * start = buf + ( plane * avctx - > height + y ) * s - > planesize ; if ( start > = buf_end ) break ; decodeplane8 ( s - > ham_buf , start , FFMIN ( s - > planesize , buf_end - start ) , plane ) ; } decode_ham_plane32 ( ( uint32_t * ) row , s - > ham_buf , s - > ham_palbuf , s - > planesize ) ; } } } else if ( avctx - > codec_tag == MKTAG ( ' D ' , ' E ' , ' E ' , ' P ' ) ) { int raw_width = avctx - > width * ( av_get_bits_per_pixel ( & av_pix_fmt_descriptors[avctx - > pix_fmt] ) > > 3 ) ; int x ; for ( y = 0 ; y < avctx - > height & & buf < buf_end ; y + + ) { uint8_t * row = & s - > frame . data[0][y * s - > frame . linesize[0]] ; memcpy ( row , buf , FFMIN ( raw_width , buf_end - buf ) ) ; buf + = raw_width ; if ( avctx - > pix_fmt == PIX_FMT_BGR32 ) { for ( x = 0 ; x < avctx - > width ; x + + ) row[4 * x + 3] = row[4 * x + 3] & 0xF0 | ( row[4 * x + 3] > > 4 ) ; } } } else if ( avctx - > codec_tag == MKTAG ( ' I ' , ' L ' , ' B ' , ' M ' ) ) { // interleaved if ( avctx - > pix_fmt == PIX_FMT_PAL8 || avctx - > pix_fmt == PIX_FMT_GRAY8 ) { for ( y = 0 ; y < avctx - > height ; y + + ) { uint8_t * row = & s - > frame . data[0][ y * s - > frame . linesize[0] ] ; memset ( row , 0 , avctx - > width ) ; for ( plane = 0 ; plane < s - > bpp & & buf < buf_end ; plane + + ) { decodeplane8 ( row , buf , FFMIN ( s - > planesize , buf_end - buf ) , plane ) ; buf + = s - > planesize ; } } } else if ( s - > ham ) { // HAM to PIX_FMT_BGR32 for ( y = 0 ; y < avctx - > height ; y + + ) { uint8_t * row = & s - > frame . data[0][ y * s - > frame . linesize[0] ] ; memset ( s - > ham_buf , 0 , s - > planesize * 8 ) ; for ( plane = 0 ; plane < s - > bpp & & buf < buf_end ; plane + + ) { decodeplane8 ( s - > ham_buf , buf , FFMIN ( s - > planesize , buf_end - buf ) , plane ) ; buf + = s - > planesize ; } decode_ham_plane32 ( ( uint32_t * ) row , s - > ham_buf , s - > ham_palbuf , s - > planesize ) ; } } else { // PIX_FMT_BGR32 for ( y = 0 ; y < avctx - > height ; y + + ) { uint8_t * row = & s - > frame . data[0][y * s - > frame . linesize[0]] ; memset ( row , 0 , avctx - > width < < 2 ) ; for ( plane = 0 ; plane < s - > bpp & & buf < buf_end ; plane + + ) { decodeplane32 ( ( uint32_t * ) row , buf , FFMIN ( s - > planesize , buf_end - buf ) , plane ) ; buf + =",1
"static int jacosub_read_header ( AVFormatContext * s ) { AVBPrint header ; AVIOContext * pb = s - > pb ; char line[JSS_MAX_LINESIZE] ; JACOsubContext * jacosub = s - > priv_data ; int shift_set = 0 ; // only the first shift matters int merge_line = 0 ; int i , ret ; AVStream * st = avformat_new_stream ( s , NULL ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; avpriv_set_pts_info ( st , 64 , 1 , 100 ) ; st - > codec - > codec_type = AVMEDIA_TYPE_SUBTITLE ; st - > codec - > codec_id = AV_CODEC_ID_JACOSUB ; jacosub - > timeres = 30 ; av_bprint_init ( & header , 1024 + FF_INPUT_BUFFER_PADDING_SIZE , 4096 ) ; while ( ! avio_feof ( pb ) ) { int cmd_len ; const char * p = line ; int64_t pos = avio_tell ( pb ) ; int len = ff_get_line ( pb , line , sizeof ( line ) ) ; p = jss_skip_whitespace ( p ) ; / * queue timed line * / if ( merge_line || timed_line ( p ) ) { AVPacket * sub ; sub = ff_subtitles_queue_insert ( & jacosub - > q , line , len , merge_line ) ; if ( ! sub ) return AVERROR ( ENOMEM ) ; sub - > pos = pos ; merge_line = len > 1 & & ! strcmp ( & line[len - 2] , \\\n ) ; continue ; } / * skip all non - compiler commands and focus on the command * / if ( * p ! = ' ' ) continue ; p + + ; i = get_jss_cmd ( p[0] ) ; if ( i == - 1 ) continue ; / * trim command + spaces * / cmd_len = strlen ( cmds[i] ) ; if ( av_strncasecmp ( p , cmds[i] , cmd_len ) == 0 ) p + = cmd_len ; else p + + ; p = jss_skip_whitespace ( p ) ; / * handle commands which affect the whole script * / switch ( cmds[i][0] ) { case ' S ' : // SHIFT command affect the whole script . . . if ( ! shift_set ) { jacosub - > shift = get_shift ( jacosub - > timeres , p ) ; shift_set = 1 ; } av_bprintf ( & header , S %s , p ) ; break ; case ' T ' : // . . . but must be placed after TIMERES jacosub - > timeres = strtol ( p , NULL , 10 ) ; if ( ! jacosub - > timeres ) jacosub - > timeres = 30 ; else av_bprintf ( & header , T %s , p ) ; break ; } } / * general/essential directives in the extradata * / ret = avpriv_bprint_to_extradata ( st - > codec , & header ) ; if ( ret < 0 ) return ret ; / * SHIFT and TIMERES affect the whole script so packet timing can only be * done in a second pass * / for ( i = 0 ; i < jacosub - > q . nb_subs ; i + + ) { AVPacket * sub = & jacosub - > q . subs[i] ; read_ts ( jacosub , sub - > data , & sub - > pts , & sub - > duration ) ; } ff_subtitles_queue_finalize ( & jacosub - > q ) ; return 0 ; }",1
"static int get_packet_payload_size ( AVFormatContext * ctx , int stream_index , int64_t pts , int64_t dts ) { MpegMuxContext * s = ctx - > priv_data ; int buf_index ; StreamInfo * stream ; stream = ctx - > streams[stream_index] - > priv_data ; buf_index = 0 ; if ( ( ( s - > packet_number % s - > pack_header_freq ) == 0 ) ) { / * pack header size * / if ( s - > is_mpeg2 ) buf_index + = 14 ; else buf_index + = 12 ; if ( s - > is_vcd ) { / * there is exactly one system header for each stream in a VCD MPEG , One in the very first video packet and one in the very first audio packet ( see VCD standard p . IV - 7 and IV - 8 ) . * / if ( stream - > packet_number==0 ) / * The system headers refer only to the stream they occur in , so they have a constant size . * / buf_index + = 15 ; } else { if ( ( s - > packet_number % s - > system_header_freq ) == 0 ) buf_index + = s - > system_header_size ; } } if ( s - > is_vcd & & stream - > packet_number==0 ) / * the first pack of each stream contains only the pack header , the system header and some padding ( see VCD standard p . IV - 6 ) Add the padding size , so that the actual payload becomes 0 . * / buf_index + = s - > packet_size - buf_index ; else { / * packet header size * / buf_index + = 6 ; if ( s - > is_mpeg2 ) buf_index + = 3 ; if ( pts ! = AV_NOPTS_VALUE ) { if ( dts ! = pts ) buf_index + = 5 + 5 ; else buf_index + = 5 ; } else { if ( ! s - > is_mpeg2 ) buf_index + + ; } if ( stream - > id < 0xc0 ) { / * AC3/LPCM private data header * / buf_index + = 4 ; if ( stream - > id > = 0xa0 ) { int n ; buf_index + = 3 ; / * NOTE : we round the payload size to an integer number of LPCM samples * / n = ( s - > packet_size - buf_index ) % stream - > lpcm_align ; if ( n ) buf_index + = ( stream - > lpcm_align - n ) ; } } if ( s - > is_vcd & & stream - > id == AUDIO_ID ) / * The VCD standard demands that 20 zero bytes follow each audio packet ( see standard p . IV - 8 ) . * / buf_index + =20 ; } return s - > packet_size - buf_index ; }",0
"static int flic_decode_frame_15_16BPP ( AVCodecContext * avctx , void * data , int * data_size , const uint8_t * buf , int buf_size ) { / * Note , the only difference between the 15Bpp and 16Bpp * / / * Format is the pixel format , the packets are processed the same . * / FlicDecodeContext * s = avctx - > priv_data ; int stream_ptr = 0 ; int pixel_ptr ; unsigned char palette_idx1 ; unsigned int frame_size ; int num_chunks ; unsigned int chunk_size ; int chunk_type ; int i , j ; int lines ; int compressed_lines ; signed short line_packets ; int y_ptr ; int byte_run ; int pixel_skip ; int pixel_countdown ; unsigned char * pixels ; int pixel ; unsigned int pixel_limit ; s - > frame . reference = 1 ; s - > frame . buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE ; if ( avctx - > reget_buffer ( avctx , & s - > frame ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , reget_buffer ( ) failed\n ) ; return - 1 ; } pixels = s - > frame . data[0] ; pixel_limit = s - > avctx - > height * s - > frame . linesize[0] ; frame_size = AV_RL32 ( & buf[stream_ptr] ) ; stream_ptr + = 6 ; / * skip the magic number * / num_chunks = AV_RL16 ( & buf[stream_ptr] ) ; stream_ptr + = 10 ; / * skip padding * / frame_size - = 16 ; / * iterate through the chunks * / while ( ( frame_size > 0 ) & & ( num_chunks > 0 ) ) { chunk_size = AV_RL32 ( & buf[stream_ptr] ) ; stream_ptr + = 4 ; chunk_type = AV_RL16 ( & buf[stream_ptr] ) ; stream_ptr + = 2 ; switch ( chunk_type ) { case FLI_256_COLOR : case FLI_COLOR : / * For some reason , it seems that non - palettized flics do * include one of these chunks in their first frame . * Why I do not know , it seems rather extraneous . * / / * av_log ( avctx , AV_LOG_ERROR , Unexpected Palette chunk %d in non - paletised FLC\n , chunk_type ) ; * / stream_ptr = stream_ptr + chunk_size - 6 ; break ; case FLI_DELTA : case FLI_DTA_LC : y_ptr = 0 ; compressed_lines = AV_RL16 ( & buf[stream_ptr] ) ; stream_ptr + = 2 ; while ( compressed_lines > 0 ) { line_packets = AV_RL16 ( & buf[stream_ptr] ) ; stream_ptr + = 2 ; if ( line_packets < 0 ) { line_packets = - line_packets ; y_ptr + = line_packets * s - > frame . linesize[0] ; } else { compressed_lines - - ; pixel_ptr = y_ptr ; CHECK_PIXEL_PTR ( 0 ) ; pixel_countdown = s - > avctx - > width ; for ( i = 0 ; i < line_packets ; i + + ) { / * account for the skip bytes * / pixel_skip = buf[stream_ptr + + ] ; pixel_ptr + = ( pixel_skip * 2 ) ; / * Pixel is 2 bytes wide * / pixel_countdown - = pixel_skip ; byte_run = ( signed char ) ( buf[stream_ptr + + ] ) ; if ( byte_run < 0 ) { byte_run = - byte_run ; pixel = AV_RL16 ( & buf[stream_ptr] ) ; stream_ptr + = 2 ; CHECK_PIXEL_PTR ( 2 * byte_run ) ; for ( j = 0 ; j < byte_run ; j + + , pixel_countdown - = 2 ) { * ( ( signed short * ) ( & pixels[pixel_ptr] ) ) = pixel ; pixel_ptr + = 2 ; } } else { CHECK_PIXEL_PTR ( 2 * byte_run ) ; for ( j = 0 ; j < byte_run ; j + + , pixel_countdown - - ) { * ( ( signed short * ) ( & pixels[pixel_ptr] ) ) = AV_RL16 ( & buf[stream_ptr] ) ; stream_ptr + = 2 ; pixel_ptr + = 2 ; } } } y_ptr + = s - > frame . linesize[0] ; } } break ; case FLI_LC : av_log ( avctx , AV_LOG_ERROR , Unexpected FLI_LC chunk in non - paletised FLC\n ) ; stream_ptr = stream_ptr + chunk_size - 6 ; break ; case FLI_BLACK : / * set the whole frame to 0x0000 which is black in both 15Bpp and 16Bpp modes . * / memset ( pixels , 0x0000 , s - > frame . linesize[0] * s - > avctx - > height ) ; break ; case FLI_BRUN : y_ptr = 0 ; for ( lines = 0 ; lines < s - > avctx - > height ; lines + + ) { pixel_ptr = y_ptr ; / * disregard the line packets ; instead , iterate through all * pixels on a row * / stream_ptr + + ; pixel_countdown = ( s - > avctx - > width * 2 ) ; while ( pixel_countdown > 0 ) { byte_run = ( signed char ) ( buf[stream_ptr + + ] ) ; if ( byte_run > 0 ) { palette_idx1 = buf[stream_ptr + + ] ; CHECK_PIXEL_PTR ( byte_run ) ; for ( j = 0 ; j < byte_run ; j + + ) { pixels[pixel_ptr + + ] = palette_idx1 ; pixel_countdown - - ; if ( pixel_countdown < 0 ) av_log ( avctx , AV_LOG_ERROR , pixel_countdown < 0 ( %d ) ( linea%d ) \n , pixel_countdown , lines ) ; } } else { / * copy bytes if byte_run < 0 * / byte_run = - byte_run ; CHECK_PIXEL_PTR ( byte_run ) ; for ( j = 0 ; j < byte_run ; j + + ) { palette_idx1 = buf[stream_ptr + + ] ; pixels[pixel_ptr + + ] = palette_idx1 ; pixel_countdown - - ; if ( pixel_countdown < 0 ) av_log ( avctx , AV_LOG_ERROR , pixel_countdown < 0 ( %d ) at line %d\n , pixel_countdown , lines ) ; } } } / * Now FLX is strange , in that it is byte as opposed to pixel run length compressed . * This does not give us any good oportunity to perform word endian conversion * during decompression . So if it is required ( i . e . , this is not a LE target , we do * a second pass over the line here , swapping the bytes . * / if HAVE_BIGENDIAN pixel_ptr = y_ptr ; pixel_countdown = s - > avctx - > width ; while ( pixel_countdown > 0 ) { * ( ( signed short * ) ( & pixels[pixel_ptr] ) ) = AV_RL16 ( & buf[pixel_ptr] ) ; pixel_ptr + = 2 ; } endif y_ptr + = s - > frame . linesize[0] ; } break ; case FLI_DTA_BRUN : y_ptr = 0 ; for ( lines = 0 ; lines < s - > avctx - > height ; lines + + ) { pixel_ptr = y_ptr ; / * disregard the line packets ; instead",1
"ogm_header ( AVFormatContext * s , int idx ) { struct ogg * ogg = s - > priv_data ; struct ogg_stream * os = ogg - > streams + idx ; AVStream * st = s - > streams[idx] ; const uint8_t * p = os - > buf + os - > pstart ; uint64_t time_unit ; uint64_t spu ; uint32_t size ; if ( ! ( * p & 1 ) ) return 0 ; if ( * p == 1 ) { p + + ; if ( * p == ' v ' ) { int tag ; st - > codec - > codec_type = AVMEDIA_TYPE_VIDEO ; p + = 8 ; tag = bytestream_get_le32 ( & p ) ; st - > codec - > codec_id = ff_codec_get_id ( ff_codec_bmp_tags , tag ) ; st - > codec - > codec_tag = tag ; } else if ( * p == ' t ' ) { st - > codec - > codec_type = AVMEDIA_TYPE_SUBTITLE ; st - > codec - > codec_id = CODEC_ID_TEXT ; p + = 12 ; } else { uint8_t acid[5] ; int cid ; st - > codec - > codec_type = AVMEDIA_TYPE_AUDIO ; p + = 8 ; bytestream_get_buffer ( & p , acid , 4 ) ; acid[4] = 0 ; cid = strtol ( acid , NULL , 16 ) ; st - > codec - > codec_id = ff_codec_get_id ( ff_codec_wav_tags , cid ) ; // our parser completely breaks AAC in Ogg if ( st - > codec - > codec_id ! = CODEC_ID_AAC ) st - > need_parsing = AVSTREAM_PARSE_FULL ; } size = bytestream_get_le32 ( & p ) ; size = FFMIN ( size , os - > psize ) ; time_unit = bytestream_get_le64 ( & p ) ; spu = bytestream_get_le64 ( & p ) ; p + = 4 ; / * default_len * / p + = 8 ; / * buffersize + bits_per_sample * / if ( st - > codec - > codec_type == AVMEDIA_TYPE_VIDEO ) { st - > codec - > width = bytestream_get_le32 ( & p ) ; st - > codec - > height = bytestream_get_le32 ( & p ) ; avpriv_set_pts_info ( st , 64 , time_unit , spu * 10000000 ) ; } else { st - > codec - > channels = bytestream_get_le16 ( & p ) ; p + = 2 ; / * block_align * / st - > codec - > bit_rate = bytestream_get_le32 ( & p ) * 8 ; st - > codec - > sample_rate = spu * 10000000 / time_unit ; avpriv_set_pts_info ( st , 64 , 1 , st - > codec - > sample_rate ) ; if ( size > = 56 & & st - > codec - > codec_id == CODEC_ID_AAC ) { p + = 4 ; size - = 4 ; } if ( size > 52 ) { av_assert0 ( FF_INPUT_BUFFER_PADDING_SIZE < = 52 ) ; size - = 52 ; st - > codec - > extradata_size = size ; st - > codec - > extradata = av_malloc ( size + FF_INPUT_BUFFER_PADDING_SIZE ) ; bytestream_get_buffer ( & p , st - > codec - > extradata , size ) ; } } } else if ( * p == 3 ) { if ( os - > psize > 8 ) ff_vorbis_comment ( s , & st - > metadata , p + 7 , os - > psize - 8 ) ; } return 1 ; }",1
"static int ape_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame_ptr , AVPacket * avpkt ) { AVFrame * frame = data ; const uint8_t * buf = avpkt - > data ; APEContext * s = avctx - > priv_data ; uint8_t * sample8 ; int16_t * sample16 ; int32_t * sample24 ; int i , ch , ret ; int blockstodecode ; / * this should never be negative , but bad things will happen if it is , so check it just to make sure . * / av_assert0 ( s - > samples > = 0 ) ; if ( ! s - > samples ) { uint32_t nblocks , offset ; int buf_size ; if ( ! avpkt - > size ) { * got_frame_ptr = 0 ; return 0 ; } if ( avpkt - > size < 8 ) { av_log ( avctx , AV_LOG_ERROR , Packet is too small\n ) ; return AVERROR_INVALIDDATA ; } buf_size = avpkt - > size & 3 ; if ( buf_size ! = avpkt - > size ) { av_log ( avctx , AV_LOG_WARNING , packet size is not a multiple of 4 . extra bytes at the end will be skipped . \n ) ; } if ( s - > fileversion < 3950 ) // previous versions overread two bytes buf_size + = 2 ; av_fast_malloc ( & s - > data , & s - > data_size , buf_size ) ; if ( ! s - > data ) return AVERROR ( ENOMEM ) ; s - > dsp . bswap_buf ( ( uint32_t * ) s - > data , ( const uint32_t * ) buf , buf_size > > 2 ) ; memset ( s - > data + ( buf_size & 3 ) , 0 , buf_size & 3 ) ; s - > ptr = s - > data ; s - > data_end = s - > data + buf_size ; nblocks = bytestream_get_be32 ( & s - > ptr ) ; offset = bytestream_get_be32 ( & s - > ptr ) ; if ( s - > fileversion > = 3900 ) { if ( offset > 3 ) { av_log ( avctx , AV_LOG_ERROR , Incorrect offset passed\n ) ; s - > data = NULL ; return AVERROR_INVALIDDATA ; } if ( s - > data_end - s - > ptr < offset ) { av_log ( avctx , AV_LOG_ERROR , Packet is too small\n ) ; return AVERROR_INVALIDDATA ; } s - > ptr + = offset ; } else { if ( ( ret = init_get_bits8 ( & s - > gb , s - > ptr , s - > data_end - s - > ptr ) ) < 0 ) return ret ; if ( s - > fileversion > 3800 ) skip_bits_long ( & s - > gb , offset * 8 ) ; else skip_bits_long ( & s - > gb , offset ) ; } if ( ! nblocks || nblocks > INT_MAX ) { av_log ( avctx , AV_LOG_ERROR , Invalid sample count : %u . \n , nblocks ) ; return AVERROR_INVALIDDATA ; } s - > samples = nblocks ; / * Initialize the frame decoder * / if ( init_frame_decoder ( s ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , Error reading frame header\n ) ; return AVERROR_INVALIDDATA ; } } if ( ! s - > data ) { * got_frame_ptr = 0 ; return avpkt - > size ; } blockstodecode = FFMIN ( s - > blocks_per_loop , s - > samples ) ; // for old files coefficients were not interleaved , // so we need to decode all of them at once if ( s - > fileversion < 3930 ) blockstodecode = s - > samples ; / * reallocate decoded sample buffer if needed * / av_fast_malloc ( & s - > decoded_buffer , & s - > decoded_size , 2 * FFALIGN ( blockstodecode , 8 ) * sizeof ( * s - > decoded_buffer ) ) ; if ( ! s - > decoded_buffer ) return AVERROR ( ENOMEM ) ; memset ( s - > decoded_buffer , 0 , s - > decoded_size ) ; s - > decoded[0] = s - > decoded_buffer ; s - > decoded[1] = s - > decoded_buffer + FFALIGN ( blockstodecode , 8 ) ; / * get output buffer * / frame - > nb_samples = blockstodecode ; if ( ( ret = ff_get_buffer ( avctx , frame , 0 ) ) < 0 ) return ret ; s - > error=0 ; if ( ( s - > channels == 1 ) || ( s - > frameflags & APE_FRAMECODE_PSEUDO_STEREO ) ) ape_unpack_mono ( s , blockstodecode ) ; else ape_unpack_stereo ( s , blockstodecode ) ; emms_c ( ) ; if ( s - > error ) { s - > samples=0 ; av_log ( avctx , AV_LOG_ERROR , Error decoding frame\n ) ; return AVERROR_INVALIDDATA ; } switch ( s - > bps ) { case 8 : for ( ch = 0 ; ch < s - > channels ; ch + + ) { sample8 = ( uint8_t * ) frame - > data[ch] ; for ( i = 0 ; i < blockstodecode ; i + + ) * sample8 + + = ( s - > decoded[ch][i] + 0x80 ) & 0xff ; } break ; case 16 : for ( ch = 0 ; ch < s - > channels ; ch + + ) { sample16 = ( int16_t * ) frame - > data[ch] ; for ( i = 0 ; i < blockstodecode ; i + + ) * sample16 + + = s - > decoded[ch][i] ; } break ; case 24 : for ( ch = 0 ; ch < s - > channels ; ch + + ) { sample24 = ( int32_t * ) frame - > data[ch] ; for ( i = 0 ; i < blockstodecode ; i + + ) * sample24 + + = s - > decoded[ch][i] < < 8 ; } break ; } s - > samples - = blockstodecode ; * got_frame_ptr = 1 ; return ! s - > samples ? avpkt - > size : 0 ; }",1
"static inline void RENAME ( rgb32tobgr16 ) ( const uint8_t * src , uint8_t * dst , long src_size ) { const uint8_t * s = src ; const uint8_t * end ; if COMPILE_TEMPLATE_MMX const uint8_t * mm_end ; endif uint16_t * d = ( uint16_t * ) dst ; end = s + src_size ; if COMPILE_TEMPLATE_MMX __asm__ volatile ( PREFETCH %0 : : m ( * src ) : memory ) ; __asm__ volatile ( movq %0 , %%mm7 \n\t movq %1 , %%mm6 \n\t : : m ( red_16mask ) , m ( green_16mask ) ) ; mm_end = end - 15 ; while ( s < mm_end ) { __asm__ volatile ( PREFETCH 32%1 \n\t movd %1 , %%mm0 \n\t movd 4%1 , %%mm3 \n\t punpckldq 8%1 , %%mm0 \n\t punpckldq 12%1 , %%mm3 \n\t movq %%mm0 , %%mm1 \n\t movq %%mm0 , %%mm2 \n\t movq %%mm3 , %%mm4 \n\t movq %%mm3 , %%mm5 \n\t psllq 8 , %%mm0 \n\t psllq 8 , %%mm3 \n\t pand %%mm7 , %%mm0 \n\t pand %%mm7 , %%mm3 \n\t psrlq 5 , %%mm1 \n\t psrlq 5 , %%mm4 \n\t pand %%mm6 , %%mm1 \n\t pand %%mm6 , %%mm4 \n\t psrlq 19 , %%mm2 \n\t psrlq 19 , %%mm5 \n\t pand %2 , %%mm2 \n\t pand %2 , %%mm5 \n\t por %%mm1 , %%mm0 \n\t por %%mm4 , %%mm3 \n\t por %%mm2 , %%mm0 \n\t por %%mm5 , %%mm3 \n\t psllq 16 , %%mm3 \n\t por %%mm3 , %%mm0 \n\t MOVNTQ %%mm0 , %0 \n\t : =m ( * d ) : m ( * s ) , m ( blue_16mask ) : memory ) ; d + = 4 ; s + = 16 ; } __asm__ volatile ( SFENCE : : : memory ) ; __asm__ volatile ( EMMS : : : memory ) ; endif while ( s < end ) { register int rgb = * ( const uint32_t * ) s ; s + = 4 ; * d + + = ( ( rgb & 0xF8 ) < < 8 ) + ( ( rgb & 0xFC00 ) > > 5 ) + ( ( rgb & 0xF80000 ) > > 19 ) ; } }",0
"static int truemotion1_decode_header ( TrueMotion1Context * s ) { int i ; int width_shift = 0 ; int new_pix_fmt ; struct frame_header header ; uint8_t header_buffer[128] ; / * logical maximum size of the header * / const uint8_t * sel_vector_table ; header . header_size = ( ( s - > buf[0] > > 5 ) | ( s - > buf[0] < < 3 ) ) & 0x7f ; if ( s - > buf[0] < 0x10 ) { av_log ( s - > avctx , AV_LOG_ERROR , invalid header size ( %d ) \n , s - > buf[0] ) ; return - 1 ; } / * unscramble the header bytes with a XOR operation * / memset ( header_buffer , 0 , 128 ) ; for ( i = 1 ; i < header . header_size ; i + + ) header_buffer[i - 1] = s - > buf[i] s - > buf[i + 1] ; header . compression = header_buffer[0] ; header . deltaset = header_buffer[1] ; header . vectable = header_buffer[2] ; header . ysize = AV_RL16 ( & header_buffer[3] ) ; header . xsize = AV_RL16 ( & header_buffer[5] ) ; header . checksum = AV_RL16 ( & header_buffer[7] ) ; header . version = header_buffer[9] ; header . header_type = header_buffer[10] ; header . flags = header_buffer[11] ; header . control = header_buffer[12] ; / * Version 2 * / if ( header . version > = 2 ) { if ( header . header_type > 3 ) { av_log ( s - > avctx , AV_LOG_ERROR , invalid header type ( %d ) \n , header . header_type ) ; return - 1 ; } else if ( ( header . header_type == 2 ) || ( header . header_type == 3 ) ) { s - > flags = header . flags ; if ( ! ( s - > flags & FLAG_INTERFRAME ) ) s - > flags |= FLAG_KEYFRAME ; } else s - > flags = FLAG_KEYFRAME ; } else / * Version 1 * / s - > flags = FLAG_KEYFRAME ; if ( s - > flags & FLAG_SPRITE ) { av_log ( s - > avctx , AV_LOG_INFO , SPRITE frame found , please report the sample to the developers\n ) ; / * FIXME header . width , height , xoffset and yoffset aren ' t initialized * / if 0 s - > w = header . width ; s - > h = header . height ; s - > x = header . xoffset ; s - > y = header . yoffset ; else return - 1 ; endif } else { s - > w = header . xsize ; s - > h = header . ysize ; if ( header . header_type < 2 ) { if ( ( s - > w < 213 ) & & ( s - > h > = 176 ) ) { s - > flags |= FLAG_INTERPOLATED ; av_log ( s - > avctx , AV_LOG_INFO , INTERPOLATION selected , please report the sample to the developers\n ) ; } } } if ( header . compression > = 17 ) { av_log ( s - > avctx , AV_LOG_ERROR , invalid compression type ( %d ) \n , header . compression ) ; return - 1 ; } if ( ( header . deltaset ! = s - > last_deltaset ) || ( header . vectable ! = s - > last_vectable ) ) select_delta_tables ( s , header . deltaset ) ; if ( ( header . compression & 1 ) & & header . header_type ) sel_vector_table = pc_tbl2 ; else { if ( header . vectable < 4 ) sel_vector_table = tables[header . vectable - 1] ; else { av_log ( s - > avctx , AV_LOG_ERROR , invalid vector table id ( %d ) \n , header . vectable ) ; return - 1 ; } } if ( compression_types[header . compression] . algorithm == ALGO_RGB24H ) { new_pix_fmt = PIX_FMT_RGB32 ; width_shift = 1 ; } else new_pix_fmt = PIX_FMT_RGB555 ; // RGB565 is supported as well s - > w > > = width_shift ; if ( av_image_check_size ( s - > w , s - > h , 0 , s - > avctx ) < 0 ) return - 1 ; if ( s - > w ! = s - > avctx - > width || s - > h ! = s - > avctx - > height || new_pix_fmt ! = s - > avctx - > pix_fmt ) { if ( s - > frame . data[0] ) s - > avctx - > release_buffer ( s - > avctx , & s - > frame ) ; s - > avctx - > sample_aspect_ratio = ( AVRational ) { 1 < < width_shift , 1 } ; s - > avctx - > pix_fmt = new_pix_fmt ; avcodec_set_dimensions ( s - > avctx , s - > w , s - > h ) ; av_fast_malloc ( & s - > vert_pred , & s - > vert_pred_size , s - > avctx - > width * sizeof ( unsigned int ) ) ; } / * There is 1 change bit per 4 pixels , so each change byte represents * 32 pixels ; divide width by 4 to obtain the number of change bits and * then round up to the nearest byte . * / s - > mb_change_bits_row_size = ( ( s - > avctx - > width > > ( 2 - width_shift ) ) + 7 ) > > 3 ; if ( ( header . deltaset ! = s - > last_deltaset ) || ( header . vectable ! = s - > last_vectable ) ) { if ( compression_types[header . compression] . algorithm == ALGO_RGB24H ) gen_vector_table24 ( s , sel_vector_table ) ; else if ( s - > avctx - > pix_fmt == PIX_FMT_RGB555 ) gen_vector_table15 ( s , sel_vector_table ) ; else gen_vector_table16 ( s , sel_vector_table ) ; } / * set up pointers to the other key data chunks * / s - > mb_change_bits = s - > buf + header . header_size ; if ( s - > flags & FLAG_KEYFRAME ) { / * no change bits specified for a keyframe ; only index bytes * / s - > index_stream = s - > mb_change_bits ; } else { / * one change bit per 4x4 block * / s - > index_stream = s - > mb_change_bits + ( s - > mb_change_bits_row_size * ( s - > avctx - > height > > 2 ) ) ; } s - > index_stream_size = s - > size - ( s - > index_stream - s - > buf ) ; s - > last_deltaset = header . deltaset ; s - > last_vectable = header . vectable ; s - > compression = header . compression ; s - > block_width = compression_types[header . compression] .",0
"static int opt_input_ts_scale ( const char * opt , const char * arg ) { unsigned int stream ; double scale ; char * p ; stream = strtol ( arg , & p , 0 ) ; if ( * p ) p + + ; scale= strtod ( p , & p ) ; if ( stream > = MAX_STREAMS ) ffmpeg_exit ( 1 ) ; ts_scale = grow_array ( ts_scale , sizeof ( * ts_scale ) , & nb_ts_scale , stream + 1 ) ; ts_scale[stream] = scale ; return 0 ; }",0
"static av_always_inline int normal_limit ( uint8_t * p , int stride , int E , int I ) { LOAD_PIXELS return simple_limit ( p , stride , 2 * E + I ) & & FFABS ( p3 - p2 ) < = I & & FFABS ( p2 - p1 ) < = I & & FFABS ( p1 - p0 ) < = I & & FFABS ( q3 - q2 ) < = I & & FFABS ( q2 - q1 ) < = I & & FFABS ( q1 - q0 ) < = I ; }",0
"static int mov_open_dref ( AVIOContext * * pb , const char * src , MOVDref * ref , AVIOInterruptCB * int_cb , int use_absolute_path , AVFormatContext * fc ) { / * try relative path , we do not try the absolute because it can leak information about our system to an attacker * / if ( ref - > nlvl_to > 0 & & ref - > nlvl_from > 0 ) { char filename[1024] ; const char * src_path ; int i , l ; / * find a source dir * / src_path = strrchr ( src , ' / ' ) ; if ( src_path ) src_path + + ; else src_path = src ; / * find a next level down to target * / for ( i = 0 , l = strlen ( ref - > path ) - 1 ; l > = 0 ; l - - ) if ( ref - > path[l] == ' / ' ) { if ( i == ref - > nlvl_to - 1 ) break ; else i + + ; } / * compose filename if next level down to target was found * / if ( i == ref - > nlvl_to - 1 & & src_path - src < sizeof ( filename ) ) { memcpy ( filename , src , src_path - src ) ; filename[src_path - src] = 0 ; for ( i = 1 ; i < ref - > nlvl_from ; i + + ) av_strlcat ( filename , . . / , sizeof ( filename ) ) ; av_strlcat ( filename , ref - > path + l + 1 , sizeof ( filename ) ) ; if ( ! avio_open2 ( pb , filename , AVIO_FLAG_READ , int_cb , NULL ) ) return 0 ; } } else if ( use_absolute_path ) { av_log ( fc , AV_LOG_WARNING , Using absolute path on user request , this is a possible security issue\n ) ; if ( ! avio_open2 ( pb , ref - > path , AVIO_FLAG_READ , int_cb , NULL ) ) return 0 ; } return AVERROR ( ENOENT ) ; }",0
"static int swScale ( SwsContext * c , const uint8_t * src[] , int srcStride[] , int srcSliceY , int srcSliceH , uint8_t * dst[] , int dstStride[] ) { / * load a few things into local vars to make the code more readable ? and faster * / const int srcW= c - > srcW ; const int dstW= c - > dstW ; const int dstH= c - > dstH ; const int chrDstW= c - > chrDstW ; const int chrSrcW= c - > chrSrcW ; const int lumXInc= c - > lumXInc ; const int chrXInc= c - > chrXInc ; const enum PixelFormat dstFormat= c - > dstFormat ; const int flags= c - > flags ; int16_t * vLumFilterPos= c - > vLumFilterPos ; int16_t * vChrFilterPos= c - > vChrFilterPos ; int16_t * hLumFilterPos= c - > hLumFilterPos ; int16_t * hChrFilterPos= c - > hChrFilterPos ; int16_t * vLumFilter= c - > vLumFilter ; int16_t * vChrFilter= c - > vChrFilter ; int16_t * hLumFilter= c - > hLumFilter ; int16_t * hChrFilter= c - > hChrFilter ; int32_t * lumMmxFilter= c - > lumMmxFilter ; int32_t * chrMmxFilter= c - > chrMmxFilter ; int32_t av_unused * alpMmxFilter= c - > alpMmxFilter ; const int vLumFilterSize= c - > vLumFilterSize ; const int vChrFilterSize= c - > vChrFilterSize ; const int hLumFilterSize= c - > hLumFilterSize ; const int hChrFilterSize= c - > hChrFilterSize ; int16_t * * lumPixBuf= c - > lumPixBuf ; int16_t * * chrUPixBuf= c - > chrUPixBuf ; int16_t * * chrVPixBuf= c - > chrVPixBuf ; int16_t * * alpPixBuf= c - > alpPixBuf ; const int vLumBufSize= c - > vLumBufSize ; const int vChrBufSize= c - > vChrBufSize ; uint8_t * formatConvBuffer= c - > formatConvBuffer ; const int chrSrcSliceY= srcSliceY > > c - > chrSrcVSubSample ; const int chrSrcSliceH= - ( ( - srcSliceH ) > > c - > chrSrcVSubSample ) ; int lastDstY ; uint32_t * pal=c - > pal_yuv ; yuv2planar1_fn yuv2yuv1 = c - > yuv2yuv1 ; yuv2planarX_fn yuv2yuvX = c - > yuv2yuvX ; yuv2packed1_fn yuv2packed1 = c - > yuv2packed1 ; yuv2packed2_fn yuv2packed2 = c - > yuv2packed2 ; yuv2packedX_fn yuv2packedX = c - > yuv2packedX ; / * vars which will change and which we need to store back in the context * / int dstY= c - > dstY ; int lumBufIndex= c - > lumBufIndex ; int chrBufIndex= c - > chrBufIndex ; int lastInLumBuf= c - > lastInLumBuf ; int lastInChrBuf= c - > lastInChrBuf ; if ( isPacked ( c - > srcFormat ) ) { src[0]= src[1]= src[2]= src[3]= src[0] ; srcStride[0]= srcStride[1]= srcStride[2]= srcStride[3]= srcStride[0] ; } srcStride[1] < < = c - > vChrDrop ; srcStride[2] < < = c - > vChrDrop ; DEBUG_BUFFERS ( swScale ( ) %p[%d] %p[%d] %p[%d] %p[%d] - > %p[%d] %p[%d] %p[%d] %p[%d]\n , src[0] , srcStride[0] , src[1] , srcStride[1] , src[2] , srcStride[2] , src[3] , srcStride[3] , dst[0] , dstStride[0] , dst[1] , dstStride[1] , dst[2] , dstStride[2] , dst[3] , dstStride[3] ) ; DEBUG_BUFFERS ( srcSliceY : %d srcSliceH : %d dstY : %d dstH : %d\n , srcSliceY , srcSliceH , dstY , dstH ) ; DEBUG_BUFFERS ( vLumFilterSize : %d vLumBufSize : %d vChrFilterSize : %d vChrBufSize : %d\n , vLumFilterSize , vLumBufSize , vChrFilterSize , vChrBufSize ) ; if ( dstStride[0]%8 ! =0 || dstStride[1]%8 ! =0 || dstStride[2]%8 ! =0 || dstStride[3]%8 ! = 0 ) { static int warnedAlready=0 ; //FIXME move this into the context perhaps if ( flags & SWS_PRINT_INFO & & ! warnedAlready ) { av_log ( c , AV_LOG_WARNING , Warning : dstStride is not aligned ! \n - > cannot do aligned memory accesses anymore\n ) ; warnedAlready=1 ; } } / * Note the user might start scaling the picture in the middle so this will not get executed . This is not really intended but works currently , so people might do it . * / if ( srcSliceY ==0 ) { lumBufIndex= - 1 ; chrBufIndex= - 1 ; dstY=0 ; lastInLumBuf= - 1 ; lastInChrBuf= - 1 ; } lastDstY= dstY ; for ( ; dstY < dstH ; dstY + + ) { unsigned char * dest =dst[0] + dstStride[0] * dstY ; const int chrDstY= dstY > > c - > chrDstVSubSample ; unsigned char * uDest=dst[1] + dstStride[1] * chrDstY ; unsigned char * vDest=dst[2] + dstStride[2] * chrDstY ; unsigned char * aDest= ( CONFIG_SWSCALE_ALPHA & & alpPixBuf ) ? dst[3] + dstStride[3] * dstY : NULL ; const int firstLumSrcY= vLumFilterPos[dstY] ; //First line needed as input const int firstLumSrcY2= vLumFilterPos[FFMIN ( dstY | ( ( 1 < < c - > chrDstVSubSample ) - 1 ) , dstH - 1 ) ] ; const int firstChrSrcY= vChrFilterPos[chrDstY] ; //First line needed as input int lastLumSrcY= firstLumSrcY + vLumFilterSize - 1 ; // Last line needed as input int lastLumSrcY2=firstLumSrcY2 + vLumFilterSize - 1 ; // Last line needed as input int lastChrSrcY= firstChrSrcY + vChrFilterSize - 1 ; // Last line needed as input int enough_lines ; //handle holes ( FAST_BILINEAR & weird filters ) if ( firstLumSrcY > lastInLumBuf ) lastInLumBuf= firstLumSrcY - 1 ; if ( firstChrSrcY > lastInChrBuf ) lastInChrBuf= firstChrSrcY - 1 ; assert ( firstLumSrcY > = lastInLumBuf - vLumBufSize + 1 ) ; assert ( firstChrSrcY > = lastInChrBuf - vChrBufSize + 1 ) ; DEBUG_BUFFERS ( dstY : %d\n , dstY ) ; DEBUG_BUFFERS ( \tfirstLumSrcY : %d lastLumSrcY : %d lastInLumBuf : %d\n , firstLumSrcY , lastLumSrcY , lastInLumBuf ) ; DEBUG_BUFFERS ( \tfirstChrSrcY : %d lastChrSrcY : %d lastInChrBuf : %d\n , firstChrSrcY , lastChrSrcY , lastInChrBuf ) ; // Do we have enough lines in this slice to output the dstY line enough_lines = lastLumSrcY2 < srcSliceY + srcSliceH & & lastChrSrcY < - ( ( - srcSliceY - srcSliceH ) > > c - > chrSrcVSubSample ) ; if ( ! enough_lines ) { lastLumSrcY = srcSliceY + srcSliceH - 1 ; lastChrSrcY = chrSrcSliceY + chrSrcSliceH - 1 ; DEBUG_BUFFERS ( buffering slice : lastLumSrcY %d lastChrSrcY %d\n , lastLumSrcY , lastChrSrcY ) ; } //Do horizontal scaling while ( lastInLumBuf < lastLumSrcY ) { const uint8_t * src1= src[0] + ( lastInLumBuf + 1 - srcSliceY ) * srcStride[0] ; const uint8_t * src2= src[3] + ( lastInLumBuf + 1 - srcSliceY ) * srcStride[3] ; lumBufIndex + + ; assert ( lumBufIndex < 2 * vLumBufSize ) ; assert ( lastInLumBuf + 1 - srcSliceY < srcSliceH ) ; assert ( lastInLumBuf + 1 - srcSliceY > = 0 ) ; hyscale ( c , lumPixBuf[ lumBufIndex ] , dstW , src1 , srcW , lumXInc , hLumFilter , hLumFilterPos , hLumFilterSize , formatConvBuffer , pal , 0 ) ; if ( CONFIG_SWSCALE_ALPHA & & alpPixBuf ) hyscale ( c , alpPixBuf[ lumBufIndex ] , dstW , src2 , srcW , lumXInc , hLumFilter , hLumFilterPos , hLumFilterSize , formatConvBuffer , pal , 1 ) ; lastInLumBuf + + ; DEBUG_BUFFERS ( \t\tlumBufIndex",0
"int sws_setColorspaceDetails ( struct SwsContext * c , const int inv_table[4] , int srcRange , const int table[4] , int dstRange , int brightness , int contrast , int saturation ) { const AVPixFmtDescriptor * desc_dst = av_pix_fmt_desc_get ( c - > dstFormat ) ; const AVPixFmtDescriptor * desc_src = av_pix_fmt_desc_get ( c - > srcFormat ) ; memcpy ( c - > srcColorspaceTable , inv_table , sizeof ( int ) * 4 ) ; memcpy ( c - > dstColorspaceTable , table , sizeof ( int ) * 4 ) ; c - > brightness = brightness ; c - > contrast = contrast ; c - > saturation = saturation ; c - > srcRange = srcRange ; c - > dstRange = dstRange ; if ( isYUV ( c - > dstFormat ) || isGray ( c - > dstFormat ) ) return - 1 ; c - > dstFormatBpp = av_get_bits_per_pixel ( desc_dst ) ; c - > srcFormatBpp = av_get_bits_per_pixel ( desc_src ) ; ff_yuv2rgb_c_init_tables ( c , inv_table , srcRange , brightness , contrast , saturation ) ; // FIXME factorize if ( HAVE_ALTIVEC & & av_get_cpu_flags ( ) & AV_CPU_FLAG_ALTIVEC ) ff_yuv2rgb_init_tables_altivec ( c , inv_table , brightness , contrast , saturation ) ; return 0 ; }",0
"static int submit_stats ( AVCodecContext * avctx ) { ifdef TH_ENCCTL_2PASS_IN TheoraContext * h = avctx - > priv_data ; int bytes ; if ( ! avctx - > stats_in ) { av_log ( avctx , AV_LOG_ERROR , No statsfile for second pass\n ) ; return AVERROR ( EINVAL ) ; h - > stats_size = strlen ( avctx - > stats_in ) * 3/4 ; h - > stats = av_malloc ( h - > stats_size ) ; h - > stats_size = av_base64_decode ( h - > stats , avctx - > stats_in , h - > stats_size ) ; while ( h - > stats_size - h - > stats_offset > 0 ) { bytes = th_encode_ctl ( h - > t_state , TH_ENCCTL_2PASS_IN , h - > stats + h - > stats_offset , h - > stats_size - h - > stats_offset ) ; if ( bytes < 0 ) { av_log ( avctx , AV_LOG_ERROR , Error submitting stats\n ) ; return AVERROR_EXTERNAL ; if ( ! bytes ) return 0 ; h - > stats_offset + = bytes ; return 0 ; else av_log ( avctx , AV_LOG_ERROR , libtheora too old to support 2pass\n ) ; return AVERROR ( ENOSUP ) ; endif",1
"static int encode_plane ( AVCodecContext * avctx , uint8_t * src , uint8_t * dst , int stride , int width , int height , PutByteContext * pb ) { UtvideoContext * c = avctx - > priv_data ; uint8_t lengths[256] ; uint64_t counts[256] = { 0 } ; HuffEntry he[256] ; uint32_t offset = 0 , slice_len = 0 ; int i , sstart , send = 0 ; int symbol ; / * Do prediction / make planes * / switch ( c - > frame_pred ) { case PRED_NONE : for ( i = 0 ; i < c - > slices ; i + + ) { sstart = send ; send = height * ( i + 1 ) / c - > slices ; write_plane ( src + sstart * stride , dst + sstart * width , stride , width , send - sstart ) ; } break ; case PRED_LEFT : for ( i = 0 ; i < c - > slices ; i + + ) { sstart = send ; send = height * ( i + 1 ) / c - > slices ; left_predict ( src + sstart * stride , dst + sstart * width , stride , width , send - sstart ) ; } break ; case PRED_MEDIAN : for ( i = 0 ; i < c - > slices ; i + + ) { sstart = send ; send = height * ( i + 1 ) / c - > slices ; median_predict ( c , src + sstart * stride , dst + sstart * width , stride , width , send - sstart ) ; } break ; default : av_log ( avctx , AV_LOG_ERROR , Unknown prediction mode : %d\n , c - > frame_pred ) ; return AVERROR_OPTION_NOT_FOUND ; } / * Count the usage of values * / count_usage ( dst , width , height , counts ) ; / * Check for a special case where only one symbol was used * / for ( symbol = 0 ; symbol < 256 ; symbol + + ) { / * If non - zero count is found , see if it matches width * height * / if ( counts[symbol] ) { / * Special case if only one symbol was used * / if ( counts[symbol] == width * height ) { / * * Write a zero for the single symbol * used in the plane , else 0xFF . * / for ( i = 0 ; i < 256 ; i + + ) { if ( i == symbol ) bytestream2_put_byte ( pb , 0 ) ; else bytestream2_put_byte ( pb , 0xFF ) ; } / * Write zeroes for lengths * / for ( i = 0 ; i < c - > slices ; i + + ) bytestream2_put_le32 ( pb , 0 ) ; / * And that ' s all for that plane folks * / return 0 ; } break ; } } / * Calculate huffman lengths * / ff_huff_gen_len_table ( lengths , counts ) ; / * * Write the plane ' s header into the output packet : * - huffman code lengths ( 256 bytes ) * - slice end offsets ( gotten from the slice lengths ) * / for ( i = 0 ; i < 256 ; i + + ) { bytestream2_put_byte ( pb , lengths[i] ) ; he[i] . len = lengths[i] ; he[i] . sym = i ; } / * Calculate the huffman codes themselves * / calculate_codes ( he ) ; send = 0 ; for ( i = 0 ; i < c - > slices ; i + + ) { sstart = send ; send = height * ( i + 1 ) / c - > slices ; / * * Write the huffman codes to a buffer , * get the offset in bits and convert to bytes . * / offset + = write_huff_codes ( dst + sstart * width , c - > slice_bits , width * ( send - sstart ) , width , send - sstart , he ) > > 3 ; slice_len = offset - slice_len ; / * Byteswap the written huffman codes * / c - > dsp . bswap_buf ( ( uint32_t * ) c - > slice_bits , ( uint32_t * ) c - > slice_bits , slice_len > > 2 ) ; / * Write the offset to the stream * / bytestream2_put_le32 ( pb , offset ) ; / * Seek to the data part of the packet * / bytestream2_seek_p ( pb , 4 * ( c - > slices - i - 1 ) + offset - slice_len , SEEK_CUR ) ; / * Write the slices ' data into the output packet * / bytestream2_put_buffer ( pb , c - > slice_bits , slice_len ) ; / * Seek back to the slice offsets * / bytestream2_seek_p ( pb , - 4 * ( c - > slices - i - 1 ) - offset , SEEK_CUR ) ; slice_len = offset ; } / * And at the end seek to the end of written slice ( s ) * / bytestream2_seek_p ( pb , offset , SEEK_CUR ) ; return 0 ; }",1
"static av_cold int g726_encode_init ( AVCodecContext * avctx ) { G726Context * c = avctx - > priv_data ; if ( avctx - > strict_std_compliance > FF_COMPLIANCE_UNOFFICIAL & & avctx - > sample_rate ! = 8000 ) { av_log ( avctx , AV_LOG_ERROR , Sample rates other than 8kHz are not allowed when the compliance level is higher than unofficial . Resample or reduce the compliance level . \n ) ; return AVERROR ( EINVAL ) ; } av_assert0 ( avctx - > sample_rate > 0 ) ; if ( avctx - > channels ! = 1 ) { av_log ( avctx , AV_LOG_ERROR , Only mono is supported\n ) ; return - 1 ; } if ( avctx - > bit_rate % avctx - > sample_rate ) { av_log ( avctx , AV_LOG_ERROR , Bitrate - Samplerate combination is invalid\n ) ; return AVERROR ( EINVAL ) ; } c - > code_size = ( avctx - > bit_rate + avctx - > sample_rate/2 ) / avctx - > sample_rate ; if ( c - > code_size < 2 || c - > code_size > 5 ) { av_log ( avctx , AV_LOG_ERROR , Invalid number of bits %d\n , c - > code_size ) ; return AVERROR ( EINVAL ) ; } avctx - > bits_per_coded_sample = c - > code_size ; g726_reset ( c , c - > code_size - 2 ) ; avctx - > coded_frame = avcodec_alloc_frame ( ) ; if ( ! avctx - > coded_frame ) return AVERROR ( ENOMEM ) ; avctx - > coded_frame - > key_frame = 1 ; / * select a frame size that will end on a byte boundary and have a size of approximately 1024 bytes * / avctx - > frame_size = ( ( int[] ) { 4096 , 2736 , 2048 , 1640 } ) [c - > code_size - 2] ; return 0 ; }",0
"static void write_audio_frame ( AVFormatContext * oc , AVStream * st ) { AVCodecContext * c ; AVPacket pkt = { 0 } ; // data and size must be 0 ; int got_packet , ret , dst_nb_samples ; av_init_packet ( & pkt ) ; c = st - > codec ; get_audio_frame ( ( int16_t * ) src_samples_data[0] , src_nb_samples , c - > channels ) ; / * convert samples from native format to destination codec format , using the resampler * / if ( swr_ctx ) { / * compute destination number of samples * / dst_nb_samples = av_rescale_rnd ( swr_get_delay ( swr_ctx , c - > sample_rate ) + src_nb_samples , c - > sample_rate , c - > sample_rate , AV_ROUND_UP ) ; if ( dst_nb_samples > max_dst_nb_samples ) { av_free ( dst_samples_data[0] ) ; ret = av_samples_alloc ( dst_samples_data , & dst_samples_linesize , c - > channels , dst_nb_samples , c - > sample_fmt , 0 ) ; if ( ret < 0 ) exit ( 1 ) ; max_dst_nb_samples = dst_nb_samples ; dst_samples_size = av_samples_get_buffer_size ( NULL , c - > channels , dst_nb_samples , c - > sample_fmt , 0 ) ; } / * convert to destination format * / ret = swr_convert ( swr_ctx , dst_samples_data , dst_nb_samples , ( const uint8_t * * ) src_samples_data , src_nb_samples ) ; if ( ret < 0 ) { fprintf ( stderr , Error while converting\n ) ; exit ( 1 ) ; } } else { dst_nb_samples = src_nb_samples ; } audio_frame - > nb_samples = dst_nb_samples ; audio_frame - > pts = av_rescale_q ( samples_count , ( AVRational ) { 1 , c - > sample_rate } , c - > time_base ) ; avcodec_fill_audio_frame ( audio_frame , c - > channels , c - > sample_fmt , dst_samples_data[0] , dst_samples_size , 0 ) ; samples_count + = dst_nb_samples ; ret = avcodec_encode_audio2 ( c , & pkt , audio_frame , & got_packet ) ; if ( ret < 0 ) { fprintf ( stderr , Error encoding audio frame : %s\n , av_err2str ( ret ) ) ; exit ( 1 ) ; } if ( ! got_packet ) return ; ret = write_frame ( oc , & c - > time_base , st , & pkt ) ; if ( ret ! = 0 ) { fprintf ( stderr , Error while writing audio frame : %s\n , av_err2str ( ret ) ) ; exit ( 1 ) ; } }",0
"static void RENAME ( hyscale_fast ) ( SwsContext * c , int16_t * dst , int dstWidth , const uint8_t * src , int srcW , int xInc ) { int16_t * filterPos = c - > hLumFilterPos ; int16_t * filter = c - > hLumFilter ; void * mmx2FilterCode= c - > lumMmx2FilterCode ; int i ; if defined ( PIC ) uint64_t ebxsave ; endif if ARCH_X86_64 uint64_t retsave ; endif __asm__ volatile ( if defined ( PIC ) mov %% REG_b , %5 \n\t if ARCH_X86_64 mov - 8 ( %%rsp ) , %% REG_a \n\t mov %% REG_a , %6 \n\t endif else if ARCH_X86_64 mov - 8 ( %%rsp ) , %% REG_a \n\t mov %% REG_a , %5 \n\t endif endif pxor %%mm7 , %%mm7 \n\t mov %0 , %% REG_c \n\t mov %1 , %% REG_D \n\t mov %2 , %% REG_d \n\t mov %3 , %% REG_b \n\t xor %% REG_a , %% REG_a \n\t // i PREFETCH ( %% REG_c ) \n\t PREFETCH 32 ( %% REG_c ) \n\t PREFETCH 64 ( %% REG_c ) \n\t if ARCH_X86_64 define CALL_MMX2_FILTER_CODE \ movl ( %% REG_b ) , %%esi \n\t \ call * %4 \n\t \ movl ( %% REG_b , %% REG_a ) , %%esi \n\t \ add %% REG_S , %% REG_c \n\t \ add %% REG_a , %% REG_D \n\t \ xor %% REG_a , %% REG_a \n\t \ else define CALL_MMX2_FILTER_CODE \ movl ( %% REG_b ) , %%esi \n\t \ call * %4 \n\t \ addl ( %% REG_b , %% REG_a ) , %% REG_c \n\t \ add %% REG_a , %% REG_D \n\t \ xor %% REG_a , %% REG_a \n\t \ endif / * ARCH_X86_64 * / CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE if defined ( PIC ) mov %5 , %% REG_b \n\t if ARCH_X86_64 mov %6 , %% REG_a \n\t mov %% REG_a , - 8 ( %%rsp ) \n\t endif else if ARCH_X86_64 mov %5 , %% REG_a \n\t mov %% REG_a , - 8 ( %%rsp ) \n\t endif endif : : m ( src ) , m ( dst ) , m ( filter ) , m ( filterPos ) , m ( mmx2FilterCode ) if defined ( PIC ) , m ( ebxsave ) endif if ARCH_X86_64 , m ( retsave ) endif : % REG_a , % REG_c , % REG_d , % REG_S , % REG_D if ! defined ( PIC ) , % REG_b endif ) ; for ( i=dstWidth - 1 ; ( i * xInc ) > > 16 > =srcW - 1 ; i - - ) dst[i] = src[srcW - 1] * 128 ; }",1
"static int decode_dc_progressive ( MJpegDecodeContext * s , int16_t * block , int component , int dc_index , uint16_t * quant_matrix , int Al ) { int val ; s - > bdsp . clear_block ( block ) ; val = mjpeg_decode_dc ( s , dc_index ) ; if ( val == 0xfffff ) { av_log ( s - > avctx , AV_LOG_ERROR , error dc\n ) ; return AVERROR_INVALIDDATA ; } val = ( val * ( quant_matrix[0] < < Al ) ) + s - > last_dc[component] ; s - > last_dc[component] = val ; block[0] = val ; return 0 ; }",1
"static void vp7_idct_add_c ( uint8_t * dst , int16_t block[16] , ptrdiff_t stride ) { int i , a1 , b1 , c1 , d1 ; int16_t tmp[16] ; for ( i = 0 ; i < 4 ; i + + ) { a1 = ( block[i * 4 + 0] + block[i * 4 + 2] ) * 23170 ; b1 = ( block[i * 4 + 0] - block[i * 4 + 2] ) * 23170 ; c1 = block[i * 4 + 1] * 12540 - block[i * 4 + 3] * 30274 ; d1 = block[i * 4 + 1] * 30274 + block[i * 4 + 3] * 12540 ; AV_ZERO64 ( block + i * 4 ) ; tmp[i * 4 + 0] = ( a1 + d1 ) > > 14 ; tmp[i * 4 + 3] = ( a1 - d1 ) > > 14 ; tmp[i * 4 + 1] = ( b1 + c1 ) > > 14 ; tmp[i * 4 + 2] = ( b1 - c1 ) > > 14 ; } for ( i = 0 ; i < 4 ; i + + ) { a1 = ( tmp[i + 0] + tmp[i + 8] ) * 23170 ; b1 = ( tmp[i + 0] - tmp[i + 8] ) * 23170 ; c1 = tmp[i + 4] * 12540 - tmp[i + 12] * 30274 ; d1 = tmp[i + 4] * 30274 + tmp[i + 12] * 12540 ; dst[0 * stride + i] = av_clip_uint8 ( dst[0 * stride + i] + ( ( a1 + d1 + 0x20000 ) > > 18 ) ) ; dst[3 * stride + i] = av_clip_uint8 ( dst[3 * stride + i] + ( ( a1 - d1 + 0x20000 ) > > 18 ) ) ; dst[1 * stride + i] = av_clip_uint8 ( dst[1 * stride + i] + ( ( b1 + c1 + 0x20000 ) > > 18 ) ) ; dst[2 * stride + i] = av_clip_uint8 ( dst[2 * stride + i] + ( ( b1 - c1 + 0x20000 ) > > 18 ) ) ; } }",1
"void ff_er_add_slice ( ERContext * s , int startx , int starty , int endx , int endy , int status ) { const int start_i = av_clip ( startx + starty * s - > mb_width , 0 , s - > mb_num - 1 ) ; const int end_i = av_clip ( endx + endy * s - > mb_width , 0 , s - > mb_num ) ; const int start_xy = s - > mb_index2xy[start_i] ; const int end_xy = s - > mb_index2xy[end_i] ; int mask = - 1 ; if ( s - > avctx - > hwaccel & & s - > avctx - > hwaccel - > decode_slice ) return ; if ( start_i > end_i || start_xy > end_xy ) { av_log ( s - > avctx , AV_LOG_ERROR , internal error , slice end before start\n ) ; return ; } if ( ! s - > avctx - > error_concealment ) return ; mask & = VP_START ; if ( status & ( ER_AC_ERROR | ER_AC_END ) ) { mask & = ( ER_AC_ERROR | ER_AC_END ) ; s - > error_count - = end_i - start_i + 1 ; } if ( status & ( ER_DC_ERROR | ER_DC_END ) ) { mask & = ( ER_DC_ERROR | ER_DC_END ) ; s - > error_count - = end_i - start_i + 1 ; } if ( status & ( ER_MV_ERROR | ER_MV_END ) ) { mask & = ( ER_MV_ERROR | ER_MV_END ) ; s - > error_count - = end_i - start_i + 1 ; } if ( status & ER_MB_ERROR ) { s - > error_occurred = 1 ; s - > error_count = INT_MAX ; } if ( mask == 0x7F ) { memset ( & s - > error_status_table[start_xy] , 0 , ( end_xy - start_xy ) * sizeof ( uint8_t ) ) ; } else { int i ; for ( i = start_xy ; i < end_xy ; i + + ) s - > error_status_table[i] & = mask ; } if ( end_i == s - > mb_num ) s - > error_count = INT_MAX ; else { s - > error_status_table[end_xy] & = mask ; s - > error_status_table[end_xy] |= status ; } s - > error_status_table[start_xy] |= VP_START ; if ( start_xy > 0 & & ! ( s - > avctx - > active_thread_type & FF_THREAD_SLICE ) & & er_supported ( s ) & & s - > avctx - > skip_top * s - > mb_width < start_i ) { int prev_status = s - > error_status_table[s - > mb_index2xy[start_i - 1]] ; prev_status & = VP_START ; if ( prev_status ! = ( ER_MV_END | ER_DC_END | ER_AC_END ) ) { s - > error_occurred = 1 ; s - > error_count = INT_MAX ; } } }",1
"static inline void RENAME ( yuv2yuvX ) ( SwsContext * c , const int16_t * lumFilter , const int16_t * * lumSrc , int lumFilterSize , const int16_t * chrFilter , const int16_t * * chrUSrc , const int16_t * * chrVSrc , int chrFilterSize , const int16_t * * alpSrc , uint8_t * dest , uint8_t * uDest , uint8_t * vDest , uint8_t * aDest , long dstW , long chrDstW ) { if ( uDest ) { YSCALEYUV2YV12X ( CHR_MMX_FILTER_OFFSET , uDest , chrDstW , 0 ) YSCALEYUV2YV12X ( CHR_MMX_FILTER_OFFSET , vDest , chrDstW + c - > uv_off , c - > uv_off ) } if ( CONFIG_SWSCALE_ALPHA & & aDest ) { YSCALEYUV2YV12X ( ALP_MMX_FILTER_OFFSET , aDest , dstW , 0 ) } YSCALEYUV2YV12X ( LUM_MMX_FILTER_OFFSET , dest , dstW , 0 ) }",1
AVFrame * avcodec_alloc_frame ( void ) { AVFrame * frame = av_malloc ( sizeof ( AVFrame ) ) ; if ( frame == NULL ) return NULL ; avcodec_get_frame_defaults ( frame ) ; return frame ; },1
"int av_cold ff_mlp_init_crc2D ( AVCodecParserContext * s ) { if ( ! crc_init_2D ) { av_crc_init ( crc_2D , 0 , 16 , 0x002D , sizeof ( crc_2D ) ) ; crc_init_2D = 1 ; } return 0 ; }",0
"static AVStream * add_av_stream1 ( FFServerStream * stream , AVCodecContext * codec , int copy ) { AVStream * fst ; if ( stream - > nb_streams > = FF_ARRAY_ELEMS ( stream - > streams ) ) return NULL ; fst = av_mallocz ( sizeof ( AVStream ) ) ; if ( ! fst ) return NULL ; if ( copy ) { fst - > codec = avcodec_alloc_context3 ( codec - > codec ) ; if ( ! fst - > codec ) { av_free ( fst ) ; return NULL ; } avcodec_copy_context ( fst - > codec , codec ) ; } else / * live streams must use the actual feed ' s codec since it may be * updated later to carry extradata needed by them . * / fst - > codec = codec ; fst - > priv_data = av_mallocz ( sizeof ( FeedData ) ) ; fst - > index = stream - > nb_streams ; avpriv_set_pts_info ( fst , 33 , 1 , 90000 ) ; fst - > sample_aspect_ratio = codec - > sample_aspect_ratio ; stream - > streams[stream - > nb_streams + + ] = fst ; return fst ; }",1
"static av_cold int vp3_decode_init ( AVCodecContext * avctx ) { Vp3DecodeContext * s = avctx - > priv_data ; int i , inter , plane ; int c_width ; int c_height ; int y_fragment_count , c_fragment_count ; if ( avctx - > codec_tag == MKTAG ( ' V ' , ' P ' , ' 3 ' , ' 0 ' ) ) s - > version = 0 ; else s - > version = 1 ; s - > avctx = avctx ; s - > width = FFALIGN ( avctx - > width , 16 ) ; s - > height = FFALIGN ( avctx - > height , 16 ) ; if ( avctx - > pix_fmt == PIX_FMT_NONE ) avctx - > pix_fmt = PIX_FMT_YUV420P ; avctx - > chroma_sample_location = AVCHROMA_LOC_CENTER ; if ( avctx - > idct_algo==FF_IDCT_AUTO ) avctx - > idct_algo=FF_IDCT_VP3 ; ff_dsputil_init ( & s - > dsp , avctx ) ; ff_init_scantable ( s - > dsp . idct_permutation , & s - > scantable , ff_zigzag_direct ) ; / * initialize to an impossible value which will force a recalculation * in the first frame decode * / for ( i = 0 ; i < 3 ; i + + ) s - > qps[i] = - 1 ; avcodec_get_chroma_sub_sample ( avctx - > pix_fmt , & s - > chroma_x_shift , & s - > chroma_y_shift ) ; s - > y_superblock_width = ( s - > width + 31 ) / 32 ; s - > y_superblock_height = ( s - > height + 31 ) / 32 ; s - > y_superblock_count = s - > y_superblock_width * s - > y_superblock_height ; / * work out the dimensions for the C planes * / c_width = s - > width > > s - > chroma_x_shift ; c_height = s - > height > > s - > chroma_y_shift ; s - > c_superblock_width = ( c_width + 31 ) / 32 ; s - > c_superblock_height = ( c_height + 31 ) / 32 ; s - > c_superblock_count = s - > c_superblock_width * s - > c_superblock_height ; s - > superblock_count = s - > y_superblock_count + ( s - > c_superblock_count * 2 ) ; s - > u_superblock_start = s - > y_superblock_count ; s - > v_superblock_start = s - > u_superblock_start + s - > c_superblock_count ; s - > macroblock_width = ( s - > width + 15 ) / 16 ; s - > macroblock_height = ( s - > height + 15 ) / 16 ; s - > macroblock_count = s - > macroblock_width * s - > macroblock_height ; s - > fragment_width[0] = s - > width / FRAGMENT_PIXELS ; s - > fragment_height[0] = s - > height / FRAGMENT_PIXELS ; s - > fragment_width[1] = s - > fragment_width[0] > > s - > chroma_x_shift ; s - > fragment_height[1] = s - > fragment_height[0] > > s - > chroma_y_shift ; / * fragment count covers all 8x8 blocks for all 3 planes * / y_fragment_count = s - > fragment_width[0] * s - > fragment_height[0] ; c_fragment_count = s - > fragment_width[1] * s - > fragment_height[1] ; s - > fragment_count = y_fragment_count + 2 * c_fragment_count ; s - > fragment_start[1] = y_fragment_count ; s - > fragment_start[2] = y_fragment_count + c_fragment_count ; if ( ! s - > theora_tables ) { for ( i = 0 ; i < 64 ; i + + ) { s - > coded_dc_scale_factor[i] = vp31_dc_scale_factor[i] ; s - > coded_ac_scale_factor[i] = vp31_ac_scale_factor[i] ; s - > base_matrix[0][i] = vp31_intra_y_dequant[i] ; s - > base_matrix[1][i] = vp31_intra_c_dequant[i] ; s - > base_matrix[2][i] = vp31_inter_dequant[i] ; s - > filter_limit_values[i] = vp31_filter_limit_values[i] ; } for ( inter=0 ; inter < 2 ; inter + + ) { for ( plane=0 ; plane < 3 ; plane + + ) { s - > qr_count[inter][plane]= 1 ; s - > qr_size [inter][plane][0]= 63 ; s - > qr_base [inter][plane][0]= s - > qr_base [inter][plane][1]= 2 * inter + ( ! ! plane ) * ! inter ; } } / * init VLC tables * / for ( i = 0 ; i < 16 ; i + + ) { / * DC histograms * / init_vlc ( & s - > dc_vlc[i] , 11 , 32 , & dc_bias[i][0][1] , 4 , 2 , & dc_bias[i][0][0] , 4 , 2 , 0 ) ; / * group 1 AC histograms * / init_vlc ( & s - > ac_vlc_1[i] , 11 , 32 , & ac_bias_0[i][0][1] , 4 , 2 , & ac_bias_0[i][0][0] , 4 , 2 , 0 ) ; / * group 2 AC histograms * / init_vlc ( & s - > ac_vlc_2[i] , 11 , 32 , & ac_bias_1[i][0][1] , 4 , 2 , & ac_bias_1[i][0][0] , 4 , 2 , 0 ) ; / * group 3 AC histograms * / init_vlc ( & s - > ac_vlc_3[i] , 11 , 32 , & ac_bias_2[i][0][1] , 4 , 2 , & ac_bias_2[i][0][0] , 4 , 2 , 0 ) ; / * group 4 AC histograms * / init_vlc ( & s - > ac_vlc_4[i] , 11 , 32 , & ac_bias_3[i][0][1] , 4 , 2 , & ac_bias_3[i][0][0] , 4 , 2 , 0 ) ; } } else { for ( i = 0 ; i < 16 ; i + + ) { / * DC histograms * / if ( init_vlc ( & s - > dc_vlc[i] , 11 , 32 , & s - > huffman_table[i][0][1] , 8 , 4 , & s - > huffman_table[i][0][0] , 8 , 4 , 0 ) < 0 ) goto vlc_fail ; / * group 1 AC histograms * / if ( init_vlc ( & s - > ac_vlc_1[i] , 11 , 32 , & s - > huffman_table[i + 16][0][1] , 8 , 4 , & s - > huffman_table[i + 16][0][0] , 8 , 4 , 0 ) < 0 ) goto vlc_fail ; / * group 2 AC histograms * / if ( init_vlc ( & s - > ac_vlc_2[i] , 11 , 32 , & s - > huffman_table[i + 16 * 2][0][1] , 8 , 4 , & s - > huffman_table[i + 16 * 2][0][0] , 8 , 4 , 0 ) < 0 ) goto vlc_fail ; / * group 3 AC histograms * / if ( init_vlc ( & s - > ac_vlc_3[i] , 11 , 32 , & s - > huffman_table[i + 16 * 3][0][1] , 8 , 4 , & s - > huffman_table[i + 16 * 3][0][0] , 8 , 4 , 0 ) < 0 ) goto vlc_fail ; / * group 4 AC histograms * / if ( init_vlc ( & s - > ac_vlc_4[i] , 11 , 32 , & s - > huffman_table[i + 16 * 4][0][1] , 8 , 4 , & s - > huffman_table[i + 16 * 4][0][0] , 8 ,",1
"static inline void RENAME ( bgr24ToUV ) ( uint8_t * dstU , uint8_t * dstV , uint8_t * src1 , uint8_t * src2 , long width ) { ifdef HAVE_MMX asm volatile ( mov %4 , %% REG_a \n\t movq MANGLE ( w1111 ) , %%mm5 \n\t movq MANGLE ( bgr2UCoeff ) , %%mm6 \n\t pxor %%mm7 , %%mm7 \n\t lea ( %% REG_a , %% REG_a , 2 ) , %% REG_b \n\t add %% REG_b , %% REG_b \n\t ASMALIGN16 1 : \n\t PREFETCH 64 ( %0 , %% REG_b ) \n\t PREFETCH 64 ( %1 , %% REG_b ) \n\t if defined ( HAVE_MMX2 ) || defined ( HAVE_3DNOW ) movq ( %0 , %% REG_b ) , %%mm0 \n\t movq ( %1 , %% REG_b ) , %%mm1 \n\t movq 6 ( %0 , %% REG_b ) , %%mm2 \n\t movq 6 ( %1 , %% REG_b ) , %%mm3 \n\t PAVGB ( %%mm1 , %%mm0 ) PAVGB ( %%mm3 , %%mm2 ) movq %%mm0 , %%mm1 \n\t movq %%mm2 , %%mm3 \n\t psrlq 24 , %%mm0 \n\t psrlq 24 , %%mm2 \n\t PAVGB ( %%mm1 , %%mm0 ) PAVGB ( %%mm3 , %%mm2 ) punpcklbw %%mm7 , %%mm0 \n\t punpcklbw %%mm7 , %%mm2 \n\t else movd ( %0 , %% REG_b ) , %%mm0 \n\t movd ( %1 , %% REG_b ) , %%mm1 \n\t movd 3 ( %0 , %% REG_b ) , %%mm2 \n\t movd 3 ( %1 , %% REG_b ) , %%mm3 \n\t punpcklbw %%mm7 , %%mm0 \n\t punpcklbw %%mm7 , %%mm1 \n\t punpcklbw %%mm7 , %%mm2 \n\t punpcklbw %%mm7 , %%mm3 \n\t paddw %%mm1 , %%mm0 \n\t paddw %%mm3 , %%mm2 \n\t paddw %%mm2 , %%mm0 \n\t movd 6 ( %0 , %% REG_b ) , %%mm4 \n\t movd 6 ( %1 , %% REG_b ) , %%mm1 \n\t movd 9 ( %0 , %% REG_b ) , %%mm2 \n\t movd 9 ( %1 , %% REG_b ) , %%mm3 \n\t punpcklbw %%mm7 , %%mm4 \n\t punpcklbw %%mm7 , %%mm1 \n\t punpcklbw %%mm7 , %%mm2 \n\t punpcklbw %%mm7 , %%mm3 \n\t paddw %%mm1 , %%mm4 \n\t paddw %%mm3 , %%mm2 \n\t paddw %%mm4 , %%mm2 \n\t psrlw 2 , %%mm0 \n\t psrlw 2 , %%mm2 \n\t endif movq MANGLE ( bgr2VCoeff ) , %%mm1 \n\t movq MANGLE ( bgr2VCoeff ) , %%mm3 \n\t pmaddwd %%mm0 , %%mm1 \n\t pmaddwd %%mm2 , %%mm3 \n\t pmaddwd %%mm6 , %%mm0 \n\t pmaddwd %%mm6 , %%mm2 \n\t ifndef FAST_BGR2YV12 psrad 8 , %%mm0 \n\t psrad 8 , %%mm1 \n\t psrad 8 , %%mm2 \n\t psrad 8 , %%mm3 \n\t endif packssdw %%mm2 , %%mm0 \n\t packssdw %%mm3 , %%mm1 \n\t pmaddwd %%mm5 , %%mm0 \n\t pmaddwd %%mm5 , %%mm1 \n\t packssdw %%mm1 , %%mm0 \n\t // V1 V0 U1 U0 psraw 7 , %%mm0 \n\t if defined ( HAVE_MMX2 ) || defined ( HAVE_3DNOW ) movq 12 ( %0 , %% REG_b ) , %%mm4 \n\t movq 12 ( %1 , %% REG_b ) , %%mm1 \n\t movq 18 ( %0 , %% REG_b ) , %%mm2 \n\t movq 18 ( %1 , %% REG_b ) , %%mm3 \n\t PAVGB ( %%mm1 , %%mm4 ) PAVGB ( %%mm3 , %%mm2 ) movq %%mm4 , %%mm1 \n\t movq %%mm2 , %%mm3 \n\t psrlq 24 , %%mm4 \n\t psrlq 24 , %%mm2 \n\t PAVGB ( %%mm1 , %%mm4 ) PAVGB ( %%mm3 , %%mm2 ) punpcklbw %%mm7 , %%mm4 \n\t punpcklbw %%mm7 , %%mm2 \n\t else movd 12 ( %0 , %% REG_b ) , %%mm4 \n\t movd 12 ( %1 , %% REG_b ) , %%mm1 \n\t movd 15 ( %0 , %% REG_b ) , %%mm2 \n\t movd 15 ( %1 , %% REG_b ) , %%mm3 \n\t punpcklbw %%mm7 , %%mm4 \n\t punpcklbw %%mm7 , %%mm1 \n\t punpcklbw %%mm7 , %%mm2 \n\t punpcklbw %%mm7 , %%mm3 \n\t paddw %%mm1 , %%mm4 \n\t paddw %%mm3 , %%mm2 \n\t paddw %%mm2 , %%mm4 \n\t movd 18 ( %0 , %% REG_b ) , %%mm5 \n\t movd 18 ( %1 , %% REG_b ) , %%mm1 \n\t movd 21 ( %0 , %% REG_b ) , %%mm2 \n\t movd 21 ( %1 , %% REG_b ) , %%mm3 \n\t punpcklbw %%mm7 , %%mm5 \n\t punpcklbw %%mm7 , %%mm1 \n\t punpcklbw %%mm7 , %%mm2 \n\t punpcklbw %%mm7 , %%mm3 \n\t paddw %%mm1 , %%mm5 \n\t paddw %%mm3 , %%mm2 \n\t paddw %%mm5 , %%mm2 \n\t movq MANGLE ( w1111 ) , %%mm5 \n\t psrlw 2 , %%mm4 \n\t psrlw 2 , %%mm2 \n\t endif movq MANGLE ( bgr2VCoeff ) , %%mm1 \n\t movq MANGLE ( bgr2VCoeff ) , %%mm3 \n\t pmaddwd %%mm4 , %%mm1 \n\t pmaddwd %%mm2 , %%mm3 \n\t pmaddwd %%mm6 , %%mm4 \n\t pmaddwd %%mm6 , %%mm2 \n\t ifndef FAST_BGR2YV12 psrad 8 , %%mm4 \n\t psrad 8 , %%mm1 \n\t psrad 8 , %%mm2 \n\t psrad 8 , %%mm3 \n\t endif packssdw %%mm2 , %%mm4 \n\t packssdw %%mm3 , %%mm1 \n\t pmaddwd %%mm5 , %%mm4 \n\t pmaddwd %%mm5 , %%mm1 \n\t add 24 , %% REG_b \n\t packssdw %%mm1 , %%mm4 \n\t // V3 V2 U3 U2 psraw 7 , %%mm4 \n\t movq %%mm0 , %%mm1 \n\t punpckldq %%mm4 , %%mm0 \n\t punpckhdq %%mm4 , %%mm1 \n\t packsswb %%mm1 , %%mm0 \n\t paddb MANGLE ( bgr2UVOffset ) , %%mm0 \n\t movd %%mm0 , ( %2 , %% REG_a ) \n\t punpckhdq %%mm0 , %%mm0 \n\t movd %%mm0 , ( %3 , %% REG_a ) \n\t add 4 , %% REG_a \n\t js 1b \n\t : : r ( src1 + width * 6 ) , r ( src2 + width * 6 ) , r ( dstU + width ) , r ( dstV + width ) , g ( - width ) : % REG_a , % REG_b ) ; else int i ; for ( i=0 ; i < width ; i + + ) { int b= src1[6 * i + 0] + src1[6 * i + 3] + src2[6 * i + 0] + src2[6 * i + 3] ; int g= src1[6 * i + 1] + src1[6 * i + 4] + src2[6 * i + 1] + src2[6 * i + 4] ; int r= src1[6 * i + 2] + src1[6 * i + 5] + src2[6 * i + 2] + src2[6 * i + 5] ; dstU[i]= ( ( RU * r + GU * g + BU * b ) > > ( RGB2YUV_SHIFT + 2 ) ) + 128 ; dstV[i]= ( ( RV * r + GV * g + BV * b ) > > ( RGB2YUV_SHIFT + 2 ) ) + 128 ; } endif }",0
"static av_cold int fbdev_write_header ( AVFormatContext * h ) { FBDevContext * fbdev = h - > priv_data ; enum AVPixelFormat pix_fmt ; AVStream * st = NULL ; int ret , flags = O_RDWR ; int i ; for ( i = 0 ; i < h - > nb_streams ; i + + ) { if ( h - > streams[i] - > codec - > codec_type == AVMEDIA_TYPE_VIDEO ) { if ( ! st ) { fbdev - > index = i ; st = h - > streams[i] ; } else { av_log ( h , AV_LOG_WARNING , More than one video stream found . First one is used . \n ) ; break ; } } } if ( ! st ) { av_log ( h , AV_LOG_ERROR , No video stream found . \n ) ; return AVERROR ( EINVAL ) ; } if ( ( fbdev - > fd = avpriv_open ( h - > filename , flags ) ) == - 1 ) { ret = AVERROR ( errno ) ; av_log ( h , AV_LOG_ERROR , Could not open framebuffer device ' %s ' : %s\n , h - > filename , av_err2str ( ret ) ) ; return ret ; } if ( ioctl ( fbdev - > fd , FBIOGET_VSCREENINFO , & fbdev - > varinfo ) < 0 ) { ret = AVERROR ( errno ) ; av_log ( h , AV_LOG_ERROR , FBIOGET_VSCREENINFO : %s\n , av_err2str ( ret ) ) ; goto fail ; } if ( ioctl ( fbdev - > fd , FBIOGET_FSCREENINFO , & fbdev - > fixinfo ) < 0 ) { ret = AVERROR ( errno ) ; av_log ( h , AV_LOG_ERROR , FBIOGET_FSCREENINFO : %s\n , av_err2str ( ret ) ) ; goto fail ; } pix_fmt = ff_get_pixfmt_from_fb_varinfo ( & fbdev - > varinfo ) ; if ( pix_fmt == AV_PIX_FMT_NONE ) { ret = AVERROR ( EINVAL ) ; av_log ( h , AV_LOG_ERROR , Framebuffer pixel format not supported . \n ) ; goto fail ; } fbdev - > data = mmap ( NULL , fbdev - > fixinfo . smem_len , PROT_WRITE , MAP_SHARED , fbdev - > fd , 0 ) ; if ( fbdev - > data == MAP_FAILED ) { ret = AVERROR ( errno ) ; av_log ( h , AV_LOG_ERROR , Error in mmap ( ) : %s\n , av_err2str ( ret ) ) ; goto fail ; } return 0 ; fail : close ( fbdev - > fd ) ; return ret ; }",0
"static int mov_write_hdlr_tag ( ByteIOContext * pb , MOVTrack * track ) { const char * descr , * hdlr , * hdlr_type ; int64_t pos = url_ftell ( pb ) ; if ( ! track ) { / * no media - - > data handler * / hdlr = dhlr ; hdlr_type = url ; descr = DataHandler ; } else { hdlr = ( track - > mode == MODE_MOV ) ? mhlr : \0\0\0\0 ; if ( track - > enc - > codec_type == CODEC_TYPE_VIDEO ) { hdlr_type = vide ; descr = VideoHandler ; } else if ( track - > enc - > codec_type == CODEC_TYPE_AUDIO ) { hdlr_type = soun ; descr = SoundHandler ; } else if ( track - > enc - > codec_type == CODEC_TYPE_SUBTITLE ) { if ( track - > mode == MODE_IPOD ) hdlr_type = sbtl ; else hdlr_type = text ; descr = SubtitleHandler ; } } put_be32 ( pb , 0 ) ; / * size * / put_tag ( pb , hdlr ) ; put_be32 ( pb , 0 ) ; / * Version & flags * / put_buffer ( pb , hdlr , 4 ) ; / * handler * / put_tag ( pb , hdlr_type ) ; / * handler type * / put_be32 ( pb , 0 ) ; / * reserved * / put_be32 ( pb , 0 ) ; / * reserved * / put_be32 ( pb , 0 ) ; / * reserved * / put_byte ( pb , strlen ( descr ) ) ; / * string counter * / put_buffer ( pb , descr , strlen ( descr ) ) ; / * handler description * / return updateSize ( pb , pos ) ; }",1
"static int swScale ( SwsContext * c , const uint8_t * src[] , int srcStride[] , int srcSliceY , int srcSliceH , uint8_t * dst[] , int dstStride[] ) { / * load a few things into local vars to make the code more readable ? * and faster * / const int srcW = c - > srcW ; const int dstW = c - > dstW ; const int dstH = c - > dstH ; const int chrDstW = c - > chrDstW ; const int chrSrcW = c - > chrSrcW ; const int lumXInc = c - > lumXInc ; const int chrXInc = c - > chrXInc ; const enum PixelFormat dstFormat = c - > dstFormat ; const int flags = c - > flags ; int32_t * vLumFilterPos = c - > vLumFilterPos ; int32_t * vChrFilterPos = c - > vChrFilterPos ; int32_t * hLumFilterPos = c - > hLumFilterPos ; int32_t * hChrFilterPos = c - > hChrFilterPos ; int16_t * vLumFilter = c - > vLumFilter ; int16_t * vChrFilter = c - > vChrFilter ; int16_t * hLumFilter = c - > hLumFilter ; int16_t * hChrFilter = c - > hChrFilter ; int32_t * lumMmxFilter = c - > lumMmxFilter ; int32_t * chrMmxFilter = c - > chrMmxFilter ; const int vLumFilterSize = c - > vLumFilterSize ; const int vChrFilterSize = c - > vChrFilterSize ; const int hLumFilterSize = c - > hLumFilterSize ; const int hChrFilterSize = c - > hChrFilterSize ; int16_t * * lumPixBuf = c - > lumPixBuf ; int16_t * * chrUPixBuf = c - > chrUPixBuf ; int16_t * * chrVPixBuf = c - > chrVPixBuf ; int16_t * * alpPixBuf = c - > alpPixBuf ; const int vLumBufSize = c - > vLumBufSize ; const int vChrBufSize = c - > vChrBufSize ; uint8_t * formatConvBuffer = c - > formatConvBuffer ; uint32_t * pal = c - > pal_yuv ; yuv2planar1_fn yuv2plane1 = c - > yuv2plane1 ; yuv2planarX_fn yuv2planeX = c - > yuv2planeX ; yuv2interleavedX_fn yuv2nv12cX = c - > yuv2nv12cX ; yuv2packed1_fn yuv2packed1 = c - > yuv2packed1 ; yuv2packed2_fn yuv2packed2 = c - > yuv2packed2 ; yuv2packedX_fn yuv2packedX = c - > yuv2packedX ; const int chrSrcSliceY = srcSliceY > > c - > chrSrcVSubSample ; const int chrSrcSliceH = - ( ( - srcSliceH ) > > c - > chrSrcVSubSample ) ; int should_dither = is9_OR_10BPS ( c - > srcFormat ) || is16BPS ( c - > srcFormat ) ; int lastDstY ; / * vars which will change and which we need to store back in the context * / int dstY = c - > dstY ; int lumBufIndex = c - > lumBufIndex ; int chrBufIndex = c - > chrBufIndex ; int lastInLumBuf = c - > lastInLumBuf ; int lastInChrBuf = c - > lastInChrBuf ; if ( isPacked ( c - > srcFormat ) ) { src[0] = src[1] = src[2] = src[3] = src[0] ; srcStride[0] = srcStride[1] = srcStride[2] = srcStride[3] = srcStride[0] ; } srcStride[1] < < = c - > vChrDrop ; srcStride[2] < < = c - > vChrDrop ; DEBUG_BUFFERS ( swScale ( ) %p[%d] %p[%d] %p[%d] %p[%d] - > %p[%d] %p[%d] %p[%d] %p[%d]\n , src[0] , srcStride[0] , src[1] , srcStride[1] , src[2] , srcStride[2] , src[3] , srcStride[3] , dst[0] , dstStride[0] , dst[1] , dstStride[1] , dst[2] , dstStride[2] , dst[3] , dstStride[3] ) ; DEBUG_BUFFERS ( srcSliceY : %d srcSliceH : %d dstY : %d dstH : %d\n , srcSliceY , srcSliceH , dstY , dstH ) ; DEBUG_BUFFERS ( vLumFilterSize : %d vLumBufSize : %d vChrFilterSize : %d vChrBufSize : %d\n , vLumFilterSize , vLumBufSize , vChrFilterSize , vChrBufSize ) ; if ( dstStride[0] % 8 ! = 0 || dstStride[1] % 8 ! = 0 || dstStride[2] % 8 ! = 0 || dstStride[3] % 8 ! = 0 ) { static int warnedAlready = 0 ; // FIXME maybe move this into the context if ( flags & SWS_PRINT_INFO & & ! warnedAlready ) { av_log ( c , AV_LOG_WARNING , Warning : dstStride is not aligned ! \n - > cannot do aligned memory accesses anymore\n ) ; warnedAlready = 1 ; } } / * Note the user might start scaling the picture in the middle so this * will not get executed . This is not really intended but works * currently , so people might do it . * / if ( srcSliceY == 0 ) { lumBufIndex = - 1 ; chrBufIndex = - 1 ; dstY = 0 ; lastInLumBuf = - 1 ; lastInChrBuf = - 1 ; } if ( ! should_dither ) { c - > chrDither8 = c - > lumDither8 = ff_sws_pb_64 ; } lastDstY = dstY ; for ( ; dstY < dstH ; dstY + + ) { const int chrDstY = dstY > > c - > chrDstVSubSample ; uint8_t * dest[4] = { dst[0] + dstStride[0] * dstY , dst[1] + dstStride[1] * chrDstY , dst[2] + dstStride[2] * chrDstY , ( CONFIG_SWSCALE_ALPHA & & alpPixBuf ) ? dst[3] + dstStride[3] * dstY : NULL , } ; // First line needed as input const int firstLumSrcY = FFMAX ( 1 - vLumFilterSize , vLumFilterPos[dstY] ) ; const int firstLumSrcY2 = FFMAX ( 1 - vLumFilterSize , vLumFilterPos[FFMIN ( dstY | ( ( 1 < < c - > chrDstVSubSample ) - 1 ) , dstH - 1 ) ] ) ; // First line needed as input const int firstChrSrcY = FFMAX ( 1 - vChrFilterSize , vChrFilterPos[chrDstY] ) ; // Last line needed as input int lastLumSrcY = FFMIN ( c - > srcH , firstLumSrcY + vLumFilterSize ) - 1 ; int lastLumSrcY2 = FFMIN ( c - > srcH , firstLumSrcY2 + vLumFilterSize ) - 1 ; int lastChrSrcY = FFMIN ( c - > chrSrcH , firstChrSrcY + vChrFilterSize ) - 1 ; int enough_lines ; // handle holes ( FAST_BILINEAR & weird filters ) if ( firstLumSrcY > lastInLumBuf ) lastInLumBuf = firstLumSrcY - 1 ; if ( firstChrSrcY > lastInChrBuf ) lastInChrBuf = firstChrSrcY - 1 ; assert ( firstLumSrcY > = lastInLumBuf - vLumBufSize + 1 ) ; assert ( firstChrSrcY > = lastInChrBuf - vChrBufSize + 1 ) ; DEBUG_BUFFERS ( dstY : %d\n , dstY ) ; DEBUG_BUFFERS ( \tfirstLumSrcY : %d lastLumSrcY : %d lastInLumBuf : %d\n , firstLumSrcY , lastLumSrcY , lastInLumBuf ) ; DEBUG_BUFFERS ( \tfirstChrSrcY : %d lastChrSrcY : %d lastInChrBuf : %d\n , firstChrSrcY , lastChrSrcY , lastInChrBuf ) ; // Do we have enough lines in this slice to output the dstY line enough_lines = lastLumSrcY2 < srcSliceY + srcSliceH & & lastChrSrcY < - ( ( - srcSliceY - srcSliceH ) > > c - > chrSrcVSubSample ) ; if ( ! enough_lines ) { lastLumSrcY = srcSliceY + srcSliceH - 1 ; lastChrSrcY = chrSrcSliceY + chrSrcSliceH - 1 ; DEBUG_BUFFERS ( buffering slice : lastLumSrcY %d lastChrSrcY %d\n , lastLumSrcY , lastChrSrcY ) ; }",0
"static inline int spx_strategy ( AC3DecodeContext * s , int blk ) { GetBitContext * bc = & s - > gbc ; int fbw_channels = s - > fbw_channels ; int dst_start_freq , dst_end_freq , src_start_freq , start_subband , end_subband , ch ; / * determine which channels use spx * / if ( s - > channel_mode == AC3_CHMODE_MONO ) { s - > channel_uses_spx[1] = 1 ; } else { for ( ch = 1 ; ch < = fbw_channels ; ch + + ) s - > channel_uses_spx[ch] = get_bits1 ( bc ) ; } / * get the frequency bins of the spx copy region and the spx start and end subbands * / dst_start_freq = get_bits ( bc , 2 ) ; start_subband = get_bits ( bc , 3 ) + 2 ; if ( start_subband > 7 ) start_subband + = start_subband - 7 ; end_subband = get_bits ( bc , 3 ) + 5 ; if USE_FIXED s - > spx_dst_end_freq = end_freq_inv_tab[end_subband - 5] ; endif if ( end_subband > 7 ) end_subband + = end_subband - 7 ; dst_start_freq = dst_start_freq * 12 + 25 ; src_start_freq = start_subband * 12 + 25 ; dst_end_freq = end_subband * 12 + 25 ; / * check validity of spx ranges * / if ( start_subband > = end_subband ) { av_log ( s - > avctx , AV_LOG_ERROR , invalid spectral extension range ( %d > = %d ) \n , start_subband , end_subband ) ; return AVERROR_INVALIDDATA ; } if ( dst_start_freq > = src_start_freq ) { av_log ( s - > avctx , AV_LOG_ERROR , invalid spectral extension copy start bin ( %d > = %d ) \n , dst_start_freq , src_start_freq ) ; return AVERROR_INVALIDDATA ; } s - > spx_dst_start_freq = dst_start_freq ; s - > spx_src_start_freq = src_start_freq ; if ( ! USE_FIXED ) s - > spx_dst_end_freq = dst_end_freq ; decode_band_structure ( bc , blk , s - > eac3 , 0 , start_subband , end_subband , ff_eac3_default_spx_band_struct , & s - > num_spx_bands , s - > spx_band_sizes ) ; return 0 ; }",1
"static void finalize_packet ( RTPDemuxContext * s , AVPacket * pkt , uint32_t timestamp ) { if ( s - > last_rtcp_ntp_time ! = AV_NOPTS_VALUE ) { int64_t addend ; int delta_timestamp ; / * compute pts from timestamp with received ntp_time * / delta_timestamp = timestamp - s - > last_rtcp_timestamp ; / * convert to the PTS timebase * / addend = av_rescale ( s - > last_rtcp_ntp_time - s - > first_rtcp_ntp_time , s - > st - > time_base . den , ( uint64_t ) s - > st - > time_base . num < < 32 ) ; pkt - > pts = addend + delta_timestamp ; } }",1
"static av_always_inline void decode_cabac_residual_internal ( H264Context * h , DCTELEM * block , int cat , int n , const uint8_t * scantable , const uint32_t * qmul , int max_coeff , int is_dc ) { static const int significant_coeff_flag_offset[2][6] = { { 105 + 0 , 105 + 15 , 105 + 29 , 105 + 44 , 105 + 47 , 402 } , { 277 + 0 , 277 + 15 , 277 + 29 , 277 + 44 , 277 + 47 , 436 } } ; static const int last_coeff_flag_offset[2][6] = { { 166 + 0 , 166 + 15 , 166 + 29 , 166 + 44 , 166 + 47 , 417 } , { 338 + 0 , 338 + 15 , 338 + 29 , 338 + 44 , 338 + 47 , 451 } } ; static const int coeff_abs_level_m1_offset[6] = { 227 + 0 , 227 + 10 , 227 + 20 , 227 + 30 , 227 + 39 , 426 } ; static const uint8_t significant_coeff_flag_offset_8x8[2][63] = { { 0 , 1 , 2 , 3 , 4 , 5 , 5 , 4 , 4 , 3 , 3 , 4 , 4 , 4 , 5 , 5 , 4 , 4 , 4 , 4 , 3 , 3 , 6 , 7 , 7 , 7 , 8 , 9 , 10 , 9 , 8 , 7 , 7 , 6 , 11 , 12 , 13 , 11 , 6 , 7 , 8 , 9 , 14 , 10 , 9 , 8 , 6 , 11 , 12 , 13 , 11 , 6 , 9 , 14 , 10 , 9 , 11 , 12 , 13 , 11 , 14 , 10 , 12 } , { 0 , 1 , 1 , 2 , 2 , 3 , 3 , 4 , 5 , 6 , 7 , 7 , 7 , 8 , 4 , 5 , 6 , 9 , 10 , 10 , 8 , 11 , 12 , 11 , 9 , 9 , 10 , 10 , 8 , 11 , 12 , 11 , 9 , 9 , 10 , 10 , 8 , 11 , 12 , 11 , 9 , 9 , 10 , 10 , 8 , 13 , 13 , 9 , 9 , 10 , 10 , 8 , 13 , 13 , 9 , 9 , 10 , 10 , 14 , 14 , 14 , 14 , 14 } } ; / * node ctx : 0 . . 3 : abslevel1 ( with abslevelgt1 == 0 ) . * 4 . . 7 : abslevelgt1 + 3 ( and abslevel1 doesn ' t matter ) . * map node ctx = > cabac ctx for level=1 * / static const uint8_t coeff_abs_level1_ctx[8] = { 1 , 2 , 3 , 4 , 0 , 0 , 0 , 0 } ; / * map node ctx = > cabac ctx for level > 1 * / static const uint8_t coeff_abs_levelgt1_ctx[8] = { 5 , 5 , 5 , 5 , 6 , 7 , 8 , 9 } ; static const uint8_t coeff_abs_level_transition[2][8] = { / * update node ctx after decoding a level=1 * / { 1 , 2 , 3 , 3 , 4 , 5 , 6 , 7 } , / * update node ctx after decoding a level > 1 * / { 4 , 4 , 4 , 4 , 5 , 6 , 7 , 7 } } ; int index[64] ; int av_unused last ; int coeff_count = 0 ; int node_ctx = 0 ; uint8_t * significant_coeff_ctx_base ; uint8_t * last_coeff_ctx_base ; uint8_t * abs_level_m1_ctx_base ; ifndef ARCH_X86 define CABAC_ON_STACK endif ifdef CABAC_ON_STACK define CC & cc CABACContext cc ; cc . range = h - > cabac . range ; cc . low = h - > cabac . low ; cc . bytestream= h - > cabac . bytestream ; else define CC & h - > cabac endif / * cat : 0 - > DC 16x16 n = 0 * 1 - > AC 16x16 n = luma4x4idx * 2 - > Luma4x4 n = luma4x4idx * 3 - > DC Chroma n = iCbCr * 4 - > AC Chroma n = 4 * iCbCr + chroma4x4idx * 5 - > Luma8x8 n = 4 * luma8x8idx * / / * read coded block flag * / if ( is_dc || cat ! = 5 ) { if ( get_cabac ( CC , & h - > cabac_state[85 + get_cabac_cbf_ctx ( h , cat , n , is_dc ) ] ) == 0 ) { if ( ! is_dc ) { if ( cat == 1 || cat == 2 ) h - > non_zero_count_cache[scan8[n]] = 0 ; else h - > non_zero_count_cache[scan8[16 + n]] = 0 ; } ifdef CABAC_ON_STACK h - > cabac . range = cc . range ; h - > cabac . low = cc . low ; h - > cabac . bytestream= cc . bytestream ; endif return ; } } significant_coeff_ctx_base = h - > cabac_state + significant_coeff_flag_offset[MB_FIELD][cat] ; last_coeff_ctx_base = h - > cabac_state + last_coeff_flag_offset[MB_FIELD][cat] ; abs_level_m1_ctx_base = h - > cabac_state + coeff_abs_level_m1_offset[cat] ; if ( ! is_dc & & cat == 5 ) { define DECODE_SIGNIFICANCE ( coefs , sig_off , last_off ) \ for ( last= 0 ; last < coefs ; last + + ) { \ uint8_t * sig_ctx = significant_coeff_ctx_base + sig_off ; \ if ( get_cabac ( CC , sig_ctx ) ) { \ uint8_t * last_ctx = last_coeff_ctx_base + last_off ; \ index[coeff_count + + ] = last ; \ if ( get_cabac ( CC , last_ctx ) ) { \ last= max_coeff ; \ break ; \ } \ } \ } \ if ( last == max_coeff - 1 ) { \ index[coeff_count + + ] = last ; \ } const uint8_t * sig_off = significant_coeff_flag_offset_8x8[MB_FIELD] ; if defined ( ARCH_X86 ) & & defined ( HAVE_7REGS ) & & defined ( HAVE_EBX_AVAILABLE ) & & ! defined ( BROKEN_RELOCATIONS ) coeff_count= decode_significance_8x8_x86 ( CC , significant_coeff_ctx_base , index , sig_off ) ; } else { coeff_count= decode_significance_x86 ( CC , max_coeff , significant_coeff_ctx_base , index ) ; else DECODE_SIGNIFICANCE ( 63 , sig_off[last] , last_coeff_flag_offset_8x8[last] ) ; } else { DECODE_SIGNIFICANCE ( max_coeff - 1 , last , last ) ; endif } assert ( coeff_count > 0 ) ; if ( is_dc ) { if ( cat == 0 ) h - > cbp_table[h - > mb_xy] |= 0x100 ; else h - > cbp_table[h - > mb_xy] |= 0x40 < < n ; } else { if ( cat == 1 || cat == 2 ) h - > non_zero_count_cache[scan8[n]] = coeff_count ; else if ( cat == 4 ) h - > non_zero_count_cache[scan8[16 + n]] = coeff_count ; else { assert ( cat == 5 ) ; fill_rectangle ( & h - >",0
"static void h264_v_loop_filter_chroma_intra_c ( uint8_t * pix , int stride , int alpha , int beta ) { h264_loop_filter_chroma_intra_c ( pix , stride , 1 , alpha , beta ) ; }",0
"static void mpc8_parse_seektable ( AVFormatContext * s , int64_t off ) { MPCContext * c = s - > priv_data ; int tag ; int64_t size , pos , ppos[2] ; uint8_t * buf ; int i , t , seekd ; GetBitContext gb ; if ( s - > nb_streams == 0 ) { av_log ( s , AV_LOG_ERROR , No stream added before parsing seek table\n ) ; return ; } avio_seek ( s - > pb , off , SEEK_SET ) ; mpc8_get_chunk_header ( s - > pb , & tag , & size ) ; if ( tag ! = TAG_SEEKTABLE ) { av_log ( s , AV_LOG_ERROR , No seek table at given position\n ) ; return ; } if ( size > INT_MAX/10 || size < =0 ) { av_log ( s , AV_LOG_ERROR , Bad seek table size\n ) ; return ; } if ( ! ( buf = av_malloc ( size + FF_INPUT_BUFFER_PADDING_SIZE ) ) ) return ; avio_read ( s - > pb , buf , size ) ; memset ( buf + size , 0 , FF_INPUT_BUFFER_PADDING_SIZE ) ; init_get_bits ( & gb , buf , size * 8 ) ; size = gb_get_v ( & gb ) ; if ( size > UINT_MAX/4 || size > c - > samples/1152 ) { av_log ( s , AV_LOG_ERROR , Seek table is too big\n ) ; return ; } seekd = get_bits ( & gb , 4 ) ; for ( i = 0 ; i < 2 ; i + + ) { pos = gb_get_v ( & gb ) + c - > header_pos ; ppos[1 - i] = pos ; av_add_index_entry ( s - > streams[0] , pos , i , 0 , 0 , AVINDEX_KEYFRAME ) ; } for ( ; i < size ; i + + ) { t = get_unary ( & gb , 1 , 33 ) < < 12 ; t + = get_bits ( & gb , 12 ) ; if ( t & 1 ) t = - ( t & 1 ) ; pos = ( t > > 1 ) + ppos[0] * 2 - ppos[1] ; av_add_index_entry ( s - > streams[0] , pos , i < < seekd , 0 , 0 , AVINDEX_KEYFRAME ) ; ppos[1] = ppos[0] ; ppos[0] = pos ; } av_free ( buf ) ; }",0
"static av_always_inline int small_diamond_search ( MpegEncContext * s , int * best , int dmin , int src_index , int ref_index , int const penalty_factor , int size , int h , int flags ) { MotionEstContext * const c= & s - > me ; me_cmp_func cmpf , chroma_cmpf ; int next_dir= - 1 ; LOAD_COMMON LOAD_COMMON2 unsigned map_generation = c - > map_generation ; cmpf = s - > mecc . me_cmp[size] ; chroma_cmpf = s - > mecc . me_cmp[size + 1] ; { / * ensure that the best point is in the MAP as h/qpel refinement needs it * / const unsigned key = ( best[1] < < ME_MAP_MV_BITS ) + best[0] + map_generation ; const int index= ( ( best[1] < < ME_MAP_SHIFT ) + best[0] ) & ( ME_MAP_SIZE - 1 ) ; if ( map[index] ! =key ) { //this will be executed only very rarey score_map[index]= cmp ( s , best[0] , best[1] , 0 , 0 , size , h , ref_index , src_index , cmpf , chroma_cmpf , flags ) ; map[index]= key ; } } for ( ; ; ) { int d ; const int dir= next_dir ; const int x= best[0] ; const int y= best[1] ; next_dir= - 1 ; if ( dir ! =2 & & x > xmin ) CHECK_MV_DIR ( x - 1 , y , 0 ) if ( dir ! =3 & & y > ymin ) CHECK_MV_DIR ( x , y - 1 , 1 ) if ( dir ! =0 & & x < xmax ) CHECK_MV_DIR ( x + 1 , y , 2 ) if ( dir ! =1 & & y < ymax ) CHECK_MV_DIR ( x , y + 1 , 3 ) if ( next_dir== - 1 ) { return dmin ; } } }",1
"static void opt_frame_aspect_ratio ( const char * arg ) { int x = 0 , y = 0 ; double ar = 0 ; const char * p ; char * end ; p = strchr ( arg , ' : ' ) ; if ( p ) { x = strtol ( arg , & end , 10 ) ; if ( end == p ) y = strtol ( end + 1 , & end , 10 ) ; if ( x > 0 & & y > 0 ) ar = ( double ) x / ( double ) y ; } else ar = strtod ( arg , NULL ) ; if ( ! ar ) { fprintf ( stderr , Incorrect aspect ratio specification . \n ) ; ffmpeg_exit ( 1 ) ; } frame_aspect_ratio = ar ; x = vfilters ? strlen ( vfilters ) : 0 ; vfilters = av_realloc ( vfilters , x + 100 ) ; snprintf ( vfilters + x , x + 100 , %csetdar=%f\n , x ? ' , ' : ' ' , ar ) ; }",1
"static int ftp_features ( FTPContext * s ) { static const char * feat_command = FEAT\r\n ; static const char * enable_utf8_command = OPTS UTF8 ON\r\n ; static const int feat_codes[] = { 211 , 0 } ; static const int opts_codes[] = { 200 , 451 } ; char * feat ; if ( ftp_send_command ( s , feat_command , feat_codes , & feat ) == 211 ) { if ( av_stristr ( feat , UTF8 ) ) ftp_send_command ( s , enable_utf8_command , opts_codes , NULL ) ; } return 0 ; }",1
"static int tcp_write ( URLContext * h , uint8_t * buf , int size ) { TCPContext * s = h - > priv_data ; int ret , size1 , fd_max ; fd_set wfds ; struct timeval tv ; size1 = size ; while ( size > 0 ) { if ( url_interrupt_cb ( ) ) return - EINTR ; fd_max = s - > fd ; FD_ZERO ( & wfds ) ; FD_SET ( s - > fd , & wfds ) ; tv . tv_sec = 0 ; tv . tv_usec = 100 * 1000 ; select ( fd_max + 1 , NULL , & wfds , NULL , & tv ) ; ifdef __BEOS__ ret = send ( s - > fd , buf , size , 0 ) ; else ret = write ( s - > fd , buf , size ) ; endif if ( ret < 0 ) { if ( errno ! = EINTR & & errno ! = EAGAIN ) { ifdef __BEOS__ return errno ; else return - errno ; endif } continue ; } size - = ret ; buf + = ret ; } return size1 - size ; }",0
static av_cold int mm_decode_init ( AVCodecContext * avctx ) { MmContext * s = avctx - > priv_data ; s - > avctx = avctx ; avctx - > pix_fmt = AV_PIX_FMT_PAL8 ; s - > frame = av_frame_alloc ( ) ; if ( ! s - > frame ) return AVERROR ( ENOMEM ) ; return 0 ;,1
"static int split_init ( AVFilterContext * ctx , const char * args , void * opaque ) { int i , nb_outputs = 2 ; if ( args ) { nb_outputs = strtol ( args , NULL , 0 ) ; if ( nb_outputs < = 0 ) { av_log ( ctx , AV_LOG_ERROR , Invalid number of outputs specified : %d . \n , nb_outputs ) ; return AVERROR ( EINVAL ) ; } } for ( i = 0 ; i < nb_outputs ; i + + ) { char name[32] ; AVFilterPad pad = { 0 } ; snprintf ( name , sizeof ( name ) , output%d , i ) ; pad . type = ! strcmp ( ctx - > name , split ) ? AVMEDIA_TYPE_VIDEO : AVMEDIA_TYPE_AUDIO ; pad . name = av_strdup ( name ) ; avfilter_insert_outpad ( ctx , i , & pad ) ; } return 0 ; }",0
"static int ffserver_apply_stream_config ( AVCodecContext * enc , const AVDictionary * conf , AVDictionary * * opts ) { AVDictionaryEntry * e ; int ret = 0 ; / * Return values from ffserver_set_ * _param are ignored . Values are initially parsed and checked before inserting to AVDictionary . * / //video params if ( ( e = av_dict_get ( conf , VideoBitRateRangeMin , NULL , 0 ) ) ) ffserver_set_int_param ( & enc - > rc_min_rate , e - > value , 1000 , INT_MIN , INT_MAX , NULL , 0 , NULL ) ; if ( ( e = av_dict_get ( conf , VideoBitRateRangeMax , NULL , 0 ) ) ) ffserver_set_int_param ( & enc - > rc_max_rate , e - > value , 1000 , INT_MIN , INT_MAX , NULL , 0 , NULL ) ; if ( ( e = av_dict_get ( conf , Debug , NULL , 0 ) ) ) ffserver_set_int_param ( & enc - > debug , e - > value , 0 , INT_MIN , INT_MAX , NULL , 0 , NULL ) ; if ( ( e = av_dict_get ( conf , Strict , NULL , 0 ) ) ) ffserver_set_int_param ( & enc - > strict_std_compliance , e - > value , 0 , INT_MIN , INT_MAX , NULL , 0 , NULL ) ; if ( ( e = av_dict_get ( conf , VideoBufferSize , NULL , 0 ) ) ) ffserver_set_int_param ( & enc - > rc_buffer_size , e - > value , 8 * 1024 , INT_MIN , INT_MAX , NULL , 0 , NULL ) ; if ( ( e = av_dict_get ( conf , VideoBitRateTolerance , NULL , 0 ) ) ) ffserver_set_int_param ( & enc - > bit_rate_tolerance , e - > value , 1000 , INT_MIN , INT_MAX , NULL , 0 , NULL ) ; if ( ( e = av_dict_get ( conf , VideoBitRate , NULL , 0 ) ) ) ffserver_set_int_param ( & enc - > bit_rate , e - > value , 1000 , INT_MIN , INT_MAX , NULL , 0 , NULL ) ; if ( ( e = av_dict_get ( conf , VideoSizeWidth , NULL , 0 ) ) ) ffserver_set_int_param ( & enc - > width , e - > value , 0 , INT_MIN , INT_MAX , NULL , 0 , NULL ) ; if ( ( e = av_dict_get ( conf , VideoSizeHeight , NULL , 0 ) ) ) ffserver_set_int_param ( & enc - > height , e - > value , 0 , INT_MIN , INT_MAX , NULL , 0 , NULL ) ; if ( ( e = av_dict_get ( conf , PixelFormat , NULL , 0 ) ) ) { int val ; ffserver_set_int_param ( & val , e - > value , 0 , INT_MIN , INT_MAX , NULL , 0 , NULL ) ; enc - > pix_fmt = val ; } if ( ( e = av_dict_get ( conf , VideoGopSize , NULL , 0 ) ) ) ffserver_set_int_param ( & enc - > gop_size , e - > value , 0 , INT_MIN , INT_MAX , NULL , 0 , NULL ) ; if ( ( e = av_dict_get ( conf , VideoFrameRateNum , NULL , 0 ) ) ) ffserver_set_int_param ( & enc - > time_base . num , e - > value , 0 , INT_MIN , INT_MAX , NULL , 0 , NULL ) ; if ( ( e = av_dict_get ( conf , VideoFrameRateDen , NULL , 0 ) ) ) ffserver_set_int_param ( & enc - > time_base . den , e - > value , 0 , INT_MIN , INT_MAX , NULL , 0 , NULL ) ; if ( ( e = av_dict_get ( conf , VideoQDiff , NULL , 0 ) ) ) ffserver_set_int_param ( & enc - > max_qdiff , e - > value , 0 , INT_MIN , INT_MAX , NULL , 0 , NULL ) ; if ( ( e = av_dict_get ( conf , VideoQMax , NULL , 0 ) ) ) ffserver_set_int_param ( & enc - > qmax , e - > value , 0 , INT_MIN , INT_MAX , NULL , 0 , NULL ) ; if ( ( e = av_dict_get ( conf , VideoQMin , NULL , 0 ) ) ) ffserver_set_int_param ( & enc - > qmin , e - > value , 0 , INT_MIN , INT_MAX , NULL , 0 , NULL ) ; if ( ( e = av_dict_get ( conf , LumiMask , NULL , 0 ) ) ) ffserver_set_float_param ( & enc - > lumi_masking , e - > value , 0 , - FLT_MAX , FLT_MAX , NULL , 0 , NULL ) ; if ( ( e = av_dict_get ( conf , DarkMask , NULL , 0 ) ) ) ffserver_set_float_param ( & enc - > dark_masking , e - > value , 0 , - FLT_MAX , FLT_MAX , NULL , 0 , NULL ) ; if ( av_dict_get ( conf , BitExact , NULL , 0 ) ) enc - > flags |= CODEC_FLAG_BITEXACT ; if ( av_dict_get ( conf , DctFastint , NULL , 0 ) ) enc - > dct_algo = FF_DCT_FASTINT ; if ( av_dict_get ( conf , IdctSimple , NULL , 0 ) ) enc - > idct_algo = FF_IDCT_SIMPLE ; if ( av_dict_get ( conf , VideoHighQuality , NULL , 0 ) ) enc - > mb_decision = FF_MB_DECISION_BITS ; if ( ( e = av_dict_get ( conf , VideoTag , NULL , 0 ) ) ) enc - > codec_tag = MKTAG ( e - > value[0] , e - > value[1] , e - > value[2] , e - > value[3] ) ; if ( av_dict_get ( conf , Qscale , NULL , 0 ) ) { enc - > flags |= CODEC_FLAG_QSCALE ; ffserver_set_int_param ( & enc - > global_quality , e - > value , FF_QP2LAMBDA , INT_MIN , INT_MAX , NULL , 0 , NULL ) ; } if ( av_dict_get ( conf , Video4MotionVector , NULL , 0 ) ) { enc - > mb_decision = FF_MB_DECISION_BITS ; //FIXME remove enc - > flags |= CODEC_FLAG_4MV ; } //audio params if ( ( e = av_dict_get ( conf , AudioChannels , NULL , 0 ) ) ) ffserver_set_int_param ( & enc - > channels , e - > value , 0 , INT_MIN , INT_MAX , NULL , 0 , NULL ) ; if ( ( e = av_dict_get ( conf , AudioSampleRate , NULL , 0 ) ) ) ffserver_set_int_param ( & enc - > sample_rate , e - > value , 0 , INT_MIN , INT_MAX , NULL , 0 , NULL ) ; if ( ( e = av_dict_get ( conf , AudioBitRate , NULL , 0 ) ) ) ffserver_set_int_param ( & enc - > bit_rate , e - > value , 0 , INT_MIN , INT_MAX , NULL , 0 , NULL ) ; av_opt_set_dict2 ( enc , opts , AV_OPT_SEARCH_CHILDREN ) ; e = NULL ; while ( e = av_dict_get ( *",0
"static int amf_parse_object ( AVFormatContext * s , AVStream * astream , AVStream * vstream , const char * key , unsigned int max_pos , int depth ) { AVCodecContext * acodec , * vcodec ; ByteIOContext * ioc ; AMFDataType amf_type ; char str_val[256] ; double num_val ; num_val = 0 ; ioc = s - > pb ; amf_type = get_byte ( ioc ) ; switch ( amf_type ) { case AMF_DATA_TYPE_NUMBER : num_val = av_int2dbl ( get_be64 ( ioc ) ) ; break ; case AMF_DATA_TYPE_BOOL : num_val = get_byte ( ioc ) ; break ; case AMF_DATA_TYPE_STRING : if ( amf_get_string ( ioc , str_val , sizeof ( str_val ) ) < 0 ) return - 1 ; break ; case AMF_DATA_TYPE_OBJECT : { unsigned int keylen ; while ( url_ftell ( ioc ) < max_pos - 2 & & ( keylen = get_be16 ( ioc ) ) ) { url_fskip ( ioc , keylen ) ; //skip key string if ( amf_parse_object ( s , NULL , NULL , NULL , max_pos , depth + 1 ) < 0 ) return - 1 ; //if we couldn ' t skip , bomb out . } if ( get_byte ( ioc ) ! = AMF_END_OF_OBJECT ) return - 1 ; } break ; case AMF_DATA_TYPE_NULL : case AMF_DATA_TYPE_UNDEFINED : case AMF_DATA_TYPE_UNSUPPORTED : break ; //these take up no additional space case AMF_DATA_TYPE_MIXEDARRAY : url_fskip ( ioc , 4 ) ; //skip 32 - bit max array index while ( url_ftell ( ioc ) < max_pos - 2 & & amf_get_string ( ioc , str_val , sizeof ( str_val ) ) > 0 ) { //this is the only case in which we would want a nested parse to not skip over the object if ( amf_parse_object ( s , astream , vstream , str_val , max_pos , depth + 1 ) < 0 ) return - 1 ; } if ( get_byte ( ioc ) ! = AMF_END_OF_OBJECT ) return - 1 ; break ; case AMF_DATA_TYPE_ARRAY : { unsigned int arraylen , i ; arraylen = get_be32 ( ioc ) ; for ( i = 0 ; i < arraylen & & url_ftell ( ioc ) < max_pos - 1 ; i + + ) { if ( amf_parse_object ( s , NULL , NULL , NULL , max_pos , depth + 1 ) < 0 ) return - 1 ; //if we couldn ' t skip , bomb out . } } break ; case AMF_DATA_TYPE_DATE : url_fskip ( ioc , 8 + 2 ) ; //timestamp ( double ) and UTC offset ( int16 ) break ; default : //unsupported type , we couldn ' t skip return - 1 ; } if ( depth == 1 & & key ) { //only look for metadata values when we are not nested and key ! = NULL acodec = astream ? astream - > codec : NULL ; vcodec = vstream ? vstream - > codec : NULL ; if ( amf_type == AMF_DATA_TYPE_BOOL ) { if ( ! strcmp ( key , stereo ) & & acodec ) acodec - > channels = num_val > 0 ? 2 : 1 ; } else if ( amf_type == AMF_DATA_TYPE_NUMBER ) { if ( ! strcmp ( key , duration ) ) s - > duration = num_val * AV_TIME_BASE ; // else if ( ! strcmp ( key , width ) & & vcodec & & num_val > 0 ) vcodec - > width = num_val ; // else if ( ! strcmp ( key , height ) & & vcodec & & num_val > 0 ) vcodec - > height = num_val ; else if ( ! strcmp ( key , audiocodecid ) & & acodec ) flv_set_audio_codec ( s , astream , ( int ) num_val < < FLV_AUDIO_CODECID_OFFSET ) ; else if ( ! strcmp ( key , videocodecid ) & & vcodec ) flv_set_video_codec ( s , vstream , ( int ) num_val ) ; else if ( ! strcmp ( key , audiosamplesize ) & & acodec & & num_val > = 0 ) { acodec - > bits_per_sample = num_val ; //we may have to rewrite a previously read codecid because FLV only marks PCM endianness . if ( num_val == 8 & & ( acodec - > codec_id == CODEC_ID_PCM_S16BE || acodec - > codec_id == CODEC_ID_PCM_S16LE ) ) acodec - > codec_id = CODEC_ID_PCM_S8 ; } else if ( ! strcmp ( key , audiosamplerate ) & & acodec & & num_val > = 0 ) { //some tools , like FLVTool2 , write consistently approximate metadata sample rates if ( ! acodec - > sample_rate ) { switch ( ( int ) num_val ) { case 44000 : acodec - > sample_rate = 44100 ; break ; case 22000 : acodec - > sample_rate = 22050 ; break ; case 11000 : acodec - > sample_rate = 11025 ; break ; case 5000 : acodec - > sample_rate = 5512 ; break ; default : acodec - > sample_rate = num_val ; } } } } } return 0 ; }",0
"static void draw_slice ( AVFilterLink * link , int y , int h ) { ScaleContext * scale = link - > dst - > priv ; int out_h ; AVFilterPicRef * cur_pic = link - > cur_pic ; uint8_t * data[4] ; if ( ! scale - > slice_dir ) { if ( y ! = 0 & & y + h ! = link - > h ) { av_log ( scale , AV_LOG_ERROR , Slices start in the middle ! \n ) ; return ; } scale - > slice_dir = y ? - 1 : 1 ; scale - > slice_y = y ? link - > dst - > outputs[0] - > h : y ; } data[0] = cur_pic - > data[0] + y * cur_pic - > linesize[0] ; data[1] = scale - > input_is_pal ? cur_pic - > data[1] : cur_pic - > data[1] + ( y > > scale - > vsub ) * cur_pic - > linesize[1] ; data[2] = cur_pic - > data[2] + ( y > > scale - > vsub ) * cur_pic - > linesize[2] ; data[3] = cur_pic - > data[3] + y * cur_pic - > linesize[3] ; out_h = sws_scale ( scale - > sws , data , cur_pic - > linesize , y , h , link - > dst - > outputs[0] - > outpic - > data , link - > dst - > outputs[0] - > outpic - > linesize ) ; if ( scale - > slice_dir == - 1 ) scale - > slice_y - = out_h ; avfilter_draw_slice ( link - > dst - > outputs[0] , scale - > slice_y , out_h ) ; if ( scale - > slice_dir == 1 ) scale - > slice_y + = out_h ; }",0
"static int join_request_frame ( AVFilterLink * outlink ) { AVFilterContext * ctx = outlink - > src ; JoinContext * s = ctx - > priv ; AVFilterBufferRef * buf ; JoinBufferPriv * priv ; int linesize = INT_MAX ; int perms = 0 ; int nb_samples ; int i , j , ret ; / * get a frame on each input * / for ( i = 0 ; i < ctx - > nb_inputs ; i + + ) { AVFilterLink * inlink = ctx - > inputs[i] ; if ( ! s - > input_frames[i] & & ( ret = ff_request_frame ( inlink ) ) < 0 ) return ret ; / * request the same number of samples on all inputs * / if ( i == 0 ) { nb_samples = s - > input_frames[0] - > audio - > nb_samples ; for ( j = 1 ; ! i & & j < ctx - > nb_inputs ; j + + ) ctx - > inputs[j] - > request_samples = nb_samples ; } } for ( i = 0 ; i < s - > nb_channels ; i + + ) { ChannelMap * ch = & s - > channels[i] ; AVFilterBufferRef * cur_buf = s - > input_frames[ch - > input] ; s - > data[i] = cur_buf - > extended_data[ch - > in_channel_idx] ; linesize = FFMIN ( linesize , cur_buf - > linesize[0] ) ; perms & = cur_buf - > perms ; } buf = avfilter_get_audio_buffer_ref_from_arrays ( s - > data , linesize , perms , nb_samples , outlink - > format , outlink - > channel_layout ) ; if ( ! buf ) return AVERROR ( ENOMEM ) ; buf - > buf - > free = join_free_buffer ; buf - > pts = s - > input_frames[0] - > pts ; if ( ! ( priv = av_mallocz ( sizeof ( * priv ) ) ) ) goto fail ; if ( ! ( priv - > in_buffers = av_mallocz ( sizeof ( * priv - > in_buffers ) * ctx - > nb_inputs ) ) ) goto fail ; for ( i = 0 ; i < ctx - > nb_inputs ; i + + ) priv - > in_buffers[i] = s - > input_frames[i] ; priv - > nb_in_buffers = ctx - > nb_inputs ; buf - > buf - > priv = priv ; ff_filter_samples ( outlink , buf ) ; memset ( s - > input_frames , 0 , sizeof ( * s - > input_frames ) * ctx - > nb_inputs ) ; return 0 ; fail : avfilter_unref_buffer ( buf ) ; if ( priv ) av_freep ( & priv - > in_buffers ) ; av_freep ( & priv ) ; return AVERROR ( ENOMEM ) ; }",1
"static inline void yuv2yuvXinC ( int16_t * lumFilter , int16_t * * lumSrc , int lumFilterSize , int16_t * chrFilter , int16_t * * chrSrc , int chrFilterSize , uint8_t * dest , uint8_t * uDest , uint8_t * vDest , int dstW , int chrDstW ) { //FIXME Optimize ( just quickly writen not opti . . ) int i ; for ( i=0 ; i < dstW ; i + + ) { int val=1 < < 18 ; int j ; for ( j=0 ; j < lumFilterSize ; j + + ) val + = lumSrc[j][i] * lumFilter[j] ; dest[i]= av_clip_uint8 ( val > > 19 ) ; } if ( uDest ) for ( i=0 ; i < chrDstW ; i + + ) { int u=1 < < 18 ; int v=1 < < 18 ; int j ; for ( j=0 ; j < chrFilterSize ; j + + ) { u + = chrSrc[j][i] * chrFilter[j] ; v + = chrSrc[j][i + 2048] * chrFilter[j] ; } uDest[i]= av_clip_uint8 ( u > > 19 ) ; vDest[i]= av_clip_uint8 ( v > > 19 ) ; } }",1
"static void check_decode_result ( int * got_output , int ret ) { if ( * got_output || ret < 0 ) decode_error_stat[ret < 0] + + ; if ( ret < 0 & & exit_on_error ) exit_program ( 1 ) ; }",1
"static int mace_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame_ptr , AVPacket * avpkt ) { AVFrame * frame = data ; const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; int16_t * * samples ; MACEContext * ctx = avctx - > priv_data ; int i , j , k , l , ret ; int is_mace3 = ( avctx - > codec_id == AV_CODEC_ID_MACE3 ) ; / * get output buffer * / frame - > nb_samples = 3 * ( buf_size < < ( 1 - is_mace3 ) ) / avctx - > channels ; if ( ( ret = ff_get_buffer ( avctx , frame , 0 ) ) < 0 ) return ret ; samples = ( int16_t * * ) frame - > extended_data ; for ( i = 0 ; i < avctx - > channels ; i + + ) { int16_t * output = samples[i] ; for ( j=0 ; j < buf_size / ( avctx - > channels < < is_mace3 ) ; j + + ) for ( k=0 ; k < ( 1 < < is_mace3 ) ; k + + ) { uint8_t pkt = buf[ ( i < < is_mace3 ) + ( j * avctx - > channels < < is_mace3 ) + k] ; uint8_t val[2][3] = { { pkt > > 5 , ( pkt > > 3 ) & 3 , pkt & 7 } , { pkt & 7 , ( pkt > > 3 ) & 3 , pkt > > 5 } } ; for ( l=0 ; l < 3 ; l + + ) { if ( is_mace3 ) chomp3 ( & ctx - > chd[i] , output , val[1][l] , l ) ; else chomp6 ( & ctx - > chd[i] , output , val[0][l] , l ) ; output + = 1 < < ( 1 - is_mace3 ) ; * got_frame_ptr = 1 ; return buf_size ;",1
"static av_cold int rv30_decode_init ( AVCodecContext * avctx ) { RV34DecContext * r = avctx - > priv_data ; int ret ; r - > rv30 = 1 ; if ( ( ret = ff_rv34_decode_init ( avctx ) ) < 0 ) return ret ; if ( avctx - > extradata_size < 2 ) { av_log ( avctx , AV_LOG_ERROR , Extradata is too small . \n ) ; return - 1 ; r - > max_rpr = avctx - > extradata[1] & 7 ; r - > parse_slice_header = rv30_parse_slice_header ; r - > decode_intra_types = rv30_decode_intra_types ; r - > decode_mb_info = rv30_decode_mb_info ; r - > loop_filter = rv30_loop_filter ; r - > luma_dc_quant_i = rv30_luma_dc_quant ; r - > luma_dc_quant_p = rv30_luma_dc_quant ; return 0 ;",1
"static int mpeg_decode_slice ( MpegEncContext * s , int mb_y , const uint8_t * * buf , int buf_size ) { AVCodecContext * avctx = s - > avctx ; const int field_pic = s - > picture_structure ! = PICT_FRAME ; int ret ; s - > resync_mb_x = s - > resync_mb_y = - 1 ; assert ( mb_y < s - > mb_height ) ; init_get_bits ( & s - > gb , * buf , buf_size * 8 ) ; ff_mpeg1_clean_buffers ( s ) ; s - > interlaced_dct = 0 ; s - > qscale = get_qscale ( s ) ; if ( s - > qscale == 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , qscale == 0\n ) ; return AVERROR_INVALIDDATA ; } / * extra slice info * / while ( get_bits1 ( & s - > gb ) ! = 0 ) skip_bits ( & s - > gb , 8 ) ; s - > mb_x = 0 ; if ( mb_y == 0 & & s - > codec_tag == AV_RL32 ( SLIF ) ) { skip_bits1 ( & s - > gb ) ; } else { while ( get_bits_left ( & s - > gb ) > 0 ) { int code = get_vlc2 ( & s - > gb , ff_mbincr_vlc . table , MBINCR_VLC_BITS , 2 ) ; if ( code < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , first mb_incr damaged\n ) ; return AVERROR_INVALIDDATA ; } if ( code > = 33 ) { if ( code == 33 ) s - > mb_x + = 33 ; / * otherwise , stuffing , nothing to do * / } else { s - > mb_x + = code ; break ; } } } if ( s - > mb_x > = ( unsigned ) s - > mb_width ) { av_log ( s - > avctx , AV_LOG_ERROR , initial skip overflow\n ) ; return AVERROR_INVALIDDATA ; } if ( avctx - > hwaccel ) { const uint8_t * buf_end , * buf_start = * buf - 4 ; / * include start_code * / int start_code = - 1 ; buf_end = avpriv_find_start_code ( buf_start + 2 , * buf + buf_size , & start_code ) ; if ( buf_end < * buf + buf_size ) buf_end - = 4 ; s - > mb_y = mb_y ; if ( avctx - > hwaccel - > decode_slice ( avctx , buf_start , buf_end - buf_start ) < 0 ) return DECODE_SLICE_ERROR ; * buf = buf_end ; return DECODE_SLICE_OK ; } s - > resync_mb_x = s - > mb_x ; s - > resync_mb_y = s - > mb_y = mb_y ; s - > mb_skip_run = 0 ; ff_init_block_index ( s ) ; if ( s - > mb_y == 0 & & s - > mb_x == 0 & & ( s - > first_field || s - > picture_structure == PICT_FRAME ) ) { if ( s - > avctx - > debug & FF_DEBUG_PICT_INFO ) { av_log ( s - > avctx , AV_LOG_DEBUG , qp : %d fc : %2d%2d%2d%2d %s %s %s %s %s dc : %d pstruct : %d fdct : %d cmv : %d qtype : %d ivlc : %d rff : %d %s\n , s - > qscale , s - > mpeg_f_code[0][0] , s - > mpeg_f_code[0][1] , s - > mpeg_f_code[1][0] , s - > mpeg_f_code[1][1] , s - > pict_type == AV_PICTURE_TYPE_I ? I : ( s - > pict_type == AV_PICTURE_TYPE_P ? P : ( s - > pict_type == AV_PICTURE_TYPE_B ? B : S ) ) , s - > progressive_sequence ? ps : , s - > progressive_frame ? pf : , s - > alternate_scan ? alt : , s - > top_field_first ? top : , s - > intra_dc_precision , s - > picture_structure , s - > frame_pred_frame_dct , s - > concealment_motion_vectors , s - > q_scale_type , s - > intra_vlc_format , s - > repeat_first_field , s - > chroma_420_type ? 420 : ) ; } } for ( ; ; ) { if FF_API_XVMC FF_DISABLE_DEPRECATION_WARNINGS // If 1 , we memcpy blocks in xvmcvideo . if ( CONFIG_MPEG_XVMC_DECODER & & s - > avctx - > xvmc_acceleration > 1 ) ff_xvmc_init_block ( s ) ; // set s - > block FF_ENABLE_DEPRECATION_WARNINGS endif / * FF_API_XVMC * / if ( ( ret = mpeg_decode_mb ( s , s - > block ) ) < 0 ) return ret ; // Note motion_val is normally NULL unless we want to extract the MVs . if ( s - > current_picture . motion_val[0] & & ! s - > encoding ) { const int wrap = s - > b8_stride ; int xy = s - > mb_x * 2 + s - > mb_y * 2 * wrap ; int b8_xy = 4 * ( s - > mb_x + s - > mb_y * s - > mb_stride ) ; int motion_x , motion_y , dir , i ; for ( i = 0 ; i < 2 ; i + + ) { for ( dir = 0 ; dir < 2 ; dir + + ) { if ( s - > mb_intra || ( dir == 1 & & s - > pict_type ! = AV_PICTURE_TYPE_B ) ) { motion_x = motion_y = 0 ; } else if ( s - > mv_type == MV_TYPE_16X16 || ( s - > mv_type == MV_TYPE_FIELD & & field_pic ) ) { motion_x = s - > mv[dir][0][0] ; motion_y = s - > mv[dir][0][1] ; } else { / * if ( ( s - > mv_type == MV_TYPE_FIELD ) || ( s - > mv_type == MV_TYPE_16X8 ) ) * / motion_x = s - > mv[dir][i][0] ; motion_y = s - > mv[dir][i][1] ; } s - > current_picture . motion_val[dir][xy][0] = motion_x ; s - > current_picture . motion_val[dir][xy][1] = motion_y ; s - > current_picture . motion_val[dir][xy + 1][0] = motion_x ; s - > current_picture . motion_val[dir][xy + 1][1] = motion_y ; s - > current_picture . ref_index [dir][b8_xy] = s - > current_picture . ref_index [dir][b8_xy + 1] = s - > field_select[dir][i] ; assert ( s - > field_select[dir][i] == 0 || s - > field_select[dir][i] == 1 ) ; } xy + = wrap ; b8_xy + = 2 ; } } s - > dest[0] + = 16 ; s - > dest[1] + = 16 > > s - > chroma_x_shift ; s - > dest[2] + = 16 > > s - > chroma_x_shift ; ff_mpv_decode_mb ( s , s - > block ) ; if ( + + s - > mb_x > = s - > mb_width ) { const int mb_size = 16 ; ff_mpeg_draw_horiz_band ( s , mb_size * ( s - > mb_y > > field_pic ) , mb_size ) ; ff_mpv_report_decode_progress ( s ) ; s - > mb_x",0
"int avfilter_graph_parse ( AVFilterGraph * graph , const char * filters , AVFilterInOut * * open_inputs , AVFilterInOut * * open_outputs , void * log_ctx ) { int index = 0 , ret ; char chr = 0 ; AVFilterInOut * curr_inputs = NULL ; do { AVFilterContext * filter ; const char * filterchain = filters ; filters + = strspn ( filters , WHITESPACES ) ; if ( ( ret = parse_inputs ( & filters , & curr_inputs , open_outputs , log_ctx ) ) < 0 ) goto fail ; if ( ( ret = parse_filter ( & filter , & filters , graph , index , log_ctx ) ) < 0 ) goto fail ; if ( filter - > input_count == 1 & & ! curr_inputs & & ! index ) { / * First input can be omitted if it is [in] * / const char * tmp = [in] ; if ( ( ret = parse_inputs ( & tmp , & curr_inputs , open_outputs , log_ctx ) ) < 0 ) goto fail ; } if ( ( ret = link_filter_inouts ( filter , & curr_inputs , open_inputs , log_ctx ) ) < 0 ) goto fail ; if ( ( ret = parse_outputs ( & filters , & curr_inputs , open_inputs , open_outputs , log_ctx ) ) < 0 ) goto fail ; filters + = strspn ( filters , WHITESPACES ) ; chr = * filters + + ; if ( chr == ' ; ' & & curr_inputs ) { av_log ( log_ctx , AV_LOG_ERROR , Invalid filterchain containing an unlabelled output pad : \ %s\ \n , filterchain ) ; ret = AVERROR ( EINVAL ) ; goto fail ; } index + + ; } while ( chr == ' , ' || chr == ' ; ' ) ; if ( chr ) { av_log ( log_ctx , AV_LOG_ERROR , Unable to parse graph description substring : \ %s\ \n , filters - 1 ) ; ret = AVERROR ( EINVAL ) ; goto fail ; } if ( * open_inputs & & ! strcmp ( ( * open_inputs ) - > name , out ) & & curr_inputs ) { / * Last output can be omitted if it is [out] * / const char * tmp = [out] ; if ( ( ret = parse_outputs ( & tmp , & curr_inputs , open_inputs , open_outputs , log_ctx ) ) < 0 ) goto fail ; } return 0 ; fail : for ( ; graph - > filter_count > 0 ; graph - > filter_count - - ) avfilter_free ( graph - > filters[graph - > filter_count - 1] ) ; av_freep ( & graph - > filters ) ; avfilter_inout_free ( open_inputs ) ; avfilter_inout_free ( open_outputs ) ; avfilter_inout_free ( & curr_inputs ) ; return ret ; }",1
"static int vid_probe ( AVProbeData * p ) { // little - endian VID tag , file starts with VID\0 if ( AV_RL32 ( p - > buf ) ! = MKTAG ( ' V ' , ' I ' , ' D ' , 0 ) ) return 0 ; return AVPROBE_SCORE_MAX ; }",1
"static int mpeg_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , uint8_t * buf , int buf_size ) { Mpeg1Context * s = avctx - > priv_data ; uint8_t * buf_end , * buf_ptr ; int ret , start_code , input_size ; AVFrame * picture = data ; MpegEncContext * s2 = & s - > mpeg_enc_ctx ; dprintf ( fill_buffer\n ) ; * data_size = 0 ; / * special case for last picture * / if ( buf_size == 0 ) { if ( s2 - > picture_number > 0 ) { * picture= * ( AVFrame * ) & s2 - > next_picture ; * data_size = sizeof ( AVFrame ) ; } return 0 ; } if ( s2 - > flags & CODEC_FLAG_TRUNCATED ) { int next ; next= mpeg1_find_frame_end ( s2 , buf , buf_size ) ; if ( ff_combine_frame ( s2 , next , & buf , & buf_size ) < 0 ) return buf_size ; } buf_ptr = buf ; buf_end = buf + buf_size ; if 0 if ( s - > repeat_field % 2 == 1 ) { s - > repeat_field + + ; //fprintf ( stderr , \nRepeating last frame : %d - > %d ! pict : %d %d , avctx - > frame_number - 1 , avctx - > frame_number , // s2 - > picture_number , s - > repeat_field ) ; if ( avctx - > flags & CODEC_FLAG_REPEAT_FIELD ) { * data_size = sizeof ( AVPicture ) ; goto the_end ; } } endif for ( ; ; ) { / * find start next code * / start_code = find_start_code ( & buf_ptr , buf_end ) ; if ( start_code < 0 ) { printf ( missing end of picture\n ) ; return FFMAX ( 1 , buf_ptr - buf - s2 - > parse_context . last_index ) ; } / * prepare data for next start code * / input_size = buf_end - buf_ptr ; switch ( start_code ) { case SEQ_START_CODE : mpeg1_decode_sequence ( avctx , buf_ptr , input_size ) ; break ; case PICTURE_START_CODE : / * we have a complete image : we try to decompress it * / mpeg1_decode_picture ( avctx , buf_ptr , input_size ) ; break ; case EXT_START_CODE : mpeg_decode_extension ( avctx , buf_ptr , input_size ) ; break ; case USER_START_CODE : mpeg_decode_user_data ( avctx , buf_ptr , input_size ) ; break ; default : if ( start_code > = SLICE_MIN_START_CODE & & start_code < = SLICE_MAX_START_CODE ) { / * skip b frames if we dont have reference frames * / if ( s2 - > last_picture_ptr==NULL & & s2 - > pict_type==B_TYPE ) break ; / * skip b frames if we are in a hurry * / if ( avctx - > hurry_up & & s2 - > pict_type==B_TYPE ) break ; / * skip everything if we are in a hurry > =5 * / if ( avctx - > hurry_up > =5 ) break ; if ( ! s - > mpeg_enc_ctx_allocated ) break ; ret = mpeg_decode_slice ( avctx , picture , start_code , & buf_ptr , input_size ) ; if ( ret == DECODE_SLICE_EOP ) { if ( s2 - > last_picture_ptr ) //FIXME merge with the stuff in mpeg_decode_slice * data_size = sizeof ( AVPicture ) ; return FFMAX ( 1 , buf_ptr - buf - s2 - > parse_context . last_index ) ; } else if ( ret < 0 ) { if ( ret == DECODE_SLICE_ERROR ) ff_er_add_slice ( s2 , s2 - > resync_mb_x , s2 - > resync_mb_y , s2 - > mb_x , s2 - > mb_y , AC_ERROR|DC_ERROR|MV_ERROR ) ; fprintf ( stderr , Error while decoding slice\n ) ; if ( ret==DECODE_SLICE_FATAL_ERROR ) return - 1 ; } } break ; } } }",0
"static int libopenjpeg_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; LibOpenJPEGContext * ctx = avctx - > priv_data ; AVFrame * picture = & ctx - > image , * output = data ; opj_dinfo_t * dec ; opj_cio_t * stream ; opj_image_t * image ; int width , height , ret = - 1 ; int pixel_size = 0 ; int ispacked = 0 ; * data_size = 0 ; // Check if input is a raw jpeg2k codestream or in jp2 wrapping if ( ( AV_RB32 ( buf ) == 12 ) & & ( AV_RB32 ( buf + 4 ) == JP2_SIG_TYPE ) & & ( AV_RB32 ( buf + 8 ) == JP2_SIG_VALUE ) ) { dec = opj_create_decompress ( CODEC_JP2 ) ; } else { // If the AVPacket contains a jp2c box , then skip to // the starting byte of the codestream . if ( AV_RB32 ( buf + 4 ) == AV_RB32 ( jp2c ) ) buf + = 8 ; dec = opj_create_decompress ( CODEC_J2K ) ; if ( ! dec ) { av_log ( avctx , AV_LOG_ERROR , Error initializing decoder . \n ) ; opj_set_event_mgr ( ( opj_common_ptr ) dec , NULL , NULL ) ; ctx - > dec_params . cp_limit_decoding = LIMIT_TO_MAIN_HEADER ; // Tie decoder with decoding parameters opj_setup_decoder ( dec , & ctx - > dec_params ) ; stream = opj_cio_open ( ( opj_common_ptr ) dec , buf , buf_size ) ; if ( ! stream ) { av_log ( avctx , AV_LOG_ERROR , Codestream could not be opened for reading . \n ) ; // Decode the header only image = opj_decode_with_info ( dec , stream , NULL ) ; opj_cio_close ( stream ) ; width = image - > x1 - image - > x0 ; height = image - > y1 - image - > y0 ; if ( av_image_check_size ( width , height , 0 , avctx ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , %dx%d dimension invalid . \n , width , height ) ; goto done ; avcodec_set_dimensions ( avctx , width , height ) ; switch ( image - > numcomps ) { case 1 : avctx - > pix_fmt = ( image - > comps[0] . bpp == 8 ) ? PIX_FMT_GRAY8 : PIX_FMT_GRAY16 ; break ; case 2 : avctx - > pix_fmt = PIX_FMT_GRAY8A ; break ; case 3 : case 4 : avctx - > pix_fmt = check_image_attributes ( avctx , image ) ; break ; default : av_log ( avctx , AV_LOG_ERROR , %d components unsupported . \n , image - > numcomps ) ; goto done ; if ( picture - > data[0] ) ff_thread_release_buffer ( avctx , picture ) ; if ( ff_thread_get_buffer ( avctx , picture ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , ff_thread_get_buffer ( ) failed\n ) ; ctx - > dec_params . cp_limit_decoding = NO_LIMITATION ; ctx - > dec_params . cp_reduce = avctx - > lowres ; // Tie decoder with decoding parameters opj_setup_decoder ( dec , & ctx - > dec_params ) ; stream = opj_cio_open ( ( opj_common_ptr ) dec , buf , buf_size ) ; if ( ! stream ) { av_log ( avctx , AV_LOG_ERROR , Codestream could not be opened for reading . \n ) ; // Decode the codestream image = opj_decode_with_info ( dec , stream , NULL ) ; opj_cio_close ( stream ) ; pixel_size = av_pix_fmt_descriptors[avctx - > pix_fmt] . comp[0] . step_minus1 + 1 ; ispacked = libopenjpeg_ispacked ( avctx - > pix_fmt ) ; switch ( pixel_size ) { case 1 : if ( ispacked ) { libopenjpeg_copy_to_packed8 ( picture , image ) ; } else { libopenjpeg_copyto8 ( picture , image ) ; break ; case 2 : if ( ispacked ) { libopenjpeg_copy_to_packed8 ( picture , image ) ; } else { libopenjpeg_copyto16 ( picture , image ) ; break ; case 3 : case 4 : if ( ispacked ) { libopenjpeg_copy_to_packed8 ( picture , image ) ; break ; case 6 : case 8 : if ( ispacked ) { libopenjpeg_copy_to_packed16 ( picture , image ) ; break ; default : av_log ( avctx , AV_LOG_ERROR , unsupported pixel size %d\n , pixel_size ) ; goto done ; * output = ctx - > image ; * data_size = sizeof ( AVPicture ) ; ret = buf_size ; done : opj_image_destroy ( image ) ; return ret ;",1
"static int pcm_encode_frame ( AVCodecContext * avctx , AVPacket * avpkt , const AVFrame * frame , int * got_packet_ptr ) { int n , c , sample_size , v , ret ; const short * samples ; unsigned char * dst ; const uint8_t * samples_uint8_t ; const int16_t * samples_int16_t ; const int32_t * samples_int32_t ; const int64_t * samples_int64_t ; const uint16_t * samples_uint16_t ; const uint32_t * samples_uint32_t ; sample_size = av_get_bits_per_sample ( avctx - > codec - > id ) / 8 ; n = frame - > nb_samples * avctx - > channels ; samples = ( const short * ) frame - > data[0] ; if ( ( ret = ff_alloc_packet2 ( avctx , avpkt , n * sample_size ) ) ) return ret ; dst = avpkt - > data ; switch ( avctx - > codec - > id ) { case AV_CODEC_ID_PCM_U32LE : ENCODE ( uint32_t , le32 , samples , dst , n , 0 , 0x80000000 ) break ; case AV_CODEC_ID_PCM_U32BE : ENCODE ( uint32_t , be32 , samples , dst , n , 0 , 0x80000000 ) break ; case AV_CODEC_ID_PCM_S24LE : ENCODE ( int32_t , le24 , samples , dst , n , 8 , 0 ) break ; case AV_CODEC_ID_PCM_S24LE_PLANAR : ENCODE_PLANAR ( int32_t , le24 , dst , n , 8 , 0 ) break ; case AV_CODEC_ID_PCM_S24BE : ENCODE ( int32_t , be24 , samples , dst , n , 8 , 0 ) break ; case AV_CODEC_ID_PCM_U24LE : ENCODE ( uint32_t , le24 , samples , dst , n , 8 , 0x800000 ) break ; case AV_CODEC_ID_PCM_U24BE : ENCODE ( uint32_t , be24 , samples , dst , n , 8 , 0x800000 ) break ; case AV_CODEC_ID_PCM_S24DAUD : for ( ; n > 0 ; n - - ) { uint32_t tmp = ff_reverse[ ( * samples > > 8 ) & 0xff] + ( ff_reverse[ * samples & 0xff] < < 8 ) ; tmp < < = 4 ; // sync flags would go here bytestream_put_be24 ( & dst , tmp ) ; samples + + ; } break ; case AV_CODEC_ID_PCM_U16LE : ENCODE ( uint16_t , le16 , samples , dst , n , 0 , 0x8000 ) break ; case AV_CODEC_ID_PCM_U16BE : ENCODE ( uint16_t , be16 , samples , dst , n , 0 , 0x8000 ) break ; case AV_CODEC_ID_PCM_S8 : ENCODE ( uint8_t , byte , samples , dst , n , 0 , - 128 ) break ; case AV_CODEC_ID_PCM_S8_PLANAR : ENCODE_PLANAR ( uint8_t , byte , dst , n , 0 , - 128 ) break ; if HAVE_BIGENDIAN case AV_CODEC_ID_PCM_F64LE : ENCODE ( int64_t , le64 , samples , dst , n , 0 , 0 ) break ; case AV_CODEC_ID_PCM_S32LE : case AV_CODEC_ID_PCM_F32LE : ENCODE ( int32_t , le32 , samples , dst , n , 0 , 0 ) break ; case AV_CODEC_ID_PCM_S32LE_PLANAR : ENCODE_PLANAR ( int32_t , le32 , dst , n , 0 , 0 ) break ; case AV_CODEC_ID_PCM_S16LE : ENCODE ( int16_t , le16 , samples , dst , n , 0 , 0 ) break ; case AV_CODEC_ID_PCM_S16LE_PLANAR : ENCODE_PLANAR ( int16_t , le16 , dst , n , 0 , 0 ) break ; case AV_CODEC_ID_PCM_F64BE : case AV_CODEC_ID_PCM_F32BE : case AV_CODEC_ID_PCM_S32BE : case AV_CODEC_ID_PCM_S16BE : else case AV_CODEC_ID_PCM_F64BE : ENCODE ( int64_t , be64 , samples , dst , n , 0 , 0 ) break ; case AV_CODEC_ID_PCM_F32BE : case AV_CODEC_ID_PCM_S32BE : ENCODE ( int32_t , be32 , samples , dst , n , 0 , 0 ) break ; case AV_CODEC_ID_PCM_S16BE : ENCODE ( int16_t , be16 , samples , dst , n , 0 , 0 ) break ; case AV_CODEC_ID_PCM_S16BE_PLANAR : ENCODE_PLANAR ( int16_t , be16 , dst , n , 0 , 0 ) break ; case AV_CODEC_ID_PCM_F64LE : case AV_CODEC_ID_PCM_F32LE : case AV_CODEC_ID_PCM_S32LE : case AV_CODEC_ID_PCM_S16LE : endif / * HAVE_BIGENDIAN * / case AV_CODEC_ID_PCM_U8 : memcpy ( dst , samples , n * sample_size ) ; break ; if HAVE_BIGENDIAN case AV_CODEC_ID_PCM_S16BE_PLANAR : else case AV_CODEC_ID_PCM_S16LE_PLANAR : case AV_CODEC_ID_PCM_S32LE_PLANAR : endif / * HAVE_BIGENDIAN * / n /= avctx - > channels ; for ( c = 0 ; c < avctx - > channels ; c + + ) { const uint8_t * src = frame - > extended_data[c] ; bytestream_put_buffer ( & dst , src , n * sample_size ) ; } break ; case AV_CODEC_ID_PCM_ALAW : for ( ; n > 0 ; n - - ) { v = * samples + + ; * dst + + = linear_to_alaw[ ( v + 32768 ) > > 2] ; } break ; case AV_CODEC_ID_PCM_MULAW : for ( ; n > 0 ; n - - ) { v = * samples + + ; * dst + + = linear_to_ulaw[ ( v + 32768 ) > > 2] ; } break ; default : return - 1 ; } * got_packet_ptr = 1 ; return 0 ; }",0
"static int RENAME ( epzs_motion_search ) ( MpegEncContext * s , int * mx_ptr , int * my_ptr , int P[10][2] , int pred_x , int pred_y , uint8_t * src_data[3] , uint8_t * ref_data[3] , int stride , int uvstride , int16_t ( * last_mv ) [2] , int ref_mv_scale , uint8_t * const mv_penalty ) { int best[2]= { 0 , 0 } ; int d , dmin ; const int shift= 1 + s - > quarter_sample ; uint32_t * map= s - > me . map ; int map_generation ; const int penalty_factor= s - > me . penalty_factor ; const int size=0 ; const int h=16 ; const int ref_mv_stride= s - > mb_stride ; //pass as arg FIXME const int ref_mv_xy= s - > mb_x + s - > mb_y * ref_mv_stride ; //add to last_mv beforepassing FIXME me_cmp_func cmp , chroma_cmp ; LOAD_COMMON cmp= s - > dsp . me_cmp[size] ; chroma_cmp= s - > dsp . me_cmp[size + 1] ; map_generation= update_map_generation ( s ) ; CMP ( dmin , 0 , 0 , size ) ; map[0]= map_generation ; score_map[0]= dmin ; / * first line * / if ( s - > first_slice_line ) { CHECK_MV ( P_LEFT[0] > > shift , P_LEFT[1] > > shift ) CHECK_CLIPED_MV ( ( last_mv[ref_mv_xy][0] * ref_mv_scale + ( 1 < < 15 ) ) > > 16 , ( last_mv[ref_mv_xy][1] * ref_mv_scale + ( 1 < < 15 ) ) > > 16 ) } else { if ( dmin < 256 & & ( P_LEFT[0] |P_LEFT[1] |P_TOP[0] |P_TOP[1] |P_TOPRIGHT[0]|P_TOPRIGHT[1] ) ==0 ) { * mx_ptr= 0 ; * my_ptr= 0 ; s - > me . skip=1 ; return dmin ; } CHECK_MV ( P_MEDIAN[0] > > shift , P_MEDIAN[1] > > shift ) if ( dmin > 256 * 2 ) { CHECK_CLIPED_MV ( ( last_mv[ref_mv_xy][0] * ref_mv_scale + ( 1 < < 15 ) ) > > 16 , ( last_mv[ref_mv_xy][1] * ref_mv_scale + ( 1 < < 15 ) ) > > 16 ) CHECK_MV ( P_LEFT[0] > > shift , P_LEFT[1] > > shift ) CHECK_MV ( P_TOP[0] > > shift , P_TOP[1] > > shift ) CHECK_MV ( P_TOPRIGHT[0] > > shift , P_TOPRIGHT[1] > > shift ) } } if ( dmin > 256 * 4 ) { if ( s - > me . pre_pass ) { CHECK_CLIPED_MV ( ( last_mv[ref_mv_xy - 1][0] * ref_mv_scale + ( 1 < < 15 ) ) > > 16 , ( last_mv[ref_mv_xy - 1][1] * ref_mv_scale + ( 1 < < 15 ) ) > > 16 ) if ( ! s - > first_slice_line ) CHECK_CLIPED_MV ( ( last_mv[ref_mv_xy - ref_mv_stride][0] * ref_mv_scale + ( 1 < < 15 ) ) > > 16 , ( last_mv[ref_mv_xy - ref_mv_stride][1] * ref_mv_scale + ( 1 < < 15 ) ) > > 16 ) } else { CHECK_CLIPED_MV ( ( last_mv[ref_mv_xy + 1][0] * ref_mv_scale + ( 1 < < 15 ) ) > > 16 , ( last_mv[ref_mv_xy + 1][1] * ref_mv_scale + ( 1 < < 15 ) ) > > 16 ) if ( s - > end_mb_y == s - > mb_height || s - > mb_y + 1 < s - > end_mb_y ) //FIXME replace at least with last_slice_line CHECK_CLIPED_MV ( ( last_mv[ref_mv_xy + ref_mv_stride][0] * ref_mv_scale + ( 1 < < 15 ) ) > > 16 , ( last_mv[ref_mv_xy + ref_mv_stride][1] * ref_mv_scale + ( 1 < < 15 ) ) > > 16 ) } } if ( s - > avctx - > last_predictor_count ) { const int count= s - > avctx - > last_predictor_count ; const int xstart= FFMAX ( 0 , s - > mb_x - count ) ; const int ystart= FFMAX ( 0 , s - > mb_y - count ) ; const int xend= FFMIN ( s - > mb_width , s - > mb_x + count + 1 ) ; const int yend= FFMIN ( s - > mb_height , s - > mb_y + count + 1 ) ; int mb_y ; for ( mb_y=ystart ; mb_y < yend ; mb_y + + ) { int mb_x ; for ( mb_x=xstart ; mb_x < xend ; mb_x + + ) { const int xy= mb_x + 1 + ( mb_y + 1 ) * ref_mv_stride ; int mx= ( last_mv[xy][0] * ref_mv_scale + ( 1 < < 15 ) ) > > 16 ; int my= ( last_mv[xy][1] * ref_mv_scale + ( 1 < < 15 ) ) > > 16 ; if ( mx > xmax || mx < xmin || my > ymax || my < ymin ) continue ; CHECK_MV ( mx , my ) } } } //check ( best[0] , best[1] , 0 , b0 ) if ( s - > me . dia_size== - 1 ) dmin= RENAME ( funny_diamond_search ) ( s , best , dmin , src_data , ref_data , stride , uvstride , pred_x , pred_y , penalty_factor , shift , map , map_generation , size , h , mv_penalty ) ; else if ( s - > me . dia_size < - 1 ) dmin= RENAME ( sab_diamond_search ) ( s , best , dmin , src_data , ref_data , stride , uvstride , pred_x , pred_y , penalty_factor , shift , map , map_generation , size , h , mv_penalty ) ; else if ( s - > me . dia_size < 2 ) dmin= RENAME ( small_diamond_search ) ( s , best , dmin , src_data , ref_data , stride , uvstride , pred_x , pred_y , penalty_factor , shift , map , map_generation , size , h , mv_penalty ) ; else dmin= RENAME ( var_diamond_search ) ( s , best , dmin , src_data , ref_data , stride , uvstride , pred_x , pred_y , penalty_factor , shift , map , map_generation , size , h , mv_penalty ) ; //check ( best[0] , best[1] , 0 , b1 ) * mx_ptr= best[0] ; * my_ptr= best[1] ; // printf ( %d %d %d \n , best[0] , best[1] , dmin ) ; return dmin ; }",0
"static int decode_residual_block ( AVSContext * h , GetBitContext * gb , const dec_2dvlc_t * r , int esc_golomb_order , int qp , uint8_t * dst , int stride ) { int i , level_code , esc_code , level , run , mask ; DCTELEM level_buf[64] ; uint8_t run_buf[64] ; DCTELEM * block = h - > block ; for ( i=0 ; i < 65 ; i + + ) { level_code = get_ue_code ( gb , r - > golomb_order ) ; if ( level_code > = ESCAPE_CODE ) { run = ( ( level_code - ESCAPE_CODE ) > > 1 ) + 1 ; esc_code = get_ue_code ( gb , esc_golomb_order ) ; level = esc_code + ( run > r - > max_run ? 1 : r - > level_add[run] ) ; while ( level > r - > inc_limit ) r + + ; mask = - ( level_code & 1 ) ; level = ( level mask ) - mask ; } else { level = r - > rltab[level_code][0] ; if ( ! level ) //end of block signal break ; run = r - > rltab[level_code][1] ; r + = r - > rltab[level_code][2] ; } level_buf[i] = level ; run_buf[i] = run ; } if ( dequant ( h , level_buf , run_buf , block , ff_cavs_dequant_mul[qp] , ff_cavs_dequant_shift[qp] , i ) ) return - 1 ; h - > s . dsp . cavs_idct8_add ( dst , block , stride ) ; return 0 ; }",1
"int ff_thread_decode_frame ( AVCodecContext * avctx , AVFrame * picture , int * got_picture_ptr , AVPacket * avpkt ) { FrameThreadContext * fctx = avctx - > internal - > thread_ctx ; int finished = fctx - > next_finished ; PerThreadContext * p ; int err ; / * release the async lock , permitting blocked hwaccel threads to * go forward while we are in this function * / async_unlock ( fctx ) ; / * * Submit a packet to the next decoding thread . * / p = & fctx - > threads[fctx - > next_decoding] ; err = update_context_from_user ( p - > avctx , avctx ) ; if ( err ) goto finish ; err = submit_packet ( p , avpkt ) ; if ( err ) goto finish ; / * * If we ' re still receiving the initial packets , don ' t return a frame . * / if ( fctx - > next_decoding > ( avctx - > thread_count - 1 - ( avctx - > codec_id == AV_CODEC_ID_FFV1 ) ) ) fctx - > delaying = 0 ; if ( fctx - > delaying ) { * got_picture_ptr=0 ; if ( avpkt - > size ) { err = avpkt - > size ; goto finish ; } } / * * Return the next available frame from the oldest thread . * If we ' re at the end of the stream , then we have to skip threads that * didn ' t output a frame , because we don ' t want to accidentally signal * EOF ( avpkt - > size == 0 & & * got_picture_ptr == 0 ) . * / do { p = & fctx - > threads[finished + + ] ; if ( atomic_load ( & p - > state ) ! = STATE_INPUT_READY ) { pthread_mutex_lock ( & p - > progress_mutex ) ; while ( atomic_load_explicit ( & p - > state , memory_order_relaxed ) ! = STATE_INPUT_READY ) pthread_cond_wait ( & p - > output_cond , & p - > progress_mutex ) ; pthread_mutex_unlock ( & p - > progress_mutex ) ; } av_frame_move_ref ( picture , p - > frame ) ; * got_picture_ptr = p - > got_frame ; picture - > pkt_dts = p - > avpkt . dts ; if ( p - > result < 0 ) err = p - > result ; / * * A later call with avkpt - > size == 0 may loop over all threads , * including this one , searching for a frame to return before being * stopped by the finished ! = fctx - > next_finished condition . * Make sure we don ' t mistakenly return the same frame again . * / p - > got_frame = 0 ; if ( finished > = avctx - > thread_count ) finished = 0 ; } while ( ! avpkt - > size & & ! * got_picture_ptr & & finished ! = fctx - > next_finished ) ; update_context_from_thread ( avctx , p - > avctx , 1 ) ; if ( fctx - > next_decoding > = avctx - > thread_count ) fctx - > next_decoding = 0 ; fctx - > next_finished = finished ; / * return the size of the consumed packet if no error occurred * / if ( err > = 0 ) err = avpkt - > size ; finish : async_lock ( fctx ) ; return err ; }",1
"static unsigned int find_best ( struct vf_instance * vf ) { int is_format_okay = vf - > next - > query_format ( vf - > next , IMGFMT_YV12 ) ; if ( ( is_format_okay & VFCAP_CSP_SUPPORTED_BY_HW ) || ( is_format_okay & VFCAP_CSP_SUPPORTED ) ) return IMGFMT_YV12 ; else return 0 ; }",1
static int swf_probe ( AVProbeData * p ) { / * check file header * / if ( p - > buf_size < = 16 ) return 0 ; if ( ( p - > buf[0] == ' F ' || p - > buf[0] == ' C ' ) & & p - > buf[1] == ' W ' & & p - > buf[2] == ' S ' ) return AVPROBE_SCORE_MAX ; else return 0 ; },0
"static int16_t * precalc_coefs ( double dist25 , int depth ) { int i ; double gamma , simil , C ; int16_t * ct = av_malloc ( ( 512 < < LUT_BITS ) * sizeof ( int16_t ) ) ; if ( ! ct ) return NULL ; gamma = log ( 0 . 25 ) / log ( 1 . 0 - FFMIN ( dist25 , 252 . 0 ) /255 . 0 - 0 . 00001 ) ; for ( i = - 255 < < LUT_BITS ; i < = 255 < < LUT_BITS ; i + + ) { double f = ( ( i < < ( 9 - LUT_BITS ) ) + ( 1 < < ( 8 - LUT_BITS ) ) - 1 ) / 512 . 0 ; // midpoint of the bin simil = 1 . 0 - FFABS ( f ) / 255 . 0 ; C = pow ( simil , gamma ) * 256 . 0 * f ; ct[ ( 256 < < LUT_BITS ) + i] = lrint ( C ) ; } ct[0] = ! ! dist25 ; return ct ; }",0
"void ffv1_clear_slice_state ( FFV1Context * f , FFV1Context * fs ) { int i , j ; for ( i = 0 ; i < f - > plane_count ; i + + ) { PlaneContext * p = & fs - > plane[i] ; p - > interlace_bit_state[0] = 128 ; p - > interlace_bit_state[1] = 128 ; if ( fs - > ac ) { if ( f - > initial_states[p - > quant_table_index] ) { memcpy ( p - > state , f - > initial_states[p - > quant_table_index] , CONTEXT_SIZE * p - > context_count ) ; } else memset ( p - > state , 128 , CONTEXT_SIZE * p - > context_count ) ; } else { for ( j = 0 ; j < p - > context_count ; j + + ) { p - > vlc_state[j] . drift = 0 ; p - > vlc_state[j] . error_sum = 4 ; //FFMAX ( ( RANGE + 32 ) /64 , 2 ) ; p - > vlc_state[j] . bias = 0 ; p - > vlc_state[j] . count = 1 ; } } } }",0
"static void avc_biwgt_4x2_msa ( uint8_t * src , int32_t src_stride , uint8_t * dst , int32_t dst_stride , int32_t log2_denom , int32_t src_weight , int32_t dst_weight , int32_t offset_in ) { uint32_t load0 , load1 , out0 , out1 ; v16i8 src_wgt , dst_wgt , wgt ; v16i8 src0 , src1 , dst0 , dst1 ; v8i16 temp0 , temp1 , denom , offset , add_val ; int32_t val = 128 * ( src_weight + dst_weight ) ; offset_in = ( ( offset_in + 1 ) | 1 ) < < log2_denom ; src_wgt = __msa_fill_b ( src_weight ) ; dst_wgt = __msa_fill_b ( dst_weight ) ; offset = __msa_fill_h ( offset_in ) ; denom = __msa_fill_h ( log2_denom + 1 ) ; add_val = __msa_fill_h ( val ) ; offset + = add_val ; wgt = __msa_ilvev_b ( dst_wgt , src_wgt ) ; load0 = LOAD_WORD ( src ) ; src + = src_stride ; load1 = LOAD_WORD ( src ) ; src0 = ( v16i8 ) __msa_fill_w ( load0 ) ; src1 = ( v16i8 ) __msa_fill_w ( load1 ) ; load0 = LOAD_WORD ( dst ) ; load1 = LOAD_WORD ( dst + dst_stride ) ; dst0 = ( v16i8 ) __msa_fill_w ( load0 ) ; dst1 = ( v16i8 ) __msa_fill_w ( load1 ) ; XORI_B_4VECS_SB ( src0 , src1 , dst0 , dst1 , src0 , src1 , dst0 , dst1 , 128 ) ; ILVR_B_2VECS_SH ( src0 , src1 , dst0 , dst1 , temp0 , temp1 ) ; temp0 = __msa_dpadd_s_h ( offset , wgt , ( v16i8 ) temp0 ) ; temp1 = __msa_dpadd_s_h ( offset , wgt , ( v16i8 ) temp1 ) ; temp0 > > = denom ; temp1 > > = denom ; temp0 = CLIP_UNSIGNED_CHAR_H ( temp0 ) ; temp1 = CLIP_UNSIGNED_CHAR_H ( temp1 ) ; dst0 = __msa_pckev_b ( ( v16i8 ) temp0 , ( v16i8 ) temp0 ) ; dst1 = __msa_pckev_b ( ( v16i8 ) temp1 , ( v16i8 ) temp1 ) ; out0 = __msa_copy_u_w ( ( v4i32 ) dst0 , 0 ) ; out1 = __msa_copy_u_w ( ( v4i32 ) dst1 , 0 ) ; STORE_WORD ( dst , out0 ) ; dst + = dst_stride ; STORE_WORD ( dst , out1 ) ; }",0
"static int asf_read_value ( AVFormatContext * s , uint8_t * name , uint16_t name_len , uint16_t val_len , int type , AVDictionary * * met ) { int ret ; uint8_t * value ; uint16_t buflen = 2 * val_len + 1 ; AVIOContext * pb = s - > pb ; value = av_malloc ( buflen ) ; if ( ! value ) return AVERROR ( ENOMEM ) ; if ( type == ASF_UNICODE ) { // get_asf_string reads UTF - 16 and converts it to UTF - 8 which needs longer buffer if ( ( ret = get_asf_string ( pb , val_len , value , buflen ) ) < 0 ) goto failed ; if ( av_dict_set ( met , name , value , 0 ) < 0 ) av_log ( s , AV_LOG_WARNING , av_dict_set failed . \n ) ; } else { char buf[256] ; if ( val_len > sizeof ( buf ) ) { ret = AVERROR_INVALIDDATA ; goto failed ; } if ( ( ret = avio_read ( pb , value , val_len ) ) < 0 ) goto failed ; if ( ret < 2 * val_len ) value[ret] = ' \0 ' ; else value[2 * val_len - 1] = ' \0 ' ; snprintf ( buf , sizeof ( buf ) , %s , value ) ; if ( av_dict_set ( met , name , buf , 0 ) < 0 ) av_log ( s , AV_LOG_WARNING , av_dict_set failed . \n ) ; } av_freep ( & value ) ; return 0 ; failed : av_freep ( & value ) ; return ret ; }",1
"static int av_buffersrc_add_frame_internal ( AVFilterContext * ctx , AVFrame * frame , int flags ) { BufferSourceContext * s = ctx - > priv ; AVFrame * copy ; int ret ; if ( ! frame ) { s - > eof = 1 ; return 0 ; } else if ( s - > eof ) return AVERROR ( EINVAL ) ; if ( ! ( flags & AV_BUFFERSRC_FLAG_NO_CHECK_FORMAT ) ) { switch ( ctx - > outputs[0] - > type ) { case AVMEDIA_TYPE_VIDEO : CHECK_VIDEO_PARAM_CHANGE ( ctx , s , frame - > width , frame - > height , frame - > format ) ; break ; case AVMEDIA_TYPE_AUDIO : CHECK_AUDIO_PARAM_CHANGE ( ctx , s , frame - > sample_rate , frame - > channel_layout , frame - > format ) ; break ; default : return AVERROR ( EINVAL ) ; } } if ( ! av_fifo_space ( s - > fifo ) & & ( ret = av_fifo_realloc2 ( s - > fifo , av_fifo_size ( s - > fifo ) + sizeof ( copy ) ) ) < 0 ) return ret ; if ( ! ( copy = av_frame_alloc ( ) ) ) return AVERROR ( ENOMEM ) ; av_frame_move_ref ( copy , frame ) ; if ( ( ret = av_fifo_generic_write ( s - > fifo , & copy , sizeof ( copy ) , NULL ) ) < 0 ) { av_frame_move_ref ( frame , copy ) ; av_frame_free ( & copy ) ; return ret ; } if ( ( flags & AV_BUFFERSRC_FLAG_PUSH ) ) if ( ( ret = ctx - > output_pads[0] . request_frame ( ctx - > outputs[0] ) ) < 0 ) return ret ; return 0 ; }",1
"static void smc_decode_stream ( SmcContext * s ) { int width = s - > avctx - > width ; int height = s - > avctx - > height ; int stride = s - > frame . linesize[0] ; int i ; int stream_ptr = 0 ; int chunk_size ; unsigned char opcode ; int n_blocks ; unsigned int color_flags ; unsigned int color_flags_a ; unsigned int color_flags_b ; unsigned int flag_mask ; unsigned char * pixels = s - > frame . data[0] ; int image_size = height * s - > frame . linesize[0] ; int row_ptr = 0 ; int pixel_ptr = 0 ; int pixel_x , pixel_y ; int row_inc = stride - 4 ; int block_ptr ; int prev_block_ptr ; int prev_block_ptr1 , prev_block_ptr2 ; int prev_block_flag ; int total_blocks ; int color_table_index ; / * indexes to color pair , quad , or octet tables * / int pixel ; int color_pair_index = 0 ; int color_quad_index = 0 ; int color_octet_index = 0 ; / * make the palette available * / memcpy ( s - > frame . data[1] , s - > pal , AVPALETTE_SIZE ) ; chunk_size = AV_RB32 ( & s - > buf[stream_ptr] ) & 0x00FFFFFF ; stream_ptr + = 4 ; if ( chunk_size ! = s - > size ) av_log ( s - > avctx , AV_LOG_INFO , warning : MOV chunk size ! = encoded chunk size ( %d ! = %d ) ; using MOV chunk size\n , chunk_size , s - > size ) ; chunk_size = s - > size ; total_blocks = ( ( s - > avctx - > width + 3 ) / 4 ) * ( ( s - > avctx - > height + 3 ) / 4 ) ; / * traverse through the blocks * / while ( total_blocks ) { / * sanity checks * / / * make sure stream ptr hasn ' t gone out of bounds * / if ( stream_ptr > chunk_size ) { av_log ( s - > avctx , AV_LOG_INFO , SMC decoder just went out of bounds ( stream ptr = %d , chunk size = %d ) \n , stream_ptr , chunk_size ) ; return ; } / * make sure the row pointer hasn ' t gone wild * / if ( row_ptr > = image_size ) { av_log ( s - > avctx , AV_LOG_INFO , SMC decoder just went out of bounds ( row ptr = %d , height = %d ) \n , row_ptr , image_size ) ; return ; } opcode = s - > buf[stream_ptr + + ] ; switch ( opcode & 0xF0 ) { / * skip n blocks * / case 0x00 : case 0x10 : n_blocks = GET_BLOCK_COUNT ( ) ; while ( n_blocks - - ) { ADVANCE_BLOCK ( ) ; } break ; / * repeat last block n times * / case 0x20 : case 0x30 : n_blocks = GET_BLOCK_COUNT ( ) ; / * sanity check * / if ( ( row_ptr == 0 ) & & ( pixel_ptr == 0 ) ) { av_log ( s - > avctx , AV_LOG_INFO , encountered repeat block opcode ( %02X ) but no blocks rendered yet\n , opcode & 0xF0 ) ; break ; } / * figure out where the previous block started * / if ( pixel_ptr == 0 ) prev_block_ptr1 = ( row_ptr - s - > avctx - > width * 4 ) + s - > avctx - > width - 4 ; else prev_block_ptr1 = row_ptr + pixel_ptr - 4 ; while ( n_blocks - - ) { block_ptr = row_ptr + pixel_ptr ; prev_block_ptr = prev_block_ptr1 ; for ( pixel_y = 0 ; pixel_y < 4 ; pixel_y + + ) { for ( pixel_x = 0 ; pixel_x < 4 ; pixel_x + + ) { pixels[block_ptr + + ] = pixels[prev_block_ptr + + ] ; } block_ptr + = row_inc ; prev_block_ptr + = row_inc ; } ADVANCE_BLOCK ( ) ; } break ; / * repeat previous pair of blocks n times * / case 0x40 : case 0x50 : n_blocks = GET_BLOCK_COUNT ( ) ; n_blocks * = 2 ; / * sanity check * / if ( ( row_ptr == 0 ) & & ( pixel_ptr < 2 * 4 ) ) { av_log ( s - > avctx , AV_LOG_INFO , encountered repeat block opcode ( %02X ) but not enough blocks rendered yet\n , opcode & 0xF0 ) ; break ; } / * figure out where the previous 2 blocks started * / if ( pixel_ptr == 0 ) prev_block_ptr1 = ( row_ptr - s - > avctx - > width * 4 ) + s - > avctx - > width - 4 * 2 ; else if ( pixel_ptr == 4 ) prev_block_ptr1 = ( row_ptr - s - > avctx - > width * 4 ) + row_inc ; else prev_block_ptr1 = row_ptr + pixel_ptr - 4 * 2 ; if ( pixel_ptr == 0 ) prev_block_ptr2 = ( row_ptr - s - > avctx - > width * 4 ) + row_inc ; else prev_block_ptr2 = row_ptr + pixel_ptr - 4 ; prev_block_flag = 0 ; while ( n_blocks - - ) { block_ptr = row_ptr + pixel_ptr ; if ( prev_block_flag ) prev_block_ptr = prev_block_ptr2 ; else prev_block_ptr = prev_block_ptr1 ; prev_block_flag = ! prev_block_flag ; for ( pixel_y = 0 ; pixel_y < 4 ; pixel_y + + ) { for ( pixel_x = 0 ; pixel_x < 4 ; pixel_x + + ) { pixels[block_ptr + + ] = pixels[prev_block_ptr + + ] ; } block_ptr + = row_inc ; prev_block_ptr + = row_inc ; } ADVANCE_BLOCK ( ) ; } break ; / * 1 - color block encoding * / case 0x60 : case 0x70 : n_blocks = GET_BLOCK_COUNT ( ) ; pixel = s - > buf[stream_ptr + + ] ; while ( n_blocks - - ) { block_ptr = row_ptr + pixel_ptr ; for ( pixel_y = 0 ; pixel_y < 4 ; pixel_y + + ) { for ( pixel_x = 0 ; pixel_x < 4 ; pixel_x + + ) { pixels[block_ptr + + ] = pixel ; } block_ptr + = row_inc ; } ADVANCE_BLOCK ( ) ; } break ; / * 2 - color block encoding * / case 0x80 : case 0x90 : n_blocks = ( opcode & 0x0F ) + 1 ; / * figure out which color pair to use to paint the 2 - color block * / if ( ( opcode & 0xF0 ) == 0x80 ) { / * fetch the next 2 colors from bytestream and store in next * available entry in the color pair table * / for ( i = 0 ; i < CPAIR ; i + + ) { pixel = s - > buf[stream_ptr + + ] ; color_table_index = CPAIR * color_pair_index + i ; s - > color_pairs[color_table_index] = pixel ; } / *",1
"static inline void idct_col ( int16_t * blk , const uint8_t * quant ) { int t0 , t1 , t2 , t3 , t4 , t5 , t6 , t7 , t8 , t9 , tA , tB , tC , tD , tE , tF ; int t10 , t11 , t12 , t13 ; int s0 , s1 , s2 , s3 , s4 , s5 , s6 , s7 ; s0 = ( int ) blk[0 * 8] * quant[0 * 8] ; s1 = ( int ) blk[1 * 8] * quant[1 * 8] ; s2 = ( int ) blk[2 * 8] * quant[2 * 8] ; s3 = ( int ) blk[3 * 8] * quant[3 * 8] ; s4 = ( int ) blk[4 * 8] * quant[4 * 8] ; s5 = ( int ) blk[5 * 8] * quant[5 * 8] ; s6 = ( int ) blk[6 * 8] * quant[6 * 8] ; s7 = ( int ) blk[7 * 8] * quant[7 * 8] ; t0 = ( s3 * 19266 + s5 * 12873 ) > > 15 ; t1 = ( s5 * 19266 - s3 * 12873 ) > > 15 ; t2 = ( ( s7 * 4520 + s1 * 22725 ) > > 15 ) - t0 ; t3 = ( ( s1 * 4520 - s7 * 22725 ) > > 15 ) - t1 ; t4 = t0 * 2 + t2 ; t5 = t1 * 2 + t3 ; t6 = t2 - t3 ; t7 = t3 * 2 + t6 ; t8 = ( t6 * 11585 ) > > 14 ; t9 = ( t7 * 11585 ) > > 14 ; tA = ( s2 * 8867 - s6 * 21407 ) > > 14 ; tB = ( s6 * 8867 + s2 * 21407 ) > > 14 ; tC = ( s0 > > 1 ) - ( s4 > > 1 ) ; tD = ( s4 > > 1 ) * 2 + tC ; tE = tC - ( tA > > 1 ) ; tF = tD - ( tB > > 1 ) ; t10 = tF - t5 ; t11 = tE - t8 ; t12 = tE + ( tA > > 1 ) * 2 - t9 ; t13 = tF + ( tB > > 1 ) * 2 - t4 ; blk[0 * 8] = t13 + t4 * 2 ; blk[1 * 8] = t12 + t9 * 2 ; blk[2 * 8] = t11 + t8 * 2 ; blk[3 * 8] = t10 + t5 * 2 ; blk[4 * 8] = t10 ; blk[5 * 8] = t11 ; blk[6 * 8] = t12 ; blk[7 * 8] = t13 ; }",1
"static int estimate_sid_gain ( G723_1_Context * p ) { int i , shift , seg , seg2 , t , val , val_add , x , y ; shift = 16 - p - > cur_gain * 2 ; if ( shift > 0 ) t = p - > sid_gain < < shift ; else t = p - > sid_gain > > - shift ; x = av_clipl_int32 ( t * ( int64_t ) cng_filt[0] > > 16 ) ; if ( x > = cng_bseg[2] ) return 0x3F ; if ( x > = cng_bseg[1] ) { shift = 4 ; seg = 3 ; } else { shift = 3 ; seg = ( x > = cng_bseg[0] ) ; } seg2 = FFMIN ( seg , 3 ) ; val = 1 < < shift ; val_add = val > > 1 ; for ( i = 0 ; i < shift ; i + + ) { t = seg * 32 + ( val < < seg2 ) ; t * = t ; if ( x > = t ) val + = val_add ; else val - = val_add ; val_add > > = 1 ; } t = seg * 32 + ( val < < seg2 ) ; y = t * t - x ; if ( y < = 0 ) { t = seg * 32 + ( val + 1 < < seg2 ) ; t = t * t - x ; val = ( seg2 - 1 < < 4 ) + val ; if ( t > = y ) val + + ; } else { t = seg * 32 + ( val - 1 < < seg2 ) ; t = t * t - x ; val = ( seg2 - 1 < < 4 ) + val ; if ( t > = y ) val - - ; } return val ; }",1
"static int decode_exp_vlc ( WMACodecContext * s , int ch ) { int last_exp , n , code ; const uint16_t * ptr ; float v , max_scale ; uint32_t * q , * q_end , iv ; const float * ptab = pow_tab + 60 ; const uint32_t * iptab = ( const uint32_t * ) ptab ; ptr = s - > exponent_bands[s - > frame_len_bits - s - > block_len_bits] ; q = ( uint32_t * ) s - > exponents[ch] ; q_end = q + s - > block_len ; max_scale = 0 ; if ( s - > version == 1 ) { last_exp = get_bits ( & s - > gb , 5 ) + 10 ; v = ptab[last_exp] ; iv = iptab[last_exp] ; max_scale = v ; n = * ptr + + ; switch ( n & 3 ) do { case 0 : * q + + = iv ; case 3 : * q + + = iv ; case 2 : * q + + = iv ; case 1 : * q + + = iv ; } while ( ( n - = 4 ) > 0 ) ; } else last_exp = 36 ; while ( q < q_end ) { code = get_vlc2 ( & s - > gb , s - > exp_vlc . table , EXPVLCBITS , EXPMAX ) ; if ( code < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , Exponent vlc invalid\n ) ; return - 1 ; } / * NOTE : this offset is the same as MPEG4 AAC ! * / last_exp + = code - 60 ; if ( ( unsigned ) last_exp + 60 > FF_ARRAY_ELEMS ( pow_tab ) ) { av_log ( s - > avctx , AV_LOG_ERROR , Exponent out of range : %d\n , last_exp ) ; return - 1 ; } v = ptab[last_exp] ; iv = iptab[last_exp] ; if ( v > max_scale ) max_scale = v ; n = * ptr + + ; switch ( n & 3 ) do { case 0 : * q + + = iv ; case 3 : * q + + = iv ; case 2 : * q + + = iv ; case 1 : * q + + = iv ; } while ( ( n - = 4 ) > 0 ) ; } s - > max_exponent[ch] = max_scale ; return 0 ; }",1
"static int decode ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { BC_STATUS ret ; BC_DTS_STATUS decoder_status ; CopyRet rec_ret ; CHDContext * priv = avctx - > priv_data ; HANDLE dev = priv - > dev ; int len = avpkt - > size ; uint8_t pic_type = 0 ; av_log ( avctx , AV_LOG_VERBOSE , CrystalHD : decode_frame\n ) ; if ( len ) { int32_t tx_free = ( int32_t ) DtsTxFreeSize ( dev ) ; if ( priv - > parser ) { uint8_t * pout ; int psize = len ; H264Context * h = priv - > parser - > priv_data ; while ( psize ) ret = av_parser_parse2 ( priv - > parser , avctx , & pout , & psize , avpkt - > data , len , avctx - > pkt - > pts , avctx - > pkt - > dts , len - psize ) ; av_log ( avctx , AV_LOG_VERBOSE , CrystalHD : parser picture type %d\n , h - > s . picture_structure ) ; pic_type = h - > s . picture_structure ; } if ( len < tx_free - 1024 ) { / * * Despite being notionally opaque , either libcrystalhd or * the hardware itself will mangle pts values that are too * small or too large . The docs claim it should be in units * of 100ns . Given that we ' re nominally dealing with a black * box on both sides , any transform we do has no guarantee of * avoiding mangling so we need to build a mapping to values * we know will not be mangled . * / uint64_t pts = opaque_list_push ( priv , avctx - > pkt - > pts , pic_type ) ; if ( ! pts ) { return AVERROR ( ENOMEM ) ; } av_log ( priv - > avctx , AV_LOG_VERBOSE , input \ pts\ : % PRIu64 \n , pts ) ; ret = DtsProcInput ( dev , avpkt - > data , len , pts , 0 ) ; if ( ret == BC_STS_BUSY ) { av_log ( avctx , AV_LOG_WARNING , CrystalHD : ProcInput returned busy\n ) ; usleep ( BASE_WAIT ) ; return AVERROR ( EBUSY ) ; } else if ( ret ! = BC_STS_SUCCESS ) { av_log ( avctx , AV_LOG_ERROR , CrystalHD : ProcInput failed : %u\n , ret ) ; return - 1 ; } avctx - > has_b_frames + + ; } else { av_log ( avctx , AV_LOG_WARNING , CrystalHD : Input buffer full\n ) ; len = 0 ; // We didn ' t consume any bytes . } } else { av_log ( avctx , AV_LOG_INFO , CrystalHD : No more input data\n ) ; } if ( priv - > skip_next_output ) { av_log ( avctx , AV_LOG_VERBOSE , CrystalHD : Skipping next output . \n ) ; priv - > skip_next_output = 0 ; avctx - > has_b_frames - - ; return len ; } ret = DtsGetDriverStatus ( dev , & decoder_status ) ; if ( ret ! = BC_STS_SUCCESS ) { av_log ( avctx , AV_LOG_ERROR , CrystalHD : GetDriverStatus failed\n ) ; return - 1 ; } / * * No frames ready . Don ' t try to extract . * * Empirical testing shows that ReadyListCount can be a damn lie , * and ProcOut still fails when count > 0 . The same testing showed * that two more iterations were needed before ProcOutput would * succeed . * / if ( priv - > output_ready < 2 ) { if ( decoder_status . ReadyListCount ! = 0 ) priv - > output_ready + + ; usleep ( BASE_WAIT ) ; av_log ( avctx , AV_LOG_INFO , CrystalHD : Filling pipeline . \n ) ; return len ; } else if ( decoder_status . ReadyListCount == 0 ) { / * * After the pipeline is established , if we encounter a lack of frames * that probably means we ' re not giving the hardware enough time to * decode them , so start increasing the wait time at the end of a * decode call . * / usleep ( BASE_WAIT ) ; priv - > decode_wait + = WAIT_UNIT ; av_log ( avctx , AV_LOG_INFO , CrystalHD : No frames ready . Returning\n ) ; return len ; } do { rec_ret = receive_frame ( avctx , data , data_size , 0 ) ; if ( rec_ret == RET_OK & & * data_size == 0 ) { / * * This case is for when the encoded fields are stored * separately and we get a separate avpkt for each one . To keep * the pipeline stable , we should return nothing and wait for * the next time round to grab the second field . * H . 264 PAFF is an example of this . * / av_log ( avctx , AV_LOG_VERBOSE , Returning after first field . \n ) ; avctx - > has_b_frames - - ; } else if ( rec_ret == RET_COPY_NEXT_FIELD ) { / * * This case is for when the encoded fields are stored in a * single avpkt but the hardware returns then separately . Unless * we grab the second field before returning , we ' ll slip another * frame in the pipeline and if that happens a lot , we ' re sunk . * So we have to get that second field now . * Interlaced mpeg2 and vc1 are examples of this . * / av_log ( avctx , AV_LOG_VERBOSE , Trying to get second field . \n ) ; while ( 1 ) { usleep ( priv - > decode_wait ) ; ret = DtsGetDriverStatus ( dev , & decoder_status ) ; if ( ret == BC_STS_SUCCESS & & decoder_status . ReadyListCount > 0 ) { rec_ret = receive_frame ( avctx , data , data_size , 1 ) ; if ( ( rec_ret == RET_OK & & * data_size > 0 ) || rec_ret == RET_ERROR ) break ; } } av_log ( avctx , AV_LOG_VERBOSE , CrystalHD : Got second field . \n ) ; } else if ( rec_ret == RET_SKIP_NEXT_COPY ) { / * * Two input packets got turned into a field pair . Gawd . * / av_log ( avctx , AV_LOG_VERBOSE , Don ' t output on next decode call . \n ) ; priv - > skip_next_output = 1 ; } / * * If rec_ret == RET_COPY_AGAIN , that means that either we just handled * a FMT_CHANGE event and need to go around again for the actual frame , * we got a busy status and need to try again , or we ' re dealing with * packed b - frames , where the hardware strangely returns the packed * p - frame twice . We choose to keep the second copy as it carries the * valid pts . * / } while ( rec_ret == RET_COPY_AGAIN ) ; usleep (",1
"static int au_read_packet ( AVFormatContext * s , AVPacket * pkt ) { int ret ; ret= av_get_packet ( s - > pb , pkt , BLOCK_SIZE * s - > streams[0] - > codec - > channels * av_get_bits_per_sample ( s - > streams[0] - > codec - > codec_id ) > > 3 ) ; if ( ret < 0 ) return ret ; pkt - > stream_index = 0 ; / * note : we need to modify the packet size here to handle the last packet * / pkt - > size = ret ; return 0 ; }",1
"static int mov_find_codec_tag ( AVFormatContext * s , MOVTrack * track ) { int tag = track - > enc - > codec_tag ; if ( track - > mode == MODE_MP4 || track - > mode == MODE_PSP ) { if ( ! codec_get_tag ( ff_mp4_obj_type , track - > enc - > codec_id ) ) return 0 ; if ( track - > enc - > codec_id == CODEC_ID_H264 ) tag = MKTAG ( ' a ' , ' v ' , ' c ' , ' 1 ' ) ; else if ( track - > enc - > codec_id == CODEC_ID_AC3 ) tag = MKTAG ( ' a ' , ' c ' , ' - ' , ' 3 ' ) ; else if ( track - > enc - > codec_id == CODEC_ID_DIRAC ) tag = MKTAG ( ' d ' , ' r ' , ' a ' , ' c ' ) ; else if ( track - > enc - > codec_id == CODEC_ID_MOV_TEXT ) tag = MKTAG ( ' t ' , ' x ' , ' 3 ' , ' g ' ) ; else if ( track - > enc - > codec_type == CODEC_TYPE_VIDEO ) tag = MKTAG ( ' m ' , ' p ' , ' 4 ' , ' v ' ) ; else if ( track - > enc - > codec_type == CODEC_TYPE_AUDIO ) tag = MKTAG ( ' m ' , ' p ' , ' 4 ' , ' a ' ) ; } else if ( track - > mode == MODE_IPOD ) { if ( track - > enc - > codec_type == CODEC_TYPE_SUBTITLE & & ( tag == MKTAG ( ' t ' , ' x ' , ' 3 ' , ' g ' ) || tag == MKTAG ( ' t ' , ' e ' , ' x ' , ' t ' ) ) ) track - > tag = tag ; // keep original tag else tag = codec_get_tag ( codec_ipod_tags , track - > enc - > codec_id ) ; if ( ! match_ext ( s - > filename , m4a ) & & ! match_ext ( s - > filename , m4v ) ) av_log ( s , AV_LOG_WARNING , Warning , extension is not . m4a nor . m4v Quicktime/Ipod might not play the file\n ) ; } else if ( track - > mode & MODE_3GP ) { tag = codec_get_tag ( codec_3gp_tags , track - > enc - > codec_id ) ; } else if ( ! tag || ( track - > enc - > strict_std_compliance > = FF_COMPLIANCE_NORMAL & & ( tag == MKTAG ( ' d ' , ' v ' , ' c ' , ' p ' ) || track - > enc - > codec_id == CODEC_ID_RAWVIDEO ) ) ) { if ( track - > enc - > codec_id == CODEC_ID_DVVIDEO ) { if ( track - > enc - > height == 480 ) / * NTSC * / if ( track - > enc - > pix_fmt == PIX_FMT_YUV422P ) tag = MKTAG ( ' d ' , ' v ' , ' 5 ' , ' n ' ) ; else tag = MKTAG ( ' d ' , ' v ' , ' c ' , ' ' ) ; else if ( track - > enc - > pix_fmt == PIX_FMT_YUV422P ) tag = MKTAG ( ' d ' , ' v ' , ' 5 ' , ' p ' ) ; else if ( track - > enc - > pix_fmt == PIX_FMT_YUV420P ) tag = MKTAG ( ' d ' , ' v ' , ' c ' , ' p ' ) ; else tag = MKTAG ( ' d ' , ' v ' , ' p ' , ' p ' ) ; } else if ( track - > enc - > codec_id == CODEC_ID_RAWVIDEO ) { tag = codec_get_tag ( mov_pix_fmt_tags , track - > enc - > pix_fmt ) ; if ( ! tag ) // restore tag tag = track - > enc - > codec_tag ; } else { if ( track - > enc - > codec_type == CODEC_TYPE_VIDEO ) { tag = codec_get_tag ( codec_movvideo_tags , track - > enc - > codec_id ) ; if ( ! tag ) { // if no mac fcc found , try with Microsoft tags tag = codec_get_tag ( codec_bmp_tags , track - > enc - > codec_id ) ; if ( tag ) av_log ( s , AV_LOG_INFO , Warning , using MS style video codec tag , the file may be unplayable ! \n ) ; } } else if ( track - > enc - > codec_type == CODEC_TYPE_AUDIO ) { tag = codec_get_tag ( codec_movaudio_tags , track - > enc - > codec_id ) ; if ( ! tag ) { // if no mac fcc found , try with Microsoft tags int ms_tag = codec_get_tag ( codec_wav_tags , track - > enc - > codec_id ) ; if ( ms_tag ) { tag = MKTAG ( ' m ' , ' s ' , ( ( ms_tag > > 8 ) & 0xff ) , ( ms_tag & 0xff ) ) ; av_log ( s , AV_LOG_INFO , Warning , using MS style audio codec tag , the file may be unplayable ! \n ) ; } } } else if ( track - > enc - > codec_type == CODEC_TYPE_SUBTITLE ) { tag = codec_get_tag ( ff_codec_movsubtitle_tags , track - > enc - > codec_id ) ; } } } return tag ; }",0
"static int asf_read_seek ( AVFormatContext * s , int stream_index , int64_t pts , int flags ) { ASFContext * asf = s - > priv_data ; AVStream * st = s - > streams[stream_index] ; int64_t pos ; int index ; if ( s - > packet_size < = 0 ) return - 1 ; / * Try using the protocol ' s read_seek if available * / if ( s - > pb ) { int ret = avio_seek_time ( s - > pb , stream_index , pts , flags ) ; if ( ret > = 0 ) asf_reset_header ( s ) ; if ( ret ! = AVERROR ( ENOSYS ) ) return ret ; } if ( ! asf - > index_read ) asf_build_simple_index ( s , stream_index ) ; if ( ( asf - > index_read & & st - > index_entries ) ) { index= av_index_search_timestamp ( st , pts , flags ) ; if ( index > = 0 ) { / * find the position * / pos = st - > index_entries[index] . pos ; / * do the seek * / av_log ( s , AV_LOG_DEBUG , SEEKTO : % PRId64 \n , pos ) ; avio_seek ( s - > pb , pos , SEEK_SET ) ; asf_reset_header ( s ) ; return 0 ; } } / * no index or seeking by index failed * / if ( av_seek_frame_binary ( s , stream_index , pts , flags ) < 0 ) return - 1 ; asf_reset_header ( s ) ; return 0 ; }",0
"static void decode ( RA288Context * ractx , float gain , int cb_coef ) { int i , j ; double sumsum ; float sum , buffer[5] ; memmove ( ractx - > sp_block + 5 , ractx - > sp_block , 36 * sizeof ( * ractx - > sp_block ) ) ; for ( i=4 ; i > = 0 ; i - - ) ractx - > sp_block[i] = - scalar_product_float ( ractx - > sp_block + i + 1 , ractx - > sp_lpc , 36 ) ; / * block 46 of G . 728 spec * / sum = 32 . - scalar_product_float ( ractx - > gain_lpc , ractx - > gain_block , 10 ) ; / * block 47 of G . 728 spec * / sum = av_clipf ( sum , 0 , 60 ) ; / * block 48 of G . 728 spec * / sumsum = exp ( sum * 0 . 1151292546497 ) * gain ; / * pow ( 10 . 0 , sum/20 ) * gain * / for ( i=0 ; i < 5 ; i + + ) buffer[i] = codetable[cb_coef][i] * sumsum ; sum = scalar_product_float ( buffer , buffer , 5 ) / 5 ; sum = FFMAX ( sum , 1 ) ; / * shift and store * / memmove ( ractx - > gain_block , ractx - > gain_block - 1 , 10 * sizeof ( * ractx - > gain_block ) ) ; * ractx - > gain_block = 10 * log10 ( sum ) - 32 ; for ( i=1 ; i < 5 ; i + + ) for ( j=i - 1 ; j > = 0 ; j - - ) buffer[i] - = ractx - > sp_lpc[i - j - 1] * buffer[j] ; / * output * / for ( i=0 ; i < 5 ; i + + ) ractx - > sp_block[4 - i] = av_clipf ( ractx - > sp_block[4 - i] + buffer[i] , - 4095 , 4095 ) ; }",0
static int fourxm_probe ( AVProbeData * p ) { if ( p - > buf_size < 12 ) return 0 ; if ( ( AV_RL32 ( & p - > buf[0] ) ! = RIFF_TAG ) || ( AV_RL32 ( & p - > buf[8] ) ! = _4XMV_TAG ) ) return 0 ; return AVPROBE_SCORE_MAX ; },0
"static av_cold void nvenc_setup_rate_control ( AVCodecContext * avctx ) { NvencContext * ctx = avctx - > priv_data ; if ( avctx - > bit_rate > 0 ) { ctx - > encode_config . rcParams . averageBitRate = avctx - > bit_rate ; } else if ( ctx - > encode_config . rcParams . averageBitRate > 0 ) { ctx - > encode_config . rcParams . maxBitRate = ctx - > encode_config . rcParams . averageBitRate ; } if ( avctx - > rc_max_rate > 0 ) ctx - > encode_config . rcParams . maxBitRate = avctx - > rc_max_rate ; if ( ctx - > rc < 0 ) { if ( ctx - > flags & NVENC_ONE_PASS ) ctx - > twopass = 0 ; if ( ctx - > flags & NVENC_TWO_PASSES ) ctx - > twopass = 1 ; if ( ctx - > twopass < 0 ) ctx - > twopass = ( ctx - > flags & NVENC_LOWLATENCY ) ! = 0 ; if ( ctx - > cbr ) { if ( ctx - > twopass ) { ctx - > rc = NV_ENC_PARAMS_RC_2_PASS_QUALITY ; } else { ctx - > rc = NV_ENC_PARAMS_RC_CBR ; } } else if ( avctx - > global_quality > 0 ) { ctx - > rc = NV_ENC_PARAMS_RC_CONSTQP ; } else if ( ctx - > twopass ) { ctx - > rc = NV_ENC_PARAMS_RC_2_PASS_VBR ; } else if ( avctx - > qmin > = 0 & & avctx - > qmax > = 0 ) { ctx - > rc = NV_ENC_PARAMS_RC_VBR_MINQP ; } } if ( ctx - > flags & NVENC_LOSSLESS ) { set_lossless ( avctx ) ; } else if ( ctx - > rc > = 0 ) { nvenc_override_rate_control ( avctx ) ; } else { ctx - > encode_config . rcParams . rateControlMode = NV_ENC_PARAMS_RC_VBR ; set_vbr ( avctx ) ; } if ( avctx - > rc_buffer_size > 0 ) { ctx - > encode_config . rcParams . vbvBufferSize = avctx - > rc_buffer_size ; } else if ( ctx - > encode_config . rcParams . averageBitRate > 0 ) { ctx - > encode_config . rcParams . vbvBufferSize = 2 * ctx - > encode_config . rcParams . averageBitRate ; } if ( ctx - > aq ) { ctx - > encode_config . rcParams . enableAQ = 1 ; ctx - > encode_config . rcParams . aqStrength = ctx - > aq_strength ; av_log ( avctx , AV_LOG_VERBOSE , AQ enabled . \n ) ; } if ( ctx - > temporal_aq ) { ctx - > encode_config . rcParams . enableTemporalAQ = 1 ; av_log ( avctx , AV_LOG_VERBOSE , Temporal AQ enabled . \n ) ; } if ( ctx - > rc_lookahead ) { int lkd_bound = FFMIN ( ctx - > nb_surfaces , ctx - > async_depth ) - ctx - > encode_config . frameIntervalP - 4 ; if ( lkd_bound < 0 ) { av_log ( avctx , AV_LOG_WARNING , Lookahead not enabled . Increase buffer delay ( - delay ) . \n ) ; } else { ctx - > encode_config . rcParams . enableLookahead = 1 ; ctx - > encode_config . rcParams . lookaheadDepth = av_clip ( ctx - > rc_lookahead , 0 , lkd_bound ) ; ctx - > encode_config . rcParams . disableIadapt = ctx - > no_scenecut ; ctx - > encode_config . rcParams . disableBadapt = ! ctx - > b_adapt ; av_log ( avctx , AV_LOG_VERBOSE , Lookahead enabled : depth %d , scenecut %s , B - adapt %s . \n , ctx - > encode_config . rcParams . lookaheadDepth , ctx - > encode_config . rcParams . disableIadapt ? disabled : enabled , ctx - > encode_config . rcParams . disableBadapt ? disabled : enabled ) ; } } if ( ctx - > strict_gop ) { ctx - > encode_config . rcParams . strictGOPTarget = 1 ; av_log ( avctx , AV_LOG_VERBOSE , Strict GOP target enabled . \n ) ; } if ( ctx - > nonref_p ) ctx - > encode_config . rcParams . enableNonRefP = 1 ; if ( ctx - > zerolatency ) ctx - > encode_config . rcParams . zeroReorderDelay = 1 ; if ( ctx - > quality ) ctx - > encode_config . rcParams . targetQuality = ctx - > quality ; }",0
"int ff_rv34_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , uint8_t * buf , int buf_size ) { RV34DecContext * r = avctx - > priv_data ; MpegEncContext * s = & r - > s ; AVFrame * pict = data ; SliceInfo si ; int i ; int slice_count ; uint8_t * slices_hdr = NULL ; int last = 0 ; / * no supplementary picture * / if ( buf_size == 0 ) { / * special case for last picture * / if ( s - > low_delay==0 & & s - > next_picture_ptr ) { * pict= * ( AVFrame * ) s - > next_picture_ptr ; s - > next_picture_ptr= NULL ; * data_size = sizeof ( AVFrame ) ; } return 0 ; } if ( ! avctx - > slice_count ) { slice_count = ( * buf + + ) + 1 ; slices_hdr = buf + 4 ; buf + = 8 * slice_count ; } else slice_count = avctx - > slice_count ; for ( i=0 ; i < slice_count ; i + + ) { int offset= get_slice_offset ( avctx , slices_hdr , i ) ; int size ; if ( i + 1 == slice_count ) size= buf_size - offset ; else size= get_slice_offset ( avctx , slices_hdr , i + 1 ) - offset ; r - > si . end = s - > mb_width * s - > mb_height ; if ( i + 1 < slice_count ) { init_get_bits ( & s - > gb , buf + get_slice_offset ( avctx , slices_hdr , i + 1 ) , ( buf_size - get_slice_offset ( avctx , slices_hdr , i + 1 ) ) * 8 ) ; if ( r - > parse_slice_header ( r , & r - > s . gb , & si ) < 0 ) { if ( i + 2 < slice_count ) size = get_slice_offset ( avctx , slices_hdr , i + 2 ) - offset ; else size = buf_size - offset ; } else r - > si . end = si . start ; } last = rv34_decode_slice ( r , r - > si . end , buf + offset , size ) ; s - > mb_num_left = r - > s . mb_x + r - > s . mb_y * r - > s . mb_width - r - > si . start ; if ( last ) break ; } if ( last ) { if ( r - > loop_filter ) r - > loop_filter ( r ) ; ff_er_frame_end ( s ) ; MPV_frame_end ( s ) ; if ( s - > pict_type == FF_B_TYPE || s - > low_delay ) { * pict= * ( AVFrame * ) s - > current_picture_ptr ; } else if ( s - > last_picture_ptr ! = NULL ) { * pict= * ( AVFrame * ) s - > last_picture_ptr ; } if ( s - > last_picture_ptr || s - > low_delay ) { * data_size = sizeof ( AVFrame ) ; ff_print_debug_info ( s , pict ) ; } s - > current_picture_ptr= NULL ; //so we can detect if frame_end wasnt called ( find some nicer solution . . . ) } return buf_size ; }",0
"static void blend_subrect ( AVPicture * dst , const AVSubtitleRect * rect , int imgw , int imgh ) { int x , y , Y , U , V , A ; uint8_t * lum , * cb , * cr ; int dstx , dsty , dstw , dsth ; const AVPicture * src = & rect - > pict ; dstw = av_clip ( rect - > w , 0 , imgw ) ; dsth = av_clip ( rect - > h , 0 , imgh ) ; dstx = av_clip ( rect - > x , 0 , imgw - dstw ) ; dsty = av_clip ( rect - > y , 0 , imgh - dsth ) ; lum = dst - > data[0] + dstx + dsty * dst - > linesize[0] ; cb = dst - > data[1] + dstx/2 + ( dsty > > 1 ) * dst - > linesize[1] ; cr = dst - > data[2] + dstx/2 + ( dsty > > 1 ) * dst - > linesize[2] ; for ( y = 0 ; y < dsth ; y + + ) { for ( x = 0 ; x < dstw ; x + + ) { Y = src - > data[0][x + y * src - > linesize[0]] ; A = src - > data[3][x + y * src - > linesize[3]] ; lum[0] = ALPHA_BLEND ( A , lum[0] , Y , 0 ) ; lum + + ; } lum + = dst - > linesize[0] - dstw ; } for ( y = 0 ; y < dsth/2 ; y + + ) { for ( x = 0 ; x < dstw/2 ; x + + ) { U = src - > data[1][x + y * src - > linesize[1]] ; V = src - > data[2][x + y * src - > linesize[2]] ; A = src - > data[3][2 * x + 2 * y * src - > linesize[3]] + src - > data[3][2 * x + 1 + 2 * y * src - > linesize[3]] + src - > data[3][2 * x + 1 + ( 2 * y + 1 ) * src - > linesize[3]] + src - > data[3][2 * x + ( 2 * y + 1 ) * src - > linesize[3]] ; cb[0] = ALPHA_BLEND ( A > > 2 , cb[0] , U , 0 ) ; cr[0] = ALPHA_BLEND ( A > > 2 , cr[0] , V , 0 ) ; cb + + ; cr + + ; } cb + = dst - > linesize[1] - dstw/2 ; cr + = dst - > linesize[2] - dstw/2 ; } }",0
"static void jpeg_table_header ( AVCodecContext * avctx , PutBitContext * p , ScanTable * intra_scantable , uint16_t luma_intra_matrix[64] , uint16_t chroma_intra_matrix[64] , int hsample[3] ) { int i , j , size ; uint8_t * ptr ; MpegEncContext * s = avctx - > priv_data ; if ( avctx - > codec_id ! = AV_CODEC_ID_LJPEG ) { int matrix_count = 1 + ! ! memcmp ( luma_intra_matrix , chroma_intra_matrix , sizeof ( luma_intra_matrix[0] ) * 64 ) ; if ( s - > force_duplicated_matrix ) matrix_count = 2 ; / * quant matrixes * / put_marker ( p , DQT ) ; put_bits ( p , 16 , 2 + matrix_count * ( 1 + 64 ) ) ; put_bits ( p , 4 , 0 ) ; / * 8 bit precision * / put_bits ( p , 4 , 0 ) ; / * table 0 * / for ( i=0 ; i < 64 ; i + + ) { j = intra_scantable - > permutated[i] ; put_bits ( p , 8 , luma_intra_matrix[j] ) ; } if ( matrix_count > 1 ) { put_bits ( p , 4 , 0 ) ; / * 8 bit precision * / put_bits ( p , 4 , 1 ) ; / * table 1 * / for ( i=0 ; i < 64 ; i + + ) { j = intra_scantable - > permutated[i] ; put_bits ( p , 8 , chroma_intra_matrix[j] ) ; } } } if ( avctx - > active_thread_type & FF_THREAD_SLICE ) { put_marker ( p , DRI ) ; put_bits ( p , 16 , 4 ) ; put_bits ( p , 16 , ( avctx - > width - 1 ) / ( 8 * hsample[0] ) + 1 ) ; } / * huffman table * / put_marker ( p , DHT ) ; flush_put_bits ( p ) ; ptr = put_bits_ptr ( p ) ; put_bits ( p , 16 , 0 ) ; / * patched later * / size = 2 ; // Only MJPEG can have a variable Huffman variable . All other // formats use the default Huffman table . if ( s - > out_format == FMT_MJPEG & & s - > huffman == HUFFMAN_TABLE_OPTIMAL ) { size + = put_huffman_table ( p , 0 , 0 , s - > mjpeg_ctx - > bits_dc_luminance , s - > mjpeg_ctx - > val_dc_luminance ) ; size + = put_huffman_table ( p , 0 , 1 , s - > mjpeg_ctx - > bits_dc_chrominance , s - > mjpeg_ctx - > val_dc_chrominance ) ; size + = put_huffman_table ( p , 1 , 0 , s - > mjpeg_ctx - > bits_ac_luminance , s - > mjpeg_ctx - > val_ac_luminance ) ; size + = put_huffman_table ( p , 1 , 1 , s - > mjpeg_ctx - > bits_ac_chrominance , s - > mjpeg_ctx - > val_ac_chrominance ) ; } else { size + = put_huffman_table ( p , 0 , 0 , avpriv_mjpeg_bits_dc_luminance , avpriv_mjpeg_val_dc ) ; size + = put_huffman_table ( p , 0 , 1 , avpriv_mjpeg_bits_dc_chrominance , avpriv_mjpeg_val_dc ) ; size + = put_huffman_table ( p , 1 , 0 , avpriv_mjpeg_bits_ac_luminance , avpriv_mjpeg_val_ac_luminance ) ; size + = put_huffman_table ( p , 1 , 1 , avpriv_mjpeg_bits_ac_chrominance , avpriv_mjpeg_val_ac_chrominance ) ; } AV_WB16 ( ptr , size ) ; }",0
"int avio_read_partial ( AVIOContext * s , unsigned char * buf , int size ) { int len ; if ( size < 0 ) return - 1 ; if ( s - > read_packet & & s - > write_flag ) { len = s - > read_packet ( s - > opaque , buf , size ) ; if ( len > 0 ) s - > pos + = len ; return len ; } len = s - > buf_end - s - > buf_ptr ; if ( len == 0 ) { / * Reset the buf_end pointer to the start of the buffer , to make sure * the fill_buffer call tries to read as much data as fits into the * full buffer , instead of just what space is left after buf_end . * This avoids returning partial packets at the end of the buffer , * for packet based inputs . * / s - > buf_end = s - > buf_ptr = s - > buffer ; fill_buffer ( s ) ; len = s - > buf_end - s - > buf_ptr ; } if ( len > size ) len = size ; memcpy ( buf , s - > buf_ptr , len ) ; s - > buf_ptr + = len ; if ( ! len ) { if ( s - > error ) return s - > error ; if ( avio_feof ( s ) ) return AVERROR_EOF ; } return len ; }",0
"static int sp5x_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , uint8_t * buf , int buf_size ) { if 0 MJpegDecodeContext * s = avctx - > priv_data ; endif const int qscale = 5 ; uint8_t * buf_ptr , * buf_end , * recoded ; int i = 0 , j = 0 ; / * no supplementary picture * / if ( buf_size == 0 ) return 0 ; if ( ! avctx - > width || ! avctx - > height ) return - 1 ; buf_ptr = buf ; buf_end = buf + buf_size ; if 1 recoded = av_mallocz ( buf_size + 1024 ) ; if ( ! recoded ) return - 1 ; / * SOI * / recoded[j + + ] = 0xFF ; recoded[j + + ] = 0xD8 ; memcpy ( recoded + j , & sp5x_data_dqt[0] , sizeof ( sp5x_data_dqt ) ) ; memcpy ( recoded + j + 5 , & sp5x_quant_table[qscale * 2] , 64 ) ; memcpy ( recoded + j + 70 , & sp5x_quant_table[ ( qscale * 2 ) + 1] , 64 ) ; j + = sizeof ( sp5x_data_dqt ) ; memcpy ( recoded + j , & sp5x_data_dht[0] , sizeof ( sp5x_data_dht ) ) ; j + = sizeof ( sp5x_data_dht ) ; memcpy ( recoded + j , & sp5x_data_sof[0] , sizeof ( sp5x_data_sof ) ) ; recoded[j + 5] = ( avctx - > coded_height > > 8 ) & 0xFF ; recoded[j + 6] = avctx - > coded_height & 0xFF ; recoded[j + 7] = ( avctx - > coded_width > > 8 ) & 0xFF ; recoded[j + 8] = avctx - > coded_width & 0xFF ; j + = sizeof ( sp5x_data_sof ) ; memcpy ( recoded + j , & sp5x_data_sos[0] , sizeof ( sp5x_data_sos ) ) ; j + = sizeof ( sp5x_data_sos ) ; for ( i = 14 ; i < buf_size & & j < buf_size + 1024 - 2 ; i + + ) { recoded[j + + ] = buf[i] ; if ( buf[i] == 0xff ) recoded[j + + ] = 0 ; } / * EOI * / recoded[j + + ] = 0xFF ; recoded[j + + ] = 0xD9 ; i = mjpeg_decode_frame ( avctx , data , data_size , recoded , j ) ; av_free ( recoded ) ; else / * SOF * / s - > bits = 8 ; s - > width = avctx - > coded_width ; s - > height = avctx - > coded_height ; s - > nb_components = 3 ; s - > component_id[0] = 0 ; s - > h_count[0] = 2 ; s - > v_count[0] = 2 ; s - > quant_index[0] = 0 ; s - > component_id[1] = 1 ; s - > h_count[1] = 1 ; s - > v_count[1] = 1 ; s - > quant_index[1] = 1 ; s - > component_id[2] = 2 ; s - > h_count[2] = 1 ; s - > v_count[2] = 1 ; s - > quant_index[2] = 1 ; s - > h_max = 2 ; s - > v_max = 2 ; s - > qscale_table = av_mallocz ( ( s - > width + 15 ) /16 ) ; avctx - > pix_fmt = s - > cs_itu601 ? PIX_FMT_YUV420P : PIX_FMT_YUVJ420 ; s - > interlaced = 0 ; s - > picture . reference = 0 ; if ( avctx - > get_buffer ( avctx , & s - > picture ) < 0 ) { fprintf ( stderr , get_buffer ( ) failed\n ) ; return - 1 ; } s - > picture . pict_type = I_TYPE ; s - > picture . key_frame = 1 ; for ( i = 0 ; i < 3 ; i + + ) s - > linesize[i] = s - > picture . linesize[i] < < s - > interlaced ; / * DQT * / for ( i = 0 ; i < 64 ; i + + ) { j = s - > scantable . permutated[i] ; s - > quant_matrixes[0][j] = sp5x_quant_table[ ( qscale * 2 ) + i] ; } s - > qscale[0] = FFMAX ( s - > quant_matrixes[0][s - > scantable . permutated[1]] , s - > quant_matrixes[0][s - > scantable . permutated[8]] ) > > 1 ; for ( i = 0 ; i < 64 ; i + + ) { j = s - > scantable . permutated[i] ; s - > quant_matrixes[1][j] = sp5x_quant_table[ ( qscale * 2 ) + 1 + i] ; } s - > qscale[1] = FFMAX ( s - > quant_matrixes[1][s - > scantable . permutated[1]] , s - > quant_matrixes[1][s - > scantable . permutated[8]] ) > > 1 ; / * DHT * / / * SOS * / s - > comp_index[0] = 0 ; s - > nb_blocks[0] = s - > h_count[0] * s - > v_count[0] ; s - > h_scount[0] = s - > h_count[0] ; s - > v_scount[0] = s - > v_count[0] ; s - > dc_index[0] = 0 ; s - > ac_index[0] = 0 ; s - > comp_index[1] = 1 ; s - > nb_blocks[1] = s - > h_count[1] * s - > v_count[1] ; s - > h_scount[1] = s - > h_count[1] ; s - > v_scount[1] = s - > v_count[1] ; s - > dc_index[1] = 1 ; s - > ac_index[1] = 1 ; s - > comp_index[2] = 2 ; s - > nb_blocks[2] = s - > h_count[2] * s - > v_count[2] ; s - > h_scount[2] = s - > h_count[2] ; s - > v_scount[2] = s - > v_count[2] ; s - > dc_index[2] = 1 ; s - > ac_index[2] = 1 ; for ( i = 0 ; i < 3 ; i + + ) s - > last_dc[i] = 1024 ; s - > mb_width = ( s - > width * s - > h_max * 8 - 1 ) / ( s - > h_max * 8 ) ; s - > mb_height = ( s - > height * s - > v_max * 8 - 1 ) / ( s - > v_max * 8 ) ; init_get_bits ( & s - > gb , buf + 14 , ( buf_size - 14 ) * 8 ) ; return mjpeg_decode_scan ( s ) ; endif return i ; }",0
"static void color16 ( WaveformContext * s , AVFrame * in , AVFrame * out , int component , int intensity , int offset , int column ) { const int plane = s - > desc - > comp[component] . plane ; const int mirror = s - > mirror ; const int limit = s - > size - 1 ; const uint16_t * c0_data = ( const uint16_t * ) in - > data[plane + 0] ; const uint16_t * c1_data = ( const uint16_t * ) in - > data[ ( plane + 1 ) % s - > ncomp] ; const uint16_t * c2_data = ( const uint16_t * ) in - > data[ ( plane + 2 ) % s - > ncomp] ; const int c0_linesize = in - > linesize[ plane + 0 ] / 2 ; const int c1_linesize = in - > linesize[ ( plane + 1 ) % s - > ncomp] / 2 ; const int c2_linesize = in - > linesize[ ( plane + 2 ) % s - > ncomp] / 2 ; const int d0_linesize = out - > linesize[ plane + 0 ] / 2 ; const int d1_linesize = out - > linesize[ ( plane + 1 ) % s - > ncomp] / 2 ; const int d2_linesize = out - > linesize[ ( plane + 2 ) % s - > ncomp] / 2 ; const int src_h = in - > height ; const int src_w = in - > width ; int x , y ; if ( s - > mode ) { const int d0_signed_linesize = d0_linesize * ( mirror == 1 ? - 1 : 1 ) ; const int d1_signed_linesize = d1_linesize * ( mirror == 1 ? - 1 : 1 ) ; const int d2_signed_linesize = d2_linesize * ( mirror == 1 ? - 1 : 1 ) ; uint16_t * d0_data = ( uint16_t * ) out - > data[plane] + offset * d0_linesize ; uint16_t * d1_data = ( uint16_t * ) out - > data[ ( plane + 1 ) % s - > ncomp] + offset * d1_linesize ; uint16_t * d2_data = ( uint16_t * ) out - > data[ ( plane + 2 ) % s - > ncomp] + offset * d2_linesize ; uint16_t * const d0_bottom_line = d0_data + d0_linesize * ( s - > size - 1 ) ; uint16_t * const d0 = ( mirror ? d0_bottom_line : d0_data ) ; uint16_t * const d1_bottom_line = d1_data + d1_linesize * ( s - > size - 1 ) ; uint16_t * const d1 = ( mirror ? d1_bottom_line : d1_data ) ; uint16_t * const d2_bottom_line = d2_data + d2_linesize * ( s - > size - 1 ) ; uint16_t * const d2 = ( mirror ? d2_bottom_line : d2_data ) ; for ( y = 0 ; y < src_h ; y + + ) { for ( x = 0 ; x < src_w ; x + + ) { const int c0 = FFMIN ( c0_data[x] , limit ) ; const int c1 = c1_data[x] ; const int c2 = c2_data[x] ; * ( d0 + d0_signed_linesize * c0 + x ) = c0 ; * ( d1 + d1_signed_linesize * c0 + x ) = c1 ; * ( d2 + d2_signed_linesize * c0 + x ) = c2 ; } c0_data + = c0_linesize ; c1_data + = c1_linesize ; c2_data + = c2_linesize ; d0_data + = d0_linesize ; d1_data + = d1_linesize ; d2_data + = d2_linesize ; } } else { uint16_t * d0_data = ( uint16_t * ) out - > data[plane] + offset ; uint16_t * d1_data = ( uint16_t * ) out - > data[ ( plane + 1 ) % s - > ncomp] + offset ; uint16_t * d2_data = ( uint16_t * ) out - > data[ ( plane + 2 ) % s - > ncomp] + offset ; if ( mirror ) { d0_data + = s - > size - 1 ; d1_data + = s - > size - 1 ; d2_data + = s - > size - 1 ; } for ( y = 0 ; y < src_h ; y + + ) { for ( x = 0 ; x < src_w ; x + + ) { const int c0 = FFMIN ( c0_data[x] , limit ) ; const int c1 = c1_data[x] ; const int c2 = c2_data[x] ; if ( mirror ) { * ( d0_data - c0 ) = c0 ; * ( d1_data - c0 ) = c1 ; * ( d2_data - c0 ) = c2 ; } else { * ( d0_data + c0 ) = c0 ; * ( d1_data + c0 ) = c1 ; * ( d2_data + c0 ) = c2 ; } } c0_data + = c0_linesize ; c1_data + = c1_linesize ; c2_data + = c2_linesize ; d0_data + = d0_linesize ; d1_data + = d1_linesize ; d2_data + = d2_linesize ; } } envelope16 ( s , out , plane , plane ) ; }",0
"static inline void RENAME ( hyscale_fast ) ( SwsContext * c , int16_t * dst , long dstWidth , const uint8_t * src , int srcW , int xInc ) { if ARCH_X86 if COMPILE_TEMPLATE_MMX2 int32_t * filterPos = c - > hLumFilterPos ; int16_t * filter = c - > hLumFilter ; int canMMX2BeUsed = c - > canMMX2BeUsed ; void * mmx2FilterCode= c - > lumMmx2FilterCode ; int i ; if defined ( PIC ) DECLARE_ALIGNED ( 8 , uint64_t , ebxsave ) ; endif if ( canMMX2BeUsed ) { __asm__ volatile ( if defined ( PIC ) mov %% REG_b , %5 \n\t endif pxor %%mm7 , %%mm7 \n\t mov %0 , %% REG_c \n\t mov %1 , %% REG_D \n\t mov %2 , %% REG_d \n\t mov %3 , %% REG_b \n\t xor %% REG_a , %% REG_a \n\t // i PREFETCH ( %% REG_c ) \n\t PREFETCH 32 ( %% REG_c ) \n\t PREFETCH 64 ( %% REG_c ) \n\t if ARCH_X86_64 define CALL_MMX2_FILTER_CODE \ movl ( %% REG_b ) , %%esi \n\t \ call * %4 \n\t \ movl ( %% REG_b , %% REG_a ) , %%esi \n\t \ add %% REG_S , %% REG_c \n\t \ add %% REG_a , %% REG_D \n\t \ xor %% REG_a , %% REG_a \n\t \ else define CALL_MMX2_FILTER_CODE \ movl ( %% REG_b ) , %%esi \n\t \ call * %4 \n\t \ addl ( %% REG_b , %% REG_a ) , %% REG_c \n\t \ add %% REG_a , %% REG_D \n\t \ xor %% REG_a , %% REG_a \n\t \ endif / * ARCH_X86_64 * / CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE if defined ( PIC ) mov %5 , %% REG_b \n\t endif : : m ( src ) , m ( dst ) , m ( filter ) , m ( filterPos ) , m ( mmx2FilterCode ) if defined ( PIC ) , m ( ebxsave ) endif : % REG_a , % REG_c , % REG_d , % REG_S , % REG_D if ! defined ( PIC ) , % REG_b endif ) ; for ( i=dstWidth - 1 ; ( i * xInc ) > > 16 > =srcW - 1 ; i - - ) dst[i] = src[srcW - 1] * 128 ; } else { endif / * COMPILE_TEMPLATE_MMX2 * / x86_reg xInc_shr16 = xInc > > 16 ; uint16_t xInc_mask = xInc & 0xffff ; x86_reg dstWidth_reg = dstWidth ; //NO MMX just normal asm . . . __asm__ volatile ( xor %% REG_a , %% REG_a \n\t // i xor %% REG_d , %% REG_d \n\t // xx xorl %%ecx , %%ecx \n\t // xalpha . p2align 4 \n\t 1 : \n\t movzbl ( %0 , %% REG_d ) , %%edi \n\t //src[xx] movzbl 1 ( %0 , %% REG_d ) , %%esi \n\t //src[xx + 1] FAST_BILINEAR_X86 movw %%si , ( %% REG_D , %% REG_a , 2 ) \n\t addw %4 , %%cx \n\t //xalpha + = xInc & 0xFFFF adc %3 , %% REG_d \n\t //xx + = xInc > > 16 + carry movzbl ( %0 , %% REG_d ) , %%edi \n\t //src[xx] movzbl 1 ( %0 , %% REG_d ) , %%esi \n\t //src[xx + 1] FAST_BILINEAR_X86 movw %%si , 2 ( %% REG_D , %% REG_a , 2 ) \n\t addw %4 , %%cx \n\t //xalpha + = xInc & 0xFFFF adc %3 , %% REG_d \n\t //xx + = xInc > > 16 + carry add 2 , %% REG_a \n\t cmp %2 , %% REG_a \n\t jb 1b \n\t : : r ( src ) , m ( dst ) , m ( dstWidth_reg ) , m ( xInc_shr16 ) , m ( xInc_mask ) : % REG_a , % REG_d , %ecx , % REG_D , %esi ) ; if COMPILE_TEMPLATE_MMX2 } //if MMX2 can ' t be used endif else int i ; unsigned int xpos=0 ; for ( i=0 ; i < dstWidth ; i + + ) { register unsigned int xx=xpos > > 16 ; register unsigned int xalpha= ( xpos & 0xFFFF ) > > 9 ; dst[i]= ( src[xx] < < 7 ) + ( src[xx + 1] - src[xx] ) * xalpha ; xpos + =xInc ; } endif / * ARCH_X86 * / }",0
"static void filter_mb ( H264Context * h , int mb_x , int mb_y ) { MpegEncContext * const s = & h - > s ; const int mb_xy= mb_x + mb_y * s - > mb_stride ; uint8_t * img_y = s - > current_picture . data[0] + ( mb_y * 16 * s - > linesize ) + mb_x * 16 ; uint8_t * img_cb = s - > current_picture . data[1] + ( mb_y * 8 * s - > uvlinesize ) + mb_x * 8 ; uint8_t * img_cr = s - > current_picture . data[2] + ( mb_y * 8 * s - > uvlinesize ) + mb_x * 8 ; int linesize , uvlinesize ; int dir ; if 0 / * FIXME what ' s that ? * / if ( ! s - > decode ) return ; endif / * FIXME Implement deblocking filter for field MB * / if ( h - > sps . mb_aff ) { return ; } linesize = s - > linesize ; uvlinesize = s - > uvlinesize ; / * dir : 0 - > vertical edge , 1 - > horizontal edge * / for ( dir = 0 ; dir < 2 ; dir + + ) { int start = 0 ; int edge ; / * test picture boundary * / if ( ( dir == 0 & & mb_x == 0 ) || ( dir == 1 & & mb_y == 0 ) ) { start = 1 ; } / * FIXME test slice boundary * / if ( h - > disable_deblocking_filter_idc == 2 ) { } / * Calculate bS * / for ( edge = start ; edge < 4 ; edge + + ) { / * mbn_xy : neighbour macroblock ( how that works for field ? ) * / int mbn_xy = edge > 0 ? mb_xy : ( dir == 0 ? mb_xy - 1 : mb_xy - s - > mb_stride ) ; int bS[4] ; int qp ; if ( IS_INTRA ( s - > current_picture . mb_type[mb_xy] ) || IS_INTRA ( s - > current_picture . mb_type[mbn_xy] ) ) { bS[0] = bS[1] = bS[2] = bS[3] = ( edge == 0 ? 4 : 3 ) ; } else { int i ; for ( i = 0 ; i < 4 ; i + + ) { static const uint8_t block_idx_xy[4][4] = { { 0 , 2 , 8 , 10 } , { 1 , 3 , 9 , 11 } , { 4 , 6 , 12 , 14 } , { 5 , 7 , 13 , 15 } } ; int x = dir == 0 ? edge : i ; int y = dir == 0 ? i : edge ; int xn = ( x - ( dir == 0 ? 1 : 0 ) ) & 0x03 ; int yn = ( y - ( dir == 0 ? 0 : 1 ) ) & 0x03 ; if ( h - > non_zero_count[mb_xy][block_idx_xy[x][y]] ! = 0 || h - > non_zero_count[mbn_xy][block_idx_xy[xn][yn]] ! = 0 ) { bS[i] = 2 ; } else if ( h - > slice_type == P_TYPE ) { const int b8_xy = h - > mb2b8_xy[mb_xy] + ( y > > 1 ) * h - > b8_stride + ( x > > 1 ) ; const int b8n_xy= h - > mb2b8_xy[mbn_xy] + ( yn > > 1 ) * h - > b8_stride + ( xn > > 1 ) ; const int b_xy = h - > mb2b_xy[mb_xy] + y * h - > b_stride + x ; const int bn_xy = h - > mb2b_xy[mbn_xy] + yn * h - > b_stride + xn ; if ( s - > current_picture . ref_index[0][b8_xy] ! = s - > current_picture . ref_index[0][b8n_xy] || ABS ( s - > current_picture . motion_val[0][b_xy][0] - s - > current_picture . motion_val[0][bn_xy][0] ) > = 4 || ABS ( s - > current_picture . motion_val[0][b_xy][1] - s - > current_picture . motion_val[0][bn_xy][1] ) > = 4 ) bS[i] = 1 ; else bS[i] = 0 ; } else { / * FIXME Add support for B frame * / return ; } } } / * Filter edge * / qp = ( s - > current_picture . qscale_table[mb_xy] + s - > current_picture . qscale_table[mbn_xy] + 1 ) > > 1 ; if ( dir == 0 ) { filter_mb_edgev ( h , & img_y[4 * edge] , linesize , bS , qp ) ; if ( ( edge & 1 ) == 0 ) { int chroma_qp = ( get_chroma_qp ( h , s - > current_picture . qscale_table[mb_xy] ) + get_chroma_qp ( h , s - > current_picture . qscale_table[mbn_xy] ) + 1 ) > > 1 ; filter_mb_edgecv ( h , & img_cb[2 * edge] , uvlinesize , bS , chroma_qp ) ; filter_mb_edgecv ( h , & img_cr[2 * edge] , uvlinesize , bS , chroma_qp ) ; } } else { filter_mb_edgeh ( h , & img_y[4 * edge * linesize] , linesize , bS , qp ) ; if ( ( edge & 1 ) == 0 ) { int chroma_qp = ( get_chroma_qp ( h , s - > current_picture . qscale_table[mb_xy] ) + get_chroma_qp ( h , s - > current_picture . qscale_table[mbn_xy] ) + 1 ) > > 1 ; filter_mb_edgech ( h , & img_cb[2 * edge * uvlinesize] , uvlinesize , bS , chroma_qp ) ; filter_mb_edgech ( h , & img_cr[2 * edge * uvlinesize] , uvlinesize , bS , chroma_qp ) ; } } } } }",0
"void mpeg_motion_internal ( MpegEncContext * s , uint8_t * dest_y , uint8_t * dest_cb , uint8_t * dest_cr , int field_based , int bottom_field , int field_select , uint8_t * * ref_picture , op_pixels_func ( * pix_op ) [4] , int motion_x , int motion_y , int h , int is_mpeg12 , int mb_y ) { uint8_t * ptr_y , * ptr_cb , * ptr_cr ; int dxy , uvdxy , mx , my , src_x , src_y , uvsrc_x , uvsrc_y , v_edge_pos ; ptrdiff_t uvlinesize , linesize ; if 0 if ( s - > quarter_sample ) { motion_x > > = 1 ; motion_y > > = 1 ; } endif v_edge_pos = s - > v_edge_pos > > field_based ; linesize = s - > current_picture . f . linesize[0] < < field_based ; uvlinesize = s - > current_picture . f . linesize[1] < < field_based ; dxy = ( ( motion_y & 1 ) < < 1 ) | ( motion_x & 1 ) ; src_x = s - > mb_x * 16 + ( motion_x > > 1 ) ; src_y = ( mb_y < < ( 4 - field_based ) ) + ( motion_y > > 1 ) ; if ( ! is_mpeg12 & & s - > out_format == FMT_H263 ) { if ( ( s - > workaround_bugs & FF_BUG_HPEL_CHROMA ) & & field_based ) { mx = ( motion_x > > 1 ) | ( motion_x & 1 ) ; my = motion_y > > 1 ; uvdxy = ( ( my & 1 ) < < 1 ) | ( mx & 1 ) ; uvsrc_x = s - > mb_x * 8 + ( mx > > 1 ) ; uvsrc_y = ( mb_y < < ( 3 - field_based ) ) + ( my > > 1 ) ; } else { uvdxy = dxy | ( motion_y & 2 ) | ( ( motion_x & 2 ) > > 1 ) ; uvsrc_x = src_x > > 1 ; uvsrc_y = src_y > > 1 ; } // Even chroma mv ' s are full pel in H261 } else if ( ! is_mpeg12 & & s - > out_format == FMT_H261 ) { mx = motion_x / 4 ; my = motion_y / 4 ; uvdxy = 0 ; uvsrc_x = s - > mb_x * 8 + mx ; uvsrc_y = mb_y * 8 + my ; } else { if ( s - > chroma_y_shift ) { mx = motion_x / 2 ; my = motion_y / 2 ; uvdxy = ( ( my & 1 ) < < 1 ) | ( mx & 1 ) ; uvsrc_x = s - > mb_x * 8 + ( mx > > 1 ) ; uvsrc_y = ( mb_y < < ( 3 - field_based ) ) + ( my > > 1 ) ; } else { if ( s - > chroma_x_shift ) { // Chroma422 mx = motion_x / 2 ; uvdxy = ( ( motion_y & 1 ) < < 1 ) | ( mx & 1 ) ; uvsrc_x = s - > mb_x * 8 + ( mx > > 1 ) ; uvsrc_y = src_y ; } else { // Chroma444 uvdxy = dxy ; uvsrc_x = src_x ; uvsrc_y = src_y ; } } } ptr_y = ref_picture[0] + src_y * linesize + src_x ; ptr_cb = ref_picture[1] + uvsrc_y * uvlinesize + uvsrc_x ; ptr_cr = ref_picture[2] + uvsrc_y * uvlinesize + uvsrc_x ; if ( ( unsigned ) src_x > FFMAX ( s - > h_edge_pos - ( motion_x & 1 ) - 16 , 0 ) || ( unsigned ) src_y > FFMAX ( v_edge_pos - ( motion_y & 1 ) - h , 0 ) ) { if ( is_mpeg12 || s - > codec_id == AV_CODEC_ID_MPEG2VIDEO || s - > codec_id == AV_CODEC_ID_MPEG1VIDEO ) { av_log ( s - > avctx , AV_LOG_DEBUG , MPEG motion vector out of boundary ( %d %d ) \n , src_x , src_y ) ; return ; } s - > vdsp . emulated_edge_mc ( s - > edge_emu_buffer , ptr_y , s - > linesize , s - > linesize , 17 , 17 + field_based , src_x , src_y < < field_based , s - > h_edge_pos , s - > v_edge_pos ) ; ptr_y = s - > edge_emu_buffer ; if ( ! CONFIG_GRAY || ! ( s - > flags & CODEC_FLAG_GRAY ) ) { uint8_t * uvbuf = s - > edge_emu_buffer + 18 * s - > linesize ; s - > vdsp . emulated_edge_mc ( uvbuf , ptr_cb , s - > uvlinesize , s - > uvlinesize , 9 , 9 + field_based , uvsrc_x , uvsrc_y < < field_based , s - > h_edge_pos > > 1 , s - > v_edge_pos > > 1 ) ; s - > vdsp . emulated_edge_mc ( uvbuf + 16 , ptr_cr , s - > uvlinesize , s - > uvlinesize , 9 , 9 + field_based , uvsrc_x , uvsrc_y < < field_based , s - > h_edge_pos > > 1 , s - > v_edge_pos > > 1 ) ; ptr_cb = uvbuf ; ptr_cr = uvbuf + 16 ; } } / * FIXME use this for field pix too instead of the obnoxious hack which * changes picture . data * / if ( bottom_field ) { dest_y + = s - > linesize ; dest_cb + = s - > uvlinesize ; dest_cr + = s - > uvlinesize ; } if ( field_select ) { ptr_y + = s - > linesize ; ptr_cb + = s - > uvlinesize ; ptr_cr + = s - > uvlinesize ; } pix_op[0][dxy] ( dest_y , ptr_y , linesize , h ) ; if ( ! CONFIG_GRAY || ! ( s - > flags & CODEC_FLAG_GRAY ) ) { pix_op[s - > chroma_x_shift][uvdxy] ( dest_cb , ptr_cb , uvlinesize , h > > s - > chroma_y_shift ) ; pix_op[s - > chroma_x_shift][uvdxy] ( dest_cr , ptr_cr , uvlinesize , h > > s - > chroma_y_shift ) ; } if ( ! is_mpeg12 & & ( CONFIG_H261_ENCODER || CONFIG_H261_DECODER ) & & s - > out_format == FMT_H261 ) { ff_h261_loop_filter ( s ) ; } }",1
"static av_cold int vp9_decode_free ( AVCodecContext * ctx ) { VP9Context * s = ctx - > priv_data ; int i ; for ( i = 0 ; i < 2 ; i + + ) { if ( s - > frames[i] . tf . f - > data[0] ) vp9_unref_frame ( ctx , & s - > frames[i] ) ; av_frame_free ( & s - > frames[i] . tf . f ) ; } for ( i = 0 ; i < 8 ; i + + ) { if ( s - > refs[i] . f - > data[0] ) ff_thread_release_buffer ( ctx , & s - > refs[i] ) ; av_frame_free ( & s - > refs[i] . f ) ; if ( s - > next_refs[i] . f - > data[0] ) ff_thread_release_buffer ( ctx , & s - > next_refs[i] ) ; av_frame_free ( & s - > next_refs[i] . f ) ; } av_freep ( & s - > above_partition_ctx ) ; av_freep ( & s - > c_b ) ; s - > c_b_size = 0 ; av_freep ( & s - > b_base ) ; av_freep ( & s - > block_base ) ; return 0 ; }",1
"static int ffm_read_header ( AVFormatContext * s ) { FFMContext * ffm = s - > priv_data ; AVStream * st ; AVIOContext * pb = s - > pb ; AVCodecContext * codec ; const AVCodecDescriptor * codec_desc ; int i , nb_streams ; uint32_t tag ; / * header * / tag = avio_rl32 ( pb ) ; if ( tag == MKTAG ( ' F ' , ' F ' , ' M ' , ' 2 ' ) ) return ffm2_read_header ( s ) ; if ( tag ! = MKTAG ( ' F ' , ' F ' , ' M ' , ' 1 ' ) ) ffm - > packet_size = avio_rb32 ( pb ) ; if ( ffm - > packet_size ! = FFM_PACKET_SIZE ) ffm - > write_index = avio_rb64 ( pb ) ; / * get also filesize * / if ( pb - > seekable ) { ffm - > file_size = avio_size ( pb ) ; if ( ffm - > write_index & & 0 ) adjust_write_index ( s ) ; } else { ffm - > file_size = ( UINT64_C ( 1 ) < < 63 ) - 1 ; nb_streams = avio_rb32 ( pb ) ; avio_rb32 ( pb ) ; / * total bitrate * / / * read each stream * / for ( i=0 ; i < nb_streams ; i + + ) { char rc_eq_buf[128] ; st = avformat_new_stream ( s , NULL ) ; if ( ! st ) avpriv_set_pts_info ( st , 64 , 1 , 1000000 ) ; codec = st - > codec ; / * generic info * / codec - > codec_id = avio_rb32 ( pb ) ; codec_desc = avcodec_descriptor_get ( codec - > codec_id ) ; if ( ! codec_desc ) { av_log ( s , AV_LOG_ERROR , Invalid codec id : %d\n , codec - > codec_id ) ; codec - > codec_id = AV_CODEC_ID_NONE ; codec - > codec_type = avio_r8 ( pb ) ; / * codec_type * / if ( codec - > codec_type ! = codec_desc - > type ) { av_log ( s , AV_LOG_ERROR , Codec type mismatch : expected %d , found %d\n , codec_desc - > type , codec - > codec_type ) ; codec - > codec_id = AV_CODEC_ID_NONE ; codec - > codec_type = AVMEDIA_TYPE_UNKNOWN ; codec - > bit_rate = avio_rb32 ( pb ) ; codec - > flags = avio_rb32 ( pb ) ; codec - > flags2 = avio_rb32 ( pb ) ; codec - > debug = avio_rb32 ( pb ) ; / * specific info * / switch ( codec - > codec_type ) { case AVMEDIA_TYPE_VIDEO : codec - > time_base . num = avio_rb32 ( pb ) ; codec - > time_base . den = avio_rb32 ( pb ) ; if ( codec - > time_base . num < = 0 || codec - > time_base . den < = 0 ) { av_log ( s , AV_LOG_ERROR , Invalid time base %d/%d\n , codec - > time_base . num , codec - > time_base . den ) ; codec - > width = avio_rb16 ( pb ) ; codec - > height = avio_rb16 ( pb ) ; codec - > gop_size = avio_rb16 ( pb ) ; codec - > pix_fmt = avio_rb32 ( pb ) ; codec - > qmin = avio_r8 ( pb ) ; codec - > qmax = avio_r8 ( pb ) ; codec - > max_qdiff = avio_r8 ( pb ) ; codec - > qcompress = avio_rb16 ( pb ) / 10000 . 0 ; codec - > qblur = avio_rb16 ( pb ) / 10000 . 0 ; codec - > bit_rate_tolerance = avio_rb32 ( pb ) ; avio_get_str ( pb , INT_MAX , rc_eq_buf , sizeof ( rc_eq_buf ) ) ; codec - > rc_eq = av_strdup ( rc_eq_buf ) ; codec - > rc_max_rate = avio_rb32 ( pb ) ; codec - > rc_min_rate = avio_rb32 ( pb ) ; codec - > rc_buffer_size = avio_rb32 ( pb ) ; codec - > i_quant_factor = av_int2double ( avio_rb64 ( pb ) ) ; codec - > b_quant_factor = av_int2double ( avio_rb64 ( pb ) ) ; codec - > i_quant_offset = av_int2double ( avio_rb64 ( pb ) ) ; codec - > b_quant_offset = av_int2double ( avio_rb64 ( pb ) ) ; codec - > dct_algo = avio_rb32 ( pb ) ; codec - > strict_std_compliance = avio_rb32 ( pb ) ; codec - > max_b_frames = avio_rb32 ( pb ) ; codec - > mpeg_quant = avio_rb32 ( pb ) ; codec - > intra_dc_precision = avio_rb32 ( pb ) ; codec - > me_method = avio_rb32 ( pb ) ; codec - > mb_decision = avio_rb32 ( pb ) ; codec - > nsse_weight = avio_rb32 ( pb ) ; codec - > frame_skip_cmp = avio_rb32 ( pb ) ; codec - > rc_buffer_aggressivity = av_int2double ( avio_rb64 ( pb ) ) ; codec - > codec_tag = avio_rb32 ( pb ) ; codec - > thread_count = avio_r8 ( pb ) ; codec - > coder_type = avio_rb32 ( pb ) ; codec - > me_cmp = avio_rb32 ( pb ) ; codec - > me_subpel_quality = avio_rb32 ( pb ) ; codec - > me_range = avio_rb32 ( pb ) ; codec - > keyint_min = avio_rb32 ( pb ) ; codec - > scenechange_threshold = avio_rb32 ( pb ) ; codec - > b_frame_strategy = avio_rb32 ( pb ) ; codec - > qcompress = av_int2double ( avio_rb64 ( pb ) ) ; codec - > qblur = av_int2double ( avio_rb64 ( pb ) ) ; codec - > max_qdiff = avio_rb32 ( pb ) ; codec - > refs = avio_rb32 ( pb ) ; break ; case AVMEDIA_TYPE_AUDIO : codec - > sample_rate = avio_rb32 ( pb ) ; codec - > channels = avio_rl16 ( pb ) ; codec - > frame_size = avio_rl16 ( pb ) ; break ; default : if ( codec - > flags & AV_CODEC_FLAG_GLOBAL_HEADER ) { int size = avio_rb32 ( pb ) ; codec - > extradata = av_mallocz ( size + AV_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! codec - > extradata ) return AVERROR ( ENOMEM ) ; codec - > extradata_size = size ; avio_read ( pb , codec - > extradata , size ) ; avcodec_parameters_from_context ( st - > codecpar , codec ) ; / * get until end of block reached * / while ( ( avio_tell ( pb ) % ffm - > packet_size ) ! = 0 & & ! pb - > eof_reached ) avio_r8 ( pb ) ; / * init packet demux * / ffm - > packet_ptr = ffm - > packet ; ffm - > packet_end = ffm - > packet ; ffm - > frame_offset = 0 ; ffm - > dts = 0 ; ffm - > read_state = READ_HEADER ; ffm - > first_packet = 1 ; return 0 ; fail : ffm_close ( s",1
"static int aac_sync ( uint64_t state , AACAC3ParseContext * hdr_info , int * need_next_header , int * new_frame_start ) { GetBitContext bits ; AACADTSHeaderInfo hdr ; int size ; union { uint64_t u64 ; uint8_t u8[8] ; } tmp ; tmp . u64 = av_be2ne64 ( state ) ; init_get_bits ( & bits , tmp . u8 + 8 - AAC_ADTS_HEADER_SIZE , AAC_ADTS_HEADER_SIZE * 8 ) ; if ( ( size = avpriv_aac_parse_header ( & bits , & hdr ) ) < 0 ) return 0 ; * need_next_header = 0 ; * new_frame_start = 1 ; hdr_info - > sample_rate = hdr . sample_rate ; hdr_info - > channels = ff_mpeg4audio_channels[hdr . chan_config] ; hdr_info - > samples = hdr . samples ; hdr_info - > bit_rate = hdr . bit_rate ; return size ; }",1
"static int sdp_read_header ( AVFormatContext * s ) { RTSPState * rt = s - > priv_data ; RTSPStream * rtsp_st ; int size , i , err ; char * content ; char url[1024] ; if ( ! ff_network_init ( ) ) return AVERROR ( EIO ) ; if ( s - > max_delay < 0 ) / * Not set by the caller * / s - > max_delay = DEFAULT_REORDERING_DELAY ; if ( rt - > rtsp_flags & RTSP_FLAG_CUSTOM_IO ) rt - > lower_transport = RTSP_LOWER_TRANSPORT_CUSTOM ; / * read the whole sdp file * / / * XXX : better loading * / content = av_malloc ( SDP_MAX_SIZE ) ; size = avio_read ( s - > pb , content , SDP_MAX_SIZE - 1 ) ; if ( size < = 0 ) { av_free ( content ) ; return AVERROR_INVALIDDATA ; } content[size] = ' \0 ' ; err = ff_sdp_parse ( s , content ) ; av_freep ( & content ) ; if ( err ) goto fail ; / * open each RTP stream * / for ( i = 0 ; i < rt - > nb_rtsp_streams ; i + + ) { char namebuf[50] ; rtsp_st = rt - > rtsp_streams[i] ; if ( ! ( rt - > rtsp_flags & RTSP_FLAG_CUSTOM_IO ) ) { AVDictionary * opts = map_to_opts ( rt ) ; getnameinfo ( ( struct sockaddr * ) & rtsp_st - > sdp_ip , sizeof ( rtsp_st - > sdp_ip ) , namebuf , sizeof ( namebuf ) , NULL , 0 , NI_NUMERICHOST ) ; ff_url_join ( url , sizeof ( url ) , rtp , NULL , namebuf , rtsp_st - > sdp_port , ? localport=%d & ttl=%d & connect=%d & write_to_source=%d , rtsp_st - > sdp_port , rtsp_st - > sdp_ttl , rt - > rtsp_flags & RTSP_FLAG_FILTER_SRC ? 1 : 0 , rt - > rtsp_flags & RTSP_FLAG_RTCP_TO_SOURCE ? 1 : 0 ) ; append_source_addrs ( url , sizeof ( url ) , sources , rtsp_st - > nb_include_source_addrs , rtsp_st - > include_source_addrs ) ; append_source_addrs ( url , sizeof ( url ) , block , rtsp_st - > nb_exclude_source_addrs , rtsp_st - > exclude_source_addrs ) ; err = ffurl_open ( & rtsp_st - > rtp_handle , url , AVIO_FLAG_READ_WRITE , & s - > interrupt_callback , & opts ) ; av_dict_free ( & opts ) ; if ( err < 0 ) { err = AVERROR_INVALIDDATA ; goto fail ; } } if ( ( err = ff_rtsp_open_transport_ctx ( s , rtsp_st ) ) ) goto fail ; } return 0 ; fail : ff_rtsp_close_streams ( s ) ; ff_network_close ( ) ; return err ; }",1
"static int mov_create_chapter_track ( AVFormatContext * s , int tracknum ) { MOVMuxContext * mov = s - > priv_data ; MOVTrack * track = & mov - > tracks[tracknum] ; AVPacket pkt = { . stream_index = tracknum , . flags = AV_PKT_FLAG_KEY } ; int i , len ; // These properties are required to make QT recognize the chapter track uint8_t chapter_properties[43] = { 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , } ; track - > mode = mov - > mode ; track - > tag = MKTAG ( ' t ' , ' e ' , ' x ' , ' t ' ) ; track - > timescale = MOV_TIMESCALE ; track - > enc = avcodec_alloc_context3 ( NULL ) ; if ( ! track - > enc ) track - > enc - > codec_type = AVMEDIA_TYPE_SUBTITLE ; track - > enc - > extradata = av_malloc ( sizeof ( chapter_properties ) ) ; if ( track - > enc - > extradata == NULL ) track - > enc - > extradata_size = sizeof ( chapter_properties ) ; memcpy ( track - > enc - > extradata , chapter_properties , sizeof ( chapter_properties ) ) ; for ( i = 0 ; i < s - > nb_chapters ; i + + ) { AVChapter * c = s - > chapters[i] ; AVDictionaryEntry * t ; int64_t end = av_rescale_q ( c - > end , c - > time_base , ( AVRational ) { 1 , MOV_TIMESCALE } ) ; pkt . pts = pkt . dts = av_rescale_q ( c - > start , c - > time_base , ( AVRational ) { 1 , MOV_TIMESCALE } ) ; pkt . duration = end - pkt . dts ; if ( ( t = av_dict_get ( c - > metadata , title , NULL , 0 ) ) ) { len = strlen ( t - > value ) ; pkt . size = len + 2 ; pkt . data = av_malloc ( pkt . size ) ; AV_WB16 ( pkt . data , len ) ; memcpy ( pkt . data + 2 , t - > value , len ) ; ff_mov_write_packet ( s , & pkt ) ; av_freep ( & pkt . data ) ; } } return 0 ; }",1
"static av_cold int vc2_encode_init ( AVCodecContext * avctx ) { Plane * p ; SubBand * b ; int i , j , level , o , shift , ret ; const AVPixFmtDescriptor * fmt = av_pix_fmt_desc_get ( avctx - > pix_fmt ) ; const int depth = fmt - > comp[0] . depth ; VC2EncContext * s = avctx - > priv_data ; s - > picture_number = 0 ; / * Total allowed quantization range * / s - > q_ceil = DIRAC_MAX_QUANT_INDEX ; s - > ver . major = 2 ; s - > ver . minor = 0 ; s - > profile = 3 ; s - > level = 3 ; s - > base_vf = - 1 ; s - > strict_compliance = 1 ; s - > q_avg = 0 ; s - > slice_max_bytes = 0 ; s - > slice_min_bytes = 0 ; / * Mark unknown as progressive * / s - > interlaced = ! ( ( avctx - > field_order == AV_FIELD_UNKNOWN ) || ( avctx - > field_order == AV_FIELD_PROGRESSIVE ) ) ; for ( i = 0 ; i < base_video_fmts_len ; i + + ) { const VC2BaseVideoFormat * fmt = & base_video_fmts[i] ; if ( avctx - > pix_fmt ! = fmt - > pix_fmt ) continue ; if ( avctx - > time_base . num ! = fmt - > time_base . num ) continue ; if ( avctx - > time_base . den ! = fmt - > time_base . den ) continue ; if ( avctx - > width ! = fmt - > width ) continue ; if ( avctx - > height ! = fmt - > height ) continue ; if ( s - > interlaced ! = fmt - > interlaced ) continue ; s - > base_vf = i ; s - > level = base_video_fmts[i] . level ; break ; } if ( s - > interlaced ) av_log ( avctx , AV_LOG_WARNING , Interlacing enabled ! \n ) ; if ( ( s - > slice_width & ( s - > slice_width - 1 ) ) || ( s - > slice_height & ( s - > slice_height - 1 ) ) ) { av_log ( avctx , AV_LOG_ERROR , Slice size is not a power of two ! \n ) ; return AVERROR_UNKNOWN ; } if ( ( s - > slice_width > avctx - > width ) || ( s - > slice_height > avctx - > height ) ) { av_log ( avctx , AV_LOG_ERROR , Slice size is bigger than the image ! \n ) ; return AVERROR_UNKNOWN ; } if ( s - > base_vf < = 0 ) { if ( avctx - > strict_std_compliance < FF_COMPLIANCE_STRICT ) { s - > strict_compliance = s - > base_vf = 0 ; av_log ( avctx , AV_LOG_WARNING , Format does not strictly comply with VC2 specs\n ) ; } else { av_log ( avctx , AV_LOG_WARNING , Given format does not strictly comply with the specifications , decrease strictness to use it . \n ) ; return AVERROR_UNKNOWN ; } } else { av_log ( avctx , AV_LOG_INFO , Selected base video format = %i ( %s ) \n , s - > base_vf , base_video_fmts[s - > base_vf] . name ) ; } / * Chroma subsampling * / ret = av_pix_fmt_get_chroma_sub_sample ( avctx - > pix_fmt , & s - > chroma_x_shift , & s - > chroma_y_shift ) ; if ( ret ) return ret ; / * Bit depth and color range index * / if ( depth == 8 & & avctx - > color_range == AVCOL_RANGE_JPEG ) { s - > bpp = 1 ; s - > bpp_idx = 1 ; s - > diff_offset = 128 ; } else if ( depth == 8 & & ( avctx - > color_range == AVCOL_RANGE_MPEG || avctx - > color_range == AVCOL_RANGE_UNSPECIFIED ) ) { s - > bpp = 1 ; s - > bpp_idx = 2 ; s - > diff_offset = 128 ; } else if ( depth == 10 ) { s - > bpp = 2 ; s - > bpp_idx = 3 ; s - > diff_offset = 512 ; } else { s - > bpp = 2 ; s - > bpp_idx = 4 ; s - > diff_offset = 2048 ; } / * Planes initialization * / for ( i = 0 ; i < 3 ; i + + ) { int w , h ; p = & s - > plane[i] ; p - > width = avctx - > width > > ( i ? s - > chroma_x_shift : 0 ) ; p - > height = avctx - > height > > ( i ? s - > chroma_y_shift : 0 ) ; if ( s - > interlaced ) p - > height > > = 1 ; p - > dwt_width = w = FFALIGN ( p - > width , ( 1 < < s - > wavelet_depth ) ) ; p - > dwt_height = h = FFALIGN ( p - > height , ( 1 < < s - > wavelet_depth ) ) ; p - > coef_stride = FFALIGN ( p - > dwt_width , 32 ) ; p - > coef_buf = av_malloc ( p - > coef_stride * p - > dwt_height * sizeof ( dwtcoef ) ) ; if ( ! p - > coef_buf ) goto alloc_fail ; for ( level = s - > wavelet_depth - 1 ; level > = 0 ; level - - ) { w = w > > 1 ; h = h > > 1 ; for ( o = 0 ; o < 4 ; o + + ) { b = & p - > band[level][o] ; b - > width = w ; b - > height = h ; b - > stride = p - > coef_stride ; shift = ( o > 1 ) * b - > height * b - > stride + ( o & 1 ) * b - > width ; b - > buf = p - > coef_buf + shift ; } } / * DWT init * / if ( ff_vc2enc_init_transforms ( & s - > transform_args[i] . t , s - > plane[i] . coef_stride , s - > plane[i] . dwt_height ) ) goto alloc_fail ; } / * Slices * / s - > num_x = s - > plane[0] . dwt_width/s - > slice_width ; s - > num_y = s - > plane[0] . dwt_height/s - > slice_height ; s - > slice_args = av_calloc ( s - > num_x * s - > num_y , sizeof ( SliceArgs ) ) ; if ( ! s - > slice_args ) goto alloc_fail ; / * Lookup tables * / s - > coef_lut_len = av_malloc ( COEF_LUT_TAB * ( s - > q_ceil + 1 ) * sizeof (",1
"static void compute_rematrixing_strategy ( AC3EncodeContext * s ) { int nb_coefs ; int blk , bnd , i ; AC3Block * block , * av_uninit ( block0 ) ; if ( s - > channel_mode ! = AC3_CHMODE_STEREO ) return ; for ( blk = 0 ; blk < AC3_MAX_BLOCKS ; blk + + ) { block = & s - > blocks[blk] ; block - > new_rematrixing_strategy = ! blk ; if ( ! s - > rematrixing_enabled ) { block0 = block ; continue ; } block - > num_rematrixing_bands = 4 ; if ( block - > cpl_in_use ) { block - > num_rematrixing_bands - = ( s - > start_freq[CPL_CH] < = 61 ) ; block - > num_rematrixing_bands - = ( s - > start_freq[CPL_CH] == 37 ) ; if ( blk & & block - > num_rematrixing_bands ! = block0 - > num_rematrixing_bands ) block - > new_rematrixing_strategy = 1 ; } nb_coefs = FFMIN ( block - > end_freq[1] , block - > end_freq[2] ) ; for ( bnd = 0 ; bnd < block - > num_rematrixing_bands ; bnd + + ) { / * calculate calculate sum of squared coeffs for one band in one block * / int start = ff_ac3_rematrix_band_tab[bnd] ; int end = FFMIN ( nb_coefs , ff_ac3_rematrix_band_tab[bnd + 1] ) ; CoefSumType sum[4] = { 0 , } ; for ( i = start ; i < end ; i + + ) { CoefType lt = block - > mdct_coef[1][i] ; CoefType rt = block - > mdct_coef[2][i] ; CoefType md = lt + rt ; CoefType sd = lt - rt ; MAC_COEF ( sum[0] , lt , lt ) ; MAC_COEF ( sum[1] , rt , rt ) ; MAC_COEF ( sum[2] , md , md ) ; MAC_COEF ( sum[3] , sd , sd ) ; } / * compare sums to determine if rematrixing will be used for this band * / if ( FFMIN ( sum[2] , sum[3] ) < FFMIN ( sum[0] , sum[1] ) ) block - > rematrixing_flags[bnd] = 1 ; else block - > rematrixing_flags[bnd] = 0 ; / * determine if new rematrixing flags will be sent * / if ( blk & & block - > rematrixing_flags[bnd] ! = block0 - > rematrixing_flags[bnd] ) { block - > new_rematrixing_strategy = 1 ; } } block0 = block ; } }",0
"int ff_msmpeg4_pred_dc ( MpegEncContext * s , int n , int16_t * * dc_val_ptr , int * dir_ptr ) { int a , b , c , wrap , pred , scale ; int16_t * dc_val ; / * find prediction * / if ( n < 4 ) { scale = s - > y_dc_scale ; } else { scale = s - > c_dc_scale ; } wrap = s - > block_wrap[n] ; dc_val= s - > dc_val[0] + s - > block_index[n] ; / * B C * A X * / a = dc_val[ - 1] ; b = dc_val[ - 1 - wrap] ; c = dc_val[ - wrap] ; if ( s - > first_slice_line & & ( n & 2 ) ==0 & & s - > msmpeg4_version < 4 ) { b=c=1024 ; } / * XXX : the following solution consumes divisions , but it does not necessitate to modify mpegvideo . c . The problem comes from the fact they decided to store the quantized DC ( which would lead to problems if Q could vary ! ) * / if ARCH_X86 & & HAVE_7REGS & & HAVE_EBX_AVAILABLE __asm__ volatile ( movl %3 , %%eax \n\t shrl 1 , %%eax \n\t addl %%eax , %2 \n\t addl %%eax , %1 \n\t addl %0 , %%eax \n\t mull %4 \n\t movl %%edx , %0 \n\t movl %1 , %%eax \n\t mull %4 \n\t movl %%edx , %1 \n\t movl %2 , %%eax \n\t mull %4 \n\t movl %%edx , %2 \n\t : + b ( a ) , + c ( b ) , + D ( c ) : g ( scale ) , S ( ff_inverse[scale] ) : %eax , %edx ) ; else / * Divisions are costly everywhere ; optimize the most common case . * / if ( scale == 8 ) { a = ( a + ( 8 > > 1 ) ) / 8 ; b = ( b + ( 8 > > 1 ) ) / 8 ; c = ( c + ( 8 > > 1 ) ) / 8 ; } else { a = FASTDIV ( ( a + ( scale > > 1 ) ) , scale ) ; b = FASTDIV ( ( b + ( scale > > 1 ) ) , scale ) ; c = FASTDIV ( ( c + ( scale > > 1 ) ) , scale ) ; } endif / * XXX : WARNING : they did not choose the same test as MPEG4 . This is very important ! * / if ( s - > msmpeg4_version > 3 ) { if ( s - > inter_intra_pred ) { uint8_t * dest ; int wrap ; if ( n==1 ) { pred=a ; * dir_ptr = 0 ; } else if ( n==2 ) { pred=c ; * dir_ptr = 1 ; } else if ( n==3 ) { if ( abs ( a - b ) < abs ( b - c ) ) { pred = c ; * dir_ptr = 1 ; } else { pred = a ; * dir_ptr = 0 ; } } else { if ( n < 4 ) { wrap= s - > linesize ; dest= s - > current_picture . f . data[0] + ( ( ( n > > 1 ) + 2 * s - > mb_y ) * 8 * wrap ) + ( ( n & 1 ) + 2 * s - > mb_x ) * 8 ; } else { wrap= s - > uvlinesize ; dest= s - > current_picture . f . data[n - 3] + ( s - > mb_y * 8 * wrap ) + s - > mb_x * 8 ; } if ( s - > mb_x==0 ) a= ( 1024 + ( scale > > 1 ) ) /scale ; else a= get_dc ( dest - 8 , wrap , scale * 8 ) ; if ( s - > mb_y==0 ) c= ( 1024 + ( scale > > 1 ) ) /scale ; else c= get_dc ( dest - 8 * wrap , wrap , scale * 8 ) ; if ( s - > h263_aic_dir==0 ) { pred= a ; * dir_ptr = 0 ; } else if ( s - > h263_aic_dir==1 ) { if ( n==0 ) { pred= c ; * dir_ptr = 1 ; } else { pred= a ; * dir_ptr = 0 ; } } else if ( s - > h263_aic_dir==2 ) { if ( n==0 ) { pred= a ; * dir_ptr = 0 ; } else { pred= c ; * dir_ptr = 1 ; } } else { pred= c ; * dir_ptr = 1 ; } } } else { if ( abs ( a - b ) < abs ( b - c ) ) { pred = c ; * dir_ptr = 1 ; } else { pred = a ; * dir_ptr = 0 ; } } } else { if ( abs ( a - b ) < = abs ( b - c ) ) { pred = c ; * dir_ptr = 1 ; } else { pred = a ; * dir_ptr = 0 ; } } / * update predictor * / * dc_val_ptr = & dc_val[0] ; return pred ; }",1
"int url_open ( URLContext * * puc , const char * filename , int flags ) { URLProtocol * up ; const char * p ; char proto_str[128] , * q ; p = filename ; q = proto_str ; while ( * p ! = ' \0 ' & & * p ! = ' : ' ) { / * protocols can only contain alphabetic chars * / if ( ! isalpha ( * p ) ) goto file_proto ; if ( ( q - proto_str ) < sizeof ( proto_str ) - 1 ) * q + + = * p ; p + + ; } / * if the protocol has length 1 , we consider it is a dos drive * / if ( * p == ' \0 ' || ( q - proto_str ) < = 1 ) { file_proto : strcpy ( proto_str , file ) ; } else { * q = ' \0 ' ; } up = first_protocol ; while ( up ! = NULL ) { if ( ! strcmp ( proto_str , up - > name ) ) return url_open_protocol ( puc , up , filename , flags ) ; up = up - > next ; } * puc = NULL ; return AVERROR ( ENOENT ) ; }",1
"struct SwsContext * sws_getContext ( int srcW , int srcH , int srcFormat , int dstW , int dstH , int dstFormat , int flags , SwsFilter * srcFilter , SwsFilter * dstFilter , double * param ) { struct SwsContext * ctx ; ctx = av_malloc ( sizeof ( struct SwsContext ) ) ; if ( ctx ) ctx - > av_class = av_mallocz ( sizeof ( AVClass ) ) ; if ( ! ctx || ! ctx - > av_class ) { av_log ( NULL , AV_LOG_ERROR , Cannot allocate a resampling context ! \n ) ; return NULL ; } if ( ( srcH ! = dstH ) || ( srcW ! = dstW ) ) { if ( ( srcFormat ! = PIX_FMT_YUV420P ) || ( dstFormat ! = PIX_FMT_YUV420P ) ) { av_log ( NULL , AV_LOG_INFO , PIX_FMT_YUV420P will be used as an intermediate format for rescaling\n ) ; } ctx - > resampling_ctx = img_resample_init ( dstW , dstH , srcW , srcH ) ; } else { ctx - > resampling_ctx = av_malloc ( sizeof ( ImgReSampleContext ) ) ; ctx - > resampling_ctx - > iheight = srcH ; ctx - > resampling_ctx - > iwidth = srcW ; ctx - > resampling_ctx - > oheight = dstH ; ctx - > resampling_ctx - > owidth = dstW ; } ctx - > src_pix_fmt = srcFormat ; ctx - > dst_pix_fmt = dstFormat ; return ctx ; }",1
"static int vp8_encode ( AVCodecContext * avctx , AVPacket * pkt , const AVFrame * frame , int * got_packet ) { VP8Context * ctx = avctx - > priv_data ; struct vpx_image * rawimg = NULL ; struct vpx_image * rawimg_alpha = NULL ; int64_t timestamp = 0 ; int res , coded_size ; vpx_enc_frame_flags_t flags = 0 ; if ( frame ) { rawimg = & ctx - > rawimg ; rawimg - > planes[VPX_PLANE_Y] = frame - > data[0] ; rawimg - > planes[VPX_PLANE_U] = frame - > data[1] ; rawimg - > planes[VPX_PLANE_V] = frame - > data[2] ; rawimg - > stride[VPX_PLANE_Y] = frame - > linesize[0] ; rawimg - > stride[VPX_PLANE_U] = frame - > linesize[1] ; rawimg - > stride[VPX_PLANE_V] = frame - > linesize[2] ; if ( ctx - > is_alpha ) { uint8_t * u_plane , * v_plane ; rawimg_alpha = & ctx - > rawimg_alpha ; rawimg_alpha - > planes[VPX_PLANE_Y] = frame - > data[3] ; u_plane = av_malloc ( frame - > linesize[1] * frame - > height ) ; memset ( u_plane , 0x80 , frame - > linesize[1] * frame - > height ) ; rawimg_alpha - > planes[VPX_PLANE_U] = u_plane ; v_plane = av_malloc ( frame - > linesize[2] * frame - > height ) ; memset ( v_plane , 0x80 , frame - > linesize[2] * frame - > height ) ; rawimg_alpha - > planes[VPX_PLANE_V] = v_plane ; rawimg_alpha - > stride[VPX_PLANE_Y] = frame - > linesize[0] ; rawimg_alpha - > stride[VPX_PLANE_U] = frame - > linesize[1] ; rawimg_alpha - > stride[VPX_PLANE_V] = frame - > linesize[2] ; } timestamp = frame - > pts ; if ( frame - > pict_type == AV_PICTURE_TYPE_I ) flags |= VPX_EFLAG_FORCE_KF ; } res = vpx_codec_encode ( & ctx - > encoder , rawimg , timestamp , avctx - > ticks_per_frame , flags , ctx - > deadline ) ; if ( res ! = VPX_CODEC_OK ) { log_encoder_error ( avctx , Error encoding frame ) ; return AVERROR_INVALIDDATA ; } if ( ctx - > is_alpha ) { res = vpx_codec_encode ( & ctx - > encoder_alpha , rawimg_alpha , timestamp , avctx - > ticks_per_frame , flags , ctx - > deadline ) ; if ( res ! = VPX_CODEC_OK ) { log_encoder_error ( avctx , Error encoding alpha frame ) ; return AVERROR_INVALIDDATA ; } } coded_size = queue_frames ( avctx , pkt , avctx - > coded_frame ) ; if ( ! frame & & avctx - > flags & CODEC_FLAG_PASS1 ) { unsigned int b64_size = AV_BASE64_SIZE ( ctx - > twopass_stats . sz ) ; avctx - > stats_out = av_malloc ( b64_size ) ; if ( ! avctx - > stats_out ) { av_log ( avctx , AV_LOG_ERROR , Stat buffer alloc ( %d bytes ) failed\n , b64_size ) ; return AVERROR ( ENOMEM ) ; } av_base64_encode ( avctx - > stats_out , b64_size , ctx - > twopass_stats . buf , ctx - > twopass_stats . sz ) ; } if ( rawimg_alpha ) { av_freep ( & rawimg_alpha - > planes[VPX_PLANE_U] ) ; av_freep ( & rawimg_alpha - > planes[VPX_PLANE_V] ) ; } * got_packet = ! ! coded_size ; return 0 ; }",1
void av_opt_freep_ranges ( AVOptionRanges * * rangesp ) { int i ; AVOptionRanges * ranges = * rangesp ; if ( ! ranges ) return ; for ( i = 0 ; i < ranges - > nb_ranges * ranges - > nb_components ; i + + ) { AVOptionRange * range = ranges - > range[i] ; av_freep ( & range - > str ) ; av_freep ( & ranges - > range[i] ) ; } av_freep ( & ranges - > range ) ; av_freep ( rangesp ) ; },1
"static int oggvorbis_encode_frame ( AVCodecContext * avctx , AVPacket * avpkt , const AVFrame * frame , int * got_packet_ptr ) { OggVorbisEncContext * s = avctx - > priv_data ; ogg_packet op ; int ret , duration ; / * send samples to libvorbis * / if ( frame ) { const int samples = frame - > nb_samples ; float * * buffer ; int c , channels = s - > vi . channels ; buffer = vorbis_analysis_buffer ( & s - > vd , samples ) ; for ( c = 0 ; c < channels ; c + + ) { int co = ( channels > 8 ) ? c : ff_vorbis_encoding_channel_layout_offsets[channels - 1][c] ; memcpy ( buffer[c] , frame - > extended_data[co] , samples * sizeof ( * buffer[c] ) ) ; } if ( ( ret = vorbis_analysis_wrote ( & s - > vd , samples ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , error in vorbis_analysis_wrote ( ) \n ) ; return vorbis_error_to_averror ( ret ) ; } if ( ( ret = ff_af_queue_add ( & s - > afq , frame ) ) < 0 ) return ret ; } else { if ( ! s - > eof ) if ( ( ret = vorbis_analysis_wrote ( & s - > vd , 0 ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , error in vorbis_analysis_wrote ( ) \n ) ; return vorbis_error_to_averror ( ret ) ; } s - > eof = 1 ; } / * retrieve available packets from libvorbis * / while ( ( ret = vorbis_analysis_blockout ( & s - > vd , & s - > vb ) ) == 1 ) { if ( ( ret = vorbis_analysis ( & s - > vb , NULL ) ) < 0 ) break ; if ( ( ret = vorbis_bitrate_addblock ( & s - > vb ) ) < 0 ) break ; / * add any available packets to the output packet buffer * / while ( ( ret = vorbis_bitrate_flushpacket ( & s - > vd , & op ) ) == 1 ) { if ( av_fifo_space ( s - > pkt_fifo ) < sizeof ( ogg_packet ) + op . bytes ) { av_log ( avctx , AV_LOG_ERROR , packet buffer is too small\n ) ; return AVERROR_BUG ; } av_fifo_generic_write ( s - > pkt_fifo , & op , sizeof ( ogg_packet ) , NULL ) ; av_fifo_generic_write ( s - > pkt_fifo , op . packet , op . bytes , NULL ) ; } if ( ret < 0 ) { av_log ( avctx , AV_LOG_ERROR , error getting available packets\n ) ; break ; } } if ( ret < 0 ) { av_log ( avctx , AV_LOG_ERROR , error getting available packets\n ) ; return vorbis_error_to_averror ( ret ) ; } / * check for available packets * / if ( av_fifo_size ( s - > pkt_fifo ) < sizeof ( ogg_packet ) ) return 0 ; av_fifo_generic_read ( s - > pkt_fifo , & op , sizeof ( ogg_packet ) , NULL ) ; if ( ( ret = ff_alloc_packet2 ( avctx , avpkt , op . bytes ) ) ) return ret ; av_fifo_generic_read ( s - > pkt_fifo , avpkt - > data , op . bytes , NULL ) ; avpkt - > pts = ff_samples_to_time_base ( avctx , op . granulepos ) ; duration = avpriv_vorbis_parse_frame ( & s - > vp , avpkt - > data , avpkt - > size ) ; if ( duration > 0 ) { / * we do not know encoder delay until we get the first packet from * libvorbis , so we have to update the AudioFrameQueue counts * / if ( ! avctx - > delay & & s - > afq . frames ) { avctx - > delay = duration ; av_assert0 ( ! s - > afq . remaining_delay ) ; s - > afq . frames - > duration + = duration ; s - > afq . frames - > pts - = duration ; s - > afq . remaining_samples + = duration ; } ff_af_queue_remove ( & s - > afq , duration , & avpkt - > pts , & avpkt - > duration ) ; } * got_packet_ptr = 1 ; return 0 ; }",0
static av_cold int rv40_decode_init ( AVCodecContext * avctx ) { RV34DecContext * r = avctx - > priv_data ; r - > rv30 = 0 ; ff_rv34_decode_init ( avctx ) ; if ( ! aic_top_vlc . bits ) rv40_init_tables ( ) ; r - > parse_slice_header = rv40_parse_slice_header ; r - > decode_intra_types = rv40_decode_intra_types ; r - > decode_mb_info = rv40_decode_mb_info ; r - > loop_filter = rv40_loop_filter ; r - > luma_dc_quant_i = rv40_luma_dc_quant[0] ; r - > luma_dc_quant_p = rv40_luma_dc_quant[1] ; return 0 ; },1
"void ff_er_add_slice ( ERContext * s , int startx , int starty , int endx , int endy , int status ) { const int start_i = av_clip ( startx + starty * s - > mb_width , 0 , s - > mb_num - 1 ) ; const int end_i = av_clip ( endx + endy * s - > mb_width , 0 , s - > mb_num ) ; const int start_xy = s - > mb_index2xy[start_i] ; const int end_xy = s - > mb_index2xy[end_i] ; int mask = - 1 ; if ( s - > avctx - > hwaccel ) return ; if ( start_i > end_i || start_xy > end_xy ) { av_log ( s - > avctx , AV_LOG_ERROR , internal error , slice end before start\n ) ; return ; } if ( ! s - > avctx - > err_recognition ) return ; mask & = VP_START ; if ( status & ( ER_AC_ERROR | ER_AC_END ) ) { mask & = ( ER_AC_ERROR | ER_AC_END ) ; s - > error_count - = end_i - start_i + 1 ; } if ( status & ( ER_DC_ERROR | ER_DC_END ) ) { mask & = ( ER_DC_ERROR | ER_DC_END ) ; s - > error_count - = end_i - start_i + 1 ; } if ( status & ( ER_MV_ERROR | ER_MV_END ) ) { mask & = ( ER_MV_ERROR | ER_MV_END ) ; s - > error_count - = end_i - start_i + 1 ; } if ( status & ER_MB_ERROR ) { s - > error_occurred = 1 ; s - > error_count = INT_MAX ; } if ( mask == 0x7F ) { memset ( & s - > error_status_table[start_xy] , 0 , ( end_xy - start_xy ) * sizeof ( uint8_t ) ) ; } else { int i ; for ( i = start_xy ; i < end_xy ; i + + ) s - > error_status_table[i] & = mask ; } if ( end_i == s - > mb_num ) s - > error_count = INT_MAX ; else { s - > error_status_table[end_xy] & = mask ; s - > error_status_table[end_xy] |= status ; } s - > error_status_table[start_xy] |= VP_START ; if ( start_xy > 0 & & ! ( s - > avctx - > active_thread_type & FF_THREAD_SLICE ) & & s - > avctx - > skip_top * s - > mb_width < start_i ) { int prev_status = s - > error_status_table[s - > mb_index2xy[start_i - 1]] ; prev_status & = VP_START ; if ( prev_status ! = ( ER_MV_END | ER_DC_END | ER_AC_END ) ) { s - > error_occurred = 1 ; s - > error_count = INT_MAX ; } } }",0
"static void avc_luma_hv_qrt_4w_msa ( const uint8_t * src_x , const uint8_t * src_y , int32_t src_stride , uint8_t * dst , int32_t dst_stride , int32_t height ) { uint32_t loop_cnt ; v16i8 src_hz0 , src_hz1 , src_hz2 , src_hz3 ; v16i8 src_vt0 , src_vt1 , src_vt2 , src_vt3 , src_vt4 ; v16i8 src_vt5 , src_vt6 , src_vt7 , src_vt8 ; v16i8 mask0 , mask1 , mask2 ; v8i16 hz_out0 , hz_out1 , vert_out0 , vert_out1 ; v8i16 out0 , out1 ; v16u8 out ; LD_SB3 ( & luma_mask_arr[48] , 16 , mask0 , mask1 , mask2 ) ; LD_SB5 ( src_y , src_stride , src_vt0 , src_vt1 , src_vt2 , src_vt3 , src_vt4 ) ; src_y + = ( 5 * src_stride ) ; src_vt0 = ( v16i8 ) __msa_insve_w ( ( v4i32 ) src_vt0 , 1 , ( v4i32 ) src_vt1 ) ; src_vt1 = ( v16i8 ) __msa_insve_w ( ( v4i32 ) src_vt1 , 1 , ( v4i32 ) src_vt2 ) ; src_vt2 = ( v16i8 ) __msa_insve_w ( ( v4i32 ) src_vt2 , 1 , ( v4i32 ) src_vt3 ) ; src_vt3 = ( v16i8 ) __msa_insve_w ( ( v4i32 ) src_vt3 , 1 , ( v4i32 ) src_vt4 ) ; XORI_B4_128_SB ( src_vt0 , src_vt1 , src_vt2 , src_vt3 ) ; for ( loop_cnt = ( height > > 2 ) ; loop_cnt - - ; ) { LD_SB4 ( src_x , src_stride , src_hz0 , src_hz1 , src_hz2 , src_hz3 ) ; src_x + = ( 4 * src_stride ) ; XORI_B4_128_SB ( src_hz0 , src_hz1 , src_hz2 , src_hz3 ) ; hz_out0 = AVC_XOR_VSHF_B_AND_APPLY_6TAP_HORIZ_FILT_SH ( src_hz0 , src_hz1 , mask0 , mask1 , mask2 ) ; hz_out1 = AVC_XOR_VSHF_B_AND_APPLY_6TAP_HORIZ_FILT_SH ( src_hz2 , src_hz3 , mask0 , mask1 , mask2 ) ; SRARI_H2_SH ( hz_out0 , hz_out1 , 5 ) ; SAT_SH2_SH ( hz_out0 , hz_out1 , 7 ) ; LD_SB4 ( src_y , src_stride , src_vt5 , src_vt6 , src_vt7 , src_vt8 ) ; src_y + = ( 4 * src_stride ) ; src_vt4 = ( v16i8 ) __msa_insve_w ( ( v4i32 ) src_vt4 , 1 , ( v4i32 ) src_vt5 ) ; src_vt5 = ( v16i8 ) __msa_insve_w ( ( v4i32 ) src_vt5 , 1 , ( v4i32 ) src_vt6 ) ; src_vt6 = ( v16i8 ) __msa_insve_w ( ( v4i32 ) src_vt6 , 1 , ( v4i32 ) src_vt7 ) ; src_vt7 = ( v16i8 ) __msa_insve_w ( ( v4i32 ) src_vt7 , 1 , ( v4i32 ) src_vt8 ) ; XORI_B4_128_SB ( src_vt4 , src_vt5 , src_vt6 , src_vt7 ) ; / * filter calc * / vert_out0 = AVC_CALC_DPADD_B_6PIX_2COEFF_R_SH ( src_vt0 , src_vt1 , src_vt2 , src_vt3 , src_vt4 , src_vt5 ) ; vert_out1 = AVC_CALC_DPADD_B_6PIX_2COEFF_R_SH ( src_vt2 , src_vt3 , src_vt4 , src_vt5 , src_vt6 , src_vt7 ) ; SRARI_H2_SH ( vert_out0 , vert_out1 , 5 ) ; SAT_SH2_SH ( vert_out0 , vert_out1 , 7 ) ; out0 = __msa_srari_h ( ( hz_out0 + vert_out0 ) , 1 ) ; out1 = __msa_srari_h ( ( hz_out1 + vert_out1 ) , 1 ) ; SAT_SH2_SH ( out0 , out1 , 7 ) ; out = PCKEV_XORI128_UB ( out0 , out1 ) ; ST4x4_UB ( out , out , 0 , 1 , 2 , 3 , dst , dst_stride ) ; dst + = ( 4 * dst_stride ) ; src_vt3 = src_vt7 ; src_vt1 = src_vt5 ; src_vt0 = src_vt4 ; src_vt4 = src_vt8 ; src_vt2 = src_vt6 ; } }",0
"static void qtrle_decode_24bpp ( QtrleContext * s ) { int stream_ptr ; int header ; int start_line ; int lines_to_change ; signed char rle_code ; int row_ptr , pixel_ptr ; int row_inc = s - > frame . linesize[0] ; unsigned char r , g , b ; unsigned char * rgb = s - > frame . data[0] ; int pixel_limit = s - > frame . linesize[0] * s - > avctx - > height ; / * check if this frame is even supposed to change * / if ( s - > size < 8 ) return ; / * start after the chunk size * / stream_ptr = 4 ; / * fetch the header * / CHECK_STREAM_PTR ( 2 ) ; header = BE_16 ( & s - > buf[stream_ptr] ) ; stream_ptr + = 2 ; / * if a header is present , fetch additional decoding parameters * / if ( header & 0x0008 ) { CHECK_STREAM_PTR ( 8 ) ; start_line = BE_16 ( & s - > buf[stream_ptr] ) ; stream_ptr + = 4 ; lines_to_change = BE_16 ( & s - > buf[stream_ptr] ) ; stream_ptr + = 4 ; } else { start_line = 0 ; lines_to_change = s - > avctx - > height ; } row_ptr = row_inc * start_line ; while ( lines_to_change - - ) { CHECK_STREAM_PTR ( 2 ) ; pixel_ptr = row_ptr + ( s - > buf[stream_ptr + + ] - 1 ) * 3 ; while ( ( rle_code = ( signed char ) s - > buf[stream_ptr + + ] ) ! = - 1 ) { if ( rle_code == 0 ) { / * there ' s another skip code in the stream * / CHECK_STREAM_PTR ( 1 ) ; pixel_ptr + = ( s - > buf[stream_ptr + + ] - 1 ) * 3 ; CHECK_PIXEL_PTR ( 0 ) ; / * make sure pixel_ptr is positive * / } else if ( rle_code < 0 ) { / * decode the run length code * / rle_code = - rle_code ; CHECK_STREAM_PTR ( 3 ) ; r = s - > buf[stream_ptr + + ] ; g = s - > buf[stream_ptr + + ] ; b = s - > buf[stream_ptr + + ] ; CHECK_PIXEL_PTR ( rle_code * 3 ) ; while ( rle_code - - ) { rgb[pixel_ptr + + ] = r ; rgb[pixel_ptr + + ] = g ; rgb[pixel_ptr + + ] = b ; } } else { CHECK_STREAM_PTR ( rle_code * 3 ) ; CHECK_PIXEL_PTR ( rle_code * 3 ) ; / * copy pixels directly to output * / while ( rle_code - - ) { rgb[pixel_ptr + + ] = s - > buf[stream_ptr + + ] ; rgb[pixel_ptr + + ] = s - > buf[stream_ptr + + ] ; rgb[pixel_ptr + + ] = s - > buf[stream_ptr + + ] ; } } } row_ptr + = row_inc ; } }",1
"static void rtcp_send_sr ( AVFormatContext * s1 , int64_t ntp_time ) { RTPDemuxContext * s = s1 - > priv_data ; uint32_t rtp_ts ; if defined ( DEBUG ) printf ( RTCP : %02x % PRIx64 %x\n , s - > payload_type , ntp_time , s - > timestamp ) ; endif if ( s - > first_rtcp_ntp_time == AV_NOPTS_VALUE ) s - > first_rtcp_ntp_time = ntp_time ; s - > last_rtcp_ntp_time = ntp_time ; rtp_ts = av_rescale_q ( ntp_time - s - > first_rtcp_ntp_time , AV_TIME_BASE_Q , s1 - > streams[0] - > time_base ) + s - > base_timestamp ; put_byte ( s1 - > pb , ( RTP_VERSION < < 6 ) ) ; put_byte ( s1 - > pb , 200 ) ; put_be16 ( s1 - > pb , 6 ) ; / * length in words - 1 * / put_be32 ( s1 - > pb , s - > ssrc ) ; put_be32 ( s1 - > pb , ntp_time / 1000000 ) ; put_be32 ( s1 - > pb , ( ( ntp_time % 1000000 ) < < 32 ) / 1000000 ) ; put_be32 ( s1 - > pb , rtp_ts ) ; put_be32 ( s1 - > pb , s - > packet_count ) ; put_be32 ( s1 - > pb , s - > octet_count ) ; put_flush_packet ( s1 - > pb ) ; }",1
"static void decode_cabac_residual ( H264Context * h , DCTELEM * block , int cat , int n , const uint8_t * scantable , const uint32_t * qmul , int max_coeff ) { static const int significant_coeff_flag_offset[2][6] = { { 105 + 0 , 105 + 15 , 105 + 29 , 105 + 44 , 105 + 47 , 402 } , { 277 + 0 , 277 + 15 , 277 + 29 , 277 + 44 , 277 + 47 , 436 } } ; static const int last_coeff_flag_offset[2][6] = { { 166 + 0 , 166 + 15 , 166 + 29 , 166 + 44 , 166 + 47 , 417 } , { 338 + 0 , 338 + 15 , 338 + 29 , 338 + 44 , 338 + 47 , 451 } } ; static const int coeff_abs_level_m1_offset[6] = { 227 + 0 , 227 + 10 , 227 + 20 , 227 + 30 , 227 + 39 , 426 } ; static const uint8_t significant_coeff_flag_offset_8x8[2][63] = { { 0 , 1 , 2 , 3 , 4 , 5 , 5 , 4 , 4 , 3 , 3 , 4 , 4 , 4 , 5 , 5 , 4 , 4 , 4 , 4 , 3 , 3 , 6 , 7 , 7 , 7 , 8 , 9 , 10 , 9 , 8 , 7 , 7 , 6 , 11 , 12 , 13 , 11 , 6 , 7 , 8 , 9 , 14 , 10 , 9 , 8 , 6 , 11 , 12 , 13 , 11 , 6 , 9 , 14 , 10 , 9 , 11 , 12 , 13 , 11 , 14 , 10 , 12 } , { 0 , 1 , 1 , 2 , 2 , 3 , 3 , 4 , 5 , 6 , 7 , 7 , 7 , 8 , 4 , 5 , 6 , 9 , 10 , 10 , 8 , 11 , 12 , 11 , 9 , 9 , 10 , 10 , 8 , 11 , 12 , 11 , 9 , 9 , 10 , 10 , 8 , 11 , 12 , 11 , 9 , 9 , 10 , 10 , 8 , 13 , 13 , 9 , 9 , 10 , 10 , 8 , 13 , 13 , 9 , 9 , 10 , 10 , 14 , 14 , 14 , 14 , 14 } } ; / * node ctx : 0 . . 3 : abslevel1 ( with abslevelgt1 == 0 ) . * 4 . . 7 : abslevelgt1 + 3 ( and abslevel1 doesn ' t matter ) . * map node ctx = > cabac ctx for level=1 * / static const uint8_t coeff_abs_level1_ctx[8] = { 1 , 2 , 3 , 4 , 0 , 0 , 0 , 0 } ; / * map node ctx = > cabac ctx for level > 1 * / static const uint8_t coeff_abs_levelgt1_ctx[8] = { 5 , 5 , 5 , 5 , 6 , 7 , 8 , 9 } ; static const uint8_t coeff_abs_level_transition[2][8] = { / * update node ctx after decoding a level=1 * / { 1 , 2 , 3 , 3 , 4 , 5 , 6 , 7 } , / * update node ctx after decoding a level > 1 * / { 4 , 4 , 4 , 4 , 5 , 6 , 7 , 7 } } ; int index[64] ; int av_unused last ; int coeff_count = 0 ; int node_ctx = 0 ; uint8_t * significant_coeff_ctx_base ; uint8_t * last_coeff_ctx_base ; uint8_t * abs_level_m1_ctx_base ; ifndef ARCH_X86 define CABAC_ON_STACK endif ifdef CABAC_ON_STACK define CC & cc CABACContext cc ; cc . range = h - > cabac . range ; cc . low = h - > cabac . low ; cc . bytestream= h - > cabac . bytestream ; else define CC & h - > cabac endif / * cat : 0 - > DC 16x16 n = 0 * 1 - > AC 16x16 n = luma4x4idx * 2 - > Luma4x4 n = luma4x4idx * 3 - > DC Chroma n = iCbCr * 4 - > AC Chroma n = 4 * iCbCr + chroma4x4idx * 5 - > Luma8x8 n = 4 * luma8x8idx * / / * read coded block flag * / if ( cat ! = 5 ) { if ( get_cabac ( CC , & h - > cabac_state[85 + get_cabac_cbf_ctx ( h , cat , n ) ] ) == 0 ) { if ( cat == 1 || cat == 2 ) h - > non_zero_count_cache[scan8[n]] = 0 ; else if ( cat == 4 ) h - > non_zero_count_cache[scan8[16 + n]] = 0 ; ifdef CABAC_ON_STACK h - > cabac . range = cc . range ; h - > cabac . low = cc . low ; h - > cabac . bytestream= cc . bytestream ; endif return ; } } significant_coeff_ctx_base = h - > cabac_state + significant_coeff_flag_offset[MB_FIELD][cat] ; last_coeff_ctx_base = h - > cabac_state + last_coeff_flag_offset[MB_FIELD][cat] ; abs_level_m1_ctx_base = h - > cabac_state + coeff_abs_level_m1_offset[cat] ; if ( cat == 5 ) { define DECODE_SIGNIFICANCE ( coefs , sig_off , last_off ) \ for ( last= 0 ; last < coefs ; last + + ) { \ uint8_t * sig_ctx = significant_coeff_ctx_base + sig_off ; \ if ( get_cabac ( CC , sig_ctx ) ) { \ uint8_t * last_ctx = last_coeff_ctx_base + last_off ; \ index[coeff_count + + ] = last ; \ if ( get_cabac ( CC , last_ctx ) ) { \ last= max_coeff ; \ break ; \ } \ } \ } \ if ( last == max_coeff - 1 ) { \ index[coeff_count + + ] = last ; \ } const uint8_t * sig_off = significant_coeff_flag_offset_8x8[MB_FIELD] ; if defined ( ARCH_X86 ) & & defined ( HAVE_7REGS ) & & defined ( HAVE_EBX_AVAILABLE ) & & ! defined ( BROKEN_RELOCATIONS ) coeff_count= decode_significance_8x8_x86 ( CC , significant_coeff_ctx_base , index , sig_off ) ; } else { coeff_count= decode_significance_x86 ( CC , max_coeff , significant_coeff_ctx_base , index ) ; else DECODE_SIGNIFICANCE ( 63 , sig_off[last] , last_coeff_flag_offset_8x8[last] ) ; } else { DECODE_SIGNIFICANCE ( max_coeff - 1 , last , last ) ; endif } assert ( coeff_count > 0 ) ; if ( cat == 0 ) h - > cbp_table[h - > mb_xy] |= 0x100 ; else if ( cat == 1 || cat == 2 ) h - > non_zero_count_cache[scan8[n]] = coeff_count ; else if ( cat == 3 ) h - > cbp_table[h - > mb_xy] |= 0x40 < < n ; else if ( cat == 4 ) h - > non_zero_count_cache[scan8[16 + n]] = coeff_count ; else { assert ( cat == 5 ) ; fill_rectangle ( & h - > non_zero_count_cache[scan8[n]] , 2 , 2 , 8 , coeff_count , 1 ) ; }",0
static inline void downmix_2f_2r_to_dolby ( float * samples ) { int i ; for ( i = 0 ; i < 256 ; i + + ) { samples[i] - = samples[i + 512] ; samples[i + 256] + = samples[i + 768] ; samples[i + 512] = samples[i + 768] = 0 ; } },0
"static int extract_extradata_h2645 ( AVBSFContext * ctx , AVPacket * pkt , uint8_t * * data , int * size ) { static const int extradata_nal_types_hevc[] = { HEVC_NAL_VPS , HEVC_NAL_SPS , HEVC_NAL_PPS , } ; static const int extradata_nal_types_h264[] = { H264_NAL_SPS , H264_NAL_PPS , } ; ExtractExtradataContext * s = ctx - > priv_data ; H2645Packet h2645_pkt = { 0 } ; int extradata_size = 0 ; const int * extradata_nal_types ; int nb_extradata_nal_types ; int i , has_sps = 0 , has_vps = 0 , ret = 0 ; if ( ctx - > par_in - > codec_id == AV_CODEC_ID_HEVC ) { extradata_nal_types = extradata_nal_types_hevc ; nb_extradata_nal_types = FF_ARRAY_ELEMS ( extradata_nal_types_hevc ) ; } else { extradata_nal_types = extradata_nal_types_h264 ; nb_extradata_nal_types = FF_ARRAY_ELEMS ( extradata_nal_types_h264 ) ; } ret = ff_h2645_packet_split ( & h2645_pkt , pkt - > data , pkt - > size , ctx , 0 , 0 , ctx - > par_in - > codec_id , 1 ) ; if ( ret < 0 ) return ret ; for ( i = 0 ; i < h2645_pkt . nb_nals ; i + + ) { H2645NAL * nal = & h2645_pkt . nals[i] ; if ( val_in_array ( extradata_nal_types , nb_extradata_nal_types , nal - > type ) ) { extradata_size + = nal - > raw_size + 3 ; if ( ctx - > par_in - > codec_id == AV_CODEC_ID_HEVC ) { if ( nal - > type == HEVC_NAL_SPS ) has_sps = 1 ; if ( nal - > type == HEVC_NAL_VPS ) has_vps = 1 ; } else { if ( nal - > type == H264_NAL_SPS ) has_sps = 1 ; } } } if ( extradata_size & & ( ( ctx - > par_in - > codec_id == AV_CODEC_ID_HEVC & & has_sps & & has_vps ) || ( ctx - > par_in - > codec_id == AV_CODEC_ID_H264 & & has_sps ) ) ) { AVBufferRef * filtered_buf ; uint8_t * extradata , * filtered_data ; if ( s - > remove ) { filtered_buf = av_buffer_alloc ( pkt - > size + AV_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! filtered_buf ) { ret = AVERROR ( ENOMEM ) ; goto fail ; } filtered_data = filtered_buf - > data ; } extradata = av_malloc ( extradata_size + AV_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! extradata ) { av_buffer_unref ( & filtered_buf ) ; ret = AVERROR ( ENOMEM ) ; goto fail ; } * data = extradata ; * size = extradata_size ; for ( i = 0 ; i < h2645_pkt . nb_nals ; i + + ) { H2645NAL * nal = & h2645_pkt . nals[i] ; if ( val_in_array ( extradata_nal_types , nb_extradata_nal_types , nal - > type ) ) { AV_WB24 ( extradata , 1 ) ; // startcode memcpy ( extradata + 3 , nal - > raw_data , nal - > raw_size ) ; extradata + = 3 + nal - > raw_size ; } else if ( s - > remove ) { AV_WB24 ( filtered_data , 1 ) ; // startcode memcpy ( filtered_data + 3 , nal - > raw_data , nal - > raw_size ) ; filtered_data + = 3 + nal - > raw_size ; } } if ( s - > remove ) { av_buffer_unref ( & pkt - > buf ) ; pkt - > buf = filtered_buf ; pkt - > data = filtered_buf - > data ; pkt - > size = filtered_data - filtered_buf - > data ; } } fail : ff_h2645_packet_uninit ( & h2645_pkt ) ; return ret ; }",1
av_cold void ff_psy_end ( FFPsyContext * ctx ) { if ( ctx - > model - > end ) ctx - > model - > end ( ctx ) ; av_freep ( & ctx - > bands ) ; av_freep ( & ctx - > num_bands ) ; av_freep ( & ctx - > group ) ; av_freep ( & ctx - > ch ) ; },1
"static void FUNC ( put_hevc_epel_bi_w_h ) ( uint8_t * _dst , ptrdiff_t _dststride , uint8_t * _src , ptrdiff_t _srcstride , int16_t * src2 , int height , int denom , int wx0 , int wx1 , int ox0 , int ox1 , intptr_t mx , intptr_t my , int width ) { int x , y ; pixel * src = ( pixel * ) _src ; ptrdiff_t srcstride = _srcstride / sizeof ( pixel ) ; pixel * dst = ( pixel * ) _dst ; ptrdiff_t dststride = _dststride / sizeof ( pixel ) ; const int8_t * filter = ff_hevc_epel_filters[mx - 1] ; int shift = 14 + 1 - BIT_DEPTH ; int log2Wd = denom + shift - 1 ; ox0 = ox0 * ( 1 < < ( BIT_DEPTH - 8 ) ) ; ox1 = ox1 * ( 1 < < ( BIT_DEPTH - 8 ) ) ; for ( y = 0 ; y < height ; y + + ) { for ( x = 0 ; x < width ; x + + ) dst[x] = av_clip_pixel ( ( ( EPEL_FILTER ( src , 1 ) > > ( BIT_DEPTH - 8 ) ) * wx1 + src2[x] * wx0 + ( ( ox0 + ox1 + 1 ) < < log2Wd ) ) > > ( log2Wd + 1 ) ) ; src + = srcstride ; dst + = dststride ; src2 + = MAX_PB_SIZE ; } }",1
"static inline void RENAME ( yuvPlanartoyuy2 ) ( const uint8_t * ysrc , const uint8_t * usrc , const uint8_t * vsrc , uint8_t * dst , unsigned int width , unsigned int height , int lumStride , int chromStride , int dstStride , int vertLumPerChroma ) { unsigned y ; const unsigned chromWidth= width > > 1 ; for ( y=0 ; y < height ; y + + ) { ifdef HAVE_MMX //FIXME handle 2 lines a once ( fewer prefetch , reuse some chrom , but very likely limited by mem anyway ) asm volatile ( xor %% REG_a , %% REG_a \n\t . balign 16 \n\t 1 : \n\t PREFETCH 32 ( %1 , %% REG_a , 2 ) \n\t PREFETCH 32 ( %2 , %% REG_a ) \n\t PREFETCH 32 ( %3 , %% REG_a ) \n\t movq ( %2 , %% REG_a ) , %%mm0 \n\t // U ( 0 ) movq %%mm0 , %%mm2 \n\t // U ( 0 ) movq ( %3 , %% REG_a ) , %%mm1 \n\t // V ( 0 ) punpcklbw %%mm1 , %%mm0 \n\t // UVUV UVUV ( 0 ) punpckhbw %%mm1 , %%mm2 \n\t // UVUV UVUV ( 8 ) movq ( %1 , %% REG_a , 2 ) , %%mm3 \n\t // Y ( 0 ) movq 8 ( %1 , %% REG_a , 2 ) , %%mm5 \n\t // Y ( 8 ) movq %%mm3 , %%mm4 \n\t // Y ( 0 ) movq %%mm5 , %%mm6 \n\t // Y ( 8 ) punpcklbw %%mm0 , %%mm3 \n\t // YUYV YUYV ( 0 ) punpckhbw %%mm0 , %%mm4 \n\t // YUYV YUYV ( 4 ) punpcklbw %%mm2 , %%mm5 \n\t // YUYV YUYV ( 8 ) punpckhbw %%mm2 , %%mm6 \n\t // YUYV YUYV ( 12 ) MOVNTQ %%mm3 , ( %0 , %% REG_a , 4 ) \n\t MOVNTQ %%mm4 , 8 ( %0 , %% REG_a , 4 ) \n\t MOVNTQ %%mm5 , 16 ( %0 , %% REG_a , 4 ) \n\t MOVNTQ %%mm6 , 24 ( %0 , %% REG_a , 4 ) \n\t add 8 , %% REG_a \n\t cmp %4 , %% REG_a \n\t jb 1b \n\t : : r ( dst ) , r ( ysrc ) , r ( usrc ) , r ( vsrc ) , g ( ( long ) chromWidth ) : % REG_a ) ; else if defined ARCH_ALPHA & & defined HAVE_MVI define pl2yuy2 ( n ) \ y1 = yc[n] ; \ y2 = yc2[n] ; \ u = uc[n] ; \ v = vc[n] ; \ asm ( unpkbw %1 , %0 : =r ( y1 ) : r ( y1 ) ) ; \ asm ( unpkbw %1 , %0 : =r ( y2 ) : r ( y2 ) ) ; \ asm ( unpkbl %1 , %0 : =r ( u ) : r ( u ) ) ; \ asm ( unpkbl %1 , %0 : =r ( v ) : r ( v ) ) ; \ yuv1 = ( u < < 8 ) + ( v < < 24 ) ; \ yuv2 = yuv1 + y2 ; \ yuv1 + = y1 ; \ qdst[n] = yuv1 ; \ qdst2[n] = yuv2 ; int i ; uint64_t * qdst = ( uint64_t * ) dst ; uint64_t * qdst2 = ( uint64_t * ) ( dst + dstStride ) ; const uint32_t * yc = ( uint32_t * ) ysrc ; const uint32_t * yc2 = ( uint32_t * ) ( ysrc + lumStride ) ; const uint16_t * uc = ( uint16_t * ) usrc , * vc = ( uint16_t * ) vsrc ; for ( i = 0 ; i < chromWidth ; i + = 8 ) { uint64_t y1 , y2 , yuv1 , yuv2 ; uint64_t u , v ; / * Prefetch * / asm ( ldq 31 , 64 ( %0 ) : : r ( yc ) ) ; asm ( ldq 31 , 64 ( %0 ) : : r ( yc2 ) ) ; asm ( ldq 31 , 64 ( %0 ) : : r ( uc ) ) ; asm ( ldq 31 , 64 ( %0 ) : : r ( vc ) ) ; pl2yuy2 ( 0 ) ; pl2yuy2 ( 1 ) ; pl2yuy2 ( 2 ) ; pl2yuy2 ( 3 ) ; yc + = 4 ; yc2 + = 4 ; uc + = 4 ; vc + = 4 ; qdst + = 4 ; qdst2 + = 4 ; } y + + ; ysrc + = lumStride ; dst + = dstStride ; elif __WORDSIZE > = 64 int i ; uint64_t * ldst = ( uint64_t * ) dst ; const uint8_t * yc = ysrc , * uc = usrc , * vc = vsrc ; for ( i = 0 ; i < chromWidth ; i + = 2 ) { uint64_t k , l ; k = yc[0] + ( uc[0] < < 8 ) + ( yc[1] < < 16 ) + ( vc[0] < < 24 ) ; l = yc[2] + ( uc[1] < < 8 ) + ( yc[3] < < 16 ) + ( vc[1] < < 24 ) ; * ldst + + = k + ( l < < 32 ) ; yc + = 4 ; uc + = 2 ; vc + = 2 ; } else int i , * idst = ( int32_t * ) dst ; const uint8_t * yc = ysrc , * uc = usrc , * vc = vsrc ; for ( i = 0 ; i < chromWidth ; i + + ) { ifdef WORDS_BIGENDIAN * idst + + = ( yc[0] < < 24 ) + ( uc[0] < < 16 ) + ( yc[1] < < 8 ) + ( vc[0] < < 0 ) ; else * idst + + = yc[0] + ( uc[0] < < 8 ) + ( yc[1] < < 16 ) + ( vc[0] < < 24 ) ; endif yc + = 2 ; uc + + ; vc + + ; } endif endif if ( ( y & ( vertLumPerChroma - 1 ) ) == ( vertLumPerChroma - 1 ) ) { usrc + = chromStride ; vsrc + = chromStride ; } ysrc + = lumStride ; dst + = dstStride ; } ifdef HAVE_MMX asm ( EMMS \n\t SFENCE \n\t : : : memory ) ; endif }",1
"static void vc1_inv_trans_4x4_dc_c ( uint8_t * dest , int linesize , DCTELEM * block ) { int i ; int dc = block[0] ; const uint8_t * cm ; dc = ( 17 * dc + 4 ) > > 3 ; dc = ( 17 * dc + 64 ) > > 7 ; cm = ff_cropTbl + MAX_NEG_CROP + dc ; for ( i = 0 ; i < 4 ; i + + ) { dest[0] = cm[dest[0]] ; dest[1] = cm[dest[1]] ; dest[2] = cm[dest[2]] ; dest[3] = cm[dest[3]] ; dest + = linesize ; } }",1
"static void read_sbr_noise ( SpectralBandReplication * sbr , GetBitContext * gb , SBRData * ch_data , int ch ) { int i , j ; VLC_TYPE ( * t_huff ) [2] , ( * f_huff ) [2] ; int t_lav , f_lav ; int delta = ( ch == 1 & & sbr - > bs_coupling == 1 ) + 1 ; if ( sbr - > bs_coupling & & ch ) { t_huff = vlc_sbr[T_HUFFMAN_NOISE_BAL_3_0DB] . table ; t_lav = vlc_sbr_lav[T_HUFFMAN_NOISE_BAL_3_0DB] ; f_huff = vlc_sbr[F_HUFFMAN_ENV_BAL_3_0DB] . table ; f_lav = vlc_sbr_lav[F_HUFFMAN_ENV_BAL_3_0DB] ; } else { t_huff = vlc_sbr[T_HUFFMAN_NOISE_3_0DB] . table ; t_lav = vlc_sbr_lav[T_HUFFMAN_NOISE_3_0DB] ; f_huff = vlc_sbr[F_HUFFMAN_ENV_3_0DB] . table ; f_lav = vlc_sbr_lav[F_HUFFMAN_ENV_3_0DB] ; } if USE_FIXED for ( i = 0 ; i < ch_data - > bs_num_noise ; i + + ) { if ( ch_data - > bs_df_noise[i] ) { for ( j = 0 ; j < sbr - > n_q ; j + + ) ch_data - > noise_facs[i + 1][j] . mant = ch_data - > noise_facs[i][j] . mant + delta * ( get_vlc2 ( gb , t_huff , 9 , 2 ) - t_lav ) ; } else { ch_data - > noise_facs[i + 1][0] . mant = delta * get_bits ( gb , 5 ) ; // bs_noise_start_value_balance or bs_noise_start_value_level for ( j = 1 ; j < sbr - > n_q ; j + + ) ch_data - > noise_facs[i + 1][j] . mant = ch_data - > noise_facs[i + 1][j - 1] . mant + delta * ( get_vlc2 ( gb , f_huff , 9 , 3 ) - f_lav ) ; } } else for ( i = 0 ; i < ch_data - > bs_num_noise ; i + + ) { if ( ch_data - > bs_df_noise[i] ) { for ( j = 0 ; j < sbr - > n_q ; j + + ) ch_data - > noise_facs[i + 1][j] = ch_data - > noise_facs[i][j] + delta * ( get_vlc2 ( gb , t_huff , 9 , 2 ) - t_lav ) ; } else { ch_data - > noise_facs[i + 1][0] = delta * get_bits ( gb , 5 ) ; // bs_noise_start_value_balance or bs_noise_start_value_level for ( j = 1 ; j < sbr - > n_q ; j + + ) ch_data - > noise_facs[i + 1][j] = ch_data - > noise_facs[i + 1][j - 1] + delta * ( get_vlc2 ( gb , f_huff , 9 , 3 ) - f_lav ) ; } } endif / * USE_FIXED * / //assign 0th elements of noise_facs from last elements memcpy ( ch_data - > noise_facs[0] , ch_data - > noise_facs[ch_data - > bs_num_noise] , sizeof ( ch_data - > noise_facs[0] ) ) ; }",0
"static unsigned tget_short ( GetByteContext * gb , int le ) { unsigned v = le ? bytestream2_get_le16u ( gb ) : bytestream2_get_be16u ( gb ) ; return v ; }",0
"static int dv_decode_video_segment ( AVCodecContext * avctx , void * arg ) { DVVideoContext * s = avctx - > priv_data ; DVwork_chunk * work_chunk = arg ; int quant , dc , dct_mode , class1 , j ; int mb_index , mb_x , mb_y , last_index ; int y_stride , linesize ; DCTELEM * block , * block1 ; int c_offset ; uint8_t * y_ptr ; const uint8_t * buf_ptr ; PutBitContext pb , vs_pb ; GetBitContext gb ; BlockInfo mb_data[5 * DV_MAX_BPM] , * mb , * mb1 ; LOCAL_ALIGNED_16 ( DCTELEM , sblock , [5 * DV_MAX_BPM] , [64] ) ; LOCAL_ALIGNED_16 ( uint8_t , mb_bit_buffer , [80 + 4] ) ; / * allow some slack * / LOCAL_ALIGNED_16 ( uint8_t , vs_bit_buffer , [5 * 80 + 4] ) ; / * allow some slack * / const int log2_blocksize = 3 - s - > avctx - > lowres ; int is_field_mode[5] ; assert ( ( ( ( int ) mb_bit_buffer ) & 7 ) == 0 ) ; assert ( ( ( ( int ) vs_bit_buffer ) & 7 ) == 0 ) ; memset ( sblock , 0 , 5 * DV_MAX_BPM * sizeof ( * sblock ) ) ; / * pass 1 : read DC and AC coefficients in blocks * / buf_ptr = & s - > buf[work_chunk - > buf_offset * 80] ; block1 = & sblock[0][0] ; mb1 = mb_data ; init_put_bits ( & vs_pb , vs_bit_buffer , 5 * 80 ) ; for ( mb_index = 0 ; mb_index < 5 ; mb_index + + , mb1 + = s - > sys - > bpm , block1 + = s - > sys - > bpm * 64 ) { / * skip header * / quant = buf_ptr[3] & 0x0f ; buf_ptr + = 4 ; init_put_bits ( & pb , mb_bit_buffer , 80 ) ; mb = mb1 ; block = block1 ; is_field_mode[mb_index] = 0 ; for ( j = 0 ; j < s - > sys - > bpm ; j + + ) { last_index = s - > sys - > block_sizes[j] ; init_get_bits ( & gb , buf_ptr , last_index ) ; / * get the DC * / dc = get_sbits ( & gb , 9 ) ; dct_mode = get_bits1 ( & gb ) ; class1 = get_bits ( & gb , 2 ) ; if ( DV_PROFILE_IS_HD ( s - > sys ) ) { mb - > idct_put = s - > idct_put[0] ; mb - > scan_table = s - > dv_zigzag[0] ; mb - > factor_table = & s - > sys - > idct_factor[ ( j > = 4 ) * 4 * 16 * 64 + class1 * 16 * 64 + quant * 64] ; is_field_mode[mb_index] |= ! j & & dct_mode ; } else { mb - > idct_put = s - > idct_put[dct_mode & & log2_blocksize == 3] ; mb - > scan_table = s - > dv_zigzag[dct_mode] ; mb - > factor_table = & s - > sys - > idct_factor[ ( class1 == 3 ) * 2 * 22 * 64 + dct_mode * 22 * 64 + ( quant + dv_quant_offset[class1] ) * 64] ; } dc = dc < < 2 ; / * convert to unsigned because 128 is not added in the standard IDCT * / dc + = 1024 ; block[0] = dc ; buf_ptr + = last_index > > 3 ; mb - > pos = 0 ; mb - > partial_bit_count = 0 ; av_dlog ( avctx , MB block : %d , %d , mb_index , j ) ; dv_decode_ac ( & gb , mb , block ) ; / * write the remaining bits in a new buffer only if the block is finished * / if ( mb - > pos > = 64 ) bit_copy ( & pb , & gb ) ; block + = 64 ; mb + + ; } / * pass 2 : we can do it just after * / av_dlog ( avctx , * * * pass 2 size=%d MB =%d\n , put_bits_count ( & pb ) , mb_index ) ; block = block1 ; mb = mb1 ; init_get_bits ( & gb , mb_bit_buffer , put_bits_count ( & pb ) ) ; flush_put_bits ( & pb ) ; for ( j = 0 ; j < s - > sys - > bpm ; j + + , block + = 64 , mb + + ) { if ( mb - > pos < 64 & & get_bits_left ( & gb ) > 0 ) { dv_decode_ac ( & gb , mb , block ) ; / * if still not finished , no need to parse other blocks * / if ( mb - > pos < 64 ) break ; } } / * all blocks are finished , so the extra bytes can be used at the video segment level * / if ( j > = s - > sys - > bpm ) bit_copy ( & vs_pb , & gb ) ; } / * we need a pass over the whole video segment * / av_dlog ( avctx , * * * pass 3 size=%d\n , put_bits_count ( & vs_pb ) ) ; block = & sblock[0][0] ; mb = mb_data ; init_get_bits ( & gb , vs_bit_buffer , put_bits_count ( & vs_pb ) ) ; flush_put_bits ( & vs_pb ) ; for ( mb_index = 0 ; mb_index < 5 ; mb_index + + ) { for ( j = 0 ; j < s - > sys - > bpm ; j + + ) { if ( mb - > pos < 64 ) { av_dlog ( avctx , start %d : %d\n , mb_index , j ) ; dv_decode_ac ( & gb , mb , block ) ; } if ( mb - > pos > = 64 & & mb - > pos < 127 ) av_log ( avctx , AV_LOG_ERROR , AC EOB marker is absent pos=%d\n , mb - > pos ) ; block + = 64 ; mb + + ; } } / * compute idct and place blocks * / block = & sblock[0][0] ; mb = mb_data ; for ( mb_index = 0 ; mb_index < 5 ; mb_index + + ) { dv_calculate_mb_xy ( s , work_chunk , mb_index , & mb_x , & mb_y ) ; / * idct_put ' ting luminance * / if ( ( s - > sys - > pix_fmt == PIX_FMT_YUV420P ) || ( s - > sys - > pix_fmt == PIX_FMT_YUV411P & & mb_x > = ( 704 / 8 ) ) || ( s - > sys - > height > = 720 & & mb_y ! = 134 ) ) { y_stride = ( s - > picture . linesize[0] < < ( ( ! is_field_mode[mb_index] ) * log2_blocksize ) ) ; } else { y_stride = ( 2 < < log2_blocksize ) ; } y_ptr",1
"static int decode_syncpoint ( NUTContext * nut , int64_t * ts , int64_t * back_ptr ) { AVFormatContext * s= nut - > avf ; ByteIOContext * bc = & s - > pb ; int64_t end , tmp ; AVRational time_base ; nut - > last_syncpoint_pos= url_ftell ( bc ) - 8 ; end= get_packetheader ( nut , bc , 1 ) ; end + = url_ftell ( bc ) ; tmp= get_v ( bc ) ; * back_ptr= nut - > last_syncpoint_pos - 16 * get_v ( bc ) ; if ( * back_ptr < 0 ) return - 1 ; ff_nut_reset_ts ( nut , nut - > time_base[tmp % nut - > time_base_count] , tmp ) ; if ( skip_reserved ( bc , end ) || get_checksum ( bc ) ) { av_log ( s , AV_LOG_ERROR , sync point checksum mismatch\n ) ; return - 1 ; } * ts= tmp / s - > nb_streams * av_q2d ( nut - > time_base[tmp % s - > nb_streams] ) * AV_TIME_BASE ; add_sp ( nut , nut - > last_syncpoint_pos , * back_ptr , * ts ) ; return 0 ; }",0
"int av_image_fill_linesizes ( int linesizes[4] , enum PixelFormat pix_fmt , int width ) { int i ; const AVPixFmtDescriptor * desc = & av_pix_fmt_descriptors[pix_fmt] ; int max_step [4] ; / * max pixel step for each plane * / int max_step_comp[4] ; / * the component for each plane which has the max pixel step * / memset ( linesizes , 0 , 4 * sizeof ( linesizes[0] ) ) ; if ( desc - > flags & PIX_FMT_HWACCEL ) return AVERROR ( EINVAL ) ; if ( desc - > flags & PIX_FMT_BITSTREAM ) { linesizes[0] = ( width * ( desc - > comp[0] . step_minus1 + 1 ) + 7 ) > > 3 ; return 0 ; } av_image_fill_max_pixsteps ( max_step , max_step_comp , desc ) ; for ( i = 0 ; i < 4 ; i + + ) { int s = ( max_step_comp[i] == 1 || max_step_comp[i] == 2 ) ? desc - > log2_chroma_w : 0 ; linesizes[i] = max_step[i] * ( ( ( width + ( 1 < < s ) - 1 ) ) > > s ) ; } return 0 ; }",0
av_cold void ff_vorbisdsp_init_x86 ( VorbisDSPContext * dsp ) { if HAVE_YASM int cpu_flags = av_get_cpu_flags ( ) ; if ARCH_X86_32 if ( cpu_flags & AV_CPU_FLAG_3DNOW ) dsp - > vorbis_inverse_coupling = ff_vorbis_inverse_coupling_3dnow ; endif / * ARCH_X86_32 * / if ( cpu_flags & AV_CPU_FLAG_SSE ) dsp - > vorbis_inverse_coupling = ff_vorbis_inverse_coupling_sse ; endif / * HAVE_YASM * / },0
"static void output_packet ( AVFormatContext * s , AVPacket * pkt , OutputStream * ost ) { int ret = 0 ; / * apply the output bitstream filters , if any * / if ( ost - > nb_bitstream_filters ) { int idx ; ret = av_bsf_send_packet ( ost - > bsf_ctx[0] , pkt ) ; if ( ret < 0 ) goto finish ; idx = 1 ; while ( idx ) { / * get a packet from the previous filter up the chain * / ret = av_bsf_receive_packet ( ost - > bsf_ctx[idx - 1] , pkt ) ; if ( ret == AVERROR ( EAGAIN ) ) { ret = 0 ; idx - - ; continue ; } else if ( ret < 0 ) goto finish ; / * send it to the next filter down the chain or to the muxer * / if ( idx < ost - > nb_bitstream_filters ) { ret = av_bsf_send_packet ( ost - > bsf_ctx[idx] , pkt ) ; if ( ret < 0 ) goto finish ; idx + + ; } else write_packet ( s , pkt , ost ) ; } } else write_packet ( s , pkt , ost ) ; finish : if ( ret < 0 & & ret ! = AVERROR_EOF ) { av_log ( NULL , AV_LOG_FATAL , Error applying bitstream filters to an output packet for stream %d : %d . \n , ost - > file_index , ost - > index ) ; exit_program ( 1 ) ; } }",0
"static void pred_temp_direct_motion ( const H264Context * const h , H264SliceContext * sl , int * mb_type ) { int b8_stride = 2 ; int b4_stride = h - > b_stride ; int mb_xy = sl - > mb_xy , mb_y = sl - > mb_y ; int mb_type_col[2] ; const int16_t ( * l1mv0 ) [2] , ( * l1mv1 ) [2] ; const int8_t * l1ref0 , * l1ref1 ; const int is_b8x8 = IS_8X8 ( * mb_type ) ; unsigned int sub_mb_type ; int i8 , i4 ; assert ( sl - > ref_list[1][0] . reference & 3 ) ; await_reference_mb_row ( h , sl - > ref_list[1][0] . parent , sl - > mb_y + ! ! IS_INTERLACED ( * mb_type ) ) ; if ( IS_INTERLACED ( sl - > ref_list[1][0] . parent - > mb_type[mb_xy] ) ) { // AFL/AFR/FR/FL - > AFL/FL if ( ! IS_INTERLACED ( * mb_type ) ) { // AFR/FR - > AFL/FL mb_y = ( sl - > mb_y & 1 ) + sl - > col_parity ; mb_xy = sl - > mb_x + ( ( sl - > mb_y & 1 ) + sl - > col_parity ) * h - > mb_stride ; b8_stride = 0 ; } else { mb_y + = sl - > col_fieldoff ; mb_xy + = h - > mb_stride * sl - > col_fieldoff ; // non - zero for FL - > FL & differ parity } goto single_col ; } else { // AFL/AFR/FR/FL - > AFR/FR if ( IS_INTERLACED ( * mb_type ) ) { // AFL /FL - > AFR/FR mb_y = sl - > mb_y & 1 ; mb_xy = sl - > mb_x + ( sl - > mb_y & 1 ) * h - > mb_stride ; mb_type_col[0] = sl - > ref_list[1][0] . parent - > mb_type[mb_xy] ; mb_type_col[1] = sl - > ref_list[1][0] . parent - > mb_type[mb_xy + h - > mb_stride] ; b8_stride = 2 + 4 * h - > mb_stride ; b4_stride * = 6 ; if ( IS_INTERLACED ( mb_type_col[0] ) ! = IS_INTERLACED ( mb_type_col[1] ) ) { mb_type_col[0] & = MB_TYPE_INTERLACED ; mb_type_col[1] & = MB_TYPE_INTERLACED ; } sub_mb_type = MB_TYPE_16x16 | MB_TYPE_P0L0 | MB_TYPE_P0L1 | MB_TYPE_DIRECT2 ; / * B_SUB_8x8 * / if ( ( mb_type_col[0] & MB_TYPE_16x16_OR_INTRA ) & & ( mb_type_col[1] & MB_TYPE_16x16_OR_INTRA ) & & ! is_b8x8 ) { * mb_type |= MB_TYPE_16x8 | MB_TYPE_L0L1 | MB_TYPE_DIRECT2 ; / * B_16x8 * / } else { * mb_type |= MB_TYPE_8x8 | MB_TYPE_L0L1 ; } } else { // AFR/FR - > AFR/FR single_col : mb_type_col[0] = mb_type_col[1] = sl - > ref_list[1][0] . parent - > mb_type[mb_xy] ; sub_mb_type = MB_TYPE_16x16 | MB_TYPE_P0L0 | MB_TYPE_P0L1 | MB_TYPE_DIRECT2 ; / * B_SUB_8x8 * / if ( ! is_b8x8 & & ( mb_type_col[0] & MB_TYPE_16x16_OR_INTRA ) ) { * mb_type |= MB_TYPE_16x16 | MB_TYPE_P0L0 | MB_TYPE_P0L1 | MB_TYPE_DIRECT2 ; / * B_16x16 * / } else if ( ! is_b8x8 & & ( mb_type_col[0] & ( MB_TYPE_16x8 | MB_TYPE_8x16 ) ) ) { * mb_type |= MB_TYPE_L0L1 | MB_TYPE_DIRECT2 | ( mb_type_col[0] & ( MB_TYPE_16x8 | MB_TYPE_8x16 ) ) ; } else { if ( ! h - > sps . direct_8x8_inference_flag ) { / * FIXME : save sub mb types from previous frames ( or derive * from MVs ) so we know exactly what block size to use * / sub_mb_type = MB_TYPE_8x8 | MB_TYPE_P0L0 | MB_TYPE_P0L1 | MB_TYPE_DIRECT2 ; / * B_SUB_4x4 * / } * mb_type |= MB_TYPE_8x8 | MB_TYPE_L0L1 ; } } } await_reference_mb_row ( h , sl - > ref_list[1][0] . parent , mb_y ) ; l1mv0 = & sl - > ref_list[1][0] . parent - > motion_val[0][h - > mb2b_xy[mb_xy]] ; l1mv1 = & sl - > ref_list[1][0] . parent - > motion_val[1][h - > mb2b_xy[mb_xy]] ; l1ref0 = & sl - > ref_list[1][0] . parent - > ref_index[0][4 * mb_xy] ; l1ref1 = & sl - > ref_list[1][0] . parent - > ref_index[1][4 * mb_xy] ; if ( ! b8_stride ) { if ( sl - > mb_y & 1 ) { l1ref0 + = 2 ; l1ref1 + = 2 ; l1mv0 + = 2 * b4_stride ; l1mv1 + = 2 * b4_stride ; } } { const int * map_col_to_list0[2] = { sl - > map_col_to_list0[0] , sl - > map_col_to_list0[1] } ; const int * dist_scale_factor = sl - > dist_scale_factor ; int ref_offset ; if ( FRAME_MBAFF ( h ) & & IS_INTERLACED ( * mb_type ) ) { map_col_to_list0[0] = sl - > map_col_to_list0_field[sl - > mb_y & 1][0] ; map_col_to_list0[1] = sl - > map_col_to_list0_field[sl - > mb_y & 1][1] ; dist_scale_factor = sl - > dist_scale_factor_field[sl - > mb_y & 1] ; } ref_offset = ( sl - > ref_list[1][0] . parent - > mbaff < < 4 ) & ( mb_type_col[0] > > 3 ) ; if ( IS_INTERLACED ( * mb_type ) ! = IS_INTERLACED ( mb_type_col[0] ) ) { int y_shift = 2 * ! IS_INTERLACED ( * mb_type ) ; assert ( h - > sps . direct_8x8_inference_flag ) ; for ( i8 = 0 ; i8 < 4 ; i8 + + ) { const int x8 = i8 & 1 ; const int y8 = i8 > > 1 ; int ref0 , scale ; const int16_t ( * l1mv ) [2] = l1mv0 ; if ( is_b8x8 & & ! IS_DIRECT ( sl - > sub_mb_type[i8] ) ) continue ; sl - > sub_mb_type[i8] = sub_mb_type ; fill_rectangle ( & sl - > ref_cache[1][scan8[i8 * 4]] , 2 , 2 , 8 , 0 , 1 ) ; if ( IS_INTRA ( mb_type_col[y8] ) ) { fill_rectangle ( & sl - > ref_cache[0][scan8[i8 * 4]] , 2 , 2 , 8 , 0 , 1 ) ; fill_rectangle ( & sl - > mv_cache[0][scan8[i8 * 4]] , 2 , 2 , 8 , 0 , 4 ) ; fill_rectangle ( & sl - > mv_cache[1][scan8[i8 * 4]] , 2 , 2 , 8 , 0 , 4 ) ; continue ; } ref0 = l1ref0[x8 + y8 * b8_stride] ; if ( ref0 > = 0 ) ref0 = map_col_to_list0[0][ref0 + ref_offset] ; else { ref0 = map_col_to_list0[1][l1ref1[x8 + y8 * b8_stride] + ref_offset] ; l1mv = l1mv1 ; } scale = dist_scale_factor[ref0] ; fill_rectangle ( & sl - > ref_cache[0][scan8[i8 * 4]] , 2 , 2 , 8 , ref0 , 1 ) ; { const int16_t * mv_col = l1mv[x8 * 3 + y8 * b4_stride] ; int my_col = ( mv_col[1] < < y_shift ) / 2 ; int mx = ( scale * mv_col[0] + 128 ) > > 8 ; int my = ( scale * my_col + 128 ) > > 8 ; fill_rectangle ( & sl - > mv_cache[0][scan8[i8 * 4]] , 2 , 2 , 8 , pack16to32 ( mx , my ) , 4 ) ; fill_rectangle ( & sl - > mv_cache[1][scan8[i8 * 4]] , 2 , 2 , 8 , pack16to32 ( mx - mv_col[0] ,",0
"static int vaapi_vc1_start_frame ( AVCodecContext * avctx , av_unused const uint8_t * buffer , av_unused uint32_t size ) { const VC1Context * v = avctx - > priv_data ; const MpegEncContext * s = & v - > s ; struct vaapi_context * const vactx = avctx - > hwaccel_context ; VAPictureParameterBufferVC1 * pic_param ; vactx - > slice_param_size = sizeof ( VASliceParameterBufferVC1 ) ; / * Fill in VAPictureParameterBufferVC1 * / pic_param = ff_vaapi_alloc_pic_param ( vactx , sizeof ( VAPictureParameterBufferVC1 ) ) ; if ( ! pic_param ) return - 1 ; pic_param - > forward_reference_picture = VA_INVALID_ID ; pic_param - > backward_reference_picture = VA_INVALID_ID ; pic_param - > inloop_decoded_picture = VA_INVALID_ID ; pic_param - > sequence_fields . value = 0 ; / * reset all bits * / pic_param - > sequence_fields . bits . pulldown = v - > broadcast ; pic_param - > sequence_fields . bits . interlace = v - > interlace ; pic_param - > sequence_fields . bits . tfcntrflag = v - > tfcntrflag ; pic_param - > sequence_fields . bits . finterpflag = v - > finterpflag ; pic_param - > sequence_fields . bits . psf = v - > psf ; pic_param - > sequence_fields . bits . multires = v - > multires ; pic_param - > sequence_fields . bits . overlap = v - > overlap ; pic_param - > sequence_fields . bits . syncmarker = v - > resync_marker ; pic_param - > sequence_fields . bits . rangered = v - > rangered ; pic_param - > sequence_fields . bits . max_b_frames = s - > avctx - > max_b_frames ; if VA_CHECK_VERSION ( 0 , 32 , 0 ) pic_param - > sequence_fields . bits . profile = v - > profile ; endif pic_param - > coded_width = s - > avctx - > coded_width ; pic_param - > coded_height = s - > avctx - > coded_height ; pic_param - > entrypoint_fields . value = 0 ; / * reset all bits * / pic_param - > entrypoint_fields . bits . broken_link = v - > broken_link ; pic_param - > entrypoint_fields . bits . closed_entry = v - > closed_entry ; pic_param - > entrypoint_fields . bits . panscan_flag = v - > panscanflag ; pic_param - > entrypoint_fields . bits . loopfilter = s - > loop_filter ; pic_param - > conditional_overlap_flag = v - > condover ; pic_param - > fast_uvmc_flag = v - > fastuvmc ; pic_param - > range_mapping_fields . value = 0 ; / * reset all bits * / pic_param - > range_mapping_fields . bits . luma_flag = v - > range_mapy_flag ; pic_param - > range_mapping_fields . bits . luma = v - > range_mapy ; pic_param - > range_mapping_fields . bits . chroma_flag = v - > range_mapuv_flag ; pic_param - > range_mapping_fields . bits . chroma = v - > range_mapuv ; pic_param - > b_picture_fraction = v - > bfraction_lut_index ; pic_param - > cbp_table = v - > cbpcy_vlc ? v - > cbpcy_vlc - ff_vc1_cbpcy_p_vlc : 0 ; pic_param - > mb_mode_table = 0 ; / * XXX : interlaced frame * / pic_param - > range_reduction_frame = v - > rangeredfrm ; pic_param - > rounding_control = v - > rnd ; pic_param - > post_processing = v - > postproc ; pic_param - > picture_resolution_index = v - > respic ; pic_param - > luma_scale = v - > lumscale ; pic_param - > luma_shift = v - > lumshift ; pic_param - > picture_fields . value = 0 ; / * reset all bits * / pic_param - > picture_fields . bits . picture_type = vc1_get_PTYPE ( v ) ; pic_param - > picture_fields . bits . frame_coding_mode = v - > fcm ; pic_param - > picture_fields . bits . top_field_first = v - > tff ; pic_param - > picture_fields . bits . is_first_field = v - > fcm == 0 ; / * XXX : interlaced frame * / pic_param - > picture_fields . bits . intensity_compensation = v - > mv_mode == MV_PMODE_INTENSITY_COMP ; pic_param - > raw_coding . value = 0 ; / * reset all bits * / pic_param - > raw_coding . flags . mv_type_mb = v - > mv_type_is_raw ; pic_param - > raw_coding . flags . direct_mb = v - > dmb_is_raw ; pic_param - > raw_coding . flags . skip_mb = v - > skip_is_raw ; pic_param - > raw_coding . flags . field_tx = 0 ; / * XXX : interlaced frame * / pic_param - > raw_coding . flags . forward_mb = 0 ; / * XXX : interlaced frame * / pic_param - > raw_coding . flags . ac_pred = v - > acpred_is_raw ; pic_param - > raw_coding . flags . overflags = v - > overflg_is_raw ; pic_param - > bitplane_present . value = 0 ; / * reset all bits * / pic_param - > bitplane_present . flags . bp_mv_type_mb = vc1_has_MVTYPEMB_bitplane ( v ) ; pic_param - > bitplane_present . flags . bp_direct_mb = vc1_has_DIRECTMB_bitplane ( v ) ; pic_param - > bitplane_present . flags . bp_skip_mb = vc1_has_SKIPMB_bitplane ( v ) ; pic_param - > bitplane_present . flags . bp_field_tx = 0 ; / * XXX : interlaced frame * / pic_param - > bitplane_present . flags . bp_forward_mb = 0 ; / * XXX : interlaced frame * / pic_param - > bitplane_present . flags . bp_ac_pred = vc1_has_ACPRED_bitplane ( v ) ; pic_param - > bitplane_present . flags . bp_overflags = vc1_has_OVERFLAGS_bitplane ( v ) ; pic_param - > reference_fields . value = 0 ; / * reset all bits * / pic_param - > reference_fields . bits . reference_distance_flag = v - > refdist_flag ; pic_param - > reference_fields . bits . reference_distance = 0 ; / * XXX : interlaced frame * / pic_param - > reference_fields . bits . num_reference_pictures = 0 ; / * XXX : interlaced frame * / pic_param - > reference_fields . bits . reference_field_pic_indicator = 0 ; / * XXX : interlaced frame * / pic_param - > mv_fields . value = 0 ; / * reset all bits * / pic_param - > mv_fields . bits . mv_mode = vc1_get_MVMODE ( v ) ; pic_param - > mv_fields . bits . mv_mode2 = vc1_get_MVMODE2 ( v ) ; pic_param - > mv_fields . bits . mv_table = s - > mv_table_index ; pic_param - > mv_fields . bits . two_mv_block_pattern_table = 0 ; / * XXX : interlaced frame * / pic_param - > mv_fields . bits . four_mv_switch = 0 ; / * XXX : interlaced frame * / pic_param - > mv_fields . bits . four_mv_block_pattern_table = 0 ; / * XXX : interlaced frame * / pic_param - > mv_fields . bits . extended_mv_flag = v - > extended_mv ; pic_param - > mv_fields . bits . extended_mv_range = v - > mvrange ; pic_param - > mv_fields . bits . extended_dmv_flag = v - > extended_dmv ; pic_param - > mv_fields . bits . extended_dmv_range = 0 ; / * XXX : interlaced frame * /",0
"static int read_huffman_tables ( HYuvContext * s , uint8_t * src , int length ) { GetBitContext gb ; int i ; init_get_bits ( & gb , src , length ) ; for ( i=0 ; i < 3 ; i + + ) { read_len_table ( s - > len[i] , & gb ) ; if ( generate_bits_table ( s - > bits[i] , s - > len[i] ) < 0 ) { return - 1 ; } if 0 for ( j=0 ; j < 256 ; j + + ) { printf ( %6X , %2d , %3d\n , s - > bits[i][j] , s - > len[i][j] , j ) ; } endif init_vlc ( & s - > vlc[i] , VLC_BITS , 256 , s - > len[i] , 1 , 1 , s - > bits[i] , 4 , 4 ) ; } return 0 ; }",0
"static void pred_spatial_direct_motion ( const H264Context * const h , H264SliceContext * sl , int * mb_type ) { int b8_stride = 2 ; int b4_stride = h - > b_stride ; int mb_xy = sl - > mb_xy , mb_y = sl - > mb_y ; int mb_type_col[2] ; const int16_t ( * l1mv0 ) [2] , ( * l1mv1 ) [2] ; const int8_t * l1ref0 , * l1ref1 ; const int is_b8x8 = IS_8X8 ( * mb_type ) ; unsigned int sub_mb_type = MB_TYPE_L0L1 ; int i8 , i4 ; int ref[2] ; int mv[2] ; int list ; assert ( sl - > ref_list[1][0] . reference & 3 ) ; await_reference_mb_row ( h , sl - > ref_list[1][0] . parent , sl - > mb_y + ! ! IS_INTERLACED ( * mb_type ) ) ; define MB_TYPE_16x16_OR_INTRA ( MB_TYPE_16x16 | MB_TYPE_INTRA4x4 | \ MB_TYPE_INTRA16x16 | MB_TYPE_INTRA_PCM ) / * ref = min ( neighbors ) * / for ( list = 0 ; list < 2 ; list + + ) { int left_ref = sl - > ref_cache[list][scan8[0] - 1] ; int top_ref = sl - > ref_cache[list][scan8[0] - 8] ; int refc = sl - > ref_cache[list][scan8[0] - 8 + 4] ; const int16_t * C = sl - > mv_cache[list][scan8[0] - 8 + 4] ; if ( refc == PART_NOT_AVAILABLE ) { refc = sl - > ref_cache[list][scan8[0] - 8 - 1] ; C = sl - > mv_cache[list][scan8[0] - 8 - 1] ; } ref[list] = FFMIN3 ( ( unsigned ) left_ref , ( unsigned ) top_ref , ( unsigned ) refc ) ; if ( ref[list] > = 0 ) { / * This is just pred_motion ( ) but with the cases removed that * cannot happen for direct blocks . * / const int16_t * const A = sl - > mv_cache[list][scan8[0] - 1] ; const int16_t * const B = sl - > mv_cache[list][scan8[0] - 8] ; int match_count = ( left_ref == ref[list] ) + ( top_ref == ref[list] ) + ( refc == ref[list] ) ; if ( match_count > 1 ) { // most common mv[list] = pack16to32 ( mid_pred ( A[0] , B[0] , C[0] ) , mid_pred ( A[1] , B[1] , C[1] ) ) ; } else { assert ( match_count == 1 ) ; if ( left_ref == ref[list] ) mv[list] = AV_RN32A ( A ) ; else if ( top_ref == ref[list] ) mv[list] = AV_RN32A ( B ) ; else mv[list] = AV_RN32A ( C ) ; } } else { int mask = ( MB_TYPE_L0 < < ( 2 * list ) ) ; mv[list] = 0 ; ref[list] = - 1 ; if ( ! is_b8x8 ) * mb_type & = mask ; sub_mb_type & = mask ; } } if ( ref[0] < 0 & & ref[1] < 0 ) { ref[0] = ref[1] = 0 ; if ( ! is_b8x8 ) * mb_type |= MB_TYPE_L0L1 ; sub_mb_type |= MB_TYPE_L0L1 ; } if ( ! ( is_b8x8 | mv[0] | mv[1] ) ) { fill_rectangle ( & sl - > ref_cache[0][scan8[0]] , 4 , 4 , 8 , ( uint8_t ) ref[0] , 1 ) ; fill_rectangle ( & sl - > ref_cache[1][scan8[0]] , 4 , 4 , 8 , ( uint8_t ) ref[1] , 1 ) ; fill_rectangle ( & sl - > mv_cache[0][scan8[0]] , 4 , 4 , 8 , 0 , 4 ) ; fill_rectangle ( & sl - > mv_cache[1][scan8[0]] , 4 , 4 , 8 , 0 , 4 ) ; * mb_type = ( * mb_type & ( MB_TYPE_8x8 | MB_TYPE_16x8 | MB_TYPE_8x16 | MB_TYPE_P1L0 | MB_TYPE_P1L1 ) ) | MB_TYPE_16x16 | MB_TYPE_DIRECT2 ; return ; } if ( IS_INTERLACED ( sl - > ref_list[1][0] . parent - > mb_type[mb_xy] ) ) { // AFL/AFR/FR/FL - > AFL/FL if ( ! IS_INTERLACED ( * mb_type ) ) { // AFR/FR - > AFL/FL mb_y = ( sl - > mb_y & 1 ) + sl - > col_parity ; mb_xy = sl - > mb_x + ( ( sl - > mb_y & 1 ) + sl - > col_parity ) * h - > mb_stride ; b8_stride = 0 ; } else { mb_y + = sl - > col_fieldoff ; mb_xy + = h - > mb_stride * sl - > col_fieldoff ; // non - zero for FL - > FL & differ parity } goto single_col ; } else { // AFL/AFR/FR/FL - > AFR/FR if ( IS_INTERLACED ( * mb_type ) ) { // AFL /FL - > AFR/FR mb_y = sl - > mb_y & 1 ; mb_xy = ( sl - > mb_y & 1 ) * h - > mb_stride + sl - > mb_x ; mb_type_col[0] = sl - > ref_list[1][0] . parent - > mb_type[mb_xy] ; mb_type_col[1] = sl - > ref_list[1][0] . parent - > mb_type[mb_xy + h - > mb_stride] ; b8_stride = 2 + 4 * h - > mb_stride ; b4_stride * = 6 ; if ( IS_INTERLACED ( mb_type_col[0] ) ! = IS_INTERLACED ( mb_type_col[1] ) ) { mb_type_col[0] & = MB_TYPE_INTERLACED ; mb_type_col[1] & = MB_TYPE_INTERLACED ; } sub_mb_type |= MB_TYPE_16x16 | MB_TYPE_DIRECT2 ; / * B_SUB_8x8 * / if ( ( mb_type_col[0] & MB_TYPE_16x16_OR_INTRA ) & & ( mb_type_col[1] & MB_TYPE_16x16_OR_INTRA ) & & ! is_b8x8 ) { * mb_type |= MB_TYPE_16x8 | MB_TYPE_DIRECT2 ; / * B_16x8 * / } else { * mb_type |= MB_TYPE_8x8 ; } } else { // AFR/FR - > AFR/FR single_col : mb_type_col[0] = mb_type_col[1] = sl - > ref_list[1][0] . parent - > mb_type[mb_xy] ; sub_mb_type |= MB_TYPE_16x16 | MB_TYPE_DIRECT2 ; / * B_SUB_8x8 * / if ( ! is_b8x8 & & ( mb_type_col[0] & MB_TYPE_16x16_OR_INTRA ) ) { * mb_type |= MB_TYPE_16x16 | MB_TYPE_DIRECT2 ; / * B_16x16 * / } else if ( ! is_b8x8 & & ( mb_type_col[0] & ( MB_TYPE_16x8 | MB_TYPE_8x16 ) ) ) { * mb_type |= MB_TYPE_DIRECT2 | ( mb_type_col[0] & ( MB_TYPE_16x8 | MB_TYPE_8x16 ) ) ; } else { if ( ! h - > ps . sps - > direct_8x8_inference_flag ) { / * FIXME : Save sub mb types from previous frames ( or derive * from MVs ) so we know exactly what block size to use . * / sub_mb_type + = ( MB_TYPE_8x8 - MB_TYPE_16x16 ) ; / * B_SUB_4x4 * / } * mb_type |= MB_TYPE_8x8 ; } } } await_reference_mb_row ( h , sl - > ref_list[1][0] . parent , mb_y ) ; l1mv0 = & sl - > ref_list[1][0] . parent - > motion_val[0][h - > mb2b_xy[mb_xy]] ; l1mv1 = & sl - > ref_list[1][0] . parent - > motion_val[1][h - > mb2b_xy[mb_xy]] ; l1ref0 = & sl - > ref_list[1][0] . parent - > ref_index[0][4 * mb_xy] ; l1ref1 = & sl - > ref_list[1][0] . parent - > ref_index[1][4 * mb_xy] ; if ( ! b8_stride ) { if ( sl - > mb_y & 1 ) { l1ref0 + = 2 ; l1ref1 + = 2 ; l1mv0 + = 2 * b4_stride ; l1mv1",1
"static int wc3_read_packet ( AVFormatContext * s , AVPacket * pkt ) { Wc3DemuxContext * wc3 = s - > priv_data ; ByteIOContext * pb = s - > pb ; unsigned int fourcc_tag ; unsigned int size ; int packet_read = 0 ; int ret = 0 ; unsigned char text[1024] ; unsigned int palette_number ; int i ; unsigned char r , g , b ; int base_palette_index ; while ( ! packet_read ) { fourcc_tag = get_le32 ( pb ) ; / * chunk sizes are 16 - bit aligned * / size = ( get_be32 ( pb ) + 1 ) & ( 1 ) ; if ( url_feof ( pb ) ) return AVERROR ( EIO ) ; switch ( fourcc_tag ) { case BRCH_TAG : / * no - op * / break ; case SHOT_TAG : / * load up new palette * / palette_number = get_le32 ( pb ) ; if ( palette_number > = wc3 - > palette_count ) return AVERROR_INVALIDDATA ; base_palette_index = palette_number * PALETTE_COUNT * 3 ; for ( i = 0 ; i < PALETTE_COUNT ; i + + ) { r = wc3 - > palettes[base_palette_index + i * 3 + 0] ; g = wc3 - > palettes[base_palette_index + i * 3 + 1] ; b = wc3 - > palettes[base_palette_index + i * 3 + 2] ; wc3 - > palette_control . palette[i] = ( r < < 16 ) | ( g < < 8 ) | ( b ) ; } wc3 - > palette_control . palette_changed = 1 ; break ; case VGA__TAG : / * send out video chunk * / ret= av_get_packet ( pb , pkt , size ) ; pkt - > stream_index = wc3 - > video_stream_index ; pkt - > pts = wc3 - > pts ; packet_read = 1 ; break ; case TEXT_TAG : / * subtitle chunk * / if 0 url_fseek ( pb , size , SEEK_CUR ) ; else if ( ( unsigned ) size > sizeof ( text ) || ( ret = get_buffer ( pb , text , size ) ) ! = size ) ret = AVERROR ( EIO ) ; else { int i = 0 ; av_log ( s , AV_LOG_DEBUG , Subtitle time ! \n ) ; av_log ( s , AV_LOG_DEBUG , inglish : %s\n , & text[i + 1] ) ; i + = text[i] + 1 ; av_log ( s , AV_LOG_DEBUG , doytsch : %s\n , & text[i + 1] ) ; i + = text[i] + 1 ; av_log ( s , AV_LOG_DEBUG , fronsay : %s\n , & text[i + 1] ) ; } endif break ; case AUDI_TAG : / * send out audio chunk * / ret= av_get_packet ( pb , pkt , size ) ; pkt - > stream_index = wc3 - > audio_stream_index ; pkt - > pts = wc3 - > pts ; / * time to advance pts * / wc3 - > pts + + ; packet_read = 1 ; break ; default : av_log ( s , AV_LOG_ERROR , unrecognized WC3 chunk : %c%c%c%c ( 0x%02X%02X%02X%02X ) \n , ( uint8_t ) fourcc_tag , ( uint8_t ) ( fourcc_tag > > 8 ) , ( uint8_t ) ( fourcc_tag > > 16 ) , ( uint8_t ) ( fourcc_tag > > 24 ) , ( uint8_t ) fourcc_tag , ( uint8_t ) ( fourcc_tag > > 8 ) , ( uint8_t ) ( fourcc_tag > > 16 ) , ( uint8_t ) ( fourcc_tag > > 24 ) ) ; ret = AVERROR_INVALIDDATA ; packet_read = 1 ; break ; } } return ret ; }",1
"static int rate_control ( AVCodecContext * avctx , void * arg ) { SliceArgs * slice_dat = arg ; VC2EncContext * s = slice_dat - > ctx ; const int sx = slice_dat - > x ; const int sy = slice_dat - > y ; int quant_buf[2] , bits_buf[2] , quant = s - > q_start , range = s - > q_start/3 ; const int64_t top = slice_dat - > bits_ceil ; const double percent = s - > tolerance ; const double bottom = top - top * ( percent/100 . 0f ) ; int bits = count_hq_slice ( s , sx , sy , quant ) ; range - = range & 1 ; / * Make it an even number * / while ( ( bits > top ) || ( bits < bottom ) ) { range * = bits > top ? + 1 : - 1 ; quant = av_clip ( quant + range , 0 , s - > q_ceil ) ; bits = count_hq_slice ( s , sx , sy , quant ) ; range = av_clip ( range/2 , 1 , s - > q_ceil ) ; if ( quant_buf[1] == quant ) { quant = bits_buf[0] < bits ? quant_buf[0] : quant ; bits = bits_buf[0] < bits ? bits_buf[0] : bits ; break ; } quant_buf[1] = quant_buf[0] ; quant_buf[0] = quant ; bits_buf[1] = bits_buf[0] ; bits_buf[0] = bits ; } slice_dat - > quant_idx = av_clip ( quant , 0 , s - > q_ceil ) ; slice_dat - > bytes = FFALIGN ( ( bits > > 3 ) , s - > size_scaler ) + 4 + s - > prefix_bytes ; return 0 ; }",1
"static int ogg_read_page ( AVFormatContext * s , int * str ) { AVIOContext * bc = s - > pb ; struct ogg * ogg = s - > priv_data ; struct ogg_stream * os ; int ret , i = 0 ; int flags , nsegs ; uint64_t gp ; uint32_t serial ; int size , idx ; uint8_t sync[4] ; int sp = 0 ; ret = avio_read ( bc , sync , 4 ) ; if ( ret < 4 ) return ret < 0 ? ret : AVERROR_EOF ; do { int c ; if ( sync[sp & 3] == ' O ' & & sync[ ( sp + 1 ) & 3] == ' g ' & & sync[ ( sp + 2 ) & 3] == ' g ' & & sync[ ( sp + 3 ) & 3] == ' S ' ) break ; c = avio_r8 ( bc ) ; if ( bc - > eof_reached ) return AVERROR_EOF ; sync[sp + + & 3] = c ; } while ( i + + < MAX_PAGE_SIZE ) ; if ( i > = MAX_PAGE_SIZE ) { av_log ( s , AV_LOG_INFO , ogg , can ' t find sync word\n ) ; return AVERROR_INVALIDDATA ; } if ( avio_r8 ( bc ) ! = 0 ) / * version * / return AVERROR_INVALIDDATA ; flags = avio_r8 ( bc ) ; gp = avio_rl64 ( bc ) ; serial = avio_rl32 ( bc ) ; avio_skip ( bc , 8 ) ; / * seq , crc * / nsegs = avio_r8 ( bc ) ; idx = ogg_find_stream ( ogg , serial ) ; if ( idx < 0 ) { if ( ogg - > headers ) { int n ; for ( n = 0 ; n < ogg - > nstreams ; n + + ) { av_freep ( & ogg - > streams[n] . buf ) ; if ( ! ogg - > state || ogg - > state - > streams[n] . private ! = ogg - > streams[n] . private ) av_freep ( & ogg - > streams[n] . private ) ; } ogg - > curidx = - 1 ; ogg - > nstreams = 0 ; idx = ogg_new_stream ( s , serial , 0 ) ; } else { idx = ogg_new_stream ( s , serial , 1 ) ; } if ( idx < 0 ) return idx ; } os = ogg - > streams + idx ; os - > page_pos = avio_tell ( bc ) - 27 ; if ( os - > psize > 0 ) ogg_new_buf ( ogg , idx ) ; ret = avio_read ( bc , os - > segments , nsegs ) ; if ( ret < nsegs ) return ret < 0 ? ret : AVERROR_EOF ; os - > nsegs = nsegs ; os - > segp = 0 ; size = 0 ; for ( i = 0 ; i < nsegs ; i + + ) size + = os - > segments[i] ; if ( flags & OGG_FLAG_CONT || os - > incomplete ) { if ( ! os - > psize ) { while ( os - > segp < os - > nsegs ) { int seg = os - > segments[os - > segp + + ] ; os - > pstart + = seg ; if ( seg < 255 ) break ; } os - > sync_pos = os - > page_pos ; } } else { os - > psize = 0 ; os - > sync_pos = os - > page_pos ; } if ( os - > bufsize - os - > bufpos < size ) { uint8_t * nb = av_malloc ( os - > bufsize * = 2 ) ; memcpy ( nb , os - > buf , os - > bufpos ) ; av_free ( os - > buf ) ; os - > buf = nb ; } ret = avio_read ( bc , os - > buf + os - > bufpos , size ) ; if ( ret < size ) return ret < 0 ? ret : AVERROR_EOF ; os - > bufpos + = size ; os - > granule = gp ; os - > flags = flags ; if ( str ) * str = idx ; return 0 ; }",1
"void ff_ivi_recompose53 ( const IVIPlaneDesc * plane , uint8_t * dst , const ptrdiff_t dst_pitch ) { int x , y , indx ; int32_t p0 , p1 , p2 , p3 , tmp0 , tmp1 , tmp2 ; int32_t b0_1 , b0_2 , b1_1 , b1_2 , b1_3 , b2_1 , b2_2 , b2_3 , b2_4 , b2_5 , b2_6 ; int32_t b3_1 , b3_2 , b3_3 , b3_4 , b3_5 , b3_6 , b3_7 , b3_8 , b3_9 ; ptrdiff_t pitch , back_pitch ; const short * b0_ptr , * b1_ptr , * b2_ptr , * b3_ptr ; const int num_bands = 4 ; / * all bands should have the same pitch * / pitch = plane - > bands[0] . pitch ; / * pixels at the position y - 1 will be set to pixels at the y for the 1st iteration * / back_pitch = 0 ; / * get pointers to the wavelet bands * / b0_ptr = plane - > bands[0] . buf ; b1_ptr = plane - > bands[1] . buf ; b2_ptr = plane - > bands[2] . buf ; b3_ptr = plane - > bands[3] . buf ; for ( y = 0 ; y < plane - > height ; y + = 2 ) { if ( y + 2 > = plane - > height ) pitch= 0 ; / * load storage variables with values * / if ( num_bands > 0 ) { b0_1 = b0_ptr[0] ; b0_2 = b0_ptr[pitch] ; } if ( num_bands > 1 ) { b1_1 = b1_ptr[back_pitch] ; b1_2 = b1_ptr[0] ; b1_3 = b1_1 - b1_2 * 6 + b1_ptr[pitch] ; } if ( num_bands > 2 ) { b2_2 = b2_ptr[0] ; // b2[x , y ] b2_3 = b2_2 ; // b2[x + 1 , y ] = b2[x , y] b2_5 = b2_ptr[pitch] ; // b2[x , y + 1] b2_6 = b2_5 ; // b2[x + 1 , y + 1] = b2[x , y + 1] } if ( num_bands > 3 ) { b3_2 = b3_ptr[back_pitch] ; // b3[x , y - 1] b3_3 = b3_2 ; // b3[x + 1 , y - 1] = b3[x , y - 1] b3_5 = b3_ptr[0] ; // b3[x , y ] b3_6 = b3_5 ; // b3[x + 1 , y ] = b3[x , y ] b3_8 = b3_2 - b3_5 * 6 + b3_ptr[pitch] ; b3_9 = b3_8 ; } for ( x = 0 , indx = 0 ; x < plane - > width ; x + =2 , indx + + ) { if ( x + 2 > = plane - > width ) { b0_ptr - - ; b1_ptr - - ; b2_ptr - - ; b3_ptr - - ; } / * some values calculated in the previous iterations can * / / * be reused in the next ones , so do appropriate copying * / b2_1 = b2_2 ; // b2[x - 1 , y ] = b2[x , y ] b2_2 = b2_3 ; // b2[x , y ] = b2[x + 1 , y ] b2_4 = b2_5 ; // b2[x - 1 , y + 1] = b2[x , y + 1] b2_5 = b2_6 ; // b2[x , y + 1] = b2[x + 1 , y + 1] b3_1 = b3_2 ; // b3[x - 1 , y - 1] = b3[x , y - 1] b3_2 = b3_3 ; // b3[x , y - 1] = b3[x + 1 , y - 1] b3_4 = b3_5 ; // b3[x - 1 , y ] = b3[x , y ] b3_5 = b3_6 ; // b3[x , y ] = b3[x + 1 , y ] b3_7 = b3_8 ; // vert_HPF ( x - 1 ) b3_8 = b3_9 ; // vert_HPF ( x ) p0 = p1 = p2 = p3 = 0 ; / * process the LL - band by applying LPF both vertically and horizontally * / if ( num_bands > 0 ) { tmp0 = b0_1 ; tmp2 = b0_2 ; b0_1 = b0_ptr[indx + 1] ; b0_2 = b0_ptr[pitch + indx + 1] ; tmp1 = tmp0 + b0_1 ; p0 = tmp0 < < 4 ; p1 = tmp1 < < 3 ; p2 = ( tmp0 + tmp2 ) < < 3 ; p3 = ( tmp1 + tmp2 + b0_2 ) < < 2 ; } / * process the HL - band by applying HPF vertically and LPF horizontally * / if ( num_bands > 1 ) { tmp0 = b1_2 ; tmp1 = b1_1 ; b1_2 = b1_ptr[indx + 1] ; b1_1 = b1_ptr[back_pitch + indx + 1] ; tmp2 = tmp1 - tmp0 * 6 + b1_3 ; b1_3 = b1_1 - b1_2 * 6 + b1_ptr[pitch + indx + 1] ; p0 + = ( tmp0 + tmp1 ) < < 3 ; p1 + = ( tmp0 + tmp1 + b1_1 + b1_2 ) < < 2 ; p2 + = tmp2 < < 2 ; p3 + = ( tmp2 + b1_3 ) < < 1 ; } / * process the LH - band by applying LPF vertically and HPF horizontally * / if ( num_bands > 2 ) { b2_3 = b2_ptr[indx + 1] ; b2_6 = b2_ptr[pitch + indx + 1] ; tmp0 = b2_1 + b2_2 ; tmp1 = b2_1 - b2_2 * 6 + b2_3 ; p0 + = tmp0 < < 3 ; p1 + = tmp1 < < 2 ; p2 + = ( tmp0 + b2_4 + b2_5 ) < < 2 ; p3 + = ( tmp1 + b2_4 - b2_5 * 6 + b2_6 ) < < 1 ; } / * process the HH - band by applying HPF both vertically and horizontally * / if ( num_bands > 3 ) { b3_6 = b3_ptr[indx + 1] ; // b3[x + 1 , y ] b3_3 = b3_ptr[back_pitch + indx + 1] ; // b3[x + 1 , y - 1] tmp0 = b3_1 + b3_4 ; tmp1 = b3_2 + b3_5 ; tmp2 = b3_3 + b3_6 ; b3_9 = b3_3 - b3_6 * 6 + b3_ptr[pitch + indx + 1] ; p0 + = ( tmp0 + tmp1 ) < < 2 ; p1 + = ( tmp0 - tmp1 * 6 + tmp2 ) < < 1 ; p2 + = ( b3_7 + b3_8 ) < < 1 ; p3 + = b3_7 - b3_8 * 6 + b3_9 ; } / * output four pixels * / dst[x] = av_clip_uint8 ( ( p0 > > 6 ) + 128 ) ; dst[x + 1] = av_clip_uint8 ( ( p1 > > 6 ) + 128 ) ; dst[dst_pitch + x] = av_clip_uint8 ( ( p2 > > 6 ) + 128 ) ; dst[dst_pitch + x + 1] = av_clip_uint8 ( ( p3 > > 6 ) + 128 ) ; } // for x dst + = dst_pitch < < 1 ; back_pitch = -",1
"static void compute_status ( HTTPContext * c ) { HTTPContext * c1 ; FFStream * stream ; char * p ; time_t ti ; int i , len ; AVIOContext * pb ; if ( avio_open_dyn_buf ( & pb ) < 0 ) { / * XXX : return an error ? * / c - > buffer_ptr = c - > buffer ; c - > buffer_end = c - > buffer ; return ; } avio_printf ( pb , HTTP/1 . 0 200 OK\r\n ) ; avio_printf ( pb , Content - type : %s\r\n , text/html ) ; avio_printf ( pb , Pragma : no - cache\r\n ) ; avio_printf ( pb , \r\n ) ; avio_printf ( pb , < html > < head > < title > %s Status < /title > \n , program_name ) ; if ( c - > stream - > feed_filename[0] ) avio_printf ( pb , < link rel=\ shortcut icon\ href=\ %s\ > \n , c - > stream - > feed_filename ) ; avio_printf ( pb , < /head > \n < body > ) ; avio_printf ( pb , < h1 > %s Status < /h1 > \n , program_name ) ; / * format status * / avio_printf ( pb , < h2 > Available Streams < /h2 > \n ) ; avio_printf ( pb , < table cellspacing=0 cellpadding=4 > \n ) ; avio_printf ( pb , < tr > < th valign=top > Path < th align=left > Served < br > Conns < th > < br > bytes < th valign=top > Format < th > Bit rate < br > kbits/s < th align=left > Video < br > kbits/s < th > < br > Codec < th align=left > Audio < br > kbits/s < th > < br > Codec < th align=left valign=top > Feed\n ) ; stream = first_stream ; while ( stream ! = NULL ) { char sfilename[1024] ; char * eosf ; if ( stream - > feed ! = stream ) { av_strlcpy ( sfilename , stream - > filename , sizeof ( sfilename ) - 10 ) ; eosf = sfilename + strlen ( sfilename ) ; if ( eosf - sfilename > = 4 ) { if ( strcmp ( eosf - 4 , . asf ) == 0 ) strcpy ( eosf - 4 , . asx ) ; else if ( strcmp ( eosf - 3 , . rm ) == 0 ) strcpy ( eosf - 3 , . ram ) ; else if ( stream - > fmt & & ! strcmp ( stream - > fmt - > name , rtp ) ) { / * generate a sample RTSP director if unicast . Generate an SDP redirector if multicast * / eosf = strrchr ( sfilename , ' . ' ) ; if ( ! eosf ) eosf = sfilename + strlen ( sfilename ) ; if ( stream - > is_multicast ) strcpy ( eosf , . sdp ) ; else strcpy ( eosf , . rtsp ) ; } } avio_printf ( pb , < tr > < td > < a href=\ /%s\ > %s < /a > , sfilename , stream - > filename ) ; avio_printf ( pb , < td align=right > %d < td align=right > , stream - > conns_served ) ; fmt_bytecount ( pb , stream - > bytes_served ) ; switch ( stream - > stream_type ) { case STREAM_TYPE_LIVE : { int audio_bit_rate = 0 ; int video_bit_rate = 0 ; const char * audio_codec_name = ; const char * video_codec_name = ; const char * audio_codec_name_extra = ; const char * video_codec_name_extra = ; for ( i=0 ; i < stream - > nb_streams ; i + + ) { AVStream * st = stream - > streams[i] ; AVCodec * codec = avcodec_find_encoder ( st - > codec - > codec_id ) ; switch ( st - > codec - > codec_type ) { case AVMEDIA_TYPE_AUDIO : audio_bit_rate + = st - > codec - > bit_rate ; if ( codec ) { if ( * audio_codec_name ) audio_codec_name_extra = . . . ; audio_codec_name = codec - > name ; } break ; case AVMEDIA_TYPE_VIDEO : video_bit_rate + = st - > codec - > bit_rate ; if ( codec ) { if ( * video_codec_name ) video_codec_name_extra = . . . ; video_codec_name = codec - > name ; } break ; case AVMEDIA_TYPE_DATA : video_bit_rate + = st - > codec - > bit_rate ; break ; default : abort ( ) ; } } avio_printf ( pb , < td align=center > %s < td align=right > %d < td align=right > %d < td > %s %s < td align=right > %d < td > %s %s , stream - > fmt - > name , stream - > bandwidth , video_bit_rate / 1000 , video_codec_name , video_codec_name_extra , audio_bit_rate / 1000 , audio_codec_name , audio_codec_name_extra ) ; if ( stream - > feed ) avio_printf ( pb , < td > %s , stream - > feed - > filename ) ; else avio_printf ( pb , < td > %s , stream - > feed_filename ) ; avio_printf ( pb , \n ) ; } break ; default : avio_printf ( pb , < td align=center > - < td align=right > - < td align=right > - < td > < td align=right > - < td > \n ) ; break ; } } stream = stream - > next ; } avio_printf ( pb , < /table > \n ) ; stream = first_stream ; while ( stream ! = NULL ) { if ( stream - > feed == stream ) { avio_printf ( pb , < h2 > Feed %s < /h2 > , stream - > filename ) ; if ( stream - > pid ) { avio_printf ( pb , Running as pid %d . \n , stream - > pid ) ; if defined ( linux ) & & ! defined ( CONFIG_NOCUTILS ) { FILE * pid_stat ; char ps_cmd[64] ; / * This is somewhat linux specific I guess * / snprintf ( ps_cmd , sizeof ( ps_cmd ) , ps - o \ %%cpu , cputime\ - - no - headers %d , stream - > pid ) ; pid_stat = popen ( ps_cmd , r ) ; if ( pid_stat ) { char cpuperc[10] ; char cpuused[64] ; if ( fscanf ( pid_stat , %9s %63s , cpuperc , cpuused ) == 2 ) { avio_printf ( pb , Currently using %s%% of the cpu . Total time used %s . \n , cpuperc , cpuused ) ; } fclose ( pid_stat ) ; } } endif avio_printf ( pb , < p > ) ; } avio_printf ( pb , < table cellspacing=0 cellpadding=4 > < tr > < th > Stream < th > type < th > kbits/s < th align=left > codec < th align=left > Parameters\n )",0
"int av_image_fill_pointers ( uint8_t * data[4] , enum PixelFormat pix_fmt , int height , uint8_t * ptr , const int linesizes[4] ) { int i , total_size , size[4] , has_plane[4] ; const AVPixFmtDescriptor * desc = & av_pix_fmt_descriptors[pix_fmt] ; memset ( data , 0 , sizeof ( data[0] ) * 4 ) ; memset ( size , 0 , sizeof ( size ) ) ; memset ( has_plane , 0 , sizeof ( has_plane ) ) ; if ( desc - > flags & PIX_FMT_HWACCEL ) return AVERROR ( EINVAL ) ; data[0] = ptr ; size[0] = linesizes[0] * height ; if ( desc - > flags & PIX_FMT_PAL ) { size[0] = ( size[0] + 3 ) & 3 ; data[1] = ptr + size[0] ; / * palette is stored here as 256 32 bits words * / return size[0] + 256 * 4 ; } for ( i = 0 ; i < 4 ; i + + ) has_plane[desc - > comp[i] . plane] = 1 ; total_size = size[0] ; for ( i = 1 ; has_plane[i] & & i < 4 ; i + + ) { int h , s = ( i == 1 || i == 2 ) ? desc - > log2_chroma_h : 0 ; data[i] = data[i - 1] + size[i - 1] ; h = ( height + ( 1 < < s ) - 1 ) > > s ; size[i] = h * linesizes[i] ; total_size + = size[i] ; } return total_size ; }",0
"static int genh_read_packet ( AVFormatContext * s , AVPacket * pkt ) { AVCodecContext * codec = s - > streams[0] - > codec ; GENHDemuxContext * c = s - > priv_data ; int ret ; if ( c - > dsp_int_type == 1 & & codec - > codec_id == AV_CODEC_ID_ADPCM_THP & & codec - > channels > 1 ) { int i , ch ; if ( avio_feof ( s - > pb ) ) return AVERROR_EOF ; av_new_packet ( pkt , 8 * codec - > channels ) ; for ( i = 0 ; i < 8 / c - > interleave_size ; i + + ) { for ( ch = 0 ; ch < codec - > channels ; ch + + ) { pkt - > data[ch * 8 + i * c - > interleave_size + 0] = avio_r8 ( s - > pb ) ; pkt - > data[ch * 8 + i * c - > interleave_size + 1] = avio_r8 ( s - > pb ) ; } } ret = 0 ; } else { ret = av_get_packet ( s - > pb , pkt , codec - > block_align ? codec - > block_align : 1024 * codec - > channels ) ; } pkt - > stream_index = 0 ; return ret ; }",0
"static int pcm_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame_ptr , AVPacket * avpkt ) { const uint8_t * src = avpkt - > data ; int buf_size = avpkt - > size ; PCMDecode * s = avctx - > priv_data ; AVFrame * frame = data ; int sample_size , c , n , ret , samples_per_block ; uint8_t * samples ; int32_t * dst_int32_t ; sample_size = av_get_bits_per_sample ( avctx - > codec_id ) / 8 ; / * av_get_bits_per_sample returns 0 for AV_CODEC_ID_PCM_DVD * / samples_per_block = 1 ; if ( avctx - > codec - > id == AV_CODEC_ID_PCM_DVD ) { if ( avctx - > bits_per_coded_sample ! = 20 & & avctx - > bits_per_coded_sample ! = 24 ) { av_log ( avctx , AV_LOG_ERROR , PCM DVD unsupported sample depth\n ) ; return AVERROR ( EINVAL ) ; } / * 2 samples are interleaved per block in PCM_DVD * / samples_per_block = 2 ; sample_size = avctx - > bits_per_coded_sample * 2 / 8 ; } else if ( avctx - > codec_id == AV_CODEC_ID_PCM_LXF ) { / * we process 40 - bit blocks per channel for LXF * / samples_per_block = 2 ; sample_size = 5 ; } if ( sample_size == 0 ) { av_log ( avctx , AV_LOG_ERROR , Invalid sample_size\n ) ; return AVERROR ( EINVAL ) ; } n = avctx - > channels * sample_size ; if ( n & & buf_size % n ) { if ( buf_size < n ) { av_log ( avctx , AV_LOG_ERROR , invalid PCM packet\n ) ; return - 1 ; } else buf_size - = buf_size % n ; } n = buf_size / sample_size ; / * get output buffer * / frame - > nb_samples = n * samples_per_block / avctx - > channels ; if ( ( ret = ff_get_buffer ( avctx , frame , 0 ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed\n ) ; return ret ; } samples = frame - > data[0] ; switch ( avctx - > codec - > id ) { case AV_CODEC_ID_PCM_U32LE : DECODE ( 32 , le32 , src , samples , n , 0 , 0x80000000 ) break ; case AV_CODEC_ID_PCM_U32BE : DECODE ( 32 , be32 , src , samples , n , 0 , 0x80000000 ) break ; case AV_CODEC_ID_PCM_S24LE : DECODE ( 32 , le24 , src , samples , n , 8 , 0 ) break ; case AV_CODEC_ID_PCM_S24BE : DECODE ( 32 , be24 , src , samples , n , 8 , 0 ) break ; case AV_CODEC_ID_PCM_U24LE : DECODE ( 32 , le24 , src , samples , n , 8 , 0x800000 ) break ; case AV_CODEC_ID_PCM_U24BE : DECODE ( 32 , be24 , src , samples , n , 8 , 0x800000 ) break ; case AV_CODEC_ID_PCM_S24DAUD : for ( ; n > 0 ; n - - ) { uint32_t v = bytestream_get_be24 ( & src ) ; v > > = 4 ; // sync flags are here AV_WN16A ( samples , ff_reverse[ ( v > > 8 ) & 0xff] + ( ff_reverse[v & 0xff] < < 8 ) ) ; samples + = 2 ; } break ; case AV_CODEC_ID_PCM_S16LE_PLANAR : { int av_unused n2 ; n /= avctx - > channels ; for ( c = 0 ; c < avctx - > channels ; c + + ) { samples = frame - > extended_data[c] ; if HAVE_BIGENDIAN n2 = n ; DECODE ( 16 , le16 , src , samples , n2 , 0 , 0 ) else memcpy ( samples , src , n * 2 ) ; src + = n * 2 ; endif } break ; } case AV_CODEC_ID_PCM_U16LE : DECODE ( 16 , le16 , src , samples , n , 0 , 0x8000 ) break ; case AV_CODEC_ID_PCM_U16BE : DECODE ( 16 , be16 , src , samples , n , 0 , 0x8000 ) break ; case AV_CODEC_ID_PCM_S8 : for ( ; n > 0 ; n - - ) * samples + + = * src + + + 128 ; break ; if HAVE_BIGENDIAN case AV_CODEC_ID_PCM_F64LE : DECODE ( 64 , le64 , src , samples , n , 0 , 0 ) break ; case AV_CODEC_ID_PCM_S32LE : case AV_CODEC_ID_PCM_F32LE : DECODE ( 32 , le32 , src , samples , n , 0 , 0 ) break ; case AV_CODEC_ID_PCM_S16LE : DECODE ( 16 , le16 , src , samples , n , 0 , 0 ) break ; case AV_CODEC_ID_PCM_F64BE : case AV_CODEC_ID_PCM_F32BE : case AV_CODEC_ID_PCM_S32BE : case AV_CODEC_ID_PCM_S16BE : else case AV_CODEC_ID_PCM_F64BE : DECODE ( 64 , be64 , src , samples , n , 0 , 0 ) break ; case AV_CODEC_ID_PCM_F32BE : case AV_CODEC_ID_PCM_S32BE : DECODE ( 32 , be32 , src , samples , n , 0 , 0 ) break ; case AV_CODEC_ID_PCM_S16BE : DECODE ( 16 , be16 , src , samples , n , 0 , 0 ) break ; case AV_CODEC_ID_PCM_F64LE : case AV_CODEC_ID_PCM_F32LE : case AV_CODEC_ID_PCM_S32LE : case AV_CODEC_ID_PCM_S16LE : endif / * HAVE_BIGENDIAN * / case AV_CODEC_ID_PCM_U8 : memcpy ( samples , src , n * sample_size ) ; break ; case AV_CODEC_ID_PCM_ZORK : for ( ; n > 0 ; n - - ) { int v = * src + + ; if ( v < 128 ) v = 128 - v ; * samples + + = v ; } break ; case AV_CODEC_ID_PCM_ALAW : case AV_CODEC_ID_PCM_MULAW : for ( ; n > 0 ; n - - ) { AV_WN16A ( samples , s - > table[ * src + + ] ) ; samples + = 2 ; } break ; case AV_CODEC_ID_PCM_DVD : { const uint8_t * src8 ; dst_int32_t = ( int32_t * ) frame - > data[0] ; n /= avctx - > channels ; switch ( avctx - > bits_per_coded_sample ) { case 20 : while ( n - - ) { c = avctx - > channels ; src8 = src + 4 * c ; while ( c - - ) { * dst_int32_t + + = ( bytestream_get_be16 ( & src ) < < 16 ) + ( ( * src8 & 0xf0 ) < < 8 ) ; * dst_int32_t + + = ( bytestream_get_be16 ( & src ) < < 16 ) + ( ( * src8 + + & 0x0f ) < < 12 ) ; } src = src8 ; } break ; case 24 : while ( n - - ) { c = avctx - > channels ; src8 = src + 4 * c ; while ( c - - ) { * dst_int32_t + + = ( bytestream_get_be16 ( & src ) < < 16 ) + ( ( * src8 + + ) < < 8 ) ; * dst_int32_t + + = ( bytestream_get_be16 ( & src ) < < 16 ) + ( ( * src8 + + ) <",1
"static av_cold int MPA_encode_init ( AVCodecContext * avctx ) { MpegAudioContext * s = avctx - > priv_data ; int freq = avctx - > sample_rate ; int bitrate = avctx - > bit_rate ; int channels = avctx - > channels ; int i , v , table ; float a ; if ( channels < = 0 || channels > 2 ) { av_log ( avctx , AV_LOG_ERROR , encoding %d channel ( s ) is not allowed in mp2\n , channels ) ; return AVERROR ( EINVAL ) ; } bitrate = bitrate / 1000 ; s - > nb_channels = channels ; avctx - > frame_size = MPA_FRAME_SIZE ; avctx - > delay = 512 - 32 + 1 ; / * encoding freq * / s - > lsf = 0 ; for ( i=0 ; i < 3 ; i + + ) { if ( avpriv_mpa_freq_tab[i] == freq ) break ; if ( ( avpriv_mpa_freq_tab[i] / 2 ) == freq ) { s - > lsf = 1 ; break ; } } if ( i == 3 ) { av_log ( avctx , AV_LOG_ERROR , Sampling rate %d is not allowed in mp2\n , freq ) ; return AVERROR ( EINVAL ) ; } s - > freq_index = i ; / * encoding bitrate & frequency * / for ( i=0 ; i < 15 ; i + + ) { if ( avpriv_mpa_bitrate_tab[s - > lsf][1][i] == bitrate ) break ; } if ( i == 15 ) { av_log ( avctx , AV_LOG_ERROR , bitrate %d is not allowed in mp2\n , bitrate ) ; return AVERROR ( EINVAL ) ; } s - > bitrate_index = i ; / * compute total header size & pad bit * / a = ( float ) ( bitrate * 1000 * MPA_FRAME_SIZE ) / ( freq * 8 . 0 ) ; s - > frame_size = ( ( int ) a ) * 8 ; / * frame fractional size to compute padding * / s - > frame_frac = 0 ; s - > frame_frac_incr = ( int ) ( ( a - floor ( a ) ) * 65536 . 0 ) ; / * select the right allocation table * / table = ff_mpa_l2_select_table ( bitrate , s - > nb_channels , freq , s - > lsf ) ; / * number of used subbands * / s - > sblimit = ff_mpa_sblimit_table[table] ; s - > alloc_table = ff_mpa_alloc_tables[table] ; av_dlog ( avctx , %d kb/s , %d Hz , frame_size=%d bits , table=%d , padincr=%x\n , bitrate , freq , s - > frame_size , table , s - > frame_frac_incr ) ; for ( i=0 ; i < s - > nb_channels ; i + + ) s - > samples_offset[i] = 0 ; for ( i=0 ; i < 257 ; i + + ) { int v ; v = ff_mpa_enwindow[i] ; if WFRAC_BITS ! = 16 v = ( v + ( 1 < < ( 16 - WFRAC_BITS - 1 ) ) ) > > ( 16 - WFRAC_BITS ) ; endif s - > filter_bank[i] = v ; if ( ( i & 63 ) ! = 0 ) v = - v ; if ( i ! = 0 ) s - > filter_bank[512 - i] = v ; } for ( i=0 ; i < 64 ; i + + ) { v = ( int ) ( pow ( 2 . 0 , ( 3 - i ) / 3 . 0 ) * ( 1 < < 20 ) ) ; if ( v < = 0 ) v = 1 ; s - > scale_factor_table[i] = v ; s - > scale_factor_inv_table[i] = pow ( 2 . 0 , - ( 3 - i ) / 3 . 0 ) / ( float ) ( 1 < < 20 ) ; } for ( i=0 ; i < 128 ; i + + ) { v = i - 64 ; if ( v < = - 3 ) v = 0 ; else if ( v < 0 ) v = 1 ; else if ( v == 0 ) v = 2 ; else if ( v < 3 ) v = 3 ; else v = 4 ; s - > scale_diff_table[i] = v ; } for ( i=0 ; i < 17 ; i + + ) { v = ff_mpa_quant_bits[i] ; if ( v < 0 ) v = - v ; else v = v * 3 ; s - > total_quant_bits[i] = 12 * v ; } return 0 ; }",0
"void ff_avg_h264_qpel8_mc32_msa ( uint8_t * dst , const uint8_t * src , ptrdiff_t stride ) { avc_luma_midh_qrt_and_aver_dst_8w_msa ( src - ( 2 * stride ) - 2 , stride , dst , stride , 8 , 1 ) ; }",0
"static void deblocking_filter_CTB ( HEVCContext * s , int x0 , int y0 ) { uint8_t * src ; int x , y , x_end , y_end , chroma ; int c_tc[2] , beta[2] , tc[2] ; uint8_t no_p[2] = { 0 } ; uint8_t no_q[2] = { 0 } ; int log2_ctb_size = s - > sps - > log2_ctb_size ; int ctb_size = 1 < < log2_ctb_size ; int ctb = ( x0 > > log2_ctb_size ) + ( y0 > > log2_ctb_size ) * s - > sps - > ctb_width ; int cur_tc_offset = s - > deblock[ctb] . tc_offset ; int cur_beta_offset = s - > deblock[ctb] . beta_offset ; int tc_offset , left_tc_offset , beta_offset , left_beta_offset ; int pcmf = ( s - > sps - > pcm_enabled_flag & & s - > sps - > pcm . loop_filter_disable_flag ) || s - > pps - > transquant_bypass_enable_flag ; if ( x0 ) { left_tc_offset = s - > deblock[ctb - 1] . tc_offset ; left_beta_offset = s - > deblock[ctb - 1] . beta_offset ; } x_end = x0 + ctb_size ; if ( x_end > s - > sps - > width ) x_end = s - > sps - > width ; y_end = y0 + ctb_size ; if ( y_end > s - > sps - > height ) y_end = s - > sps - > height ; tc_offset = cur_tc_offset ; beta_offset = cur_beta_offset ; // vertical filtering luma for ( y = y0 ; y < y_end ; y + = 8 ) { for ( x = x0 ? x0 : 8 ; x < x_end ; x + = 8 ) { const int bs0 = s - > vertical_bs[ ( x > > 3 ) + ( y > > 2 ) * s - > bs_width] ; const int bs1 = s - > vertical_bs[ ( x > > 3 ) + ( ( y + 4 ) > > 2 ) * s - > bs_width] ; if ( bs0 || bs1 ) { const int qp0 = ( get_qPy ( s , x - 1 , y ) + get_qPy ( s , x , y ) + 1 ) > > 1 ; const int qp1 = ( get_qPy ( s , x - 1 , y + 4 ) + get_qPy ( s , x , y + 4 ) + 1 ) > > 1 ; beta[0] = betatable[av_clip ( qp0 + beta_offset , 0 , MAX_QP ) ] ; beta[1] = betatable[av_clip ( qp1 + beta_offset , 0 , MAX_QP ) ] ; tc[0] = bs0 ? TC_CALC ( qp0 , bs0 ) : 0 ; tc[1] = bs1 ? TC_CALC ( qp1 , bs1 ) : 0 ; src = & s - > frame - > data[LUMA][y * s - > frame - > linesize[LUMA] + ( x < < s - > sps - > pixel_shift ) ] ; if ( pcmf ) { no_p[0] = get_pcm ( s , x - 1 , y ) ; no_p[1] = get_pcm ( s , x - 1 , y + 4 ) ; no_q[0] = get_pcm ( s , x , y ) ; no_q[1] = get_pcm ( s , x , y + 4 ) ; s - > hevcdsp . hevc_v_loop_filter_luma_c ( src , s - > frame - > linesize[LUMA] , beta , tc , no_p , no_q ) ; } else s - > hevcdsp . hevc_v_loop_filter_luma ( src , s - > frame - > linesize[LUMA] , beta , tc , no_p , no_q ) ; } } } // vertical filtering chroma for ( chroma = 1 ; chroma < = 2 ; chroma + + ) { for ( y = y0 ; y < y_end ; y + = 16 ) { for ( x = x0 ? x0 : 16 ; x < x_end ; x + = 16 ) { const int bs0 = s - > vertical_bs[ ( x > > 3 ) + ( y > > 2 ) * s - > bs_width] ; const int bs1 = s - > vertical_bs[ ( x > > 3 ) + ( ( y + 8 ) > > 2 ) * s - > bs_width] ; if ( ( bs0 == 2 ) || ( bs1 == 2 ) ) { const int qp0 = ( get_qPy ( s , x - 1 , y ) + get_qPy ( s , x , y ) + 1 ) > > 1 ; const int qp1 = ( get_qPy ( s , x - 1 , y + 8 ) + get_qPy ( s , x , y + 8 ) + 1 ) > > 1 ; c_tc[0] = ( bs0 == 2 ) ? chroma_tc ( s , qp0 , chroma , tc_offset ) : 0 ; c_tc[1] = ( bs1 == 2 ) ? chroma_tc ( s , qp1 , chroma , tc_offset ) : 0 ; src = & s - > frame - > data[chroma][y / 2 * s - > frame - > linesize[chroma] + ( ( x / 2 ) < < s - > sps - > pixel_shift ) ] ; if ( pcmf ) { no_p[0] = get_pcm ( s , x - 1 , y ) ; no_p[1] = get_pcm ( s , x - 1 , y + 8 ) ; no_q[0] = get_pcm ( s , x , y ) ; no_q[1] = get_pcm ( s , x , y + 8 ) ; s - > hevcdsp . hevc_v_loop_filter_chroma_c ( src , s - > frame - > linesize[chroma] , c_tc , no_p , no_q ) ; } else s - > hevcdsp . hevc_v_loop_filter_chroma ( src , s - > frame - > linesize[chroma] , c_tc , no_p , no_q ) ; } } } } // horizontal filtering luma if ( x_end ! = s - > sps - > width ) x_end - = 8 ; for ( y = y0 ? y0 : 8 ; y < y_end ; y + = 8 ) { for ( x = x0 ? x0 - 8 : 0 ; x < x_end ; x + = 8 ) { const int bs0 = s - > horizontal_bs[ ( x + y * s - > bs_width ) > > 2] ; const int bs1 = s - > horizontal_bs[ ( x + 4 + y * s - > bs_width ) > > 2] ; if ( bs0 || bs1 ) { const int qp0 = ( get_qPy ( s , x , y - 1 ) + get_qPy ( s , x , y ) + 1 ) > > 1 ; const int qp1 = ( get_qPy ( s , x + 4 , y - 1 ) + get_qPy ( s , x + 4 , y ) + 1 ) > > 1 ; tc_offset = x > = x0 ? cur_tc_offset : left_tc_offset",0
"static inline void mix_2f_2r_to_dolby ( AC3DecodeContext * ctx ) { int i ; float ( * output ) [256] = ctx - > audio_block . block_output ; for ( i = 0 ; i < 256 ; i + + ) { output[1][i] - = output[3][i] ; output[2][i] + = output[4][i] ; } memset ( output[3] , 0 , sizeof ( output[3] ) ) ; memset ( output[4] , 0 , sizeof ( output[4] ) ) ; }",0
"int ff_qsv_enc_close ( AVCodecContext * avctx , QSVEncContext * q ) { QSVFrame * cur ; MFXVideoENCODE_Close ( q - > session ) ; if ( q - > internal_session ) MFXClose ( q - > internal_session ) ; q - > session = NULL ; q - > internal_session = NULL ; cur = q - > work_frames ; while ( cur ) { q - > work_frames = cur - > next ; av_frame_free ( & cur - > frame ) ; av_freep ( & cur ) ; cur = q - > work_frames ; } while ( q - > async_fifo & & av_fifo_size ( q - > async_fifo ) ) { AVPacket pkt ; mfxSyncPoint sync ; mfxBitstream * bs ; av_fifo_generic_read ( q - > async_fifo , & pkt , sizeof ( pkt ) , NULL ) ; av_fifo_generic_read ( q - > async_fifo , & sync , sizeof ( sync ) , NULL ) ; av_fifo_generic_read ( q - > async_fifo , & bs , sizeof ( bs ) , NULL ) ; av_freep ( & bs ) ; av_packet_unref ( & pkt ) ; } av_fifo_free ( q - > async_fifo ) ; q - > async_fifo = NULL ; av_frame_free ( & avctx - > coded_frame ) ; return 0 ; }",0
static av_cold int raw_encode_init ( AVCodecContext * avctx ) { const AVPixFmtDescriptor * desc = av_pix_fmt_desc_get ( avctx - > pix_fmt ) ; avctx - > coded_frame = av_frame_alloc ( ) ; if ( ! avctx - > coded_frame ) return AVERROR ( ENOMEM ) ; avctx - > coded_frame - > pict_type = AV_PICTURE_TYPE_I ; avctx - > coded_frame - > key_frame = 1 ; avctx - > bits_per_coded_sample = av_get_bits_per_pixel ( desc ) ; if ( ! avctx - > codec_tag ) avctx - > codec_tag = avcodec_pix_fmt_to_codec_tag ( avctx - > pix_fmt ) ; return 0 ; },0
"int ff_audio_mix ( AudioMix * am , AudioData * src ) { int use_generic = 1 ; int len = src - > nb_samples ; int i , j ; / * determine whether to use the optimized function based on pointer and samples alignment in both the input and output * / if ( am - > has_optimized_func ) { int aligned_len = FFALIGN ( len , am - > samples_align ) ; if ( ! ( src - > ptr_align % am - > ptr_align ) & & src - > samples_align > = aligned_len ) { len = aligned_len ; use_generic = 0 ; } } av_dlog ( am - > avr , audio_mix : %d samples - %d to %d channels ( %s ) \n , src - > nb_samples , am - > in_channels , am - > out_channels , use_generic ? am - > func_descr_generic : am - > func_descr ) ; if ( am - > in_matrix_channels & & am - > out_matrix_channels ) { uint8_t * * data ; uint8_t * data0[AVRESAMPLE_MAX_CHANNELS] ; if ( am - > out_matrix_channels < am - > out_channels || am - > in_matrix_channels < am - > in_channels ) { for ( i = 0 , j = 0 ; i < FFMAX ( am - > in_channels , am - > out_channels ) ; i + + ) { if ( am - > input_skip[i] || am - > output_skip[i] || am - > output_zero[i] ) continue ; data0[j + + ] = src - > data[i] ; } data = data0 ; } else { data = src - > data ; } if ( use_generic ) am - > mix_generic ( data , am - > matrix , len , am - > out_matrix_channels , am - > in_matrix_channels ) ; else am - > mix ( data , am - > matrix , len , am - > out_matrix_channels , am - > in_matrix_channels ) ; } if ( am - > out_matrix_channels < am - > out_channels ) { for ( i = 0 ; i < am - > out_channels ; i + + ) if ( am - > output_zero[i] ) av_samples_set_silence ( & src - > data[i] , 0 , len , 1 , am - > fmt ) ; } ff_audio_data_set_channels ( src , am - > out_channels ) ; return 0 ; }",1
"static void mm_decode_intra ( MmContext * s , int half_horiz , int half_vert , const uint8_t * buf , int buf_size ) { int i , x , y ; i=0 ; x=0 ; y=0 ; while ( i < buf_size ) { int run_length , color ; if ( buf[i] & 0x80 ) { run_length = 1 ; color = buf[i] ; i + + ; } else { run_length = ( buf[i] & 0x7f ) + 2 ; color = buf[i + 1] ; i + =2 ; } if ( half_horiz ) run_length * =2 ; if ( color ) { memset ( s - > frame . data[0] + y * s - > frame . linesize[0] + x , color , run_length ) ; if ( half_vert ) memset ( s - > frame . data[0] + ( y + 1 ) * s - > frame . linesize[0] + x , color , run_length ) ; } x + = run_length ; if ( x > = s - > avctx - > width ) { x=0 ; y + = half_vert ? 2 : 1 ; } } }",0
"void av_log_default_callback ( void * ptr , int level , const char * fmt , va_list vl ) { static int print_prefix=1 ; static int count ; static char line[1024] , prev[1024] ; static int is_atty ; AVClass * avc= ptr ? * ( AVClass * * ) ptr : NULL ; if ( level > av_log_level ) return ; line[0]=0 ; undef fprintf if ( print_prefix & & avc ) { if ( avc - > parent_log_context_offset ) { AVClass * * parent= * ( AVClass * * * ) ( ( ( uint8_t * ) ptr ) + avc - > parent_log_context_offset ) ; if ( parent & & * parent ) { snprintf ( line , sizeof ( line ) , [%s %p] , ( * parent ) - > item_name ( parent ) , parent ) ; } } snprintf ( line + strlen ( line ) , sizeof ( line ) - strlen ( line ) , [%s %p] , avc - > item_name ( ptr ) , ptr ) ; } vsnprintf ( line + strlen ( line ) , sizeof ( line ) - strlen ( line ) , fmt , vl ) ; print_prefix= line[strlen ( line ) - 1] == ' \n ' ; if HAVE_ISATTY if ( ! is_atty ) is_atty= isatty ( 2 ) ? 1 : - 1 ; endif if ( print_prefix & & ( flags & AV_LOG_SKIP_REPEATED ) & & ! strcmp ( line , prev ) ) { count + + ; if ( is_atty==1 ) fprintf ( stderr , Last message repeated %d times\r , count ) ; return ; } if ( count > 0 ) { fprintf ( stderr , Last message repeated %d times\n , count ) ; count=0 ; } colored_fputs ( av_clip ( level > > 3 , 0 , 6 ) , line ) ; strcpy ( prev , line ) ; }",1
"void ff_thread_await_progress ( ThreadFrame * f , int n , int field ) { PerThreadContext * p ; atomic_int * progress = f - > progress ? ( atomic_int * ) f - > progress - > data : NULL ; if ( ! progress || atomic_load_explicit ( & progress[field] , memory_order_acquire ) > = n ) return ; p = f - > owner[field] - > internal - > thread_ctx ; pthread_mutex_lock ( & p - > progress_mutex ) ; if ( f - > owner[field] - > debug & FF_DEBUG_THREADS ) av_log ( f - > owner[field] , AV_LOG_DEBUG , thread awaiting %d field %d from %p\n , n , field , progress ) ; while ( atomic_load_explicit ( & progress[field] , memory_order_relaxed ) < n ) pthread_cond_wait ( & p - > progress_cond , & p - > progress_mutex ) ; pthread_mutex_unlock ( & p - > progress_mutex ) ; }",1
"int av_opt_is_set_to_default ( void * obj , const AVOption * o ) { int64_t i64 ; double d , d2 ; float f ; AVRational q ; int ret , w , h ; char * str ; void * dst ; if ( ! o || ! obj ) return AVERROR ( EINVAL ) ; dst = ( ( uint8_t * ) obj ) + o - > offset ; switch ( o - > type ) { case AV_OPT_TYPE_CONST : return 1 ; case AV_OPT_TYPE_FLAGS : case AV_OPT_TYPE_PIXEL_FMT : case AV_OPT_TYPE_SAMPLE_FMT : case AV_OPT_TYPE_INT : case AV_OPT_TYPE_CHANNEL_LAYOUT : case AV_OPT_TYPE_DURATION : case AV_OPT_TYPE_INT64 : read_number ( o , dst , NULL , NULL , & i64 ) ; return o - > default_val . i64 == i64 ; case AV_OPT_TYPE_STRING : str = * ( char * * ) dst ; if ( str == o - > default_val . str ) //2 NULLs return 1 ; if ( ! str || ! o - > default_val . str ) //1 NULL return 0 ; return ! strcmp ( str , o - > default_val . str ) ; case AV_OPT_TYPE_DOUBLE : read_number ( o , dst , & d , NULL , NULL ) ; return o - > default_val . dbl == d ; case AV_OPT_TYPE_FLOAT : read_number ( o , dst , & d , NULL , NULL ) ; f = o - > default_val . dbl ; d2 = f ; return d2 == d ; case AV_OPT_TYPE_RATIONAL : q = av_d2q ( o - > default_val . dbl , INT_MAX ) ; return ! av_cmp_q ( * ( AVRational * ) dst , q ) ; case AV_OPT_TYPE_BINARY : { struct { uint8_t * data ; int size ; } tmp = { 0 } ; int opt_size = * ( int * ) ( ( void * * ) dst + 1 ) ; void * opt_ptr = * ( void * * ) dst ; if ( ! opt_ptr & & ( ! o - > default_val . str || ! strlen ( o - > default_val . str ) ) ) return 1 ; if ( opt_ptr & & o - > default_val . str & & ! strlen ( o - > default_val . str ) ) return 0 ; if ( opt_size ! = strlen ( o - > default_val . str ) / 2 ) return 0 ; ret = set_string_binary ( NULL , NULL , o - > default_val . str , & tmp . data ) ; if ( ! ret ) ret = ! memcmp ( opt_ptr , tmp . data , tmp . size ) ; av_free ( tmp . data ) ; return ret ; } case AV_OPT_TYPE_DICT : / * Binary and dict have not default support yet . Any pointer is not default . * / return ! ! ( * ( void * * ) dst ) ; case AV_OPT_TYPE_IMAGE_SIZE : if ( ! o - > default_val . str || ! strcmp ( o - > default_val . str , none ) ) w = h = 0 ; else if ( ( ret = av_parse_video_size ( & w , & h , o - > default_val . str ) ) < 0 ) return ret ; return ( w == * ( int * ) dst ) & & ( h == * ( ( int * ) dst + 1 ) ) ; case AV_OPT_TYPE_VIDEO_RATE : q = ( AVRational ) { 0 , 0 } ; if ( o - > default_val . str ) av_parse_video_rate ( & q , o - > default_val . str ) ; return ! av_cmp_q ( * ( AVRational * ) dst , q ) ; case AV_OPT_TYPE_COLOR : { uint8_t color[4] = { 0 , 0 , 0 , 0 } ; if ( o - > default_val . str ) av_parse_color ( color , o - > default_val . str , - 1 , NULL ) ; return ! memcmp ( color , dst , sizeof ( color ) ) ; } default : av_log ( obj , AV_LOG_WARNING , Not supported option type : %d , option name : %s\n , o - > type , o - > name ) ; break ; } return AVERROR_PATCHWELCOME ; }",0
"static int indeo3_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , unsigned char * buf , int buf_size ) { Indeo3DecodeContext * s=avctx - > priv_data ; unsigned char * src , * dest ; int y ; / * no supplementary picture * / if ( buf_size == 0 ) { return 0 ; } iv_decode_frame ( s , buf , buf_size ) ; if ( s - > frame . data[0] ) avctx - > release_buffer ( avctx , & s - > frame ) ; s - > frame . reference = 0 ; if ( avctx - > get_buffer ( avctx , & s - > frame ) < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , get_buffer ( ) failed\n ) ; return - 1 ; } src = s - > cur_frame - > Ybuf ; dest = s - > frame . data[0] ; for ( y = 0 ; y < s - > height ; y + + ) { memcpy ( dest , src , s - > cur_frame - > y_w ) ; src + = s - > cur_frame - > y_w ; dest + = s - > frame . linesize[0] ; } if ( ! ( s - > avctx - > flags & CODEC_FLAG_GRAY ) ) { src = s - > cur_frame - > Ubuf ; dest = s - > frame . data[1] ; for ( y = 0 ; y < s - > height / 4 ; y + + ) { memcpy ( dest , src , s - > cur_frame - > uv_w ) ; src + = s - > cur_frame - > uv_w ; dest + = s - > frame . linesize[1] ; } src = s - > cur_frame - > Vbuf ; dest = s - > frame . data[2] ; for ( y = 0 ; y < s - > height / 4 ; y + + ) { memcpy ( dest , src , s - > cur_frame - > uv_w ) ; src + = s - > cur_frame - > uv_w ; dest + = s - > frame . linesize[2] ; } } * data_size=sizeof ( AVFrame ) ; * ( AVFrame * ) data= s - > frame ; return buf_size ; }",0
"void ff_h261_loop_filter ( MpegEncContext * s ) { H261Context * h= ( H261Context * ) s ; const int linesize = s - > linesize ; const int uvlinesize= s - > uvlinesize ; uint8_t * dest_y = s - > dest[0] ; uint8_t * dest_cb= s - > dest[1] ; uint8_t * dest_cr= s - > dest[2] ; if ( ! ( IS_FIL ( h - > mtype ) ) ) return ; s - > dsp . h261_loop_filter ( dest_y , linesize ) ; s - > dsp . h261_loop_filter ( dest_y + 8 , linesize ) ; s - > dsp . h261_loop_filter ( dest_y + 8 * linesize , linesize ) ; s - > dsp . h261_loop_filter ( dest_y + 8 * linesize + 8 , linesize ) ; s - > dsp . h261_loop_filter ( dest_cb , uvlinesize ) ; s - > dsp . h261_loop_filter ( dest_cr , uvlinesize ) ; }",0
"int udp_set_remote_url ( URLContext * h , const char * uri ) { UDPContext * s = h - > priv_data ; char hostname[256] ; int port ; url_split ( NULL , 0 , hostname , sizeof ( hostname ) , & port , NULL , 0 , uri ) ; / * set the destination address * / if ( resolve_host ( & s - > dest_addr . sin_addr , hostname ) < 0 ) return AVERROR_IO ; s - > dest_addr . sin_family = AF_INET ; s - > dest_addr . sin_port = htons ( port ) ; return 0 ; }",0
"static int parse_tonal ( DCALbrDecoder * s , int group ) { unsigned int amp[DCA_LBR_CHANNELS_TOTAL] ; unsigned int phs[DCA_LBR_CHANNELS_TOTAL] ; unsigned int diff , main_amp , shift ; int sf , sf_idx , ch , main_ch , freq ; int ch_nbits = av_ceil_log2 ( s - > nchannels_total ) ; // Parse subframes for this group for ( sf = 0 ; sf < 1 < < group ; sf + = diff ? 8 : 1 ) { sf_idx = ( ( s - > framenum < < group ) + sf ) & 31 ; s - > tonal_bounds[group][sf_idx][0] = s - > ntones ; // Parse tones for this subframe for ( freq = 1 ; ; freq + + ) { if ( get_bits_left ( & s - > gb ) < 1 ) { av_log ( s - > avctx , AV_LOG_ERROR , Tonal group chunk too short\n ) ; return - 1 ; } diff = parse_vlc ( & s - > gb , & ff_dca_vlc_tnl_grp[group] , 2 ) ; if ( diff > = FF_ARRAY_ELEMS ( ff_dca_fst_amp ) ) { av_log ( s - > avctx , AV_LOG_ERROR , Invalid tonal frequency diff\n ) ; return - 1 ; } diff = get_bitsz ( & s - > gb , diff > > 2 ) + ff_dca_fst_amp[diff] ; if ( diff < = 1 ) break ; // End of subframe freq + = diff - 2 ; if ( freq > > ( 5 - group ) > s - > nsubbands * 4 - 5 ) { av_log ( s - > avctx , AV_LOG_ERROR , Invalid spectral line offset\n ) ; return - 1 ; } // Main channel main_ch = get_bitsz ( & s - > gb , ch_nbits ) ; main_amp = parse_vlc ( & s - > gb , & ff_dca_vlc_tnl_scf , 2 ) + s - > tonal_scf[ff_dca_freq_to_sb[freq > > ( 7 - group ) ]] + s - > limited_range - 2 ; amp[main_ch] = main_amp < AMP_MAX ? main_amp : 0 ; phs[main_ch] = get_bits ( & s - > gb , 3 ) ; // Secondary channels for ( ch = 0 ; ch < s - > nchannels_total ; ch + + ) { if ( ch == main_ch ) continue ; if ( get_bits1 ( & s - > gb ) ) { amp[ch] = amp[main_ch] - parse_vlc ( & s - > gb , & ff_dca_vlc_damp , 1 ) ; phs[ch] = phs[main_ch] - parse_vlc ( & s - > gb , & ff_dca_vlc_dph , 1 ) ; } else { amp[ch] = 0 ; phs[ch] = 0 ; } } if ( amp[main_ch] ) { // Allocate new tone DCALbrTone * t = & s - > tones[s - > ntones] ; s - > ntones = ( s - > ntones + 1 ) & ( DCA_LBR_TONES - 1 ) ; t - > x_freq = freq > > ( 5 - group ) ; t - > f_delt = ( freq & ( ( 1 < < ( 5 - group ) ) - 1 ) ) < < group ; t - > ph_rot = 256 - ( t - > x_freq & 1 ) * 128 - t - > f_delt * 4 ; shift = ff_dca_ph0_shift[ ( t - > x_freq & 3 ) * 2 + ( freq & 1 ) ] - ( ( t - > ph_rot < < ( 5 - group ) ) - t - > ph_rot ) ; for ( ch = 0 ; ch < s - > nchannels ; ch + + ) { t - > amp[ch] = amp[ch] < AMP_MAX ? amp[ch] : 0 ; t - > phs[ch] = 128 - phs[ch] * 32 + shift ; } } } s - > tonal_bounds[group][sf_idx][1] = s - > ntones ; } return 0 ; }",1
"static int make_cdt16_entry ( int p1 , int p2 , int16_t * cdt ) { int r , b , lo ; b = cdt[p2] ; r = cdt[p1] < < 11 ; lo = b + r ; return ( lo + ( lo < < 16 ) ) < < 1 ; }",1
"void ff_estimate_p_frame_motion ( MpegEncContext * s , int mb_x , int mb_y ) { MotionEstContext * const c= & s - > me ; uint8_t * pix , * ppix ; int sum , mx , my , dmin ; int varc ; /// < the variance of the block ( sum of squared ( p[y][x] - average ) ) int vard ; /// < sum of squared differences with the estimated motion vector int P[10][2] ; const int shift= 1 + s - > quarter_sample ; int mb_type=0 ; Picture * const pic= & s - > current_picture ; init_ref ( c , s - > new_picture . f . data , s - > last_picture . f . data , NULL , 16 * mb_x , 16 * mb_y , 0 ) ; assert ( s - > quarter_sample==0 || s - > quarter_sample==1 ) ; assert ( s - > linesize == c - > stride ) ; assert ( s - > uvlinesize == c - > uvstride ) ; c - > penalty_factor = get_penalty_factor ( s - > lambda , s - > lambda2 , c - > avctx - > me_cmp ) ; c - > sub_penalty_factor= get_penalty_factor ( s - > lambda , s - > lambda2 , c - > avctx - > me_sub_cmp ) ; c - > mb_penalty_factor = get_penalty_factor ( s - > lambda , s - > lambda2 , c - > avctx - > mb_cmp ) ; c - > current_mv_penalty= c - > mv_penalty[s - > f_code] + MAX_MV ; get_limits ( s , 16 * mb_x , 16 * mb_y ) ; c - > skip=0 ; / * intra / predictive decision * / pix = c - > src[0][0] ; sum = s - > dsp . pix_sum ( pix , s - > linesize ) ; varc = s - > dsp . pix_norm1 ( pix , s - > linesize ) - ( ( ( unsigned ) ( sum * sum ) ) > > 8 ) + 500 ; pic - > mb_mean[s - > mb_stride * mb_y + mb_x] = ( sum + 128 ) > > 8 ; pic - > mb_var [s - > mb_stride * mb_y + mb_x] = ( varc + 128 ) > > 8 ; c - > mb_var_sum_temp + = ( varc + 128 ) > > 8 ; if ( c - > avctx - > me_threshold ) { vard= check_input_motion ( s , mb_x , mb_y , 1 ) ; if ( ( vard + 128 ) > > 8 < c - > avctx - > me_threshold ) { int p_score= FFMIN ( vard , varc - 500 + ( s - > lambda2 > > FF_LAMBDA_SHIFT ) * 100 ) ; int i_score= varc - 500 + ( s - > lambda2 > > FF_LAMBDA_SHIFT ) * 20 ; pic - > mc_mb_var[s - > mb_stride * mb_y + mb_x] = ( vard + 128 ) > > 8 ; c - > mc_mb_var_sum_temp + = ( vard + 128 ) > > 8 ; c - > scene_change_score + = ff_sqrt ( p_score ) - ff_sqrt ( i_score ) ; return ; } if ( ( vard + 128 ) > > 8 < c - > avctx - > mb_threshold ) mb_type= s - > mb_type[mb_x + mb_y * s - > mb_stride] ; } switch ( s - > me_method ) { case ME_ZERO : default : no_motion_search ( s , & mx , & my ) ; mx - = mb_x * 16 ; my - = mb_y * 16 ; dmin = 0 ; break ; case ME_X1 : case ME_EPZS : { const int mot_stride = s - > b8_stride ; const int mot_xy = s - > block_index[0] ; P_LEFT[0] = s - > current_picture . f . motion_val[0][mot_xy - 1][0] ; P_LEFT[1] = s - > current_picture . f . motion_val[0][mot_xy - 1][1] ; if ( P_LEFT[0] > ( c - > xmax < < shift ) ) P_LEFT[0] = ( c - > xmax < < shift ) ; if ( ! s - > first_slice_line ) { P_TOP[0] = s - > current_picture . f . motion_val[0][mot_xy - mot_stride ][0] ; P_TOP[1] = s - > current_picture . f . motion_val[0][mot_xy - mot_stride ][1] ; P_TOPRIGHT[0] = s - > current_picture . f . motion_val[0][mot_xy - mot_stride + 2][0] ; P_TOPRIGHT[1] = s - > current_picture . f . motion_val[0][mot_xy - mot_stride + 2][1] ; if ( P_TOP[1] > ( c - > ymax < < shift ) ) P_TOP[1] = ( c - > ymax < < shift ) ; if ( P_TOPRIGHT[0] < ( c - > xmin < < shift ) ) P_TOPRIGHT[0]= ( c - > xmin < < shift ) ; if ( P_TOPRIGHT[1] > ( c - > ymax < < shift ) ) P_TOPRIGHT[1]= ( c - > ymax < < shift ) ; P_MEDIAN[0]= mid_pred ( P_LEFT[0] , P_TOP[0] , P_TOPRIGHT[0] ) ; P_MEDIAN[1]= mid_pred ( P_LEFT[1] , P_TOP[1] , P_TOPRIGHT[1] ) ; if ( s - > out_format == FMT_H263 ) { c - > pred_x = P_MEDIAN[0] ; c - > pred_y = P_MEDIAN[1] ; } else { / * mpeg1 at least * / c - > pred_x= P_LEFT[0] ; c - > pred_y= P_LEFT[1] ; } } else { c - > pred_x= P_LEFT[0] ; c - > pred_y= P_LEFT[1] ; } } dmin = ff_epzs_motion_search ( s , & mx , & my , P , 0 , 0 , s - > p_mv_table , ( 1 < < 16 ) > > shift , 0 , 16 ) ; break ; } / * At this point ( mx , my ) are full - pell and the relative displacement * / ppix = c - > ref[0][0] + ( my * s - > linesize ) + mx ; vard = s - > dsp . sse[0] ( NULL , pix , ppix , s - > linesize , 16 ) ; pic - > mc_mb_var[s - > mb_stride * mb_y + mb_x] = ( vard + 128 ) > > 8 ; // pic - > mb_cmp_score[s - > mb_stride * mb_y + mb_x] = dmin ; c - > mc_mb_var_sum_temp + = ( vard + 128 ) > > 8 ; if ( mb_type ) { int p_score= FFMIN ( vard , varc - 500 + ( s - > lambda2 > > FF_LAMBDA_SHIFT ) * 100 ) ; int i_score= varc - 500 + ( s - > lambda2 > > FF_LAMBDA_SHIFT ) * 20 ; c - > scene_change_score + = ff_sqrt ( p_score ) - ff_sqrt ( i_score ) ; if ( mb_type == CANDIDATE_MB_TYPE_INTER ) { c - > sub_motion_search ( s , & mx , & my , dmin , 0 , 0 , 0 , 16 ) ; set_p_mv_tables ( s , mx , my , 1 ) ; } else { mx < < =shift ; my < < =shift ; } if",1
"static void filter_mb_mbaff_edgecv ( H264Context * h , uint8_t * pix , int stride , int16_t bS[8] , int qp[2] ) { int i ; for ( i = 0 ; i < 8 ; i + + , pix + = stride ) { int index_a ; int alpha ; int beta ; int qp_index ; int bS_index = i ; if ( bS[bS_index] == 0 ) { continue ; } qp_index = MB_FIELD ? ( i > > 2 ) : ( i & 1 ) ; index_a = qp[qp_index] + h - > slice_alpha_c0_offset ; alpha = ( alpha_table + 52 ) [index_a] ; beta = ( beta_table + 52 ) [qp[qp_index] + h - > slice_beta_offset] ; if ( bS[bS_index] < 4 ) { const int tc = ( tc0_table + 52 ) [index_a][bS[bS_index]] + 1 ; const int p0 = pix[ - 1] ; const int p1 = pix[ - 2] ; const int q0 = pix[0] ; const int q1 = pix[1] ; if ( FFABS ( p0 - q0 ) < alpha & & FFABS ( p1 - p0 ) < beta & & FFABS ( q1 - q0 ) < beta ) { const int i_delta = av_clip ( ( ( ( q0 - p0 ) < < 2 ) + ( p1 - q1 ) + 4 ) > > 3 , - tc , tc ) ; pix[ - 1] = av_clip_uint8 ( p0 + i_delta ) ; / * p0 ' * / pix[0] = av_clip_uint8 ( q0 - i_delta ) ; / * q0 ' * / tprintf ( h - > s . avctx , filter_mb_mbaff_edgecv i : %d , qp : %d , indexA : %d , alpha : %d , beta : %d , tc : %d\n bS : %d - > [%02x , %02x , %02x , %02x , %02x , %02x] = > [%02x , %02x , %02x , %02x]\n , i , qp[qp_index] , index_a , alpha , beta , tc , bS[bS_index] , pix[ - 3] , p1 , p0 , q0 , q1 , pix[2] , p1 , pix[ - 1] , pix[0] , q1 ) ; } } else { const int p0 = pix[ - 1] ; const int p1 = pix[ - 2] ; const int q0 = pix[0] ; const int q1 = pix[1] ; if ( FFABS ( p0 - q0 ) < alpha & & FFABS ( p1 - p0 ) < beta & & FFABS ( q1 - q0 ) < beta ) { pix[ - 1] = ( 2 * p1 + p0 + q1 + 2 ) > > 2 ; / * p0 ' * / pix[0] = ( 2 * q1 + q0 + p1 + 2 ) > > 2 ; / * q0 ' * / tprintf ( h - > s . avctx , filter_mb_mbaff_edgecv i : %d\n bS : 4 - > [%02x , %02x , %02x , %02x , %02x , %02x] = > [%02x , %02x , %02x , %02x , %02x , %02x]\n , i , pix[ - 3] , p1 , p0 , q0 , q1 , pix[2] , pix[ - 3] , pix[ - 2] , pix[ - 1] , pix[0] , pix[1] , pix[2] ) ; } } } }",0
"int ff_dxva2_commit_buffer ( AVCodecContext * avctx , AVDXVAContext * ctx , DECODER_BUFFER_DESC * dsc , unsigned type , const void * data , unsigned size , unsigned mb_count ) { void * dxva_data ; unsigned dxva_size ; int result ; HRESULT hr ; if CONFIG_D3D11VA if ( avctx - > pix_fmt == AV_PIX_FMT_D3D11VA_VLD ) hr = ID3D11VideoContext_GetDecoderBuffer ( D3D11VA_CONTEXT ( ctx ) - > video_context , D3D11VA_CONTEXT ( ctx ) - > decoder , type , & dxva_size , & dxva_data ) ; endif if CONFIG_DXVA2 if ( avctx - > pix_fmt == AV_PIX_FMT_DXVA2_VLD ) hr = IDirectXVideoDecoder_GetBuffer ( DXVA2_CONTEXT ( ctx ) - > decoder , type , & dxva_data , & dxva_size ) ; endif if ( FAILED ( hr ) ) { av_log ( avctx , AV_LOG_ERROR , Failed to get a buffer for %u : 0x%x\n , type , hr ) ; return - 1 ; } if ( size < = dxva_size ) { memcpy ( dxva_data , data , size ) ; if CONFIG_D3D11VA if ( avctx - > pix_fmt == AV_PIX_FMT_D3D11VA_VLD ) { D3D11_VIDEO_DECODER_BUFFER_DESC * dsc11 = dsc ; memset ( dsc11 , 0 , sizeof ( * dsc11 ) ) ; dsc11 - > BufferType = type ; dsc11 - > DataSize = size ; dsc11 - > NumMBsInBuffer = mb_count ; } endif if CONFIG_DXVA2 if ( avctx - > pix_fmt == AV_PIX_FMT_DXVA2_VLD ) { DXVA2_DecodeBufferDesc * dsc2 = dsc ; memset ( dsc2 , 0 , sizeof ( * dsc2 ) ) ; dsc2 - > CompressedBufferType = type ; dsc2 - > DataSize = size ; dsc2 - > NumMBsInBuffer = mb_count ; } endif result = 0 ; } else { av_log ( avctx , AV_LOG_ERROR , Buffer for type %u was too small\n , type ) ; result = - 1 ; } if CONFIG_D3D11VA if ( avctx - > pix_fmt == AV_PIX_FMT_D3D11VA_VLD ) hr = ID3D11VideoContext_ReleaseDecoderBuffer ( D3D11VA_CONTEXT ( ctx ) - > video_context , D3D11VA_CONTEXT ( ctx ) - > decoder , type ) ; endif if CONFIG_DXVA2 if ( avctx - > pix_fmt == AV_PIX_FMT_DXVA2_VLD ) hr = IDirectXVideoDecoder_ReleaseBuffer ( DXVA2_CONTEXT ( ctx ) - > decoder , type ) ; endif if ( FAILED ( hr ) ) { av_log ( avctx , AV_LOG_ERROR , Failed to release buffer type %u : 0x%x\n , type , hr ) ; result = - 1 ; } return result ; }",0
"int av_seek_frame ( AVFormatContext * s , int stream_index , int64_t timestamp , int flags ) { int ret ; AVStream * st ; ff_read_frame_flush ( s ) ; if ( flags & AVSEEK_FLAG_BYTE ) return seek_frame_byte ( s , stream_index , timestamp , flags ) ; if ( stream_index < 0 ) { stream_index= av_find_default_stream_index ( s ) ; if ( stream_index < 0 ) return - 1 ; st= s - > streams[stream_index] ; / * timestamp for default must be expressed in AV_TIME_BASE units * / timestamp = av_rescale ( timestamp , st - > time_base . den , AV_TIME_BASE * ( int64_t ) st - > time_base . num ) ; } / * first , we try the format specific seek * / if ( s - > iformat - > read_seek ) ret = s - > iformat - > read_seek ( s , stream_index , timestamp , flags ) ; else ret = - 1 ; if ( ret > = 0 ) { return 0 ; } if ( s - > iformat - > read_timestamp & & ! ( s - > iformat - > flags & AVFMT_NOBINSEARCH ) ) return av_seek_frame_binary ( s , stream_index , timestamp , flags ) ; else if ( ! ( s - > iformat - > flags & AVFMT_NOGENSEARCH ) ) return seek_frame_generic ( s , stream_index , timestamp , flags ) ; else return - 1 ; }",0
"static const char * srt_to_ass ( AVCodecContext * avctx , char * out , char * out_end , const char * in , int x1 , int y1 , int x2 , int y2 ) { char c , * param , buffer[128] , tmp[128] ; int len , tag_close , sptr = 1 , line_start = 1 , an = 0 , end = 0 ; SrtStack stack[16] ; stack[0] . tag[0] = 0 ; strcpy ( stack[0] . param[PARAM_SIZE] , { \\fs } ) ; strcpy ( stack[0] . param[PARAM_COLOR] , { \\c } ) ; strcpy ( stack[0] . param[PARAM_FACE] , { \\fn } ) ; if ( x1 > = 0 & & y1 > = 0 ) { if ( x2 > = 0 & & y2 > = 0 & & ( x2 ! = x1 || y2 ! = y1 ) ) out + = snprintf ( out , out_end - out , { \\an1 } { \\move ( %d , %d , %d , %d ) } , x1 , y1 , x2 , y2 ) ; else out + = snprintf ( out , out_end - out , { \\an1 } { \\pos ( %d , %d ) } , x1 , y1 ) ; } for ( ; out < out_end & & ! end & & * in ; in + + ) { switch ( * in ) { case ' \r ' : break ; case ' \n ' : if ( line_start ) { end = 1 ; break ; } while ( out[ - 1] == ' ' ) out - - ; out + = snprintf ( out , out_end - out , \\N ) ; line_start = 1 ; break ; case ' ' : if ( ! line_start ) * out + + = * in ; break ; case ' { ' : / * skip all { \xxx } substrings except for { \an%d } and all microdvd like styles such as { Y : xxx } * / an + = sscanf ( in , { \\an% * 1u } %c , & c ) == 1 ; if ( ( an ! = 1 & & sscanf ( in , { \\% * [ } ] } %n%c , & len , & c ) > 0 ) || sscanf ( in , { % * 1[CcFfoPSsYy] : % * [ } ] } %n%c , & len , & c ) > 0 ) { in + = len - 1 ; } else * out + + = * in ; break ; case ' < ' : tag_close = in[1] == ' / ' ; if ( sscanf ( in + tag_close + 1 , %127[ > ] > %n%c , buffer , & len , & c ) > = 2 ) { if ( ( param = strchr ( buffer , ' ' ) ) ) * param + + = 0 ; if ( ( ! tag_close & & sptr < FF_ARRAY_ELEMS ( stack ) ) || ( tag_close & & sptr > 0 & & ! strcmp ( stack[sptr - 1] . tag , buffer ) ) ) { int i , j , unknown = 0 ; in + = len + tag_close ; if ( ! tag_close ) memset ( stack + sptr , 0 , sizeof ( * stack ) ) ; if ( ! strcmp ( buffer , font ) ) { if ( tag_close ) { for ( i=PARAM_NUMBER - 1 ; i > =0 ; i - - ) if ( stack[sptr - 1] . param[i][0] ) for ( j=sptr - 2 ; j > =0 ; j - - ) if ( stack[j] . param[i][0] ) { out + = snprintf ( out , out_end - out , %s , stack[j] . param[i] ) ; break ; } } else { while ( param ) { if ( ! strncmp ( param , size= , 5 ) ) { unsigned font_size ; param + = 5 + ( param[5] == ' ' ) ; if ( sscanf ( param , %u , & font_size ) == 1 ) { snprintf ( stack[sptr] . param[PARAM_SIZE] , sizeof ( stack[0] . param[PARAM_SIZE] ) , { \\fs%u } , font_size ) ; } } else if ( ! strncmp ( param , color= , 6 ) ) { param + = 6 + ( param[6] == ' ' ) ; snprintf ( stack[sptr] . param[PARAM_COLOR] , sizeof ( stack[0] . param[PARAM_COLOR] ) , { \\c & H%X & } , html_color_parse ( avctx , param ) ) ; } else if ( ! strncmp ( param , face= , 5 ) ) { param + = 5 + ( param[5] == ' ' ) ; len = strcspn ( param , param[ - 1] == ' ' ? \ : ) ; av_strlcpy ( tmp , param , FFMIN ( sizeof ( tmp ) , len + 1 ) ) ; param + = len ; snprintf ( stack[sptr] . param[PARAM_FACE] , sizeof ( stack[0] . param[PARAM_FACE] ) , { \\fn%s } , tmp ) ; } if ( ( param = strchr ( param , ' ' ) ) ) param + + ; } for ( i=0 ; i < PARAM_NUMBER ; i + + ) if ( stack[sptr] . param[i][0] ) out + = snprintf ( out , out_end - out , %s , stack[sptr] . param[i] ) ; } } else if ( ! buffer[1] & & strspn ( buffer , bisu ) == 1 ) { out + = snprintf ( out , out_end - out , { \\%c%d } , buffer[0] , ! tag_close ) ; } else { unknown = 1 ; snprintf ( tmp , sizeof ( tmp ) , < /%s > , buffer ) ; } if ( tag_close ) { sptr - - ; } else if ( unknown & & ! strstr ( in , tmp ) ) { in - = len + tag_close ; * out + + = * in ; } else av_strlcpy ( stack[sptr + + ] . tag , buffer , sizeof ( stack[0] . tag ) ) ; break ; } } default : * out + + = * in ; break ; } if ( * in ! = ' ' & & * in ! = ' \r ' & & * in ! = ' \n ' ) line_start = 0 ; } out = FFMIN ( out , out_end - 3 ) ; while ( ! strncmp ( out - 2 , \\N , 2 ) ) out - = 2 ; while ( out[ - 1] == ' ' ) out - - ; out + = snprintf ( out , out_end - out , \r\n ) ; return in ; }",0
"AVResampleContext * av_resample_init ( int out_rate , int in_rate , int filter_size , int phase_shift , int linear , double cutoff ) { AVResampleContext * c= av_mallocz ( sizeof ( AVResampleContext ) ) ; double factor= FFMIN ( out_rate * cutoff / in_rate , 1 . 0 ) ; int phase_count= 1 < < phase_shift ; c - > phase_shift= phase_shift ; c - > phase_mask= phase_count - 1 ; c - > linear= linear ; c - > filter_length= FFMAX ( ceil ( filter_size/factor ) , 1 ) ; c - > filter_bank= av_mallocz ( c - > filter_length * ( phase_count + 1 ) * sizeof ( FELEM ) ) ; av_build_filter ( c - > filter_bank , factor , c - > filter_length , phase_count , 1 < < FILTER_SHIFT , 1 ) ; memcpy ( & c - > filter_bank[c - > filter_length * phase_count + 1] , c - > filter_bank , ( c - > filter_length - 1 ) * sizeof ( FELEM ) ) ; c - > filter_bank[c - > filter_length * phase_count]= c - > filter_bank[c - > filter_length - 1] ; c - > src_incr= out_rate ; c - > ideal_dst_incr= c - > dst_incr= in_rate * phase_count ; c - > index= - phase_count * ( ( c - > filter_length - 1 ) /2 ) ; return c ; }",0
"static int mov_read_elst ( MOVContext * c , ByteIOContext * pb , MOVAtom atom ) { MOVStreamContext * sc = c - > fc - > streams[c - > fc - > nb_streams - 1] - > priv_data ; int i , edit_count ; get_byte ( pb ) ; / * version * / get_be24 ( pb ) ; / * flags * / edit_count= sc - > edit_count = get_be32 ( pb ) ; / * entries * / for ( i=0 ; i < edit_count ; i + + ) { int time ; get_be32 ( pb ) ; / * Track duration * / time = get_be32 ( pb ) ; / * Media time * / get_be32 ( pb ) ; / * Media rate * / if ( time ! = 0 ) av_log ( c - > fc , AV_LOG_WARNING , edit list not starting at 0 , a/v desync might occur , patch welcome\n ) ; } dprintf ( c - > fc , track[%i] . edit_count = %i\n , c - > fc - > nb_streams - 1 , sc - > edit_count ) ; return 0 ; }",0
"int av_metadata_set ( AVMetadata * * pm , const char * key , const char * value ) { AVMetadata * m= * pm ; AVMetadataTag * tag= av_metadata_get ( m , key , NULL , AV_METADATA_MATCH_CASE ) ; if ( ! m ) m= * pm= av_mallocz ( sizeof ( * m ) ) ; if ( tag ) { av_free ( tag - > value ) ; av_free ( tag - > key ) ; * tag= m - > elems[ - - m - > count] ; } else { AVMetadataTag * tmp= av_realloc ( m - > elems , ( m - > count + 1 ) * sizeof ( * m - > elems ) ) ; if ( tmp ) { m - > elems= tmp ; } else return AVERROR ( ENOMEM ) ; } if ( value ) { m - > elems[m - > count] . key = av_strdup ( key ) ; m - > elems[m - > count] . value= av_strdup ( value ) ; m - > count + + ; } if ( ! m - > count ) { av_free ( m - > elems ) ; av_freep ( pm ) ; } return 0 ; }",0
"static int mov_read_ares ( MOVContext * c , AVIOContext * pb , MOVAtom atom ) { AVCodecContext * codec = c - > fc - > streams[c - > fc - > nb_streams - 1] - > codec ; if ( codec - > codec_tag == MKTAG ( ' A ' , ' V ' , ' i ' , ' n ' ) & & codec - > codec_id == AV_CODEC_ID_H264 & & atom . size > 11 ) { avio_skip ( pb , 10 ) ; / * For AVID AVCI50 , force width of 1440 to be able to select the correct SPS and PPS * / if ( avio_rb16 ( pb ) == 0xd4d ) codec - > width = 1440 ; return 0 ; } return mov_read_avid ( c , pb , atom ) ; }",0
"static int decode_vop_header ( MpegEncContext * s , GetBitContext * gb ) { int time_incr , time_increment ; s - > pict_type = get_bits ( gb , 2 ) + I_TYPE ; / * pict type : I = 0 , P = 1 * / if ( s - > pict_type==B_TYPE & & s - > low_delay & & s - > vol_control_parameters==0 & & ! ( s - > flags & CODEC_FLAG_LOW_DELAY ) ) { av_log ( s - > avctx , AV_LOG_ERROR , low_delay flag set , but shouldnt , clearing it\n ) ; s - > low_delay=0 ; } s - > partitioned_frame= s - > data_partitioning & & s - > pict_type ! =B_TYPE ; if ( s - > partitioned_frame ) s - > decode_mb= mpeg4_decode_partitioned_mb ; else s - > decode_mb= ff_h263_decode_mb ; if ( s - > time_increment_resolution==0 ) { s - > time_increment_resolution=1 ; // fprintf ( stderr , time_increment_resolution is illegal\n ) ; } time_incr=0 ; while ( get_bits1 ( gb ) ! = 0 ) time_incr + + ; check_marker ( gb , before time_increment ) ; if ( s - > time_increment_bits==0 ) { av_log ( s - > avctx , AV_LOG_ERROR , hmm , seems the headers arnt complete , trying to guess time_increment_bits\n ) ; for ( s - > time_increment_bits=1 ; s - > time_increment_bits < 16 ; s - > time_increment_bits + + ) { if ( show_bits ( gb , s - > time_increment_bits + 1 ) & 1 ) break ; } av_log ( s - > avctx , AV_LOG_ERROR , my guess is %d bits ; ) \n , s - > time_increment_bits ) ; } if ( IS_3IV1 ) time_increment= get_bits1 ( gb ) ; //FIXME investigate further else time_increment= get_bits ( gb , s - > time_increment_bits ) ; // printf ( %d %X\n , s - > time_increment_bits , time_increment ) ; //printf ( type : %d modulo_time_base : %d increment : %d\n , s - > pict_type , time_incr , time_increment ) ; if ( s - > pict_type ! =B_TYPE ) { s - > last_time_base= s - > time_base ; s - > time_base + = time_incr ; s - > time= s - > time_base * s - > time_increment_resolution + time_increment ; if ( s - > workaround_bugs & FF_BUG_UMP4 ) { if ( s - > time < s - > last_non_b_time ) { // fprintf ( stderr , header is not mpeg4 compatible , broken encoder , trying to workaround\n ) ; s - > time_base + + ; s - > time + = s - > time_increment_resolution ; } } s - > pp_time= s - > time - s - > last_non_b_time ; s - > last_non_b_time= s - > time ; } else { s - > time= ( s - > last_time_base + time_incr ) * s - > time_increment_resolution + time_increment ; s - > pb_time= s - > pp_time - ( s - > last_non_b_time - s - > time ) ; if ( s - > pp_time < =s - > pb_time || s - > pp_time < = s - > pp_time - s - > pb_time || s - > pp_time < =0 ) { // printf ( messed up order , seeking ? , skiping current b frame\n ) ; return FRAME_SKIPED ; } if ( s - > t_frame==0 ) s - > t_frame= s - > time - s - > last_time_base ; if ( s - > t_frame==0 ) s - > t_frame=1 ; // 1/0 protection //printf ( %Ld %Ld %d %d\n , s - > last_non_b_time , s - > time , s - > pp_time , s - > t_frame ) ; fflush ( stdout ) ; s - > pp_field_time= ( ROUNDED_DIV ( s - > last_non_b_time , s - > t_frame ) - ROUNDED_DIV ( s - > last_non_b_time - s - > pp_time , s - > t_frame ) ) * 2 ; s - > pb_field_time= ( ROUNDED_DIV ( s - > time , s - > t_frame ) - ROUNDED_DIV ( s - > last_non_b_time - s - > pp_time , s - > t_frame ) ) * 2 ; } s - > current_picture_ptr - > pts= s - > time * 1000LL * 1000LL / s - > time_increment_resolution ; if ( s - > avctx - > debug & FF_DEBUG_PTS ) av_log ( s - > avctx , AV_LOG_DEBUG , MPEG4 PTS : %f\n , s - > current_picture_ptr - > pts/ ( 1000 . 0 * 1000 . 0 ) ) ; check_marker ( gb , before vop_coded ) ; / * vop coded * / if ( get_bits1 ( gb ) ! = 1 ) { av_log ( s - > avctx , AV_LOG_ERROR , vop not coded\n ) ; return FRAME_SKIPED ; } //printf ( time %d %d %d || %Ld %Ld %Ld\n , s - > time_increment_bits , s - > time_increment_resolution , s - > time_base , //s - > time , s - > last_non_b_time , s - > last_non_b_time - s - > pp_time ) ; if ( s - > shape ! = BIN_ONLY_SHAPE & & ( s - > pict_type == P_TYPE || ( s - > pict_type == S_TYPE & & s - > vol_sprite_usage==GMC_SPRITE ) ) ) { / * rounding type for motion estimation * / s - > no_rounding = get_bits1 ( gb ) ; } else { s - > no_rounding = 0 ; } //FIXME reduced res stuff if ( s - > shape ! = RECT_SHAPE ) { if ( s - > vol_sprite_usage ! = 1 || s - > pict_type ! = I_TYPE ) { int width , height , hor_spat_ref , ver_spat_ref ; width = get_bits ( gb , 13 ) ; skip_bits1 ( gb ) ; / * marker * / height = get_bits ( gb , 13 ) ; skip_bits1 ( gb ) ; / * marker * / hor_spat_ref = get_bits ( gb , 13 ) ; / * hor_spat_ref * / skip_bits1 ( gb ) ; / * marker * / ver_spat_ref = get_bits ( gb , 13 ) ; / * ver_spat_ref * / } skip_bits1 ( gb ) ; / * change_CR_disable * / if ( get_bits1 ( gb ) ! = 0 ) { skip_bits ( gb , 8 ) ; / * constant_alpha_value * / } } //FIXME complexity estimation stuff if ( s - > shape ! = BIN_ONLY_SHAPE ) { s - > intra_dc_threshold= mpeg4_dc_threshold[ get_bits ( gb , 3 ) ] ; if ( ! s - > progressive_sequence ) { s - > top_field_first= get_bits1 ( gb ) ; s - > alternate_scan= get_bits1 ( gb ) ; } else s - > alternate_scan= 0 ; } if ( s - > alternate_scan ) { ff_init_scantable ( s - > dsp . idct_permutation , & s - > inter_scantable , ff_alternate_vertical_scan ) ; ff_init_scantable ( s - > dsp . idct_permutation , & s -",0
"static int txd_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { GetByteContext gb ; AVFrame * const p = data ; unsigned int version , w , h , d3d_format , depth , stride , flags ; unsigned int y , v ; uint8_t * ptr ; uint32_t * pal ; int ret ; bytestream2_init ( & gb , avpkt - > data , avpkt - > size ) ; version = bytestream2_get_le32 ( & gb ) ; bytestream2_skip ( & gb , 72 ) ; d3d_format = bytestream2_get_le32 ( & gb ) ; w = bytestream2_get_le16 ( & gb ) ; h = bytestream2_get_le16 ( & gb ) ; depth = bytestream2_get_byte ( & gb ) ; bytestream2_skip ( & gb , 2 ) ; flags = bytestream2_get_byte ( & gb ) ; if ( version < 8 || version > 9 ) { av_log ( avctx , AV_LOG_ERROR , texture data version %i is unsupported\n , version ) ; return AVERROR_PATCHWELCOME ; } if ( depth == 8 ) { avctx - > pix_fmt = AV_PIX_FMT_PAL8 ; } else if ( depth == 16 || depth == 32 ) { avctx - > pix_fmt = AV_PIX_FMT_RGB32 ; } else { av_log ( avctx , AV_LOG_ERROR , depth of %i is unsupported\n , depth ) ; return AVERROR_PATCHWELCOME ; } if ( ( ret = ff_set_dimensions ( avctx , w , h ) ) < 0 ) return ret ; if ( ( ret = ff_get_buffer ( avctx , p , 0 ) ) < 0 ) return ret ; p - > pict_type = AV_PICTURE_TYPE_I ; ptr = p - > data[0] ; stride = p - > linesize[0] ; if ( depth == 8 ) { pal = ( uint32_t * ) p - > data[1] ; for ( y = 0 ; y < 256 ; y + + ) { v = bytestream2_get_be32 ( & gb ) ; pal[y] = ( v > > 8 ) + ( v < < 24 ) ; } if ( bytestream2_get_bytes_left ( & gb ) < w * h ) return AVERROR_INVALIDDATA ; bytestream2_skip ( & gb , 4 ) ; for ( y=0 ; y < h ; y + + ) { bytestream2_get_buffer ( & gb , ptr , w ) ; ptr + = stride ; } } else if ( depth == 16 ) { bytestream2_skip ( & gb , 4 ) ; switch ( d3d_format ) { case 0 : if ( ! ( flags & 1 ) ) goto unsupported ; case FF_S3TC_DXT1 : if ( bytestream2_get_bytes_left ( & gb ) < ( w/4 ) * ( h/4 ) * 8 ) return AVERROR_INVALIDDATA ; ff_decode_dxt1 ( & gb , ptr , w , h , stride ) ; break ; case FF_S3TC_DXT3 : if ( bytestream2_get_bytes_left ( & gb ) < ( w/4 ) * ( h/4 ) * 16 ) return AVERROR_INVALIDDATA ; ff_decode_dxt3 ( & gb , ptr , w , h , stride ) ; break ; default : goto unsupported ; } } else if ( depth == 32 ) { switch ( d3d_format ) { case 0x15 : case 0x16 : if ( bytestream2_get_bytes_left ( & gb ) < h * w * 4 ) return AVERROR_INVALIDDATA ; for ( y=0 ; y < h ; y + + ) { bytestream2_get_buffer ( & gb , ptr , w * 4 ) ; ptr + = stride ; } break ; default : goto unsupported ; } } * got_frame = 1 ; return avpkt - > size ; unsupported : av_log ( avctx , AV_LOG_ERROR , unsupported d3d format ( %08x ) \n , d3d_format ) ; return AVERROR_PATCHWELCOME ; }",0
"static int read_packet ( AVFormatContext * ctx , AVPacket * pkt ) { al_data * ad = ctx - > priv_data ; int error=0 ; const char * error_msg ; ALCint nb_samples ; / * Get number of samples available * / alcGetIntegerv ( ad - > device , ALC_CAPTURE_SAMPLES , ( ALCsizei ) sizeof ( ALCint ) , & nb_samples ) ; if ( error = al_get_error ( ad - > device , & error_msg ) ) goto fail ; / * Create a packet of appropriate size * / av_new_packet ( pkt , nb_samples * ad - > sample_step ) ; pkt - > pts = av_gettime ( ) ; / * Fill the packet with the available samples * / alcCaptureSamples ( ad - > device , pkt - > data , nb_samples ) ; if ( error = al_get_error ( ad - > device , & error_msg ) ) goto fail ; return pkt - > size ; fail : / * Handle failure * / if ( pkt - > data ) av_destruct_packet ( pkt ) ; if ( error_msg ) av_log ( ctx , AV_LOG_ERROR , Error : %s\n , error_msg ) ; return error ; }",0
"static int read_header ( FFV1Context * f ) { uint8_t state[CONTEXT_SIZE] ; int i , j , context_count ; RangeCoder * const c= & f - > slice_context[0] - > c ; memset ( state , 128 , sizeof ( state ) ) ; if ( f - > version < 2 ) { f - > version= get_symbol ( c , state , 0 ) ; f - > ac= f - > avctx - > coder_type= get_symbol ( c , state , 0 ) ; if ( f - > ac > 1 ) { for ( i=1 ; i < 256 ; i + + ) { f - > state_transition[i]= get_symbol ( c , state , 1 ) + c - > one_state[i] ; } } f - > colorspace= get_symbol ( c , state , 0 ) ; //YUV cs type if ( f - > version > 0 ) f - > avctx - > bits_per_raw_sample= get_symbol ( c , state , 0 ) ; f - > chroma_planes= get_rac ( c , state ) ; f - > chroma_h_shift= get_symbol ( c , state , 0 ) ; f - > chroma_v_shift= get_symbol ( c , state , 0 ) ; f - > transparency= get_rac ( c , state ) ; f - > plane_count= 2 + f - > transparency ; } if ( f - > colorspace==0 ) { if ( ! f - > transparency & & ! f - > chroma_planes ) { if ( f - > avctx - > bits_per_raw_sample < =8 ) f - > avctx - > pix_fmt= PIX_FMT_GRAY8 ; else f - > avctx - > pix_fmt= PIX_FMT_GRAY16 ; } else if ( f - > avctx - > bits_per_raw_sample < =8 & & ! f - > transparency ) { switch ( 16 * f - > chroma_h_shift + f - > chroma_v_shift ) { case 0x00 : f - > avctx - > pix_fmt= PIX_FMT_YUV444P ; break ; case 0x01 : f - > avctx - > pix_fmt= PIX_FMT_YUV440P ; break ; case 0x10 : f - > avctx - > pix_fmt= PIX_FMT_YUV422P ; break ; case 0x11 : f - > avctx - > pix_fmt= PIX_FMT_YUV420P ; break ; case 0x20 : f - > avctx - > pix_fmt= PIX_FMT_YUV411P ; break ; case 0x22 : f - > avctx - > pix_fmt= PIX_FMT_YUV410P ; break ; default : av_log ( f - > avctx , AV_LOG_ERROR , format not supported\n ) ; return - 1 ; } } else if ( f - > avctx - > bits_per_raw_sample < =8 & & f - > transparency ) { switch ( 16 * f - > chroma_h_shift + f - > chroma_v_shift ) { case 0x00 : f - > avctx - > pix_fmt= PIX_FMT_YUVA444P ; break ; case 0x11 : f - > avctx - > pix_fmt= PIX_FMT_YUVA420P ; break ; default : av_log ( f - > avctx , AV_LOG_ERROR , format not supported\n ) ; return - 1 ; } } else if ( f - > avctx - > bits_per_raw_sample==9 ) { f - > packed_at_lsb=1 ; switch ( 16 * f - > chroma_h_shift + f - > chroma_v_shift ) { case 0x00 : f - > avctx - > pix_fmt= PIX_FMT_YUV444P9 ; break ; case 0x10 : f - > avctx - > pix_fmt= PIX_FMT_YUV422P9 ; break ; case 0x11 : f - > avctx - > pix_fmt= PIX_FMT_YUV420P9 ; break ; default : av_log ( f - > avctx , AV_LOG_ERROR , format not supported\n ) ; return - 1 ; } } else if ( f - > avctx - > bits_per_raw_sample==10 ) { f - > packed_at_lsb=1 ; switch ( 16 * f - > chroma_h_shift + f - > chroma_v_shift ) { case 0x00 : f - > avctx - > pix_fmt= PIX_FMT_YUV444P10 ; break ; case 0x10 : f - > avctx - > pix_fmt= PIX_FMT_YUV422P10 ; break ; case 0x11 : f - > avctx - > pix_fmt= PIX_FMT_YUV420P10 ; break ; default : av_log ( f - > avctx , AV_LOG_ERROR , format not supported\n ) ; return - 1 ; } } else { switch ( 16 * f - > chroma_h_shift + f - > chroma_v_shift ) { case 0x00 : f - > avctx - > pix_fmt= PIX_FMT_YUV444P16 ; break ; case 0x10 : f - > avctx - > pix_fmt= PIX_FMT_YUV422P16 ; break ; case 0x11 : f - > avctx - > pix_fmt= PIX_FMT_YUV420P16 ; break ; default : av_log ( f - > avctx , AV_LOG_ERROR , format not supported\n ) ; return - 1 ; } } } else if ( f - > colorspace==1 ) { if ( f - > chroma_h_shift || f - > chroma_v_shift ) { av_log ( f - > avctx , AV_LOG_ERROR , chroma subsampling not supported in this colorspace\n ) ; return - 1 ; } if ( f - > transparency ) f - > avctx - > pix_fmt= PIX_FMT_RGB32 ; else f - > avctx - > pix_fmt= PIX_FMT_0RGB32 ; } else { av_log ( f - > avctx , AV_LOG_ERROR , colorspace not supported\n ) ; return - 1 ; } //printf ( %d %d %d\n , f - > chroma_h_shift , f - > chroma_v_shift , f - > avctx - > pix_fmt ) ; if ( f - > version < 2 ) { context_count= read_quant_tables ( c , f - > quant_table ) ; if ( context_count < 0 ) { av_log ( f - > avctx , AV_LOG_ERROR , read_quant_table error\n ) ; return - 1 ; } } else { f - > slice_count= get_symbol ( c , state , 0 ) ; if ( f - > slice_count > ( unsigned ) MAX_SLICES ) return - 1 ; } for ( j=0 ; j < f - > slice_count ; j + + ) { FFV1Context * fs= f - > slice_context[j] ; fs - > ac= f - > ac ; fs - > packed_at_lsb= f - > packed_at_lsb ; if ( f - > version > = 2 ) { fs - > slice_x = get_symbol ( c , state , 0 ) * f - > width ; fs - > slice_y = get_symbol ( c , state , 0 ) * f - > height ; fs - > slice_width = ( get_symbol ( c , state , 0 ) + 1 ) * f - > width + fs - > slice_x ; fs - > slice_height= ( get_symbol ( c , state , 0 ) + 1 ) * f - > height + fs - > slice_y ; fs - > slice_x /= f - > num_h_slices ; fs - > slice_y /= f - > num_v_slices ; fs - > slice_width = fs - > slice_width /f - > num_h_slices - fs - > slice_x ; fs - > slice_height = fs - > slice_height/f - > num_v_slices - fs - > slice_y ; if ( ( unsigned ) fs - > slice_width > f -",0
"static void avc_loopfilter_cb_or_cr_intra_edge_hor_msa ( uint8_t * data_cb_or_cr , uint8_t alpha_in , uint8_t beta_in , uint32_t img_width ) { v16u8 alpha , beta ; v16u8 is_less_than ; v8i16 p0_or_q0 , q0_or_p0 ; v16u8 p1_or_q1_org , p0_or_q0_org , q0_or_p0_org , q1_or_p1_org ; v16i8 zero = { 0 } ; v16u8 p0_asub_q0 , p1_asub_p0 , q1_asub_q0 ; v16u8 is_less_than_alpha , is_less_than_beta ; v8i16 p1_org_r , p0_org_r , q0_org_r , q1_org_r ; alpha = ( v16u8 ) __msa_fill_b ( alpha_in ) ; beta = ( v16u8 ) __msa_fill_b ( beta_in ) ; p1_or_q1_org = LOAD_UB ( data_cb_or_cr - ( img_width < < 1 ) ) ; p0_or_q0_org = LOAD_UB ( data_cb_or_cr - img_width ) ; q0_or_p0_org = LOAD_UB ( data_cb_or_cr ) ; q1_or_p1_org = LOAD_UB ( data_cb_or_cr + img_width ) ; p0_asub_q0 = __msa_asub_u_b ( p0_or_q0_org , q0_or_p0_org ) ; p1_asub_p0 = __msa_asub_u_b ( p1_or_q1_org , p0_or_q0_org ) ; q1_asub_q0 = __msa_asub_u_b ( q1_or_p1_org , q0_or_p0_org ) ; is_less_than_alpha = ( p0_asub_q0 < alpha ) ; is_less_than_beta = ( p1_asub_p0 < beta ) ; is_less_than = is_less_than_beta & is_less_than_alpha ; is_less_than_beta = ( q1_asub_q0 < beta ) ; is_less_than = is_less_than_beta & is_less_than ; is_less_than = ( v16u8 ) __msa_ilvr_d ( ( v2i64 ) zero , ( v2i64 ) is_less_than ) ; if ( ! __msa_test_bz_v ( is_less_than ) ) { p1_org_r = ( v8i16 ) __msa_ilvr_b ( zero , ( v16i8 ) p1_or_q1_org ) ; p0_org_r = ( v8i16 ) __msa_ilvr_b ( zero , ( v16i8 ) p0_or_q0_org ) ; q0_org_r = ( v8i16 ) __msa_ilvr_b ( zero , ( v16i8 ) q0_or_p0_org ) ; q1_org_r = ( v8i16 ) __msa_ilvr_b ( zero , ( v16i8 ) q1_or_p1_org ) ; AVC_LOOP_FILTER_P0_OR_Q0 ( p0_org_r , q1_org_r , p1_org_r , p0_or_q0 ) ; AVC_LOOP_FILTER_P0_OR_Q0 ( q0_org_r , p1_org_r , q1_org_r , q0_or_p0 ) ; p0_or_q0 = ( v8i16 ) __msa_pckev_b ( zero , ( v16i8 ) p0_or_q0 ) ; q0_or_p0 = ( v8i16 ) __msa_pckev_b ( zero , ( v16i8 ) q0_or_p0 ) ; p0_or_q0_org = __msa_bmnz_v ( p0_or_q0_org , ( v16u8 ) p0_or_q0 , is_less_than ) ; q0_or_p0_org = __msa_bmnz_v ( q0_or_p0_org , ( v16u8 ) q0_or_p0 , is_less_than ) ; STORE_UB ( q0_or_p0_org , data_cb_or_cr ) ; STORE_UB ( p0_or_q0_org , data_cb_or_cr - img_width ) ; } }",0
"static inline void RENAME ( uyvytoyv12 ) ( const uint8_t * src , uint8_t * ydst , uint8_t * udst , uint8_t * vdst , long width , long height , long lumStride , long chromStride , long srcStride ) { long y ; const long chromWidth= width > > 1 ; for ( y=0 ; y < height ; y + =2 ) { ifdef HAVE_MMX asm volatile ( xorl %%eax , %%eax \n\t pcmpeqw %%mm7 , %%mm7 \n\t psrlw 8 , %%mm7 \n\t // FF , 00 , FF , 00 . . . ASMALIGN ( 4 ) 1 : \n\t PREFETCH 64 ( %0 , %%eax , 4 ) \n\t movq ( %0 , %%eax , 4 ) , %%mm0 \n\t // UYVY UYVY ( 0 ) movq 8 ( %0 , %%eax , 4 ) , %%mm1 \n\t // UYVY UYVY ( 4 ) movq %%mm0 , %%mm2 \n\t // UYVY UYVY ( 0 ) movq %%mm1 , %%mm3 \n\t // UYVY UYVY ( 4 ) pand %%mm7 , %%mm0 \n\t // U0V0 U0V0 ( 0 ) pand %%mm7 , %%mm1 \n\t // U0V0 U0V0 ( 4 ) psrlw 8 , %%mm2 \n\t // Y0Y0 Y0Y0 ( 0 ) psrlw 8 , %%mm3 \n\t // Y0Y0 Y0Y0 ( 4 ) packuswb %%mm1 , %%mm0 \n\t // UVUV UVUV ( 0 ) packuswb %%mm3 , %%mm2 \n\t // YYYY YYYY ( 0 ) MOVNTQ %%mm2 , ( %1 , %%eax , 2 ) \n\t movq 16 ( %0 , %%eax , 4 ) , %%mm1 \n\t // UYVY UYVY ( 8 ) movq 24 ( %0 , %%eax , 4 ) , %%mm2 \n\t // UYVY UYVY ( 12 ) movq %%mm1 , %%mm3 \n\t // UYVY UYVY ( 8 ) movq %%mm2 , %%mm4 \n\t // UYVY UYVY ( 12 ) pand %%mm7 , %%mm1 \n\t // U0V0 U0V0 ( 8 ) pand %%mm7 , %%mm2 \n\t // U0V0 U0V0 ( 12 ) psrlw 8 , %%mm3 \n\t // Y0Y0 Y0Y0 ( 8 ) psrlw 8 , %%mm4 \n\t // Y0Y0 Y0Y0 ( 12 ) packuswb %%mm2 , %%mm1 \n\t // UVUV UVUV ( 8 ) packuswb %%mm4 , %%mm3 \n\t // YYYY YYYY ( 8 ) MOVNTQ %%mm3 , 8 ( %1 , %%eax , 2 ) \n\t movq %%mm0 , %%mm2 \n\t // UVUV UVUV ( 0 ) movq %%mm1 , %%mm3 \n\t // UVUV UVUV ( 8 ) psrlw 8 , %%mm0 \n\t // V0V0 V0V0 ( 0 ) psrlw 8 , %%mm1 \n\t // V0V0 V0V0 ( 8 ) pand %%mm7 , %%mm2 \n\t // U0U0 U0U0 ( 0 ) pand %%mm7 , %%mm3 \n\t // U0U0 U0U0 ( 8 ) packuswb %%mm1 , %%mm0 \n\t // VVVV VVVV ( 0 ) packuswb %%mm3 , %%mm2 \n\t // UUUU UUUU ( 0 ) MOVNTQ %%mm0 , ( %3 , %%eax ) \n\t MOVNTQ %%mm2 , ( %2 , %%eax ) \n\t addl 8 , %%eax \n\t cmpl %4 , %%eax \n\t jb 1b \n\t : : r ( src ) , r ( ydst ) , r ( udst ) , r ( vdst ) , g ( chromWidth ) : memory , %eax ) ; ydst + = lumStride ; src + = srcStride ; asm volatile ( xorl %%eax , %%eax \n\t ASMALIGN ( 4 ) 1 : \n\t PREFETCH 64 ( %0 , %%eax , 4 ) \n\t movq ( %0 , %%eax , 4 ) , %%mm0 \n\t // YUYV YUYV ( 0 ) movq 8 ( %0 , %%eax , 4 ) , %%mm1 \n\t // YUYV YUYV ( 4 ) movq 16 ( %0 , %%eax , 4 ) , %%mm2 \n\t // YUYV YUYV ( 8 ) movq 24 ( %0 , %%eax , 4 ) , %%mm3 \n\t // YUYV YUYV ( 12 ) psrlw 8 , %%mm0 \n\t // Y0Y0 Y0Y0 ( 0 ) psrlw 8 , %%mm1 \n\t // Y0Y0 Y0Y0 ( 4 ) psrlw 8 , %%mm2 \n\t // Y0Y0 Y0Y0 ( 8 ) psrlw 8 , %%mm3 \n\t // Y0Y0 Y0Y0 ( 12 ) packuswb %%mm1 , %%mm0 \n\t // YYYY YYYY ( 0 ) packuswb %%mm3 , %%mm2 \n\t // YYYY YYYY ( 8 ) MOVNTQ %%mm0 , ( %1 , %%eax , 2 ) \n\t MOVNTQ %%mm2 , 8 ( %1 , %%eax , 2 ) \n\t addl 8 , %%eax \n\t cmpl %4 , %%eax \n\t jb 1b \n\t : : r ( src ) , r ( ydst ) , r ( udst ) , r ( vdst ) , g ( chromWidth ) : memory , %eax ) ; else long i ; for ( i=0 ; i < chromWidth ; i + + ) { udst[i] = src[4 * i + 0] ; ydst[2 * i + 0] = src[4 * i + 1] ; vdst[i] = src[4 * i + 2] ; ydst[2 * i + 1] = src[4 * i + 3] ; } ydst + = lumStride ; src + = srcStride ; for ( i=0 ; i < chromWidth ; i + + ) { ydst[2 * i + 0] = src[4 * i + 1] ; ydst[2 * i + 1] = src[4 * i + 3] ; } endif udst + = chromStride ; vdst + = chromStride ; ydst + = lumStride ; src + = srcStride ; } ifdef HAVE_MMX asm volatile ( EMMS \n\t SFENCE \n\t : : : memory ) ; endif }",1
"void palette8tobgr15 ( const uint8_t * src , uint8_t * dst , unsigned num_pixels , const uint8_t * palette ) { unsigned i ; for ( i=0 ; i < num_pixels ; i + + ) ( ( uint16_t * ) dst ) [i] = bswap_16 ( ( ( uint16_t * ) palette ) [ src[i] ] ) ; }",1
static int decode_interrupt_cb ( void * ctx ) { return received_nb_signals > transcode_init_done ; },1
"static int mxf_read_content_storage ( void * arg , AVIOContext * pb , int tag , int size , UID uid , int64_t klv_offset ) { MXFContext * mxf = arg ; switch ( tag ) { case 0x1901 : mxf - > packages_count = avio_rb32 ( pb ) ; mxf - > packages_refs = av_calloc ( mxf - > packages_count , sizeof ( UID ) ) ; if ( ! mxf - > packages_refs ) return AVERROR ( ENOMEM ) ; avio_skip ( pb , 4 ) ; / * useless size of objects , always 16 according to specs * / avio_read ( pb , ( uint8_t * ) mxf - > packages_refs , mxf - > packages_count * sizeof ( UID ) ) ; break ; } return 0 ; }",1
"int vc1_parse_frame_header_adv ( VC1Context * v , GetBitContext * gb ) { int pqindex , lowquant ; int status ; int mbmodetab , imvtab , icbptab , twomvbptab , fourmvbptab ; / * useful only for debugging * / int scale , shift , i ; / * for initializing LUT for intensity compensation * / v - > numref=0 ; v - > fcm=0 ; v - > field_mode=0 ; v - > p_frame_skipped = 0 ; if ( v - > second_field ) { v - > s . pict_type = ( v - > fptype & 1 ) ? AV_PICTURE_TYPE_P : AV_PICTURE_TYPE_I ; if ( v - > fptype & 4 ) v - > s . pict_type = ( v - > fptype & 1 ) ? AV_PICTURE_TYPE_BI : AV_PICTURE_TYPE_B ; v - > s . current_picture_ptr - > f . pict_type = v - > s . pict_type ; if ( ! v - > pic_header_flag ) goto parse_common_info ; } if ( v - > interlace ) { v - > fcm = decode012 ( gb ) ; if ( v - > fcm ) { if ( v - > fcm == 2 ) v - > field_mode = 1 ; else v - > field_mode = 0 ; if ( ! v - > warn_interlaced + + ) av_log ( v - > s . avctx , AV_LOG_ERROR , Interlaced frames/fields support is incomplete\n ) ; } } if ( v - > field_mode ) { v - > fptype = get_bits ( gb , 3 ) ; v - > s . pict_type = ( v - > fptype & 2 ) ? AV_PICTURE_TYPE_P : AV_PICTURE_TYPE_I ; if ( v - > fptype & 4 ) // B - picture v - > s . pict_type = ( v - > fptype & 2 ) ? AV_PICTURE_TYPE_BI : AV_PICTURE_TYPE_B ; } else { switch ( get_unary ( gb , 0 , 4 ) ) { case 0 : v - > s . pict_type = AV_PICTURE_TYPE_P ; break ; case 1 : v - > s . pict_type = AV_PICTURE_TYPE_B ; break ; case 2 : v - > s . pict_type = AV_PICTURE_TYPE_I ; break ; case 3 : v - > s . pict_type = AV_PICTURE_TYPE_BI ; break ; case 4 : v - > s . pict_type = AV_PICTURE_TYPE_P ; // skipped pic v - > p_frame_skipped = 1 ; break ; } } if ( v - > tfcntrflag ) skip_bits ( gb , 8 ) ; if ( v - > broadcast ) { if ( ! v - > interlace || v - > psf ) { v - > rptfrm = get_bits ( gb , 2 ) ; } else { v - > tff = get_bits1 ( gb ) ; v - > rff = get_bits1 ( gb ) ; } } if ( v - > panscanflag ) { av_log_missing_feature ( v - > s . avctx , Pan - scan , 0 ) ; // . . . } if ( v - > p_frame_skipped ) { return 0 ; } v - > rnd = get_bits1 ( gb ) ; if ( v - > interlace ) v - > uvsamp = get_bits1 ( gb ) ; if ( v - > field_mode ) { if ( ! v - > refdist_flag ) v - > refdist = 0 ; else { if ( ( v - > s . pict_type ! = AV_PICTURE_TYPE_B ) & & ( v - > s . pict_type ! = AV_PICTURE_TYPE_BI ) ) { v - > refdist = get_bits ( gb , 2 ) ; if ( v - > refdist == 3 ) v - > refdist + = get_unary ( gb , 0 , 16 ) ; } else { v - > bfraction_lut_index = get_vlc2 ( gb , ff_vc1_bfraction_vlc . table , VC1_BFRACTION_VLC_BITS , 1 ) ; v - > bfraction = ff_vc1_bfraction_lut[v - > bfraction_lut_index] ; v - > frfd = ( v - > bfraction * v - > refdist ) > > 8 ; v - > brfd = v - > refdist - v - > frfd - 1 ; if ( v - > brfd < 0 ) v - > brfd = 0 ; } } goto parse_common_info ; } if ( v - > finterpflag ) v - > interpfrm = get_bits1 ( gb ) ; if ( v - > s . pict_type == AV_PICTURE_TYPE_B ) { v - > bfraction_lut_index = get_vlc2 ( gb , ff_vc1_bfraction_vlc . table , VC1_BFRACTION_VLC_BITS , 1 ) ; v - > bfraction = ff_vc1_bfraction_lut[v - > bfraction_lut_index] ; if ( v - > bfraction == 0 ) { v - > s . pict_type = AV_PICTURE_TYPE_BI ; / * XXX : should not happen here * / } } parse_common_info : if ( v - > field_mode ) v - > cur_field_type = ! ( v - > tff v - > second_field ) ; pqindex = get_bits ( gb , 5 ) ; if ( ! pqindex ) return - 1 ; v - > pqindex = pqindex ; if ( v - > quantizer_mode == QUANT_FRAME_IMPLICIT ) v - > pq = ff_vc1_pquant_table[0][pqindex] ; else v - > pq = ff_vc1_pquant_table[1][pqindex] ; v - > pquantizer = 1 ; if ( v - > quantizer_mode == QUANT_FRAME_IMPLICIT ) v - > pquantizer = pqindex < 9 ; if ( v - > quantizer_mode == QUANT_NON_UNIFORM ) v - > pquantizer = 0 ; v - > pqindex = pqindex ; if ( pqindex < 9 ) v - > halfpq = get_bits1 ( gb ) ; else v - > halfpq = 0 ; if ( v - > quantizer_mode == QUANT_FRAME_EXPLICIT ) v - > pquantizer = get_bits1 ( gb ) ; if ( v - > postprocflag ) v - > postproc = get_bits ( gb , 2 ) ; if ( v - > s . pict_type == AV_PICTURE_TYPE_I || v - > s . pict_type == AV_PICTURE_TYPE_P ) v - > use_ic = 0 ; if ( v - > parse_only ) return 0 ; switch ( v - > s . pict_type ) { case AV_PICTURE_TYPE_I : case AV_PICTURE_TYPE_BI : if ( v - > fcm == 1 ) { //interlace frame picture status = bitplane_decoding ( v - > fieldtx_plane , & v - > fieldtx_is_raw , v ) ; if ( status < 0 ) return - 1 ; av_log ( v - > s . avctx , AV_LOG_DEBUG , FIELDTX plane encoding : Imode : %i , Invert : %i\n , status > > 1 , status & 1 ) ; } status = bitplane_decoding ( v - > acpred_plane , & v - > acpred_is_raw , v ) ; if ( status < 0 ) return - 1 ; av_log ( v - > s . avctx , AV_LOG_DEBUG , ACPRED plane encoding : Imode : %i , Invert : %i\n , status > > 1 , status & 1 ) ; v -",1
"static int decode_mb ( MadContext * s , AVFrame * frame , int inter ) { int mv_map = 0 ; int mv_x , mv_y ; int j ; if ( inter ) { int v = decode210 ( & s - > gb ) ; if ( v < 2 ) { mv_map = v ? get_bits ( & s - > gb , 6 ) : 63 ; mv_x = decode_motion ( & s - > gb ) ; mv_y = decode_motion ( & s - > gb ) ; } } for ( j=0 ; j < 6 ; j + + ) { if ( mv_map & ( 1 < < j ) ) { // mv_x and mv_y are guarded by mv_map int add = 2 * decode_motion ( & s - > gb ) ; if ( s - > last_frame - > data[0] ) comp_block ( s , frame , s - > mb_x , s - > mb_y , j , mv_x , mv_y , add ) ; } else { s - > dsp . clear_block ( s - > block ) ; if ( decode_block_intra ( s , s - > block ) < 0 ) return - 1 ; idct_put ( s , frame , s - > block , s - > mb_x , s - > mb_y , j ) ; } } return 0 ; }",1
"static int hls_read_packet ( AVFormatContext * s , AVPacket * pkt ) { HLSContext * c = s - > priv_data ; int ret , i , minvariant = - 1 ; if ( c - > first_packet ) { recheck_discard_flags ( s , 1 ) ; c - > first_packet = 0 ; } start : c - > end_of_segment = 0 ; for ( i = 0 ; i < c - > n_variants ; i + + ) { struct variant * var = c - > variants[i] ; / * Make sure we ' ve got one buffered packet from each open variant * stream * / if ( var - > needed & & ! var - > pkt . data ) { while ( 1 ) { int64_t ts_diff ; AVStream * st ; ret = av_read_frame ( var - > ctx , & var - > pkt ) ; if ( ret < 0 ) { if ( ! var - > pb . eof_reached ) return ret ; break ; } else { if ( c - > first_timestamp == AV_NOPTS_VALUE & & var - > pkt . dts ! = AV_NOPTS_VALUE ) c - > first_timestamp = av_rescale_q ( var - > pkt . dts , var - > ctx - > streams[var - > pkt . stream_index] - > time_base , AV_TIME_BASE_Q ) ; } if ( c - > seek_timestamp == AV_NOPTS_VALUE ) break ; if ( var - > pkt . dts == AV_NOPTS_VALUE ) { c - > seek_timestamp = AV_NOPTS_VALUE ; break ; } st = var - > ctx - > streams[var - > pkt . stream_index] ; ts_diff = av_rescale_rnd ( var - > pkt . dts , AV_TIME_BASE , st - > time_base . den , AV_ROUND_DOWN ) - c - > seek_timestamp ; if ( ts_diff > = 0 & & ( c - > seek_flags & AVSEEK_FLAG_ANY || var - > pkt . flags & AV_PKT_FLAG_KEY ) ) { c - > seek_timestamp = AV_NOPTS_VALUE ; break ; } } } / * Check if this stream still is on an earlier segment number , or * has the packet with the lowest dts * / if ( var - > pkt . data ) { struct variant * minvar = c - > variants[minvariant] ; if ( minvariant < 0 || var - > cur_seq_no < minvar - > cur_seq_no ) { minvariant = i ; } else if ( var - > cur_seq_no == minvar - > cur_seq_no ) { int64_t dts = var - > pkt . dts ; int64_t mindts = minvar - > pkt . dts ; AVStream * st = var - > ctx - > streams[var - > pkt . stream_index] ; AVStream * minst = minvar - > ctx - > streams[minvar - > pkt . stream_index] ; if ( dts == AV_NOPTS_VALUE ) { minvariant = i ; } else if ( mindts ! = AV_NOPTS_VALUE ) { if ( st - > start_time ! = AV_NOPTS_VALUE ) dts - = st - > start_time ; if ( minst - > start_time ! = AV_NOPTS_VALUE ) mindts - = minst - > start_time ; if ( av_compare_ts ( dts , st - > time_base , mindts , minst - > time_base ) < 0 ) minvariant = i ; } } } } if ( c - > end_of_segment ) { if ( recheck_discard_flags ( s , 0 ) ) goto start ; } / * If we got a packet , return it * / if ( minvariant > = 0 ) { * pkt = c - > variants[minvariant] - > pkt ; pkt - > stream_index + = c - > variants[minvariant] - > stream_offset ; reset_packet ( & c - > variants[minvariant] - > pkt ) ; return 0 ; } return AVERROR_EOF ; }",1
"static inline void qpel_motion ( MpegEncContext * s , uint8_t * dest_y , uint8_t * dest_cb , uint8_t * dest_cr , int field_based , int bottom_field , int field_select , uint8_t * * ref_picture , op_pixels_func ( * pix_op ) [4] , qpel_mc_func ( * qpix_op ) [16] , int motion_x , int motion_y , int h ) { uint8_t * ptr_y , * ptr_cb , * ptr_cr ; int dxy , uvdxy , mx , my , src_x , src_y , uvsrc_x , uvsrc_y , v_edge_pos , linesize , uvlinesize ; dxy = ( ( motion_y & 3 ) < < 2 ) | ( motion_x & 3 ) ; src_x = s - > mb_x * 16 + ( motion_x > > 2 ) ; src_y = s - > mb_y * ( 16 > > field_based ) + ( motion_y > > 2 ) ; v_edge_pos = s - > v_edge_pos > > field_based ; linesize = s - > linesize < < field_based ; uvlinesize = s - > uvlinesize < < field_based ; if ( field_based ) { mx= motion_x/2 ; my= motion_y > > 1 ; } else if ( s - > workaround_bugs & FF_BUG_QPEL_CHROMA2 ) { static const int rtab[8]= { 0 , 0 , 1 , 1 , 0 , 0 , 0 , 1 } ; mx= ( motion_x > > 1 ) + rtab[motion_x & 7] ; my= ( motion_y > > 1 ) + rtab[motion_y & 7] ; } else if ( s - > workaround_bugs & FF_BUG_QPEL_CHROMA ) { mx= ( motion_x > > 1 ) | ( motion_x & 1 ) ; my= ( motion_y > > 1 ) | ( motion_y & 1 ) ; } else { mx= motion_x/2 ; my= motion_y/2 ; } mx= ( mx > > 1 ) | ( mx & 1 ) ; my= ( my > > 1 ) | ( my & 1 ) ; uvdxy= ( mx & 1 ) | ( ( my & 1 ) < < 1 ) ; mx > > =1 ; my > > =1 ; uvsrc_x = s - > mb_x * 8 + mx ; uvsrc_y = s - > mb_y * ( 8 > > field_based ) + my ; ptr_y = ref_picture[0] + src_y * linesize + src_x ; ptr_cb = ref_picture[1] + uvsrc_y * uvlinesize + uvsrc_x ; ptr_cr = ref_picture[2] + uvsrc_y * uvlinesize + uvsrc_x ; if ( ( unsigned ) src_x > FFMAX ( s - > h_edge_pos - ( motion_x & 3 ) - 16 , 0 ) || ( unsigned ) src_y > FFMAX ( v_edge_pos - ( motion_y & 3 ) - h , 0 ) ) { s - > vdsp . emulated_edge_mc ( s - > edge_emu_buffer , ptr_y , s - > linesize , 17 , 17 + field_based , src_x , src_y < < field_based , s - > h_edge_pos , s - > v_edge_pos ) ; ptr_y= s - > edge_emu_buffer ; if ( ! CONFIG_GRAY || ! ( s - > flags & CODEC_FLAG_GRAY ) ) { uint8_t * uvbuf= s - > edge_emu_buffer + 18 * s - > linesize ; s - > vdsp . emulated_edge_mc ( uvbuf , ptr_cb , s - > uvlinesize , 9 , 9 + field_based , uvsrc_x , uvsrc_y < < field_based , s - > h_edge_pos > > 1 , s - > v_edge_pos > > 1 ) ; s - > vdsp . emulated_edge_mc ( uvbuf + 16 , ptr_cr , s - > uvlinesize , 9 , 9 + field_based , uvsrc_x , uvsrc_y < < field_based , s - > h_edge_pos > > 1 , s - > v_edge_pos > > 1 ) ; ptr_cb= uvbuf ; ptr_cr= uvbuf + 16 ; } } if ( ! field_based ) qpix_op[0][dxy] ( dest_y , ptr_y , linesize ) ; else { if ( bottom_field ) { dest_y + = s - > linesize ; dest_cb + = s - > uvlinesize ; dest_cr + = s - > uvlinesize ; } if ( field_select ) { ptr_y + = s - > linesize ; ptr_cb + = s - > uvlinesize ; ptr_cr + = s - > uvlinesize ; } //damn interlaced mode //FIXME boundary mirroring is not exactly correct here qpix_op[1][dxy] ( dest_y , ptr_y , linesize ) ; qpix_op[1][dxy] ( dest_y + 8 , ptr_y + 8 , linesize ) ; } if ( ! CONFIG_GRAY || ! ( s - > flags & CODEC_FLAG_GRAY ) ) { pix_op[1][uvdxy] ( dest_cr , ptr_cr , uvlinesize , h > > 1 ) ; pix_op[1][uvdxy] ( dest_cb , ptr_cb , uvlinesize , h > > 1 ) ; } }",1
"static int decode_packet ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { WmallDecodeCtx * s = avctx - > priv_data ; GetBitContext * gb = & s - > pgb ; const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; int num_bits_prev_frame ; int packet_sequence_number ; s - > samples = data ; s - > samples_end = ( float * ) ( ( int8_t * ) data + * data_size ) ; * data_size = 0 ; if ( s - > packet_done || s - > packet_loss ) { s - > packet_done = 0 ; / * * sanity check for the buffer length * / if ( buf_size < avctx - > block_align ) return 0 ; s - > next_packet_start = buf_size - avctx - > block_align ; buf_size = avctx - > block_align ; s - > buf_bit_size = buf_size < < 3 ; / * * parse packet header * / init_get_bits ( gb , buf , s - > buf_bit_size ) ; packet_sequence_number = get_bits ( gb , 4 ) ; int seekable_frame_in_packet = get_bits1 ( gb ) ; int spliced_packet = get_bits1 ( gb ) ; / * * get number of bits that need to be added to the previous frame * / num_bits_prev_frame = get_bits ( gb , s - > log2_frame_size ) ; / * * check for packet loss * / if ( ! s - > packet_loss & & ( ( s - > packet_sequence_number + 1 ) & 0xF ) ! = packet_sequence_number ) { s - > packet_loss = 1 ; av_log ( avctx , AV_LOG_ERROR , Packet loss detected ! seq %x vs %x\n , s - > packet_sequence_number , packet_sequence_number ) ; } s - > packet_sequence_number = packet_sequence_number ; if ( num_bits_prev_frame > 0 ) { int remaining_packet_bits = s - > buf_bit_size - get_bits_count ( gb ) ; if ( num_bits_prev_frame > = remaining_packet_bits ) { num_bits_prev_frame = remaining_packet_bits ; s - > packet_done = 1 ; } / * * append the previous frame data to the remaining data from the previous packet to create a full frame * / save_bits ( s , gb , num_bits_prev_frame , 1 ) ; / * * decode the cross packet frame if it is valid * / if ( ! s - > packet_loss ) decode_frame ( s ) ; } else if ( s - > num_saved_bits - s - > frame_offset ) { dprintf ( avctx , ignoring %x previously saved bits\n , s - > num_saved_bits - s - > frame_offset ) ; } if ( s - > packet_loss ) { / * * reset number of saved bits so that the decoder does not start to decode incomplete frames in the s - > len_prefix == 0 case * / s - > num_saved_bits = 0 ; s - > packet_loss = 0 ; } } else { int frame_size ; s - > buf_bit_size = ( avpkt - > size - s - > next_packet_start ) < < 3 ; init_get_bits ( gb , avpkt - > data , s - > buf_bit_size ) ; skip_bits ( gb , s - > packet_offset ) ; if ( s - > len_prefix & & remaining_bits ( s , gb ) > s - > log2_frame_size & & ( frame_size = show_bits ( gb , s - > log2_frame_size ) ) & & frame_size < = remaining_bits ( s , gb ) ) { save_bits ( s , gb , frame_size , 0 ) ; s - > packet_done = ! decode_frame ( s ) ; } else if ( ! s - > len_prefix & & s - > num_saved_bits > get_bits_count ( & s - > gb ) ) { / * * when the frames do not have a length prefix , we don ' t know the compressed length of the individual frames however , we know what part of a new packet belongs to the previous frame therefore we save the incoming packet first , then we append the previous frame data from the next packet so that we get a buffer that only contains full frames * / s - > packet_done = ! decode_frame ( s ) ; } else { s - > packet_done = 1 ; } } if ( s - > packet_done & & ! s - > packet_loss & & remaining_bits ( s , gb ) > 0 ) { / * * save the rest of the data so that it can be decoded with the next packet * / save_bits ( s , gb , remaining_bits ( s , gb ) , 0 ) ; } * data_size = 0 ; // ( int8_t * ) s - > samples - ( int8_t * ) data ; s - > packet_offset = get_bits_count ( gb ) & 7 ; return ( s - > packet_loss ) ? AVERROR_INVALIDDATA : get_bits_count ( gb ) > > 3 ; }",1
"static int asf_read_header ( AVFormatContext * s , AVFormatParameters * ap ) { ASFContext * asf = s - > priv_data ; ff_asf_guid g ; ByteIOContext * pb = s - > pb ; AVStream * st ; ASFStream * asf_st ; int size , i ; int64_t gsize ; AVRational dar[128] ; uint32_t bitrate[128] ; memset ( dar , 0 , sizeof ( dar ) ) ; memset ( bitrate , 0 , sizeof ( bitrate ) ) ; get_guid ( pb , & g ) ; if ( guidcmp ( & g , & ff_asf_header ) ) return - 1 ; get_le64 ( pb ) ; get_le32 ( pb ) ; get_byte ( pb ) ; get_byte ( pb ) ; memset ( & asf - > asfid2avid , - 1 , sizeof ( asf - > asfid2avid ) ) ; for ( ; ; ) { uint64_t gpos= url_ftell ( pb ) ; get_guid ( pb , & g ) ; gsize = get_le64 ( pb ) ; dprintf ( s , %08 PRIx64 : , gpos ) ; print_guid ( & g ) ; dprintf ( s , size=0x% PRIx64 \n , gsize ) ; if ( ! guidcmp ( & g , & ff_asf_data_header ) ) { asf - > data_object_offset = url_ftell ( pb ) ; // if not streaming , gsize is not unlimited ( how ? ) , and there is enough space in the file . . if ( ! ( asf - > hdr . flags & 0x01 ) & & gsize > = 100 ) { asf - > data_object_size = gsize - 24 ; } else { asf - > data_object_size = ( uint64_t ) - 1 ; } break ; } if ( gsize < 24 ) return - 1 ; if ( ! guidcmp ( & g , & ff_asf_file_header ) ) { get_guid ( pb , & asf - > hdr . guid ) ; asf - > hdr . file_size = get_le64 ( pb ) ; asf - > hdr . create_time = get_le64 ( pb ) ; asf - > nb_packets = get_le64 ( pb ) ; asf - > hdr . play_time = get_le64 ( pb ) ; asf - > hdr . send_time = get_le64 ( pb ) ; asf - > hdr . preroll = get_le32 ( pb ) ; asf - > hdr . ignore = get_le32 ( pb ) ; asf - > hdr . flags = get_le32 ( pb ) ; asf - > hdr . min_pktsize = get_le32 ( pb ) ; asf - > hdr . max_pktsize = get_le32 ( pb ) ; asf - > hdr . max_bitrate = get_le32 ( pb ) ; s - > packet_size = asf - > hdr . max_pktsize ; } else if ( ! guidcmp ( & g , & ff_asf_stream_header ) ) { enum AVMediaType type ; int type_specific_size , sizeX ; uint64_t total_size ; unsigned int tag1 ; int64_t pos1 , pos2 , start_time ; int test_for_ext_stream_audio , is_dvr_ms_audio=0 ; if ( s - > nb_streams == ASF_MAX_STREAMS ) { av_log ( s , AV_LOG_ERROR , too many streams\n ) ; return AVERROR ( EINVAL ) ; } pos1 = url_ftell ( pb ) ; st = av_new_stream ( s , 0 ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; av_set_pts_info ( st , 32 , 1 , 1000 ) ; / * 32 bit pts in ms * / asf_st = av_mallocz ( sizeof ( ASFStream ) ) ; if ( ! asf_st ) return AVERROR ( ENOMEM ) ; st - > priv_data = asf_st ; start_time = asf - > hdr . preroll ; asf_st - > stream_language_index = 128 ; // invalid stream index means no language info if ( ! ( asf - > hdr . flags & 0x01 ) ) { // if we aren ' t streaming . . . st - > duration = asf - > hdr . play_time / ( 10000000 / 1000 ) - start_time ; } get_guid ( pb , & g ) ; test_for_ext_stream_audio = 0 ; if ( ! guidcmp ( & g , & ff_asf_audio_stream ) ) { type = AVMEDIA_TYPE_AUDIO ; } else if ( ! guidcmp ( & g , & ff_asf_video_stream ) ) { type = AVMEDIA_TYPE_VIDEO ; } else if ( ! guidcmp ( & g , & ff_asf_command_stream ) ) { type = AVMEDIA_TYPE_DATA ; } else if ( ! guidcmp ( & g , & ff_asf_ext_stream_embed_stream_header ) ) { test_for_ext_stream_audio = 1 ; type = AVMEDIA_TYPE_UNKNOWN ; } else { return - 1 ; } get_guid ( pb , & g ) ; total_size = get_le64 ( pb ) ; type_specific_size = get_le32 ( pb ) ; get_le32 ( pb ) ; st - > id = get_le16 ( pb ) & 0x7f ; / * stream id * / // mapping of asf ID to AV stream ID ; asf - > asfid2avid[st - > id] = s - > nb_streams - 1 ; get_le32 ( pb ) ; if ( test_for_ext_stream_audio ) { get_guid ( pb , & g ) ; if ( ! guidcmp ( & g , & ff_asf_ext_stream_audio_stream ) ) { type = AVMEDIA_TYPE_AUDIO ; is_dvr_ms_audio=1 ; get_guid ( pb , & g ) ; get_le32 ( pb ) ; get_le32 ( pb ) ; get_le32 ( pb ) ; get_guid ( pb , & g ) ; get_le32 ( pb ) ; } } st - > codec - > codec_type = type ; if ( type == AVMEDIA_TYPE_AUDIO ) { ff_get_wav_header ( pb , st - > codec , type_specific_size ) ; if ( is_dvr_ms_audio ) { // codec_id and codec_tag are unreliable in dvr_ms // files . Set them later by probing stream . st - > codec - > codec_id = CODEC_ID_PROBE ; st - > codec - > codec_tag = 0 ; } if ( st - > codec - > codec_id == CODEC_ID_AAC ) { st - > need_parsing = AVSTREAM_PARSE_NONE ; } else { st - > need_parsing = AVSTREAM_PARSE_FULL ; } / * We have to init the frame size at some point . . . . * / pos2 = url_ftell ( pb ) ; if ( gsize > = ( pos2 + 8 - pos1 + 24 ) ) { asf_st - > ds_span = get_byte ( pb ) ; asf_st - > ds_packet_size = get_le16 ( pb ) ; asf_st - > ds_chunk_size = get_le16 ( pb ) ; get_le16 ( pb ) ; //ds_data_size get_byte ( pb ) ; //ds_silence_data } //printf ( Descrambling : ps : %d cs : %d ds : %d s : %d sd : %d\n , // asf_st - > ds_packet_size , asf_st - > ds_chunk_size , // asf_st - > ds_data_size , asf_st - > ds_span , asf_st - > ds_silence_data ) ; if ( asf_st - > ds_span > 1 ) { if ( ! asf_st - > ds_chunk_size || ( asf_st - > ds_packet_size/asf_st - > ds_chunk_size < = 1 ) || asf_st -",1
"static av_cold int rl2_read_header ( AVFormatContext * s ) { AVIOContext * pb = s - > pb ; AVStream * st ; unsigned int frame_count ; unsigned int audio_frame_counter = 0 ; unsigned int video_frame_counter = 0 ; unsigned int back_size ; unsigned short sound_rate ; unsigned short rate ; unsigned short channels ; unsigned short def_sound_size ; unsigned int signature ; unsigned int pts_den = 11025 ; / * video only case * / unsigned int pts_num = 1103 ; unsigned int * chunk_offset = NULL ; int * chunk_size = NULL ; int * audio_size = NULL ; int i ; int ret = 0 ; avio_skip ( pb , 4 ) ; / * skip FORM tag * / back_size = avio_rl32 ( pb ) ; / * * < get size of the background frame * / signature = avio_rb32 ( pb ) ; avio_skip ( pb , 4 ) ; / * data size * / frame_count = avio_rl32 ( pb ) ; / * disallow back_sizes and frame_counts that may lead to overflows later * / if ( back_size > INT_MAX/2 || frame_count > INT_MAX / sizeof ( uint32_t ) ) avio_skip ( pb , 2 ) ; / * encoding mentod * / sound_rate = avio_rl16 ( pb ) ; rate = avio_rl16 ( pb ) ; channels = avio_rl16 ( pb ) ; def_sound_size = avio_rl16 ( pb ) ; / * * setup video stream * / st = avformat_new_stream ( s , NULL ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; st - > codec - > codec_type = AVMEDIA_TYPE_VIDEO ; st - > codec - > codec_id = AV_CODEC_ID_RL2 ; st - > codec - > codec_tag = 0 ; / * no fourcc * / st - > codec - > width = 320 ; st - > codec - > height = 200 ; / * * allocate and fill extradata * / st - > codec - > extradata_size = EXTRADATA1_SIZE ; if ( signature == RLV3_TAG & & back_size > 0 ) st - > codec - > extradata_size + = back_size ; st - > codec - > extradata = av_mallocz ( st - > codec - > extradata_size + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! st - > codec - > extradata ) return AVERROR ( ENOMEM ) ; if ( avio_read ( pb , st - > codec - > extradata , st - > codec - > extradata_size ) ! = st - > codec - > extradata_size ) return AVERROR ( EIO ) ; / * * setup audio stream if present * / if ( sound_rate ) { pts_num = def_sound_size ; pts_den = rate ; st = avformat_new_stream ( s , NULL ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; st - > codec - > codec_type = AVMEDIA_TYPE_AUDIO ; st - > codec - > codec_id = AV_CODEC_ID_PCM_U8 ; st - > codec - > codec_tag = 1 ; st - > codec - > channels = channels ; st - > codec - > bits_per_coded_sample = 8 ; st - > codec - > sample_rate = rate ; st - > codec - > bit_rate = st - > codec - > channels * st - > codec - > sample_rate * st - > codec - > bits_per_coded_sample ; st - > codec - > block_align = st - > codec - > channels * st - > codec - > bits_per_coded_sample / 8 ; avpriv_set_pts_info ( st , 32 , 1 , rate ) ; avpriv_set_pts_info ( s - > streams[0] , 32 , pts_num , pts_den ) ; chunk_size = av_malloc ( frame_count * sizeof ( uint32_t ) ) ; audio_size = av_malloc ( frame_count * sizeof ( uint32_t ) ) ; chunk_offset = av_malloc ( frame_count * sizeof ( uint32_t ) ) ; if ( ! chunk_size || ! audio_size || ! chunk_offset ) { av_free ( chunk_size ) ; av_free ( audio_size ) ; av_free ( chunk_offset ) ; return AVERROR ( ENOMEM ) ; / * * read offset and size tables * / for ( i=0 ; i < frame_count ; i + + ) chunk_size[i] = avio_rl32 ( pb ) ; for ( i=0 ; i < frame_count ; i + + ) chunk_offset[i] = avio_rl32 ( pb ) ; for ( i=0 ; i < frame_count ; i + + ) audio_size[i] = avio_rl32 ( pb ) & 0xFFFF ; / * * build the sample index * / for ( i=0 ; i < frame_count ; i + + ) { if ( chunk_size[i] < 0 || audio_size[i] > chunk_size[i] ) { ret = AVERROR_INVALIDDATA ; break ; if ( sound_rate & & audio_size[i] ) { av_add_index_entry ( s - > streams[1] , chunk_offset[i] , audio_frame_counter , audio_size[i] , 0 , AVINDEX_KEYFRAME ) ; audio_frame_counter + = audio_size[i] / channels ; av_add_index_entry ( s - > streams[0] , chunk_offset[i] + audio_size[i] , video_frame_counter , chunk_size[i] - audio_size[i] , 0 , AVINDEX_KEYFRAME ) ; + + video_frame_counter ; av_free ( chunk_size ) ; av_free ( audio_size ) ; av_free ( chunk_offset ) ; return ret ;",1
"static av_cold int ffmmal_init_decoder ( AVCodecContext * avctx ) { MMALDecodeContext * ctx = avctx - > priv_data ; MMAL_STATUS_T status ; MMAL_ES_FORMAT_T * format_in ; MMAL_COMPONENT_T * decoder ; char tmp[32] ; int ret = 0 ; bcm_host_init ( ) ; if ( mmal_vc_init ( ) ) { av_log ( avctx , AV_LOG_ERROR , Cannot initialize MMAL VC driver ! \n ) ; return AVERROR ( ENOSYS ) ; if ( ( ret = ff_get_format ( avctx , avctx - > codec - > pix_fmts ) ) < 0 ) return ret ; avctx - > pix_fmt = ret ; if ( ( status = mmal_component_create ( MMAL_COMPONENT_DEFAULT_VIDEO_DECODER , & ctx - > decoder ) ) ) goto fail ; decoder = ctx - > decoder ; format_in = decoder - > input[0] - > format ; format_in - > type = MMAL_ES_TYPE_VIDEO ; switch ( avctx - > codec_id ) { case AV_CODEC_ID_MPEG2VIDEO : format_in - > encoding = MMAL_ENCODING_MP2V ; break ; case AV_CODEC_ID_MPEG4 : format_in - > encoding = MMAL_ENCODING_MP4V ; break ; case AV_CODEC_ID_VC1 : format_in - > encoding = MMAL_ENCODING_WVC1 ; break ; case AV_CODEC_ID_H264 : default : format_in - > encoding = MMAL_ENCODING_H264 ; break ; format_in - > es - > video . width = FFALIGN ( avctx - > width , 32 ) ; format_in - > es - > video . height = FFALIGN ( avctx - > height , 16 ) ; format_in - > es - > video . crop . width = avctx - > width ; format_in - > es - > video . crop . height = avctx - > height ; format_in - > es - > video . frame_rate . num = 24000 ; format_in - > es - > video . frame_rate . den = 1001 ; format_in - > es - > video . par . num = avctx - > sample_aspect_ratio . num ; format_in - > es - > video . par . den = avctx - > sample_aspect_ratio . den ; format_in - > flags = MMAL_ES_FORMAT_FLAG_FRAMED ; av_get_codec_tag_string ( tmp , sizeof ( tmp ) , format_in - > encoding ) ; av_log ( avctx , AV_LOG_DEBUG , Using MMAL %s encoding . \n , tmp ) ; if ( ( status = mmal_port_format_commit ( decoder - > input[0] ) ) ) goto fail ; decoder - > input[0] - > buffer_num = FFMAX ( decoder - > input[0] - > buffer_num_min , 20 ) ; decoder - > input[0] - > buffer_size = FFMAX ( decoder - > input[0] - > buffer_size_min , 512 * 1024 ) ; ctx - > pool_in = mmal_pool_create ( decoder - > input[0] - > buffer_num , 0 ) ; if ( ! ctx - > pool_in ) { ret = AVERROR ( ENOMEM ) ; goto fail ; if ( ( ret = ffmal_update_format ( avctx ) ) < 0 ) goto fail ; ctx - > queue_decoded_frames = mmal_queue_create ( ) ; if ( ! ctx - > queue_decoded_frames ) goto fail ; decoder - > input[0] - > userdata = ( void * ) avctx ; decoder - > output[0] - > userdata = ( void * ) avctx ; decoder - > control - > userdata = ( void * ) avctx ; if ( ( status = mmal_port_enable ( decoder - > control , control_port_cb ) ) ) goto fail ; if ( ( status = mmal_port_enable ( decoder - > input[0] , input_callback ) ) ) goto fail ; if ( ( status = mmal_port_enable ( decoder - > output[0] , output_callback ) ) ) goto fail ; if ( ( status = mmal_component_enable ( decoder ) ) ) goto fail ; return 0 ; fail : ffmmal_close_decoder ( avctx ) ; return ret < 0 ? ret : AVERROR_UNKNOWN ;",1
"static int cdxl_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * pkt ) { CDXLVideoContext * c = avctx - > priv_data ; AVFrame * const p = data ; int ret , w , h , encoding , aligned_width , buf_size = pkt - > size ; const uint8_t * buf = pkt - > data ; if ( buf_size < 32 ) return AVERROR_INVALIDDATA ; encoding = buf[1] & 7 ; c - > format = buf[1] & 0xE0 ; w = AV_RB16 ( & buf[14] ) ; h = AV_RB16 ( & buf[16] ) ; c - > bpp = buf[19] ; c - > palette_size = AV_RB16 ( & buf[20] ) ; c - > palette = buf + 32 ; c - > video = c - > palette + c - > palette_size ; c - > video_size = buf_size - c - > palette_size - 32 ; if ( c - > palette_size > 512 ) return AVERROR_INVALIDDATA ; if ( buf_size < c - > palette_size + 32 ) return AVERROR_INVALIDDATA ; if ( c - > bpp < 1 ) return AVERROR_INVALIDDATA ; if ( c - > format ! = BIT_PLANAR & & c - > format ! = BIT_LINE & & c - > format ! = CHUNKY ) { avpriv_request_sample ( avctx , Pixel format 0x%0x , c - > format ) ; return AVERROR_PATCHWELCOME ; } if ( ( ret = ff_set_dimensions ( avctx , w , h ) ) < 0 ) return ret ; if ( c - > format == CHUNKY ) aligned_width = avctx - > width ; else aligned_width = FFALIGN ( c - > avctx - > width , 16 ) ; c - > padded_bits = aligned_width - c - > avctx - > width ; if ( c - > video_size < aligned_width * avctx - > height * c - > bpp / 8 ) return AVERROR_INVALIDDATA ; if ( ! encoding & & c - > palette_size & & c - > bpp < = 8 ) { avctx - > pix_fmt = AV_PIX_FMT_PAL8 ; } else if ( encoding == 1 & & ( c - > bpp == 6 || c - > bpp == 8 ) ) { if ( c - > palette_size ! = ( 1 < < ( c - > bpp - 1 ) ) ) return AVERROR_INVALIDDATA ; avctx - > pix_fmt = AV_PIX_FMT_BGR24 ; } else if ( ! encoding & & c - > bpp == 24 & & c - > format == CHUNKY & & ! c - > palette_size ) { avctx - > pix_fmt = AV_PIX_FMT_RGB24 ; } else { avpriv_request_sample ( avctx , Encoding %d , bpp %d and format 0x%x , encoding , c - > bpp , c - > format ) ; return AVERROR_PATCHWELCOME ; } if ( ( ret = ff_get_buffer ( avctx , p , 0 ) ) < 0 ) return ret ; p - > pict_type = AV_PICTURE_TYPE_I ; if ( encoding ) { av_fast_padded_malloc ( & c - > new_video , & c - > new_video_size , h * w + AV_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! c - > new_video ) return AVERROR ( ENOMEM ) ; if ( c - > bpp == 8 ) cdxl_decode_ham8 ( c , p ) ; else cdxl_decode_ham6 ( c , p ) ; } else if ( avctx - > pix_fmt == AV_PIX_FMT_PAL8 ) { cdxl_decode_rgb ( c , p ) ; } else { cdxl_decode_raw ( c , p ) ; } * got_frame = 1 ; return buf_size ; }",1
"static int ogg_get_length ( AVFormatContext * s ) { struct ogg * ogg = s - > priv_data ; int i ; int64_t size , end ; int streams_left=0 ; if ( ! s - > pb - > seekable ) return 0 ; // already set if ( s - > duration ! = AV_NOPTS_VALUE ) return 0 ; size = avio_size ( s - > pb ) ; if ( size < 0 ) return 0 ; end = size > MAX_PAGE_SIZE ? size - MAX_PAGE_SIZE : 0 ; ogg_save ( s ) ; avio_seek ( s - > pb , end , SEEK_SET ) ; while ( ! ogg_read_page ( s , & i ) ) { if ( ogg - > streams[i] . granule ! = - 1 & & ogg - > streams[i] . granule ! = 0 & & ogg - > streams[i] . codec ) { s - > streams[i] - > duration = ogg_gptopts ( s , i , ogg - > streams[i] . granule , NULL ) ; if ( s - > streams[i] - > start_time ! = AV_NOPTS_VALUE ) { s - > streams[i] - > duration - = s - > streams[i] - > start_time ; streams_left - = ( ogg - > streams[i] . got_start== - 1 ) ; ogg - > streams[i] . got_start= 1 ; } else if ( ! ogg - > streams[i] . got_start ) { ogg - > streams[i] . got_start= - 1 ; streams_left + + ; } } } ogg_restore ( s , 0 ) ; ogg_save ( s ) ; avio_seek ( s - > pb , s - > data_offset , SEEK_SET ) ; ogg_reset ( s ) ; while ( ! ogg_packet ( s , & i , NULL , NULL , NULL ) ) { int64_t pts = ogg_calc_pts ( s , i , NULL ) ; if ( pts ! = AV_NOPTS_VALUE & & s - > streams[i] - > start_time == AV_NOPTS_VALUE & & ! ogg - > streams[i] . got_start ) { s - > streams[i] - > duration - = pts ; ogg - > streams[i] . got_start= 1 ; streams_left - - ; } else if ( s - > streams[i] - > start_time ! = AV_NOPTS_VALUE & & ! ogg - > streams[i] . got_start ) { ogg - > streams[i] . got_start= 1 ; streams_left - - ; } } if ( streams_left < =0 ) break ; } ogg_restore ( s , 0 ) ; return 0 ; }",1
"static int raw_decode ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { const AVPixFmtDescriptor * desc = av_pix_fmt_desc_get ( avctx - > pix_fmt ) ; RawVideoContext * context = avctx - > priv_data ; const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; int linesize_align = 4 ; int res , len ; int need_copy = ! avpkt - > buf || context - > is_2_4_bpp || context - > is_yuv2 ; AVFrame * frame = data ; AVPicture * picture = data ; frame - > pict_type = AV_PICTURE_TYPE_I ; frame - > key_frame = 1 ; frame - > reordered_opaque = avctx - > reordered_opaque ; frame - > pkt_pts = avctx - > pkt - > pts ; av_frame_set_pkt_pos ( frame , avctx - > pkt - > pos ) ; av_frame_set_pkt_duration ( frame , avctx - > pkt - > duration ) ; if ( context - > tff > = 0 ) { frame - > interlaced_frame = 1 ; frame - > top_field_first = context - > tff ; } if ( ( res = av_image_check_size ( avctx - > width , avctx - > height , 0 , avctx ) ) < 0 ) return res ; if ( need_copy ) frame - > buf[0] = av_buffer_alloc ( context - > frame_size ) ; else frame - > buf[0] = av_buffer_ref ( avpkt - > buf ) ; if ( ! frame - > buf[0] ) return AVERROR ( ENOMEM ) ; //2bpp and 4bpp raw in avi and mov ( yes this is ugly . . . ) if ( context - > is_2_4_bpp ) { int i ; uint8_t * dst = frame - > buf[0] - > data ; buf_size = context - > frame_size - AVPALETTE_SIZE ; if ( avctx - > bits_per_coded_sample == 4 ) { for ( i = 0 ; 2 * i + 1 < buf_size & & i < avpkt - > size ; i + + ) { dst[2 * i + 0] = buf[i] > > 4 ; dst[2 * i + 1] = buf[i] & 15 ; } linesize_align = 8 ; } else { av_assert0 ( avctx - > bits_per_coded_sample == 2 ) ; for ( i = 0 ; 4 * i + 3 < buf_size & & i < avpkt - > size ; i + + ) { dst[4 * i + 0] = buf[i] > > 6 ; dst[4 * i + 1] = buf[i] > > 4 & 3 ; dst[4 * i + 2] = buf[i] > > 2 & 3 ; dst[4 * i + 3] = buf[i] & 3 ; } linesize_align = 16 ; } buf = dst ; } else if ( need_copy ) { memcpy ( frame - > buf[0] - > data , buf , FFMIN ( buf_size , context - > frame_size ) ) ; buf = frame - > buf[0] - > data ; } if ( avctx - > codec_tag == MKTAG ( ' A ' , ' V ' , ' 1 ' , ' x ' ) || avctx - > codec_tag == MKTAG ( ' A ' , ' V ' , ' u ' , ' p ' ) ) buf + = buf_size - context - > frame_size ; len = context - > frame_size - ( avctx - > pix_fmt==AV_PIX_FMT_PAL8 ? AVPALETTE_SIZE : 0 ) ; if ( buf_size < len ) { av_log ( avctx , AV_LOG_ERROR , Invalid buffer size , packet size %d < expected frame_size %d\n , buf_size , len ) ; av_buffer_unref ( & frame - > buf[0] ) ; return AVERROR ( EINVAL ) ; } if ( ( res = avpicture_fill ( picture , buf , avctx - > pix_fmt , avctx - > width , avctx - > height ) ) < 0 ) { av_buffer_unref ( & frame - > buf[0] ) ; return res ; } if ( avctx - > pix_fmt == AV_PIX_FMT_PAL8 ) { const uint8_t * pal = av_packet_get_side_data ( avpkt , AV_PKT_DATA_PALETTE , NULL ) ; if ( pal ) { av_buffer_unref ( & context - > palette ) ; context - > palette = av_buffer_alloc ( AVPALETTE_SIZE ) ; if ( ! context - > palette ) { av_buffer_unref ( & frame - > buf[0] ) ; return AVERROR ( ENOMEM ) ; } memcpy ( context - > palette - > data , pal , AVPALETTE_SIZE ) ; frame - > palette_has_changed = 1 ; } } if ( ( avctx - > pix_fmt==AV_PIX_FMT_BGR24 || avctx - > pix_fmt==AV_PIX_FMT_GRAY8 || avctx - > pix_fmt==AV_PIX_FMT_RGB555LE || avctx - > pix_fmt==AV_PIX_FMT_RGB555BE || avctx - > pix_fmt==AV_PIX_FMT_RGB565LE || avctx - > pix_fmt==AV_PIX_FMT_MONOWHITE || avctx - > pix_fmt==AV_PIX_FMT_PAL8 ) & & FFALIGN ( frame - > linesize[0] , linesize_align ) * avctx - > height < = buf_size ) frame - > linesize[0] = FFALIGN ( frame - > linesize[0] , linesize_align ) ; if ( avctx - > pix_fmt == AV_PIX_FMT_NV12 & & avctx - > codec_tag == MKTAG ( ' N ' , ' V ' , ' 1 ' , ' 2 ' ) & & FFALIGN ( frame - > linesize[0] , linesize_align ) * avctx - > height + FFALIGN ( frame - > linesize[1] , linesize_align ) * ( ( avctx - > height + 1 ) / 2 ) < = buf_size ) { int la0 = FFALIGN ( frame - > linesize[0] , linesize_align ) ; frame - > data[1] + = ( la0 - frame - > linesize[0] ) * avctx - > height ; frame - > linesize[0] = la0 ; frame - > linesize[1] = FFALIGN ( frame - > linesize[1] , linesize_align ) ; } if ( ( avctx - > pix_fmt == AV_PIX_FMT_PAL8 & & buf_size < context - > frame_size ) || ( desc - > flags & AV_PIX_FMT_FLAG_PSEUDOPAL ) ) { frame - > buf[1] = av_buffer_ref ( context - > palette ) ; if ( ! frame - > buf[1] ) { av_buffer_unref ( & frame - > buf[0] ) ; return AVERROR ( ENOMEM ) ; } frame - > data[1] = frame - > buf[1] - > data ; } if ( avctx - > pix_fmt == AV_PIX_FMT_BGR24 & & ( ( frame - > linesize[0] + 3 ) & 3 ) * avctx - > height < = buf_size ) frame - > linesize[0] = ( frame - > linesize[0] + 3 ) & 3 ; if ( context - > flip ) flip ( avctx , picture ) ; if ( avctx - > codec_tag == MKTAG ( ' Y ' , ' V ' , ' 1 ' , ' 2 ' ) || avctx - > codec_tag == MKTAG ( ' Y ' , ' V ' , ' 1 ' , ' 6 ' ) || avctx - > codec_tag == MKTAG ( ' Y ' , ' V ' , ' 2 ' , '",1
"int ff_vaapi_mpeg_end_frame ( AVCodecContext * avctx ) { struct vaapi_context * const vactx = avctx - > hwaccel_context ; MpegEncContext * s = avctx - > priv_data ; int ret ; ret = ff_vaapi_commit_slices ( vactx ) ; if ( ret < 0 ) goto finish ; ret = ff_vaapi_render_picture ( vactx , ff_vaapi_get_surface_id ( & s - > current_picture_ptr - > f ) ) ; if ( ret < 0 ) goto finish ; ff_mpeg_draw_horiz_band ( s , 0 , s - > avctx - > height ) ; finish : ff_vaapi_common_end_frame ( avctx ) ; return ret ; }",1
"static int rscc_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { RsccContext * ctx = avctx - > priv_data ; GetByteContext * gbc = & ctx - > gbc ; GetByteContext tiles_gbc ; AVFrame * frame = data ; const uint8_t * pixels , * raw ; uint8_t * inflated_tiles = NULL ; int tiles_nb , packed_size , pixel_size = 0 ; int i , ret = 0 ; bytestream2_init ( gbc , avpkt - > data , avpkt - > size ) ; / * Size check * / if ( bytestream2_get_bytes_left ( gbc ) < 12 ) { av_log ( avctx , AV_LOG_ERROR , Packet too small ( %d ) \n , avpkt - > size ) ; return AVERROR_INVALIDDATA ; / * Read number of tiles , and allocate the array * / tiles_nb = bytestream2_get_le16 ( gbc ) ; av_fast_malloc ( & ctx - > tiles , & ctx - > tiles_size , tiles_nb * sizeof ( * ctx - > tiles ) ) ; if ( ! ctx - > tiles ) { ret = AVERROR ( ENOMEM ) ; av_log ( avctx , AV_LOG_DEBUG , Frame with %d tiles . \n , tiles_nb ) ; / * When there are more than 5 tiles , they are packed together with * a size header . When that size does not match the number of tiles * times the tile size , it means it needs to be inflated as well * / if ( tiles_nb > 5 ) { uLongf packed_tiles_size ; if ( tiles_nb < 32 ) packed_tiles_size = bytestream2_get_byte ( gbc ) ; else packed_tiles_size = bytestream2_get_le16 ( gbc ) ; ff_dlog ( avctx , packed tiles of size %lu . \n , packed_tiles_size ) ; / * If necessary , uncompress tiles , and hijack the bytestream reader * / if ( packed_tiles_size ! = tiles_nb * TILE_SIZE ) { uLongf length = tiles_nb * TILE_SIZE ; inflated_tiles = av_malloc ( length ) ; if ( ! inflated_tiles ) { ret = AVERROR ( ENOMEM ) ; ret = uncompress ( inflated_tiles , & length , gbc - > buffer , packed_tiles_size ) ; if ( ret ) { av_log ( avctx , AV_LOG_ERROR , Tile deflate error %d . \n , ret ) ; ret = AVERROR_UNKNOWN ; / * Skip the compressed tile section in the main byte reader , * and point it to read the newly uncompressed data * / bytestream2_skip ( gbc , packed_tiles_size ) ; bytestream2_init ( & tiles_gbc , inflated_tiles , length ) ; gbc = & tiles_gbc ; / * Fill in array of tiles , keeping track of how many pixels are updated * / for ( i = 0 ; i < tiles_nb ; i + + ) { ctx - > tiles[i] . x = bytestream2_get_le16 ( gbc ) ; ctx - > tiles[i] . w = bytestream2_get_le16 ( gbc ) ; ctx - > tiles[i] . y = bytestream2_get_le16 ( gbc ) ; ctx - > tiles[i] . h = bytestream2_get_le16 ( gbc ) ; pixel_size + = ctx - > tiles[i] . w * ctx - > tiles[i] . h * ctx - > component_size ; ff_dlog ( avctx , tile %d orig ( %d , %d ) %dx%d . \n , i , ctx - > tiles[i] . x , ctx - > tiles[i] . y , ctx - > tiles[i] . w , ctx - > tiles[i] . h ) ; if ( ctx - > tiles[i] . w == 0 || ctx - > tiles[i] . h == 0 ) { av_log ( avctx , AV_LOG_ERROR , invalid tile %d at ( %d . %d ) with size %dx%d . \n , i , ctx - > tiles[i] . x , ctx - > tiles[i] . y , ctx - > tiles[i] . w , ctx - > tiles[i] . h ) ; } else if ( ctx - > tiles[i] . x + ctx - > tiles[i] . w > avctx - > width || ctx - > tiles[i] . y + ctx - > tiles[i] . h > avctx - > height ) { av_log ( avctx , AV_LOG_ERROR , out of bounds tile %d at ( %d . %d ) with size %dx%d . \n , i , ctx - > tiles[i] . x , ctx - > tiles[i] . y , ctx - > tiles[i] . w , ctx - > tiles[i] . h ) ; / * Reset the reader in case it had been modified before * / gbc = & ctx - > gbc ; / * Extract how much pixel data the tiles contain * / if ( pixel_size < 0x100 ) packed_size = bytestream2_get_byte ( gbc ) ; else if ( pixel_size < 0x10000 ) packed_size = bytestream2_get_le16 ( gbc ) ; else if ( pixel_size < 0x1000000 ) packed_size = bytestream2_get_le24 ( gbc ) ; else packed_size = bytestream2_get_le32 ( gbc ) ; ff_dlog ( avctx , pixel_size %d packed_size %d . \n , pixel_size , packed_size ) ; if ( packed_size < 0 ) { av_log ( avctx , AV_LOG_ERROR , Invalid tile size %d\n , packed_size ) ; / * Get pixels buffer , it may be deflated or just raw * / if ( pixel_size == packed_size ) { if ( bytestream2_get_bytes_left ( gbc ) < pixel_size ) { av_log ( avctx , AV_LOG_ERROR , Insufficient input for %d\n , pixel_size ) ; pixels = gbc - > buffer ; } else { uLongf len = ctx - > inflated_size ; if ( bytestream2_get_bytes_left ( gbc ) < packed_size ) { av_log ( avctx , AV_LOG_ERROR , Insufficient input for %d\n , packed_size ) ; ret = uncompress ( ctx - > inflated_buf , & len , gbc - > buffer , packed_size ) ; if ( ret ) { av_log ( avctx , AV_LOG_ERROR , Pixel deflate error %d . \n , ret ) ; ret = AVERROR_UNKNOWN ; pixels = ctx - > inflated_buf ; / * Allocate when needed * / ret = ff_reget_buffer ( avctx , ctx - > reference ) ; if ( ret < 0 ) / * Pointer to actual pixels , will be updated when data is consumed * / raw = pixels ; for ( i = 0 ; i < tiles_nb ; i + + ) { uint8_t * dst = ctx - > reference - > data[0] + ctx - > reference - > linesize[0] * ( avctx - > height - ctx - > tiles[i] . y - 1 ) + ctx - > tiles[i] . x * ctx - > component_size ; av_image_copy_plane ( dst , - 1 * ctx - > reference - > linesize[0] , raw , ctx - > tiles[i] . w * ctx - > component_size , ctx - > tiles[i] . w * ctx - > component_size , ctx - > tiles[i] . h ) ; raw + = ctx - > tiles[i] . w * ctx - > component_size * ctx - >",1
"static void swap_channel_layouts_on_filter ( AVFilterContext * filter ) { AVFilterLink * link = NULL ; int i , j , k ; for ( i = 0 ; i < filter - > nb_inputs ; i + + ) { link = filter - > inputs[i] ; if ( link - > type == AVMEDIA_TYPE_AUDIO & & link - > out_channel_layouts - > nb_channel_layouts == 1 ) break ; } if ( i == filter - > nb_inputs ) return ; for ( i = 0 ; i < filter - > nb_outputs ; i + + ) { AVFilterLink * outlink = filter - > outputs[i] ; int best_idx , best_score = INT_MIN , best_count_diff = INT_MAX ; if ( outlink - > type ! = AVMEDIA_TYPE_AUDIO || outlink - > in_channel_layouts - > nb_channel_layouts < 2 ) continue ; for ( j = 0 ; j < outlink - > in_channel_layouts - > nb_channel_layouts ; j + + ) { uint64_t in_chlayout = link - > out_channel_layouts - > channel_layouts[0] ; uint64_t out_chlayout = outlink - > in_channel_layouts - > channel_layouts[j] ; int in_channels = av_get_channel_layout_nb_channels ( in_chlayout ) ; int out_channels = av_get_channel_layout_nb_channels ( out_chlayout ) ; int count_diff = out_channels - in_channels ; int matched_channels , extra_channels ; int score = 0 ; / * channel substitution * / for ( k = 0 ; k < FF_ARRAY_ELEMS ( ch_subst ) ; k + + ) { uint64_t cmp0 = ch_subst[k][0] ; uint64_t cmp1 = ch_subst[k][1] ; if ( ( in_chlayout & cmp0 ) & & ( ! ( out_chlayout & cmp0 ) ) & & ( out_chlayout & cmp1 ) & & ( ! ( in_chlayout & cmp1 ) ) ) { in_chlayout & = cmp0 ; out_chlayout & = cmp1 ; / * add score for channel match , minus a deduction for having to do the substitution * / score + = 10 * av_get_channel_layout_nb_channels ( cmp1 ) - 2 ; } } / * no penalty for LFE channel mismatch * / if ( ( in_chlayout & AV_CH_LOW_FREQUENCY ) & & ( out_chlayout & AV_CH_LOW_FREQUENCY ) ) score + = 10 ; in_chlayout & = AV_CH_LOW_FREQUENCY ; out_chlayout & = AV_CH_LOW_FREQUENCY ; matched_channels = av_get_channel_layout_nb_channels ( in_chlayout & out_chlayout ) ; extra_channels = av_get_channel_layout_nb_channels ( out_chlayout & ( in_chlayout ) ) ; score + = 10 * matched_channels - 5 * extra_channels ; if ( score > best_score || ( count_diff < best_count_diff & & score == best_score ) ) { best_score = score ; best_idx = j ; best_count_diff = count_diff ; } } FFSWAP ( uint64_t , outlink - > in_channel_layouts - > channel_layouts[0] , outlink - > in_channel_layouts - > channel_layouts[best_idx] ) ; } }",1
"int img_convert ( AVPicture * dst , int dst_pix_fmt , const AVPicture * src , int src_pix_fmt , int src_width , int src_height ) { static int inited ; int i , ret , dst_width , dst_height , int_pix_fmt ; const PixFmtInfo * src_pix , * dst_pix ; const ConvertEntry * ce ; AVPicture tmp1 , * tmp = & tmp1 ; if ( src_pix_fmt < 0 || src_pix_fmt > = PIX_FMT_NB || dst_pix_fmt < 0 || dst_pix_fmt > = PIX_FMT_NB ) return - 1 ; if ( src_width < = 0 || src_height < = 0 ) return 0 ; if ( ! inited ) { inited = 1 ; img_convert_init ( ) ; } dst_width = src_width ; dst_height = src_height ; dst_pix = & pix_fmt_info[dst_pix_fmt] ; src_pix = & pix_fmt_info[src_pix_fmt] ; if ( src_pix_fmt == dst_pix_fmt ) { / * no conversion needed : just copy * / av_picture_copy ( dst , src , dst_pix_fmt , dst_width , dst_height ) ; return 0 ; } ce = & convert_table[src_pix_fmt][dst_pix_fmt] ; if ( ce - > convert ) { / * specific conversion routine * / ce - > convert ( dst , src , dst_width , dst_height ) ; return 0 ; } / * gray to YUV * / if ( is_yuv_planar ( dst_pix ) & & src_pix_fmt == PIX_FMT_GRAY8 ) { int w , h , y ; uint8_t * d ; if ( dst_pix - > color_type == FF_COLOR_YUV_JPEG ) { ff_img_copy_plane ( dst - > data[0] , dst - > linesize[0] , src - > data[0] , src - > linesize[0] , dst_width , dst_height ) ; } else { img_apply_table ( dst - > data[0] , dst - > linesize[0] , src - > data[0] , src - > linesize[0] , dst_width , dst_height , y_jpeg_to_ccir ) ; } / * fill U and V with 128 * / w = dst_width ; h = dst_height ; w > > = dst_pix - > x_chroma_shift ; h > > = dst_pix - > y_chroma_shift ; for ( i = 1 ; i < = 2 ; i + + ) { d = dst - > data[i] ; for ( y = 0 ; y < h ; y + + ) { memset ( d , 128 , w ) ; d + = dst - > linesize[i] ; } } return 0 ; } / * YUV to gray * / if ( is_yuv_planar ( src_pix ) & & dst_pix_fmt == PIX_FMT_GRAY8 ) { if ( src_pix - > color_type == FF_COLOR_YUV_JPEG ) { ff_img_copy_plane ( dst - > data[0] , dst - > linesize[0] , src - > data[0] , src - > linesize[0] , dst_width , dst_height ) ; } else { img_apply_table ( dst - > data[0] , dst - > linesize[0] , src - > data[0] , src - > linesize[0] , dst_width , dst_height , y_ccir_to_jpeg ) ; } return 0 ; } / * YUV to YUV planar * / if ( is_yuv_planar ( dst_pix ) & & is_yuv_planar ( src_pix ) ) { int x_shift , y_shift , w , h , xy_shift ; void ( * resize_func ) ( uint8_t * dst , int dst_wrap , const uint8_t * src , int src_wrap , int width , int height ) ; / * compute chroma size of the smallest dimensions * / w = dst_width ; h = dst_height ; if ( dst_pix - > x_chroma_shift > = src_pix - > x_chroma_shift ) w > > = dst_pix - > x_chroma_shift ; else w > > = src_pix - > x_chroma_shift ; if ( dst_pix - > y_chroma_shift > = src_pix - > y_chroma_shift ) h > > = dst_pix - > y_chroma_shift ; else h > > = src_pix - > y_chroma_shift ; x_shift = ( dst_pix - > x_chroma_shift - src_pix - > x_chroma_shift ) ; y_shift = ( dst_pix - > y_chroma_shift - src_pix - > y_chroma_shift ) ; xy_shift = ( ( x_shift & 0xf ) < < 4 ) | ( y_shift & 0xf ) ; / * there must be filters for conversion at least from and to YUV444 format * / switch ( xy_shift ) { case 0x00 : resize_func = ff_img_copy_plane ; break ; case 0x10 : resize_func = shrink21 ; break ; case 0x20 : resize_func = shrink41 ; break ; case 0x01 : resize_func = shrink12 ; break ; case 0x11 : resize_func = ff_shrink22 ; break ; case 0x22 : resize_func = ff_shrink44 ; break ; case 0xf0 : resize_func = grow21 ; break ; case 0x0f : resize_func = grow12 ; break ; case 0xe0 : resize_func = grow41 ; break ; case 0xff : resize_func = grow22 ; break ; case 0xee : resize_func = grow44 ; break ; case 0xf1 : resize_func = conv411 ; break ; default : / * currently not handled * / goto no_chroma_filter ; } ff_img_copy_plane ( dst - > data[0] , dst - > linesize[0] , src - > data[0] , src - > linesize[0] , dst_width , dst_height ) ; for ( i = 1 ; i < = 2 ; i + + ) resize_func ( dst - > data[i] , dst - > linesize[i] , src - > data[i] , src - > linesize[i] , dst_width > > dst_pix - > x_chroma_shift , dst_height > > dst_pix - > y_chroma_shift ) ; / * if yuv color space conversion is needed , we do it here on the destination image * / if ( dst_pix - > color_type ! = src_pix - > color_type ) { const uint8_t * y_table , * c_table ; if ( dst_pix - > color_type == FF_COLOR_YUV ) { y_table = y_jpeg_to_ccir ; c_table = c_jpeg_to_ccir ; } else { y_table = y_ccir_to_jpeg ; c_table = c_ccir_to_jpeg ; } img_apply_table ( dst - > data[0] , dst - > linesize[0] , dst - > data[0] , dst - > linesize[0] , dst_width , dst_height , y_table ) ; for ( i = 1 ; i < = 2 ; i + + ) img_apply_table ( dst - > data[i] , dst - > linesize[i] , dst - > data[i] , dst - > linesize[i] , dst_width > > dst_pix - > x_chroma_shift , dst_height > > dst_pix - > y_chroma_shift , c_table ) ; } return 0 ; } no_chroma_filter : / * try to use an intermediate format * / if ( src_pix_fmt == PIX_FMT_YUYV422 || dst_pix_fmt == PIX_FMT_YUYV422 ) { / * specific case : convert to YUV422P first * / int_pix_fmt = PIX_FMT_YUV422P ; } else if ( src_pix_fmt == PIX_FMT_UYVY422 || dst_pix_fmt == PIX_FMT_UYVY422 ) { / * specific case : convert to YUV422P first * / int_pix_fmt = PIX_FMT_YUV422P ; } else if ( src_pix_fmt == PIX_FMT_UYYVYY411 || dst_pix_fmt == PIX_FMT_UYYVYY411 ) { / * specific case : convert to YUV411P first * / int_pix_fmt = PIX_FMT_YUV411P ; } else if ( ( src_pix - > color_type == FF_COLOR_GRAY & & src_pix_fmt ! = PIX_FMT_GRAY8 ) || ( dst_pix - > color_type == FF_COLOR_GRAY & & dst_pix_fmt ! =",0
"static void nal_send ( AVFormatContext * ctx , const uint8_t * buf , int len , int last_packet_of_frame ) { RTPMuxContext * rtp_ctx = ctx - > priv_data ; int rtp_payload_size = rtp_ctx - > max_payload_size - RTP_HEVC_HEADERS_SIZE ; int nal_type = ( buf[0] > > 1 ) & 0x3F ; / * send it as one single NAL unit ? * / if ( len < = rtp_ctx - > max_payload_size ) { int buffered_size = rtp_ctx - > buf_ptr - rtp_ctx - > buf ; / * Flush buffered NAL units if the current unit doesn ' t fit * / if ( buffered_size + 2 + len > rtp_ctx - > max_payload_size ) { flush_buffered ( ctx , 0 ) ; buffered_size = 0 ; } / * If the NAL unit fits including the framing , write the unit * to the buffer as an aggregate packet , otherwise flush and * send as single NAL . * / if ( buffered_size + 4 + len < = rtp_ctx - > max_payload_size ) { if ( buffered_size == 0 ) { * rtp_ctx - > buf_ptr + + = 48 < < 1 ; * rtp_ctx - > buf_ptr + + = 1 ; } AV_WB16 ( rtp_ctx - > buf_ptr , len ) ; rtp_ctx - > buf_ptr + = 2 ; memcpy ( rtp_ctx - > buf_ptr , buf , len ) ; rtp_ctx - > buf_ptr + = len ; rtp_ctx - > buffered_nals + + ; } else { flush_buffered ( ctx , 0 ) ; ff_rtp_send_data ( ctx , buf , len , last_packet_of_frame ) ; } } else { flush_buffered ( ctx , 0 ) ; / * create the HEVC payload header and transmit the buffer as fragmentation units ( FU ) 0 1 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 + - + - + - + - + - + - + - + - + - + - + - + - + - + - + - + - + |F| Type | LayerId | TID | + - - - - - - - - - - - - - + - - - - - - - - - - - - - - - - - + F = 0 Type = 49 ( fragmentation unit ( FU ) ) LayerId = 0 TID = 1 * / rtp_ctx - > buf[0] = 49 < < 1 ; rtp_ctx - > buf[1] = 1 ; / * create the FU header 0 1 2 3 4 5 6 7 + - + - + - + - + - + - + - + - + |S|E| FuType | + - - - - - - - - - - - - - - - + S = variable E = variable FuType = NAL unit type * / rtp_ctx - > buf[2] = nal_type ; / * set the S bit : mark as start fragment * / rtp_ctx - > buf[2] |= 1 < < 7 ; / * pass the original NAL header * / buf + = 2 ; len - = 2 ; while ( len > rtp_payload_size ) { / * complete and send current RTP packet * / memcpy ( & rtp_ctx - > buf[RTP_HEVC_HEADERS_SIZE] , buf , rtp_payload_size ) ; ff_rtp_send_data ( ctx , rtp_ctx - > buf , rtp_ctx - > max_payload_size , 0 ) ; buf + = rtp_payload_size ; len - = rtp_payload_size ; / * reset the S bit * / rtp_ctx - > buf[2] & = ( 1 < < 7 ) ; } / * set the E bit : mark as last fragment * / rtp_ctx - > buf[2] |= 1 < < 6 ; / * complete and send last RTP packet * / memcpy ( & rtp_ctx - > buf[RTP_HEVC_HEADERS_SIZE] , buf , len ) ; ff_rtp_send_data ( ctx , rtp_ctx - > buf , len + 2 , last_packet_of_frame ) ; } }",1
"static void decode_band_structure ( GetBitContext * gbc , int blk , int eac3 , int ecpl , int start_subband , int end_subband , const uint8_t * default_band_struct , uint8_t * band_struct , int * num_subbands , int * num_bands , int * band_sizes ) { int subbnd , bnd , n_subbands , n_bands , bnd_sz[22] ; n_subbands = end_subband - start_subband ; / * decode band structure from bitstream or use default * / if ( ! eac3 || get_bits1 ( gbc ) ) { for ( subbnd = 0 ; subbnd < n_subbands - 1 ; subbnd + + ) { band_struct[subbnd] = get_bits1 ( gbc ) ; } } else if ( ! blk ) { memcpy ( band_struct , & default_band_struct[start_subband + 1] , n_subbands - 1 ) ; } band_struct[n_subbands - 1] = 0 ; / * calculate number of bands and band sizes based on band structure . note that the first 4 subbands in enhanced coupling span only 6 bins instead of 12 . * / if ( num_bands || band_sizes ) { n_bands = n_subbands ; bnd_sz[0] = ecpl ? 6 : 12 ; for ( bnd = 0 , subbnd = 1 ; subbnd < n_subbands ; subbnd + + ) { int subbnd_size = ( ecpl & & subbnd < 4 ) ? 6 : 12 ; if ( band_struct[subbnd - 1] ) { n_bands - - ; bnd_sz[bnd] + = subbnd_size ; } else { bnd_sz[ + + bnd] = subbnd_size ; } } } / * set optional output params * / if ( num_subbands ) * num_subbands = n_subbands ; if ( num_bands ) * num_bands = n_bands ; if ( band_sizes ) memcpy ( band_sizes , bnd_sz , sizeof ( int ) * n_bands ) ; }",1
"static int mimic_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; MimicContext * ctx = avctx - > priv_data ; GetByteContext gb ; int is_pframe ; int width , height ; int quality , num_coeffs ; int swap_buf_size = buf_size - MIMIC_HEADER_SIZE ; if ( buf_size < = MIMIC_HEADER_SIZE ) { av_log ( avctx , AV_LOG_ERROR , insufficient data\n ) ; return - 1 ; } bytestream2_init ( & gb , buf , MIMIC_HEADER_SIZE ) ; bytestream2_skip ( & gb , 2 ) ; / * some constant ( always 256 ) * / quality = bytestream2_get_le16u ( & gb ) ; width = bytestream2_get_le16u ( & gb ) ; height = bytestream2_get_le16u ( & gb ) ; bytestream2_skip ( & gb , 4 ) ; / * some constant * / is_pframe = bytestream2_get_le32u ( & gb ) ; num_coeffs = bytestream2_get_byteu ( & gb ) ; bytestream2_skip ( & gb , 3 ) ; / * some constant * / if ( ! ctx - > avctx ) { int i ; if ( ! ( width == 160 & & height == 120 ) & & ! ( width == 320 & & height == 240 ) ) { av_log ( avctx , AV_LOG_ERROR , invalid width/height ! \n ) ; return - 1 ; } ctx - > avctx = avctx ; avctx - > width = width ; avctx - > height = height ; avctx - > pix_fmt = PIX_FMT_YUV420P ; for ( i = 0 ; i < 3 ; i + + ) { ctx - > num_vblocks[i] = - ( ( - height ) > > ( 3 + ! ! i ) ) ; ctx - > num_hblocks[i] = width > > ( 3 + ! ! i ) ; } } else if ( width ! = ctx - > avctx - > width || height ! = ctx - > avctx - > height ) { av_log ( avctx , AV_LOG_ERROR , resolution changing is not supported\n ) ; return - 1 ; } if ( is_pframe & & ! ctx - > buf_ptrs[ctx - > prev_index] . data[0] ) { av_log ( avctx , AV_LOG_ERROR , decoding must start with keyframe\n ) ; return - 1 ; } ctx - > buf_ptrs[ctx - > cur_index] . reference = 1 ; ctx - > buf_ptrs[ctx - > cur_index] . pict_type = is_pframe ? AV_PICTURE_TYPE_P : AV_PICTURE_TYPE_I ; if ( ff_thread_get_buffer ( avctx , & ctx - > buf_ptrs[ctx - > cur_index] ) ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed\n ) ; return - 1 ; } ctx - > next_prev_index = ctx - > cur_index ; ctx - > next_cur_index = ( ctx - > cur_index - 1 ) & 15 ; prepare_avpic ( ctx , & ctx - > flipped_ptrs[ctx - > cur_index] , ( AVPicture * ) & ctx - > buf_ptrs[ctx - > cur_index] ) ; ff_thread_finish_setup ( avctx ) ; av_fast_malloc ( & ctx - > swap_buf , & ctx - > swap_buf_size , swap_buf_size + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! ctx - > swap_buf ) return AVERROR ( ENOMEM ) ; ctx - > dsp . bswap_buf ( ctx - > swap_buf , ( const uint32_t * ) ( buf + MIMIC_HEADER_SIZE ) , swap_buf_size > > 2 ) ; init_get_bits ( & ctx - > gb , ctx - > swap_buf , swap_buf_size < < 3 ) ; if ( ! decode ( ctx , quality , num_coeffs , ! is_pframe ) ) { if ( avctx - > active_thread_type & FF_THREAD_FRAME ) ff_thread_report_progress ( & ctx - > buf_ptrs[ctx - > cur_index] , INT_MAX , 0 ) ; else { ff_thread_release_buffer ( avctx , & ctx - > buf_ptrs[ctx - > cur_index] ) ; return - 1 ; } } * ( AVFrame * ) data = ctx - > buf_ptrs[ctx - > cur_index] ; * data_size = sizeof ( AVFrame ) ; ctx - > prev_index = ctx - > next_prev_index ; ctx - > cur_index = ctx - > next_cur_index ; / * Only release frames that aren ' t used for backreferences anymore * / if ( ctx - > buf_ptrs[ctx - > cur_index] . data[0] ) ff_thread_release_buffer ( avctx , & ctx - > buf_ptrs[ctx - > cur_index] ) ; return buf_size ; }",1
"static void init_coef_vlc ( VLC * vlc , uint16_t * * prun_table , uint16_t * * plevel_table , const CoefVLCTable * vlc_table ) { int n = vlc_table - > n ; const uint8_t * table_bits = vlc_table - > huffbits ; const uint32_t * table_codes = vlc_table - > huffcodes ; const uint16_t * levels_table = vlc_table - > levels ; uint16_t * run_table , * level_table ; const uint16_t * p ; int i , l , j , level ; init_vlc ( vlc , 9 , n , table_bits , 1 , 1 , table_codes , 4 , 4 ) ; run_table = av_malloc ( n * sizeof ( uint16_t ) ) ; level_table = av_malloc ( n * sizeof ( uint16_t ) ) ; p = levels_table ; i = 2 ; level = 1 ; while ( i < n ) { l = * p + + ; for ( j=0 ; j < l ; j + + ) { run_table[i] = j ; level_table[i] = level ; i + + ; } level + + ; } * prun_table = run_table ; * plevel_table = level_table ; }",1
"static int avisynth_read_packet_video ( AVFormatContext * s , AVPacket * pkt , int discard ) { AviSynthContext * avs = s - > priv_data ; AVS_VideoFrame * frame ; unsigned char * dst_p ; const unsigned char * src_p ; int n , i , plane , rowsize , planeheight , pitch , bits ; const char * error ; if ( avs - > curr_frame > = avs - > vi - > num_frames ) return AVERROR_EOF ; / * This must happen even if the stream is discarded to prevent desync . * / n = avs - > curr_frame + + ; if ( discard ) return 0 ; ifdef USING_AVISYNTH / * Define the bpp values for the new AviSynth 2 . 6 colorspaces . * Since AvxSynth doesn ' t have these functions , special - case * it in order to avoid implicit declaration errors . * / if ( avs_library . avs_is_yv24 ( avs - > vi ) ) bits = 24 ; else if ( avs_library . avs_is_yv16 ( avs - > vi ) ) bits = 16 ; else if ( avs_library . avs_is_yv411 ( avs - > vi ) ) bits = 12 ; else if ( avs_library . avs_is_y8 ( avs - > vi ) ) bits = 8 ; else bits = avs_library . avs_bits_per_pixel ( avs - > vi ) ; else bits = avs_bits_per_pixel ( avs - > vi ) ; endif / * Without the cast to int64_t , calculation overflows at about 9k x 9k * resolution . * / pkt - > size = ( ( ( int64_t ) avs - > vi - > width * ( int64_t ) avs - > vi - > height ) * bits ) / 8 ; if ( ! pkt - > size ) return AVERROR_UNKNOWN ; if ( av_new_packet ( pkt , pkt - > size ) < 0 ) return AVERROR ( ENOMEM ) ; pkt - > pts = n ; pkt - > dts = n ; pkt - > duration = 1 ; pkt - > stream_index = avs - > curr_stream ; frame = avs_library . avs_get_frame ( avs - > clip , n ) ; error = avs_library . avs_clip_get_error ( avs - > clip ) ; if ( error ) { av_log ( s , AV_LOG_ERROR , %s\n , error ) ; avs - > error = 1 ; av_packet_unref ( pkt ) ; return AVERROR_UNKNOWN ; } dst_p = pkt - > data ; for ( i = 0 ; i < avs - > n_planes ; i + + ) { plane = avs - > planes[i] ; ifdef USING_AVISYNTH src_p = avs_library . avs_get_read_ptr_p ( frame , plane ) ; pitch = avs_library . avs_get_pitch_p ( frame , plane ) ; rowsize = avs_library . avs_get_row_size_p ( frame , plane ) ; planeheight = avs_library . avs_get_height_p ( frame , plane ) ; else src_p = avs_get_read_ptr_p ( frame , plane ) ; pitch = avs_get_pitch_p ( frame , plane ) ; rowsize = avs_get_row_size_p ( frame , plane ) ; planeheight = avs_get_height_p ( frame , plane ) ; endif / * Flip RGB video . * / if ( avs_is_rgb24 ( avs - > vi ) || avs_is_rgb ( avs - > vi ) ) { src_p = src_p + ( planeheight - 1 ) * pitch ; pitch = - pitch ; } avs_library . avs_bit_blt ( avs - > env , dst_p , rowsize , src_p , pitch , rowsize , planeheight ) ; dst_p + = rowsize * planeheight ; } avs_library . avs_release_video_frame ( frame ) ; return 0 ; }",0
"static void avc_luma_midh_qrt_and_aver_dst_16w_msa ( const uint8_t * src , int32_t src_stride , uint8_t * dst , int32_t dst_stride , int32_t height , uint8_t horiz_offset ) { uint32_t multiple8_cnt ; for ( multiple8_cnt = 4 ; multiple8_cnt - - ; ) { avc_luma_midh_qrt_and_aver_dst_4w_msa ( src , src_stride , dst , dst_stride , height , horiz_offset ) ; src + = 4 ; dst + = 4 ; } }",0
"static int tiff_decode_tag ( TiffContext * s , AVFrame * frame ) { unsigned tag , type , count , off , value = 0 , value2 = 0 ; int i , start ; int pos ; int ret ; double * dp ; ret = ff_tread_tag ( & s - > gb , s - > le , & tag , & type , & count , & start ) ; if ( ret < 0 ) { goto end ; off = bytestream2_tell ( & s - > gb ) ; if ( count == 1 ) { switch ( type ) { case TIFF_BYTE : case TIFF_SHORT : case TIFF_LONG : value = ff_tget ( & s - > gb , type , s - > le ) ; break ; case TIFF_RATIONAL : value = ff_tget ( & s - > gb , TIFF_LONG , s - > le ) ; value2 = ff_tget ( & s - > gb , TIFF_LONG , s - > le ) ; break ; case TIFF_STRING : if ( count < = 4 ) { break ; default : value = UINT_MAX ; switch ( tag ) { case TIFF_WIDTH : s - > width = value ; break ; case TIFF_HEIGHT : s - > height = value ; break ; case TIFF_BPP : if ( count > 4U ) { This format is not supported ( bpp=%d , %d components ) \n , value , count ) ; s - > bppcount = count ; if ( count == 1 ) s - > bpp = value ; else { switch ( type ) { case TIFF_BYTE : case TIFF_SHORT : case TIFF_LONG : s - > bpp = 0 ; if ( bytestream2_get_bytes_left ( & s - > gb ) < type_sizes[type] * count ) for ( i = 0 ; i < count ; i + + ) s - > bpp + = ff_tget ( & s - > gb , type , s - > le ) ; break ; default : s - > bpp = - 1 ; break ; case TIFF_SAMPLES_PER_PIXEL : if ( count ! = 1 ) { Samples per pixel requires a single value , many provided\n ) ; if ( value > 4U ) { Samples per pixel %d is too large\n , value ) ; if ( s - > bppcount == 1 ) s - > bpp * = value ; s - > bppcount = value ; break ; case TIFF_COMPR : s - > compr = value ; av_log ( s - > avctx , AV_LOG_DEBUG , compression : %d\n , s - > compr ) ; s - > predictor = 0 ; switch ( s - > compr ) { case TIFF_RAW : case TIFF_PACKBITS : case TIFF_LZW : case TIFF_CCITT_RLE : break ; case TIFF_G3 : case TIFF_G4 : s - > fax_opts = 0 ; break ; case TIFF_DEFLATE : case TIFF_ADOBE_DEFLATE : if CONFIG_ZLIB break ; else av_log ( s - > avctx , AV_LOG_ERROR , Deflate : ZLib not compiled in\n ) ; return AVERROR ( ENOSYS ) ; endif case TIFF_JPEG : case TIFF_NEWJPEG : avpriv_report_missing_feature ( s - > avctx , JPEG compression ) ; return AVERROR_PATCHWELCOME ; case TIFF_LZMA : if CONFIG_LZMA break ; else av_log ( s - > avctx , AV_LOG_ERROR , LZMA not compiled in\n ) ; return AVERROR ( ENOSYS ) ; endif default : av_log ( s - > avctx , AV_LOG_ERROR , Unknown compression method %i\n , s - > compr ) ; break ; case TIFF_ROWSPERSTRIP : if ( ! value || ( type == TIFF_LONG & & value == UINT_MAX ) ) value = s - > height ; s - > rps = FFMIN ( value , s - > height ) ; break ; case TIFF_STRIP_OFFS : if ( count == 1 ) { s - > strippos = 0 ; s - > stripoff = value ; } else s - > strippos = off ; s - > strips = count ; if ( s - > strips == 1 ) s - > rps = s - > height ; s - > sot = type ; break ; case TIFF_STRIP_SIZE : if ( count == 1 ) { stripsize %u too large\n , value ) ; s - > stripsizesoff = 0 ; s - > stripsize = value ; s - > strips = 1 ; } else { s - > stripsizesoff = off ; s - > strips = count ; s - > sstype = type ; break ; case TIFF_XRES : case TIFF_YRES : set_sar ( s , tag , value , value2 ) ; break ; case TIFF_TILE_BYTE_COUNTS : case TIFF_TILE_LENGTH : case TIFF_TILE_OFFSETS : case TIFF_TILE_WIDTH : av_log ( s - > avctx , AV_LOG_ERROR , Tiled images are not supported\n ) ; return AVERROR_PATCHWELCOME ; break ; case TIFF_PREDICTOR : s - > predictor = value ; break ; case TIFF_PHOTOMETRIC : switch ( value ) { case TIFF_PHOTOMETRIC_WHITE_IS_ZERO : case TIFF_PHOTOMETRIC_BLACK_IS_ZERO : case TIFF_PHOTOMETRIC_RGB : case TIFF_PHOTOMETRIC_PALETTE : case TIFF_PHOTOMETRIC_YCBCR : s - > photometric = value ; break ; case TIFF_PHOTOMETRIC_ALPHA_MASK : case TIFF_PHOTOMETRIC_SEPARATED : case TIFF_PHOTOMETRIC_CIE_LAB : case TIFF_PHOTOMETRIC_ICC_LAB : case TIFF_PHOTOMETRIC_ITU_LAB : case TIFF_PHOTOMETRIC_CFA : case TIFF_PHOTOMETRIC_LOG_L : case TIFF_PHOTOMETRIC_LOG_LUV : case TIFF_PHOTOMETRIC_LINEAR_RAW : avpriv_report_missing_feature ( s - > avctx , PhotometricInterpretation 0x%04X , value ) ; return AVERROR_PATCHWELCOME ; default : av_log ( s - > avctx , AV_LOG_ERROR , PhotometricInterpretation %u is unknown\n , value ) ; break ; case TIFF_FILL_ORDER : if ( value < 1 || value > 2 ) { Unknown FillOrder value %d , trying default one\n , value ) ; value = 1 ; s - > fill_order = value - 1 ; break ; case TIFF_PAL : { GetByteContext pal_gb[3] ; off = type_sizes[type] ; if ( count / 3 > 256 || bytestream2_get_bytes_left ( & s - > gb ) < count / 3 * off * 3 ) pal_gb[0] = pal_gb[1] = pal_gb[2] = s - > gb ; bytestream2_skip ( & pal_gb[1] , count / 3 * off ) ; bytestream2_skip ( & pal_gb[2] , count / 3 * off * 2 ) ; off = ( type_sizes[type] - 1 ) < < 3 ; if ( off > 31U ) { av_log ( s - > avctx , AV_LOG_ERROR , palette shift %d is out of range\n , off ) ; for ( i = 0 ; i < count / 3 ; i + + ) { uint32_t p = 0xFF000000 ; p |= ( ff_tget ( & pal_gb[0] , type , s - > le ) > > off ) < < 16 ; p |= ( ff_tget ( & pal_gb[1] , type , s - > le ) > > off ) < < 8 ; p |= ff_tget ( & pal_gb[2] , type , s - > le ) > > off ; s - > palette[i] = p ; s - > palette_is_set = 1 ; break ; case",1
"static av_cold int fieldmatch_init ( AVFilterContext * ctx ) { const FieldMatchContext * fm = ctx - > priv ; AVFilterPad pad = { . name = av_strdup ( main ) , . type = AVMEDIA_TYPE_VIDEO , . filter_frame = filter_frame , . config_props = config_input , } ; if ( ! pad . name ) return AVERROR ( ENOMEM ) ; ff_insert_inpad ( ctx , INPUT_MAIN , & pad ) ; if ( fm - > ppsrc ) { pad . name = av_strdup ( clean_src ) ; pad . config_props = NULL ; if ( ! pad . name ) return AVERROR ( ENOMEM ) ; ff_insert_inpad ( ctx , INPUT_CLEANSRC , & pad ) ; } if ( ( fm - > blockx & ( fm - > blockx - 1 ) ) || ( fm - > blocky & ( fm - > blocky - 1 ) ) ) { av_log ( ctx , AV_LOG_ERROR , blockx and blocky settings must be power of two\n ) ; return AVERROR ( EINVAL ) ; } if ( fm - > combpel > fm - > blockx * fm - > blocky ) { av_log ( ctx , AV_LOG_ERROR , Combed pixel should not be larger than blockx x blocky\n ) ; return AVERROR ( EINVAL ) ; } return 0 ; }",1
"void avpriv_tak_parse_streaminfo ( GetBitContext * gb , TAKStreamInfo * s ) { uint64_t channel_mask = 0 ; int frame_type , i ; s - > codec = get_bits ( gb , TAK_ENCODER_CODEC_BITS ) ; skip_bits ( gb , TAK_ENCODER_PROFILE_BITS ) ; frame_type = get_bits ( gb , TAK_SIZE_FRAME_DURATION_BITS ) ; s - > samples = get_bits64 ( gb , TAK_SIZE_SAMPLES_NUM_BITS ) ; s - > data_type = get_bits ( gb , TAK_FORMAT_DATA_TYPE_BITS ) ; s - > sample_rate = get_bits ( gb , TAK_FORMAT_SAMPLE_RATE_BITS ) + TAK_SAMPLE_RATE_MIN ; s - > bps = get_bits ( gb , TAK_FORMAT_BPS_BITS ) + TAK_BPS_MIN ; s - > channels = get_bits ( gb , TAK_FORMAT_CHANNEL_BITS ) + TAK_CHANNELS_MIN ; if ( get_bits1 ( gb ) ) { skip_bits ( gb , TAK_FORMAT_VALID_BITS ) ; if ( get_bits1 ( gb ) ) { for ( i = 0 ; i < s - > channels ; i + + ) { int value = get_bits ( gb , TAK_FORMAT_CH_LAYOUT_BITS ) ; if ( value < FF_ARRAY_ELEMS ( tak_channel_layouts ) ) channel_mask |= tak_channel_layouts[value] ; } } } s - > ch_layout = channel_mask ; s - > frame_samples = tak_get_nb_samples ( s - > sample_rate , frame_type ) ; }",0
"int show_formats ( void * optctx , const char * opt , const char * arg ) { AVInputFormat * ifmt = NULL ; AVOutputFormat * ofmt = NULL ; const char * last_name ; printf ( File formats : \n D . = Demuxing supported\n . E = Muxing supported\n - - \n ) ; last_name = 000 ; for ( ; ; ) { int decode = 0 ; int encode = 0 ; const char * name = NULL ; const char * long_name = NULL ; while ( ( ofmt = av_oformat_next ( ofmt ) ) ) { if ( ( name == NULL || strcmp ( ofmt - > name , name ) < 0 ) & & strcmp ( ofmt - > name , last_name ) > 0 ) { name = ofmt - > name ; long_name = ofmt - > long_name ; encode = 1 ; } } while ( ( ifmt = av_iformat_next ( ifmt ) ) ) { if ( ( name == NULL || strcmp ( ifmt - > name , name ) < 0 ) & & strcmp ( ifmt - > name , last_name ) > 0 ) { name = ifmt - > name ; long_name = ifmt - > long_name ; encode = 0 ; } if ( name & & strcmp ( ifmt - > name , name ) == 0 ) decode = 1 ; } if ( name == NULL ) break ; last_name = name ; printf ( %s%s % - 15s %s\n , decode ? D : , encode ? E : , name , long_name ? long_name : ) ; } return 0 ; }",0
"static void SET_TYPE ( resample_nearest ) ( void * dst0 , int dst_index , const void * src0 , int index ) { FELEM * dst = dst0 ; const FELEM * src = src0 ; dst[dst_index] = src[index] ; }",0
"static inline void mc_dir_part ( H264Context * h , Picture * pic , int n , int square , int chroma_height , int delta , int list , uint8_t * dest_y , uint8_t * dest_cb , uint8_t * dest_cr , int src_x_offset , int src_y_offset , qpel_mc_func * qpix_op , h264_chroma_mc_func chroma_op ) { MpegEncContext * const s = & h - > s ; const int mx= h - > mv_cache[list][ scan8[n] ][0] + src_x_offset * 8 ; int my= h - > mv_cache[list][ scan8[n] ][1] + src_y_offset * 8 ; const int luma_xy= ( mx & 3 ) + ( ( my & 3 ) < < 2 ) ; uint8_t * src_y = pic - > data[0] + ( mx > > 2 ) + ( my > > 2 ) * h - > mb_linesize ; uint8_t * src_cb , * src_cr ; int extra_width= h - > emu_edge_width ; int extra_height= h - > emu_edge_height ; int emu=0 ; const int full_mx= mx > > 2 ; const int full_my= my > > 2 ; const int pic_width = 16 * s - > mb_width ; const int pic_height = 16 * s - > mb_height > > MB_FIELD ; if ( ! pic - > data[0] ) //FIXME this is unacceptable , some sensible error concealment must be done for missing reference frames return ; if ( mx & 7 ) extra_width - = 3 ; if ( my & 7 ) extra_height - = 3 ; if ( full_mx < 0 - extra_width || full_my < 0 - extra_height || full_mx + 16 / * FIXME * / > pic_width + extra_width || full_my + 16 / * FIXME * / > pic_height + extra_height ) { ff_emulated_edge_mc ( s - > edge_emu_buffer , src_y - 2 - 2 * h - > mb_linesize , h - > mb_linesize , 16 + 5 , 16 + 5 / * FIXME * / , full_mx - 2 , full_my - 2 , pic_width , pic_height ) ; src_y= s - > edge_emu_buffer + 2 + 2 * h - > mb_linesize ; emu=1 ; } qpix_op[luma_xy] ( dest_y , src_y , h - > mb_linesize ) ; //FIXME try variable height perhaps ? if ( ! square ) { qpix_op[luma_xy] ( dest_y + delta , src_y + delta , h - > mb_linesize ) ; } if ( ENABLE_GRAY & & s - > flags & CODEC_FLAG_GRAY ) return ; if ( MB_FIELD ) { // chroma offset when predicting from a field of opposite parity my + = 2 * ( ( s - > mb_y & 1 ) - ( pic - > reference - 1 ) ) ; emu |= ( my > > 3 ) < 0 || ( my > > 3 ) + 8 > = ( pic_height > > 1 ) ; } src_cb= pic - > data[1] + ( mx > > 3 ) + ( my > > 3 ) * h - > mb_uvlinesize ; src_cr= pic - > data[2] + ( mx > > 3 ) + ( my > > 3 ) * h - > mb_uvlinesize ; if ( emu ) { ff_emulated_edge_mc ( s - > edge_emu_buffer , src_cb , h - > mb_uvlinesize , 9 , 9 / * FIXME * / , ( mx > > 3 ) , ( my > > 3 ) , pic_width > > 1 , pic_height > > 1 ) ; src_cb= s - > edge_emu_buffer ; } chroma_op ( dest_cb , src_cb , h - > mb_uvlinesize , chroma_height , mx & 7 , my & 7 ) ; if ( emu ) { ff_emulated_edge_mc ( s - > edge_emu_buffer , src_cr , h - > mb_uvlinesize , 9 , 9 / * FIXME * / , ( mx > > 3 ) , ( my > > 3 ) , pic_width > > 1 , pic_height > > 1 ) ; src_cr= s - > edge_emu_buffer ; } chroma_op ( dest_cr , src_cr , h - > mb_uvlinesize , chroma_height , mx & 7 , my & 7 ) ; }",0
"static void rtsp_send_cmd ( AVFormatContext * s , const char * cmd , RTSPMessageHeader * reply , unsigned char * * content_ptr ) { RTSPState * rt = s - > priv_data ; char buf[4096] , buf1[1024] ; rt - > seq + + ; av_strlcpy ( buf , cmd , sizeof ( buf ) ) ; snprintf ( buf1 , sizeof ( buf1 ) , CSeq : %d\r\n , rt - > seq ) ; av_strlcat ( buf , buf1 , sizeof ( buf ) ) ; if ( rt - > session_id[0] ! = ' \0 ' & & ! strstr ( cmd , \nIf - Match : ) ) { snprintf ( buf1 , sizeof ( buf1 ) , Session : %s\r\n , rt - > session_id ) ; av_strlcat ( buf , buf1 , sizeof ( buf ) ) ; } av_strlcat ( buf , \r\n , sizeof ( buf ) ) ; ifdef DEBUG printf ( Sending : \n%s - - \n , buf ) ; endif url_write ( rt - > rtsp_hd , buf , strlen ( buf ) ) ; rtsp_read_reply ( rt , reply , content_ptr ) ; }",0
"static int configure_video_filters ( AVFilterGraph * graph , VideoState * is , const char * vfilters ) { static const enum PixelFormat pix_fmts[] = { PIX_FMT_YUV420P , PIX_FMT_NONE } ; char sws_flags_str[128] ; char buffersrc_args[256] ; int ret ; AVBufferSinkParams * buffersink_params = av_buffersink_params_alloc ( ) ; AVFilterContext * filt_src = NULL , * filt_out = NULL , * filt_format ; AVCodecContext * codec = is - > video_st - > codec ; snprintf ( sws_flags_str , sizeof ( sws_flags_str ) , flags=%d , sws_flags ) ; graph - > scale_sws_opts = av_strdup ( sws_flags_str ) ; snprintf ( buffersrc_args , sizeof ( buffersrc_args ) , video_size=%dx%d : pix_fmt=%d : time_base=%d/%d : pixel_aspect=%d/%d , codec - > width , codec - > height , codec - > pix_fmt , is - > video_st - > time_base . num , is - > video_st - > time_base . den , codec - > sample_aspect_ratio . num , codec - > sample_aspect_ratio . den ) ; if ( ( ret = avfilter_graph_create_filter ( & filt_src , avfilter_get_by_name ( buffer ) , ffplay_buffer , buffersrc_args , NULL , graph ) ) < 0 ) return ret ; buffersink_params - > pixel_fmts = pix_fmts ; ret = avfilter_graph_create_filter ( & filt_out , avfilter_get_by_name ( buffersink ) , ffplay_buffersink , NULL , buffersink_params , graph ) ; av_freep ( & buffersink_params ) ; if ( ret < 0 ) return ret ; if ( ( ret = avfilter_graph_create_filter ( & filt_format , avfilter_get_by_name ( format ) , format , yuv420p , NULL , graph ) ) < 0 ) return ret ; if ( ( ret = avfilter_link ( filt_format , 0 , filt_out , 0 ) ) < 0 ) return ret ; if ( vfilters ) { AVFilterInOut * outputs = avfilter_inout_alloc ( ) ; AVFilterInOut * inputs = avfilter_inout_alloc ( ) ; outputs - > name = av_strdup ( in ) ; outputs - > filter_ctx = filt_src ; outputs - > pad_idx = 0 ; outputs - > next = NULL ; inputs - > name = av_strdup ( out ) ; inputs - > filter_ctx = filt_format ; inputs - > pad_idx = 0 ; inputs - > next = NULL ; if ( ( ret = avfilter_graph_parse ( graph , vfilters , & inputs , & outputs , NULL ) ) < 0 ) return ret ; } else { if ( ( ret = avfilter_link ( filt_src , 0 , filt_format , 0 ) ) < 0 ) return ret ; } if ( ( ret = avfilter_graph_config ( graph , NULL ) ) < 0 ) return ret ; is - > in_video_filter = filt_src ; is - > out_video_filter = filt_out ; if ( codec - > codec - > capabilities & CODEC_CAP_DR1 ) { is - > use_dr1 = 1 ; codec - > get_buffer = codec_get_buffer ; codec - > release_buffer = codec_release_buffer ; codec - > opaque = & is - > buffer_pool ; } return ret ; }",0
"static int x8_setup_spatial_predictor ( IntraX8Context * const w , const int chroma ) { MpegEncContext * const s= w - > s ; int range ; int sum ; int quant ; w - > dsp . setup_spatial_compensation ( s - > dest[chroma] , s - > edge_emu_buffer , s - > current_picture . f . linesize[chroma > 0] , & range , & sum , w - > edges ) ; if ( chroma ) { w - > orient=w - > chroma_orient ; quant=w - > quant_dc_chroma ; } else { quant=w - > quant ; } w - > flat_dc=0 ; if ( range < quant || range < 3 ) { w - > orient=0 ; if ( range < 3 ) { //yep you read right , a + - 1 idct error may break decoding ! w - > flat_dc=1 ; sum + =9 ; w - > predicted_dc = ( sum * 6899 ) > > 17 ; // ( ( 1 < < 17 ) + 9 ) / ( 8 + 8 + 1 + 2 ) =6899 } } if ( chroma ) return 0 ; assert ( w - > orient < 3 ) ; if ( range < 2 * w - > quant ) { if ( ( w - > edges & 3 ) == 0 ) { if ( w - > orient==1 ) w - > orient=11 ; if ( w - > orient==2 ) w - > orient=10 ; } else { w - > orient=0 ; } w - > raw_orient=0 ; } else { static const uint8_t prediction_table[3][12]= { { 0 , 8 , 4 , 10 , 11 , 2 , 6 , 9 , 1 , 3 , 5 , 7 } , { 4 , 0 , 8 , 11 , 10 , 3 , 5 , 2 , 6 , 9 , 1 , 7 } , { 8 , 0 , 4 , 10 , 11 , 1 , 7 , 2 , 6 , 9 , 3 , 5 } } ; w - > raw_orient=x8_get_orient_vlc ( w ) ; if ( w - > raw_orient < 0 ) return - 1 ; assert ( w - > raw_orient < 12 ) ; assert ( w - > orient < 3 ) ; w - > orient=prediction_table[w - > orient][w - > raw_orient] ; } return 0 ; }",1
"static void vc1_mc_4mv_chroma4 ( VC1Context * v , int dir , int dir2 , int avg ) { MpegEncContext * s = & v - > s ; H264ChromaContext * h264chroma = & v - > h264chroma ; uint8_t * srcU , * srcV ; int uvsrc_x , uvsrc_y ; int uvmx_field[4] , uvmy_field[4] ; int i , off , tx , ty ; int fieldmv = v - > blk_mv_type[s - > block_index[0]] ; static const int s_rndtblfield[16] = { 0 , 0 , 1 , 2 , 4 , 4 , 5 , 6 , 2 , 2 , 3 , 8 , 6 , 6 , 7 , 12 } ; int v_dist = fieldmv ? 1 : 4 ; // vertical offset for lower sub - blocks int v_edge_pos = s - > v_edge_pos > > 1 ; int use_ic ; uint8_t ( * lutuv ) [256] ; if ( s - > flags & CODEC_FLAG_GRAY ) return ; for ( i = 0 ; i < 4 ; i + + ) { int d = i < 2 ? dir : dir2 ; tx = s - > mv[d][i][0] ; uvmx_field[i] = ( tx + ( ( tx & 3 ) == 3 ) ) > > 1 ; ty = s - > mv[d][i][1] ; if ( fieldmv ) uvmy_field[i] = ( ty > > 4 ) * 8 + s_rndtblfield[ty & 0xF] ; else uvmy_field[i] = ( ty + ( ( ty & 3 ) == 3 ) ) > > 1 ; } for ( i = 0 ; i < 4 ; i + + ) { off = ( i & 1 ) * 4 + ( ( i & 2 ) ? v_dist * s - > uvlinesize : 0 ) ; uvsrc_x = s - > mb_x * 8 + ( i & 1 ) * 4 + ( uvmx_field[i] > > 2 ) ; uvsrc_y = s - > mb_y * 8 + ( ( i & 2 ) ? v_dist : 0 ) + ( uvmy_field[i] > > 2 ) ; // FIXME : implement proper pull - back ( see vc1cropmv . c , vc1CROPMV_ChromaPullBack ( ) ) uvsrc_x = av_clip ( uvsrc_x , - 8 , s - > avctx - > coded_width > > 1 ) ; uvsrc_y = av_clip ( uvsrc_y , - 8 , s - > avctx - > coded_height > > 1 ) ; if ( i < 2 ? dir : dir2 ) { srcU = s - > next_picture . f . data[1] + uvsrc_y * s - > uvlinesize + uvsrc_x ; srcV = s - > next_picture . f . data[2] + uvsrc_y * s - > uvlinesize + uvsrc_x ; lutuv = v - > next_lutuv ; use_ic = v - > next_use_ic ; } else { srcU = s - > last_picture . f . data[1] + uvsrc_y * s - > uvlinesize + uvsrc_x ; srcV = s - > last_picture . f . data[2] + uvsrc_y * s - > uvlinesize + uvsrc_x ; lutuv = v - > last_lutuv ; use_ic = v - > last_use_ic ; } uvmx_field[i] = ( uvmx_field[i] & 3 ) < < 1 ; uvmy_field[i] = ( uvmy_field[i] & 3 ) < < 1 ; if ( fieldmv & & ! ( uvsrc_y & 1 ) ) v_edge_pos - - ; if ( fieldmv & & ( uvsrc_y & 1 ) & & uvsrc_y < 2 ) uvsrc_y - - ; if ( use_ic || s - > h_edge_pos < 10 || v_edge_pos < ( 5 < < fieldmv ) || ( unsigned ) uvsrc_x > ( s - > h_edge_pos > > 1 ) - 5 || ( unsigned ) uvsrc_y > v_edge_pos - ( 5 < < fieldmv ) ) { s - > vdsp . emulated_edge_mc ( s - > edge_emu_buffer , srcU , s - > uvlinesize , s - > uvlinesize , 5 , ( 5 < < fieldmv ) , uvsrc_x , uvsrc_y , s - > h_edge_pos > > 1 , v_edge_pos ) ; s - > vdsp . emulated_edge_mc ( s - > edge_emu_buffer + 16 , srcV , s - > uvlinesize , s - > uvlinesize , 5 , ( 5 < < fieldmv ) , uvsrc_x , uvsrc_y , s - > h_edge_pos > > 1 , v_edge_pos ) ; srcU = s - > edge_emu_buffer ; srcV = s - > edge_emu_buffer + 16 ; / * if we deal with intensity compensation we need to scale source blocks * / if ( use_ic ) { int i , j ; uint8_t * src , * src2 ; src = srcU ; src2 = srcV ; for ( j = 0 ; j < 5 ; j + + ) { int f = ( uvsrc_y + ( j < < fieldmv ) ) & 1 ; for ( i = 0 ; i < 5 ; i + + ) { src[i] = lutuv[f][src[i]] ; src2[i] = lutuv[f][src2[i]] ; } src + = s - > uvlinesize < < fieldmv ; src2 + = s - > uvlinesize < < fieldmv ; } } } if ( avg ) { if ( ! v - > rnd ) { h264chroma - > avg_h264_chroma_pixels_tab[1] ( s - > dest[1] + off , srcU , s - > uvlinesize < < fieldmv , 4 , uvmx_field[i] , uvmy_field[i] ) ; h264chroma - > avg_h264_chroma_pixels_tab[1] ( s - > dest[2] + off , srcV , s - > uvlinesize < < fieldmv , 4 , uvmx_field[i] , uvmy_field[i] ) ; } else { v - > vc1dsp . avg_no_rnd_vc1_chroma_pixels_tab[1] ( s - > dest[1] + off , srcU , s - > uvlinesize < < fieldmv , 4 , uvmx_field[i] , uvmy_field[i] ) ; v - > vc1dsp . avg_no_rnd_vc1_chroma_pixels_tab[1] ( s - > dest[2] + off , srcV , s - > uvlinesize < < fieldmv , 4 , uvmx_field[i] , uvmy_field[i] ) ; } } else { if ( ! v - > rnd ) { h264chroma - > put_h264_chroma_pixels_tab[1] ( s - > dest[1] + off , srcU , s - > uvlinesize < < fieldmv , 4 , uvmx_field[i] , uvmy_field[i] ) ; h264chroma - > put_h264_chroma_pixels_tab[1] ( s - > dest[2] + off , srcV , s - > uvlinesize < < fieldmv , 4 , uvmx_field[i] , uvmy_field[i] ) ; } else { v - > vc1dsp . put_no_rnd_vc1_chroma_pixels_tab[1] ( s - > dest[1] + off , srcU , s - > uvlinesize < < fieldmv , 4 , uvmx_field[i] , uvmy_field[i] ) ; v - > vc1dsp . put_no_rnd_vc1_chroma_pixels_tab[1] ( s - > dest[2] + off , srcV , s - > uvlinesize < < fieldmv , 4 , uvmx_field[i] , uvmy_field[i] ) ; } } } }",1
"static int rtp_asf_fix_header ( uint8_t * buf , int len ) { uint8_t * p = buf , * end = buf + len ; if ( len < sizeof ( ff_asf_guid ) * 2 + 22 || memcmp ( p , ff_asf_header , sizeof ( ff_asf_guid ) ) ) { return - 1 ; } p + = sizeof ( ff_asf_guid ) + 14 ; do { uint64_t chunksize = AV_RL64 ( p + sizeof ( ff_asf_guid ) ) ; if ( memcmp ( p , ff_asf_file_header , sizeof ( ff_asf_guid ) ) ) { if ( chunksize > end - p ) return - 1 ; p + = chunksize ; continue ; } / * skip most of the file header , to min_pktsize * / p + = 6 * 8 + 3 * 4 + sizeof ( ff_asf_guid ) * 2 ; if ( p + 8 < = end & & AV_RL32 ( p ) == AV_RL32 ( p + 4 ) ) { / * and set that to zero * / AV_WL32 ( p , 0 ) ; return 0 ; } break ; } while ( end - p > = sizeof ( ff_asf_guid ) + 8 ) ; return - 1 ; }",1
"static inline void RENAME ( uyvyToY ) ( uint8_t * dst , uint8_t * src , long width ) { ifdef HAVE_MMX asm volatile ( mov %0 , %% REG_a \n\t 1 : \n\t movq ( %1 , %% REG_a , 2 ) , %%mm0 \n\t movq 8 ( %1 , %% REG_a , 2 ) , %%mm1 \n\t psrlw 8 , %%mm0 \n\t psrlw 8 , %%mm1 \n\t packuswb %%mm1 , %%mm0 \n\t movq %%mm0 , ( %2 , %% REG_a ) \n\t add 8 , %% REG_a \n\t js 1b \n\t : : g ( - width ) , r ( src + width * 2 ) , r ( dst + width ) : % REG_a ) ; else int i ; for ( i=0 ; i < width ; i + + ) dst[i]= src[2 * i + 1] ; endif }",1
"static int kempf_decode_tile ( G2MContext * c , int tile_x , int tile_y , const uint8_t * src , int src_size ) { int width , height ; int hdr , zsize , npal , tidx = - 1 , ret ; int i , j ; const uint8_t * src_end = src + src_size ; uint8_t pal[768] , transp[3] ; uLongf dlen = ( c - > tile_width + 1 ) * c - > tile_height ; int sub_type ; int nblocks , cblocks , bstride ; int bits , bitbuf , coded ; uint8_t * dst = c - > framebuf + tile_x * c - > tile_width * 3 + tile_y * c - > tile_height * c - > framebuf_stride ; if ( src_size < 2 ) width = FFMIN ( c - > width - tile_x * c - > tile_width , c - > tile_width ) ; height = FFMIN ( c - > height - tile_y * c - > tile_height , c - > tile_height ) ; hdr = * src + + ; sub_type = hdr > > 5 ; if ( sub_type == 0 ) { int j ; memcpy ( transp , src , 3 ) ; src + = 3 ; for ( j = 0 ; j < height ; j + + , dst + = c - > framebuf_stride ) for ( i = 0 ; i < width ; i + + ) memcpy ( dst + i * 3 , transp , 3 ) ; return 0 ; } else if ( sub_type == 1 ) { return jpg_decode_data ( & c - > jc , width , height , src , src_end - src , dst , c - > framebuf_stride , NULL , 0 , 0 , 0 ) ; } if ( sub_type ! = 2 ) { memcpy ( transp , src , 3 ) ; src + = 3 ; } npal = * src + + + 1 ; memcpy ( pal , src , npal * 3 ) ; src + = npal * 3 ; if ( sub_type ! = 2 ) { for ( i = 0 ; i < npal ; i + + ) { if ( ! memcmp ( pal + i * 3 , transp , 3 ) ) { tidx = i ; break ; } } } if ( src_end - src < 2 ) return 0 ; zsize = ( src[0] < < 8 ) | src[1] ; src + = 2 ; if ( src_end - src < zsize + ( sub_type ! = 2 ) ) ret = uncompress ( c - > kempf_buf , & dlen , src , zsize ) ; if ( ret ) src + = zsize ; if ( sub_type == 2 ) { kempf_restore_buf ( c - > kempf_buf , dlen , dst , c - > framebuf_stride , NULL , 0 , width , height , pal , npal , tidx ) ; return 0 ; } nblocks = * src + + + 1 ; cblocks = 0 ; bstride = FFALIGN ( width , 16 ) > > 4 ; // blocks are coded LSB and we need normal bitreader for JPEG data bits = 0 ; for ( i = 0 ; i < ( FFALIGN ( height , 16 ) > > 4 ) ; i + + ) { for ( j = 0 ; j < ( FFALIGN ( width , 16 ) > > 4 ) ; j + + ) { if ( ! bits ) { if ( src > = src_end ) bitbuf = * src + + ; bits = 8 ; } coded = bitbuf & 1 ; bits - - ; bitbuf > > = 1 ; cblocks + = coded ; if ( cblocks > nblocks ) c - > kempf_flags[j + i * bstride] = coded ; } } memset ( c - > jpeg_tile , 0 , c - > tile_stride * height ) ; jpg_decode_data ( & c - > jc , width , height , src , src_end - src , c - > jpeg_tile , c - > tile_stride , c - > kempf_flags , bstride , nblocks , 0 ) ; kempf_restore_buf ( c - > kempf_buf , dlen , dst , c - > framebuf_stride , c - > jpeg_tile , c - > tile_stride , width , height , pal , npal , tidx ) ; return 0 ; }",1
"static void interpolate_refplane ( DiracContext * s , DiracFrame * ref , int plane , int width , int height ) { / * chroma allocates an edge of 8 when subsampled which for 4 : 2 : 2 means an h edge of 16 and v edge of 8 just use 8 for everything for the moment * / int i , edge = EDGE_WIDTH/2 ; ref - > hpel[plane][0] = ref - > avframe - > data[plane] ; s - > mpvencdsp . draw_edges ( ref - > hpel[plane][0] , ref - > avframe - > linesize[plane] , width , height , edge , edge , EDGE_TOP | EDGE_BOTTOM ) ; / * EDGE_TOP | EDGE_BOTTOM values just copied to make it build , this needs to be ensured * / / * no need for hpel if we only have fpel vectors * / if ( ! s - > mv_precision ) return ; for ( i = 1 ; i < 4 ; i + + ) { if ( ! ref - > hpel_base[plane][i] ) ref - > hpel_base[plane][i] = av_malloc ( ( height + 2 * edge ) * ref - > avframe - > linesize[plane] + 32 ) ; / * we need to be 16 - byte aligned even for chroma * / ref - > hpel[plane][i] = ref - > hpel_base[plane][i] + edge * ref - > avframe - > linesize[plane] + 16 ; } if ( ! ref - > interpolated[plane] ) { s - > diracdsp . dirac_hpel_filter ( ref - > hpel[plane][1] , ref - > hpel[plane][2] , ref - > hpel[plane][3] , ref - > hpel[plane][0] , ref - > avframe - > linesize[plane] , width , height ) ; s - > mpvencdsp . draw_edges ( ref - > hpel[plane][1] , ref - > avframe - > linesize[plane] , width , height , edge , edge , EDGE_TOP | EDGE_BOTTOM ) ; s - > mpvencdsp . draw_edges ( ref - > hpel[plane][2] , ref - > avframe - > linesize[plane] , width , height , edge , edge , EDGE_TOP | EDGE_BOTTOM ) ; s - > mpvencdsp . draw_edges ( ref - > hpel[plane][3] , ref - > avframe - > linesize[plane] , width , height , edge , edge , EDGE_TOP | EDGE_BOTTOM ) ; } ref - > interpolated[plane] = 1 ; }",1
"int avfilter_process_command ( AVFilterContext * filter , const char * cmd , const char * arg , char * res , int res_len , int flags ) { if ( ! strcmp ( cmd , ping ) ) { av_strlcatf ( res , res_len , pong from : %s %s\n , filter - > filter - > name , filter - > name ) ; return 0 ; } else if ( ! strcmp ( cmd , enable ) ) { return set_enable_expr ( filter , arg ) ; } else if ( filter - > filter - > process_command ) { return filter - > filter - > process_command ( filter , cmd , arg , res , res_len , flags ) ; return AVERROR ( ENOSYS ) ;",1
"static void decode_clnpass ( Jpeg2000DecoderContext * s , Jpeg2000T1Context * t1 , int width , int height , int bpno , int bandno , int seg_symbols ) { int mask = 3 < < ( bpno - 1 ) , y0 , x , y , runlen , dec ; for ( y0 = 0 ; y0 < height ; y0 + = 4 ) for ( x = 0 ; x < width ; x + + ) { if ( y0 + 3 < height & & ! ( ( t1 - > flags[y0 + 1][x + 1] & ( JPEG2000_T1_SIG_NB | JPEG2000_T1_VIS | JPEG2000_T1_SIG ) ) || ( t1 - > flags[y0 + 2][x + 1] & ( JPEG2000_T1_SIG_NB | JPEG2000_T1_VIS | JPEG2000_T1_SIG ) ) || ( t1 - > flags[y0 + 3][x + 1] & ( JPEG2000_T1_SIG_NB | JPEG2000_T1_VIS | JPEG2000_T1_SIG ) ) || ( t1 - > flags[y0 + 4][x + 1] & ( JPEG2000_T1_SIG_NB | JPEG2000_T1_VIS | JPEG2000_T1_SIG ) ) ) ) { if ( ! ff_mqc_decode ( & t1 - > mqc , t1 - > mqc . cx_states + MQC_CX_RL ) ) continue ; runlen = ff_mqc_decode ( & t1 - > mqc , t1 - > mqc . cx_states + MQC_CX_UNI ) ; runlen = ( runlen < < 1 ) | ff_mqc_decode ( & t1 - > mqc , t1 - > mqc . cx_states + MQC_CX_UNI ) ; dec = 1 ; } else { runlen = 0 ; dec = 0 ; } for ( y = y0 + runlen ; y < y0 + 4 & & y < height ; y + + ) { if ( ! dec ) { if ( ! ( t1 - > flags[y + 1][x + 1] & ( JPEG2000_T1_SIG | JPEG2000_T1_VIS ) ) ) dec = ff_mqc_decode ( & t1 - > mqc , t1 - > mqc . cx_states + ff_jpeg2000_getsigctxno ( t1 - > flags[y + 1][x + 1] , bandno ) ) ; } if ( dec ) { int xorbit ; int ctxno = ff_jpeg2000_getsgnctxno ( t1 - > flags[y + 1][x + 1] , & xorbit ) ; t1 - > data[y][x] = ( ff_mqc_decode ( & t1 - > mqc , t1 - > mqc . cx_states + ctxno ) xorbit ) ? - mask : mask ; ff_jpeg2000_set_significance ( t1 , x , y , t1 - > data[y][x] < 0 ) ; } dec = 0 ; t1 - > flags[y + 1][x + 1] & = JPEG2000_T1_VIS ; } } if ( seg_symbols ) { int val ; val = ff_mqc_decode ( & t1 - > mqc , t1 - > mqc . cx_states + MQC_CX_UNI ) ; val = ( val < < 1 ) + ff_mqc_decode ( & t1 - > mqc , t1 - > mqc . cx_states + MQC_CX_UNI ) ; val = ( val < < 1 ) + ff_mqc_decode ( & t1 - > mqc , t1 - > mqc . cx_states + MQC_CX_UNI ) ; val = ( val < < 1 ) + ff_mqc_decode ( & t1 - > mqc , t1 - > mqc . cx_states + MQC_CX_UNI ) ; if ( val ! = 0xa ) av_log ( s - > avctx , AV_LOG_ERROR , Segmentation symbol value incorrect\n ) ; } }",0
"void ff_put_h264_qpel8_mc03_msa ( uint8_t * dst , const uint8_t * src , ptrdiff_t stride ) { avc_luma_vt_qrt_8w_msa ( src - ( stride * 2 ) , stride , dst , stride , 8 , 1 ) ; }",0
"static av_cold int audio_write_header ( AVFormatContext * s1 ) { AlsaData * s = s1 - > priv_data ; AVStream * st ; unsigned int sample_rate ; enum AVCodecID codec_id ; int res ; st = s1 - > streams[0] ; sample_rate = st - > codec - > sample_rate ; codec_id = st - > codec - > codec_id ; res = ff_alsa_open ( s1 , SND_PCM_STREAM_PLAYBACK , & sample_rate , st - > codec - > channels , & codec_id ) ; if ( sample_rate ! = st - > codec - > sample_rate ) { av_log ( s1 , AV_LOG_ERROR , sample rate %d not available , nearest is %d\n , st - > codec - > sample_rate , sample_rate ) ; goto fail ; } avpriv_set_pts_info ( st , 64 , 1 , sample_rate ) ; return res ; fail : snd_pcm_close ( s - > h ) ; return AVERROR ( EIO ) ; }",0
"int ff_jpegls_decode_lse ( MJpegDecodeContext * s ) { int id ; int tid , wt , maxtab , i , j ; int len = get_bits ( & s - > gb , 16 ) ; / * length : FIXME : verify field validity * / id = get_bits ( & s - > gb , 8 ) ; switch ( id ) { case 1 : s - > maxval = get_bits ( & s - > gb , 16 ) ; s - > t1 = get_bits ( & s - > gb , 16 ) ; s - > t2 = get_bits ( & s - > gb , 16 ) ; s - > t3 = get_bits ( & s - > gb , 16 ) ; s - > reset = get_bits ( & s - > gb , 16 ) ; // ff_jpegls_reset_coding_parameters ( s , 0 ) ; //FIXME quant table ? break ; case 2 : s - > palette_index = 0 ; case 3 : tid= get_bits ( & s - > gb , 8 ) ; wt = get_bits ( & s - > gb , 8 ) ; if ( len < 5 ) return AVERROR_INVALIDDATA ; if ( wt < 1 || wt > MAX_COMPONENTS ) { avpriv_request_sample ( s - > avctx , wt %d , wt ) ; return AVERROR_PATCHWELCOME ; } if ( ! s - > maxval ) maxtab = 255 ; else if ( ( 5 + wt * ( s - > maxval + 1 ) ) < 65535 ) maxtab = s - > maxval ; else maxtab = 65530/wt - 1 ; if ( s - > avctx - > debug & FF_DEBUG_PICT_INFO ) { av_log ( s - > avctx , AV_LOG_DEBUG , LSE palette %d tid : %d wt : %d maxtab : %d\n , id , tid , wt , maxtab ) ; } if ( maxtab > = 256 ) { avpriv_request_sample ( s - > avctx , > 8bit palette ) ; return AVERROR_PATCHWELCOME ; } maxtab = FFMIN ( maxtab , ( len - 5 ) / wt + s - > palette_index ) ; if ( s - > palette_index > maxtab ) return AVERROR_INVALIDDATA ; if ( ( s - > avctx - > pix_fmt == AV_PIX_FMT_GRAY8 || s - > avctx - > pix_fmt == AV_PIX_FMT_PAL8 ) & & ( s - > picture_ptr - > format == AV_PIX_FMT_GRAY8 || s - > picture_ptr - > format == AV_PIX_FMT_PAL8 ) ) { uint32_t * pal = s - > picture_ptr - > data[1] ; s - > picture_ptr - > format = s - > avctx - > pix_fmt = AV_PIX_FMT_PAL8 ; for ( i=s - > palette_index ; i < =maxtab ; i + + ) { pal[i] = 0 ; for ( j=0 ; j < wt ; j + + ) { pal[i] |= get_bits ( & s - > gb , 8 ) < < ( 8 * ( wt - j - 1 ) ) ; } } s - > palette_index = i ; } break ; case 4 : avpriv_request_sample ( s - > avctx , oversize image ) ; return AVERROR ( ENOSYS ) ; default : av_log ( s - > avctx , AV_LOG_ERROR , invalid id %d\n , id ) ; return AVERROR_INVALIDDATA ; } av_dlog ( s - > avctx , ID=%i , T=%i , %i , %i\n , id , s - > t1 , s - > t2 , s - > t3 ) ; return 0 ; }",0
"static int ipvideo_decode_block_opcode_0x8 ( IpvideoContext * s ) { int x , y ; unsigned char P[2] ; unsigned int flags = 0 ; / * 2 - color encoding for each 4x4 quadrant , or 2 - color encoding on * either top and bottom or left and right halves * / CHECK_STREAM_PTR ( 2 ) ; P[0] = * s - > stream_ptr + + ; P[1] = * s - > stream_ptr + + ; if ( P[0] < = P[1] ) { CHECK_STREAM_PTR ( 14 ) ; s - > stream_ptr - = 2 ; for ( y = 0 ; y < 16 ; y + + ) { // new values for each 4x4 block if ( ! ( y & 3 ) ) { P[0] = * s - > stream_ptr + + ; P[1] = * s - > stream_ptr + + ; flags = bytestream_get_le16 ( & s - > stream_ptr ) ; } for ( x = 0 ; x < 4 ; x + + , flags > > = 1 ) * s - > pixel_ptr + + = P[flags & 1] ; s - > pixel_ptr + = s - > stride - 4 ; // switch to right half if ( y == 7 ) s - > pixel_ptr - = 8 * s - > stride - 4 ; } } else { / * need 10 more bytes * / CHECK_STREAM_PTR ( 10 ) ; if ( s - > stream_ptr[4] < = s - > stream_ptr[5] ) { flags = bytestream_get_le32 ( & s - > stream_ptr ) ; / * vertical split ; left & right halves are 2 - color encoded * / for ( y = 0 ; y < 16 ; y + + ) { for ( x = 0 ; x < 4 ; x + + , flags > > = 1 ) * s - > pixel_ptr + + = P[flags & 1] ; s - > pixel_ptr + = s - > stride - 4 ; // switch to right half if ( y == 7 ) { s - > pixel_ptr - = 8 * s - > stride - 4 ; P[0] = * s - > stream_ptr + + ; P[1] = * s - > stream_ptr + + ; flags = bytestream_get_le32 ( & s - > stream_ptr ) ; } } } else { / * horizontal split ; top & bottom halves are 2 - color encoded * / for ( y = 0 ; y < 8 ; y + + ) { if ( y == 4 ) { P[0] = * s - > stream_ptr + + ; P[1] = * s - > stream_ptr + + ; } flags = * s - > stream_ptr + + | 0x100 ; for ( ; flags ! = 1 ; flags > > = 1 ) * s - > pixel_ptr + + = P[flags & 1] ; s - > pixel_ptr + = s - > line_inc ; } } } / * report success * / return 0 ; }",0
"static int mov_read_stss ( MOVContext * c , AVIOContext * pb , MOVAtom atom ) { AVStream * st ; MOVStreamContext * sc ; unsigned int i , entries ; if ( c - > fc - > nb_streams < 1 ) return 0 ; st = c - > fc - > streams[c - > fc - > nb_streams - 1] ; sc = st - > priv_data ; avio_r8 ( pb ) ; / * version * / avio_rb24 ( pb ) ; / * flags * / entries = avio_rb32 ( pb ) ; av_dlog ( c - > fc , keyframe_count = %d\n , entries ) ; if ( ! entries ) { sc - > keyframe_absent = 1 ; if ( ! st - > need_parsing ) st - > need_parsing = AVSTREAM_PARSE_HEADERS ; return 0 ; } if ( entries > = UINT_MAX / sizeof ( int ) ) return AVERROR_INVALIDDATA ; sc - > keyframes = av_malloc ( entries * sizeof ( int ) ) ; if ( ! sc - > keyframes ) return AVERROR ( ENOMEM ) ; for ( i = 0 ; i < entries & & ! pb - > eof_reached ; i + + ) { sc - > keyframes[i] = avio_rb32 ( pb ) ; //av_dlog ( c - > fc , keyframes[]=%d\n , sc - > keyframes[i] ) ; } sc - > keyframe_count = i ; if ( pb - > eof_reached ) return AVERROR_EOF ; return 0 ; }",0
"void swr_compensate ( struct SwrContext * s , int sample_delta , int compensation_distance ) { ResampleContext * c= s - > resample ; // sample_delta + = ( c - > ideal_dst_incr - c - > dst_incr ) * ( int64_t ) c - > compensation_distance / c - > ideal_dst_incr ; c - > compensation_distance= compensation_distance ; c - > dst_incr = c - > ideal_dst_incr - c - > ideal_dst_incr * ( int64_t ) sample_delta / compensation_distance ; }",0
"int MPV_frame_start ( MpegEncContext * s , AVCodecContext * avctx ) { int i ; Picture * pic ; s - > mb_skipped = 0 ; assert ( s - > last_picture_ptr==NULL || s - > out_format ! = FMT_H264 || s - > codec_id == CODEC_ID_SVQ3 ) ; / * mark & release old frames * / if ( s - > pict_type ! = FF_B_TYPE & & s - > last_picture_ptr & & s - > last_picture_ptr ! = s - > next_picture_ptr & & s - > last_picture_ptr - > data[0] ) { if ( s - > out_format ! = FMT_H264 || s - > codec_id == CODEC_ID_SVQ3 ) { free_frame_buffer ( s , s - > last_picture_ptr ) ; / * release forgotten pictures * / / * if ( mpeg124/h263 ) * / if ( ! s - > encoding ) { for ( i=0 ; i < MAX_PICTURE_COUNT ; i + + ) { if ( s - > picture[i] . data[0] & & & s - > picture[i] ! = s - > next_picture_ptr & & s - > picture[i] . reference ) { av_log ( avctx , AV_LOG_ERROR , releasing zombie picture\n ) ; free_frame_buffer ( s , & s - > picture[i] ) ; } } } } } alloc : if ( ! s - > encoding ) { / * release non reference frames * / for ( i=0 ; i < MAX_PICTURE_COUNT ; i + + ) { if ( s - > picture[i] . data[0] & & ! s - > picture[i] . reference / * & & s - > picture[i] . type ! =FF_BUFFER_TYPE_SHARED * / ) { free_frame_buffer ( s , & s - > picture[i] ) ; } } if ( s - > current_picture_ptr & & s - > current_picture_ptr - > data[0]==NULL ) pic= s - > current_picture_ptr ; //we already have a unused image ( maybe it was set before reading the header ) else { i= ff_find_unused_picture ( s , 0 ) ; pic= & s - > picture[i] ; } pic - > reference= 0 ; if ( ! s - > dropable ) { if ( s - > codec_id == CODEC_ID_H264 ) pic - > reference = s - > picture_structure ; else if ( s - > pict_type ! = FF_B_TYPE ) pic - > reference = 3 ; } pic - > coded_picture_number= s - > coded_picture_number + + ; if ( ff_alloc_picture ( s , pic , 0 ) < 0 ) return - 1 ; s - > current_picture_ptr= pic ; s - > current_picture_ptr - > top_field_first= s - > top_field_first ; //FIXME use only the vars from current_pic s - > current_picture_ptr - > interlaced_frame= ! s - > progressive_frame & & ! s - > progressive_sequence ; } s - > current_picture_ptr - > pict_type= s - > pict_type ; // if ( s - > flags & & CODEC_FLAG_QSCALE ) // s - > current_picture_ptr - > quality= s - > new_picture_ptr - > quality ; s - > current_picture_ptr - > key_frame= s - > pict_type == FF_I_TYPE ; ff_copy_picture ( & s - > current_picture , s - > current_picture_ptr ) ; if ( s - > pict_type ! = FF_B_TYPE ) { s - > last_picture_ptr= s - > next_picture_ptr ; if ( ! s - > dropable ) s - > next_picture_ptr= s - > current_picture_ptr ; } / * av_log ( s - > avctx , AV_LOG_DEBUG , L%p N%p C%p L%p N%p C%p type : %d drop : %d\n , s - > last_picture_ptr , s - > next_picture_ptr , s - > current_picture_ptr , s - > last_picture_ptr ? s - > last_picture_ptr - > data[0] : NULL , s - > next_picture_ptr ? s - > next_picture_ptr - > data[0] : NULL , s - > current_picture_ptr ? s - > current_picture_ptr - > data[0] : NULL , s - > pict_type , s - > dropable ) ; * / if ( s - > last_picture_ptr ) ff_copy_picture ( & s - > last_picture , s - > last_picture_ptr ) ; if ( s - > next_picture_ptr ) ff_copy_picture ( & s - > next_picture , s - > next_picture_ptr ) ; if ( s - > pict_type ! = FF_I_TYPE & & ( s - > last_picture_ptr==NULL || s - > last_picture_ptr - > data[0]==NULL ) & & ! s - > dropable & & s - > codec_id ! = CODEC_ID_H264 ) { av_log ( avctx , AV_LOG_ERROR , warning : first frame is no keyframe\n ) ; assert ( s - > pict_type ! = FF_B_TYPE ) ; //these should have been dropped if we don ' t have a reference goto alloc ; } assert ( s - > pict_type == FF_I_TYPE || ( s - > last_picture_ptr & & s - > last_picture_ptr - > data[0] ) ) ; if ( s - > picture_structure ! =PICT_FRAME & & s - > out_format ! = FMT_H264 ) { int i ; for ( i=0 ; i < 4 ; i + + ) { if ( s - > picture_structure == PICT_BOTTOM_FIELD ) { s - > current_picture . data[i] + = s - > current_picture . linesize[i] ; } s - > current_picture . linesize[i] * = 2 ; s - > last_picture . linesize[i] * =2 ; s - > next_picture . linesize[i] * =2 ; } } s - > hurry_up= s - > avctx - > hurry_up ; s - > error_recognition= avctx - > error_recognition ; / * set dequantizer , we can ' t do it during init as it might change for mpeg4 and we can ' t do it in the header decode as init is not called for mpeg4 there yet * / if ( s - > mpeg_quant || s - > codec_id == CODEC_ID_MPEG2VIDEO ) { s - > dct_unquantize_intra = s - > dct_unquantize_mpeg2_intra ; s - > dct_unquantize_inter = s - > dct_unquantize_mpeg2_inter ; } else if ( s - > out_format == FMT_H263 || s - > out_format == FMT_H261 ) { s - > dct_unquantize_intra = s - > dct_unquantize_h263_intra ; s - > dct_unquantize_inter = s - > dct_unquantize_h263_inter ; } else { s - > dct_unquantize_intra = s - > dct_unquantize_mpeg1_intra ; s - > dct_unquantize_inter = s - > dct_unquantize_mpeg1_inter ; } if ( s - > dct_error_sum ) { assert ( s - > avctx - > noise_reduction & & s - > encoding ) ; update_noise_reduction ( s ) ; } if ( CONFIG_MPEG_XVMC_DECODER & & s - > avctx - > xvmc_acceleration ) return ff_xvmc_field_start ( s , avctx ) ; return 0 ; }",0
"static int pcm_dvd_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame_ptr , AVPacket * avpkt ) { AVFrame * frame = data ; const uint8_t * src = avpkt - > data ; int buf_size = avpkt - > size ; PCMDVDContext * s = avctx - > priv_data ; int retval ; int blocks ; void * dst ; if ( buf_size < 3 ) { av_log ( avctx , AV_LOG_ERROR , PCM packet too small\n ) ; return AVERROR_INVALIDDATA ; if ( ( retval = pcm_dvd_parse_header ( avctx , src ) ) ) return retval ; src + = 3 ; buf_size - = 3 ; blocks = ( buf_size + s - > extra_sample_count ) / s - > block_size ; / * get output buffer * / frame - > nb_samples = blocks * s - > samples_per_block ; if ( ( retval = ff_get_buffer ( avctx , frame , 0 ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed\n ) ; return retval ; dst = frame - > data[0] ; / * consume leftover samples from last packet * / if ( s - > extra_sample_count ) { int missing_samples = s - > block_size - s - > extra_sample_count ; if ( buf_size > = missing_samples ) { memcpy ( s - > extra_samples + s - > extra_sample_count , src , missing_samples ) ; dst = pcm_dvd_decode_samples ( avctx , s - > extra_samples , dst , 1 ) ; src + = missing_samples ; buf_size - = missing_samples ; blocks - - ; } else { / * new packet still doesn ' t have enough samples * / memcpy ( s - > extra_samples + s - > extra_sample_count , src , buf_size ) ; s - > extra_sample_count + = buf_size ; return avpkt - > size ; / * decode remaining complete samples * / if ( blocks ) { pcm_dvd_decode_samples ( avctx , src , dst , blocks ) ; buf_size - = blocks * s - > block_size ; / * store leftover samples * / if ( buf_size ) { src + = blocks * s - > block_size ; memcpy ( s - > extra_samples , src , buf_size ) ; s - > extra_sample_count = buf_size ; * got_frame_ptr = 1 ; return avpkt - > size ;",1
"static inline void ls_decode_line ( JLSState * state , MJpegDecodeContext * s , void * last , void * dst , int last2 , int w , int stride , int comp , int bits ) { int i , x = 0 ; int Ra , Rb , Rc , Rd ; int D0 , D1 , D2 ; while ( x < w ) { int err , pred ; / * compute gradients * / Ra = x ? R ( dst , x - stride ) : R ( last , x ) ; Rb = R ( last , x ) ; Rc = x ? R ( last , x - stride ) : last2 ; Rd = ( x > = w - stride ) ? R ( last , x ) : R ( last , x + stride ) ; D0 = Rd - Rb ; D1 = Rb - Rc ; D2 = Rc - Ra ; / * run mode * / if ( ( FFABS ( D0 ) < = state - > near ) & & ( FFABS ( D1 ) < = state - > near ) & & ( FFABS ( D2 ) < = state - > near ) ) { int r ; int RItype ; / * decode full runs while available * / while ( get_bits1 ( & s - > gb ) ) { int r ; r = 1 < < ff_log2_run[state - > run_index[comp]] ; if ( x + r * stride > w ) r = ( w - x ) / stride ; for ( i = 0 ; i < r ; i + + ) { W ( dst , x , Ra ) ; x + = stride ; } / * if EOL reached , we stop decoding * / if ( r ! = 1 < < ff_log2_run[state - > run_index[comp]] ) return ; if ( state - > run_index[comp] < 31 ) state - > run_index[comp] + + ; if ( x + stride > w ) return ; } / * decode aborted run * / r = ff_log2_run[state - > run_index[comp]] ; if ( r ) r = get_bits_long ( & s - > gb , r ) ; if ( x + r * stride > w ) { r = ( w - x ) / stride ; } for ( i = 0 ; i < r ; i + + ) { W ( dst , x , Ra ) ; x + = stride ; } if ( x > = w ) { av_log ( NULL , AV_LOG_ERROR , run overflow\n ) ; return ; } / * decode run termination value * / Rb = R ( last , x ) ; RItype = ( FFABS ( Ra - Rb ) < = state - > near ) ? 1 : 0 ; err = ls_get_code_runterm ( & s - > gb , state , RItype , ff_log2_run[state - > run_index[comp]] ) ; if ( state - > run_index[comp] ) state - > run_index[comp] - - ; if ( state - > near & & RItype ) { pred = Ra + err ; } else { if ( Rb < Ra ) pred = Rb - err ; else pred = Rb + err ; } } else { / * regular mode * / int context , sign ; context = ff_jpegls_quantize ( state , D0 ) * 81 + ff_jpegls_quantize ( state , D1 ) * 9 + ff_jpegls_quantize ( state , D2 ) ; pred = mid_pred ( Ra , Ra + Rb - Rc , Rb ) ; if ( context < 0 ) { context = - context ; sign = 1 ; } else { sign = 0 ; } if ( sign ) { pred = av_clip ( pred - state - > C[context] , 0 , state - > maxval ) ; err = - ls_get_code_regular ( & s - > gb , state , context ) ; } else { pred = av_clip ( pred + state - > C[context] , 0 , state - > maxval ) ; err = ls_get_code_regular ( & s - > gb , state , context ) ; } / * we have to do something more for near - lossless coding * / pred + = err ; } if ( state - > near ) { if ( pred < - state - > near ) pred + = state - > range * state - > twonear ; else if ( pred > state - > maxval + state - > near ) pred - = state - > range * state - > twonear ; pred = av_clip ( pred , 0 , state - > maxval ) ; } pred & = state - > maxval ; W ( dst , x , pred ) ; x + = stride ; } }",1
"static void do_video_out ( AVFormatContext * s , OutputStream * ost , AVFrame * in_picture , float quality ) { int ret , format_video_sync ; AVPacket pkt ; AVCodecContext * enc = ost - > st - > codec ; int nb_frames ; double sync_ipts , delta ; double duration = 0 ; int frame_size = 0 ; InputStream * ist = NULL ; if ( ost - > source_index > = 0 ) ist = input_streams[ost - > source_index] ; if ( ist & & ist - > st - > start_time ! = AV_NOPTS_VALUE & & ist - > st - > first_dts ! = AV_NOPTS_VALUE & & ost - > frame_rate . num ) duration = 1/ ( av_q2d ( ost - > frame_rate ) * av_q2d ( enc - > time_base ) ) ; sync_ipts = in_picture - > pts ; delta = sync_ipts - ost - > sync_opts + duration ; / * by default , we output a single frame * / nb_frames = 1 ; format_video_sync = video_sync_method ; if ( format_video_sync == VSYNC_AUTO ) format_video_sync = ( s - > oformat - > flags & AVFMT_VARIABLE_FPS ) ? ( ( s - > oformat - > flags & AVFMT_NOTIMESTAMPS ) ? VSYNC_PASSTHROUGH : VSYNC_VFR ) : 1 ; switch ( format_video_sync ) { case VSYNC_CFR : // FIXME set to 0 . 5 after we fix some dts/pts bugs like in avidec . c if ( delta < - 1 . 1 ) nb_frames = 0 ; else if ( delta > 1 . 1 ) nb_frames = lrintf ( delta ) ; break ; case VSYNC_VFR : if ( delta < = - 0 . 6 ) nb_frames = 0 ; else if ( delta > 0 . 6 ) ost - > sync_opts = lrint ( sync_ipts ) ; break ; case VSYNC_DROP : case VSYNC_PASSTHROUGH : ost - > sync_opts = lrint ( sync_ipts ) ; break ; default : av_assert0 ( 0 ) ; } nb_frames = FFMIN ( nb_frames , ost - > max_frames - ost - > frame_number ) ; if ( nb_frames == 0 ) { nb_frames_drop + + ; av_log ( NULL , AV_LOG_VERBOSE , * * * drop ! \n ) ; return ; } else if ( nb_frames > 1 ) { if ( nb_frames > dts_error_threshold * 30 ) { av_log ( NULL , AV_LOG_ERROR , %d frame duplication too large , skiping\n , nb_frames - 1 ) ; nb_frames_drop + + ; return ; } nb_frames_dup + = nb_frames - 1 ; av_log ( NULL , AV_LOG_VERBOSE , * * * %d dup ! \n , nb_frames - 1 ) ; } duplicate_frame : av_init_packet ( & pkt ) ; pkt . data = NULL ; pkt . size = 0 ; in_picture - > pts = ost - > sync_opts ; if ( ! check_recording_time ( ost ) ) return ; if ( s - > oformat - > flags & AVFMT_RAWPICTURE & & enc - > codec - > id == CODEC_ID_RAWVIDEO ) { / * raw pictures are written as AVPicture structure to avoid any copies . We support temporarily the older method . * / enc - > coded_frame - > interlaced_frame = in_picture - > interlaced_frame ; enc - > coded_frame - > top_field_first = in_picture - > top_field_first ; pkt . data = ( uint8_t * ) in_picture ; pkt . size = sizeof ( AVPicture ) ; pkt . pts = av_rescale_q ( in_picture - > pts , enc - > time_base , ost - > st - > time_base ) ; pkt . flags |= AV_PKT_FLAG_KEY ; write_frame ( s , & pkt , ost ) ; video_size + = pkt . size ; } else { int got_packet ; AVFrame big_picture ; big_picture = * in_picture ; / * better than nothing : use input picture interlaced settings * / big_picture . interlaced_frame = in_picture - > interlaced_frame ; if ( ost - > st - > codec - > flags & ( CODEC_FLAG_INTERLACED_DCT|CODEC_FLAG_INTERLACED_ME ) ) { if ( ost - > top_field_first == - 1 ) big_picture . top_field_first = in_picture - > top_field_first ; else big_picture . top_field_first = ! ! ost - > top_field_first ; } / * handles same_quant here . This is not correct because it may not be a global option * / big_picture . quality = quality ; if ( ! enc - > me_threshold ) big_picture . pict_type = 0 ; if ( ost - > forced_kf_index < ost - > forced_kf_count & & big_picture . pts > = ost - > forced_kf_pts[ost - > forced_kf_index] ) { big_picture . pict_type = AV_PICTURE_TYPE_I ; ost - > forced_kf_index + + ; } update_benchmark ( NULL ) ; ret = avcodec_encode_video2 ( enc , & pkt , & big_picture , & got_packet ) ; update_benchmark ( encode_video %d . %d , ost - > file_index , ost - > index ) ; if ( ret < 0 ) { av_log ( NULL , AV_LOG_FATAL , Video encoding failed\n ) ; exit_program ( 1 ) ; } if ( got_packet ) { if ( pkt . pts == AV_NOPTS_VALUE & & ! ( enc - > codec - > capabilities & CODEC_CAP_DELAY ) ) pkt . pts = ost - > sync_opts ; if ( pkt . pts ! = AV_NOPTS_VALUE ) pkt . pts = av_rescale_q ( pkt . pts , enc - > time_base , ost - > st - > time_base ) ; if ( pkt . dts ! = AV_NOPTS_VALUE ) pkt . dts = av_rescale_q ( pkt . dts , enc - > time_base , ost - > st - > time_base ) ; if ( debug_ts ) { av_log ( NULL , AV_LOG_INFO , encoder - > type : video pkt_pts : %s pkt_pts_time : %s pkt_dts : %s pkt_dts_time : %s\n , av_ts2str ( pkt . pts ) , av_ts2timestr ( pkt . pts , & ost - > st - > time_base ) , av_ts2str ( pkt . dts ) , av_ts2timestr ( pkt . dts , & ost - > st - > time_base ) ) ; } write_frame ( s , & pkt , ost ) ; frame_size = pkt . size ; video_size + = pkt . size ; av_free_packet ( & pkt ) ; / * if two pass , output log * / if ( ost - > logfile & & enc - > stats_out ) { fprintf ( ost - > logfile , %s , enc - > stats_out ) ; } } } ost - > sync_opts + + ; / * * For video , number of frames in == number of packets out . * But there may be reordering , so we can ' t throw away frames on encoder * flush , we need to limit them here , before they go into encoder . * / ost - > frame_number + + ; if ( - - nb_frames ) goto duplicate_frame ; if ( vstats_filename & & frame_size ) do_video_stats ( output_files[ost - > file_index]",0
"static int jpeg2000_decode_packets ( Jpeg2000DecoderContext * s , Jpeg2000Tile * tile ) { int layno , reslevelno , compno , precno , ok_reslevel , ret ; uint8_t prog_order = tile - > codsty[0] . prog_order ; uint16_t x ; uint16_t y ; s - > bit_index = 8 ; switch ( prog_order ) { case JPEG2000_PGOD_LRCP : for ( layno = 0 ; layno < tile - > codsty[0] . nlayers ; layno + + ) { ok_reslevel = 1 ; for ( reslevelno = 0 ; ok_reslevel ; reslevelno + + ) { ok_reslevel = 0 ; for ( compno = 0 ; compno < s - > ncomponents ; compno + + ) { Jpeg2000CodingStyle * codsty = tile - > codsty + compno ; Jpeg2000QuantStyle * qntsty = tile - > qntsty + compno ; if ( reslevelno < codsty - > nreslevels ) { Jpeg2000ResLevel * rlevel = tile - > comp[compno] . reslevel + reslevelno ; ok_reslevel = 1 ; for ( precno = 0 ; precno < rlevel - > num_precincts_x * rlevel - > num_precincts_y ; precno + + ) if ( ( ret = jpeg2000_decode_packet ( s , codsty , rlevel , precno , layno , qntsty - > expn + ( reslevelno ? 3 * ( reslevelno - 1 ) + 1 : 0 ) , qntsty - > nguardbits ) ) < 0 ) return ret ; } } } } break ; case JPEG2000_PGOD_CPRL : for ( compno = 0 ; compno < s - > ncomponents ; compno + + ) { Jpeg2000CodingStyle * codsty = tile - > codsty + compno ; Jpeg2000QuantStyle * qntsty = tile - > qntsty + compno ; / * Set bit stream buffer address according to tile - part . * For DCinema one tile - part per component , so can be * indexed by component . * / s - > buf = tile - > tile_part[compno] . tp_start_bstrm ; / * Position loop ( y axis ) * TODO : Automate computing of step 256 . * Fixed here , but to be computed before entering here . * / for ( y = 0 ; y < s - > height ; y + = 256 ) { / * Position loop ( y axis ) * TODO : automate computing of step 256 . * Fixed here , but to be computed before entering here . * / for ( x = 0 ; x < s - > width ; x + = 256 ) { for ( reslevelno = 0 ; reslevelno < codsty - > nreslevels ; reslevelno + + ) { uint16_t prcx , prcy ; uint8_t reducedresno = codsty - > nreslevels - 1 - reslevelno ; // == > N_L - r Jpeg2000ResLevel * rlevel = tile - > comp[compno] . reslevel + reslevelno ; if ( ! ( ( y % ( 1 < < ( rlevel - > log2_prec_height + reducedresno ) ) == 0 ) || ( y == 0 ) ) ) // TODO : 2nd condition simplified as try0 always =0 for dcinema continue ; if ( ! ( ( x % ( 1 < < ( rlevel - > log2_prec_width + reducedresno ) ) == 0 ) || ( x == 0 ) ) ) // TODO : 2nd condition simplified as try0 always =0 for dcinema continue ; // check if a precinct exists prcx = ff_jpeg2000_ceildivpow2 ( x , reducedresno ) > > rlevel - > log2_prec_width ; prcy = ff_jpeg2000_ceildivpow2 ( y , reducedresno ) > > rlevel - > log2_prec_height ; precno = prcx + rlevel - > num_precincts_x * prcy ; for ( layno = 0 ; layno < tile - > codsty[0] . nlayers ; layno + + ) { if ( ( ret = jpeg2000_decode_packet ( s , codsty , rlevel , precno , layno , qntsty - > expn + ( reslevelno ? 3 * ( reslevelno - 1 ) + 1 : 0 ) , qntsty - > nguardbits ) ) < 0 ) return ret ; } } } } } break ; default : break ; } / * EOC marker reached * / s - > buf + = 2 ; return 0 ; }",1
"int opt_loglevel ( void * optctx , const char * opt , const char * arg ) { const struct { const char * name ; int level ; } log_levels[] = { { quiet , AV_LOG_QUIET } , { panic , AV_LOG_PANIC } , { fatal , AV_LOG_FATAL } , { error , AV_LOG_ERROR } , { warning , AV_LOG_WARNING } , { info , AV_LOG_INFO } , { verbose , AV_LOG_VERBOSE } , { debug , AV_LOG_DEBUG } , } ; char * tail ; int level ; int i ; for ( i = 0 ; i < FF_ARRAY_ELEMS ( log_levels ) ; i + + ) { if ( ! strcmp ( log_levels[i] . name , arg ) ) { av_log_set_level ( log_levels[i] . level ) ; return 0 ; } } level = strtol ( arg , & tail , 10 ) ; if ( * tail ) { av_log ( NULL , AV_LOG_FATAL , Invalid loglevel \ %s\ . Possible levels are numbers or : \n , arg ) ; for ( i = 0 ; i < FF_ARRAY_ELEMS ( log_levels ) ; i + + ) av_log ( NULL , AV_LOG_FATAL , \ %s\ \n , log_levels[i] . name ) ; exit ( 1 ) ; } av_log_set_level ( level ) ; return 0 ; }",1
"const AVOption * av_opt_next ( void * obj , const AVOption * last ) { AVClass * class = * ( AVClass * * ) obj ; if ( ! last & & class - > option & & class - > option[0] . name ) return class - > option ; if ( last & & last[1] . name ) return + + last ; return NULL ; }",0
"int avfilter_graph_create_filter ( AVFilterContext * * filt_ctx , AVFilter * filt , const char * name , const char * args , void * opaque , AVFilterGraph * graph_ctx ) { int ret ; * filt_ctx = avfilter_graph_alloc_filter ( graph_ctx , filt , name ) ; if ( ! * filt_ctx ) return AVERROR ( ENOMEM ) ; ret = avfilter_init_filter ( * filt_ctx , args , opaque ) ; if ( ret < 0 ) goto fail ; return 0 ; fail : if ( * filt_ctx ) avfilter_free ( * filt_ctx ) ; * filt_ctx = NULL ; return ret ; }",0
"static int io_open_default ( AVFormatContext * s , AVIOContext * * pb , const char * url , int flags , AVDictionary * * options ) { if FF_API_OLD_OPEN_CALLBACKS FF_DISABLE_DEPRECATION_WARNINGS if ( s - > open_cb ) return s - > open_cb ( s , pb , url , flags , & s - > interrupt_callback , options ) ; FF_ENABLE_DEPRECATION_WARNINGS endif return ffio_open_whitelist ( pb , url , flags , & s - > interrupt_callback , options , s - > protocol_whitelist , s - > protocol_blacklist ) ; }",1
"int ff_pred_weight_table ( H264Context * h ) { int list , i ; int luma_def , chroma_def ; h - > use_weight = 0 ; h - > use_weight_chroma = 0 ; h - > luma_log2_weight_denom = get_ue_golomb ( & h - > gb ) ; if ( h - > sps . chroma_format_idc ) h - > chroma_log2_weight_denom = get_ue_golomb ( & h - > gb ) ; luma_def = 1 < < h - > luma_log2_weight_denom ; chroma_def = 1 < < h - > chroma_log2_weight_denom ; for ( list = 0 ; list < 2 ; list + + ) { h - > luma_weight_flag[list] = 0 ; h - > chroma_weight_flag[list] = 0 ; for ( i = 0 ; i < h - > ref_count[list] ; i + + ) { int luma_weight_flag , chroma_weight_flag ; luma_weight_flag = get_bits1 ( & h - > gb ) ; if ( luma_weight_flag ) { h - > luma_weight[i][list][0] = get_se_golomb ( & h - > gb ) ; h - > luma_weight[i][list][1] = get_se_golomb ( & h - > gb ) ; if ( h - > luma_weight[i][list][0] ! = luma_def || h - > luma_weight[i][list][1] ! = 0 ) { h - > use_weight = 1 ; h - > luma_weight_flag[list] = 1 ; } else { h - > luma_weight[i][list][0] = luma_def ; h - > luma_weight[i][list][1] = 0 ; if ( h - > sps . chroma_format_idc ) { chroma_weight_flag = get_bits1 ( & h - > gb ) ; if ( chroma_weight_flag ) { int j ; for ( j = 0 ; j < 2 ; j + + ) { h - > chroma_weight[i][list][j][0] = get_se_golomb ( & h - > gb ) ; h - > chroma_weight[i][list][j][1] = get_se_golomb ( & h - > gb ) ; if ( h - > chroma_weight[i][list][j][0] ! = chroma_def || h - > chroma_weight[i][list][j][1] ! = 0 ) { h - > use_weight_chroma = 1 ; h - > chroma_weight_flag[list] = 1 ; } else { int j ; for ( j = 0 ; j < 2 ; j + + ) { h - > chroma_weight[i][list][j][0] = chroma_def ; h - > chroma_weight[i][list][j][1] = 0 ; if ( h - > slice_type_nos ! = AV_PICTURE_TYPE_B ) break ; h - > use_weight = h - > use_weight || h - > use_weight_chroma ; return 0 ;",1
"static int mpeg_decode_frame ( AVCodecContext * avctx , void * data , int * got_output , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; Mpeg1Context * s = avctx - > priv_data ; AVFrame * picture = data ; MpegEncContext * s2 = & s - > mpeg_enc_ctx ; av_dlog ( avctx , fill_buffer\n ) ; if ( buf_size == 0 || ( buf_size == 4 & & AV_RB32 ( buf ) == SEQ_END_CODE ) ) { / * special case for last picture * / if ( s2 - > low_delay == 0 & & s2 - > next_picture_ptr ) { int ret = av_frame_ref ( picture , & s2 - > next_picture_ptr - > f ) ; if ( ret < 0 ) return ret ; s2 - > next_picture_ptr = NULL ; * got_output = 1 ; } return buf_size ; } if ( s2 - > flags & CODEC_FLAG_TRUNCATED ) { int next = ff_mpeg1_find_frame_end ( & s2 - > parse_context , buf , buf_size , NULL ) ; if ( ff_combine_frame ( & s2 - > parse_context , next , ( const uint8_t * * ) & buf , & buf_size ) < 0 ) return buf_size ; } if ( s - > mpeg_enc_ctx_allocated == 0 & & avctx - > codec_tag == AV_RL32 ( VCR2 ) ) vcr2_init_sequence ( avctx ) ; s - > slice_count = 0 ; if ( avctx - > extradata & & ! s - > extradata_decoded ) { int ret = decode_chunks ( avctx , picture , got_output , avctx - > extradata , avctx - > extradata_size ) ; s - > extradata_decoded = 1 ; if ( ret < 0 & & ( avctx - > err_recognition & AV_EF_EXPLODE ) ) return ret ; } return decode_chunks ( avctx , picture , got_output , buf , buf_size ) ; }",1
"static void blur ( CoverContext * cover , AVFrame * in , int offx , int offy ) { int x , y , p ; for ( p=0 ; p < 3 ; p + + ) { int ox = offx > > ! ! p ; int oy = offy > > ! ! p ; int stride = in - > linesize[p] ; uint8_t * data = in - > data[p] + ox + oy * stride ; int w = FF_CEIL_RSHIFT ( cover - > width , ! ! p ) ; int h = FF_CEIL_RSHIFT ( cover - > height , ! ! p ) ; int iw = FF_CEIL_RSHIFT ( in - > width , ! ! p ) ; int ih = FF_CEIL_RSHIFT ( in - > height , ! ! p ) ; for ( y = 0 ; y < h ; y + + ) { for ( x = 0 ; x < w ; x + + ) { int c = 0 ; int s = 0 ; if ( ox ) { int scale = 65536 / ( x + 1 ) ; s + = data[ - 1 + y * stride] * scale ; c + = scale ; } if ( oy ) { int scale = 65536 / ( y + 1 ) ; s + = data[x - stride] * scale ; c + = scale ; } if ( ox + w < iw ) { int scale = 65536 / ( w - x ) ; s + = data[w + y * stride] * scale ; c + = scale ; } if ( oy + h < ih ) { int scale = 65536 / ( h - y ) ; s + = data[x + h * stride] * scale ; c + = scale ; } data[x + y * stride] = ( s + ( c > > 1 ) ) / c ; } } } }",1
"static int wav_read_header ( AVFormatContext * s ) { int64_t size , av_uninit ( data_size ) ; int64_t sample_count = 0 ; int rf64 = 0 ; char start_code[32] ; uint32_t tag ; AVIOContext * pb = s - > pb ; AVStream * st = NULL ; WAVDemuxContext * wav = s - > priv_data ; int ret , got_fmt = 0 ; int64_t next_tag_ofs , data_ofs = - 1 ; wav - > unaligned = avio_tell ( s - > pb ) & 1 ; wav - > smv_data_ofs = - 1 ; / * read chunk ID * / tag = avio_rl32 ( pb ) ; switch ( tag ) { case MKTAG ( ' R ' , ' I ' , ' F ' , ' F ' ) : break ; case MKTAG ( ' R ' , ' I ' , ' F ' , ' X ' ) : wav - > rifx = 1 ; break ; case MKTAG ( ' R ' , ' F ' , ' 6 ' , ' 4 ' ) : rf64 = 1 ; break ; default : av_get_codec_tag_string ( start_code , sizeof ( start_code ) , tag ) ; av_log ( s , AV_LOG_ERROR , invalid start code %s in RIFF header\n , start_code ) ; return AVERROR_INVALIDDATA ; / * read chunk size * / avio_rl32 ( pb ) ; / * read format * / if ( avio_rl32 ( pb ) ! = MKTAG ( ' W ' , ' A ' , ' V ' , ' E ' ) ) { av_log ( s , AV_LOG_ERROR , invalid format in RIFF header\n ) ; return AVERROR_INVALIDDATA ; if ( rf64 ) { if ( avio_rl32 ( pb ) ! = MKTAG ( ' d ' , ' s ' , ' 6 ' , ' 4 ' ) ) return AVERROR_INVALIDDATA ; size = avio_rl32 ( pb ) ; if ( size < 24 ) return AVERROR_INVALIDDATA ; avio_rl64 ( pb ) ; / * RIFF size * / data_size = avio_rl64 ( pb ) ; sample_count = avio_rl64 ( pb ) ; if ( data_size < 0 || sample_count < 0 ) { av_log ( s , AV_LOG_ERROR , negative data_size and/or sample_count in ds64 : data_size = % PRId64 , sample_count = % PRId64 \n , data_size , sample_count ) ; return AVERROR_INVALIDDATA ; avio_skip ( pb , size - 24 ) ; / * skip rest of ds64 chunk * / for ( ; ; ) { AVStream * vst ; size = next_tag ( pb , & tag , wav - > rifx ) ; next_tag_ofs = avio_tell ( pb ) + size ; if ( avio_feof ( pb ) ) break ; switch ( tag ) { case MKTAG ( ' f ' , ' m ' , ' t ' , ' ' ) : / * only parse the first ' fmt ' tag found * / if ( ! got_fmt & & ( ret = wav_parse_fmt_tag ( s , size , & st ) ) < 0 ) { return ret ; } else if ( got_fmt ) av_log ( s , AV_LOG_WARNING , found more than one ' fmt ' tag\n ) ; got_fmt = 1 ; break ; case MKTAG ( ' d ' , ' a ' , ' t ' , ' a ' ) : if ( ! got_fmt ) { av_log ( s , AV_LOG_ERROR , found no ' fmt ' tag before the ' data ' tag\n ) ; return AVERROR_INVALIDDATA ; if ( rf64 ) { next_tag_ofs = wav - > data_end = avio_tell ( pb ) + data_size ; } else if ( size ! = 0xFFFFFFFF ) { data_size = size ; next_tag_ofs = wav - > data_end = size ? next_tag_ofs : INT64_MAX ; } else { av_log ( s , AV_LOG_WARNING , Ignoring maximum wav data size , file may be invalid\n ) ; data_size = 0 ; next_tag_ofs = wav - > data_end = INT64_MAX ; data_ofs = avio_tell ( pb ) ; / * don ' t look for footer metadata if we can ' t seek or if we don ' t * know where the data tag ends * / if ( ! pb - > seekable || ( ! rf64 & & ! size ) ) goto break_loop ; break ; case MKTAG ( ' f ' , ' a ' , ' c ' , ' t ' ) : if ( ! sample_count ) sample_count = ( ! wav - > rifx ? avio_rl32 ( pb ) : avio_rb32 ( pb ) ) ; break ; case MKTAG ( ' b ' , ' e ' , ' x ' , ' t ' ) : if ( ( ret = wav_parse_bext_tag ( s , size ) ) < 0 ) return ret ; break ; case MKTAG ( ' S ' , ' M ' , ' V ' , ' 0 ' ) : if ( ! got_fmt ) { av_log ( s , AV_LOG_ERROR , found no ' fmt ' tag before the ' SMV0 ' tag\n ) ; return AVERROR_INVALIDDATA ; // SMV file , a wav file with video appended . if ( size ! = MKTAG ( ' 0 ' , ' 2 ' , ' 0 ' , ' 0 ' ) ) { av_log ( s , AV_LOG_ERROR , Unknown SMV version found\n ) ; goto break_loop ; av_log ( s , AV_LOG_DEBUG , Found SMV data\n ) ; wav - > smv_given_first = 0 ; vst = avformat_new_stream ( s , NULL ) ; if ( ! vst ) return AVERROR ( ENOMEM ) ; avio_r8 ( pb ) ; vst - > id = 1 ; vst - > codec - > codec_type = AVMEDIA_TYPE_VIDEO ; vst - > codec - > codec_id = AV_CODEC_ID_SMVJPEG ; vst - > codec - > width = avio_rl24 ( pb ) ; vst - > codec - > height = avio_rl24 ( pb ) ; if ( ff_alloc_extradata ( vst - > codec , 4 ) ) { av_log ( s , AV_LOG_ERROR , Could not allocate extradata . \n ) ; return AVERROR ( ENOMEM ) ; size = avio_rl24 ( pb ) ; wav - > smv_data_ofs = avio_tell ( pb ) + ( size - 5 ) * 3 ; avio_rl24 ( pb ) ; wav - > smv_block_size = avio_rl24 ( pb ) ; avpriv_set_pts_info ( vst , 32 , 1 , avio_rl24 ( pb ) ) ; vst - > duration = avio_rl24 ( pb ) ; avio_rl24 ( pb ) ; avio_rl24 ( pb ) ; wav - > smv_frames_per_jpeg = avio_rl24 ( pb ) ; if ( wav - > smv_frames_per_jpeg > 65536 ) { av_log ( s , AV_LOG_ERROR , too many frames per jpeg\n ) ; return AVERROR_INVALIDDATA ; AV_WL32 ( vst - > codec - > extradata , wav - > smv_frames_per_jpeg ) ; wav - > smv_cur_pt = 0 ; goto break_loop ; case MKTAG",1
"static int parse_bsfs ( void * log_ctx , const char * bsfs_spec , AVBitStreamFilterContext * * bsfs ) { char * bsf_name , * buf , * saveptr ; int ret = 0 ; if ( ! ( buf = av_strdup ( bsfs_spec ) ) ) return AVERROR ( ENOMEM ) ; while ( bsf_name = av_strtok ( buf , , , & saveptr ) ) { AVBitStreamFilterContext * bsf = av_bitstream_filter_init ( bsf_name ) ; if ( ! bsf ) { av_log ( log_ctx , AV_LOG_ERROR , Cannot initialize bitstream filter with name ' %s ' , unknown filter or internal error happened\n , bsf_name ) ; ret = AVERROR_UNKNOWN ; goto end ; } / * append bsf context to the list of bsf contexts * / * bsfs = bsf ; bsfs = & bsf - > next ; buf = NULL ; } end : av_free ( buf ) ; return ret ; }",1
"void ff_ivi_output_plane ( IVIPlaneDesc * plane , uint8_t * dst , int dst_pitch ) { int x , y ; const int16_t * src = plane - > bands[0] . buf ; uint32_t pitch = plane - > bands[0] . pitch ; for ( y = 0 ; y < plane - > height ; y + + ) { for ( x = 0 ; x < plane - > width ; x + + ) dst[x] = av_clip_uint8 ( src[x] + 128 ) ; src + = pitch ; dst + = dst_pitch ; } }",1
static void rstrip_spaces_buf ( AVBPrint * buf ) { while ( buf - > len > 0 & & buf - > str[buf - > len - 1] == ' ' ) buf - > str[ - - buf - > len] = 0 ; },1
"static inline void RENAME ( rgb24ToY ) ( uint8_t * dst , const uint8_t * src , long width , uint32_t * unused ) { if COMPILE_TEMPLATE_MMX RENAME ( bgr24ToY_mmx ) ( dst , src , width , PIX_FMT_RGB24 ) ; else int i ; for ( i=0 ; i < width ; i + + ) { int r= src[i * 3 + 0] ; int g= src[i * 3 + 1] ; int b= src[i * 3 + 2] ; dst[i]= ( ( RY * r + GY * g + BY * b + ( 33 < < ( RGB2YUV_SHIFT - 1 ) ) ) > > RGB2YUV_SHIFT ) ; } endif }",0
"static int ff_estimate_motion_b ( MpegEncContext * s , int mb_x , int mb_y , int16_t ( * mv_table ) [2] , int ref_index , int f_code ) { MotionEstContext * const c= & s - > me ; int mx , my , dmin ; int P[10][2] ; const int shift= 1 + s - > quarter_sample ; const int mot_stride = s - > mb_stride ; const int mot_xy = mb_y * mot_stride + mb_x ; uint8_t * const mv_penalty= c - > mv_penalty[f_code] + MAX_MV ; int mv_scale ; c - > penalty_factor = get_penalty_factor ( s - > lambda , s - > lambda2 , c - > avctx - > me_cmp ) ; c - > sub_penalty_factor= get_penalty_factor ( s - > lambda , s - > lambda2 , c - > avctx - > me_sub_cmp ) ; c - > mb_penalty_factor = get_penalty_factor ( s - > lambda , s - > lambda2 , c - > avctx - > mb_cmp ) ; c - > current_mv_penalty= mv_penalty ; get_limits ( s , 16 * mb_x , 16 * mb_y ) ; switch ( s - > me_method ) { case ME_ZERO : default : no_motion_search ( s , & mx , & my ) ; dmin = 0 ; mx - = mb_x * 16 ; my - = mb_y * 16 ; break ; if 0 case ME_FULL : dmin = full_motion_search ( s , & mx , & my , range , ref_picture ) ; mx - = mb_x * 16 ; my - = mb_y * 16 ; break ; case ME_LOG : dmin = log_motion_search ( s , & mx , & my , range / 2 , ref_picture ) ; mx - = mb_x * 16 ; my - = mb_y * 16 ; break ; case ME_PHODS : dmin = phods_motion_search ( s , & mx , & my , range / 2 , ref_picture ) ; mx - = mb_x * 16 ; my - = mb_y * 16 ; break ; endif case ME_X1 : case ME_EPZS : { P_LEFT[0] = mv_table[mot_xy - 1][0] ; P_LEFT[1] = mv_table[mot_xy - 1][1] ; if ( P_LEFT[0] > ( c - > xmax < < shift ) ) P_LEFT[0] = ( c - > xmax < < shift ) ; / * special case for first line * / if ( ! s - > first_slice_line ) { P_TOP[0] = mv_table[mot_xy - mot_stride ][0] ; P_TOP[1] = mv_table[mot_xy - mot_stride ][1] ; P_TOPRIGHT[0] = mv_table[mot_xy - mot_stride + 1 ][0] ; P_TOPRIGHT[1] = mv_table[mot_xy - mot_stride + 1 ][1] ; if ( P_TOP[1] > ( c - > ymax < < shift ) ) P_TOP[1]= ( c - > ymax < < shift ) ; if ( P_TOPRIGHT[0] < ( c - > xmin < < shift ) ) P_TOPRIGHT[0]= ( c - > xmin < < shift ) ; if ( P_TOPRIGHT[1] > ( c - > ymax < < shift ) ) P_TOPRIGHT[1]= ( c - > ymax < < shift ) ; P_MEDIAN[0]= mid_pred ( P_LEFT[0] , P_TOP[0] , P_TOPRIGHT[0] ) ; P_MEDIAN[1]= mid_pred ( P_LEFT[1] , P_TOP[1] , P_TOPRIGHT[1] ) ; } c - > pred_x= P_LEFT[0] ; c - > pred_y= P_LEFT[1] ; } if ( mv_table == s - > b_forw_mv_table ) { mv_scale= ( s - > pb_time < < 16 ) / ( s - > pp_time < < shift ) ; } else { mv_scale= ( ( s - > pb_time - s - > pp_time ) < < 16 ) / ( s - > pp_time < < shift ) ; } dmin = ff_epzs_motion_search ( s , & mx , & my , P , 0 , ref_index , s - > p_mv_table , mv_scale , 0 , 16 ) ; break ; } dmin= c - > sub_motion_search ( s , & mx , & my , dmin , 0 , ref_index , 0 , 16 ) ; if ( c - > avctx - > me_sub_cmp ! = c - > avctx - > mb_cmp & & ! c - > skip ) dmin= get_mb_score ( s , mx , my , 0 , ref_index ) ; //printf ( %d %d %d %d// , s - > mb_x , s - > mb_y , mx , my ) ; // s - > mb_type[mb_y * s - > mb_width + mb_x]= mb_type ; mv_table[mot_xy][0]= mx ; mv_table[mot_xy][1]= my ; return dmin ; }",0
"static int vc1_decode_b_mb_intfr ( VC1Context * v ) { MpegEncContext * s = & v - > s ; GetBitContext * gb = & s - > gb ; int i , j ; int mb_pos = s - > mb_x + s - > mb_y * s - > mb_stride ; int cbp = 0 ; / * cbp decoding stuff * / int mqdiff , mquant ; / * MB quantization * / int ttmb = v - > ttfrm ; / * MB Transform type * / int mvsw = 0 ; / * motion vector switch * / int mb_has_coeffs = 1 ; / * last_flag * / int dmv_x , dmv_y ; / * Differential MV components * / int val ; / * temp value * / int first_block = 1 ; int dst_idx , off ; int skipped , direct , twomv = 0 ; int block_cbp = 0 , pat , block_tt = 0 ; int idx_mbmode = 0 , mvbp ; int stride_y , fieldtx ; int bmvtype = BMV_TYPE_BACKWARD ; int dir , dir2 ; mquant = v - > pq ; / * Lossy initialization * / s - > mb_intra = 0 ; if ( v - > skip_is_raw ) skipped = get_bits1 ( gb ) ; else skipped = v - > s . mbskip_table[mb_pos] ; if ( ! skipped ) { idx_mbmode = get_vlc2 ( gb , v - > mbmode_vlc - > table , VC1_INTFR_NON4MV_MBMODE_VLC_BITS , 2 ) ; if ( ff_vc1_mbmode_intfrp[0][idx_mbmode][0] == MV_PMODE_INTFR_2MV_FIELD ) { twomv = 1 ; v - > blk_mv_type[s - > block_index[0]] = 1 ; v - > blk_mv_type[s - > block_index[1]] = 1 ; v - > blk_mv_type[s - > block_index[2]] = 1 ; v - > blk_mv_type[s - > block_index[3]] = 1 ; } else { v - > blk_mv_type[s - > block_index[0]] = 0 ; v - > blk_mv_type[s - > block_index[1]] = 0 ; v - > blk_mv_type[s - > block_index[2]] = 0 ; v - > blk_mv_type[s - > block_index[3]] = 0 ; } } if ( v - > dmb_is_raw ) direct = get_bits1 ( gb ) ; else direct = v - > direct_mb_plane[mb_pos] ; if ( direct ) { s - > mv[0][0][0] = s - > current_picture . motion_val[0][s - > block_index[0]][0] = scale_mv ( s - > next_picture . motion_val[1][s - > block_index[0]][0] , v - > bfraction , 0 , s - > quarter_sample ) ; s - > mv[0][0][1] = s - > current_picture . motion_val[0][s - > block_index[0]][1] = scale_mv ( s - > next_picture . motion_val[1][s - > block_index[0]][1] , v - > bfraction , 0 , s - > quarter_sample ) ; s - > mv[1][0][0] = s - > current_picture . motion_val[1][s - > block_index[0]][0] = scale_mv ( s - > next_picture . motion_val[1][s - > block_index[0]][0] , v - > bfraction , 1 , s - > quarter_sample ) ; s - > mv[1][0][1] = s - > current_picture . motion_val[1][s - > block_index[0]][1] = scale_mv ( s - > next_picture . motion_val[1][s - > block_index[0]][1] , v - > bfraction , 1 , s - > quarter_sample ) ; if ( twomv ) { s - > mv[0][2][0] = s - > current_picture . motion_val[0][s - > block_index[2]][0] = scale_mv ( s - > next_picture . motion_val[1][s - > block_index[2]][0] , v - > bfraction , 0 , s - > quarter_sample ) ; s - > mv[0][2][1] = s - > current_picture . motion_val[0][s - > block_index[2]][1] = scale_mv ( s - > next_picture . motion_val[1][s - > block_index[2]][1] , v - > bfraction , 0 , s - > quarter_sample ) ; s - > mv[1][2][0] = s - > current_picture . motion_val[1][s - > block_index[2]][0] = scale_mv ( s - > next_picture . motion_val[1][s - > block_index[2]][0] , v - > bfraction , 1 , s - > quarter_sample ) ; s - > mv[1][2][1] = s - > current_picture . motion_val[1][s - > block_index[2]][1] = scale_mv ( s - > next_picture . motion_val[1][s - > block_index[2]][1] , v - > bfraction , 1 , s - > quarter_sample ) ; for ( i = 1 ; i < 4 ; i + = 2 ) { s - > mv[0][i][0] = s - > current_picture . motion_val[0][s - > block_index[i]][0] = s - > mv[0][i - 1][0] ; s - > mv[0][i][1] = s - > current_picture . motion_val[0][s - > block_index[i]][1] = s - > mv[0][i - 1][1] ; s - > mv[1][i][0] = s - > current_picture . motion_val[1][s - > block_index[i]][0] = s - > mv[1][i - 1][0] ; s - > mv[1][i][1] = s - > current_picture . motion_val[1][s - > block_index[i]][1] = s - > mv[1][i - 1][1] ; } } else { for ( i = 1 ; i < 4 ; i + + ) { s - > mv[0][i][0] = s - > current_picture . motion_val[0][s - > block_index[i]][0] = s - > mv[0][0][0] ; s - > mv[0][i][1] = s - > current_picture . motion_val[0][s - > block_index[i]][1] = s - > mv[0][0][1] ; s - > mv[1][i][0] = s - > current_picture . motion_val[1][s - > block_index[i]][0] = s - > mv[1][0][0] ; s - > mv[1][i][1] = s - > current_picture . motion_val[1][s - > block_index[i]][1] = s - > mv[1][0][1] ; } } } if ( ff_vc1_mbmode_intfrp[0][idx_mbmode][0] == MV_PMODE_INTFR_INTRA ) { // intra MB for ( i = 0 ; i < 4 ; i + + ) { s - > mv[0][i][0] = s - > current_picture . motion_val[0][s - > block_index[i]][0] = 0 ; s - > mv[0][i][1] = s - > current_picture . motion_val[0][s - > block_index[i]][1] = 0 ; s - > mv[1][i][0] = s - > current_picture . motion_val[1][s - > block_index[i]][0] = 0 ; s - > mv[1][i][1] = s - > current_picture . motion_val[1][s - > block_index[i]][1] = 0 ; } s - > current_picture . mb_type[mb_pos] = MB_TYPE_INTRA ; s - > mb_intra = v - > is_intra[s - > mb_x] = 1 ; for ( i = 0 ; i < 6 ; i + + ) v - > mb_type[0][s - > block_index[i]] = 1 ; fieldtx = v - > fieldtx_plane[mb_pos] = get_bits1 ( gb ) ; mb_has_coeffs = get_bits1 ( gb ) ; if ( mb_has_coeffs ) cbp = 1 + get_vlc2 ( & v - > s . gb , v - > cbpcy_vlc - > table , VC1_CBPCY_P_VLC_BITS , 2 ) ; v - > s . ac_pred = v - > acpred_plane[mb_pos] = get_bits1 ( gb ) ; GET_MQUANT ( ) ; s - > current_picture . qscale_table[mb_pos] = mquant ; / * Set DC scale - y and c use the same ( not sure if necessary here ) * / s - > y_dc_scale = s - > y_dc_scale_table[mquant] ; s - > c_dc_scale = s - > c_dc_scale_table[mquant] ; dst_idx = 0 ; for ( i = 0 ; i < 6 ; i + + ) { s - > dc_val[0][s - > block_index[i]] = 0 ;",1
"static int execute_code ( AVCodecContext * avctx , int c ) { AnsiContext * s = avctx - > priv_data ; int ret , i , width , height ; switch ( c ) { case ' A ' : //Cursor Up s - > y = FFMAX ( s - > y - ( s - > nb_args > 0 ? s - > args[0] * s - > font_height : s - > font_height ) , 0 ) ; break ; case ' B ' : //Cursor Down s - > y = FFMIN ( s - > y + ( s - > nb_args > 0 ? s - > args[0] * s - > font_height : s - > font_height ) , avctx - > height - s - > font_height ) ; break ; case ' C ' : //Cursor Right s - > x = FFMIN ( s - > x + ( s - > nb_args > 0 ? s - > args[0] * FONT_WIDTH : FONT_WIDTH ) , avctx - > width - FONT_WIDTH ) ; break ; case ' D ' : //Cursor Left s - > x = FFMAX ( s - > x - ( s - > nb_args > 0 ? s - > args[0] * FONT_WIDTH : FONT_WIDTH ) , 0 ) ; break ; case ' H ' : //Cursor Position case ' f ' : //Horizontal and Vertical Position s - > y = s - > nb_args > 0 ? av_clip ( ( s - > args[0] - 1 ) * s - > font_height , 0 , avctx - > height - s - > font_height ) : 0 ; s - > x = s - > nb_args > 1 ? av_clip ( ( s - > args[1] - 1 ) * FONT_WIDTH , 0 , avctx - > width - FONT_WIDTH ) : 0 ; break ; case ' h ' : //set creen mode case ' l ' : //reset screen mode if ( s - > nb_args < 2 ) s - > args[0] = DEFAULT_SCREEN_MODE ; switch ( s - > args[0] ) { case 0 : case 1 : case 4 : case 5 : case 13 : case 19 : //320x200 ( 25 rows ) s - > font = ff_cga_font ; s - > font_height = 8 ; width = 40 < < 3 ; height = 25 < < 3 ; break ; case 2 : case 3 : //640x400 ( 25 rows ) s - > font = ff_vga16_font ; s - > font_height = 16 ; width = 80 < < 3 ; height = 25 < < 4 ; break ; case 6 : case 14 : //640x200 ( 25 rows ) s - > font = ff_cga_font ; s - > font_height = 8 ; width = 80 < < 3 ; height = 25 < < 3 ; break ; case 7 : //set line wrapping break ; case 15 : case 16 : //640x350 ( 43 rows ) s - > font = ff_cga_font ; s - > font_height = 8 ; width = 80 < < 3 ; height = 43 < < 3 ; break ; case 17 : case 18 : //640x480 ( 60 rows ) s - > font = ff_cga_font ; s - > font_height = 8 ; width = 80 < < 3 ; height = 60 < < 4 ; break ; default : avpriv_request_sample ( avctx , Unsupported screen mode ) ; } if ( width ! = avctx - > width || height ! = avctx - > height ) { av_frame_unref ( s - > frame ) ; ret = ff_set_dimensions ( avctx , width , height ) ; if ( ret < 0 ) return ret ; ret = ff_get_buffer ( avctx , s - > frame , AV_GET_BUFFER_FLAG_REF ) ; if ( ret < 0 ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed\n ) ; return ret ; } s - > frame - > pict_type = AV_PICTURE_TYPE_I ; s - > frame - > palette_has_changed = 1 ; memcpy ( s - > frame - > data[1] , ff_cga_palette , 16 * 4 ) ; erase_screen ( avctx ) ; } else if ( c == ' l ' ) { erase_screen ( avctx ) ; } break ; case ' J ' : //Erase in Page switch ( s - > args[0] ) { case 0 : erase_line ( avctx , s - > x , avctx - > width - s - > x ) ; if ( s - > y < avctx - > height - s - > font_height ) memset ( s - > frame - > data[0] + ( s - > y + s - > font_height ) * s - > frame - > linesize[0] , DEFAULT_BG_COLOR , ( avctx - > height - s - > y - s - > font_height ) * s - > frame - > linesize[0] ) ; break ; case 1 : erase_line ( avctx , 0 , s - > x ) ; if ( s - > y > 0 ) memset ( s - > frame - > data[0] , DEFAULT_BG_COLOR , s - > y * s - > frame - > linesize[0] ) ; break ; case 2 : erase_screen ( avctx ) ; } break ; case ' K ' : //Erase in Line switch ( s - > args[0] ) { case 0 : erase_line ( avctx , s - > x , avctx - > width - s - > x ) ; break ; case 1 : erase_line ( avctx , 0 , s - > x ) ; break ; case 2 : erase_line ( avctx , 0 , avctx - > width ) ; } break ; case ' m ' : //Select Graphics Rendition if ( s - > nb_args == 0 ) { s - > nb_args = 1 ; s - > args[0] = 0 ; } for ( i = 0 ; i < FFMIN ( s - > nb_args , MAX_NB_ARGS ) ; i + + ) { int m = s - > args[i] ; if ( m == 0 ) { s - > attributes = 0 ; s - > fg = DEFAULT_FG_COLOR ; s - > bg = DEFAULT_BG_COLOR ; } else if ( m == 1 || m == 2 || m == 4 || m == 5 || m == 7 || m == 8 ) { s - > attributes |= 1 < < ( m - 1 ) ; } else if ( m > = 30 & & m < = 38 ) { s - > fg = ansi_to_cga[m - 30] ; } else if ( m == 39 ) { s - > fg = ansi_to_cga[DEFAULT_FG_COLOR] ; } else if ( m > = 40 & & m < = 47 ) { s - > bg =",1
"static int compand_drain ( AVFilterLink * outlink ) { AVFilterContext * ctx = outlink - > src ; CompandContext * s = ctx - > priv ; const int channels = outlink - > channels ; AVFrame * frame = NULL ; int chan , i , dindex ; / * 2048 is to limit output frame size during drain * / frame = ff_get_audio_buffer ( outlink , FFMIN ( 2048 , s - > delay_count ) ) ; if ( ! frame ) return AVERROR ( ENOMEM ) ; frame - > pts = s - > pts ; s - > pts + = av_rescale_q ( frame - > nb_samples , ( AVRational ) { 1 , outlink - > sample_rate } , outlink - > time_base ) ; for ( chan = 0 ; chan < channels ; chan + + ) { AVFrame * delay_frame = s - > delay_frame ; double * dbuf = ( double * ) delay_frame - > extended_data[chan] ; double * dst = ( double * ) frame - > extended_data[chan] ; ChanParam * cp = & s - > channels[chan] ; dindex = s - > delay_index ; for ( i = 0 ; i < frame - > nb_samples ; i + + ) { dst[i] = av_clipd ( dbuf[dindex] * get_volume ( s , cp - > volume ) , - 1 , 1 ) ; dindex = MOD ( dindex + 1 , s - > delay_samples ) ; } } s - > delay_count - = frame - > nb_samples ; s - > delay_index = dindex ; return ff_filter_frame ( outlink , frame ) ; }",1
"int avpicture_layout ( const AVPicture * src , int pix_fmt , int width , int height , unsigned char * dest , int dest_size ) { PixFmtInfo * pf = & pix_fmt_info[pix_fmt] ; int i , j , w , h , data_planes ; const unsigned char * s ; int size = avpicture_get_size ( pix_fmt , width , height ) ; if ( size > dest_size ) return - 1 ; if ( pf - > pixel_type == FF_PIXEL_PACKED || pf - > pixel_type == FF_PIXEL_PALETTE ) { if ( pix_fmt == PIX_FMT_YUV422 || pix_fmt == PIX_FMT_UYVY422 || pix_fmt == PIX_FMT_RGB565 || pix_fmt == PIX_FMT_RGB555 ) w = width * 2 ; else if ( pix_fmt == PIX_FMT_UYVY411 ) w = width + width/2 ; else if ( pix_fmt == PIX_FMT_PAL8 ) w = width ; else w = width * ( pf - > depth * pf - > nb_channels / 8 ) ; data_planes = 1 ; h = height ; } else { data_planes = pf - > nb_channels ; w = ( width * pf - > depth + 7 ) /8 ; h = height ; } for ( i=0 ; i < data_planes ; i + + ) { if ( i == 1 ) { w = width > > pf - > x_chroma_shift ; h = height > > pf - > y_chroma_shift ; } s = src - > data[i] ; for ( j=0 ; j < h ; j + + ) { memcpy ( dest , s , w ) ; dest + = w ; s + = src - > linesize[i] ; } } if ( pf - > pixel_type == FF_PIXEL_PALETTE ) memcpy ( ( unsigned char * ) ( ( ( size_t ) dest + 3 ) & 3 ) , src - > data[1] , 256 * 4 ) ; return size ; }",1
"static int read_access_unit ( AVCodecContext * avctx , void * data , int * got_frame_ptr , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; MLPDecodeContext * m = avctx - > priv_data ; GetBitContext gb ; unsigned int length , substr ; unsigned int substream_start ; unsigned int header_size = 4 ; unsigned int substr_header_size = 0 ; uint8_t substream_parity_present[MAX_SUBSTREAMS] ; uint16_t substream_data_len[MAX_SUBSTREAMS] ; uint8_t parity_bits ; int ret ; if ( buf_size < 4 ) return AVERROR_INVALIDDATA ; length = ( AV_RB16 ( buf ) & 0xfff ) * 2 ; if ( length < 4 || length > buf_size ) return AVERROR_INVALIDDATA ; init_get_bits ( & gb , ( buf + 4 ) , ( length - 4 ) * 8 ) ; m - > is_major_sync_unit = 0 ; if ( show_bits_long ( & gb , 31 ) == ( 0xf8726fba > > 1 ) ) { if ( read_major_sync ( m , & gb ) < 0 ) m - > is_major_sync_unit = 1 ; header_size + = m - > major_sync_header_size ; if ( ! m - > params_valid ) { av_log ( m - > avctx , AV_LOG_WARNING , Stream parameters not seen ; skipping frame . \n ) ; * got_frame_ptr = 0 ; return length ; substream_start = 0 ; for ( substr = 0 ; substr < m - > num_substreams ; substr + + ) { int extraword_present , checkdata_present , end , nonrestart_substr ; extraword_present = get_bits1 ( & gb ) ; nonrestart_substr = get_bits1 ( & gb ) ; checkdata_present = get_bits1 ( & gb ) ; skip_bits1 ( & gb ) ; end = get_bits ( & gb , 12 ) * 2 ; substr_header_size + = 2 ; if ( extraword_present ) { if ( m - > avctx - > codec_id == AV_CODEC_ID_MLP ) { av_log ( m - > avctx , AV_LOG_ERROR , There must be no extraword for MLP . \n ) ; skip_bits ( & gb , 16 ) ; substr_header_size + = 2 ; if ( ! ( nonrestart_substr m - > is_major_sync_unit ) ) { av_log ( m - > avctx , AV_LOG_ERROR , Invalid nonrestart_substr . \n ) ; if ( end + header_size + substr_header_size > length ) { av_log ( m - > avctx , AV_LOG_ERROR , Indicated length of substream %d data goes off end of packet . \n , substr ) ; end = length - header_size - substr_header_size ; if ( end < substream_start ) { av_log ( avctx , AV_LOG_ERROR , Indicated end offset of substream %d data is smaller than calculated start offset . \n , substr ) ; if ( substr > m - > max_decoded_substream ) continue ; substream_parity_present[substr] = checkdata_present ; substream_data_len[substr] = end - substream_start ; substream_start = end ; parity_bits = ff_mlp_calculate_parity ( buf , 4 ) ; parity_bits = ff_mlp_calculate_parity ( buf + header_size , substr_header_size ) ; if ( ( ( ( parity_bits > > 4 ) parity_bits ) & 0xF ) ! = 0xF ) { av_log ( avctx , AV_LOG_ERROR , Parity check failed . \n ) ; buf + = header_size + substr_header_size ; for ( substr = 0 ; substr < = m - > max_decoded_substream ; substr + + ) { SubStream * s = & m - > substream[substr] ; init_get_bits ( & gb , buf , substream_data_len[substr] * 8 ) ; m - > matrix_changed = 0 ; memset ( m - > filter_changed , 0 , sizeof ( m - > filter_changed ) ) ; s - > blockpos = 0 ; do { if ( get_bits1 ( & gb ) ) { if ( get_bits1 ( & gb ) ) { / * A restart header should be present . * / if ( read_restart_header ( m , & gb , buf , substr ) < 0 ) goto next_substr ; s - > restart_seen = 1 ; if ( ! s - > restart_seen ) goto next_substr ; if ( read_decoding_params ( m , & gb , substr ) < 0 ) goto next_substr ; if ( ! s - > restart_seen ) goto next_substr ; if ( ( ret = read_block_data ( m , & gb , substr ) ) < 0 ) return ret ; if ( get_bits_count ( & gb ) > = substream_data_len[substr] * 8 ) goto substream_length_mismatch ; } while ( ! get_bits1 ( & gb ) ) ; skip_bits ( & gb , ( - get_bits_count ( & gb ) ) & 15 ) ; if ( substream_data_len[substr] * 8 - get_bits_count ( & gb ) > = 32 ) { int shorten_by ; if ( get_bits ( & gb , 16 ) ! = 0xD234 ) return AVERROR_INVALIDDATA ; shorten_by = get_bits ( & gb , 16 ) ; if ( m - > avctx - > codec_id == AV_CODEC_ID_TRUEHD & & shorten_by & 0x2000 ) s - > blockpos - = FFMIN ( shorten_by & 0x1FFF , s - > blockpos ) ; else if ( m - > avctx - > codec_id == AV_CODEC_ID_MLP & & shorten_by ! = 0xD234 ) return AVERROR_INVALIDDATA ; if ( substr == m - > max_decoded_substream ) av_log ( m - > avctx , AV_LOG_INFO , End of stream indicated . \n ) ; if ( substream_parity_present[substr] ) { uint8_t parity , checksum ; if ( substream_data_len[substr] * 8 - get_bits_count ( & gb ) ! = 16 ) goto substream_length_mismatch ; parity = ff_mlp_calculate_parity ( buf , substream_data_len[substr] - 2 ) ; checksum = ff_mlp_checksum8 ( buf , substream_data_len[substr] - 2 ) ; if ( ( get_bits ( & gb , 8 ) parity ) ! = 0xa9 ) av_log ( m - > avctx , AV_LOG_ERROR , Substream %d parity check failed . \n , substr ) ; if ( get_bits ( & gb , 8 ) ! = checksum ) av_log ( m - > avctx , AV_LOG_ERROR , Substream %d checksum failed . \n , substr ) ; if ( substream_data_len[substr] * 8 ! = get_bits_count ( & gb ) ) goto substream_length_mismatch ; next_substr : if ( ! s - > restart_seen ) av_log ( m - > avctx , AV_LOG_ERROR , No restart header present in substream %d . \n , substr ) ; buf + = substream_data_len[substr] ; if ( ( ret = output_data ( m , m - > max_decoded_substream , data , got_frame_ptr ) ) < 0 ) return ret ; return length ; substream_length_mismatch : av_log ( m - > avctx , AV_LOG_ERROR , substream %d length mismatch\n , substr ) ; return AVERROR_INVALIDDATA ; error : m - > params_valid = 0 ; return AVERROR_INVALIDDATA ;",1
"enum AVCodecID av_guess_codec ( AVOutputFormat * fmt , const char * short_name , const char * filename , const char * mime_type , enum AVMediaType type ) { if ( av_match_name ( segment , fmt - > name ) || av_match_name ( ssegment , fmt - > name ) ) { fmt = av_guess_format ( NULL , filename , NULL ) ; } if ( type == AVMEDIA_TYPE_VIDEO ) { enum AVCodecID codec_id = AV_CODEC_ID_NONE ; if CONFIG_IMAGE2_MUXER if ( ! strcmp ( fmt - > name , image2 ) || ! strcmp ( fmt - > name , image2pipe ) ) { codec_id = ff_guess_image2_codec ( filename ) ; } endif if ( codec_id == AV_CODEC_ID_NONE ) codec_id = fmt - > video_codec ; return codec_id ; } else if ( type == AVMEDIA_TYPE_AUDIO ) return fmt - > audio_codec ; else if ( type == AVMEDIA_TYPE_SUBTITLE ) return fmt - > subtitle_codec ; else return AV_CODEC_ID_NONE ; }",1
"static int rtsp_read_packet ( AVFormatContext * s , AVPacket * pkt ) { RTSPState * rt = s - > priv_data ; RTSPStream * rtsp_st ; int ret , len ; uint8_t buf[RTP_MAX_PACKET_LENGTH] ; / * get next frames from the same RTP packet * / if ( rt - > cur_rtp ) { ret = rtp_parse_packet ( rt - > cur_rtp , pkt , NULL , 0 ) ; if ( ret == 0 ) { rt - > cur_rtp = NULL ; return 0 ; } else if ( ret == 1 ) { return 0 ; } else { rt - > cur_rtp = NULL ; } } / * read next RTP packet * / redo : switch ( rt - > protocol ) { default : case RTSP_PROTOCOL_RTP_TCP : len = tcp_read_packet ( s , & rtsp_st , buf , sizeof ( buf ) ) ; break ; case RTSP_PROTOCOL_RTP_UDP : case RTSP_PROTOCOL_RTP_UDP_MULTICAST : len = udp_read_packet ( s , & rtsp_st , buf , sizeof ( buf ) ) ; if ( rtsp_st - > rtp_ctx ) rtp_check_and_send_back_rr ( rtsp_st - > rtp_ctx , len ) ; break ; } if ( len < 0 ) return AVERROR_IO ; ret = rtp_parse_packet ( rtsp_st - > rtp_ctx , pkt , buf , len ) ; if ( ret < 0 ) goto redo ; if ( ret == 1 ) { / * more packets may follow , so we save the RTP context * / rt - > cur_rtp = rtsp_st - > rtp_ctx ; } return 0 ; }",1
"static int libquvi_read_packet ( AVFormatContext * s , AVPacket * pkt ) { LibQuviContext * qc = s - > priv_data ; return av_read_frame ( qc - > fmtctx , pkt ) ; }",1
"static int wav_parse_fmt_tag ( AVFormatContext * s , int64_t size , AVStream * * st ) { AVIOContext * pb = s - > pb ; int ret ; / * parse fmt header * / * st = av_new_stream ( s , 0 ) ; if ( ! * st ) return AVERROR ( ENOMEM ) ; ff_get_wav_header ( pb , ( * st ) - > codec , size ) ; if ( ret < 0 ) return ret ; ( * st ) - > need_parsing = AVSTREAM_PARSE_FULL ; av_set_pts_info ( * st , 64 , 1 , ( * st ) - > codec - > sample_rate ) ; return 0 ; }",1
"static int chunk_mux_init ( AVFormatContext * s ) { WebMChunkContext * wc = s - > priv_data ; AVFormatContext * oc ; int ret ; ret = avformat_alloc_output_context2 ( & wc - > avf , wc - > oformat , NULL , NULL ) ; if ( ret < 0 ) return ret ; oc = wc - > avf ; oc - > interrupt_callback = s - > interrupt_callback ; oc - > max_delay = s - > max_delay ; av_dict_copy ( & oc - > metadata , s - > metadata , 0 ) ; oc - > priv_data = av_mallocz ( oc - > oformat - > priv_data_size ) ; if ( ! oc - > priv_data ) { avio_close ( oc - > pb ) ; return AVERROR ( ENOMEM ) ; } * ( const AVClass * * ) oc - > priv_data = oc - > oformat - > priv_class ; av_opt_set_defaults ( oc - > priv_data ) ; av_opt_set_int ( oc - > priv_data , dash , 1 , 0 ) ; av_opt_set_int ( oc - > priv_data , cluster_time_limit , wc - > chunk_duration , 0 ) ; av_opt_set_int ( oc - > priv_data , live , 1 , 0 ) ; oc - > streams = s - > streams ; oc - > nb_streams = s - > nb_streams ; return 0 ; }",1
"static int interp ( RA144Context * ractx , int16_t * out , int block_num , int copyold , int energy ) { int work[10] ; int a = block_num + 1 ; int b = NBLOCKS - a ; int x ; // Interpolate block coefficients from the this frame forth block and // last frame forth block for ( x=0 ; x < 30 ; x + + ) out[x] = ( a * ractx - > lpc_coef[0][x] + b * ractx - > lpc_coef[1][x] ) > > 2 ; if ( eval_refl ( work , out , ractx ) ) { // The interpolated coefficients are unstable , copy either new or old // coefficients int_to_int16 ( out , ractx - > lpc_coef[copyold] ) ; return rescale_rms ( ractx - > lpc_refl_rms[copyold] , energy ) ; } else { return rescale_rms ( rms ( work ) , energy ) ; } }",0
"int ff_framesync_request_frame ( FFFrameSync * fs , AVFilterLink * outlink ) { AVFilterContext * ctx = outlink - > src ; int input , ret ; if ( ( ret = ff_framesync_process_frame ( fs , 0 ) ) < 0 ) return ret ; if ( ret > 0 ) return 0 ; if ( fs - > eof ) return AVERROR_EOF ; input = fs - > in_request ; ret = ff_request_frame ( ctx - > inputs[input] ) ; if ( ret == AVERROR_EOF ) { if ( ( ret = ff_framesync_add_frame ( fs , input , NULL ) ) < 0 ) return ret ; if ( ( ret = ff_framesync_process_frame ( fs , 0 ) ) < 0 ) return ret ; ret = 0 ; } return ret ; }",0
AVFrame * avcodec_alloc_frame ( void ) { AVFrame * frame = av_mallocz ( sizeof ( AVFrame ) ) ; if ( frame == NULL ) return NULL ; FF_DISABLE_DEPRECATION_WARNINGS avcodec_get_frame_defaults ( frame ) ; FF_ENABLE_DEPRECATION_WARNINGS return frame ; },0
"static Jpeg2000TgtNode * ff_jpeg2000_tag_tree_init ( int w , int h ) { int pw = w , ph = h ; Jpeg2000TgtNode * res , * t , * t2 ; int32_t tt_size ; tt_size = tag_tree_size ( w , h ) ; if ( tt_size == - 1 ) return NULL ; t = res = av_mallocz_array ( tt_size , sizeof ( * t ) ) ; if ( ! res ) return NULL ; while ( w > 1 || h > 1 ) { int i , j ; pw = w ; ph = h ; w = ( w + 1 ) > > 1 ; h = ( h + 1 ) > > 1 ; t2 = t + pw * ph ; for ( i = 0 ; i < ph ; i + + ) for ( j = 0 ; j < pw ; j + + ) t[i * pw + j] . parent = & t2[ ( i > > 1 ) * w + ( j > > 1 ) ] ; t = t2 ; } t[0] . parent = NULL ; return res ; }",0
"static int source_config_props ( AVFilterLink * outlink ) { AVFilterContext * ctx = outlink - > src ; Frei0rContext * s = ctx - > priv ; if ( av_image_check_size ( s - > w , s - > h , 0 , ctx ) < 0 ) return AVERROR ( EINVAL ) ; outlink - > w = s - > w ; outlink - > h = s - > h ; outlink - > time_base = s - > time_base ; if ( ! ( s - > instance = s - > construct ( outlink - > w , outlink - > h ) ) ) { av_log ( ctx , AV_LOG_ERROR , Impossible to load frei0r instance ) ; return AVERROR ( EINVAL ) ; } return set_params ( ctx , s - > params ) ; }",1
"static int add_hfyu_left_prediction_int16_c ( uint16_t * dst , const uint16_t * src , unsigned mask , int w , int acc ) { int i ; for ( i=0 ; i < w - 1 ; i + + ) { acc + = src[i] ; dst[i]= acc & mask ; i + + ; acc + = src[i] ; dst[i]= acc & mask ; } for ( ; i < w ; i + + ) { acc + = src[i] ; dst[i]= acc & mask ; } return acc ; }",1
"static int planarRgb16ToRgb16Wrapper ( SwsContext * c , const uint8_t * src[] , int srcStride[] , int srcSliceY , int srcSliceH , uint8_t * dst[] , int dstStride[] ) { const uint16_t * src102[] = { ( uint16_t * ) src[1] , ( uint16_t * ) src[0] , ( uint16_t * ) src[2] } ; const uint16_t * src201[] = { ( uint16_t * ) src[2] , ( uint16_t * ) src[0] , ( uint16_t * ) src[1] } ; int stride102[] = { srcStride[1] , srcStride[0] , srcStride[2] } ; int stride201[] = { srcStride[2] , srcStride[0] , srcStride[1] } ; const AVPixFmtDescriptor * src_format = av_pix_fmt_desc_get ( c - > srcFormat ) ; const AVPixFmtDescriptor * dst_format = av_pix_fmt_desc_get ( c - > dstFormat ) ; int bits_per_sample = src_format - > comp[0] . depth_minus1 + 1 ; int swap = 0 ; if ( HAVE_BIGENDIAN & & ! ( src_format - > flags & AV_PIX_FMT_FLAG_BE ) || ! HAVE_BIGENDIAN & & src_format - > flags & AV_PIX_FMT_FLAG_BE ) swap + + ; if ( HAVE_BIGENDIAN & & ! ( dst_format - > flags & AV_PIX_FMT_FLAG_BE ) || ! HAVE_BIGENDIAN & & dst_format - > flags & AV_PIX_FMT_FLAG_BE ) swap + = 2 ; if ( ( src_format - > flags & ( AV_PIX_FMT_FLAG_PLANAR | AV_PIX_FMT_FLAG_RGB ) ) ! = ( AV_PIX_FMT_FLAG_PLANAR | AV_PIX_FMT_FLAG_RGB ) ) { av_log ( c , AV_LOG_ERROR , unsupported planar RGB conversion %s - > %s\n , src_format - > name , dst_format - > name ) ; return srcSliceH ; } switch ( c - > dstFormat ) { case AV_PIX_FMT_BGR48LE : case AV_PIX_FMT_BGR48BE : gbr16ptopacked16 ( src102 , stride102 , dst[0] + srcSliceY * dstStride[0] , dstStride[0] , srcSliceH , 0 , swap , bits_per_sample , c - > srcW ) ; break ; case AV_PIX_FMT_RGB48LE : case AV_PIX_FMT_RGB48BE : gbr16ptopacked16 ( src201 , stride201 , dst[0] + srcSliceY * dstStride[0] , dstStride[0] , srcSliceH , 0 , swap , bits_per_sample , c - > srcW ) ; break ; case AV_PIX_FMT_RGBA64LE : case AV_PIX_FMT_RGBA64BE : gbr16ptopacked16 ( src201 , stride201 , dst[0] + srcSliceY * dstStride[0] , dstStride[0] , srcSliceH , 1 , swap , bits_per_sample , c - > srcW ) ; break ; case AV_PIX_FMT_BGRA64LE : case AV_PIX_FMT_BGRA64BE : gbr16ptopacked16 ( src102 , stride102 , dst[0] + srcSliceY * dstStride[0] , dstStride[0] , srcSliceH , 1 , swap , bits_per_sample , c - > srcW ) ; break ; default : av_log ( c , AV_LOG_ERROR , unsupported planar RGB conversion %s - > %s\n , src_format - > name , dst_format - > name ) ; } return srcSliceH ; }",0
"void put_pixels16_altivec ( uint8_t * block , const uint8_t * pixels , int line_size , int h ) { POWERPC_TBL_DECLARE ( altivec_put_pixels16_num , 1 ) ; ifdef ALTIVEC_USE_REFERENCE_C_CODE int i ; POWERPC_TBL_START_COUNT ( altivec_put_pixels16_num , 1 ) ; for ( i=0 ; i < h ; i + + ) { * ( ( uint32_t * ) ( block ) ) = ( ( ( const struct unaligned_32 * ) ( pixels ) ) - > l ) ; * ( ( uint32_t * ) ( block + 4 ) ) = ( ( ( const struct unaligned_32 * ) ( pixels + 4 ) ) - > l ) ; * ( ( uint32_t * ) ( block + 8 ) ) = ( ( ( const struct unaligned_32 * ) ( pixels + 8 ) ) - > l ) ; * ( ( uint32_t * ) ( block + 12 ) ) = ( ( ( const struct unaligned_32 * ) ( pixels + 12 ) ) - > l ) ; pixels + =line_size ; block + =line_size ; } POWERPC_TBL_STOP_COUNT ( altivec_put_pixels16_num , 1 ) ; else / * ALTIVEC_USE_REFERENCE_C_CODE * / register vector unsigned char pixelsv1 , pixelsv2 ; register vector unsigned char perm = vec_lvsl ( 0 , pixels ) ; int i ; POWERPC_TBL_START_COUNT ( altivec_put_pixels16_num , 1 ) ; for ( i=0 ; i < h ; i + + ) { pixelsv1 = vec_ld ( 0 , ( unsigned char * ) pixels ) ; pixelsv2 = vec_ld ( 16 , ( unsigned char * ) pixels ) ; vec_st ( vec_perm ( pixelsv1 , pixelsv2 , perm ) , 0 , ( unsigned char * ) block ) ; pixels + =line_size ; block + =line_size ; } POWERPC_TBL_STOP_COUNT ( altivec_put_pixels16_num , 1 ) ; endif / * ALTIVEC_USE_REFERENCE_C_CODE * / }",0
"static int nvdec_vp9_start_frame ( AVCodecContext * avctx , const uint8_t * buffer , uint32_t size ) { VP9SharedContext * h = avctx - > priv_data ; const AVPixFmtDescriptor * pixdesc = av_pix_fmt_desc_get ( avctx - > sw_pix_fmt ) ; NVDECContext * ctx = avctx - > internal - > hwaccel_priv_data ; CUVIDPICPARAMS * pp = & ctx - > pic_params ; CUVIDVP9PICPARAMS * ppc = & pp - > CodecSpecific . vp9 ; FrameDecodeData * fdd ; NVDECFrame * cf ; AVFrame * cur_frame = h - > frames[CUR_FRAME] . tf . f ; int ret , i ; ret = ff_nvdec_start_frame ( avctx , cur_frame ) ; if ( ret < 0 ) return ret ; fdd = ( FrameDecodeData * ) cur_frame - > private_ref - > data ; cf = ( NVDECFrame * ) fdd - > hwaccel_priv ; * pp = ( CUVIDPICPARAMS ) { . PicWidthInMbs = ( cur_frame - > width + 15 ) / 16 , . FrameHeightInMbs = ( cur_frame - > height + 15 ) / 16 , . CurrPicIdx = cf - > idx , . CodecSpecific . vp9 = { . width = cur_frame - > width , . height = cur_frame - > height , . LastRefIdx = get_ref_idx ( h - > refs[h - > h . refidx[0]] . f ) , . GoldenRefIdx = get_ref_idx ( h - > refs[h - > h . refidx[1]] . f ) , . AltRefIdx = get_ref_idx ( h - > refs[h - > h . refidx[2]] . f ) , . profile = h - > h . profile , . frameContextIdx = h - > h . framectxid , . frameType = ! h - > h . keyframe , . showFrame = ! h - > h . invisible , . errorResilient = h - > h . errorres , . frameParallelDecoding = h - > h . parallelmode , . subSamplingX = pixdesc - > log2_chroma_w , . subSamplingY = pixdesc - > log2_chroma_h , . intraOnly = h - > h . intraonly , . allow_high_precision_mv = h - > h . keyframe ? 0 : h - > h . highprecisionmvs , . refreshEntropyProbs = h - > h . refreshctx , . bitDepthMinus8Luma = pixdesc - > comp[0] . depth - 8 , . bitDepthMinus8Chroma = pixdesc - > comp[1] . depth - 8 , . loopFilterLevel = h - > h . filter . level , . loopFilterSharpness = h - > h . filter . sharpness , . modeRefLfEnabled = h - > h . lf_delta . enabled , . log2_tile_columns = h - > h . tiling . log2_tile_cols , . log2_tile_rows = h - > h . tiling . log2_tile_rows , . segmentEnabled = h - > h . segmentation . enabled , . segmentMapUpdate = h - > h . segmentation . update_map , . segmentMapTemporalUpdate = h - > h . segmentation . temporal , . segmentFeatureMode = h - > h . segmentation . absolute_vals , . qpYAc = h - > h . yac_qi , . qpYDc = h - > h . ydc_qdelta , . qpChDc = h - > h . uvdc_qdelta , . qpChAc = h - > h . uvac_qdelta , . resetFrameContext = h - > h . resetctx , . mcomp_filter_type = h - > h . filtermode ( h - > h . filtermode < = 1 ) , . frameTagSize = h - > h . uncompressed_header_size , . offsetToDctParts = h - > h . compressed_header_size , . refFrameSignBias[0] = 0 , } } ; for ( i = 0 ; i < 2 ; i + + ) ppc - > mbModeLfDelta[i] = h - > h . lf_delta . mode[i] ; for ( i = 0 ; i < 4 ; i + + ) ppc - > mbRefLfDelta[i] = h - > h . lf_delta . ref[i] ; for ( i = 0 ; i < 7 ; i + + ) ppc - > mb_segment_tree_probs[i] = h - > h . segmentation . prob[i] ; for ( i = 0 ; i < 3 ; i + + ) { ppc - > activeRefIdx[i] = h - > h . refidx[i] ; ppc - > segment_pred_probs[i] = h - > h . segmentation . pred_prob[i] ; ppc - > refFrameSignBias[i + 1] = h - > h . signbias[i] ; } for ( i = 0 ; i < 8 ; i + + ) { ppc - > segmentFeatureEnable[i][0] = h - > h . segmentation . feat[i] . q_enabled ; ppc - > segmentFeatureEnable[i][1] = h - > h . segmentation . feat[i] . lf_enabled ; ppc - > segmentFeatureEnable[i][2] = h - > h . segmentation . feat[i] . ref_enabled ; ppc - > segmentFeatureEnable[i][3] = h - > h . segmentation . feat[i] . skip_enabled ; ppc - > segmentFeatureData[i][0] = h - > h . segmentation . feat[i] . q_val ; ppc - > segmentFeatureData[i][1] = h - > h . segmentation . feat[i] . lf_val ; ppc - > segmentFeatureData[i][2] = h - > h . segmentation . feat[i] . ref_val ; ppc - > segmentFeatureData[i][3] = 0 ; } switch ( avctx - > colorspace ) { default : case AVCOL_SPC_UNSPECIFIED : ppc - > colorSpace = 0 ; break ; case AVCOL_SPC_BT470BG : ppc - > colorSpace = 1 ; break ; case AVCOL_SPC_BT709 : ppc - > colorSpace = 2 ; break ; case AVCOL_SPC_SMPTE170M : ppc - > colorSpace = 3 ; break ; case AVCOL_SPC_SMPTE240M : ppc - > colorSpace = 4 ; break ; case AVCOL_SPC_BT2020_NCL : ppc - > colorSpace = 5 ; break ; case AVCOL_SPC_RESERVED : ppc - > colorSpace = 6 ; break ; case AVCOL_SPC_RGB : ppc - > colorSpace = 7 ; break ; } return 0 ; }",0
"static int draw_text ( AVFilterContext * ctx , AVFilterBufferRef * picref , int width , int height ) { DrawTextContext * dtext = ctx - > priv ; uint32_t code = 0 , prev_code = 0 ; int x = 0 , y = 0 , i = 0 , ret ; int max_text_line_w = 0 , len ; int box_w , box_h ; char * text = dtext - > text ; uint8_t * p ; int y_min = 32000 , y_max = - 32000 ; int x_min = 32000 , x_max = - 32000 ; FT_Vector delta ; Glyph * glyph = NULL , * prev_glyph = NULL ; Glyph dummy = { 0 } ; time_t now = time ( 0 ) ; struct tm ltime ; uint8_t * buf = dtext - > expanded_text ; int buf_size = dtext - > expanded_text_size ; if ( dtext - > basetime ! = AV_NOPTS_VALUE ) now= picref - > pts * av_q2d ( ctx - > inputs[0] - > time_base ) + dtext - > basetime/1000000 ; if ( ! buf ) { buf_size = 2 * strlen ( dtext - > text ) + 1 ; buf = av_malloc ( buf_size ) ; } if HAVE_LOCALTIME_R localtime_r ( & now , & ltime ) ; else if ( strchr ( dtext - > text , ' % ' ) ) ltime= * localtime ( & now ) ; endif do { * buf = 1 ; if ( strftime ( buf , buf_size , dtext - > text , & ltime ) ! = 0 || * buf == 0 ) break ; buf_size * = 2 ; } while ( ( buf = av_realloc ( buf , buf_size ) ) ) ; if ( dtext - > tc_opt_string ) { char tcbuf[AV_TIMECODE_STR_SIZE] ; av_timecode_make_string ( & dtext - > tc , tcbuf , dtext - > frame_id + + ) ; buf = av_asprintf ( %s%s , dtext - > text , tcbuf ) ; } if ( ! buf ) return AVERROR ( ENOMEM ) ; text = dtext - > expanded_text = buf ; dtext - > expanded_text_size = buf_size ; if ( ( len = strlen ( text ) ) > dtext - > nb_positions ) { if ( ! ( dtext - > positions = av_realloc ( dtext - > positions , len * sizeof ( * dtext - > positions ) ) ) ) return AVERROR ( ENOMEM ) ; dtext - > nb_positions = len ; } x = 0 ; y = 0 ; / * load and cache glyphs * / for ( i = 0 , p = text ; * p ; i + + ) { GET_UTF8 ( code , * p + + , continue ; ) ; / * get glyph * / dummy . code = code ; glyph = av_tree_find ( dtext - > glyphs , & dummy , glyph_cmp , NULL ) ; if ( ! glyph ) { load_glyph ( ctx , & glyph , code ) ; } y_min = FFMIN ( glyph - > bbox . yMin , y_min ) ; y_max = FFMAX ( glyph - > bbox . yMax , y_max ) ; x_min = FFMIN ( glyph - > bbox . xMin , x_min ) ; x_max = FFMAX ( glyph - > bbox . xMax , x_max ) ; } dtext - > max_glyph_h = y_max - y_min ; dtext - > max_glyph_w = x_max - x_min ; / * compute and save position for each glyph * / glyph = NULL ; for ( i = 0 , p = text ; * p ; i + + ) { GET_UTF8 ( code , * p + + , continue ; ) ; / * skip the \n in the sequence \r\n * / if ( prev_code == ' \r ' & & code == ' \n ' ) continue ; prev_code = code ; if ( is_newline ( code ) ) { max_text_line_w = FFMAX ( max_text_line_w , x ) ; y + = dtext - > max_glyph_h ; x = 0 ; continue ; } / * get glyph * / prev_glyph = glyph ; dummy . code = code ; glyph = av_tree_find ( dtext - > glyphs , & dummy , glyph_cmp , NULL ) ; / * kerning * / if ( dtext - > use_kerning & & prev_glyph & & glyph - > code ) { FT_Get_Kerning ( dtext - > face , prev_glyph - > code , glyph - > code , ft_kerning_default , & delta ) ; x + = delta . x > > 6 ; } / * save position * / dtext - > positions[i] . x = x + glyph - > bitmap_left ; dtext - > positions[i] . y = y - glyph - > bitmap_top + y_max ; if ( code == ' \t ' ) x = ( x / dtext - > tabsize + 1 ) * dtext - > tabsize ; else x + = glyph - > advance ; } max_text_line_w = FFMAX ( x , max_text_line_w ) ; dtext - > var_values[VAR_TW] = dtext - > var_values[VAR_TEXT_W] = max_text_line_w ; dtext - > var_values[VAR_TH] = dtext - > var_values[VAR_TEXT_H] = y + dtext - > max_glyph_h ; dtext - > var_values[VAR_MAX_GLYPH_W] = dtext - > max_glyph_w ; dtext - > var_values[VAR_MAX_GLYPH_H] = dtext - > max_glyph_h ; dtext - > var_values[VAR_MAX_GLYPH_A] = dtext - > var_values[VAR_ASCENT ] = y_max ; dtext - > var_values[VAR_MAX_GLYPH_D] = dtext - > var_values[VAR_DESCENT] = y_min ; dtext - > var_values[VAR_LINE_H] = dtext - > var_values[VAR_LH] = dtext - > max_glyph_h ; dtext - > x = dtext - > var_values[VAR_X] = av_expr_eval ( dtext - > x_pexpr , dtext - > var_values , & dtext - > prng ) ; dtext - > y = dtext - > var_values[VAR_Y] = av_expr_eval ( dtext - > y_pexpr , dtext - > var_values , & dtext - > prng ) ; dtext - > x = dtext - > var_values[VAR_X] = av_expr_eval ( dtext - > x_pexpr , dtext - > var_values , & dtext - > prng ) ; dtext - > draw = av_expr_eval ( dtext - > draw_pexpr , dtext - > var_values , & dtext - > prng ) ; if ( ! dtext - > draw ) return 0 ; box_w = FFMIN ( width - 1 , max_text_line_w ) ; box_h = FFMIN ( height - 1 , y + dtext - > max_glyph_h ) ; / * draw box * / if ( dtext - > draw_box ) ff_blend_rectangle ( & dtext - > dc , & dtext - > boxcolor , picref - > data , picref - > linesize , width , height , dtext - > x , dtext - > y , box_w , box_h ) ; if ( dtext - > shadowx || dtext - > shadowy ) { if ( ( ret = draw_glyphs ( dtext , picref , width , height , dtext - >",1
"static int av_thread_message_queue_recv_locked ( AVThreadMessageQueue * mq , void * msg , unsigned flags ) { while ( ! mq - > err_recv & & av_fifo_size ( mq - > fifo ) < mq - > elsize ) { if ( ( flags & AV_THREAD_MESSAGE_NONBLOCK ) ) return AVERROR ( EAGAIN ) ; pthread_cond_wait ( & mq - > cond , & mq - > lock ) ; } if ( av_fifo_size ( mq - > fifo ) < mq - > elsize ) return mq - > err_recv ; av_fifo_generic_read ( mq - > fifo , msg , mq - > elsize , NULL ) ; pthread_cond_signal ( & mq - > cond ) ; return 0 ; }",1
"static const ID3v2EMFunc * get_extra_meta_func ( const char * tag , int isv34 ) { int i = 0 ; while ( ff_id3v2_extra_meta_funcs[i] . tag3 ) { if ( ! memcmp ( tag , ( isv34 ? ff_id3v2_extra_meta_funcs[i] . tag4 : ff_id3v2_extra_meta_funcs[i] . tag3 ) , ( isv34 ? 4 : 3 ) ) ) return & ff_id3v2_extra_meta_funcs[i] ; i + + ; } return NULL ; }",1
"void ff_snow_vertical_compose97i_mmx ( IDWTELEM * b0 , IDWTELEM * b1 , IDWTELEM * b2 , IDWTELEM * b3 , IDWTELEM * b4 , IDWTELEM * b5 , int width ) { long i = width ; while ( i & 15 ) { i - - ; b4[i] - = ( W_DM * ( b3[i] + b5[i] ) + W_DO ) > > W_DS ; b3[i] - = ( W_CM * ( b2[i] + b4[i] ) + W_CO ) > > W_CS ; b2[i] + = ( W_BM * ( b1[i] + b3[i] ) + 4 * b2[i] + W_BO ) > > W_BS ; b1[i] + = ( W_AM * ( b0[i] + b2[i] ) + W_AO ) > > W_AS ; } i + =i ; asm volatile ( jmp 2f \n\t 1 : \n\t snow_vertical_compose_mmx_load ( %4 , mm0 , mm2 , mm4 , mm6 ) snow_vertical_compose_mmx_add ( %6 , mm0 , mm2 , mm4 , mm6 ) snow_vertical_compose_mmx_move ( mm0 , mm2 , mm4 , mm6 , mm1 , mm3 , mm5 , mm7 ) snow_vertical_compose_sra ( 1 , mm0 , mm2 , mm4 , mm6 ) snow_vertical_compose_r2r_add ( mm1 , mm3 , mm5 , mm7 , mm0 , mm2 , mm4 , mm6 ) pcmpeqw %%mm1 , %%mm1 \n\t psllw 15 , %%mm1 \n\t psrlw 14 , %%mm1 \n\t snow_vertical_compose_r2r_add ( mm1 , mm1 , mm1 , mm1 , mm0 , mm2 , mm4 , mm6 ) snow_vertical_compose_sra ( 2 , mm0 , mm2 , mm4 , mm6 ) snow_vertical_compose_mmx_load ( %5 , mm1 , mm3 , mm5 , mm7 ) snow_vertical_compose_r2r_sub ( mm0 , mm2 , mm4 , mm6 , mm1 , mm3 , mm5 , mm7 ) snow_vertical_compose_mmx_store ( %5 , mm1 , mm3 , mm5 , mm7 ) snow_vertical_compose_mmx_load ( %4 , mm0 , mm2 , mm4 , mm6 ) snow_vertical_compose_mmx_add ( %3 , mm1 , mm3 , mm5 , mm7 ) snow_vertical_compose_r2r_sub ( mm1 , mm3 , mm5 , mm7 , mm0 , mm2 , mm4 , mm6 ) snow_vertical_compose_mmx_store ( %4 , mm0 , mm2 , mm4 , mm6 ) pcmpeqw %%mm7 , %%mm7 \n\t pcmpeqw %%mm5 , %%mm5 \n\t psllw 15 , %%mm7 \n\t psrlw 13 , %%mm5 \n\t paddw %%mm7 , %%mm5 \n\t snow_vertical_compose_r2r_add ( mm5 , mm5 , mm5 , mm5 , mm0 , mm2 , mm4 , mm6 ) movq ( %2 , %% REG_d ) , %%mm1 \n\t movq 8 ( %2 , %% REG_d ) , %%mm3 \n\t paddw %%mm7 , %%mm1 \n\t paddw %%mm7 , %%mm3 \n\t pavgw %%mm1 , %%mm0 \n\t pavgw %%mm3 , %%mm2 \n\t movq 16 ( %2 , %% REG_d ) , %%mm1 \n\t movq 24 ( %2 , %% REG_d ) , %%mm3 \n\t paddw %%mm7 , %%mm1 \n\t paddw %%mm7 , %%mm3 \n\t pavgw %%mm1 , %%mm4 \n\t pavgw %%mm3 , %%mm6 \n\t snow_vertical_compose_r2r_sub ( mm7 , mm7 , mm7 , mm7 , mm0 , mm2 , mm4 , mm6 ) snow_vertical_compose_sra ( 1 , mm0 , mm2 , mm4 , mm6 ) snow_vertical_compose_mmx_add ( %3 , mm0 , mm2 , mm4 , mm6 ) snow_vertical_compose_sra ( 2 , mm0 , mm2 , mm4 , mm6 ) snow_vertical_compose_mmx_add ( %3 , mm0 , mm2 , mm4 , mm6 ) snow_vertical_compose_mmx_store ( %3 , mm0 , mm2 , mm4 , mm6 ) snow_vertical_compose_mmx_add ( %1 , mm0 , mm2 , mm4 , mm6 ) snow_vertical_compose_mmx_move ( mm0 , mm2 , mm4 , mm6 , mm1 , mm3 , mm5 , mm7 ) snow_vertical_compose_sra ( 1 , mm0 , mm2 , mm4 , mm6 ) snow_vertical_compose_r2r_add ( mm1 , mm3 , mm5 , mm7 , mm0 , mm2 , mm4 , mm6 ) snow_vertical_compose_mmx_add ( %2 , mm0 , mm2 , mm4 , mm6 ) snow_vertical_compose_mmx_store ( %2 , mm0 , mm2 , mm4 , mm6 ) 2 : \n\t sub 32 , %% REG_d \n\t jge 1b \n\t : + d ( i ) : r ( b0 ) , r ( b1 ) , r ( b2 ) , r ( b3 ) , r ( b4 ) , r ( b5 ) ) ; }",1
"void av_thread_message_flush ( AVThreadMessageQueue * mq ) { if HAVE_THREADS int used , off ; void * free_func = mq - > free_func ; pthread_mutex_lock ( & mq - > lock ) ; used = av_fifo_size ( mq - > fifo ) ; if ( free_func ) for ( off = 0 ; off < used ; off + = mq - > elsize ) av_fifo_generic_peek_at ( mq - > fifo , mq , off , mq - > elsize , free_func_wrap ) ; av_fifo_drain ( mq - > fifo , used ) ; pthread_cond_broadcast ( & mq - > cond ) ; pthread_mutex_unlock ( & mq - > lock ) ; endif / * HAVE_THREADS * / }",1
"int av_open_input_stream ( AVFormatContext * * ic_ptr , AVIOContext * pb , const char * filename , AVInputFormat * fmt , AVFormatParameters * ap ) { int err ; AVDictionary * opts ; AVFormatContext * ic ; AVFormatParameters default_ap ; if ( ! ap ) { ap= & default_ap ; memset ( ap , 0 , sizeof ( default_ap ) ) ; } opts = convert_format_parameters ( ap ) ; if ( ! ap - > prealloced_context ) ic = avformat_alloc_context ( ) ; else ic = * ic_ptr ; if ( ! ic ) { err = AVERROR ( ENOMEM ) ; goto fail ; } if ( pb & & fmt & & fmt - > flags & AVFMT_NOFILE ) av_log ( ic , AV_LOG_WARNING , Custom AVIOContext makes no sense and will be ignored with AVFMT_NOFILE format . \n ) ; else ic - > pb = pb ; err = avformat_open_input ( & ic , filename , fmt , & opts ) ; ic - > pb = ic - > pb ? ic - > pb : pb ; // don ' t leak custom pb if it wasn ' t set above * ic_ptr = ic ; fail : av_dict_free ( & opts ) ; return err ; }",1
"int av_buffersrc_add_ref ( AVFilterContext * buffer_filter , AVFilterBufferRef * picref , int flags ) { BufferSourceContext * c = buffer_filter - > priv ; AVFilterBufferRef * buf ; int ret ; if ( ! picref ) { c - > eof = 1 ; return 0 ; } else if ( c - > eof ) return AVERROR ( EINVAL ) ; if ( ! av_fifo_space ( c - > fifo ) & & ( ret = av_fifo_realloc2 ( c - > fifo , av_fifo_size ( c - > fifo ) + sizeof ( buf ) ) ) < 0 ) return ret ; if ( ! ( flags & AV_BUFFERSRC_FLAG_NO_CHECK_FORMAT ) ) { ret = check_format_change ( buffer_filter , picref ) ; if ( ret < 0 ) return ret ; } if ( flags & AV_BUFFERSRC_FLAG_NO_COPY ) buf = picref ; else buf = copy_buffer_ref ( buffer_filter , picref ) ; if ( ( ret = av_fifo_generic_write ( c - > fifo , & buf , sizeof ( buf ) , NULL ) ) < 0 ) { if ( buf ! = picref ) avfilter_unref_buffer ( buf ) ; return ret ; } c - > nb_failed_requests = 0 ; return 0 ; }",1
"const DVprofile * ff_dv_frame_profile2 ( AVCodecContext * codec , const DVprofile * sys , const uint8_t * frame , unsigned buf_size ) { int i ; int dsf = ( frame[3] & 0x80 ) > > 7 ; int stype = frame[80 * 5 + 48 + 3] & 0x1f ; / * 576i50 25Mbps 4 : 1 : 1 is a special case * / if ( dsf == 1 & & stype == 0 & & frame[4] & 0x07 / * the APT field * / ) { return & dv_profiles[2] ; } if ( codec & & codec - > codec_tag==AV_RL32 ( dvsd ) & & codec - > width==720 & & codec - > height==576 ) return & dv_profiles[1] ; for ( i=0 ; i < FF_ARRAY_ELEMS ( dv_profiles ) ; i + + ) if ( dsf == dv_profiles[i] . dsf & & stype == dv_profiles[i] . video_stype ) return & dv_profiles[i] ; / * check if old sys matches and assumes corrupted input * / if ( sys & & buf_size == sys - > frame_size ) return sys ; return NULL ; }",0
"static av_cold int libgsm_encode_init ( AVCodecContext * avctx ) { if ( avctx - > channels > 1 ) { av_log ( avctx , AV_LOG_ERROR , Mono required for GSM , got %d channels\n , avctx - > channels ) ; return - 1 ; if ( avctx - > sample_rate ! = 8000 ) { av_log ( avctx , AV_LOG_ERROR , Sample rate 8000Hz required for GSM , got %dHz\n , avctx - > sample_rate ) ; if ( avctx - > strict_std_compliance > FF_COMPLIANCE_UNOFFICIAL ) return - 1 ; if ( avctx - > bit_rate ! = 13000 / * Official * / & & avctx - > bit_rate ! = 13200 / * Very common * / & & avctx - > bit_rate ! = 0 / * Unknown ; a . o . mov does not set bitrate when decoding * / ) { av_log ( avctx , AV_LOG_ERROR , Bitrate 13000bps required for GSM , got %dbps\n , avctx - > bit_rate ) ; if ( avctx - > strict_std_compliance > FF_COMPLIANCE_UNOFFICIAL ) return - 1 ; avctx - > priv_data = gsm_create ( ) ; switch ( avctx - > codec_id ) { case CODEC_ID_GSM : avctx - > frame_size = GSM_FRAME_SIZE ; avctx - > block_align = GSM_BLOCK_SIZE ; break ; case CODEC_ID_GSM_MS : { int one = 1 ; gsm_option ( avctx - > priv_data , GSM_OPT_WAV49 , & one ) ; avctx - > frame_size = 2 * GSM_FRAME_SIZE ; avctx - > block_align = GSM_MS_BLOCK_SIZE ; avctx - > coded_frame= avcodec_alloc_frame ( ) ; return 0 ;",1
"static void avc_wgt_4x2_msa ( uint8_t * data , int32_t stride , int32_t log2_denom , int32_t src_weight , int32_t offset_in ) { uint32_t data0 , data1 ; v16u8 zero = { 0 } ; v16u8 src0 , src1 ; v4i32 res0 , res1 ; v8i16 temp0 , temp1 ; v16u8 vec0 , vec1 ; v8i16 wgt , denom , offset ; offset_in < < = ( log2_denom ) ; if ( log2_denom ) { offset_in + = ( 1 < < ( log2_denom - 1 ) ) ; } wgt = __msa_fill_h ( src_weight ) ; offset = __msa_fill_h ( offset_in ) ; denom = __msa_fill_h ( log2_denom ) ; data0 = LOAD_WORD ( data ) ; data1 = LOAD_WORD ( data + stride ) ; src0 = ( v16u8 ) __msa_fill_w ( data0 ) ; src1 = ( v16u8 ) __msa_fill_w ( data1 ) ; ILVR_B_2VECS_UB ( src0 , src1 , zero , zero , vec0 , vec1 ) ; temp0 = wgt * ( v8i16 ) vec0 ; temp1 = wgt * ( v8i16 ) vec1 ; temp0 = __msa_adds_s_h ( temp0 , offset ) ; temp1 = __msa_adds_s_h ( temp1 , offset ) ; temp0 = __msa_maxi_s_h ( temp0 , 0 ) ; temp1 = __msa_maxi_s_h ( temp1 , 0 ) ; temp0 = __msa_srl_h ( temp0 , denom ) ; temp1 = __msa_srl_h ( temp1 , denom ) ; temp0 = ( v8i16 ) __msa_sat_u_h ( ( v8u16 ) temp0 , 7 ) ; temp1 = ( v8i16 ) __msa_sat_u_h ( ( v8u16 ) temp1 , 7 ) ; res0 = ( v4i32 ) __msa_pckev_b ( ( v16i8 ) temp0 , ( v16i8 ) temp0 ) ; res1 = ( v4i32 ) __msa_pckev_b ( ( v16i8 ) temp1 , ( v16i8 ) temp1 ) ; data0 = __msa_copy_u_w ( res0 , 0 ) ; data1 = __msa_copy_u_w ( res1 , 0 ) ; STORE_WORD ( data , data0 ) ; data + = stride ; STORE_WORD ( data , data1 ) ; }",0
"void ff_imdct_calc_3dn2 ( MDCTContext * s , FFTSample * output , const FFTSample * input , FFTSample * tmp ) { long n8 , n4 , n2 , n ; x86_reg k ; const uint16_t * revtab = s - > fft . revtab ; const FFTSample * tcos = s - > tcos ; const FFTSample * tsin = s - > tsin ; const FFTSample * in1 , * in2 ; FFTComplex * z = ( FFTComplex * ) tmp ; n = 1 < < s - > nbits ; n2 = n > > 1 ; n4 = n > > 2 ; n8 = n > > 3 ; / * pre rotation * / in1 = input ; in2 = input + n2 - 1 ; for ( k = 0 ; k < n4 ; k + + ) { // FIXME a single block is faster , but gcc 2 . 95 and 3 . 4 . x on 32bit can ' t compile it asm volatile ( movd %0 , %%mm0 \n\t movd %2 , %%mm1 \n\t punpckldq %1 , %%mm0 \n\t punpckldq %3 , %%mm1 \n\t movq %%mm0 , %%mm2 \n\t pfmul %%mm1 , %%mm0 \n\t pswapd %%mm1 , %%mm1 \n\t pfmul %%mm1 , %%mm2 \n\t pfpnacc %%mm2 , %%mm0 \n\t : : m ( in2[ - 2 * k] ) , m ( in1[2 * k] ) , m ( tcos[k] ) , m ( tsin[k] ) ) ; asm volatile ( movq %%mm0 , %0 \n\t : =m ( z[revtab[k]] ) ) ; } ff_fft_calc ( & s - > fft , z ) ; / * post rotation + reordering * / for ( k = 0 ; k < n4 ; k + + ) { asm volatile ( movq %0 , %%mm0 \n\t movd %1 , %%mm1 \n\t punpckldq %2 , %%mm1 \n\t movq %%mm0 , %%mm2 \n\t pfmul %%mm1 , %%mm0 \n\t pswapd %%mm1 , %%mm1 \n\t pfmul %%mm1 , %%mm2 \n\t pfpnacc %%mm2 , %%mm0 \n\t movq %%mm0 , %0 \n\t : + m ( z[k] ) : m ( tcos[k] ) , m ( tsin[k] ) ) ; } k = n - 8 ; asm volatile ( movd %0 , %%mm7 : : r ( 1 < < 31 ) ) ; asm volatile ( 1 : \n\t movq ( %4 , %0 ) , %%mm0 \n\t // z[n8 + k] neg %0 \n\t pswapd - 8 ( %4 , %0 ) , %%mm1 \n\t // z[n8 - 1 - k] movq %%mm0 , %%mm2 \n\t pxor %%mm7 , %%mm2 \n\t punpckldq %%mm1 , %%mm2 \n\t pswapd %%mm2 , %%mm3 \n\t punpckhdq %%mm1 , %%mm0 \n\t pswapd %%mm0 , %%mm4 \n\t pxor %%mm7 , %%mm0 \n\t pxor %%mm7 , %%mm4 \n\t movq %%mm3 , - 8 ( %3 , %0 ) \n\t // output[n - 2 - 2 * k] = { z[n8 - 1 - k] . im , - z[n8 + k] . re } movq %%mm4 , - 8 ( %2 , %0 ) \n\t // output[n2 - 2 - 2 * k]= { - z[n8 - 1 - k] . re , z[n8 + k] . im } neg %0 \n\t movq %%mm0 , ( %1 , %0 ) \n\t // output[2 * k] = { - z[n8 + k] . im , z[n8 - 1 - k] . re } movq %%mm2 , ( %2 , %0 ) \n\t // output[n2 + 2 * k] = { - z[n8 + k] . re , z[n8 - 1 - k] . im } sub 8 , %0 \n\t jge 1b \n\t : + r ( k ) : r ( output ) , r ( output + n2 ) , r ( output + n ) , r ( z + n8 ) : memory ) ; asm volatile ( femms ) ; }",1
"static av_cold int roq_decode_init ( AVCodecContext * avctx ) { RoqContext * s = avctx - > priv_data ; s - > avctx = avctx ; if ( avctx - > width % 16 || avctx - > height % 16 ) { av_log ( avctx , AV_LOG_ERROR , Dimensions must be a multiple of 16\n ) ; return AVERROR_PATCHWELCOME ; } s - > width = avctx - > width ; s - > height = avctx - > height ; s - > last_frame = av_frame_alloc ( ) ; s - > current_frame = av_frame_alloc ( ) ; if ( ! s - > current_frame || ! s - > last_frame ) { av_frame_free ( & s - > current_frame ) ; av_frame_free ( & s - > last_frame ) ; return AVERROR ( ENOMEM ) ; } avctx - > pix_fmt = AV_PIX_FMT_YUV444P ; return 0 ; }",0
"void ff_put_h264_qpel8_mc01_msa ( uint8_t * dst , const uint8_t * src , ptrdiff_t stride ) { avc_luma_vt_qrt_8w_msa ( src - ( stride * 2 ) , stride , dst , stride , 8 , 0 ) ; }",0
"int attribute_align_arg avcodec_open ( AVCodecContext * avctx , AVCodec * codec ) { int ret = 0 ; / * If there is a user - supplied mutex locking routine , call it . * / if ( ff_lockmgr_cb ) { if ( ( * ff_lockmgr_cb ) ( & codec_mutex , AV_LOCK_OBTAIN ) ) return - 1 ; } entangled_thread_counter + + ; if ( entangled_thread_counter ! = 1 ) { av_log ( avctx , AV_LOG_ERROR , insufficient thread locking around avcodec_open/close ( ) \n ) ; ret = - 1 ; goto end ; } if ( avctx - > codec || ! codec ) { ret = AVERROR ( EINVAL ) ; goto end ; } if ( codec - > priv_data_size > 0 ) { if ( ! avctx - > priv_data ) { avctx - > priv_data = av_mallocz ( codec - > priv_data_size ) ; if ( ! avctx - > priv_data ) { ret = AVERROR ( ENOMEM ) ; goto end ; } if ( codec - > priv_class ) { //this can be droped once all user apps use avcodec_get_context_defaults3 ( ) * ( AVClass * * ) avctx - > priv_data= codec - > priv_class ; av_opt_set_defaults ( avctx - > priv_data ) ; } } } else { avctx - > priv_data = NULL ; } if ( avctx - > coded_width & & avctx - > coded_height ) avcodec_set_dimensions ( avctx , avctx - > coded_width , avctx - > coded_height ) ; else if ( avctx - > width & & avctx - > height ) avcodec_set_dimensions ( avctx , avctx - > width , avctx - > height ) ; if ( ( avctx - > coded_width || avctx - > coded_height || avctx - > width || avctx - > height ) & & ( av_image_check_size ( avctx - > coded_width , avctx - > coded_height , 0 , avctx ) < 0 || av_image_check_size ( avctx - > width , avctx - > height , 0 , avctx ) < 0 ) ) { av_log ( avctx , AV_LOG_WARNING , ignoring invalid width/height values\n ) ; avcodec_set_dimensions ( avctx , 0 , 0 ) ; } / * if the decoder init function was already called previously , free the already allocated subtitle_header before overwriting it * / if ( codec - > decode ) av_freep ( & avctx - > subtitle_header ) ; define SANE_NB_CHANNELS 128U if ( avctx - > channels > SANE_NB_CHANNELS ) { ret = AVERROR ( EINVAL ) ; goto free_and_end ; } avctx - > codec = codec ; if ( ( avctx - > codec_type == AVMEDIA_TYPE_UNKNOWN || avctx - > codec_type == codec - > type ) & & avctx - > codec_id == CODEC_ID_NONE ) { avctx - > codec_type = codec - > type ; avctx - > codec_id = codec - > id ; } if ( avctx - > codec_id ! = codec - > id || ( avctx - > codec_type ! = codec - > type & & avctx - > codec_type ! = AVMEDIA_TYPE_ATTACHMENT ) ) { av_log ( avctx , AV_LOG_ERROR , codec type or id mismatches\n ) ; ret = AVERROR ( EINVAL ) ; goto free_and_end ; } avctx - > frame_number = 0 ; if ( HAVE_THREADS & & ! avctx - > thread_opaque ) { ret = ff_thread_init ( avctx ) ; if ( ret < 0 ) { goto free_and_end ; } } if ( avctx - > codec - > max_lowres < avctx - > lowres ) { av_log ( avctx , AV_LOG_ERROR , The maximum value for lowres supported by the decoder is %d\n , avctx - > codec - > max_lowres ) ; ret = AVERROR ( EINVAL ) ; goto free_and_end ; } if ( avctx - > codec - > sample_fmts & & avctx - > codec - > encode ) { int i ; for ( i = 0 ; avctx - > codec - > sample_fmts[i] ! = AV_SAMPLE_FMT_NONE ; i + + ) if ( avctx - > sample_fmt == avctx - > codec - > sample_fmts[i] ) break ; if ( avctx - > codec - > sample_fmts[i] == AV_SAMPLE_FMT_NONE ) { av_log ( avctx , AV_LOG_ERROR , Specified sample_fmt is not supported . \n ) ; ret = AVERROR ( EINVAL ) ; goto free_and_end ; } } if ( avctx - > codec - > init & & ! ( avctx - > active_thread_type & FF_THREAD_FRAME ) ) { ret = avctx - > codec - > init ( avctx ) ; if ( ret < 0 ) { goto free_and_end ; } } end : entangled_thread_counter - - ; / * Release any user - supplied mutex . * / if ( ff_lockmgr_cb ) { ( * ff_lockmgr_cb ) ( & codec_mutex , AV_LOCK_RELEASE ) ; } return ret ; free_and_end : av_freep ( & avctx - > priv_data ) ; avctx - > codec= NULL ; goto end ; }",0
"static int synth_superframe ( AVCodecContext * ctx , AVFrame * frame , int * got_frame_ptr ) { WMAVoiceContext * s = ctx - > priv_data ; GetBitContext * gb = & s - > gb , s_gb ; int n , res , n_samples = 480 ; double lsps[MAX_FRAMES][MAX_LSPS] ; const double * mean_lsf = s - > lsps == 16 ? wmavoice_mean_lsf16[s - > lsp_def_mode] : wmavoice_mean_lsf10[s - > lsp_def_mode] ; float excitation[MAX_SIGNAL_HISTORY + MAX_SFRAMESIZE + 12] ; float synth[MAX_LSPS + MAX_SFRAMESIZE] ; float * samples ; memcpy ( synth , s - > synth_history , s - > lsps * sizeof ( * synth ) ) ; memcpy ( excitation , s - > excitation_history , s - > history_nsamples * sizeof ( * excitation ) ) ; if ( s - > sframe_cache_size > 0 ) { gb = & s_gb ; init_get_bits ( gb , s - > sframe_cache , s - > sframe_cache_size ) ; s - > sframe_cache_size = 0 ; } if ( ( res = check_bits_for_superframe ( gb , s ) ) == 1 ) { * got_frame_ptr = 0 ; return 1 ; } else if ( res < 0 ) return res ; / * First bit is speech/music bit , it differentiates between WMAVoice * speech samples ( the actual codec ) and WMAVoice music samples , which * are really WMAPro - in - WMAVoice - superframes . I ' ve never seen those in * the wild yet . * / if ( ! get_bits1 ( gb ) ) { avpriv_request_sample ( ctx , WMAPro - in - WMAVoice ) ; return AVERROR_PATCHWELCOME ; } / * ( optional ) nr . of samples in superframe ; always < = 480 and > = 0 * / if ( get_bits1 ( gb ) ) { if ( ( n_samples = get_bits ( gb , 12 ) ) > 480 ) { av_log ( ctx , AV_LOG_ERROR , Superframe encodes > 480 samples ( %d ) , not allowed\n , n_samples ) ; return AVERROR_INVALIDDATA ; } } / * Parse LSPs , if global for the superframe ( can also be per - frame ) . * / if ( s - > has_residual_lsps ) { double prev_lsps[MAX_LSPS] , a1[MAX_LSPS * 2] , a2[MAX_LSPS * 2] ; for ( n = 0 ; n < s - > lsps ; n + + ) prev_lsps[n] = s - > prev_lsps[n] - mean_lsf[n] ; if ( s - > lsps == 10 ) { dequant_lsp10r ( gb , lsps[2] , prev_lsps , a1 , a2 , s - > lsp_q_mode ) ; } else / * s - > lsps == 16 * / dequant_lsp16r ( gb , lsps[2] , prev_lsps , a1 , a2 , s - > lsp_q_mode ) ; for ( n = 0 ; n < s - > lsps ; n + + ) { lsps[0][n] = mean_lsf[n] + ( a1[n] - a2[n * 2] ) ; lsps[1][n] = mean_lsf[n] + ( a1[s - > lsps + n] - a2[n * 2 + 1] ) ; lsps[2][n] + = mean_lsf[n] ; } for ( n = 0 ; n < 3 ; n + + ) stabilize_lsps ( lsps[n] , s - > lsps ) ; } / * get output buffer * / frame - > nb_samples = 480 ; if ( ( res = ff_get_buffer ( ctx , frame , 0 ) ) < 0 ) return res ; frame - > nb_samples = n_samples ; samples = ( float * ) frame - > data[0] ; / * Parse frames , optionally preceded by per - frame ( independent ) LSPs . * / for ( n = 0 ; n < 3 ; n + + ) { if ( ! s - > has_residual_lsps ) { int m ; if ( s - > lsps == 10 ) { dequant_lsp10i ( gb , lsps[n] ) ; } else / * s - > lsps == 16 * / dequant_lsp16i ( gb , lsps[n] ) ; for ( m = 0 ; m < s - > lsps ; m + + ) lsps[n][m] + = mean_lsf[m] ; stabilize_lsps ( lsps[n] , s - > lsps ) ; } if ( ( res = synth_frame ( ctx , gb , n , & samples[n * MAX_FRAMESIZE] , lsps[n] , n == 0 ? s - > prev_lsps : lsps[n - 1] , & excitation[s - > history_nsamples + n * MAX_FRAMESIZE] , & synth[s - > lsps + n * MAX_FRAMESIZE] ) ) ) { * got_frame_ptr = 0 ; return res ; } } / * Statistics ? FIXME - we don ' t check for length , a slight overrun * will be caught by internal buffer padding , and anything else * will be skipped , not read . * / if ( get_bits1 ( gb ) ) { res = get_bits ( gb , 4 ) ; skip_bits ( gb , 10 * ( res + 1 ) ) ; } * got_frame_ptr = 1 ; / * Update history * / memcpy ( s - > prev_lsps , lsps[2] , s - > lsps * sizeof ( * s - > prev_lsps ) ) ; memcpy ( s - > synth_history , & synth[MAX_SFRAMESIZE] , s - > lsps * sizeof ( * synth ) ) ; memcpy ( s - > excitation_history , & excitation[MAX_SFRAMESIZE] , s - > history_nsamples * sizeof ( * excitation ) ) ; if ( s - > do_apf ) memmove ( s - > zero_exc_pf , & s - > zero_exc_pf[MAX_SFRAMESIZE] , s - > history_nsamples * sizeof ( * s - > zero_exc_pf ) ) ; return 0 ; }",0
"static void free_picture ( MpegEncContext * s , Picture * pic ) { int i ; if ( pic - > data[0] & & pic - > type ! =FF_BUFFER_TYPE_SHARED ) { free_frame_buffer ( s , pic ) ; } av_freep ( & pic - > mb_var ) ; av_freep ( & pic - > mc_mb_var ) ; av_freep ( & pic - > mb_mean ) ; av_freep ( & pic - > mbskip_table ) ; av_freep ( & pic - > qscale_table ) ; av_freep ( & pic - > mb_type_base ) ; av_freep ( & pic - > dct_coeff ) ; av_freep ( & pic - > pan_scan ) ; pic - > mb_type= NULL ; for ( i=0 ; i < 2 ; i + + ) { av_freep ( & pic - > motion_val_base[i] ) ; av_freep ( & pic - > ref_index[i] ) ; } if ( pic - > type == FF_BUFFER_TYPE_SHARED ) { for ( i=0 ; i < 4 ; i + + ) { pic - > base[i]= pic - > data[i]= NULL ; } pic - > type= 0 ; } }",1
static int mov_read_close ( AVFormatContext * s ) { int i ; MOVContext * mov = s - > priv_data ; for ( i=0 ; i < mov - > total_streams ; i + + ) mov_free_stream_context ( mov - > streams[i] ) ; for ( i=0 ; i < s - > nb_streams ; i + + ) av_free ( s - > streams[i] ) ; return 0 ; },1
"static int aac_decode_frame ( AVCodecContext * avccontext , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; AACContext * ac = avccontext - > priv_data ; ChannelElement * che = NULL , * che_prev = NULL ; GetBitContext gb ; enum RawDataBlockType elem_type , elem_type_prev = TYPE_END ; int err , elem_id , data_size_tmp ; int buf_consumed ; int samples = 1024 , multiplier ; int buf_offset ; init_get_bits ( & gb , buf , buf_size * 8 ) ; if ( show_bits ( & gb , 12 ) == 0xfff ) { if ( parse_adts_frame_header ( ac , & gb ) < 0 ) { av_log ( avccontext , AV_LOG_ERROR , Error decoding AAC frame header . \n ) ; return - 1 ; } if ( ac - > m4ac . sampling_index > 12 ) { av_log ( ac - > avccontext , AV_LOG_ERROR , invalid sampling rate index %d\n , ac - > m4ac . sampling_index ) ; return - 1 ; } } // parse while ( ( elem_type = get_bits ( & gb , 3 ) ) ! = TYPE_END ) { elem_id = get_bits ( & gb , 4 ) ; if ( elem_type < TYPE_DSE & & ! ( che=get_che ( ac , elem_type , elem_id ) ) ) { av_log ( ac - > avccontext , AV_LOG_ERROR , channel element %d . %d is not allocated\n , elem_type , elem_id ) ; return - 1 ; } switch ( elem_type ) { case TYPE_SCE : err = decode_ics ( ac , & che - > ch[0] , & gb , 0 , 0 ) ; break ; case TYPE_CPE : err = decode_cpe ( ac , & gb , che ) ; break ; case TYPE_CCE : err = decode_cce ( ac , & gb , che ) ; break ; case TYPE_LFE : err = decode_ics ( ac , & che - > ch[0] , & gb , 0 , 0 ) ; break ; case TYPE_DSE : err = skip_data_stream_element ( ac , & gb ) ; break ; case TYPE_PCE : { enum ChannelPosition new_che_pos[4][MAX_ELEM_ID] ; memset ( new_che_pos , 0 , 4 * MAX_ELEM_ID * sizeof ( new_che_pos[0][0] ) ) ; if ( ( err = decode_pce ( ac , new_che_pos , & gb ) ) ) break ; if ( ac - > output_configured > OC_TRIAL_PCE ) av_log ( avccontext , AV_LOG_ERROR , Not evaluating a further program_config_element as this construct is dubious at best . \n ) ; else err = output_configure ( ac , ac - > che_pos , new_che_pos , 0 , OC_TRIAL_PCE ) ; break ; } case TYPE_FIL : if ( elem_id == 15 ) elem_id + = get_bits ( & gb , 8 ) - 1 ; if ( get_bits_left ( & gb ) < 8 * elem_id ) { av_log ( avccontext , AV_LOG_ERROR , overread_err ) ; return - 1 ; } while ( elem_id > 0 ) elem_id - = decode_extension_payload ( ac , & gb , elem_id , che_prev , elem_type_prev ) ; err = 0 ; / * FIXME * / break ; default : err = - 1 ; / * should not happen , but keeps compiler happy * / break ; } che_prev = che ; elem_type_prev = elem_type ; if ( err ) return err ; if ( get_bits_left ( & gb ) < 3 ) { av_log ( avccontext , AV_LOG_ERROR , overread_err ) ; return - 1 ; } } spectral_to_sample ( ac ) ; multiplier = ( ac - > m4ac . sbr == 1 ) ? ac - > m4ac . ext_sample_rate > ac - > m4ac . sample_rate : 0 ; samples < < = multiplier ; if ( ac - > output_configured < OC_LOCKED ) { avccontext - > sample_rate = ac - > m4ac . sample_rate < < multiplier ; avccontext - > frame_size = samples ; } data_size_tmp = samples * avccontext - > channels * sizeof ( int16_t ) ; if ( * data_size < data_size_tmp ) { av_log ( avccontext , AV_LOG_ERROR , Output buffer too small ( %d ) or trying to output too many samples ( %d ) for this frame . \n , * data_size , data_size_tmp ) ; return - 1 ; } * data_size = data_size_tmp ; ac - > dsp . float_to_int16_interleave ( data , ( const float * * ) ac - > output_data , samples , avccontext - > channels ) ; if ( ac - > output_configured ) ac - > output_configured = OC_LOCKED ; buf_consumed = ( get_bits_count ( & gb ) + 7 ) > > 3 ; for ( buf_offset = buf_consumed ; buf_offset < buf_size ; buf_offset + + ) if ( buf[buf_offset] ) break ; return buf_size > buf_offset ? buf_consumed : buf_size ; }",1
"static inline void dv_guess_qnos ( EncBlockInfo * blks , int * qnos ) { int size[5] ; int i , j , k , a , prev , a2 ; EncBlockInfo * b ; size[4]= 1 < < 24 ; do { b = blks ; for ( i=0 ; i < 5 ; i + + ) { if ( ! qnos[i] ) continue ; qnos[i] - - ; size[i] = 0 ; for ( j=0 ; j < 6 ; j + + , b + + ) { for ( a=0 ; a < 4 ; a + + ) { if ( b - > area_q[a] ! = dv_quant_shifts[qnos[i] + dv_quant_offset[b - > cno]][a] ) { b - > bit_size[a] = 1 ; // 4 areas 4 bits for EOB : ) b - > area_q[a] + + ; prev= b - > prev[a] ; for ( k= b - > next[prev] ; k < mb_area_start[a + 1] ; k= b - > next[k] ) { b - > mb[k] > > = 1 ; if ( b - > mb[k] ) { b - > bit_size[a] + = dv_rl2vlc_size ( k - prev - 1 , b - > mb[k] ) ; prev= k ; } else { if ( b - > next[k] > = mb_area_start[a + 1] & & b - > next[k] < 64 ) { for ( a2=a + 1 ; b - > next[k] > = mb_area_start[a2 + 1] ; a2 + + ) ; assert ( a2 < 4 ) ; assert ( b - > mb[b - > next[k]] ) ; b - > bit_size[a2] + = dv_rl2vlc_size ( b - > next[k] - prev - 1 , b - > mb[b - > next[k]] ) - dv_rl2vlc_size ( b - > next[k] - k - 1 , b - > mb[b - > next[k]] ) ; } b - > next[prev] = b - > next[k] ; } } b - > prev[a + 1]= prev ; } size[i] + = b - > bit_size[a] ; } } if ( vs_total_ac_bits > = size[0] + size[1] + size[2] + size[3] + size[4] ) return ; } } while ( qnos[0]|qnos[1]|qnos[2]|qnos[3]|qnos[4] ) ; for ( a=2 ; a==2 || vs_total_ac_bits < size[0] ; a + =a ) { b = blks ; size[0] = 5 * 6 * 4 ; //EOB for ( j=0 ; j < 6 * 5 ; j + + , b + + ) { prev= b - > prev[0] ; for ( k= b - > next[prev] ; k < 64 ; k= b - > next[k] ) { if ( b - > mb[k] < a & & b - > mb[k] > - a ) { b - > next[prev] = b - > next[k] ; } else { size[0] + = dv_rl2vlc_size ( k - prev - 1 , b - > mb[k] ) ; prev= k ; } } } } }",1
"static av_cold int hnm_decode_init ( AVCodecContext * avctx ) { Hnm4VideoContext * hnm = avctx - > priv_data ; if ( avctx - > extradata_size < 1 ) { av_log ( avctx , AV_LOG_ERROR , Extradata missing , decoder requires version number\n ) ; return AVERROR_INVALIDDATA ; } hnm - > version = avctx - > extradata[0] ; avctx - > pix_fmt = AV_PIX_FMT_PAL8 ; hnm - > width = avctx - > width ; hnm - > height = avctx - > height ; hnm - > buffer1 = av_mallocz ( avctx - > width * avctx - > height ) ; hnm - > buffer2 = av_mallocz ( avctx - > width * avctx - > height ) ; hnm - > processed = av_mallocz ( avctx - > width * avctx - > height ) ; if ( ! hnm - > buffer1 || ! hnm - > buffer2 || ! hnm - > processed ) { av_log ( avctx , AV_LOG_ERROR , av_mallocz ( ) failed\n ) ; av_freep ( & hnm - > buffer1 ) ; av_freep ( & hnm - > buffer2 ) ; av_freep ( & hnm - > processed ) ; return AVERROR ( ENOMEM ) ; } hnm - > current = hnm - > buffer1 ; hnm - > previous = hnm - > buffer2 ; return 0 ; }",0
"static int tqi_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; const uint8_t * buf_end = buf + buf_size ; TqiContext * t = avctx - > priv_data ; MpegEncContext * s = & t - > s ; s - > width = AV_RL16 ( & buf[0] ) ; s - > height = AV_RL16 ( & buf[2] ) ; tqi_calculate_qtable ( s , buf[4] ) ; buf + = 8 ; if ( t - > frame . data[0] ) avctx - > release_buffer ( avctx , & t - > frame ) ; if ( s - > avctx - > width ! =s - > width || s - > avctx - > height ! =s - > height ) avcodec_set_dimensions ( s - > avctx , s - > width , s - > height ) ; if ( avctx - > get_buffer ( avctx , & t - > frame ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed\n ) ; return - 1 ; } av_fast_malloc ( & t - > bitstream_buf , & t - > bitstream_buf_size , ( buf_end - buf ) + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! t - > bitstream_buf ) return AVERROR ( ENOMEM ) ; s - > dsp . bswap_buf ( t - > bitstream_buf , ( const uint32_t * ) buf , ( buf_end - buf ) /4 ) ; init_get_bits ( & s - > gb , t - > bitstream_buf , 8 * ( buf_end - buf ) ) ; s - > last_dc[0] = s - > last_dc[1] = s - > last_dc[2] = 0 ; for ( s - > mb_y=0 ; s - > mb_y < ( avctx - > height + 15 ) /16 ; s - > mb_y + + ) for ( s - > mb_x=0 ; s - > mb_x < ( avctx - > width + 15 ) /16 ; s - > mb_x + + ) { if ( tqi_decode_mb ( s , t - > block ) < 0 ) break ; tqi_idct_put ( t , t - > block ) ; } * data_size = sizeof ( AVFrame ) ; * ( AVFrame * ) data = t - > frame ; return buf_size ; }",1
"static int mxf_compute_sample_count ( MXFContext * mxf , int stream_index , uint64_t * sample_count ) { int i , total = 0 , size = 0 ; AVStream * st = mxf - > fc - > streams[stream_index] ; MXFTrack * track = st - > priv_data ; AVRational time_base = av_inv_q ( track - > edit_rate ) ; AVRational sample_rate = av_inv_q ( st - > time_base ) ; const MXFSamplesPerFrame * spf = NULL ; if ( ( sample_rate . num / sample_rate . den ) == 48000 ) spf = ff_mxf_get_samples_per_frame ( mxf - > fc , time_base ) ; if ( ! spf ) { int remainder = ( sample_rate . num * time_base . num ) % ( time_base . den * sample_rate . den ) ; * sample_count = av_q2d ( av_mul_q ( ( AVRational ) { mxf - > current_edit_unit , 1 } , av_mul_q ( sample_rate , time_base ) ) ) ; if ( remainder ) av_log ( mxf - > fc , AV_LOG_WARNING , seeking detected on stream %d with time base ( %d/%d ) and sample rate ( %d/%d ) , audio pts won ' t be accurate . \n , stream_index , time_base . num , time_base . den , sample_rate . num , sample_rate . den ) ; return 0 ; } while ( spf - > samples_per_frame[size] ) { total + = spf - > samples_per_frame[size] ; size + + ; } av_assert2 ( size ) ; * sample_count = ( mxf - > current_edit_unit / size ) * total ; for ( i = 0 ; i < mxf - > current_edit_unit % size ; i + + ) { * sample_count + = spf - > samples_per_frame[i] ; } return 0 ; }",1
"static void sbr_dequant ( SpectralBandReplication * sbr , int id_aac ) { int k , e ; int ch ; if ( id_aac == TYPE_CPE & & sbr - > bs_coupling ) { float alpha = sbr - > data[0] . bs_amp_res ? 1 . 0f : 0 . 5f ; float pan_offset = sbr - > data[0] . bs_amp_res ? 12 . 0f : 24 . 0f ; for ( e = 1 ; e < = sbr - > data[0] . bs_num_env ; e + + ) { for ( k = 0 ; k < sbr - > n[sbr - > data[0] . bs_freq_res[e]] ; k + + ) { float temp1 = exp2f ( sbr - > data[0] . env_facs[e][k] * alpha + 7 . 0f ) ; float temp2 = exp2f ( ( pan_offset - sbr - > data[1] . env_facs[e][k] ) * alpha ) ; float fac = temp1 / ( 1 . 0f + temp2 ) ; sbr - > data[0] . env_facs[e][k] = fac ; sbr - > data[1] . env_facs[e][k] = fac * temp2 ; } } for ( e = 1 ; e < = sbr - > data[0] . bs_num_noise ; e + + ) { for ( k = 0 ; k < sbr - > n_q ; k + + ) { float temp1 = exp2f ( NOISE_FLOOR_OFFSET - sbr - > data[0] . noise_facs[e][k] + 1 ) ; float temp2 = exp2f ( 12 - sbr - > data[1] . noise_facs[e][k] ) ; float fac = temp1 / ( 1 . 0f + temp2 ) ; sbr - > data[0] . noise_facs[e][k] = fac ; sbr - > data[1] . noise_facs[e][k] = fac * temp2 ; } } } else { // SCE or one non - coupled CPE for ( ch = 0 ; ch < ( id_aac == TYPE_CPE ) + 1 ; ch + + ) { float alpha = sbr - > data[ch] . bs_amp_res ? 1 . 0f : 0 . 5f ; for ( e = 1 ; e < = sbr - > data[ch] . bs_num_env ; e + + ) for ( k = 0 ; k < sbr - > n[sbr - > data[ch] . bs_freq_res[e]] ; k + + ) sbr - > data[ch] . env_facs[e][k] = exp2f ( alpha * sbr - > data[ch] . env_facs[e][k] + 6 . 0f ) ; for ( e = 1 ; e < = sbr - > data[ch] . bs_num_noise ; e + + ) for ( k = 0 ; k < sbr - > n_q ; k + + ) sbr - > data[ch] . noise_facs[e][k] = exp2f ( NOISE_FLOOR_OFFSET - sbr - > data[ch] . noise_facs[e][k] ) ; } } }",1
"static inline int16_t logadd ( int16_t a , int16_t b ) { int16_t c = a - b ; uint8_t address = FFMIN ( ( ABS ( c ) > > 1 ) , 255 ) ; return ( ( c > = 0 ) ? ( a + latab[address] ) : ( b + latab[address] ) ) ; }",0
"static int write_manifest ( AVFormatContext * s , int final ) { DASHContext * c = s - > priv_data ; AVIOContext * out ; char temp_filename[1024] ; int ret , i ; AVDictionaryEntry * title = av_dict_get ( s - > metadata , title , NULL , 0 ) ; snprintf ( temp_filename , sizeof ( temp_filename ) , %s . tmp , s - > filename ) ; ret = avio_open2 ( & out , temp_filename , AVIO_FLAG_WRITE , & s - > interrupt_callback , NULL ) ; if ( ret < 0 ) { av_log ( s , AV_LOG_ERROR , Unable to open %s for writing\n , temp_filename ) ; return ret ; } avio_printf ( out , < ? xml version=\ 1 . 0\ encoding=\ utf - 8\ ? > \n ) ; avio_printf ( out , < MPD xmlns : xsi=\ http : //www . w3 . org/2001/XMLSchema - instance\ \n \txmlns=\ urn : mpeg : dash : schema : mpd : 2011\ \n \txmlns : xlink=\ http : //www . w3 . org/1999/xlink\ \n \txsi : schemaLocation=\ urn : mpeg : DASH : schema : MPD : 2011 http : //standards . iso . org/ittf/PubliclyAvailableStandards/MPEG - DASH_schema_files/DASH - MPD . xsd\ \n \tprofiles=\ urn : mpeg : dash : profile : isoff - live : 2011\ \n \ttype=\ %s\ \n , final ? static : dynamic ) ; if ( final ) { avio_printf ( out , \tmediaPresentationDuration=\ ) ; write_time ( out , c - > total_duration ) ; avio_printf ( out , \ \n ) ; } else { int update_period = c - > last_duration / AV_TIME_BASE ; if ( c - > use_template & & ! c - > use_timeline ) update_period = 500 ; avio_printf ( out , \tminimumUpdatePeriod=\ PT%dS\ \n , update_period ) ; avio_printf ( out , \tsuggestedPresentationDelay=\ PT%dS\ \n , c - > last_duration / AV_TIME_BASE ) ; if ( ! c - > availability_start_time[0] & & s - > nb_streams > 0 & & c - > streams[0] . nb_segments > 0 ) { time_t t = time ( NULL ) ; struct tm * ptm , tmbuf ; ptm = gmtime_r ( & t , & tmbuf ) ; if ( ptm ) { if ( ! strftime ( c - > availability_start_time , sizeof ( c - > availability_start_time ) , %Y - %m - %dT%H : %M : %S , ptm ) ) c - > availability_start_time[0] = ' \0 ' ; } } if ( c - > availability_start_time[0] ) avio_printf ( out , \tavailabilityStartTime=\ %s\ \n , c - > availability_start_time ) ; if ( c - > window_size & & c - > use_template ) { avio_printf ( out , \ttimeShiftBufferDepth=\ ) ; write_time ( out , c - > last_duration * c - > window_size ) ; avio_printf ( out , \ \n ) ; } } avio_printf ( out , \tminBufferTime=\ ) ; write_time ( out , c - > last_duration ) ; avio_printf ( out , \ > \n ) ; avio_printf ( out , \t < ProgramInformation > \n ) ; if ( title ) { char * escaped = xmlescape ( title - > value ) ; avio_printf ( out , \t\t < Title > %s < /Title > \n , escaped ) ; av_free ( escaped ) ; } avio_printf ( out , \t < /ProgramInformation > \n ) ; if ( c - > window_size & & s - > nb_streams > 0 & & c - > streams[0] . nb_segments > 0 & & ! c - > use_template ) { OutputStream * os = & c - > streams[0] ; int start_index = FFMAX ( os - > nb_segments - c - > window_size , 0 ) ; int64_t start_time = av_rescale_q ( os - > segments[start_index] - > time , s - > streams[0] - > time_base , AV_TIME_BASE_Q ) ; avio_printf ( out , \t < Period start=\ ) ; write_time ( out , start_time ) ; avio_printf ( out , \ > \n ) ; } else { avio_printf ( out , \t < Period start=\ PT0 . 0S\ > \n ) ; } if ( c - > has_video ) { avio_printf ( out , \t\t < AdaptationSet id=\ video\ segmentAlignment=\ true\ bitstreamSwitching=\ true\ > \n ) ; for ( i = 0 ; i < s - > nb_streams ; i + + ) { AVStream * st = s - > streams[i] ; OutputStream * os = & c - > streams[i] ; if ( s - > streams[i] - > codec - > codec_type ! = AVMEDIA_TYPE_VIDEO ) continue ; avio_printf ( out , \t\t\t < Representation id=\ %d\ mimeType=\ video/mp4\ codecs=\ %s\ %s width=\ %d\ height=\ %d\ > \n , i , os - > codec_str , os - > bandwidth_str , st - > codec - > width , st - > codec - > height ) ; output_segment_list ( & c - > streams[i] , out , c ) ; avio_printf ( out , \t\t\t < /Representation > \n ) ; } avio_printf ( out , \t\t < /AdaptationSet > \n ) ; } if ( c - > has_audio ) { avio_printf ( out , \t\t < AdaptationSet id=\ audio\ segmentAlignment=\ true\ bitstreamSwitching=\ true\ > \n ) ; for ( i = 0 ; i < s - > nb_streams ; i + + ) { AVStream * st = s - > streams[i] ; OutputStream * os = & c - > streams[i] ; if ( s - > streams[i] - > codec - > codec_type ! = AVMEDIA_TYPE_AUDIO ) continue ; avio_printf ( out , \t\t\t < Representation id=\ %d\ mimeType=\ audio/mp4\ codecs=\ %s\ %s audioSamplingRate=\ %d\ > \n , i , os - > codec_str , os - > bandwidth_str , st - > codec - > sample_rate ) ; avio_printf ( out , \t\t\t\t < AudioChannelConfiguration schemeIdUri=\ urn : mpeg : dash : 23003 : 3 : audio_channel_configuration : 2011\ value=\ %d\ / > \n , st - > codec - > channels ) ; output_segment_list ( & c - > streams[i] , out , c ) ; avio_printf ( out , \t\t\t < /Representation > \n ) ; } avio_printf ( out , \t\t < /AdaptationSet > \n ) ; } avio_printf ( out , \t < /Period > \n ) ; avio_printf ( out , < /MPD > \n ) ; avio_flush ( out ) ; avio_close ( out ) ; return ff_rename ( temp_filename , s - > filename , s ) ; }",1
"static int get_scale_factor ( H264SliceContext * sl , int poc , int poc1 , int i ) { int poc0 = sl - > ref_list[0][i] . poc ; int td = av_clip_int8 ( poc1 - poc0 ) ; if ( td == 0 || sl - > ref_list[0][i] . parent - > long_ref ) { return 256 ; } else { int tb = av_clip_int8 ( poc - poc0 ) ; int tx = ( 16384 + ( FFABS ( td ) > > 1 ) ) / td ; return av_clip_intp2 ( ( tb * tx + 32 ) > > 6 , 10 ) ; } }",1
"static int get_video_frame ( VideoState * is , AVFrame * frame , int64_t * pts , AVPacket * pkt ) { int got_picture , i ; if ( packet_queue_get ( & is - > videoq , pkt , 1 ) < 0 ) return - 1 ; if ( pkt - > data == flush_pkt . data ) { avcodec_flush_buffers ( is - > video_st - > codec ) ; SDL_LockMutex ( is - > pictq_mutex ) ; // Make sure there are no long delay timers ( ideally we should just flush the que but thats harder ) for ( i = 0 ; i < VIDEO_PICTURE_QUEUE_SIZE ; i + + ) { is - > pictq[i] . skip = 1 ; } while ( is - > pictq_size & & ! is - > videoq . abort_request ) { SDL_CondWait ( is - > pictq_cond , is - > pictq_mutex ) ; } is - > video_current_pos = - 1 ; is - > frame_last_pts = AV_NOPTS_VALUE ; is - > frame_last_duration = 0 ; is - > frame_timer = ( double ) av_gettime ( ) / 1000000 . 0 ; is - > frame_last_dropped_pts = AV_NOPTS_VALUE ; SDL_UnlockMutex ( is - > pictq_mutex ) ; return 0 ; } avcodec_decode_video2 ( is - > video_st - > codec , frame , & got_picture , pkt ) ; if ( got_picture ) { int ret = 1 ; if ( decoder_reorder_pts == - 1 ) { * pts = av_frame_get_best_effort_timestamp ( frame ) ; } else if ( decoder_reorder_pts ) { * pts = frame - > pkt_pts ; } else { * pts = frame - > pkt_dts ; } if ( * pts == AV_NOPTS_VALUE ) { * pts = 0 ; } if ( ( ( is - > av_sync_type == AV_SYNC_AUDIO_MASTER & & is - > audio_st ) || is - > av_sync_type == AV_SYNC_EXTERNAL_CLOCK ) & & ( framedrop > 0 || ( framedrop & & is - > audio_st ) ) ) { SDL_LockMutex ( is - > pictq_mutex ) ; if ( is - > frame_last_pts ! = AV_NOPTS_VALUE & & * pts ) { double clockdiff = get_video_clock ( is ) - get_master_clock ( is ) ; double dpts = av_q2d ( is - > video_st - > time_base ) * * pts ; double ptsdiff = dpts - is - > frame_last_pts ; if ( fabs ( clockdiff ) < AV_NOSYNC_THRESHOLD & & ptsdiff > 0 & & ptsdiff < AV_NOSYNC_THRESHOLD & & clockdiff + ptsdiff - is - > frame_last_filter_delay < 0 ) { is - > frame_last_dropped_pos = pkt - > pos ; is - > frame_last_dropped_pts = dpts ; is - > frame_drops_early + + ; ret = 0 ; } } SDL_UnlockMutex ( is - > pictq_mutex ) ; } return ret ; } return 0 ; }",0
"static int X264_frame ( AVCodecContext * ctx , uint8_t * buf , int bufsize , void * data ) { X264Context * x4 = ctx - > priv_data ; AVFrame * frame = data ; x264_nal_t * nal ; int nnal , i ; x264_picture_t pic_out ; x4 - > pic . img . i_csp = X264_CSP_I420 ; x4 - > pic . img . i_plane = 3 ; if ( frame ) { for ( i = 0 ; i < 3 ; i + + ) { x4 - > pic . img . plane[i] = frame - > data[i] ; x4 - > pic . img . i_stride[i] = frame - > linesize[i] ; } x4 - > pic . i_pts = frame - > pts ; x4 - > pic . i_type = X264_TYPE_AUTO ; } if ( x264_encoder_encode ( x4 - > enc , & nal , & nnal , frame ? & x4 - > pic : NULL , & pic_out ) < 0 ) return - 1 ; bufsize = encode_nals ( ctx , buf , bufsize , nal , nnal , 0 ) ; if ( bufsize < 0 ) return - 1 ; / * FIXME : dts * / x4 - > out_pic . pts = pic_out . i_pts ; switch ( pic_out . i_type ) { case X264_TYPE_IDR : case X264_TYPE_I : x4 - > out_pic . pict_type = FF_I_TYPE ; break ; case X264_TYPE_P : x4 - > out_pic . pict_type = FF_P_TYPE ; break ; case X264_TYPE_B : case X264_TYPE_BREF : x4 - > out_pic . pict_type = FF_B_TYPE ; break ; } x4 - > out_pic . key_frame = pic_out . i_type == X264_TYPE_IDR ; x4 - > out_pic . quality = ( pic_out . i_qpplus1 - 1 ) * FF_QP2LAMBDA ; return bufsize ; }",0
"static void fill_buffer ( ByteIOContext * s ) { int len ; / * no need to do anything if EOF already reached * / if ( s - > eof_reached ) return ; if ( s - > update_checksum ) { if ( s - > buf_end > s - > checksum_ptr ) s - > checksum= s - > update_checksum ( s - > checksum , s - > checksum_ptr , s - > buf_end - s - > checksum_ptr ) ; s - > checksum_ptr= s - > buffer ; } len = s - > read_packet ( s - > opaque , s - > buffer , s - > buffer_size ) ; if ( len < = 0 ) { / * do not modify buffer if EOF reached so that a seek back can be done without rereading data * / s - > eof_reached = 1 ; if ( len < 0 ) s - > error= len ; } else { s - > pos + = len ; s - > buf_ptr = s - > buffer ; s - > buf_end = s - > buffer + len ; } }",0
"static int adx_encode_frame ( AVCodecContext * avctx , uint8_t * frame , int buf_size , void * data ) { ADXContext * c = avctx - > priv_data ; const int16_t * samples = data ; uint8_t * dst = frame ; int ch ; if ( ! c - > header_parsed ) { int hdrsize = adx_encode_header ( avctx , dst , buf_size ) ; dst + = hdrsize ; c - > header_parsed = 1 ; } for ( ch = 0 ; ch < avctx - > channels ; ch + + ) { adx_encode ( c , dst , samples + ch , & c - > prev[ch] , avctx - > channels ) ; dst + = BLOCK_SIZE ; } return dst - frame ; }",0
"static int bmp_parse ( AVCodecParserContext * s , AVCodecContext * avctx , const uint8_t * * poutbuf , int * poutbuf_size , const uint8_t * buf , int buf_size ) { BMPParseContext * bpc = s - > priv_data ; uint64_t state = bpc - > pc . state64 ; int next = END_NOT_FOUND ; int i = 0 ; * poutbuf_size = 0 ; restart : if ( bpc - > pc . frame_start_found < = 2 + 4 + 4 ) { for ( ; i < buf_size ; i + + ) { state = ( state < < 8 ) | buf[i] ; if ( bpc - > pc . frame_start_found == 0 ) { if ( ( state > > 48 ) == ( ( ' B ' < < 8 ) | ' M ' ) ) { bpc - > fsize = av_bswap32 ( state > > 16 ) ; bpc - > pc . frame_start_found = 1 ; } } else if ( bpc - > pc . frame_start_found == 2 + 4 + 4 ) { // unsigned hsize = av_bswap32 ( state > > 32 ) ; unsigned ihsize = av_bswap32 ( state ) ; if ( ihsize < 12 || ihsize > 200 ) { bpc - > pc . frame_start_found = 0 ; continue ; } bpc - > pc . frame_start_found + + ; bpc - > remaining_size = bpc - > fsize + i - 17 ; if ( bpc - > pc . index + i > 17 ) { next = i - 17 ; state = 0 ; break ; } else { bpc - > pc . state64 = 0 ; goto restart ; } } else if ( bpc - > pc . frame_start_found ) bpc - > pc . frame_start_found + + ; } bpc - > pc . state64 = state ; } else { if ( bpc - > remaining_size ) { i = FFMIN ( bpc - > remaining_size , buf_size ) ; bpc - > remaining_size - = i ; if ( bpc - > remaining_size ) goto flush ; bpc - > pc . frame_start_found = 0 ; goto restart ; } } flush : if ( ff_combine_frame ( & bpc - > pc , next , & buf , & buf_size ) < 0 ) return buf_size ; if ( next ! = END_NOT_FOUND & & next < 0 ) bpc - > pc . frame_start_found = FFMAX ( bpc - > pc . frame_start_found - i - 1 , 0 ) ; else bpc - > pc . frame_start_found = 0 ; * poutbuf = buf ; * poutbuf_size = buf_size ; return next ; }",0
"static int avi_read_seek ( AVFormatContext * s , int stream_index , int64_t timestamp , int flags ) { AVIContext * avi = s - > priv_data ; AVStream * st ; int i , index ; int64_t pos ; AVIStream * ast ; if ( ! avi - > index_loaded ) { / * we only load the index on demand * / avi_load_index ( s ) ; avi - > index_loaded = 1 ; } assert ( stream_index > = 0 ) ; st = s - > streams[stream_index] ; ast= st - > priv_data ; index= av_index_search_timestamp ( st , timestamp * FFMAX ( ast - > sample_size , 1 ) , flags ) ; if ( index < 0 ) return - 1 ; / * find the position * / pos = st - > index_entries[index] . pos ; timestamp = st - > index_entries[index] . timestamp / FFMAX ( ast - > sample_size , 1 ) ; av_dlog ( s , XX % PRId64 %d % PRId64 \n , timestamp , index , st - > index_entries[index] . timestamp ) ; if ( CONFIG_DV_DEMUXER & & avi - > dv_demux ) { / * One and only one real stream for DV in AVI , and it has video * / / * offsets . Calling with other stream indexes should have failed * / / * the av_index_search_timestamp call above . * / assert ( stream_index == 0 ) ; / * Feed the DV video stream version of the timestamp to the * / / * DV demux so it can synthesize correct timestamps . * / ff_dv_offset_reset ( avi - > dv_demux , timestamp ) ; avio_seek ( s - > pb , pos , SEEK_SET ) ; avi - > stream_index= - 1 ; return 0 ; } for ( i = 0 ; i < s - > nb_streams ; i + + ) { AVStream * st2 = s - > streams[i] ; AVIStream * ast2 = st2 - > priv_data ; ast2 - > packet_size= ast2 - > remaining= 0 ; if ( ast2 - > sub_ctx ) { seek_subtitle ( st , st2 , timestamp ) ; continue ; } if ( st2 - > nb_index_entries < = 0 ) continue ; // assert ( st2 - > codec - > block_align ) ; assert ( ( int64_t ) st2 - > time_base . num * ast2 - > rate == ( int64_t ) st2 - > time_base . den * ast2 - > scale ) ; index = av_index_search_timestamp ( st2 , av_rescale_q ( timestamp , st - > time_base , st2 - > time_base ) * FFMAX ( ast2 - > sample_size , 1 ) , flags | AVSEEK_FLAG_BACKWARD ) ; if ( index < 0 ) index=0 ; if ( ! avi - > non_interleaved ) { while ( index > 0 & & st2 - > index_entries[index] . pos > pos ) index - - ; while ( index + 1 < st2 - > nb_index_entries & & st2 - > index_entries[index] . pos < pos ) index + + ; } av_dlog ( s , % PRId64 %d % PRId64 \n , timestamp , index , st2 - > index_entries[index] . timestamp ) ; / * extract the current frame number * / ast2 - > frame_offset = st2 - > index_entries[index] . timestamp ; } / * do the seek * / avio_seek ( s - > pb , pos , SEEK_SET ) ; avi - > stream_index= - 1 ; return 0 ; }",0
"static int opt_streamid ( const char * opt , const char * arg ) { int idx ; char * p ; char idx_str[16] ; av_strlcpy ( idx_str , arg , sizeof ( idx_str ) ) ; p = strchr ( idx_str , ' : ' ) ; if ( ! p ) { fprintf ( stderr , Invalid value ' %s ' for option ' %s ' , required syntax is ' index : value ' \n , arg , opt ) ; ffmpeg_exit ( 1 ) ; } * p + + = ' \0 ' ; idx = parse_number_or_die ( opt , idx_str , OPT_INT , 0 , INT_MAX ) ; streamid_map = grow_array ( streamid_map , sizeof ( * streamid_map ) , & nb_streamid_map , idx + 1 ) ; streamid_map[idx] = parse_number_or_die ( opt , p , OPT_INT , 0 , INT_MAX ) ; return 0 ; }",0
"static void avc_luma_midv_qrt_16w_msa ( const uint8_t * src , int32_t src_stride , uint8_t * dst , int32_t dst_stride , int32_t height , uint8_t vert_offset ) { uint32_t multiple8_cnt ; for ( multiple8_cnt = 2 ; multiple8_cnt - - ; ) { avc_luma_midv_qrt_8w_msa ( src , src_stride , dst , dst_stride , height , vert_offset ) ; src + = 8 ; dst + = 8 ; } }",0
"int mpeg4_decode_picture_header ( MpegEncContext * s ) { int time_incr , startcode , state , v ; redo : / * search next start code * / align_get_bits ( & s - > gb ) ; state = 0xff ; for ( ; ; ) { v = get_bits ( & s - > gb , 8 ) ; if ( state == 0x000001 ) { state = ( ( state < < 8 ) | v ) & 0xffffff ; startcode = state ; break ; } state = ( ( state < < 8 ) | v ) & 0xffffff ; if ( get_bits_count ( & s - > gb ) > s - > gb . size * 8 ) { printf ( no VOP startcode found\n ) ; return - 1 ; } } //printf ( startcode %X %d\n , startcode , get_bits_count ( & s - > gb ) ) ; if ( startcode == 0x120 ) { // Video Object Layer int width , height , vo_ver_id ; / * vol header * / skip_bits ( & s - > gb , 1 ) ; / * random access * / skip_bits ( & s - > gb , 8 ) ; / * vo_type * / if ( get_bits1 ( & s - > gb ) ! = 0 ) { / * is_ol_id * / vo_ver_id = get_bits ( & s - > gb , 4 ) ; / * vo_ver_id * / skip_bits ( & s - > gb , 3 ) ; / * vo_priority * / } else { vo_ver_id = 1 ; } s - > aspect_ratio_info= get_bits ( & s - > gb , 4 ) ; if ( s - > aspect_ratio_info == EXTENDET_PAR ) { skip_bits ( & s - > gb , 8 ) ; //par_width skip_bits ( & s - > gb , 8 ) ; // par_height } if ( get_bits1 ( & s - > gb ) ) { / * vol control parameter * / printf ( vol control parameter not supported\n ) ; return - 1 ; } s - > shape = get_bits ( & s - > gb , 2 ) ; / * vol shape * / if ( s - > shape ! = RECT_SHAPE ) printf ( only rectangular vol supported\n ) ; if ( s - > shape == GRAY_SHAPE & & vo_ver_id ! = 1 ) { printf ( Gray shape not supported\n ) ; skip_bits ( & s - > gb , 4 ) ; //video_object_layer_shape_extension } skip_bits1 ( & s - > gb ) ; / * marker * / s - > time_increment_resolution = get_bits ( & s - > gb , 16 ) ; s - > time_increment_bits = av_log2 ( s - > time_increment_resolution - 1 ) + 1 ; if ( s - > time_increment_bits < 1 ) s - > time_increment_bits = 1 ; skip_bits1 ( & s - > gb ) ; / * marker * / if ( get_bits1 ( & s - > gb ) ! = 0 ) { / * fixed_vop_rate * / skip_bits ( & s - > gb , s - > time_increment_bits ) ; } if ( s - > shape ! = BIN_ONLY_SHAPE ) { if ( s - > shape == RECT_SHAPE ) { skip_bits1 ( & s - > gb ) ; / * marker * / width = get_bits ( & s - > gb , 13 ) ; skip_bits1 ( & s - > gb ) ; / * marker * / height = get_bits ( & s - > gb , 13 ) ; skip_bits1 ( & s - > gb ) ; / * marker * / if ( width & & height ) { / * they should be non zero but who knows . . . * / s - > width = width ; s - > height = height ; // printf ( %d %d\n , width , height ) ; } } if ( get_bits1 ( & s - > gb ) ) printf ( interlaced not supported\n ) ; / * interlaced * / if ( ! get_bits1 ( & s - > gb ) ) printf ( OBMC not supported\n ) ; / * OBMC Disable * / if ( vo_ver_id == 1 ) { s - > vol_sprite_usage = get_bits1 ( & s - > gb ) ; / * vol_sprite_usage * / } else { s - > vol_sprite_usage = get_bits ( & s - > gb , 2 ) ; / * vol_sprite_usage * / } if ( s - > vol_sprite_usage==STATIC_SPRITE ) printf ( Static Sprites not supported\n ) ; if ( s - > vol_sprite_usage==STATIC_SPRITE || s - > vol_sprite_usage==GMC_SPRITE ) { if ( s - > vol_sprite_usage==STATIC_SPRITE ) { s - > sprite_width = get_bits ( & s - > gb , 13 ) ; skip_bits1 ( & s - > gb ) ; / * marker * / s - > sprite_height= get_bits ( & s - > gb , 13 ) ; skip_bits1 ( & s - > gb ) ; / * marker * / s - > sprite_left = get_bits ( & s - > gb , 13 ) ; skip_bits1 ( & s - > gb ) ; / * marker * / s - > sprite_top = get_bits ( & s - > gb , 13 ) ; skip_bits1 ( & s - > gb ) ; / * marker * / } s - > num_sprite_warping_points= get_bits ( & s - > gb , 6 ) ; s - > sprite_warping_accuracy = get_bits ( & s - > gb , 2 ) ; s - > sprite_brightness_change= get_bits1 ( & s - > gb ) ; if ( s - > vol_sprite_usage==STATIC_SPRITE ) s - > low_latency_sprite= get_bits1 ( & s - > gb ) ; } // FIXME sadct disable bit if verid ! =1 & & shape not rect if ( get_bits1 ( & s - > gb ) == 1 ) { / * not_8_bit * / s - > quant_precision = get_bits ( & s - > gb , 4 ) ; / * quant_precision * / if ( get_bits ( & s - > gb , 4 ) ! =8 ) printf ( N - bit not supported\n ) ; / * bits_per_pixel * / } else { s - > quant_precision = 5 ; } // FIXME a bunch of grayscale shape things if ( get_bits1 ( & s - > gb ) ) printf ( Quant - Type not supported\n ) ; / * vol_quant_type * / //FIXME if ( vo_ver_id ! = 1 ) s - > quarter_sample= get_bits1 ( & s - > gb ) ; else s - > quarter_sample=0 ; if ( ! get_bits1 ( & s - > gb ) ) printf ( Complexity estimation not supported\n ) ; if 0 if ( get_bits1 ( & s - > gb ) ) printf ( resync disable\n ) ;",0
"static void RENAME ( yuv2rgb32_1 ) ( SwsContext * c , const uint16_t * buf0 , const uint16_t * ubuf0 , const uint16_t * ubuf1 , const uint16_t * vbuf0 , const uint16_t * vbuf1 , const uint16_t * abuf0 , uint8_t * dest , int dstW , int uvalpha , enum PixelFormat dstFormat , int flags , int y ) { const uint16_t * buf1= buf0 ; //FIXME needed for RGB1/BGR1 if ( uvalpha < 2048 ) { // note this is not correct ( shifts chrominance by 0 . 5 pixels ) but it is a bit faster if ( CONFIG_SWSCALE_ALPHA & & c - > alpPixBuf ) { __asm__ volatile ( mov %% REG_b , ESP_OFFSET ( %5 ) \n\t mov %4 , %% REG_b \n\t push %% REG_BP \n\t YSCALEYUV2RGB1 ( %%REGBP , %5 ) YSCALEYUV2RGB1_ALPHA ( %%REGBP ) WRITEBGR32 ( %%REGb , 8280 ( %5 ) , %%REGBP , %%mm2 , %%mm4 , %%mm5 , %%mm7 , %%mm0 , %%mm1 , %%mm3 , %%mm6 ) pop %% REG_BP \n\t mov ESP_OFFSET ( %5 ) , %% REG_b \n\t : : c ( buf0 ) , d ( abuf0 ) , S ( ubuf0 ) , D ( ubuf1 ) , m ( dest ) , a ( & c - > redDither ) ) ; } else { __asm__ volatile ( mov %% REG_b , ESP_OFFSET ( %5 ) \n\t mov %4 , %% REG_b \n\t push %% REG_BP \n\t YSCALEYUV2RGB1 ( %%REGBP , %5 ) pcmpeqd %%mm7 , %%mm7 \n\t WRITEBGR32 ( %%REGb , 8280 ( %5 ) , %%REGBP , %%mm2 , %%mm4 , %%mm5 , %%mm7 , %%mm0 , %%mm1 , %%mm3 , %%mm6 ) pop %% REG_BP \n\t mov ESP_OFFSET ( %5 ) , %% REG_b \n\t : : c ( buf0 ) , d ( buf1 ) , S ( ubuf0 ) , D ( ubuf1 ) , m ( dest ) , a ( & c - > redDither ) ) ; } } else { if ( CONFIG_SWSCALE_ALPHA & & c - > alpPixBuf ) { __asm__ volatile ( mov %% REG_b , ESP_OFFSET ( %5 ) \n\t mov %4 , %% REG_b \n\t push %% REG_BP \n\t YSCALEYUV2RGB1b ( %%REGBP , %5 ) YSCALEYUV2RGB1_ALPHA ( %%REGBP ) WRITEBGR32 ( %%REGb , 8280 ( %5 ) , %%REGBP , %%mm2 , %%mm4 , %%mm5 , %%mm7 , %%mm0 , %%mm1 , %%mm3 , %%mm6 ) pop %% REG_BP \n\t mov ESP_OFFSET ( %5 ) , %% REG_b \n\t : : c ( buf0 ) , d ( abuf0 ) , S ( ubuf0 ) , D ( ubuf1 ) , m ( dest ) , a ( & c - > redDither ) ) ; } else { __asm__ volatile ( mov %% REG_b , ESP_OFFSET ( %5 ) \n\t mov %4 , %% REG_b \n\t push %% REG_BP \n\t YSCALEYUV2RGB1b ( %%REGBP , %5 ) pcmpeqd %%mm7 , %%mm7 \n\t WRITEBGR32 ( %%REGb , 8280 ( %5 ) , %%REGBP , %%mm2 , %%mm4 , %%mm5 , %%mm7 , %%mm0 , %%mm1 , %%mm3 , %%mm6 ) pop %% REG_BP \n\t mov ESP_OFFSET ( %5 ) , %% REG_b \n\t : : c ( buf0 ) , d ( buf1 ) , S ( ubuf0 ) , D ( ubuf1 ) , m ( dest ) , a ( & c - > redDither ) ) ; } } }",0
"static int decode_frame ( AVCodecContext * avctx , void * data , int * data_size , uint8_t * buf , int buf_size ) { HYuvContext * s = avctx - > priv_data ; const int width= s - > width ; const int width2= s - > width > > 1 ; const int height= s - > height ; int fake_ystride , fake_ustride , fake_vstride ; AVFrame * const p= & s - > picture ; AVFrame * picture = data ; * data_size = 0 ; / * no supplementary picture * / if ( buf_size == 0 ) return 0 ; bswap_buf ( ( uint32_t * ) s - > bitstream_buffer , ( uint32_t * ) buf , buf_size/4 ) ; init_get_bits ( & s - > gb , s - > bitstream_buffer , buf_size ) ; p - > reference= 0 ; if ( avctx - > get_buffer ( avctx , p ) < 0 ) { fprintf ( stderr , get_buffer ( ) failed\n ) ; return - 1 ; } fake_ystride= s - > interlaced ? p - > linesize[0] * 2 : p - > linesize[0] ; fake_ustride= s - > interlaced ? p - > linesize[1] * 2 : p - > linesize[1] ; fake_vstride= s - > interlaced ? p - > linesize[2] * 2 : p - > linesize[2] ; s - > last_slice_end= 0 ; if ( s - > bitstream_bpp < 24 ) { int y , cy ; int lefty , leftu , leftv ; int lefttopy , lefttopu , lefttopv ; if ( s - > yuy2 ) { p - > data[0][3]= get_bits ( & s - > gb , 8 ) ; p - > data[0][2]= get_bits ( & s - > gb , 8 ) ; p - > data[0][1]= get_bits ( & s - > gb , 8 ) ; p - > data[0][0]= get_bits ( & s - > gb , 8 ) ; fprintf ( stderr , YUY2 output isnt implemenetd yet\n ) ; return - 1 ; } else { leftv= p - > data[2][0]= get_bits ( & s - > gb , 8 ) ; lefty= p - > data[0][1]= get_bits ( & s - > gb , 8 ) ; leftu= p - > data[1][0]= get_bits ( & s - > gb , 8 ) ; p - > data[0][0]= get_bits ( & s - > gb , 8 ) ; switch ( s - > predictor ) { case LEFT : case PLANE : decode_422_bitstream ( s , width - 2 ) ; lefty= add_left_prediction ( p - > data[0] + 2 , s - > temp[0] , width - 2 , lefty ) ; if ( ! ( s - > flags & CODEC_FLAG_GRAY ) ) { leftu= add_left_prediction ( p - > data[1] + 1 , s - > temp[1] , width2 - 1 , leftu ) ; leftv= add_left_prediction ( p - > data[2] + 1 , s - > temp[2] , width2 - 1 , leftv ) ; } for ( cy=y=1 ; y < s - > height ; y + + , cy + + ) { uint8_t * ydst , * udst , * vdst ; if ( s - > bitstream_bpp==12 ) { decode_gray_bitstream ( s , width ) ; ydst= p - > data[0] + p - > linesize[0] * y ; lefty= add_left_prediction ( ydst , s - > temp[0] , width , lefty ) ; if ( s - > predictor == PLANE ) { if ( y > s - > interlaced ) s - > dsp . add_bytes ( ydst , ydst - fake_ystride , width ) ; } y + + ; if ( y > =s - > height ) break ; } draw_slice ( s , y ) ; ydst= p - > data[0] + p - > linesize[0] * y ; udst= p - > data[1] + p - > linesize[1] * cy ; vdst= p - > data[2] + p - > linesize[2] * cy ; decode_422_bitstream ( s , width ) ; lefty= add_left_prediction ( ydst , s - > temp[0] , width , lefty ) ; if ( ! ( s - > flags & CODEC_FLAG_GRAY ) ) { leftu= add_left_prediction ( udst , s - > temp[1] , width2 , leftu ) ; leftv= add_left_prediction ( vdst , s - > temp[2] , width2 , leftv ) ; } if ( s - > predictor == PLANE ) { if ( cy > s - > interlaced ) { s - > dsp . add_bytes ( ydst , ydst - fake_ystride , width ) ; if ( ! ( s - > flags & CODEC_FLAG_GRAY ) ) { s - > dsp . add_bytes ( udst , udst - fake_ustride , width2 ) ; s - > dsp . add_bytes ( vdst , vdst - fake_vstride , width2 ) ; } } } } draw_slice ( s , height ) ; break ; case MEDIAN : / * first line except first 2 pixels is left predicted * / decode_422_bitstream ( s , width - 2 ) ; lefty= add_left_prediction ( p - > data[0] + 2 , s - > temp[0] , width - 2 , lefty ) ; if ( ! ( s - > flags & CODEC_FLAG_GRAY ) ) { leftu= add_left_prediction ( p - > data[1] + 1 , s - > temp[1] , width2 - 1 , leftu ) ; leftv= add_left_prediction ( p - > data[2] + 1 , s - > temp[2] , width2 - 1 , leftv ) ; } cy=y=1 ; / * second line is left predicted for interlaced case * / if ( s - > interlaced ) { decode_422_bitstream ( s , width ) ; lefty= add_left_prediction ( p - > data[0] + p - > linesize[0] , s - > temp[0] , width , lefty ) ; if ( ! ( s - > flags & CODEC_FLAG_GRAY ) ) { leftu= add_left_prediction ( p - > data[1] + p - > linesize[2] , s - > temp[1] , width2 , leftu ) ; leftv= add_left_prediction ( p - > data[2] + p - > linesize[1] , s - > temp[2] , width2 , leftv ) ; } y + + ; cy + + ; } / * next 4 pixels are left predicted too * / decode_422_bitstream ( s , 4 ) ; lefty= add_left_prediction ( p - > data[0] + fake_ystride , s - > temp[0] , 4 , lefty ) ; if ( ! ( s - > flags & CODEC_FLAG_GRAY ) ) { leftu= add_left_prediction ( p - > data[1] + fake_ustride , s - > temp[1] , 2 , leftu ) ; leftv= add_left_prediction ( p - > data[2] + fake_vstride , s - > temp[2] , 2 , leftv ) ; } / * next line except the first 4 pixels is median predicted * / lefttopy= p - > data[0][3] ; decode_422_bitstream ( s , width - 4 ) ; add_median_prediction ( p - >",0
"int attribute_align_arg avcodec_decode_audio4 ( AVCodecContext * avctx , AVFrame * frame , int * got_frame_ptr , AVPacket * avpkt ) { int planar , channels ; int ret = 0 ; * got_frame_ptr = 0 ; avctx - > pkt = avpkt ; if ( ! avpkt - > data & & avpkt - > size ) { av_log ( avctx , AV_LOG_ERROR , invalid packet : NULL data , size ! = 0\n ) ; return AVERROR ( EINVAL ) ; } apply_param_change ( avctx , avpkt ) ; if ( ( avctx - > codec - > capabilities & CODEC_CAP_DELAY ) || avpkt - > size ) { ret = avctx - > codec - > decode ( avctx , frame , got_frame_ptr , avpkt ) ; if ( ret > = 0 & & * got_frame_ptr ) { avctx - > frame_number + + ; frame - > pkt_dts = avpkt - > dts ; if ( frame - > format == AV_SAMPLE_FMT_NONE ) frame - > format = avctx - > sample_fmt ; } } / * many decoders assign whole AVFrames , thus overwriting extended_data ; * make sure it ' s set correctly ; assume decoders that actually use * extended_data are doing it correctly * / planar = av_sample_fmt_is_planar ( frame - > format ) ; channels = av_get_channel_layout_nb_channels ( frame - > channel_layout ) ; if ( ! ( planar & & channels > AV_NUM_DATA_POINTERS ) ) frame - > extended_data = frame - > data ; return ret ; }",1
"int ff_j2k_init_component ( Jpeg2000Component * comp , Jpeg2000CodingStyle * codsty , Jpeg2000QuantStyle * qntsty , int cbps , int dx , int dy ) { int reslevelno , bandno , gbandno = 0 , ret , i , j , csize = 1 ; if ( ret=ff_j2k_dwt_init ( & comp - > dwt , comp - > coord , codsty - > nreslevels - 1 , codsty - > transform ) ) return ret ; for ( i = 0 ; i < 2 ; i + + ) csize * = comp - > coord[i][1] - comp - > coord[i][0] ; comp - > data = av_malloc ( csize * sizeof ( int ) ) ; if ( ! comp - > data ) return AVERROR ( ENOMEM ) ; comp - > reslevel = av_malloc ( codsty - > nreslevels * sizeof ( Jpeg2000ResLevel ) ) ; if ( ! comp - > reslevel ) return AVERROR ( ENOMEM ) ; for ( reslevelno = 0 ; reslevelno < codsty - > nreslevels ; reslevelno + + ) { int declvl = codsty - > nreslevels - reslevelno ; Jpeg2000ResLevel * reslevel = comp - > reslevel + reslevelno ; for ( i = 0 ; i < 2 ; i + + ) for ( j = 0 ; j < 2 ; j + + ) reslevel - > coord[i][j] = ff_jpeg2000_ceildivpow2 ( comp - > coord[i][j] , declvl - 1 ) ; if ( reslevelno == 0 ) reslevel - > nbands = 1 ; else reslevel - > nbands = 3 ; if ( reslevel - > coord[0][1] == reslevel - > coord[0][0] ) reslevel - > num_precincts_x = 0 ; else reslevel - > num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel - > coord[0][1] , codsty - > log2_prec_width ) - ( reslevel - > coord[0][0] > > codsty - > log2_prec_width ) ; if ( reslevel - > coord[1][1] == reslevel - > coord[1][0] ) reslevel - > num_precincts_y = 0 ; else reslevel - > num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel - > coord[1][1] , codsty - > log2_prec_height ) - ( reslevel - > coord[1][0] > > codsty - > log2_prec_height ) ; reslevel - > band = av_malloc ( reslevel - > nbands * sizeof ( Jpeg2000Band ) ) ; if ( ! reslevel - > band ) return AVERROR ( ENOMEM ) ; for ( bandno = 0 ; bandno < reslevel - > nbands ; bandno + + , gbandno + + ) { Jpeg2000Band * band = reslevel - > band + bandno ; int cblkno , precx , precy , precno ; int x0 , y0 , x1 , y1 ; int xi0 , yi0 , xi1 , yi1 ; int cblkperprecw , cblkperprech ; if ( qntsty - > quantsty ! = JPEG2000_QSTY_NONE ) { static const uint8_t lut_gain[2][4] = { { 0 , 0 , 0 , 0 } , { 0 , 1 , 1 , 2 } } ; int numbps ; numbps = cbps + lut_gain[codsty - > transform][bandno + reslevelno > 0] ; band - > stepsize = SHL ( 2048 + qntsty - > mant[gbandno] , 2 + numbps - qntsty - > expn[gbandno] ) ; } else band - > stepsize = 1 < < 13 ; if ( reslevelno == 0 ) { // the same everywhere band - > codeblock_width = 1 < < FFMIN ( codsty - > log2_cblk_width , codsty - > log2_prec_width - 1 ) ; band - > codeblock_height = 1 < < FFMIN ( codsty - > log2_cblk_height , codsty - > log2_prec_height - 1 ) ; for ( i = 0 ; i < 2 ; i + + ) for ( j = 0 ; j < 2 ; j + + ) band - > coord[i][j] = ff_jpeg2000_ceildivpow2 ( comp - > coord[i][j] , declvl - 1 ) ; } else { band - > codeblock_width = 1 < < FFMIN ( codsty - > log2_cblk_width , codsty - > log2_prec_width ) ; band - > codeblock_height = 1 < < FFMIN ( codsty - > log2_cblk_height , codsty - > log2_prec_height ) ; for ( i = 0 ; i < 2 ; i + + ) for ( j = 0 ; j < 2 ; j + + ) band - > coord[i][j] = ff_jpeg2000_ceildivpow2 ( comp - > coord[i][j] - ( ( ( bandno + 1 > > i ) & 1 ) < < declvl - 1 ) , declvl ) ; } band - > cblknx = ff_jpeg2000_ceildiv ( band - > coord[0][1] , band - > codeblock_width ) - band - > coord[0][0] / band - > codeblock_width ; band - > cblkny = ff_jpeg2000_ceildiv ( band - > coord[1][1] , band - > codeblock_height ) - band - > coord[1][0] / band - > codeblock_height ; for ( j = 0 ; j < 2 ; j + + ) band - > coord[0][j] = ff_jpeg2000_ceildiv ( band - > coord[0][j] , dx ) ; for ( j = 0 ; j < 2 ; j + + ) band - > coord[1][j] = ff_jpeg2000_ceildiv ( band - > coord[1][j] , dy ) ; band - > cblknx = ff_jpeg2000_ceildiv ( band - > cblknx , dx ) ; band - > cblkny = ff_jpeg2000_ceildiv ( band - > cblkny , dy ) ; band - > cblk = av_malloc ( sizeof ( Jpeg2000Cblk ) * band - > cblknx * band - > cblkny ) ; if ( ! band - > cblk ) return AVERROR ( ENOMEM ) ; band - > prec = av_malloc ( sizeof ( Jpeg2000Cblk ) * reslevel - > num_precincts_x * reslevel - > num_precincts_y ) ; if ( ! band - > prec ) return AVERROR ( ENOMEM ) ; for ( cblkno = 0 ; cblkno < band - > cblknx * band - > cblkny ; cblkno + + ) { Jpeg2000Cblk * cblk = band - > cblk + cblkno ; cblk - > zero = 0 ; cblk - > lblock = 3 ; cblk - > length = 0 ; cblk - > lengthinc = 0 ; cblk - > npasses = 0 ; } y0 = band - > coord[1][0] ; y1 = ( ( band - > coord[1][0] + ( 1 < < codsty - > log2_prec_height ) ) & ( ( 1 < < codsty - > log2_prec_height ) - 1 ) ) - y0 ; yi0 = 0 ; yi1 = ff_jpeg2000_ceildivpow2 ( y1 - y0 , codsty - > log2_cblk_height ) < < codsty - > log2_cblk_height ; yi1 = FFMIN ( yi1 , band - > cblkny ) ; cblkperprech = 1 < < ( codsty - > log2_prec_height - codsty - > log2_cblk_height ) ; for ( precy = 0 , precno = 0 ; precy < reslevel - > num_precincts_y ; precy + + ) { for ( precx = 0 ; precx < reslevel - > num_precincts_x ; precx + + , precno + + ) { band - >",1
"static int read_frame_internal ( AVFormatContext * s , AVPacket * pkt ) { AVStream * st ; int len , ret , i ; av_init_packet ( pkt ) ; for ( ; ; ) { / * select current input stream component * / st = s - > cur_st ; if ( st ) { if ( ! st - > need_parsing || ! st - > parser ) { / * no parsing needed : we just output the packet as is * / / * raw data support * / * pkt = st - > cur_pkt ; st - > cur_pkt . data= NULL ; compute_pkt_fields ( s , st , NULL , pkt ) ; s - > cur_st = NULL ; if ( ( s - > iformat - > flags & AVFMT_GENERIC_INDEX ) & & ( pkt - > flags & AV_PKT_FLAG_KEY ) & & pkt - > dts ! = AV_NOPTS_VALUE ) { ff_reduce_index ( s , st - > index ) ; av_add_index_entry ( st , pkt - > pos , pkt - > dts , 0 , 0 , AVINDEX_KEYFRAME ) ; } break ; } else if ( st - > cur_len > 0 & & st - > discard < AVDISCARD_ALL ) { len = av_parser_parse2 ( st - > parser , st - > codec , & pkt - > data , & pkt - > size , st - > cur_ptr , st - > cur_len , st - > cur_pkt . pts , st - > cur_pkt . dts , st - > cur_pkt . pos ) ; st - > cur_pkt . pts = AV_NOPTS_VALUE ; st - > cur_pkt . dts = AV_NOPTS_VALUE ; / * increment read pointer * / st - > cur_ptr + = len ; st - > cur_len - = len ; / * return packet if any * / if ( pkt - > size ) { got_packet : pkt - > duration = 0 ; pkt - > stream_index = st - > index ; pkt - > pts = st - > parser - > pts ; pkt - > dts = st - > parser - > dts ; pkt - > pos = st - > parser - > pos ; if ( pkt - > data == st - > cur_pkt . data & & pkt - > size == st - > cur_pkt . size ) { s - > cur_st = NULL ; pkt - > destruct= st - > cur_pkt . destruct ; st - > cur_pkt . destruct= NULL ; st - > cur_pkt . data = NULL ; assert ( st - > cur_len == 0 ) ; } else { pkt - > destruct = NULL ; } compute_pkt_fields ( s , st , st - > parser , pkt ) ; if ( ( s - > iformat - > flags & AVFMT_GENERIC_INDEX ) & & pkt - > flags & AV_PKT_FLAG_KEY ) { int64_t pos= ( st - > parser - > flags & PARSER_FLAG_COMPLETE_FRAMES ) ? pkt - > pos : st - > parser - > frame_offset ; ff_reduce_index ( s , st - > index ) ; av_add_index_entry ( st , pos , pkt - > dts , 0 , 0 , AVINDEX_KEYFRAME ) ; } break ; } } else { / * free packet * / av_free_packet ( & st - > cur_pkt ) ; s - > cur_st = NULL ; } } else { AVPacket cur_pkt ; / * read next packet * / ret = av_read_packet ( s , & cur_pkt ) ; if ( ret < 0 ) { if ( ret == AVERROR ( EAGAIN ) ) return ret ; / * return the last frames , if any * / for ( i = 0 ; i < s - > nb_streams ; i + + ) { st = s - > streams[i] ; if ( st - > parser & & st - > need_parsing ) { av_parser_parse2 ( st - > parser , st - > codec , & pkt - > data , & pkt - > size , NULL , 0 , AV_NOPTS_VALUE , AV_NOPTS_VALUE , AV_NOPTS_VALUE ) ; if ( pkt - > size ) goto got_packet ; } } / * no more packets : really terminate parsing * / return ret ; } st = s - > streams[cur_pkt . stream_index] ; st - > cur_pkt= cur_pkt ; if ( st - > cur_pkt . pts ! = AV_NOPTS_VALUE & & st - > cur_pkt . dts ! = AV_NOPTS_VALUE & & st - > cur_pkt . pts < st - > cur_pkt . dts ) { av_log ( s , AV_LOG_WARNING , Invalid timestamps stream=%d , pts=% PRId64 , dts=% PRId64 , size=%d\n , st - > cur_pkt . stream_index , st - > cur_pkt . pts , st - > cur_pkt . dts , st - > cur_pkt . size ) ; // av_free_packet ( & st - > cur_pkt ) ; // return - 1 ; } if ( s - > debug & FF_FDEBUG_TS ) av_log ( s , AV_LOG_DEBUG , av_read_packet stream=%d , pts=% PRId64 , dts=% PRId64 , size=%d , duration=%d , flags=%d\n , st - > cur_pkt . stream_index , st - > cur_pkt . pts , st - > cur_pkt . dts , st - > cur_pkt . size , st - > cur_pkt . duration , st - > cur_pkt . flags ) ; s - > cur_st = st ; st - > cur_ptr = st - > cur_pkt . data ; st - > cur_len = st - > cur_pkt . size ; if ( st - > need_parsing & & ! st - > parser & & ! ( s - > flags & AVFMT_FLAG_NOPARSE ) ) { st - > parser = av_parser_init ( st - > codec - > codec_id ) ; if ( ! st - > parser ) { av_log ( s , AV_LOG_WARNING , parser not found for codec %s , packets or times may be invalid . \n , avcodec_get_name ( st - > codec - > codec_id ) ) ; / * no parser available : just output the raw packets * / st - > need_parsing = AVSTREAM_PARSE_NONE ; } else if ( st - > need_parsing == AVSTREAM_PARSE_HEADERS ) { st - > parser - > flags |= PARSER_FLAG_COMPLETE_FRAMES ; } else if ( st - > need_parsing == AVSTREAM_PARSE_FULL_ONCE ) { st - > parser - > flags |= PARSER_FLAG_ONCE ; } } } } if ( s - > debug & FF_FDEBUG_TS ) av_log ( s , AV_LOG_DEBUG , read_frame_internal stream=%d , pts=% PRId64 , dts=% PRId64 , size=%d , duration=%d , flags=%d\n , pkt - > stream_index , pkt - > pts , pkt - > dts , pkt - > size , pkt - > duration , pkt - > flags ) ; return 0 ; }",1
"static int read_filter_params ( MLPDecodeContext * m , GetBitContext * gbp , unsigned int substr , unsigned int channel , unsigned int filter ) { SubStream * s = & m - > substream[substr] ; FilterParams * fp = & s - > channel_params[channel] . filter_params[filter] ; const int max_order = filter ? MAX_IIR_ORDER : MAX_FIR_ORDER ; const char fchar = filter ? ' I ' : ' F ' ; int i , order ; // Filter is 0 for FIR , 1 for IIR . av_assert0 ( filter < 2 ) ; if ( m - > filter_changed[channel][filter] + + > 1 ) { av_log ( m - > avctx , AV_LOG_ERROR , Filters may change only once per access unit . \n ) ; return AVERROR_INVALIDDATA ; } order = get_bits ( gbp , 4 ) ; if ( order > max_order ) { av_log ( m - > avctx , AV_LOG_ERROR , %cIR filter order %d is greater than maximum %d . \n , fchar , order , max_order ) ; return AVERROR_INVALIDDATA ; } fp - > order = order ; if ( order > 0 ) { int32_t * fcoeff = s - > channel_params[channel] . coeff[filter] ; int coeff_bits , coeff_shift ; fp - > shift = get_bits ( gbp , 4 ) ; coeff_bits = get_bits ( gbp , 5 ) ; coeff_shift = get_bits ( gbp , 3 ) ; if ( coeff_bits < 1 || coeff_bits > 16 ) { av_log ( m - > avctx , AV_LOG_ERROR , %cIR filter coeff_bits must be between 1 and 16 . \n , fchar ) ; return AVERROR_INVALIDDATA ; } if ( coeff_bits + coeff_shift > 16 ) { av_log ( m - > avctx , AV_LOG_ERROR , Sum of coeff_bits and coeff_shift for %cIR filter must be 16 or less . \n , fchar ) ; return AVERROR_INVALIDDATA ; } for ( i = 0 ; i < order ; i + + ) fcoeff[i] = get_sbits ( gbp , coeff_bits ) * ( 1 < < coeff_shift ) ; if ( get_bits1 ( gbp ) ) { int state_bits , state_shift ; if ( filter == FIR ) { av_log ( m - > avctx , AV_LOG_ERROR , FIR filter has state data specified . \n ) ; return AVERROR_INVALIDDATA ; } state_bits = get_bits ( gbp , 4 ) ; state_shift = get_bits ( gbp , 4 ) ; / * TODO : Check validity of state data . * / for ( i = 0 ; i < order ; i + + ) fp - > state[i] = state_bits ? get_sbits ( gbp , state_bits ) < < state_shift : 0 ; } } return 0 ; }",1
"static int filter_frame ( AVFilterLink * inlink , AVFilterBufferRef * inpicref ) { IlContext * il = inlink - > dst - > priv ; AVFilterLink * outlink = inlink - > dst - > outputs[0] ; AVFilterBufferRef * out ; int ret ; out = ff_get_video_buffer ( outlink , AV_PERM_WRITE , outlink - > w , outlink - > h ) ; if ( ! out ) { avfilter_unref_bufferp ( & inpicref ) ; return AVERROR ( ENOMEM ) ; } avfilter_copy_buffer_ref_props ( out , inpicref ) ; interleave ( out - > data[0] , inpicref - > data[0] , il - > width , inlink - > h , out - > linesize[0] , inpicref - > linesize[0] , il - > luma_mode , il - > luma_swap ) ; if ( il - > nb_planes > 2 ) { interleave ( out - > data[1] , inpicref - > data[1] , il - > chroma_width , il - > chroma_height , out - > linesize[1] , inpicref - > linesize[1] , il - > chroma_mode , il - > chroma_swap ) ; interleave ( out - > data[2] , inpicref - > data[2] , il - > chroma_width , il - > chroma_height , out - > linesize[2] , inpicref - > linesize[2] , il - > chroma_mode , il - > chroma_swap ) ; } if ( il - > nb_planes == 2 & & il - > nb_planes == 4 ) { int comp = il - > nb_planes - 1 ; interleave ( out - > data[comp] , inpicref - > data[comp] , il - > width , inlink - > h , out - > linesize[comp] , inpicref - > linesize[comp] , il - > alpha_mode , il - > alpha_swap ) ; } ret = ff_filter_frame ( outlink , out ) ; avfilter_unref_bufferp ( & inpicref ) ; return ret ; }",1
"decode_lpc ( WmallDecodeCtx * s ) { int ch , i , cbits ; s - > lpc_order = get_bits ( & s - > gb , 5 ) + 1 ; s - > lpc_scaling = get_bits ( & s - > gb , 4 ) ; s - > lpc_intbits = get_bits ( & s - > gb , 3 ) + 1 ; cbits = s - > lpc_scaling + s - > lpc_intbits ; for ( ch = 0 ; ch < s - > num_channels ; ch + + ) { for ( i = 0 ; i < s - > lpc_order ; i + + ) { s - > lpc_coefs[ch][i] = get_sbits ( & s - > gb , cbits ) ; } } }",1
"static double get_scene_score ( AVFilterContext * ctx , AVFrame * crnt , AVFrame * next ) { FrameRateContext * s = ctx - > priv ; double ret = 0 ; ff_dlog ( ctx , get_scene_score ( ) \n ) ; if ( crnt - > height == next - > height & & crnt - > width == next - > width ) { int64_t sad ; double mafd , diff ; ff_dlog ( ctx , get_scene_score ( ) process\n ) ; if ( s - > bitdepth == 8 ) sad = scene_sad8 ( s , crnt - > data[0] , crnt - > linesize[0] , next - > data[0] , next - > linesize[0] , crnt - > height ) ; else sad = scene_sad16 ( s , ( const uint16_t * ) crnt - > data[0] , crnt - > linesize[0] > > 1 , ( const uint16_t * ) next - > data[0] , next - > linesize[0] > > 1 , crnt - > height ) ; mafd = ( double ) sad * 100 . 0 / ( crnt - > height * crnt - > width ) / ( 1 < < s - > bitdepth ) ; diff = fabs ( mafd - s - > prev_mafd ) ; ret = av_clipf ( FFMIN ( mafd , diff ) , 0 , 100 . 0 ) ; s - > prev_mafd = mafd ; } ff_dlog ( ctx , get_scene_score ( ) result is : %f\n , ret ) ; return ret ; }",1
"int main ( int argc , char * argv[] ) { int i , j ; uint64_t sse=0 ; uint64_t dev ; FILE * f[2] ; uint8_t buf[2][SIZE] ; uint64_t psnr ; int len= argc < 4 ? 1 : atoi ( argv[3] ) ; int64_t max= ( 1 < < ( 8 * len ) ) - 1 ; int shift= argc < 5 ? 0 : atoi ( argv[4] ) ; int skip_bytes = argc < 6 ? 0 : atoi ( argv[5] ) ; if ( argc < 3 ) { printf ( tiny_psnr < file1 > < file2 > [ < elem size > [ < shift > [ < skip bytes > ]]]\n ) ; printf ( For WAV files use the following : \n ) ; printf ( . /tiny_psnr file1 . wav file2 . wav 2 0 44 to skip the header . \n ) ; return - 1 ; } f[0]= fopen ( argv[1] , rb ) ; f[1]= fopen ( argv[2] , rb ) ; if ( ! f[0] || ! f[1] ) { fprintf ( stderr , Could not open input files . \n ) ; return - 1 ; } fseek ( f[shift < 0] , shift < 0 ? - shift : shift , SEEK_SET ) ; fseek ( f[0] , skip_bytes , SEEK_CUR ) ; fseek ( f[1] , skip_bytes , SEEK_CUR ) ; for ( i=0 ; ; ) { if ( fread ( buf[0] , SIZE , 1 , f[0] ) ! = 1 ) break ; if ( fread ( buf[1] , SIZE , 1 , f[1] ) ! = 1 ) break ; for ( j=0 ; j < SIZE ; i + + , j + + ) { int64_t a= buf[0][j] ; int64_t b= buf[1][j] ; if ( len==2 ) { a= ( int16_t ) ( a | ( buf[0][ + + j] < < 8 ) ) ; b= ( int16_t ) ( b | ( buf[1][ j] < < 8 ) ) ; } sse + = ( a - b ) * ( a - b ) ; } } if ( ! i ) i=1 ; dev= int_sqrt ( ( ( sse/i ) * F * F ) + ( ( ( sse%i ) * F * F ) + i/2 ) /i ) ; if ( sse ) psnr= ( ( 2 * log16 ( max < < 16 ) + log16 ( i ) - log16 ( sse ) ) * 284619LL * F + ( 1 < < 31 ) ) / ( 1LL < < 32 ) ; else psnr= 100 * F - 1 ; //floating point free infinity : ) printf ( stddev : %3d . %02d PSNR : %2d . %02d bytes : %d\n , ( int ) ( dev/F ) , ( int ) ( dev%F ) , ( int ) ( psnr/F ) , ( int ) ( psnr%F ) , i * len ) ; return 0 ; }",0
"static int celt_header ( AVFormatContext * s , int idx ) { struct ogg * ogg = s - > priv_data ; struct ogg_stream * os = ogg - > streams + idx ; AVStream * st = s - > streams[idx] ; struct oggcelt_private * priv = os - > private ; uint8_t * p = os - > buf + os - > pstart ; if ( os - > psize == 60 & & ! memcmp ( p , ff_celt_codec . magic , ff_celt_codec . magicsize ) ) { / * Main header * / uint32_t version , sample_rate , nb_channels ; uint32_t overlap , extra_headers ; priv = av_malloc ( sizeof ( struct oggcelt_private ) ) ; if ( ! priv ) return AVERROR ( ENOMEM ) ; if ( ff_alloc_extradata ( st - > codecpar , 2 * sizeof ( uint32_t ) ) < 0 ) { av_free ( priv ) ; return AVERROR ( ENOMEM ) ; } version = AV_RL32 ( p + 28 ) ; / * unused header size field skipped * / sample_rate = AV_RL32 ( p + 36 ) ; nb_channels = AV_RL32 ( p + 40 ) ; overlap = AV_RL32 ( p + 48 ) ; / * unused bytes per packet field skipped * / extra_headers = AV_RL32 ( p + 56 ) ; st - > codecpar - > codec_type = AVMEDIA_TYPE_AUDIO ; st - > codecpar - > codec_id = AV_CODEC_ID_CELT ; st - > codecpar - > sample_rate = sample_rate ; st - > codecpar - > channels = nb_channels ; if ( sample_rate ) avpriv_set_pts_info ( st , 64 , 1 , sample_rate ) ; priv - > extra_headers_left = 1 + extra_headers ; av_free ( os - > private ) ; os - > private = priv ; AV_WL32 ( st - > codecpar - > extradata + 0 , overlap ) ; AV_WL32 ( st - > codecpar - > extradata + 4 , version ) ; return 1 ; } else if ( priv & & priv - > extra_headers_left ) { / * Extra headers ( vorbiscomment ) * / ff_vorbis_stream_comment ( s , st , p , os - > psize ) ; priv - > extra_headers_left - - ; return 1 ; } else { return 0 ; } }",1
"static int decode_group3_1d_line ( AVCodecContext * avctx , GetBitContext * gb , int pix_left , int * runs ) { int mode = 0 , run = 0 ; unsigned int t ; for ( ; ; ) { t = get_vlc2 ( gb , ccitt_vlc[mode] . table , 9 , 2 ) ; run + = t ; if ( t < 64 ) { pix_left - = run ; * runs + + = run ; if ( pix_left < = 0 ) { if ( ! pix_left ) break ; runs[ - 1] = 0 ; av_log ( avctx , AV_LOG_ERROR , Run went out of bounds\n ) ; return - 1 ; } run = 0 ; mode = ! mode ; } else if ( ( int ) t == - 1 ) { av_log ( avctx , AV_LOG_ERROR , Incorrect code\n ) ; return - 1 ; } } * runs + + = 0 ; return 0 ; }",0
"static int get_qcx ( Jpeg2000DecoderContext * s , int n , Jpeg2000QuantStyle * q ) { int i , x ; if ( s - > buf_end - s - > buf < 1 ) return AVERROR ( EINVAL ) ; x = bytestream_get_byte ( & s - > buf ) ; // Sqcd q - > nguardbits = x > > 5 ; q - > quantsty = x & 0x1f ; if ( q - > quantsty == JPEG2000_QSTY_NONE ) { n - = 3 ; if ( s - > buf_end - s - > buf < n || 32 * 3 < n ) return AVERROR ( EINVAL ) ; for ( i = 0 ; i < n ; i + + ) q - > expn[i] = bytestream_get_byte ( & s - > buf ) > > 3 ; } else if ( q - > quantsty == JPEG2000_QSTY_SI ) { if ( s - > buf_end - s - > buf < 2 ) return AVERROR ( EINVAL ) ; x = bytestream_get_be16 ( & s - > buf ) ; q - > expn[0] = x > > 11 ; q - > mant[0] = x & 0x7ff ; for ( i = 1 ; i < 32 * 3 ; i + + ) { int curexpn = FFMAX ( 0 , q - > expn[0] - ( i - 1 ) / 3 ) ; q - > expn[i] = curexpn ; q - > mant[i] = q - > mant[0] ; } } else { n = ( n - 3 ) > > 1 ; if ( s - > buf_end - s - > buf < 2 * n || 32 * 3 < n ) return AVERROR ( EINVAL ) ; for ( i = 0 ; i < n ; i + + ) { x = bytestream_get_be16 ( & s - > buf ) ; q - > expn[i] = x > > 11 ; q - > mant[i] = x & 0x7ff ; } } return 0 ; }",0
"static void ready_residue ( vorbis_enc_residue * rc , vorbis_enc_context * venc ) { int i ; assert ( rc - > type == 2 ) ; rc - > maxes = av_mallocz ( sizeof ( float[2] ) * rc - > classifications ) ; for ( i = 0 ; i < rc - > classifications ; i + + ) { int j ; vorbis_enc_codebook * cb ; for ( j = 0 ; j < 8 ; j + + ) if ( rc - > books[i][j] ! = - 1 ) break ; if ( j == 8 ) // zero continue ; cb = & venc - > codebooks[rc - > books[i][j]] ; assert ( cb - > ndimentions > = 2 ) ; assert ( cb - > lookup ) ; for ( j = 0 ; j < cb - > nentries ; j + + ) { float a ; if ( ! cb - > lens[j] ) continue ; a = fabs ( cb - > dimentions[j * cb - > ndimentions] ) ; if ( a > rc - > maxes[i][0] ) rc - > maxes[i][0] = a ; a = fabs ( cb - > dimentions[j * cb - > ndimentions + 1] ) ; if ( a > rc - > maxes[i][1] ) rc - > maxes[i][1] = a ; } } // small bias for ( i = 0 ; i < rc - > classifications ; i + + ) { rc - > maxes[i][0] + = 0 . 8 ; rc - > maxes[i][1] + = 0 . 8 ; } }",1
"static av_cold int initFilter ( int16_t * * outFilter , int32_t * * filterPos , int * outFilterSize , int xInc , int srcW , int dstW , int filterAlign , int one , int flags , int cpu_flags , SwsVector * srcFilter , SwsVector * dstFilter , double param[2] , int is_horizontal ) { int i ; int filterSize ; int filter2Size ; int minFilterSize ; int64_t * filter = NULL ; int64_t * filter2 = NULL ; const int64_t fone = 1LL < < 54 ; int ret = - 1 ; emms_c ( ) ; // FIXME should not be required but IS ( even for non - MMX versions ) // NOTE : the + 3 is for the MMX ( + 1 ) / SSE ( + 3 ) scaler which reads over the end FF_ALLOC_OR_GOTO ( NULL , * filterPos , ( dstW + 3 ) * sizeof ( * * filterPos ) , fail ) ; if ( FFABS ( xInc - 0x10000 ) < 10 ) { // unscaled int i ; filterSize = 1 ; FF_ALLOCZ_OR_GOTO ( NULL , filter , dstW * sizeof ( * filter ) * filterSize , fail ) ; for ( i = 0 ; i < dstW ; i + + ) { filter[i * filterSize] = fone ; ( * filterPos ) [i] = i ; } } else if ( flags & SWS_POINT ) { // lame looking point sampling mode int i ; int xDstInSrc ; filterSize = 1 ; FF_ALLOC_OR_GOTO ( NULL , filter , dstW * sizeof ( * filter ) * filterSize , fail ) ; xDstInSrc = xInc / 2 - 0x8000 ; for ( i = 0 ; i < dstW ; i + + ) { int xx = ( xDstInSrc - ( ( filterSize - 1 ) < < 15 ) + ( 1 < < 15 ) ) > > 16 ; ( * filterPos ) [i] = xx ; filter[i] = fone ; xDstInSrc + = xInc ; } } else if ( ( xInc < = ( 1 < < 16 ) & & ( flags & SWS_AREA ) ) || ( flags & SWS_FAST_BILINEAR ) ) { // bilinear upscale int i ; int xDstInSrc ; filterSize = 2 ; FF_ALLOC_OR_GOTO ( NULL , filter , dstW * sizeof ( * filter ) * filterSize , fail ) ; xDstInSrc = xInc / 2 - 0x8000 ; for ( i = 0 ; i < dstW ; i + + ) { int xx = ( xDstInSrc - ( ( filterSize - 1 ) < < 15 ) + ( 1 < < 15 ) ) > > 16 ; int j ; ( * filterPos ) [i] = xx ; // bilinear upscale / linear interpolate / area averaging for ( j = 0 ; j < filterSize ; j + + ) { int64_t coeff = fone - FFABS ( ( xx < < 16 ) - xDstInSrc ) * ( fone > > 16 ) ; if ( coeff < 0 ) coeff = 0 ; filter[i * filterSize + j] = coeff ; xx + + ; } xDstInSrc + = xInc ; } } else { int64_t xDstInSrc ; int sizeFactor ; if ( flags & SWS_BICUBIC ) sizeFactor = 4 ; else if ( flags & SWS_X ) sizeFactor = 8 ; else if ( flags & SWS_AREA ) sizeFactor = 1 ; // downscale only , for upscale it is bilinear else if ( flags & SWS_GAUSS ) sizeFactor = 8 ; // infinite ; ) else if ( flags & SWS_LANCZOS ) sizeFactor = param[0] ! = SWS_PARAM_DEFAULT ? ceil ( 2 * param[0] ) : 6 ; else if ( flags & SWS_SINC ) sizeFactor = 20 ; // infinite ; ) else if ( flags & SWS_SPLINE ) sizeFactor = 20 ; // infinite ; ) else if ( flags & SWS_BILINEAR ) sizeFactor = 2 ; else { sizeFactor = 0 ; // GCC warning killer assert ( 0 ) ; } if ( xInc < = 1 < < 16 ) filterSize = 1 + sizeFactor ; // upscale else filterSize = 1 + ( sizeFactor * srcW + dstW - 1 ) / dstW ; filterSize = FFMIN ( filterSize , srcW - 2 ) ; filterSize = FFMAX ( filterSize , 1 ) ; FF_ALLOC_OR_GOTO ( NULL , filter , dstW * sizeof ( * filter ) * filterSize , fail ) ; xDstInSrc = xInc - 0x10000 ; for ( i = 0 ; i < dstW ; i + + ) { int xx = ( xDstInSrc - ( ( filterSize - 2 ) < < 16 ) ) / ( 1 < < 17 ) ; int j ; ( * filterPos ) [i] = xx ; for ( j = 0 ; j < filterSize ; j + + ) { int64_t d = ( FFABS ( ( ( int64_t ) xx < < 17 ) - xDstInSrc ) ) < < 13 ; double floatd ; int64_t coeff ; if ( xInc > 1 < < 16 ) d = d * dstW / srcW ; floatd = d * ( 1 . 0 / ( 1 < < 30 ) ) ; if ( flags & SWS_BICUBIC ) { int64_t B = ( param[0] ! = SWS_PARAM_DEFAULT ? param[0] : 0 ) * ( 1 < < 24 ) ; int64_t C = ( param[1] ! = SWS_PARAM_DEFAULT ? param[1] : 0 . 6 ) * ( 1 < < 24 ) ; if ( d > = 1LL < < 31 ) { coeff = 0 . 0 ; } else { int64_t dd = ( d * d ) > > 30 ; int64_t ddd = ( dd * d ) > > 30 ; if ( d < 1LL < < 30 ) coeff = ( 12 * ( 1 < < 24 ) - 9 * B - 6 * C ) * ddd + ( - 18 * ( 1 < < 24 ) + 12 * B + 6 * C ) * dd + ( 6 * ( 1 < < 24 ) - 2 * B ) * ( 1 < < 30 ) ; else coeff = ( - B - 6 * C ) * ddd + ( 6 * B + 30 * C ) * dd + ( - 12 * B - 48 * C ) * d + ( 8 * B + 24 * C ) * ( 1 < < 30 ) ; } coeff * = fone > > ( 30 + 24 ) ; } if 0 else if ( flags & SWS_X ) { double p = param ? param * 0 . 01 : 0 . 3 ; coeff = d ? sin ( d * M_PI ) / ( d * M_PI ) : 1 . 0 ; coeff * = pow ( 2 . 0 , - p *",0
static av_cold int shorten_decode_close ( AVCodecContext * avctx ) { ShortenContext * s = avctx - > priv_data ; int i ; for ( i = 0 ; i < s - > channels ; i + + ) { s - > decoded[i] - = s - > nwrap ; av_freep ( & s - > decoded[i] ) ; av_freep ( & s - > offset[i] ) ; } av_freep ( & s - > bitstream ) ; av_freep ( & s - > coeffs ) ; return 0 ; },1
"int ff_init_vlc_sparse ( VLC * vlc , int nb_bits , int nb_codes , const void * bits , int bits_wrap , int bits_size , const void * codes , int codes_wrap , int codes_size , const void * symbols , int symbols_wrap , int symbols_size , int flags ) { VLCcode * buf ; int i , j , ret ; vlc - > bits = nb_bits ; if ( flags & INIT_VLC_USE_NEW_STATIC ) { VLC dyn_vlc = * vlc ; if ( vlc - > table_size ) return 0 ; ret = ff_init_vlc_sparse ( & dyn_vlc , nb_bits , nb_codes , bits , bits_wrap , bits_size , codes , codes_wrap , codes_size , symbols , symbols_wrap , symbols_size , flags & INIT_VLC_USE_NEW_STATIC ) ; av_assert0 ( ret > = 0 ) ; av_assert0 ( dyn_vlc . table_size < = vlc - > table_allocated ) ; if ( dyn_vlc . table_size < vlc - > table_allocated ) av_log ( NULL , AV_LOG_ERROR , needed %d had %d\n , dyn_vlc . table_size , vlc - > table_allocated ) ; memcpy ( vlc - > table , dyn_vlc . table , dyn_vlc . table_size * sizeof ( * vlc - > table ) ) ; vlc - > table_size = dyn_vlc . table_size ; ff_free_vlc ( & dyn_vlc ) ; return 0 ; } else { vlc - > table = NULL ; vlc - > table_allocated = 0 ; vlc - > table_size = 0 ; } av_dlog ( NULL , build table nb_codes=%d\n , nb_codes ) ; buf = av_malloc ( ( nb_codes + 1 ) * sizeof ( VLCcode ) ) ; av_assert0 ( symbols_size < = 2 || ! symbols ) ; j = 0 ; define COPY ( condition ) \ for ( i = 0 ; i < nb_codes ; i + + ) { \ GET_DATA ( buf[j] . bits , bits , i , bits_wrap , bits_size ) ; \ if ( ! ( condition ) ) \ continue ; \ if ( buf[j] . bits > 3 * nb_bits || buf[j] . bits > 32 ) { \ av_log ( NULL , AV_LOG_ERROR , Too long VLC ( %d ) in init_vlc\n , buf[j] . bits ) ; \ av_free ( buf ) ; \ return - 1 ; \ } \ GET_DATA ( buf[j] . code , codes , i , codes_wrap , codes_size ) ; \ if ( buf[j] . code > = ( 1LL < < buf[j] . bits ) ) { \ av_log ( NULL , AV_LOG_ERROR , Invalid code in init_vlc\n ) ; \ av_free ( buf ) ; \ return - 1 ; \ } \ if ( flags & INIT_VLC_LE ) \ buf[j] . code = bitswap_32 ( buf[j] . code ) ; \ else \ buf[j] . code < < = 32 - buf[j] . bits ; \ if ( symbols ) \ GET_DATA ( buf[j] . symbol , symbols , i , symbols_wrap , symbols_size ) \ else \ buf[j] . symbol = i ; \ j + + ; \ } COPY ( buf[j] . bits > nb_bits ) ; // qsort is the slowest part of init_vlc , and could probably be improved or avoided qsort ( buf , j , sizeof ( VLCcode ) , compare_vlcspec ) ; COPY ( buf[j] . bits & & buf[j] . bits < = nb_bits ) ; nb_codes = j ; ret = build_table ( vlc , nb_bits , nb_codes , buf , flags ) ; av_free ( buf ) ; if ( ret < 0 ) { av_freep ( & vlc - > table ) ; return ret ; } return 0 ; }",1
"AVRational av_d2q ( double d , int max ) { AVRational a ; int exponent ; int64_t den ; if ( isnan ( d ) ) return ( AVRational ) { 0 , 0 } ; if ( fabs ( d ) > INT_MAX + 3LL ) return ( AVRational ) { d < 0 ? - 1 : 1 , 0 } ; frexp ( d , & exponent ) ; exponent = FFMAX ( exponent - 1 , 0 ) ; den = 1LL < < ( 61 - exponent ) ; // ( int64_t ) rint ( ) and llrint ( ) do not work with gcc on ia64 and sparc64 av_reduce ( & a . num , & a . den , floor ( d * den + 0 . 5 ) , den , max ) ; if ( ( ! a . num || ! a . den ) & & d & & max > 0 & & max < INT_MAX ) av_reduce ( & a . num , & a . den , floor ( d * den + 0 . 5 ) , den , INT_MAX ) ; return a ; }",0
"static unsigned tget ( GetByteContext * gb , int type , int le ) { switch ( type ) { case TIFF_BYTE : return bytestream2_get_byteu ( gb ) ; case TIFF_SHORT : return tget_short ( gb , le ) ; case TIFF_LONG : return tget_long ( gb , le ) ; default : return UINT_MAX ; } }",0
"static int rtp_parse_mp4_au ( PayloadContext * data , const uint8_t * buf ) { int au_headers_length , au_header_size , i ; GetBitContext getbitcontext ; / * decode the first 2 bytes where the AUHeader sections are stored length in bits * / au_headers_length = AV_RB16 ( buf ) ; if ( au_headers_length > RTP_MAX_PACKET_LENGTH ) return - 1 ; data - > au_headers_length_bytes = ( au_headers_length + 7 ) / 8 ; / * skip AU headers length section ( 2 bytes ) * / buf + = 2 ; init_get_bits ( & getbitcontext , buf , data - > au_headers_length_bytes * 8 ) ; / * XXX : Wrong if optionnal additional sections are present ( cts , dts etc . . . ) * / au_header_size = data - > sizelength + data - > indexlength ; if ( au_header_size < = 0 || ( au_headers_length % au_header_size ! = 0 ) ) return - 1 ; data - > nb_au_headers = au_headers_length / au_header_size ; if ( ! data - > au_headers || data - > au_headers_allocated < data - > nb_au_headers ) { av_free ( data - > au_headers ) ; data - > au_headers = av_malloc ( sizeof ( struct AUHeaders ) * data - > nb_au_headers ) ; if ( ! data - > au_headers ) return AVERROR ( ENOMEM ) ; data - > au_headers_allocated = data - > nb_au_headers ; } / * XXX : We handle multiple AU Section as only one ( need to fix this for interleaving ) In my test , the FAAD decoder does not behave correctly when sending each AU one by one but does when sending the whole as one big packet . . . * / data - > au_headers[0] . size = 0 ; data - > au_headers[0] . index = 0 ; for ( i = 0 ; i < data - > nb_au_headers ; + + i ) { data - > au_headers[0] . size + = get_bits_long ( & getbitcontext , data - > sizelength ) ; data - > au_headers[0] . index = get_bits_long ( & getbitcontext , data - > indexlength ) ; } data - > nb_au_headers = 1 ; return 0 ; }",1
"static inline void RENAME ( palToUV ) ( uint8_t * dstU , uint8_t * dstV , uint8_t * src1 , uint8_t * src2 , int width , uint32_t * pal ) { int i ; assert ( src1 == src2 ) ; for ( i=0 ; i < width ; i + + ) { int p= pal[src1[i]] ; dstU[i]= p > > 8 ; dstV[i]= p > > 16 ; } }",1
"static void targa_decode_rle ( AVCodecContext * avctx , TargaContext * s , const uint8_t * src , uint8_t * dst , int w , int h , int stride , int bpp ) { int i , x , y ; int depth = ( bpp + 1 ) > > 3 ; int type , count ; int diff ; diff = stride - w * depth ; x = y = 0 ; while ( y < h ) { type = * src + + ; count = ( type & 0x7F ) + 1 ; type & = 0x80 ; if ( ( x + count > w ) & & ( x + count + 1 > ( h - y ) * w ) ) { av_log ( avctx , AV_LOG_ERROR , Packet went out of bounds : position ( %i , %i ) size %i\n , x , y , count ) ; return ; } for ( i = 0 ; i < count ; i + + ) { switch ( depth ) { case 1 : * dst = * src ; break ; case 2 : * ( ( uint16_t * ) dst ) = AV_RL16 ( src ) ; break ; case 3 : dst[0] = src[0] ; dst[1] = src[1] ; dst[2] = src[2] ; break ; case 4 : * ( ( uint32_t * ) dst ) = AV_RL32 ( src ) ; break ; } dst + = depth ; if ( ! type ) src + = depth ; x + + ; if ( x == w ) { x = 0 ; y + + ; dst + = diff ; } } if ( type ) src + = depth ; } }",1
"static int aasc_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; AascContext * s = avctx - > priv_data ; int compr , i , stride , psize ; s - > frame . reference = 3 ; s - > frame . buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE ; if ( avctx - > reget_buffer ( avctx , & s - > frame ) ) { av_log ( avctx , AV_LOG_ERROR , reget_buffer ( ) failed\n ) ; return - 1 ; compr = AV_RL32 ( buf ) ; buf + = 4 ; buf_size - = 4 ; psize = avctx - > bits_per_coded_sample / 8 ; switch ( avctx - > codec_tag ) { case MKTAG ( ' A ' , ' A ' , ' S ' , ' 4 ' ) : bytestream2_init ( & s - > gb , buf - 4 , buf_size + 4 ) ; ff_msrle_decode ( avctx , ( AVPicture * ) & s - > frame , 8 , & s - > gb ) ; break ; case MKTAG ( ' A ' , ' A ' , ' S ' , ' C ' ) : switch ( compr ) { case 0 : stride = ( avctx - > width * psize + psize ) & psize ; for ( i = avctx - > height - 1 ; i > = 0 ; i - - ) { if ( avctx - > width * psize > buf_size ) { av_log ( avctx , AV_LOG_ERROR , Next line is beyond buffer bounds\n ) ; break ; memcpy ( s - > frame . data[0] + i * s - > frame . linesize[0] , buf , avctx - > width * psize ) ; buf + = stride ; buf_size - = stride ; break ; case 1 : bytestream2_init ( & s - > gb , buf , buf_size ) ; ff_msrle_decode ( avctx , ( AVPicture * ) & s - > frame , 8 , & s - > gb ) ; break ; default : av_log ( avctx , AV_LOG_ERROR , Unknown compression type %d\n , compr ) ; return - 1 ; break ; default : av_log ( avctx , AV_LOG_ERROR , Unknown FourCC : %X\n , avctx - > codec_tag ) ; return - 1 ; if ( avctx - > pix_fmt == AV_PIX_FMT_PAL8 ) memcpy ( s - > frame . data[1] , s - > palette , s - > palette_size ) ; * data_size = sizeof ( AVFrame ) ; * ( AVFrame * ) data = s - > frame ; / * report that the buffer was completely consumed * / return buf_size ;",1
"void ff_avg_h264_qpel4_mc13_msa ( uint8_t * dst , const uint8_t * src , ptrdiff_t stride ) { avc_luma_hv_qrt_and_aver_dst_4x4_msa ( src + stride - 2 , src - ( stride * 2 ) , stride , dst , stride ) ; }",0
"static int resample ( SwrContext * s , AudioData * out_param , int out_count , const AudioData * in_param , int in_count ) { AudioData in , out , tmp ; int ret_sum=0 ; int border=0 ; av_assert1 ( s - > in_buffer . ch_count == in_param - > ch_count ) ; av_assert1 ( s - > in_buffer . planar == in_param - > planar ) ; av_assert1 ( s - > in_buffer . fmt == in_param - > fmt ) ; tmp=out= * out_param ; in = * in_param ; do { int ret , size , consumed ; if ( ! s - > resample_in_constraint & & s - > in_buffer_count ) { buf_set ( & tmp , & s - > in_buffer , s - > in_buffer_index ) ; ret= s - > resampler - > multiple_resample ( s - > resample , & out , out_count , & tmp , s - > in_buffer_count , & consumed ) ; out_count - = ret ; ret_sum + = ret ; buf_set ( & out , & out , ret ) ; s - > in_buffer_count - = consumed ; s - > in_buffer_index + = consumed ; if ( ! in_count ) break ; if ( s - > in_buffer_count < = border ) { buf_set ( & in , & in , - s - > in_buffer_count ) ; in_count + = s - > in_buffer_count ; s - > in_buffer_count=0 ; s - > in_buffer_index=0 ; border = 0 ; } } if ( ( s - > flushed || in_count ) & & ! s - > in_buffer_count ) { s - > in_buffer_index=0 ; ret= s - > resampler - > multiple_resample ( s - > resample , & out , out_count , & in , in_count , & consumed ) ; out_count - = ret ; ret_sum + = ret ; buf_set ( & out , & out , ret ) ; in_count - = consumed ; buf_set ( & in , & in , consumed ) ; } //TODO is this check sane considering the advanced copy avoidance below size= s - > in_buffer_index + s - > in_buffer_count + in_count ; if ( size > s - > in_buffer . count & & s - > in_buffer_count + in_count < = s - > in_buffer_index ) { buf_set ( & tmp , & s - > in_buffer , s - > in_buffer_index ) ; copy ( & s - > in_buffer , & tmp , s - > in_buffer_count ) ; s - > in_buffer_index=0 ; } else if ( ( ret=swri_realloc_audio ( & s - > in_buffer , size ) ) < 0 ) return ret ; if ( in_count ) { int count= in_count ; if ( s - > in_buffer_count & & s - > in_buffer_count + 2 < count & & out_count ) count= s - > in_buffer_count + 2 ; buf_set ( & tmp , & s - > in_buffer , s - > in_buffer_index + s - > in_buffer_count ) ; copy ( & tmp , & in , / * in_ * / count ) ; s - > in_buffer_count + = count ; in_count - = count ; border + = count ; buf_set ( & in , & in , count ) ; s - > resample_in_constraint= 0 ; if ( s - > in_buffer_count ! = count || in_count ) continue ; } break ; } while ( 1 ) ; s - > resample_in_constraint= ! ! out_count ; return ret_sum ; }",0
"int ff_mjpeg_decode_sof ( MJpegDecodeContext * s ) { int len , nb_components , i , width , height , pix_fmt_id ; s - > cur_scan = 0 ; s - > upscale_h = s - > upscale_v = 0 ; / * XXX : verify len field validity * / len = get_bits ( & s - > gb , 16 ) ; s - > bits = get_bits ( & s - > gb , 8 ) ; if ( s - > pegasus_rct ) s - > bits = 9 ; if ( s - > bits == 9 & & ! s - > pegasus_rct ) s - > rct = 1 ; // FIXME ugly if ( s - > bits ! = 8 & & ! s - > lossless ) { av_log ( s - > avctx , AV_LOG_ERROR , only 8 bits/component accepted\n ) ; return - 1 ; } if ( s - > lossless & & s - > avctx - > lowres ) { av_log ( s - > avctx , AV_LOG_ERROR , lowres is not possible with lossless jpeg\n ) ; return - 1 ; } height = get_bits ( & s - > gb , 16 ) ; width = get_bits ( & s - > gb , 16 ) ; // HACK for odd_height . mov if ( s - > interlaced & & s - > width == width & & s - > height == height + 1 ) height= s - > height ; av_log ( s - > avctx , AV_LOG_DEBUG , sof0 : picture : %dx%d\n , width , height ) ; if ( av_image_check_size ( width , height , 0 , s - > avctx ) ) return AVERROR_INVALIDDATA ; nb_components = get_bits ( & s - > gb , 8 ) ; if ( nb_components < = 0 || nb_components > MAX_COMPONENTS ) return - 1 ; if ( s - > interlaced & & ( s - > bottom_field == ! s - > interlace_polarity ) ) { if ( nb_components ! = s - > nb_components ) { av_log ( s - > avctx , AV_LOG_ERROR , nb_components changing in interlaced picture\n ) ; return AVERROR_INVALIDDATA ; } } if ( s - > ls & & ! ( s - > bits < = 8 || nb_components == 1 ) ) { av_log_missing_feature ( s - > avctx , For JPEG - LS anything except < = 8 bits/component or 16 - bit gray , 0 ) ; return AVERROR_PATCHWELCOME ; } s - > nb_components = nb_components ; s - > h_max = 1 ; s - > v_max = 1 ; memset ( s - > h_count , 0 , sizeof ( s - > h_count ) ) ; memset ( s - > v_count , 0 , sizeof ( s - > v_count ) ) ; for ( i = 0 ; i < nb_components ; i + + ) { / * component id * / s - > component_id[i] = get_bits ( & s - > gb , 8 ) - 1 ; s - > h_count[i] = get_bits ( & s - > gb , 4 ) ; s - > v_count[i] = get_bits ( & s - > gb , 4 ) ; / * compute hmax and vmax ( only used in interleaved case ) * / if ( s - > h_count[i] > s - > h_max ) s - > h_max = s - > h_count[i] ; if ( s - > v_count[i] > s - > v_max ) s - > v_max = s - > v_count[i] ; if ( ! s - > h_count[i] || ! s - > v_count[i] ) { av_log ( s - > avctx , AV_LOG_ERROR , h/v_count is 0\n ) ; return - 1 ; } s - > quant_index[i] = get_bits ( & s - > gb , 8 ) ; if ( s - > quant_index[i] > = 4 ) return AVERROR_INVALIDDATA ; av_log ( s - > avctx , AV_LOG_DEBUG , component %d %d : %d id : %d quant : %d\n , i , s - > h_count[i] , s - > v_count[i] , s - > component_id[i] , s - > quant_index[i] ) ; } if ( s - > ls & & ( s - > h_max > 1 || s - > v_max > 1 ) ) { av_log_missing_feature ( s - > avctx , Subsampling in JPEG - LS , 0 ) ; return AVERROR_PATCHWELCOME ; } if ( s - > v_max == 1 & & s - > h_max == 1 & & s - > lossless==1 & & nb_components==3 ) s - > rgb = 1 ; / * if different size , realloc/alloc picture * / / * XXX : also check h_count and v_count * / if ( width ! = s - > width || height ! = s - > height ) { av_freep ( & s - > qscale_table ) ; s - > width = width ; s - > height = height ; s - > interlaced = 0 ; / * test interlaced mode * / if ( s - > first_picture & & s - > org_height ! = 0 & & s - > height < ( ( s - > org_height * 3 ) / 4 ) ) { s - > interlaced = 1 ; s - > bottom_field = s - > interlace_polarity ; s - > picture_ptr - > interlaced_frame = 1 ; s - > picture_ptr - > top_field_first = ! s - > interlace_polarity ; height * = 2 ; } avcodec_set_dimensions ( s - > avctx , width , height ) ; s - > qscale_table = av_mallocz ( ( s - > width + 15 ) / 16 ) ; s - > first_picture = 0 ; } if ( s - > interlaced & & ( s - > bottom_field == ! s - > interlace_polarity ) ) { if ( s - > progressive ) { av_log_ask_for_sample ( s - > avctx , progressively coded interlaced pictures not supported\n ) ; return AVERROR_INVALIDDATA ; } } else { / * XXX : not complete test ! * / pix_fmt_id = ( s - > h_count[0] < < 28 ) | ( s - > v_count[0] < < 24 ) | ( s - > h_count[1] < < 20 ) | ( s - > v_count[1] < < 16 ) | ( s - > h_count[2] < < 12 ) | ( s - > v_count[2] < < 8 ) | ( s - > h_count[3] < < 4 ) | s - > v_count[3] ; av_log ( s - > avctx , AV_LOG_DEBUG , pix fmt id %x\n , pix_fmt_id ) ; / * NOTE we do not allocate pictures large enough for the possible * padding of h/v_count being 4 * / if ( ! ( pix_fmt_id & 0xD0D0D0D0 ) ) pix_fmt_id - = ( pix_fmt_id & 0xF0F0F0F0",0
"static int mov_read_stts ( MOVContext * c , ByteIOContext * pb , MOVAtom atom ) { AVStream * st = c - > fc - > streams[c - > fc - > nb_streams - 1] ; MOVStreamContext * sc = st - > priv_data ; unsigned int i , entries ; int64_t duration=0 ; int64_t total_sample_count=0 ; get_byte ( pb ) ; / * version * / get_be24 ( pb ) ; / * flags * / entries = get_be32 ( pb ) ; dprintf ( c - > fc , track[%i] . stts . entries = %i\n , c - > fc - > nb_streams - 1 , entries ) ; if ( entries > = UINT_MAX / sizeof ( * sc - > stts_data ) ) return - 1 ; sc - > stts_data = av_malloc ( entries * sizeof ( * sc - > stts_data ) ) ; if ( ! sc - > stts_data ) return AVERROR ( ENOMEM ) ; sc - > stts_count = entries ; for ( i=0 ; i < entries ; i + + ) { int sample_duration ; int sample_count ; sample_count=get_be32 ( pb ) ; sample_duration = get_be32 ( pb ) ; sc - > stts_data[i] . count= sample_count ; sc - > stts_data[i] . duration= sample_duration ; dprintf ( c - > fc , sample_count=%d , sample_duration=%d\n , sample_count , sample_duration ) ; duration + = ( int64_t ) sample_duration * sample_count ; total_sample_count + =sample_count ; } st - > nb_frames= total_sample_count ; if ( duration ) st - > duration= duration ; return 0 ; }",0
"static int decode_i_picture_secondary_header ( VC9Context * v ) { int status ; if HAS_ADVANCED_PROFILE if ( v - > profile > PROFILE_MAIN ) { v - > s . ac_pred = get_bits ( & v - > s . gb , 1 ) ; if ( v - > postprocflag ) v - > postproc = get_bits ( & v - > s . gb , 1 ) ; / * 7 . 1 . 1 . 34 + 8 . 5 . 2 * / if ( v - > overlap & & v - > pq < 9 ) { v - > condover = get_bits ( & v - > s . gb , 1 ) ; if ( v - > condover ) { v - > condover = 2 + get_bits ( & v - > s . gb , 1 ) ; if ( v - > condover == 3 ) { status = bitplane_decoding ( & v - > over_flags_plane , v ) ; if ( status < 0 ) return - 1 ; if TRACE av_log ( v - > s . avctx , AV_LOG_DEBUG , Overflags plane encoding : Imode : %i , Invert : %i\n , status > > 1 , status & 1 ) ; endif } } } } endif / * Epilog ( AC/DC syntax ) should be done in caller * / return 0 ; }",1
"static AVStream * get_subtitle_pkt ( AVFormatContext * s , AVStream * next_st , AVPacket * pkt ) { AVIStream * ast , * next_ast = next_st - > priv_data ; int64_t ts , next_ts , ts_min = INT64_MAX ; AVStream * st , * sub_st = NULL ; int i ; next_ts = av_rescale_q ( next_ast - > frame_offset , next_st - > time_base , AV_TIME_BASE_Q ) ; for ( i=0 ; i < s - > nb_streams ; i + + ) { st = s - > streams[i] ; ast = st - > priv_data ; if ( st - > discard < AVDISCARD_ALL & & ast - > sub_pkt . data ) { ts = av_rescale_q ( ast - > sub_pkt . dts , st - > time_base , AV_TIME_BASE_Q ) ; if ( ts < = next_ts & & ts < ts_min ) { ts_min = ts ; sub_st = st ; } } } if ( sub_st ) { ast = sub_st - > priv_data ; * pkt = ast - > sub_pkt ; pkt - > stream_index = sub_st - > index ; if ( av_read_packet ( ast - > sub_ctx , & ast - > sub_pkt ) < 0 ) ast - > sub_pkt . data = NULL ; } return sub_st ; }",1
"void dsputil_init_mmx ( DSPContext * c , AVCodecContext * avctx ) { mm_flags = mm_support ( ) ; if ( avctx - > dsp_mask ) { if ( avctx - > dsp_mask & FF_MM_FORCE ) mm_flags |= ( avctx - > dsp_mask & 0xffff ) ; else mm_flags & = ( avctx - > dsp_mask & 0xffff ) ; } if 0 av_log ( avctx , AV_LOG_INFO , libavcodec : CPU flags : ) ; if ( mm_flags & MM_MMX ) av_log ( avctx , AV_LOG_INFO , mmx ) ; if ( mm_flags & MM_MMXEXT ) av_log ( avctx , AV_LOG_INFO , mmxext ) ; if ( mm_flags & MM_3DNOW ) av_log ( avctx , AV_LOG_INFO , 3dnow ) ; if ( mm_flags & MM_SSE ) av_log ( avctx , AV_LOG_INFO , sse ) ; if ( mm_flags & MM_SSE2 ) av_log ( avctx , AV_LOG_INFO , sse2 ) ; av_log ( avctx , AV_LOG_INFO , \n ) ; endif if ( mm_flags & MM_MMX ) { const int idct_algo= avctx - > idct_algo ; if ( avctx - > lowres==0 ) { if ( idct_algo==FF_IDCT_AUTO || idct_algo==FF_IDCT_SIMPLEMMX ) { c - > idct_put= ff_simple_idct_put_mmx ; c - > idct_add= ff_simple_idct_add_mmx ; c - > idct = ff_simple_idct_mmx ; c - > idct_permutation_type= FF_SIMPLE_IDCT_PERM ; ifdef CONFIG_GPL } else if ( idct_algo==FF_IDCT_LIBMPEG2MMX ) { if ( mm_flags & MM_MMXEXT ) { c - > idct_put= ff_libmpeg2mmx2_idct_put ; c - > idct_add= ff_libmpeg2mmx2_idct_add ; c - > idct = ff_mmxext_idct ; } else { c - > idct_put= ff_libmpeg2mmx_idct_put ; c - > idct_add= ff_libmpeg2mmx_idct_add ; c - > idct = ff_mmx_idct ; } c - > idct_permutation_type= FF_LIBMPEG2_IDCT_PERM ; endif } else if ( ( ENABLE_VP3_DECODER || ENABLE_VP5_DECODER || ENABLE_VP6_DECODER || ENABLE_THEORA_DECODER ) & & idct_algo==FF_IDCT_VP3 ) { if ( mm_flags & MM_SSE2 ) { c - > idct_put= ff_vp3_idct_put_sse2 ; c - > idct_add= ff_vp3_idct_add_sse2 ; c - > idct = ff_vp3_idct_sse2 ; c - > idct_permutation_type= FF_TRANSPOSE_IDCT_PERM ; } else { c - > idct_put= ff_vp3_idct_put_mmx ; c - > idct_add= ff_vp3_idct_add_mmx ; c - > idct = ff_vp3_idct_mmx ; c - > idct_permutation_type= FF_PARTTRANS_IDCT_PERM ; } } else if ( idct_algo==FF_IDCT_CAVS ) { c - > idct_permutation_type= FF_TRANSPOSE_IDCT_PERM ; } else if ( idct_algo==FF_IDCT_XVIDMMX ) { if ( mm_flags & MM_SSE2 ) { c - > idct_put= ff_idct_xvid_sse2_put ; c - > idct_add= ff_idct_xvid_sse2_add ; c - > idct = ff_idct_xvid_sse2 ; c - > idct_permutation_type= FF_SSE2_IDCT_PERM ; } else if ( mm_flags & MM_MMXEXT ) { c - > idct_put= ff_idct_xvid_mmx2_put ; c - > idct_add= ff_idct_xvid_mmx2_add ; c - > idct = ff_idct_xvid_mmx2 ; } else { c - > idct_put= ff_idct_xvid_mmx_put ; c - > idct_add= ff_idct_xvid_mmx_add ; c - > idct = ff_idct_xvid_mmx ; } } } c - > put_pixels_clamped = put_pixels_clamped_mmx ; c - > put_signed_pixels_clamped = put_signed_pixels_clamped_mmx ; c - > add_pixels_clamped = add_pixels_clamped_mmx ; c - > clear_blocks = clear_blocks_mmx ; define SET_HPEL_FUNCS ( PFX , IDX , SIZE , CPU ) \ c - > PFX _pixels_tab[IDX][0] = PFX _pixels SIZE _ CPU ; \ c - > PFX _pixels_tab[IDX][1] = PFX _pixels SIZE _x2_ CPU ; \ c - > PFX _pixels_tab[IDX][2] = PFX _pixels SIZE _y2_ CPU ; \ c - > PFX _pixels_tab[IDX][3] = PFX _pixels SIZE _xy2_ CPU SET_HPEL_FUNCS ( put , 0 , 16 , mmx ) ; SET_HPEL_FUNCS ( put_no_rnd , 0 , 16 , mmx ) ; SET_HPEL_FUNCS ( avg , 0 , 16 , mmx ) ; SET_HPEL_FUNCS ( avg_no_rnd , 0 , 16 , mmx ) ; SET_HPEL_FUNCS ( put , 1 , 8 , mmx ) ; SET_HPEL_FUNCS ( put_no_rnd , 1 , 8 , mmx ) ; SET_HPEL_FUNCS ( avg , 1 , 8 , mmx ) ; SET_HPEL_FUNCS ( avg_no_rnd , 1 , 8 , mmx ) ; c - > gmc= gmc_mmx ; c - > add_bytes= add_bytes_mmx ; c - > add_bytes_l2= add_bytes_l2_mmx ; c - > draw_edges = draw_edges_mmx ; if ( ENABLE_ANY_H263 ) { c - > h263_v_loop_filter= h263_v_loop_filter_mmx ; c - > h263_h_loop_filter= h263_h_loop_filter_mmx ; } if ( ( ENABLE_VP3_DECODER || ENABLE_THEORA_DECODER ) & & ! ( avctx - > flags & CODEC_FLAG_BITEXACT ) ) { c - > vp3_v_loop_filter= ff_vp3_v_loop_filter_mmx ; c - > vp3_h_loop_filter= ff_vp3_h_loop_filter_mmx ; } c - > put_h264_chroma_pixels_tab[0]= put_h264_chroma_mc8_mmx_rnd ; c - > put_h264_chroma_pixels_tab[1]= put_h264_chroma_mc4_mmx ; c - > put_no_rnd_h264_chroma_pixels_tab[0]= put_h264_chroma_mc8_mmx_nornd ; c - > h264_idct_dc_add= c - > h264_idct_add= ff_h264_idct_add_mmx ; c - > h264_idct8_dc_add= c - > h264_idct8_add= ff_h264_idct8_add_mmx ; if ( mm_flags & MM_SSE2 ) c - > h264_idct8_add= ff_h264_idct8_add_sse2 ; if ( mm_flags & MM_MMXEXT ) { c - > prefetch = prefetch_mmx2 ; c - > put_pixels_tab[0][1] = put_pixels16_x2_mmx2 ; c - > put_pixels_tab[0][2] = put_pixels16_y2_mmx2 ; c - > avg_pixels_tab[0][0] = avg_pixels16_mmx2 ; c - > avg_pixels_tab[0][1] = avg_pixels16_x2_mmx2 ; c - > avg_pixels_tab[0][2] = avg_pixels16_y2_mmx2 ; c - > put_pixels_tab[1][1] = put_pixels8_x2_mmx2 ; c - > put_pixels_tab[1][2] = put_pixels8_y2_mmx2 ; c - > avg_pixels_tab[1][0] = avg_pixels8_mmx2 ; c - > avg_pixels_tab[1][1] = avg_pixels8_x2_mmx2 ; c - > avg_pixels_tab[1][2] = avg_pixels8_y2_mmx2 ; c - > h264_idct_dc_add= ff_h264_idct_dc_add_mmx2 ; c - > h264_idct8_dc_add= ff_h264_idct8_dc_add_mmx2 ; if ( ! ( avctx - > flags & CODEC_FLAG_BITEXACT ) ) { c - > put_no_rnd_pixels_tab[0][1] = put_no_rnd_pixels16_x2_mmx2 ; c - > put_no_rnd_pixels_tab[0][2] = put_no_rnd_pixels16_y2_mmx2 ; c - > put_no_rnd_pixels_tab[1][1] = put_no_rnd_pixels8_x2_mmx2 ; c - > put_no_rnd_pixels_tab[1][2] = put_no_rnd_pixels8_y2_mmx2 ; c - > avg_pixels_tab[0][3] = avg_pixels16_xy2_mmx2 ; c - > avg_pixels_tab[1][3] = avg_pixels8_xy2_mmx2 ; } define SET_QPEL_FUNCS ( PFX , IDX , SIZE , CPU ) \ c - > PFX _pixels_tab[IDX][ 0] = PFX SIZE _mc00_ CPU ; \ c - > PFX _pixels_tab[IDX][ 1] = PFX SIZE _mc10_ CPU ; \ c - > PFX _pixels_tab[IDX][ 2] = PFX SIZE _mc20_ CPU ; \ c - > PFX _pixels_tab[IDX][ 3] = PFX SIZE _mc30_ CPU ; \ c - > PFX _pixels_tab[IDX][ 4] = PFX SIZE _mc01_ CPU ; \ c - > PFX _pixels_tab[IDX][ 5] = PFX SIZE _mc11_ CPU ; \ c - > PFX _pixels_tab[IDX][ 6] = PFX SIZE _mc21_ CPU ; \ c - > PFX _pixels_tab[IDX][ 7] = PFX SIZE _mc31_ CPU ; \ c - > PFX _pixels_tab[IDX][ 8] = PFX SIZE _mc02_ CPU ; \ c - > PFX _pixels_tab[IDX][ 9] = PFX SIZE _mc12_ CPU ; \ c - > PFX _pixels_tab[IDX][10] = PFX SIZE _mc22_ CPU ; \ c - > PFX _pixels_tab[IDX][11] = PFX SIZE _mc32_ CPU ; \ c - > PFX _pixels_tab[IDX][12] = PFX SIZE _mc03_ CPU ; \ c - > PFX _pixels_tab[IDX][13] = PFX SIZE _mc13_ CPU ; \ c - > PFX _pixels_tab[IDX][14] = PFX SIZE _mc23_ CPU ; \ c - > PFX _pixels_tab[IDX][15] = PFX SIZE _mc33_ CPU SET_QPEL_FUNCS ( put_qpel , 0 , 16 , mmx2 ) ; SET_QPEL_FUNCS ( put_qpel , 1 , 8 , mmx2 ) ; SET_QPEL_FUNCS ( put_no_rnd_qpel , 0 , 16 , mmx2 ) ; SET_QPEL_FUNCS ( put_no_rnd_qpel , 1 , 8 , mmx2 ) ; SET_QPEL_FUNCS ( avg_qpel , 0 , 16 , mmx2 ) ; SET_QPEL_FUNCS ( avg_qpel , 1 , 8 , mmx2 ) ; SET_QPEL_FUNCS (",0
"static inline void RENAME ( rgb15ToY ) ( uint8_t * dst , uint8_t * src , int width ) { int i ; for ( i=0 ; i < width ; i + + ) { int d= ( ( uint16_t * ) src ) [i] ; int r= d & 0x1F ; int g= ( d > > 5 ) & 0x1F ; int b= ( d > > 10 ) & 0x1F ; dst[i]= ( ( RY * r + GY * g + BY * b ) > > ( RGB2YUV_SHIFT - 3 ) ) + 16 ; } }",1
"static void render_line ( int x0 , uint8_t y0 , int x1 , int y1 , float * buf ) { int dy = y1 - y0 ; int adx = x1 - x0 ; int ady = FFABS ( dy ) ; int sy = dy < 0 ? - 1 : 1 ; buf[x0] = ff_vorbis_floor1_inverse_db_table[y0] ; if ( ady * 2 < = adx ) { // optimized common case render_line_unrolled ( x0 , y0 , x1 , sy , ady , adx , buf ) ; } else { int base = dy / adx ; int x = x0 ; uint8_t y = y0 ; int err = - adx ; ady - = FFABS ( base ) * adx ; while ( + + x < x1 ) { y + = base ; err + = ady ; if ( err > = 0 ) { err - = adx ; y + = sy ; } buf[x] = ff_vorbis_floor1_inverse_db_table[y] ; } } }",1
"static void RENAME ( uyvytoyuv420 ) ( uint8_t * ydst , uint8_t * udst , uint8_t * vdst , const uint8_t * src , long width , long height , long lumStride , long chromStride , long srcStride ) { long y ; const long chromWidth= - ( ( - width ) > > 1 ) ; for ( y=0 ; y < height ; y + + ) { RENAME ( extract_even ) ( src + 1 , ydst , width ) ; if ( y & 1 ) { RENAME ( extract_even2avg ) ( src - srcStride , src , udst , vdst , chromWidth ) ; udst + = chromStride ; vdst + = chromStride ; } src + = srcStride ; ydst + = lumStride ; } if COMPILE_TEMPLATE_MMX __asm__ ( EMMS \n\t SFENCE \n\t : : : memory ) ; endif }",0
"static int bayer_to_yv12_wrapper ( SwsContext * c , const uint8_t * src[] , int srcStride[] , int srcSliceY , int srcSliceH , uint8_t * dst[] , int dstStride[] ) { const uint8_t * srcPtr= src[0] ; uint8_t * dstY= dst[0] ; uint8_t * dstU= dst[1] ; uint8_t * dstV= dst[2] ; int i ; void ( * copy ) ( const uint8_t * src , int src_stride , uint8_t * dstY , uint8_t * dstU , uint8_t * dstV , int luma_stride , int width , int32_t * rgb2yuv ) ; void ( * interpolate ) ( const uint8_t * src , int src_stride , uint8_t * dstY , uint8_t * dstU , uint8_t * dstV , int luma_stride , int width , int32_t * rgb2yuv ) ; switch ( c - > srcFormat ) { define CASE ( pixfmt , prefix ) \ case pixfmt : copy = bayer_ prefix _to_yv12_copy ; \ interpolate = bayer_ prefix _to_yv12_interpolate ; \ break ; CASE ( AV_PIX_FMT_BAYER_BGGR8 , bggr8 ) CASE ( AV_PIX_FMT_BAYER_BGGR16LE , bggr16le ) CASE ( AV_PIX_FMT_BAYER_BGGR16BE , bggr16be ) CASE ( AV_PIX_FMT_BAYER_RGGB8 , rggb8 ) CASE ( AV_PIX_FMT_BAYER_RGGB16LE , rggb16le ) CASE ( AV_PIX_FMT_BAYER_RGGB16BE , rggb16be ) CASE ( AV_PIX_FMT_BAYER_GBRG8 , gbrg8 ) CASE ( AV_PIX_FMT_BAYER_GBRG16LE , gbrg16le ) CASE ( AV_PIX_FMT_BAYER_GBRG16BE , gbrg16be ) CASE ( AV_PIX_FMT_BAYER_GRBG8 , grbg8 ) CASE ( AV_PIX_FMT_BAYER_GRBG16LE , grbg16le ) CASE ( AV_PIX_FMT_BAYER_GRBG16BE , grbg16be ) undef CASE default : return 0 ; } copy ( srcPtr , srcStride[0] , dstY , dstU , dstV , dstStride[0] , c - > srcW , c - > input_rgb2yuv_table ) ; srcPtr + = 2 * srcStride[0] ; dstY + = 2 * dstStride[0] ; dstU + = dstStride[1] ; dstV + = dstStride[1] ; for ( i = 2 ; i < srcSliceH - 2 ; i + = 2 ) { interpolate ( srcPtr , srcStride[0] , dstY , dstU , dstV , dstStride[0] , c - > srcW , c - > input_rgb2yuv_table ) ; srcPtr + = 2 * srcStride[0] ; dstY + = 2 * dstStride[0] ; dstU + = dstStride[1] ; dstV + = dstStride[1] ; } copy ( srcPtr , srcStride[0] , dstY , dstU , dstV , dstStride[0] , c - > srcW , c - > input_rgb2yuv_table ) ; return srcSliceH ; }",0
"static int msrle_decode_8_16_24_32 ( AVCodecContext * avctx , AVPicture * pic , int depth , GetByteContext * gb ) { uint8_t * output , * output_end ; int p1 , p2 , line=avctx - > height - 1 , pos=0 , i ; uint16_t pix16 ; uint32_t pix32 ; unsigned int width= FFABS ( pic - > linesize[0] ) / ( depth > > 3 ) ; output = pic - > data[0] + ( avctx - > height - 1 ) * pic - > linesize[0] ; output_end = pic - > data[0] + avctx - > height * pic - > linesize[0] ; while ( bytestream2_get_bytes_left ( gb ) > 0 ) { p1 = bytestream2_get_byteu ( gb ) ; if ( p1 == 0 ) { //Escape code p2 = bytestream2_get_byte ( gb ) ; if ( p2 == 0 ) { //End - of - line if ( - - line < 0 ) { if ( bytestream2_get_be16 ( gb ) == 1 ) { // end - of - picture return 0 ; } else { av_log ( avctx , AV_LOG_ERROR , Next line is beyond picture bounds ( %d bytes left ) \n , bytestream2_get_bytes_left ( gb ) ) ; return AVERROR_INVALIDDATA ; } } output = pic - > data[0] + line * pic - > linesize[0] ; pos = 0 ; continue ; } else if ( p2 == 1 ) { //End - of - picture return 0 ; } else if ( p2 == 2 ) { //Skip p1 = bytestream2_get_byte ( gb ) ; p2 = bytestream2_get_byte ( gb ) ; line - = p2 ; pos + = p1 ; if ( line < 0 || pos > = width ) { av_log ( avctx , AV_LOG_ERROR , Skip beyond picture bounds\n ) ; return - 1 ; } output = pic - > data[0] + line * pic - > linesize[0] + pos * ( depth > > 3 ) ; continue ; } // Copy data if ( ( pic - > linesize[0] > 0 & & output + p2 * ( depth > > 3 ) > output_end ) || ( pic - > linesize[0] < 0 & & output + p2 * ( depth > > 3 ) < output_end ) ) { bytestream2_skip ( gb , 2 * ( depth > > 3 ) ) ; continue ; } else if ( bytestream2_get_bytes_left ( gb ) < p2 * ( depth > > 3 ) ) { av_log ( avctx , AV_LOG_ERROR , bytestream overrun\n ) ; return AVERROR_INVALIDDATA ; } if ( ( depth == 8 ) || ( depth == 24 ) ) { for ( i = 0 ; i < p2 * ( depth > > 3 ) ; i + + ) { * output + + = bytestream2_get_byteu ( gb ) ; } // RLE8 copy is actually padded - and runs are not ! if ( depth == 8 & & ( p2 & 1 ) ) { bytestream2_skip ( gb , 1 ) ; } } else if ( depth == 16 ) { for ( i = 0 ; i < p2 ; i + + ) { * ( uint16_t * ) output = bytestream2_get_le16u ( gb ) ; output + = 2 ; } } else if ( depth == 32 ) { for ( i = 0 ; i < p2 ; i + + ) { * ( uint32_t * ) output = bytestream2_get_le32u ( gb ) ; output + = 4 ; } } pos + = p2 ; } else { //run of pixels uint8_t pix[3] ; //original pixel if ( ( pic - > linesize[0] > 0 & & output + p1 * ( depth > > 3 ) > output_end ) || ( pic - > linesize[0] < 0 & & output + p1 * ( depth > > 3 ) < output_end ) ) continue ; switch ( depth ) { case 8 : pix[0] = bytestream2_get_byte ( gb ) ; for ( i = 0 ; i < p1 ; i + + ) * output + + = pix[0] ; break ; case 16 : pix16 = bytestream2_get_le16 ( gb ) ; for ( i = 0 ; i < p1 ; i + + ) { * ( uint16_t * ) output = pix16 ; output + = 2 ; } break ; case 24 : pix[0] = bytestream2_get_byte ( gb ) ; pix[1] = bytestream2_get_byte ( gb ) ; pix[2] = bytestream2_get_byte ( gb ) ; for ( i = 0 ; i < p1 ; i + + ) { * output + + = pix[0] ; * output + + = pix[1] ; * output + + = pix[2] ; } break ; case 32 : pix32 = bytestream2_get_le32 ( gb ) ; for ( i = 0 ; i < p1 ; i + + ) { * ( uint32_t * ) output = pix32 ; output + = 4 ; } break ; } pos + = p1 ; } } av_log ( avctx , AV_LOG_WARNING , MS RLE warning : no end - of - picture code\n ) ; return 0 ; }",0
"static int vaapi_encode_h264_init_picture_params ( AVCodecContext * avctx , VAAPIEncodePicture * pic ) { VAAPIEncodeContext * ctx = avctx - > priv_data ; VAEncSequenceParameterBufferH264 * vseq = ctx - > codec_sequence_params ; VAEncPictureParameterBufferH264 * vpic = pic - > codec_picture_params ; VAAPIEncodeH264Context * priv = ctx - > priv_data ; int i ; if ( pic - > type == PICTURE_TYPE_IDR ) { av_assert0 ( pic - > display_order == pic - > encode_order ) ; vpic - > frame_num = 0 ; priv - > next_frame_num = 1 ; priv - > cpb_delay = 0 ; } else { vpic - > frame_num = priv - > next_frame_num ; if ( pic - > type ! = PICTURE_TYPE_B ) { // nal_ref_idc ! = 0 + + priv - > next_frame_num ; } + + priv - > cpb_delay ; } priv - > dpb_delay = pic - > display_order - pic - > encode_order + 1 ; vpic - > frame_num = vpic - > frame_num & ( ( 1 < < ( 4 + vseq - > seq_fields . bits . log2_max_frame_num_minus4 ) ) - 1 ) ; vpic - > CurrPic . picture_id = pic - > recon_surface ; vpic - > CurrPic . frame_idx = vpic - > frame_num ; vpic - > CurrPic . flags = 0 ; vpic - > CurrPic . TopFieldOrderCnt = pic - > display_order ; vpic - > CurrPic . BottomFieldOrderCnt = pic - > display_order ; for ( i = 0 ; i < pic - > nb_refs ; i + + ) { VAAPIEncodePicture * ref = pic - > refs[i] ; av_assert0 ( ref & & ref - > encode_order < pic - > encode_order ) ; vpic - > ReferenceFrames[i] . picture_id = ref - > recon_surface ; vpic - > ReferenceFrames[i] . frame_idx = ref - > encode_order ; vpic - > ReferenceFrames[i] . flags = VA_PICTURE_H264_SHORT_TERM_REFERENCE ; vpic - > ReferenceFrames[i] . TopFieldOrderCnt = ref - > display_order ; vpic - > ReferenceFrames[i] . BottomFieldOrderCnt = ref - > display_order ; } for ( ; i < FF_ARRAY_ELEMS ( vpic - > ReferenceFrames ) ; i + + ) { vpic - > ReferenceFrames[i] . picture_id = VA_INVALID_ID ; vpic - > ReferenceFrames[i] . flags = VA_PICTURE_H264_INVALID ; } vpic - > coded_buf = pic - > output_buffer ; vpic - > pic_fields . bits . idr_pic_flag = ( pic - > type == PICTURE_TYPE_IDR ) ; vpic - > pic_fields . bits . reference_pic_flag = ( pic - > type ! = PICTURE_TYPE_B ) ; pic - > nb_slices = 1 ; return 0 ; }",0
"static BufferPoolEntry * get_pool ( AVBufferPool * pool ) { BufferPoolEntry * cur = NULL , * last = NULL ; do { FFSWAP ( BufferPoolEntry * , cur , last ) ; cur = avpriv_atomic_ptr_cas ( ( void * volatile * ) & pool - > pool , last , NULL ) ; if ( ! cur ) return NULL ; } while ( cur ! = last ) ; return cur ; }",1
"static void switch_buffer ( MPADecodeContext * s , int * pos , int * end_pos , int * end_pos2 ) { if ( s - > in_gb . buffer & & * pos > = s - > gb . size_in_bits ) { s - > gb = s - > in_gb ; s - > in_gb . buffer = NULL ; assert ( ( get_bits_count ( & s - > gb ) & 7 ) == 0 ) ; skip_bits_long ( & s - > gb , * pos - * end_pos ) ; * end_pos2 = * end_pos = * end_pos2 + get_bits_count ( & s - > gb ) - * pos ; * pos = get_bits_count ( & s - > gb ) ; } }",1
static int libquvi_close ( AVFormatContext * s ) { LibQuviContext * qc = s - > priv_data ; if ( qc - > fmtctx ) avformat_close_input ( & qc - > fmtctx ) ; return 0 ; },1
"static int prepare_sdp_description ( FFStream * stream , uint8_t * * pbuffer , struct in_addr my_ip ) { AVFormatContext * avc ; AVStream avs[MAX_STREAMS] ; int i ; avc = avformat_alloc_context ( ) ; if ( avc == NULL ) { return - 1 ; } av_metadata_set2 ( & avc - > metadata , title , stream - > title[0] ? stream - > title : No Title , 0 ) ; avc - > nb_streams = stream - > nb_streams ; if ( stream - > is_multicast ) { snprintf ( avc - > filename , 1024 , rtp : //%s : %d ? multicast=1 ? ttl=%d , inet_ntoa ( stream - > multicast_ip ) , stream - > multicast_port , stream - > multicast_ttl ) ; } else { snprintf ( avc - > filename , 1024 , rtp : //0 . 0 . 0 . 0 ) ; } for ( i = 0 ; i < stream - > nb_streams ; i + + ) { avc - > streams[i] = & avs[i] ; avc - > streams[i] - > codec = stream - > streams[i] - > codec ; } * pbuffer = av_mallocz ( 2048 ) ; avf_sdp_create ( & avc , 1 , * pbuffer , 2048 ) ; av_free ( avc ) ; return strlen ( * pbuffer ) ; }",1
"static void RENAME ( SwScale_YV12slice ) ( unsigned char * srcptr[] , int stride[] , int srcSliceY , int srcSliceH , uint8_t * dstptr[] , int dststride , int dstbpp , int srcW , int srcH , int dstW , int dstH ) { unsigned int lumXInc= ( srcW < < 16 ) / dstW ; unsigned int lumYInc= ( srcH < < 16 ) / dstH ; unsigned int chrXInc ; unsigned int chrYInc ; static int dstY ; // used to detect a size change static int oldDstW= - 1 ; static int oldSrcW= - 1 ; static int oldDstH= - 1 ; static int oldSrcH= - 1 ; static int oldFlags= - 1 ; static int lastInLumBuf ; static int lastInChrBuf ; int chrDstW , chrDstH ; static int lumBufIndex=0 ; static int chrBufIndex=0 ; static int firstTime=1 ; int widthAlign= dstbpp==12 ? 16 : 8 ; if ( ( ( dstW + widthAlign - 1 ) & ( ( widthAlign - 1 ) ) ) > dststride ) { dstW & = ( widthAlign - 1 ) ; if ( firstTime ) fprintf ( stderr , SwScaler : Warning : dstStride is not a multiple of %d ! \n SwScaler : - > lowering width to compensate , new width=%d\n SwScaler : - > cannot do aligned memory acesses anymore\n , widthAlign , dstW ) ; } //printf ( %d %d %d %d\n , srcW , srcH , dstW , dstH ) ; //printf ( %d %d %d %d\n , lumXInc , lumYInc , srcSliceY , srcSliceH ) ; ifdef HAVE_MMX2 canMMX2BeUsed= ( lumXInc < = 0x10000 & & ( dstW & 31 ) ==0 & & ( srcW & 15 ) ==0 ) ? 1 : 0 ; if ( ! canMMX2BeUsed & & lumXInc < = 0x10000 & & ( srcW & 15 ) ==0 & & sws_flags==SWS_FAST_BILINEAR ) { if ( firstTime ) //FIXME only if verbose ? fprintf ( stderr , SwScaler : output Width is not a multiple of 32 - > no MMX2 scaler\n ) ; } endif if ( firstTime ) { if defined ( DITHER1XBPP ) & & defined ( HAVE_MMX ) char * dither= dithered ; else char * dither= ; endif if ( sws_flags==SWS_FAST_BILINEAR ) fprintf ( stderr , SwScaler : FAST_BILINEAR scaler ) ; else if ( sws_flags==SWS_BILINEAR ) fprintf ( stderr , SwScaler : BILINEAR scaler ) ; else if ( sws_flags==SWS_BICUBIC ) fprintf ( stderr , SwScaler : BICUBIC scaler ) ; else fprintf ( stderr , SwScaler : ehh flags invalid ? ! ) ; if ( dstbpp==15 ) fprintf ( stderr , with%s BGR15 output , dither ) ; else if ( dstbpp==16 ) fprintf ( stderr , with%s BGR16 output , dither ) ; else if ( dstbpp==24 ) fprintf ( stderr , with BGR24 output ) ; else if ( dstbpp==32 ) fprintf ( stderr , with BGR32 output ) ; else if ( dstbpp==12 ) fprintf ( stderr , with YV12 output ) ; else fprintf ( stderr , without output ) ; ifdef HAVE_MMX2 fprintf ( stderr , using MMX2\n ) ; elif defined ( HAVE_3DNOW ) fprintf ( stderr , using 3DNOW\n ) ; elif defined ( HAVE_MMX ) fprintf ( stderr , using MMX\n ) ; elif defined ( ARCH_X86 ) fprintf ( stderr , using X86 ASM2\n ) ; else fprintf ( stderr , using C\n ) ; endif } // match pixel 0 of the src to pixel 0 of dst and match pixel n - 2 of src to pixel n - 2 of dst // n - 2 is the last chrominance sample available // this is not perfect , but noone shuld notice the difference , the more correct variant // would be like the vertical one , but that would require some special code for the // first and last pixel if ( sws_flags==SWS_FAST_BILINEAR ) { if ( canMMX2BeUsed ) lumXInc + = 20 ; else lumXInc = ( ( srcW - 2 ) < < 16 ) / ( dstW - 2 ) - 20 ; } if ( fullUVIpol & & ! ( dstbpp==12 ) ) chrXInc= lumXInc > > 1 , chrDstW= dstW ; else chrXInc= lumXInc , chrDstW= dstW > > 1 ; if ( dstbpp==12 ) chrYInc= lumYInc , chrDstH= dstH > > 1 ; else chrYInc= lumYInc > > 1 , chrDstH= dstH ; // force calculation of the horizontal interpolation of the first line if ( srcSliceY ==0 ) { // printf ( dstW %d , srcw %d , mmx2 %d\n , dstW , srcW , canMMX2BeUsed ) ; lumBufIndex=0 ; chrBufIndex=0 ; dstY=0 ; //precalculate horizontal scaler filter coefficients if ( oldDstW ! =dstW || oldSrcW ! =srcW || oldFlags ! =sws_flags ) { ifdef HAVE_MMX const int filterAlign=4 ; else const int filterAlign=1 ; endif oldDstW= dstW ; oldSrcW= srcW ; oldFlags= sws_flags ; if ( sws_flags ! = SWS_FAST_BILINEAR ) { RENAME ( initFilter ) ( hLumFilter , hLumFilterPos , & hLumFilterSize , lumXInc , srcW , dstW , filterAlign , 1 < < 14 ) ; RENAME ( initFilter ) ( hChrFilter , hChrFilterPos , & hChrFilterSize , chrXInc , srcW > > 1 , chrDstW , filterAlign , 1 < < 14 ) ; } ifdef HAVE_MMX2 // cant downscale ! ! ! if ( canMMX2BeUsed & & sws_flags == SWS_FAST_BILINEAR ) { initMMX2HScaler ( dstW , lumXInc , funnyYCode ) ; initMMX2HScaler ( chrDstW , chrXInc , funnyUVCode ) ; } endif } // Init Horizontal stuff if ( oldDstH ! =dstH || oldSrcH ! =srcH || oldFlags ! =sws_flags ) { int i ; oldDstH= dstH ; oldSrcH= srcH ; oldFlags= sws_flags ; //FIXME swsflags conflict with x check // deallocate pixbufs for ( i=0 ; i < vLumBufSize ; i + + ) free ( lumPixBuf[i] ) ; for ( i=0 ; i < vChrBufSize ; i + + ) free ( chrPixBuf[i] ) ; RENAME ( initFilter ) ( vLumFilter , vLumFilterPos , & vLumFilterSize , lumYInc , srcH , dstH , 1 , ( 1 < < 12 ) - 4 ) ; RENAME ( initFilter ) ( vChrFilter , vChrFilterPos , & vChrFilterSize , chrYInc , srcH > > 1 , chrDstH , 1 , ( 1 < < 12 ) - 4 ) ; // Calculate Buffer Sizes so that they wont run out while handling these damn slices vLumBufSize= vLumFilterSize ; vChrBufSize= vChrFilterSize ; for ( i=0 ; i < dstH ; i + + ) { int chrI= i * chrDstH / dstH ; int nextSlice= MAX ( vLumFilterPos[i ] + vLumFilterSize - 1 , ( ( vChrFilterPos[chrI] + vChrFilterSize - 1 ) < < 1 ) ) ; nextSlice & = 1 ; // Slices start at even boundaries if ( vLumFilterPos[i ] + vLumBufSize < nextSlice ) vLumBufSize= nextSlice - vLumFilterPos[i ] ; if ( vChrFilterPos[chrI] + vChrBufSize < ( nextSlice > > 1 ) ) vChrBufSize= ( nextSlice > > 1 ) - vChrFilterPos[chrI] ; } // allocate pixbufs ( we use dynamic allocation because otherwise we would need to // allocate several megabytes to",1
"void ff_mpeg1_encode_picture_header ( MpegEncContext * s , int picture_number ) { AVFrameSideData * side_data ; mpeg1_encode_sequence_header ( s ) ; / * mpeg1 picture header * / put_header ( s , PICTURE_START_CODE ) ; / * temporal reference * / // RAL : s - > picture_number instead of s - > fake_picture_number put_bits ( & s - > pb , 10 , ( s - > picture_number - s - > gop_picture_number ) & 0x3ff ) ; put_bits ( & s - > pb , 3 , s - > pict_type ) ; s - > vbv_delay_ptr = s - > pb . buf + put_bits_count ( & s - > pb ) / 8 ; put_bits ( & s - > pb , 16 , 0xFFFF ) ; / * vbv_delay * / // RAL : Forward f_code also needed for B - frames if ( s - > pict_type == AV_PICTURE_TYPE_P || s - > pict_type == AV_PICTURE_TYPE_B ) { put_bits ( & s - > pb , 1 , 0 ) ; / * half pel coordinates * / if ( s - > codec_id == AV_CODEC_ID_MPEG1VIDEO ) put_bits ( & s - > pb , 3 , s - > f_code ) ; / * forward_f_code * / else put_bits ( & s - > pb , 3 , 7 ) ; / * forward_f_code * / } // RAL : Backward f_code necessary for B - frames if ( s - > pict_type == AV_PICTURE_TYPE_B ) { put_bits ( & s - > pb , 1 , 0 ) ; / * half pel coordinates * / if ( s - > codec_id == AV_CODEC_ID_MPEG1VIDEO ) put_bits ( & s - > pb , 3 , s - > b_code ) ; / * backward_f_code * / else put_bits ( & s - > pb , 3 , 7 ) ; / * backward_f_code * / } put_bits ( & s - > pb , 1 , 0 ) ; / * extra bit picture * / s - > frame_pred_frame_dct = 1 ; if ( s - > codec_id == AV_CODEC_ID_MPEG2VIDEO ) { put_header ( s , EXT_START_CODE ) ; put_bits ( & s - > pb , 4 , 8 ) ; / * pic ext * / if ( s - > pict_type == AV_PICTURE_TYPE_P || s - > pict_type == AV_PICTURE_TYPE_B ) { put_bits ( & s - > pb , 4 , s - > f_code ) ; put_bits ( & s - > pb , 4 , s - > f_code ) ; } else { put_bits ( & s - > pb , 8 , 255 ) ; } if ( s - > pict_type == AV_PICTURE_TYPE_B ) { put_bits ( & s - > pb , 4 , s - > b_code ) ; put_bits ( & s - > pb , 4 , s - > b_code ) ; } else { put_bits ( & s - > pb , 8 , 255 ) ; } put_bits ( & s - > pb , 2 , s - > intra_dc_precision ) ; assert ( s - > picture_structure == PICT_FRAME ) ; put_bits ( & s - > pb , 2 , s - > picture_structure ) ; if ( s - > progressive_sequence ) put_bits ( & s - > pb , 1 , 0 ) ; / * no repeat * / else put_bits ( & s - > pb , 1 , s - > current_picture_ptr - > f . top_field_first ) ; / * XXX : optimize the generation of this flag with entropy measures * / s - > frame_pred_frame_dct = s - > progressive_sequence ; put_bits ( & s - > pb , 1 , s - > frame_pred_frame_dct ) ; put_bits ( & s - > pb , 1 , s - > concealment_motion_vectors ) ; put_bits ( & s - > pb , 1 , s - > q_scale_type ) ; put_bits ( & s - > pb , 1 , s - > intra_vlc_format ) ; put_bits ( & s - > pb , 1 , s - > alternate_scan ) ; put_bits ( & s - > pb , 1 , s - > repeat_first_field ) ; s - > progressive_frame = s - > progressive_sequence ; / * chroma_420_type * / put_bits ( & s - > pb , 1 , s - > chroma_format == CHROMA_420 ? s - > progressive_frame : 0 ) ; put_bits ( & s - > pb , 1 , s - > progressive_frame ) ; put_bits ( & s - > pb , 1 , 0 ) ; / * composite_display_flag * / } if ( s - > scan_offset ) { int i ; put_header ( s , USER_START_CODE ) ; for ( i = 0 ; i < sizeof ( svcd_scan_offset_placeholder ) ; i + + ) put_bits ( & s - > pb , 8 , svcd_scan_offset_placeholder[i] ) ; } side_data = av_frame_get_side_data ( & s - > current_picture_ptr - > f , AV_FRAME_DATA_STEREO3D ) ; if ( side_data ) { AVStereo3D * stereo = ( AVStereo3D * ) side_data - > data ; uint8_t fpa_type ; switch ( stereo - > type ) { case AV_STEREO3D_SIDEBYSIDE : fpa_type = 0x03 ; break ; case AV_STEREO3D_TOPBOTTOM : fpa_type = 0x04 ; break ; case AV_STEREO3D_2D : fpa_type = 0x08 ; break ; case AV_STEREO3D_SIDEBYSIDE_QUINCUNX : fpa_type = 0x23 ; break ; default : fpa_type = 0 ; break ; } if ( fpa_type ! = 0 ) { put_header ( s , USER_START_CODE ) ; put_bits ( & s - > pb , 8 , ' J ' ) ; // S3D_video_format_signaling_identifier put_bits ( & s - > pb , 8 , ' P ' ) ; put_bits ( & s - > pb , 8 , ' 3 ' ) ; put_bits ( & s - > pb , 8 , ' D ' ) ; put_bits ( & s - > pb , 8 , 0x03 ) ; // S3D_video_format_length put_bits ( & s - > pb , 1 , 1 ) ; // reserved_bit put_bits ( & s - > pb , 7 , fpa_type ) ; // S3D_video_format_type put_bits ( & s - > pb , 8 , 0x04 ) ; // reserved_data[0] put_bits ( & s - > pb , 8 , 0xFF ) ; // reserved_data[1] } } s - > mb_y = 0 ; ff_mpeg1_encode_slice_header ( s ) ; }",1
"static int dvdsub_decode ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { DVDSubContext * ctx = avctx - > priv_data ; const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; AVSubtitle * sub = data ; int is_menu ; if ( ctx - > buf ) { int ret = append_to_cached_buf ( avctx , buf , buf_size ) ; if ( ret < 0 ) { * data_size = 0 ; return ret ; } buf = ctx - > buf ; buf_size = ctx - > buf_size ; } is_menu = decode_dvd_subtitles ( ctx , sub , buf , buf_size ) ; if ( is_menu == AVERROR ( EAGAIN ) ) { * data_size = 0 ; return append_to_cached_buf ( avctx , buf , buf_size ) ; } if ( is_menu < 0 ) { no_subtitle : reset_rects ( sub ) ; * data_size = 0 ; return buf_size ; } if ( ! is_menu & & find_smallest_bounding_rectangle ( sub ) == 0 ) goto no_subtitle ; if ( ctx - > forced_subs_only & & ! ( sub - > rects[0] - > flags & AV_SUBTITLE_FLAG_FORCED ) ) goto no_subtitle ; if defined ( DEBUG ) { char ppm_name[32] ; snprintf ( ppm_name , sizeof ( ppm_name ) , /tmp/%05d . ppm , ctx - > sub_id + + ) ; av_dlog ( NULL , start=%d ms end =%d ms\n , sub - > start_display_time , sub - > end_display_time ) ; ppm_save ( ppm_name , sub - > rects[0] - > pict . data[0] , sub - > rects[0] - > w , sub - > rects[0] - > h , ( uint32_t * ) sub - > rects[0] - > pict . data[1] ) ; } endif av_freep ( & ctx - > buf ) ; ctx - > buf_size = 0 ; * data_size = 1 ; return buf_size ; }",1
"static int read_old_huffman_tables ( HYuvContext * s ) { if 1 GetBitContext gb ; int i ; init_get_bits ( & gb , classic_shift_luma , sizeof ( classic_shift_luma ) * 8 ) ; if ( read_len_table ( s - > len[0] , & gb ) < 0 ) return - 1 ; init_get_bits ( & gb , classic_shift_chroma , sizeof ( classic_shift_chroma ) * 8 ) ; if ( read_len_table ( s - > len[1] , & gb ) < 0 ) return - 1 ; for ( i=0 ; i < 256 ; i + + ) s - > bits[0][i] = classic_add_luma [i] ; for ( i=0 ; i < 256 ; i + + ) s - > bits[1][i] = classic_add_chroma[i] ; if ( s - > bitstream_bpp > = 24 ) { memcpy ( s - > bits[1] , s - > bits[0] , 256 * sizeof ( uint32_t ) ) ; memcpy ( s - > len[1] , s - > len [0] , 256 * sizeof ( uint8_t ) ) ; } memcpy ( s - > bits[2] , s - > bits[1] , 256 * sizeof ( uint32_t ) ) ; memcpy ( s - > len[2] , s - > len [1] , 256 * sizeof ( uint8_t ) ) ; for ( i=0 ; i < 3 ; i + + ) { ff_free_vlc ( & s - > vlc[i] ) ; init_vlc ( & s - > vlc[i] , VLC_BITS , 256 , s - > len[i] , 1 , 1 , s - > bits[i] , 4 , 4 , 0 ) ; } generate_joint_tables ( s ) ; return 0 ; else av_log ( s - > avctx , AV_LOG_DEBUG , v1 huffyuv is not supported \n ) ; return - 1 ; endif }",1
"static inline void RENAME ( hcscale_fast ) ( SwsContext * c , int16_t * dst1 , int16_t * dst2 , int dstWidth , const uint8_t * src1 , const uint8_t * src2 , int srcW , int xInc ) { int32_t * filterPos = c - > hChrFilterPos ; int16_t * filter = c - > hChrFilter ; void * mmx2FilterCode= c - > chrMmx2FilterCode ; int i ; if defined ( PIC ) DECLARE_ALIGNED ( 8 , uint64_t , ebxsave ) ; endif __asm__ volatile ( if defined ( PIC ) mov %% REG_b , %7 \n\t endif pxor %%mm7 , %%mm7 \n\t mov %0 , %% REG_c \n\t mov %1 , %% REG_D \n\t mov %2 , %% REG_d \n\t mov %3 , %% REG_b \n\t xor %% REG_a , %% REG_a \n\t // i PREFETCH ( %% REG_c ) \n\t PREFETCH 32 ( %% REG_c ) \n\t PREFETCH 64 ( %% REG_c ) \n\t CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE xor %% REG_a , %% REG_a \n\t // i mov %5 , %% REG_c \n\t // src mov %6 , %% REG_D \n\t // buf2 PREFETCH ( %% REG_c ) \n\t PREFETCH 32 ( %% REG_c ) \n\t PREFETCH 64 ( %% REG_c ) \n\t CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE if defined ( PIC ) mov %7 , %% REG_b \n\t endif : : m ( src1 ) , m ( dst1 ) , m ( filter ) , m ( filterPos ) , m ( mmx2FilterCode ) , m ( src2 ) , m ( dst2 ) if defined ( PIC ) , m ( ebxsave ) endif : % REG_a , % REG_c , % REG_d , % REG_S , % REG_D if ! defined ( PIC ) , % REG_b endif ) ; for ( i=dstWidth - 1 ; ( i * xInc ) > > 16 > =srcW - 1 ; i - - ) { dst1[i] = src1[srcW - 1] * 128 ; dst2[i] = src2[srcW - 1] * 128 ; } }",0
"void av_md5_update ( AVMD5 * ctx , const uint8_t * src , int len ) { const uint8_t * end ; int j ; j = ctx - > len & 63 ; ctx - > len + = len ; if ( j ) { int cnt = FFMIN ( len , 64 - j ) ; memcpy ( ctx - > block + j , src , cnt ) ; src + = cnt ; len - = cnt ; if ( j + cnt < 64 ) return ; body ( ctx - > ABCD , ( uint32_t * ) ctx - > block ) ; } end = src + ( len & 63 ) ; if ( HAVE_BIGENDIAN || ( ! HAVE_FAST_UNALIGNED & & ( ( intptr_t ) src & 3 ) ) ) { while ( src < end ) { memcpy ( ctx - > block , src , 64 ) ; body ( ctx - > ABCD , ( uint32_t * ) ctx - > block ) ; src + = 64 ; } } else { while ( src < end ) { body ( ctx - > ABCD , ( uint32_t * ) src ) ; src + = 64 ; } } len & = 63 ; if ( len > 0 ) memcpy ( ctx - > block , src , len ) ; }",0
"static int xan_decode_init ( AVCodecContext * avctx ) { XanContext * s = avctx - > priv_data ; int i ; s - > avctx = avctx ; if ( ( avctx - > codec - > id == CODEC_ID_XAN_WC3 ) & & ( s - > avctx - > palctrl == NULL ) ) { av_log ( avctx , AV_LOG_ERROR , WC3 Xan video : palette expected . \n ) ; return - 1 ; } avctx - > pix_fmt = PIX_FMT_PAL8 ; avctx - > has_b_frames = 0 ; dsputil_init ( & s - > dsp , avctx ) ; / * initialize the RGB - > YUV tables * / for ( i = 0 ; i < 256 ; i + + ) { y_r_table[i] = Y_R * i ; y_g_table[i] = Y_G * i ; y_b_table[i] = Y_B * i ; u_r_table[i] = U_R * i ; u_g_table[i] = U_G * i ; u_b_table[i] = U_B * i ; v_r_table[i] = V_R * i ; v_g_table[i] = V_G * i ; v_b_table[i] = V_B * i ; } if ( avcodec_check_dimensions ( avctx , avctx - > width , avctx - > height ) ) return - 1 ; s - > buffer1 = av_malloc ( avctx - > width * avctx - > height ) ; s - > buffer2 = av_malloc ( avctx - > width * avctx - > height ) ; if ( ! s - > buffer1 || ! s - > buffer2 ) return - 1 ; return 0 ; }",0
"static void restore_median_il ( uint8_t * src , int step , int stride , int width , int height , int slices , int rmode ) { int i , j , slice ; int A , B , C ; uint8_t * bsrc ; int slice_start , slice_height ; const int cmask = ( rmode ? 3 : 1 ) ; const int stride2 = stride < < 1 ; for ( slice = 0 ; slice < slices ; slice + + ) { slice_start = ( ( slice * height ) / slices ) & cmask ; slice_height = ( ( ( ( slice + 1 ) * height ) / slices ) & cmask ) - slice_start ; slice_height > > = 1 ; bsrc = src + slice_start * stride ; // first line - left neighbour prediction bsrc[0] + = 0x80 ; A = bsrc[0] ; for ( i = step ; i < width * step ; i + = step ) { bsrc[i] + = A ; A = bsrc[i] ; } for ( i = 0 ; i < width * step ; i + = step ) { bsrc[stride + i] + = A ; A = bsrc[stride + i] ; } bsrc + = stride2 ; if ( slice_height == 1 ) // second line - first element has top prediction , the rest uses median C = bsrc[ - stride2] ; bsrc[0] + = C ; A = bsrc[0] ; for ( i = step ; i < width * step ; i + = step ) { B = bsrc[i - stride2] ; bsrc[i] + = mid_pred ( A , B , ( uint8_t ) ( A + B - C ) ) ; C = B ; A = bsrc[i] ; } for ( i = 0 ; i < width * step ; i + = step ) { B = bsrc[i - stride] ; bsrc[stride + i] + = mid_pred ( A , B , ( uint8_t ) ( A + B - C ) ) ; C = B ; A = bsrc[stride + i] ; } bsrc + = stride2 ; // the rest of lines use continuous median prediction for ( j = 2 ; j < slice_height ; j + + ) { for ( i = 0 ; i < width * step ; i + = step ) { B = bsrc[i - stride2] ; bsrc[i] + = mid_pred ( A , B , ( uint8_t ) ( A + B - C ) ) ; C = B ; A = bsrc[i] ; } for ( i = 0 ; i < width * step ; i + = step ) { B = bsrc[i - stride] ; bsrc[i + stride] + = mid_pred ( A , B , ( uint8_t ) ( A + B - C ) ) ; C = B ; A = bsrc[i + stride] ; } bsrc + = stride2 ; } } }",1
"static void FUNCC ( pred8x8l_vertical_add ) ( uint8_t * _pix , const int16_t * _block , ptrdiff_t stride ) { int i ; pixel * pix = ( pixel * ) _pix ; const dctcoef * block = ( const dctcoef * ) _block ; stride > > = sizeof ( pixel ) - 1 ; pix - = stride ; for ( i=0 ; i < 8 ; i + + ) { pixel v = pix[0] ; pix[1 * stride]= v + = block[0] ; pix[2 * stride]= v + = block[8] ; pix[3 * stride]= v + = block[16] ; pix[4 * stride]= v + = block[24] ; pix[5 * stride]= v + = block[32] ; pix[6 * stride]= v + = block[40] ; pix[7 * stride]= v + = block[48] ; pix[8 * stride]= v + block[56] ; pix + + ; block + + ; } }",0
"static int svq1_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; MpegEncContext * s = avctx - > priv_data ; uint8_t * current , * previous ; int result , i , x , y , width , height ; AVFrame * pict = data ; svq1_pmv * pmv ; / * initialize bit buffer * / init_get_bits ( & s - > gb , buf , buf_size * 8 ) ; / * decode frame header * / s - > f_code = get_bits ( & s - > gb , 22 ) ; if ( ( s - > f_code & 0x70 ) || ! ( s - > f_code & 0x60 ) ) return AVERROR_INVALIDDATA ; / * swap some header bytes ( why ? ) * / if ( s - > f_code ! = 0x20 ) { uint32_t * src = ( uint32_t * ) ( buf + 4 ) ; if ( buf_size < 36 ) return AVERROR_INVALIDDATA ; for ( i = 0 ; i < 4 ; i + + ) src[i] = ( ( src[i] < < 16 ) | ( src[i] > > 16 ) ) src[7 - i] ; } result = svq1_decode_frame_header ( & s - > gb , s ) ; if ( result ! = 0 ) { av_dlog ( s - > avctx , Error in svq1_decode_frame_header %i\n , result ) ; return result ; } avcodec_set_dimensions ( avctx , s - > width , s - > height ) ; / * FIXME : This avoids some confusion for B frames without 2 references . * This should be removed after libavcodec can handle more flexible * picture types & ordering * / if ( s - > pict_type == AV_PICTURE_TYPE_B & & s - > last_picture_ptr == NULL ) return buf_size ; if ( ( avctx - > skip_frame > = AVDISCARD_NONREF & & s - > pict_type == AV_PICTURE_TYPE_B ) || ( avctx - > skip_frame > = AVDISCARD_NONKEY & & s - > pict_type ! = AV_PICTURE_TYPE_I ) || avctx - > skip_frame > = AVDISCARD_ALL ) return buf_size ; if ( ( result = ff_MPV_frame_start ( s , avctx ) ) < 0 ) return result ; pmv = av_malloc ( ( FFALIGN ( s - > width , 16 ) / 8 + 3 ) * sizeof ( * pmv ) ) ; if ( ! pmv ) return AVERROR ( ENOMEM ) ; / * decode y , u and v components * / for ( i = 0 ; i < 3 ; i + + ) { int linesize ; if ( i == 0 ) { width = FFALIGN ( s - > width , 16 ) ; height = FFALIGN ( s - > height , 16 ) ; linesize = s - > linesize ; } else { if ( s - > flags & CODEC_FLAG_GRAY ) break ; width = FFALIGN ( s - > width / 4 , 16 ) ; height = FFALIGN ( s - > height / 4 , 16 ) ; linesize = s - > uvlinesize ; } current = s - > current_picture . f . data[i] ; if ( s - > pict_type == AV_PICTURE_TYPE_B ) previous = s - > next_picture . f . data[i] ; else previous = s - > last_picture . f . data[i] ; if ( s - > pict_type == AV_PICTURE_TYPE_I ) { / * keyframe * / for ( y = 0 ; y < height ; y + = 16 ) { for ( x = 0 ; x < width ; x + = 16 ) { result = svq1_decode_block_intra ( & s - > gb , & current[x] , linesize ) ; if ( result ! = 0 ) { av_log ( s - > avctx , AV_LOG_INFO , Error in svq1_decode_block %i ( keyframe ) \n , result ) ; goto err ; } } current + = 16 * linesize ; } } else { / * delta frame * / memset ( pmv , 0 , ( ( width / 8 ) + 3 ) * sizeof ( svq1_pmv ) ) ; for ( y = 0 ; y < height ; y + = 16 ) { for ( x = 0 ; x < width ; x + = 16 ) { result = svq1_decode_delta_block ( s , & s - > gb , & current[x] , previous , linesize , pmv , x , y ) ; if ( result ! = 0 ) { av_dlog ( s - > avctx , Error in svq1_decode_delta_block %i\n , result ) ; goto err ; } } pmv[0] . x = pmv[0] . y = 0 ; current + = 16 * linesize ; } } } * pict = s - > current_picture . f ; ff_MPV_frame_end ( s ) ; * data_size = sizeof ( AVFrame ) ; result = buf_size ; err : av_free ( pmv ) ; return result ; }",0
"static int rm_read_header ( AVFormatContext * s , AVFormatParameters * ap ) { RMContext * rm = s - > priv_data ; AVStream * st ; ByteIOContext * pb = & s - > pb ; unsigned int tag , v ; int tag_size , size , codec_data_size , i ; int64_t codec_pos ; unsigned int h263_hack_version , start_time , duration ; char buf[128] ; int flags = 0 ; tag = get_le32 ( pb ) ; if ( tag == MKTAG ( ' . ' , ' r ' , ' a ' , 0xfd ) ) { / * very old . ra format * / return rm_read_header_old ( s , ap ) ; } else if ( tag ! = MKTAG ( ' . ' , ' R ' , ' M ' , ' F ' ) ) { return AVERROR_IO ; get_be32 ( pb ) ; / * header size * / get_be16 ( pb ) ; get_be32 ( pb ) ; get_be32 ( pb ) ; / * number of headers * / for ( ; ; ) { if ( url_feof ( pb ) ) goto fail ; tag = get_le32 ( pb ) ; tag_size = get_be32 ( pb ) ; get_be16 ( pb ) ; if 0 printf ( tag=%c%c%c%c ( %08x ) size=%d\n , ( tag ) & 0xff , ( tag > > 8 ) & 0xff , ( tag > > 16 ) & 0xff , ( tag > > 24 ) & 0xff , tag , tag_size ) ; endif if ( tag_size < 10 & & tag ! = MKTAG ( ' D ' , ' A ' , ' T ' , ' A ' ) ) goto fail ; switch ( tag ) { case MKTAG ( ' P ' , ' R ' , ' O ' , ' P ' ) : / * file header * / get_be32 ( pb ) ; / * max bit rate * / get_be32 ( pb ) ; / * avg bit rate * / get_be32 ( pb ) ; / * max packet size * / get_be32 ( pb ) ; / * avg packet size * / get_be32 ( pb ) ; / * nb packets * / get_be32 ( pb ) ; / * duration * / get_be32 ( pb ) ; / * preroll * / get_be32 ( pb ) ; / * index offset * / get_be32 ( pb ) ; / * data offset * / get_be16 ( pb ) ; / * nb streams * / flags = get_be16 ( pb ) ; / * flags * / break ; case MKTAG ( ' C ' , ' O ' , ' N ' , ' T ' ) : get_str ( pb , s - > title , sizeof ( s - > title ) ) ; get_str ( pb , s - > author , sizeof ( s - > author ) ) ; get_str ( pb , s - > copyright , sizeof ( s - > copyright ) ) ; get_str ( pb , s - > comment , sizeof ( s - > comment ) ) ; break ; case MKTAG ( ' M ' , ' D ' , ' P ' , ' R ' ) : st = av_new_stream ( s , 0 ) ; if ( ! st ) goto fail ; st - > id = get_be16 ( pb ) ; get_be32 ( pb ) ; / * max bit rate * / st - > codec - > bit_rate = get_be32 ( pb ) ; / * bit rate * / get_be32 ( pb ) ; / * max packet size * / get_be32 ( pb ) ; / * avg packet size * / start_time = get_be32 ( pb ) ; / * start time * / get_be32 ( pb ) ; / * preroll * / duration = get_be32 ( pb ) ; / * duration * / st - > start_time = start_time ; st - > duration = duration ; get_str8 ( pb , buf , sizeof ( buf ) ) ; / * desc * / get_str8 ( pb , buf , sizeof ( buf ) ) ; / * mimetype * / codec_data_size = get_be32 ( pb ) ; codec_pos = url_ftell ( pb ) ; st - > codec - > codec_type = CODEC_TYPE_DATA ; av_set_pts_info ( st , 64 , 1 , 1000 ) ; v = get_be32 ( pb ) ; if ( v == MKTAG ( 0xfd , ' a ' , ' r ' , ' . ' ) ) { / * ra type header * / rm_read_audio_stream_info ( s , st , 0 ) ; } else { int fps , fps2 ; if ( get_le32 ( pb ) ! = MKTAG ( ' V ' , ' I ' , ' D ' , ' O ' ) ) { fail1 : av_log ( st - > codec , AV_LOG_ERROR , Unsupported video codec\n ) ; goto skip ; st - > codec - > codec_tag = get_le32 ( pb ) ; // av_log ( NULL , AV_LOG_DEBUG , %X %X\n , st - > codec - > codec_tag , MKTAG ( ' R ' , ' V ' , ' 2 ' , ' 0 ' ) ) ; if ( st - > codec - > codec_tag ! = MKTAG ( ' R ' , ' V ' , ' 1 ' , ' 0 ' ) & & st - > codec - > codec_tag ! = MKTAG ( ' R ' , ' V ' , ' 2 ' , ' 0 ' ) & & st - > codec - > codec_tag ! = MKTAG ( ' R ' , ' V ' , ' 3 ' , ' 0 ' ) & & st - > codec - > codec_tag ! = MKTAG ( ' R ' , ' V ' , ' 4 ' , ' 0 ' ) ) goto fail1 ; st - > codec - > width = get_be16 ( pb ) ; st - > codec - > height = get_be16 ( pb ) ; st - > codec - > time_base . num= 1 ; fps= get_be16 ( pb ) ; st - > codec - > codec_type = CODEC_TYPE_VIDEO ; get_be32 ( pb ) ; fps2= get_be16 ( pb ) ; get_be16 ( pb ) ; st - > codec - > extradata_size= codec_data_size - ( url_ftell ( pb ) - codec_pos ) ; st - > codec - > extradata= av_mallocz ( st - > codec - > extradata_size + FF_INPUT_BUFFER_PADDING_SIZE ) ; get_buffer ( pb , st - > codec - > extradata , st - > codec - > extradata_size ) ; // av_log ( NULL , AV_LOG_DEBUG , fps= %d fps2= %d\n , fps , fps2 ) ; st - > codec - > time_base . den = fps * st - > codec - >",1
"int ff_vorbis_len2vlc ( uint8_t * bits , uint32_t * codes , unsigned num ) { uint32_t exit_at_level[33] = { 404 } ; unsigned i , j , p , code ; for ( p = 0 ; ( bits[p] == 0 ) & & ( p < num ) ; + + p ) ; if ( p == num ) return 0 ; codes[p] = 0 ; if ( bits[p] > 32 ) return AVERROR_INVALIDDATA ; for ( i = 0 ; i < bits[p] ; + + i ) exit_at_level[i + 1] = 1 < < i ; + + p ; for ( i = p ; ( bits[i] == 0 ) & & ( i < num ) ; + + i ) ; if ( i == num ) return 0 ; for ( ; p < num ; + + p ) { if ( bits[p] > 32 ) return AVERROR_INVALIDDATA ; if ( bits[p] == 0 ) continue ; // find corresponding exit ( node which the tree can grow further from ) for ( i = bits[p] ; i > 0 ; - - i ) if ( exit_at_level[i] ) break ; if ( ! i ) // overspecified tree return AVERROR_INVALIDDATA ; code = exit_at_level[i] ; exit_at_level[i] = 0 ; // construct code ( append 0s to end ) and introduce new exits for ( j = i + 1 ; j < = bits[p] ; + + j ) exit_at_level[j] = code + ( 1 < < ( j - 1 ) ) ; codes[p] = code ; } //no exits should be left ( underspecified tree - ie . unused valid vlcs - not allowed by SPEC ) for ( p = 1 ; p < 33 ; p + + ) if ( exit_at_level[p] ) return AVERROR_INVALIDDATA ; return 0 ; }",1
"static int vobsub_read_header ( AVFormatContext * s ) { int i , ret = 0 , header_parsed = 0 , langidx = 0 ; MpegDemuxContext * vobsub = s - > priv_data ; char * sub_name = NULL ; size_t fname_len ; char * ext , * header_str ; AVBPrint header ; int64_t delay = 0 ; AVStream * st = NULL ; sub_name = av_strdup ( s - > filename ) ; fname_len = strlen ( sub_name ) ; ext = sub_name - 3 + fname_len ; if ( fname_len < 4 || * ( ext - 1 ) ! = ' . ' ) { av_log ( s , AV_LOG_ERROR , The input index filename is too short to guess the associated . SUB file\n ) ; ret = AVERROR_INVALIDDATA ; goto end ; } memcpy ( ext , ! strncmp ( ext , IDX , 3 ) ? SUB : sub , 3 ) ; av_log ( s , AV_LOG_VERBOSE , IDX/SUB : %s - > %s\n , s - > filename , sub_name ) ; ret = avformat_open_input ( & vobsub - > sub_ctx , sub_name , & ff_mpegps_demuxer , NULL ) ; if ( ret < 0 ) { av_log ( s , AV_LOG_ERROR , Unable to open %s as MPEG subtitles\n , sub_name ) ; goto end ; } av_bprint_init ( & header , 0 , AV_BPRINT_SIZE_UNLIMITED ) ; while ( ! url_feof ( s - > pb ) ) { char line[2048] ; int len = ff_get_line ( s - > pb , line , sizeof ( line ) ) ; if ( ! len ) break ; line[strcspn ( line , \r\n ) ] = 0 ; if ( ! strncmp ( line , id : , 3 ) ) { int n , stream_id = 0 ; char id[64] = { 0 } ; n = sscanf ( line , id : %63[ , ] , index : %u , id , & stream_id ) ; if ( n ! = 2 ) { av_log ( s , AV_LOG_WARNING , Unable to parse index line ' %s ' , assuming ' id : und , index : 0 ' \n , line ) ; strcpy ( id , und ) ; stream_id = 0 ; } if ( stream_id > = FF_ARRAY_ELEMS ( vobsub - > q ) ) { av_log ( s , AV_LOG_ERROR , Maximum number of subtitles streams reached\n ) ; ret = AVERROR ( EINVAL ) ; goto end ; } st = avformat_new_stream ( s , NULL ) ; if ( ! st ) { ret = AVERROR ( ENOMEM ) ; goto end ; } st - > id = stream_id ; st - > codec - > codec_type = AVMEDIA_TYPE_SUBTITLE ; st - > codec - > codec_id = AV_CODEC_ID_DVD_SUBTITLE ; avpriv_set_pts_info ( st , 64 , 1 , 1000 ) ; av_dict_set ( & st - > metadata , language , id , 0 ) ; av_log ( s , AV_LOG_DEBUG , IDX stream[%d] id=%s\n , stream_id , id ) ; header_parsed = 1 ; } else if ( st & & ! strncmp ( line , timestamp : , 10 ) ) { AVPacket * sub ; int hh , mm , ss , ms ; int64_t pos , timestamp ; const char * p = line + 10 ; if ( ! s - > nb_streams ) { av_log ( s , AV_LOG_ERROR , Timestamp declared before any stream\n ) ; ret = AVERROR_INVALIDDATA ; goto end ; } if ( sscanf ( p , %02d : %02d : %02d : %03d , filepos : % SCNx64 , & hh , & mm , & ss , & ms , & pos ) ! = 5 ) { av_log ( s , AV_LOG_ERROR , Unable to parse timestamp line ' %s ' , abort parsing\n , line ) ; break ; } timestamp = ( hh * 3600LL + mm * 60LL + ss ) * 1000LL + ms + delay ; timestamp = av_rescale_q ( timestamp , av_make_q ( 1 , 1000 ) , st - > time_base ) ; sub = ff_subtitles_queue_insert ( & vobsub - > q[s - > nb_streams - 1] , , 0 , 0 ) ; if ( ! sub ) { ret = AVERROR ( ENOMEM ) ; goto end ; } sub - > pos = pos ; sub - > pts = timestamp ; sub - > stream_index = s - > nb_streams - 1 ; } else if ( st & & ! strncmp ( line , alt : , 4 ) ) { const char * p = line + 4 ; while ( * p == ' ' ) p + + ; av_dict_set ( & st - > metadata , title , p , 0 ) ; av_log ( s , AV_LOG_DEBUG , IDX stream[%d] name=%s\n , st - > id , p ) ; header_parsed = 1 ; } else if ( ! strncmp ( line , delay : , 6 ) ) { int sign = 1 , hh = 0 , mm = 0 , ss = 0 , ms = 0 ; const char * p = line + 6 ; while ( * p == ' ' ) p + + ; if ( * p == ' - ' || * p == ' + ' ) { sign = * p == ' - ' ? - 1 : 1 ; p + + ; } sscanf ( p , %d : %d : %d : %d , & hh , & mm , & ss , & ms ) ; delay = ( ( hh * 3600LL + mm * 60LL + ss ) * 1000LL + ms ) * sign ; } else if ( ! strncmp ( line , langidx : , 8 ) ) { const char * p = line + 8 ; if ( sscanf ( p , %d , & langidx ) ! = 1 ) av_log ( s , AV_LOG_ERROR , Invalid langidx specified\n ) ; } else if ( ! header_parsed ) { if ( line[0] & & line[0] ! = ' ' ) av_bprintf ( & header , %s\n , line ) ; } } if ( langidx < s - > nb_streams ) s - > streams[langidx] - > disposition |= AV_DISPOSITION_DEFAULT ; for ( i = 0 ; i < s - > nb_streams ; i + + ) { vobsub - > q[i] . sort = SUB_SORT_POS_TS ; ff_subtitles_queue_finalize ( & vobsub - > q[i] ) ; } if ( ! av_bprint_is_complete ( & header ) ) { av_bprint_finalize ( & header , NULL ) ; ret = AVERROR ( ENOMEM ) ; goto end ; } av_bprint_finalize ( & header , & header_str ) ; for ( i = 0 ; i < s - > nb_streams ; i + + ) { AVStream * sub_st = s - > streams[i] ; sub_st - > codec - > extradata = av_strdup ( header_str ) ; sub_st -",1
"static void json_print_section_header ( WriterContext * wctx ) { JSONContext * json = wctx - > priv ; AVBPrint buf ; const struct section * section = wctx - > section[wctx - > level] ; const struct section * parent_section = wctx - > level ? wctx - > section[wctx - > level - 1] : NULL ; if ( wctx - > level & & wctx - > nb_item[wctx - > level - 1] ) printf ( , \n ) ; if ( section - > flags & SECTION_FLAG_IS_WRAPPER ) { printf ( { \n ) ; json - > indent_level + + ; } else { av_bprint_init ( & buf , 1 , AV_BPRINT_SIZE_UNLIMITED ) ; json_escape_str ( & buf , section - > name , wctx ) ; JSON_INDENT ( ) ; json - > indent_level + + ; if ( section - > flags & SECTION_FLAG_IS_ARRAY ) { printf ( \ %s\ : [\n , buf . str ) ; } else if ( ! ( parent_section - > flags & SECTION_FLAG_IS_ARRAY ) ) { printf ( \ %s\ : { %s , buf . str , json - > item_start_end ) ; } else { printf ( { %s , json - > item_start_end ) ; / * this is required so the parser can distinguish between packets and frames * / if ( parent_section - > id == SECTION_ID_PACKETS_AND_FRAMES ) { if ( ! json - > compact ) JSON_INDENT ( ) ; printf ( \ type\ : \ %s\ %s , section - > name , json - > item_sep ) ; } } av_bprint_finalize ( & buf , NULL ) ; } }",1
"static av_always_inline int mvd_decode ( HEVCContext * s ) { int ret = 2 ; int k = 1 ; while ( k < CABAC_MAX_BIN & & get_cabac_bypass ( & s - > HEVClc - > cc ) ) { ret + = 1 < < k ; k + + ; } if ( k == CABAC_MAX_BIN ) av_log ( s - > avctx , AV_LOG_ERROR , CABAC_MAX_BIN : %d\n , k ) ; while ( k - - ) ret + = get_cabac_bypass ( & s - > HEVClc - > cc ) < < k ; return get_cabac_bypass_sign ( & s - > HEVClc - > cc , - ret ) ; }",1
"av_cold int ff_vc1_decode_init_alloc_tables ( VC1Context * v ) { MpegEncContext * s = & v - > s ; int i ; int mb_height = FFALIGN ( s - > mb_height , 2 ) ; / * Allocate mb bitplanes * / v - > mv_type_mb_plane = av_malloc ( s - > mb_stride * mb_height ) ; v - > direct_mb_plane = av_malloc ( s - > mb_stride * mb_height ) ; v - > forward_mb_plane = av_malloc ( s - > mb_stride * mb_height ) ; v - > fieldtx_plane = av_mallocz ( s - > mb_stride * mb_height ) ; v - > acpred_plane = av_malloc ( s - > mb_stride * mb_height ) ; v - > over_flags_plane = av_malloc ( s - > mb_stride * mb_height ) ; v - > n_allocated_blks = s - > mb_width + 2 ; v - > block = av_malloc ( sizeof ( * v - > block ) * v - > n_allocated_blks ) ; v - > cbp_base = av_malloc ( sizeof ( v - > cbp_base[0] ) * 2 * s - > mb_stride ) ; v - > cbp = v - > cbp_base + s - > mb_stride ; v - > ttblk_base = av_malloc ( sizeof ( v - > ttblk_base[0] ) * 2 * s - > mb_stride ) ; v - > ttblk = v - > ttblk_base + s - > mb_stride ; v - > is_intra_base = av_mallocz ( sizeof ( v - > is_intra_base[0] ) * 2 * s - > mb_stride ) ; v - > is_intra = v - > is_intra_base + s - > mb_stride ; v - > luma_mv_base = av_malloc ( sizeof ( v - > luma_mv_base[0] ) * 2 * s - > mb_stride ) ; v - > luma_mv = v - > luma_mv_base + s - > mb_stride ; / * allocate block type info in that way so it could be used with s - > block_index[] * / v - > mb_type_base = av_malloc ( s - > b8_stride * ( mb_height * 2 + 1 ) + s - > mb_stride * ( mb_height + 1 ) * 2 ) ; v - > mb_type[0] = v - > mb_type_base + s - > b8_stride + 1 ; v - > mb_type[1] = v - > mb_type_base + s - > b8_stride * ( mb_height * 2 + 1 ) + s - > mb_stride + 1 ; v - > mb_type[2] = v - > mb_type[1] + s - > mb_stride * ( mb_height + 1 ) ; / * allocate memory to store block level MV info * / v - > blk_mv_type_base = av_mallocz ( s - > b8_stride * ( mb_height * 2 + 1 ) + s - > mb_stride * ( mb_height + 1 ) * 2 ) ; v - > blk_mv_type = v - > blk_mv_type_base + s - > b8_stride + 1 ; v - > mv_f_base = av_mallocz ( 2 * ( s - > b8_stride * ( mb_height * 2 + 1 ) + s - > mb_stride * ( mb_height + 1 ) * 2 ) ) ; v - > mv_f[0] = v - > mv_f_base + s - > b8_stride + 1 ; v - > mv_f[1] = v - > mv_f[0] + ( s - > b8_stride * ( mb_height * 2 + 1 ) + s - > mb_stride * ( mb_height + 1 ) * 2 ) ; v - > mv_f_next_base = av_mallocz ( 2 * ( s - > b8_stride * ( mb_height * 2 + 1 ) + s - > mb_stride * ( mb_height + 1 ) * 2 ) ) ; v - > mv_f_next[0] = v - > mv_f_next_base + s - > b8_stride + 1 ; v - > mv_f_next[1] = v - > mv_f_next[0] + ( s - > b8_stride * ( mb_height * 2 + 1 ) + s - > mb_stride * ( mb_height + 1 ) * 2 ) ; ff_intrax8_common_init ( & v - > x8 , s ) ; if ( s - > avctx - > codec_id == AV_CODEC_ID_WMV3IMAGE || s - > avctx - > codec_id == AV_CODEC_ID_VC1IMAGE ) { for ( i = 0 ; i < 4 ; i + + ) if ( ! ( v - > sr_rows[i > > 1][i & 1] = av_malloc ( v - > output_width ) ) ) return - 1 ; } if ( ! v - > mv_type_mb_plane || ! v - > direct_mb_plane || ! v - > acpred_plane || ! v - > over_flags_plane || ! v - > block || ! v - > cbp_base || ! v - > ttblk_base || ! v - > is_intra_base || ! v - > luma_mv_base || ! v - > mb_type_base ) { goto error ; } return 0 ; error : ff_vc1_decode_end ( s - > avctx ) ; return AVERROR ( ENOMEM ) ; }",1
"int ff_raw_read_partial_packet ( AVFormatContext * s , AVPacket * pkt ) { int ret , size ; size = RAW_PACKET_SIZE ; if ( av_new_packet ( pkt , size ) < 0 ) return AVERROR ( ENOMEM ) ; pkt - > pos= avio_tell ( s - > pb ) ; pkt - > stream_index = 0 ; ret = ffio_read_partial ( s - > pb , pkt - > data , size ) ; if ( ret < 0 ) { av_free_packet ( pkt ) ; return ret ; } pkt - > size = ret ; return ret ; }",1
"static inline struct rgbvec interp_tetrahedral ( const LUT3DContext * lut3d , const struct rgbvec * s ) { const struct rgbvec d = { s - > r - PREV ( s - > r ) , s - > g - PREV ( s - > g ) , s - > b - PREV ( s - > b ) } ; const struct rgbvec c000 = lut3d - > lut[PREV ( s - > r ) ][PREV ( s - > g ) ][PREV ( s - > b ) ] ; const struct rgbvec c001 = lut3d - > lut[PREV ( s - > r ) ][PREV ( s - > g ) ][NEXT ( s - > b ) ] ; const struct rgbvec c010 = lut3d - > lut[PREV ( s - > r ) ][NEXT ( s - > g ) ][PREV ( s - > b ) ] ; const struct rgbvec c011 = lut3d - > lut[PREV ( s - > r ) ][NEXT ( s - > g ) ][NEXT ( s - > b ) ] ; const struct rgbvec c100 = lut3d - > lut[NEXT ( s - > r ) ][PREV ( s - > g ) ][PREV ( s - > b ) ] ; const struct rgbvec c101 = lut3d - > lut[NEXT ( s - > r ) ][PREV ( s - > g ) ][NEXT ( s - > b ) ] ; const struct rgbvec c110 = lut3d - > lut[NEXT ( s - > r ) ][NEXT ( s - > g ) ][PREV ( s - > b ) ] ; const struct rgbvec c111 = lut3d - > lut[NEXT ( s - > r ) ][NEXT ( s - > g ) ][NEXT ( s - > b ) ] ; struct rgbvec c ; if ( d . r > d . g ) { if ( d . g > d . b ) { c . r = ( 1 - d . r ) * c000 . r + ( d . r - d . g ) * c100 . r + ( d . g - d . b ) * c110 . r + ( d . b ) * c111 . r ; c . g = ( 1 - d . r ) * c000 . g + ( d . r - d . g ) * c100 . g + ( d . g - d . b ) * c110 . g + ( d . b ) * c111 . g ; c . b = ( 1 - d . r ) * c000 . b + ( d . r - d . g ) * c100 . b + ( d . g - d . b ) * c110 . b + ( d . b ) * c111 . b ; } else if ( d . r > d . b ) { c . r = ( 1 - d . r ) * c000 . r + ( d . r - d . b ) * c100 . r + ( d . b - d . g ) * c101 . r + ( d . g ) * c111 . r ; c . g = ( 1 - d . r ) * c000 . g + ( d . r - d . b ) * c100 . g + ( d . b - d . g ) * c101 . g + ( d . g ) * c111 . g ; c . b = ( 1 - d . r ) * c000 . b + ( d . r - d . b ) * c100 . b + ( d . b - d . g ) * c101 . b + ( d . g ) * c111 . b ; } else { c . r = ( 1 - d . b ) * c000 . r + ( d . b - d . r ) * c001 . r + ( d . r - d . g ) * c101 . r + ( d . g ) * c111 . r ; c . g = ( 1 - d . b ) * c000 . g + ( d . b - d . r ) * c001 . g + ( d . r - d . g ) * c101 . g + ( d . g ) * c111 . g ; c . b = ( 1 - d . b ) * c000 . b + ( d . b - d . r ) * c001 . b + ( d . r - d . g ) * c101 . b + ( d . g ) * c111 . b ; } } else { if ( d . b > d . g ) { c . r = ( 1 - d . b ) * c000 . r + ( d . b - d . g ) * c001 . r + ( d . g - d . r ) * c011 . r + ( d . r ) * c111 . r ; c . g = ( 1 - d . b ) * c000 . g + ( d . b - d . g ) * c001 . g + ( d . g - d . r ) * c011 . g + ( d . r ) * c111 . g ; c . b = ( 1 - d . b ) * c000 . b + ( d . b - d . g ) * c001 . b + ( d . g - d . r ) * c011 . b + ( d . r ) * c111 . b ; } else if ( d . b > d . r ) { c . r = ( 1 - d . g ) * c000 . r + ( d . g - d . b ) * c010 . r + ( d . b - d . r ) * c011 . r + ( d . r ) * c111 . r ; c . g = ( 1 - d . g ) * c000 . g + ( d . g - d . b ) * c010 . g + ( d . b - d . r ) * c011 . g + ( d . r ) * c111 . g ; c . b = ( 1 - d . g ) * c000 . b + ( d . g - d . b ) * c010 . b + ( d . b - d . r ) * c011 . b + ( d . r ) * c111 . b ; } else { c . r = (",1
"static av_cold int nvenc_setup_device ( AVCodecContext * avctx ) { NvencContext * ctx = avctx - > priv_data ; NvencDynLoadFunctions * dl_fn = & ctx - > nvenc_dload_funcs ; CUresult cu_res ; CUcontext cu_context_curr ; switch ( avctx - > codec - > id ) { case AV_CODEC_ID_H264 : ctx - > init_encode_params . encodeGUID = NV_ENC_CODEC_H264_GUID ; break ; case AV_CODEC_ID_HEVC : ctx - > init_encode_params . encodeGUID = NV_ENC_CODEC_HEVC_GUID ; break ; default : return AVERROR_BUG ; } ctx - > data_pix_fmt = avctx - > pix_fmt ; if CONFIG_CUDA if ( avctx - > pix_fmt == AV_PIX_FMT_CUDA ) { AVHWFramesContext * frames_ctx ; AVCUDADeviceContext * device_hwctx ; if ( ! avctx - > hw_frames_ctx ) { av_log ( avctx , AV_LOG_ERROR , hw_frames_ctx must be set when using GPU frames as input\n ) ; return AVERROR ( EINVAL ) ; } frames_ctx = ( AVHWFramesContext * ) avctx - > hw_frames_ctx - > data ; device_hwctx = frames_ctx - > device_ctx - > hwctx ; ctx - > cu_context = device_hwctx - > cuda_ctx ; ctx - > data_pix_fmt = frames_ctx - > sw_format ; return 0 ; } endif if ( ctx - > gpu > = dl_fn - > nvenc_device_count ) { av_log ( avctx , AV_LOG_FATAL , Requested GPU %d , but only %d GPUs are available ! \n , ctx - > gpu , dl_fn - > nvenc_device_count ) ; return AVERROR ( EINVAL ) ; } ctx - > cu_context = NULL ; cu_res = dl_fn - > cu_ctx_create ( & ctx - > cu_context_internal , 4 , dl_fn - > nvenc_devices[ctx - > gpu] ) ; // CU_CTX_SCHED_BLOCKING_SYNC=4 , avoid CPU spins if ( cu_res ! = CUDA_SUCCESS ) { av_log ( avctx , AV_LOG_FATAL , Failed creating CUDA context for NVENC : 0x%x\n , ( int ) cu_res ) ; return AVERROR_EXTERNAL ; } cu_res = dl_fn - > cu_ctx_pop_current ( & cu_context_curr ) ; if ( cu_res ! = CUDA_SUCCESS ) { av_log ( avctx , AV_LOG_FATAL , Failed popping CUDA context : 0x%x\n , ( int ) cu_res ) ; return AVERROR_EXTERNAL ; } ctx - > cu_context = ctx - > cu_context_internal ; return 0 ; }",0
"static int read_channel_data ( ALSDecContext * ctx , ALSChannelData * cd , int c ) { GetBitContext * gb = & ctx - > gb ; ALSChannelData * current = cd ; unsigned int channels = ctx - > avctx - > channels ; int entries = 0 ; while ( entries < channels & & ! ( current - > stop_flag = get_bits1 ( gb ) ) ) { current - > master_channel = get_bits_long ( gb , av_ceil_log2 ( channels ) ) ; if ( current - > master_channel > = channels ) { av_log ( ctx - > avctx , AV_LOG_ERROR , Invalid master channel ! \n ) ; return - 1 ; } if ( current - > master_channel ! = c ) { current - > time_diff_flag = get_bits1 ( gb ) ; current - > weighting[0] = als_weighting ( gb , 1 , 16 ) ; current - > weighting[1] = als_weighting ( gb , 2 , 14 ) ; current - > weighting[2] = als_weighting ( gb , 1 , 16 ) ; if ( current - > time_diff_flag ) { current - > weighting[3] = als_weighting ( gb , 1 , 16 ) ; current - > weighting[4] = als_weighting ( gb , 1 , 16 ) ; current - > weighting[5] = als_weighting ( gb , 1 , 16 ) ; current - > time_diff_sign = get_bits1 ( gb ) ; current - > time_diff_index = get_bits ( gb , ctx - > ltp_lag_length - 3 ) + 3 ; } } current + + ; entries + + ; } if ( entries == channels ) { av_log ( ctx - > avctx , AV_LOG_ERROR , Damaged channel data ! \n ) ; return - 1 ; } align_get_bits ( gb ) ; return 0 ; }",1
static int rv34_decoder_alloc ( RV34DecContext * r ) { r - > intra_types_stride = r - > s . mb_width * 4 + 4 ; r - > cbp_chroma = av_malloc ( r - > s . mb_stride * r - > s . mb_height * sizeof ( * r - > cbp_chroma ) ) ; r - > cbp_luma = av_malloc ( r - > s . mb_stride * r - > s . mb_height * sizeof ( * r - > cbp_luma ) ) ; r - > deblock_coefs = av_malloc ( r - > s . mb_stride * r - > s . mb_height * sizeof ( * r - > deblock_coefs ) ) ; r - > intra_types_hist = av_malloc ( r - > intra_types_stride * 4 * 2 * sizeof ( * r - > intra_types_hist ) ) ; r - > mb_type = av_mallocz ( r - > s . mb_stride * r - > s . mb_height * sizeof ( * r - > mb_type ) ) ; if ( ! ( r - > cbp_chroma & & r - > cbp_luma & & r - > deblock_coefs & & r - > intra_types_hist & & r - > mb_type ) ) { rv34_decoder_free ( r ) ; return AVERROR ( ENOMEM ) ; } r - > intra_types = r - > intra_types_hist + r - > intra_types_stride * 4 ; return 0 ; },1
"static int dvbsub_parse ( AVCodecParserContext * s , AVCodecContext * avctx , const uint8_t * * poutbuf , int * poutbuf_size , const uint8_t * buf , int buf_size ) { DVBSubParseContext * pc = s - > priv_data ; uint8_t * p , * p_end ; int i , len , buf_pos = 0 ; av_dlog ( avctx , DVB parse packet pts=% PRIx64 , lpts=% PRIx64 , cpts=% PRIx64 : \n , s - > pts , s - > last_pts , s - > cur_frame_pts[s - > cur_frame_start_index] ) ; for ( i=0 ; i < buf_size ; i + + ) { av_dlog ( avctx , %02x , buf[i] ) ; if ( i % 16 == 15 ) av_dlog ( avctx , \n ) ; } if ( i % 16 ! = 0 ) av_dlog ( avctx , \n ) ; * poutbuf = NULL ; * poutbuf_size = 0 ; s - > fetch_timestamp = 1 ; if ( s - > last_pts ! = s - > pts & & s - > pts ! = AV_NOPTS_VALUE ) / * Start of a new packet * / { if ( pc - > packet_index ! = pc - > packet_start ) { av_dlog ( avctx , Discarding %d bytes\n , pc - > packet_index - pc - > packet_start ) ; } pc - > packet_start = 0 ; pc - > packet_index = 0 ; if ( buf_size < 2 || buf[0] ! = 0x20 || buf[1] ! = 0x00 ) { av_dlog ( avctx , Bad packet header\n ) ; return - 1 ; } buf_pos = 2 ; pc - > in_packet = 1 ; } else { if ( pc - > packet_start ! = 0 ) { if ( pc - > packet_index ! = pc - > packet_start ) { memmove ( pc - > packet_buf , pc - > packet_buf + pc - > packet_start , pc - > packet_index - pc - > packet_start ) ; pc - > packet_index - = pc - > packet_start ; pc - > packet_start = 0 ; } else { pc - > packet_start = 0 ; pc - > packet_index = 0 ; } } } if ( buf_size - buf_pos + pc - > packet_index > PARSE_BUF_SIZE ) return - 1 ; / * if not currently in a packet , discard data * / if ( pc - > in_packet == 0 ) return buf_size ; memcpy ( pc - > packet_buf + pc - > packet_index , buf + buf_pos , buf_size - buf_pos ) ; pc - > packet_index + = buf_size - buf_pos ; p = pc - > packet_buf ; p_end = pc - > packet_buf + pc - > packet_index ; while ( p < p_end ) { if ( * p == 0x0f ) { if ( p + 6 < = p_end ) { len = AV_RB16 ( p + 4 ) ; if ( p + len + 6 < = p_end ) { * poutbuf_size + = len + 6 ; p + = len + 6 ; } else break ; } else break ; } else if ( * p == 0xff ) { if ( p + 1 < p_end ) { av_dlog ( avctx , Junk at end of packet\n ) ; } pc - > packet_index = p - pc - > packet_buf ; pc - > in_packet = 0 ; break ; } else { av_log ( avctx , AV_LOG_ERROR , Junk in packet\n ) ; pc - > packet_index = p - pc - > packet_buf ; pc - > in_packet = 0 ; break ; } } if ( * poutbuf_size > 0 ) { * poutbuf = pc - > packet_buf ; pc - > packet_start = * poutbuf_size ; } if ( s - > pts == AV_NOPTS_VALUE ) s - > pts = s - > last_pts ; return buf_size ; }",1
"static void id3v2_parse ( AVFormatContext * s , int len , uint8_t version , uint8_t flags , ID3v2ExtraMeta * * extra_meta ) { int isv34 , unsync ; unsigned tlen ; char tag[5] ; int64_t next , end = avio_tell ( s - > pb ) + len ; int taghdrlen ; const char * reason = NULL ; AVIOContext pb ; AVIOContext * pbx ; unsigned char * buffer = NULL ; int buffer_size = 0 ; const ID3v2EMFunc * extra_func = NULL ; unsigned char * uncompressed_buffer = NULL ; int uncompressed_buffer_size = 0 ; av_log ( s , AV_LOG_DEBUG , id3v2 ver : %d flags : %02X len : %d\n , version , flags , len ) ; switch ( version ) { case 2 : if ( flags & 0x40 ) { reason = compression ; goto error ; } isv34 = 0 ; taghdrlen = 6 ; break ; case 3 : case 4 : isv34 = 1 ; taghdrlen = 10 ; break ; default : reason = version ; goto error ; } unsync = flags & 0x80 ; if ( isv34 & & flags & 0x40 ) { / * Extended header present , just skip over it * / int extlen = get_size ( s - > pb , 4 ) ; if ( version == 4 ) / * In v2 . 4 the length includes the length field we just read . * / extlen - = 4 ; if ( extlen < 0 ) { reason = invalid extended header length ; goto error ; } avio_skip ( s - > pb , extlen ) ; len - = extlen + 4 ; if ( len < 0 ) { reason = extended header too long . ; goto error ; } } while ( len > = taghdrlen ) { unsigned int tflags = 0 ; int tunsync = 0 ; int tcomp = 0 ; int tencr = 0 ; unsigned long dlen ; if ( isv34 ) { avio_read ( s - > pb , tag , 4 ) ; tag[4] = 0 ; if ( version == 3 ) { tlen = avio_rb32 ( s - > pb ) ; } else tlen = get_size ( s - > pb , 4 ) ; tflags = avio_rb16 ( s - > pb ) ; tunsync = tflags & ID3v2_FLAG_UNSYNCH ; } else { avio_read ( s - > pb , tag , 3 ) ; tag[3] = 0 ; tlen = avio_rb24 ( s - > pb ) ; } if ( tlen > ( 1 < < 28 ) ) break ; len - = taghdrlen + tlen ; if ( len < 0 ) break ; next = avio_tell ( s - > pb ) + tlen ; if ( ! tlen ) { if ( tag[0] ) av_log ( s , AV_LOG_DEBUG , Invalid empty frame %s , skipping . \n , tag ) ; continue ; } if ( tflags & ID3v2_FLAG_DATALEN ) { if ( tlen < 4 ) break ; dlen = avio_rb32 ( s - > pb ) ; tlen - = 4 ; } else dlen = tlen ; tcomp = tflags & ID3v2_FLAG_COMPRESSION ; tencr = tflags & ID3v2_FLAG_ENCRYPTION ; / * skip encrypted tags and , if no zlib , compressed tags * / if ( tencr || ( ! CONFIG_ZLIB & & tcomp ) ) { const char * type ; if ( ! tcomp ) type = encrypted ; else if ( ! tencr ) type = compressed ; else type = encrypted and compressed ; av_log ( s , AV_LOG_WARNING , Skipping %s ID3v2 frame %s . \n , type , tag ) ; avio_skip ( s - > pb , tlen ) ; / * check for text tag or supported special meta tag * / } else if ( tag[0] == ' T ' || ( extra_meta & & ( extra_func = get_extra_meta_func ( tag , isv34 ) ) ) ) { pbx = s - > pb ; if ( unsync || tunsync || tcomp ) { av_fast_malloc ( & buffer , & buffer_size , tlen ) ; if ( ! buffer ) { av_log ( s , AV_LOG_ERROR , Failed to alloc %d bytes\n , tlen ) ; goto seek ; } } if ( unsync || tunsync ) { int64_t end = avio_tell ( s - > pb ) + tlen ; uint8_t * b ; b = buffer ; while ( avio_tell ( s - > pb ) < end & & b - buffer < tlen & & ! s - > pb - > eof_reached ) { * b + + = avio_r8 ( s - > pb ) ; if ( * ( b - 1 ) == 0xff & & avio_tell ( s - > pb ) < end - 1 & & b - buffer < tlen & & ! s - > pb - > eof_reached ) { uint8_t val = avio_r8 ( s - > pb ) ; * b + + = val ? val : avio_r8 ( s - > pb ) ; } } ffio_init_context ( & pb , buffer , b - buffer , 0 , NULL , NULL , NULL , NULL ) ; tlen = b - buffer ; pbx = & pb ; // read from sync buffer } if CONFIG_ZLIB if ( tcomp ) { int err ; av_log ( s , AV_LOG_DEBUG , Compresssed frame %s tlen=%d dlen=%ld\n , tag , tlen , dlen ) ; av_fast_malloc ( & uncompressed_buffer , & uncompressed_buffer_size , dlen ) ; if ( ! uncompressed_buffer ) { av_log ( s , AV_LOG_ERROR , Failed to alloc %ld bytes\n , dlen ) ; goto seek ; } if ( ! ( unsync || tunsync ) ) { err = avio_read ( s - > pb , buffer , tlen ) ; if ( err < 0 ) { av_log ( s , AV_LOG_ERROR , Failed to read compressed tag\n ) ; goto seek ; } tlen = err ; } err = uncompress ( uncompressed_buffer , & dlen , buffer , tlen ) ; if ( err ! = Z_OK ) { av_log ( s , AV_LOG_ERROR , Failed to uncompress tag : %d\n , err ) ; goto seek ; } ffio_init_context ( & pb , uncompressed_buffer , dlen , 0 , NULL , NULL , NULL , NULL ) ; tlen = dlen ; pbx = & pb ; // read from sync buffer } endif if ( tag[0] == ' T ' ) / * parse text tag * / read_ttag ( s , pbx , tlen , & s - > metadata , tag ) ; else / * parse special meta tag * / extra_func - > read ( s , pbx , tlen , tag , extra_meta ) ; } else if ( ! tag[0] ) { if ( tag[1] ) av_log ( s , AV_LOG_WARNING , invalid frame id , assuming padding\n ) ; avio_skip ( s",1
"static void decode_band_structure ( GetBitContext * gbc , int blk , int eac3 , int ecpl , int start_subband , int end_subband , const uint8_t * default_band_struct , uint8_t * band_struct , int * num_subbands , int * num_bands , uint8_t * band_sizes ) { int subbnd , bnd , n_subbands , n_bands ; uint8_t bnd_sz[22] ; n_subbands = end_subband - start_subband ; / * decode band structure from bitstream or use default * / if ( ! eac3 || get_bits1 ( gbc ) ) { for ( subbnd = 0 ; subbnd < n_subbands - 1 ; subbnd + + ) { band_struct[subbnd] = get_bits1 ( gbc ) ; } } else if ( ! blk ) { memcpy ( band_struct , & default_band_struct[start_subband + 1] , n_subbands - 1 ) ; } band_struct[n_subbands - 1] = 0 ; / * calculate number of bands and band sizes based on band structure . note that the first 4 subbands in enhanced coupling span only 6 bins instead of 12 . * / if ( num_bands || band_sizes ) { n_bands = n_subbands ; bnd_sz[0] = ecpl ? 6 : 12 ; for ( bnd = 0 , subbnd = 1 ; subbnd < n_subbands ; subbnd + + ) { int subbnd_size = ( ecpl & & subbnd < 4 ) ? 6 : 12 ; if ( band_struct[subbnd - 1] ) { n_bands - - ; bnd_sz[bnd] + = subbnd_size ; } else { bnd_sz[ + + bnd] = subbnd_size ; } } } / * set optional output params * / if ( num_subbands ) * num_subbands = n_subbands ; if ( num_bands ) * num_bands = n_bands ; if ( band_sizes ) memcpy ( band_sizes , bnd_sz , n_bands ) ; }",1
"int attribute_align_arg avcodec_encode_audio2 ( AVCodecContext * avctx , AVPacket * avpkt , const AVFrame * frame , int * got_packet_ptr ) { AVFrame tmp ; AVFrame * padded_frame = NULL ; int ret ; AVPacket user_pkt = * avpkt ; int needs_realloc = ! user_pkt . data ; * got_packet_ptr = 0 ; if ( ! ( avctx - > codec - > capabilities & CODEC_CAP_DELAY ) & & ! frame ) { av_free_packet ( avpkt ) ; av_init_packet ( avpkt ) ; return 0 ; } / * ensure that extended_data is properly set * / if ( frame & & ! frame - > extended_data ) { if ( av_sample_fmt_is_planar ( avctx - > sample_fmt ) & & avctx - > channels > AV_NUM_DATA_POINTERS ) { av_log ( avctx , AV_LOG_ERROR , Encoding to a planar sample format , with more than %d channels , but extended_data is not set . \n , AV_NUM_DATA_POINTERS ) ; return AVERROR ( EINVAL ) ; } av_log ( avctx , AV_LOG_WARNING , extended_data is not set . \n ) ; tmp = * frame ; tmp . extended_data = tmp . data ; frame = & tmp ; } / * check for valid frame size * / if ( frame ) { if ( avctx - > codec - > capabilities & CODEC_CAP_SMALL_LAST_FRAME ) { if ( frame - > nb_samples > avctx - > frame_size ) { av_log ( avctx , AV_LOG_ERROR , more samples than frame size ( avcodec_encode_audio2 ) \n ) ; return AVERROR ( EINVAL ) ; } } else if ( ! ( avctx - > codec - > capabilities & CODEC_CAP_VARIABLE_FRAME_SIZE ) ) { if ( frame - > nb_samples < avctx - > frame_size & & ! avctx - > internal - > last_audio_frame ) { ret = pad_last_frame ( avctx , & padded_frame , frame ) ; if ( ret < 0 ) return ret ; frame = padded_frame ; avctx - > internal - > last_audio_frame = 1 ; } if ( frame - > nb_samples ! = avctx - > frame_size ) { av_log ( avctx , AV_LOG_ERROR , nb_samples ( %d ) ! = frame_size ( %d ) ( avcodec_encode_audio2 ) \n , frame - > nb_samples , avctx - > frame_size ) ; ret = AVERROR ( EINVAL ) ; goto end ; } } } ret = avctx - > codec - > encode2 ( avctx , avpkt , frame , got_packet_ptr ) ; if ( ! ret ) { if ( * got_packet_ptr ) { if ( ! ( avctx - > codec - > capabilities & CODEC_CAP_DELAY ) ) { if ( avpkt - > pts == AV_NOPTS_VALUE ) avpkt - > pts = frame - > pts ; if ( ! avpkt - > duration ) avpkt - > duration = ff_samples_to_time_base ( avctx , frame - > nb_samples ) ; } avpkt - > dts = avpkt - > pts ; } else { avpkt - > size = 0 ; } } if ( avpkt - > data & & avpkt - > data == avctx - > internal - > byte_buffer ) { needs_realloc = 0 ; if ( user_pkt . data ) { if ( user_pkt . size > = avpkt - > size ) { memcpy ( user_pkt . data , avpkt - > data , avpkt - > size ) ; } else { av_log ( avctx , AV_LOG_ERROR , Provided packet is too small , needs to be %d\n , avpkt - > size ) ; avpkt - > size = user_pkt . size ; ret = - 1 ; } avpkt - > buf = user_pkt . buf ; avpkt - > data = user_pkt . data ; avpkt - > destruct = user_pkt . destruct ; } else { if ( av_dup_packet ( avpkt ) < 0 ) { ret = AVERROR ( ENOMEM ) ; } } } if ( ! ret ) { if ( needs_realloc & & avpkt - > data ) { ret = av_buffer_realloc ( & avpkt - > buf , avpkt - > size + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( ret > = 0 ) avpkt - > data = avpkt - > buf - > data ; } avctx - > frame_number + + ; } if ( ret < 0 || ! * got_packet_ptr ) { av_free_packet ( avpkt ) ; av_init_packet ( avpkt ) ; goto end ; } / * NOTE : if we add any audio encoders which output non - keyframe packets , * this needs to be moved to the encoders , but for now we can do it * here to simplify things * / avpkt - > flags |= AV_PKT_FLAG_KEY ; end : av_frame_free ( & padded_frame ) ; return ret ; }",0
"static int ftp_get_line ( FTPContext * s , char * line , int line_size ) { int ch ; char * q = line ; int ori_block_flag = s - > conn_control_block_flag ; for ( ; ; ) { ch = ftp_getc ( s ) ; if ( ch < 0 ) { s - > conn_control_block_flag = ori_block_flag ; return ch ; } if ( ch == ' \n ' ) { / * process line * / if ( q > line & & q[ - 1] == ' \r ' ) q - - ; * q = ' \0 ' ; s - > conn_control_block_flag = ori_block_flag ; return 0 ; } else { s - > conn_control_block_flag = 0 ; / * line need to be finished * / if ( ( q - line ) < line_size - 1 ) * q + + = ch ; } } }",0
"int avcodec_default_get_buffer ( AVCodecContext * s , AVFrame * pic ) { int i ; int w= s - > width ; int h= s - > height ; InternalBuffer * buf ; int * picture_number ; if ( pic - > data[0] ! =NULL ) { av_log ( s , AV_LOG_ERROR , pic - > data[0] ! =NULL in avcodec_default_get_buffer\n ) ; return - 1 ; } if ( s - > internal_buffer_count > = INTERNAL_BUFFER_SIZE ) { av_log ( s , AV_LOG_ERROR , internal_buffer_count overflow ( missing release_buffer ? ) \n ) ; return - 1 ; } if ( avcodec_check_dimensions ( s , w , h ) ) return - 1 ; if ( s - > internal_buffer==NULL ) { s - > internal_buffer= av_mallocz ( INTERNAL_BUFFER_SIZE * sizeof ( InternalBuffer ) ) ; } if 0 s - > internal_buffer= av_fast_realloc ( s - > internal_buffer , & s - > internal_buffer_size , sizeof ( InternalBuffer ) * FFMAX ( 99 , s - > internal_buffer_count + 1 ) / * FIXME * / ) ; endif buf= & ( ( InternalBuffer * ) s - > internal_buffer ) [s - > internal_buffer_count] ; picture_number= & ( ( ( InternalBuffer * ) s - > internal_buffer ) [INTERNAL_BUFFER_SIZE - 1] ) . last_pic_num ; //FIXME ugly hack ( * picture_number ) + + ; if ( buf - > base[0] ) { pic - > age= * picture_number - buf - > last_pic_num ; buf - > last_pic_num= * picture_number ; } else { int h_chroma_shift , v_chroma_shift ; int pixel_size , size[3] ; AVPicture picture ; avcodec_get_chroma_sub_sample ( s - > pix_fmt , & h_chroma_shift , & v_chroma_shift ) ; if ( ! ( s - > flags & CODEC_FLAG_EMU_EDGE ) ) { w + = EDGE_WIDTH * 2 ; h + = EDGE_WIDTH * 2 ; } avpicture_fill ( & picture , NULL , s - > pix_fmt , w , h ) ; pixel_size= picture . linesize[0] * 8 / w ; //av_log ( NULL , AV_LOG_ERROR , %d %d %d %d\n , ( int ) picture . data[1] , w , h , s - > pix_fmt ) ; assert ( pixel_size > =1 ) ; //FIXME next ensures that linesize= 2 x uvlinesize , thats needed because some MC code assumes it if ( pixel_size == 3 * 8 ) w= ALIGN ( w , STRIDE_ALIGN < < h_chroma_shift ) ; else w= ALIGN ( pixel_size * w , STRIDE_ALIGN < < ( h_chroma_shift + 3 ) ) / pixel_size ; size[1] = avpicture_fill ( & picture , NULL , s - > pix_fmt , w , h ) ; size[0] = picture . linesize[0] * h ; size[1] - = size[0] ; if ( picture . data[2] ) size[1]= size[2]= size[1]/2 ; else size[2]= 0 ; buf - > last_pic_num= - 256 * 256 * 256 * 64 ; memset ( buf - > base , 0 , sizeof ( buf - > base ) ) ; memset ( buf - > data , 0 , sizeof ( buf - > data ) ) ; for ( i=0 ; i < 3 & & size[i] ; i + + ) { const int h_shift= i==0 ? 0 : h_chroma_shift ; const int v_shift= i==0 ? 0 : v_chroma_shift ; buf - > linesize[i]= picture . linesize[i] ; buf - > base[i]= av_malloc ( size[i] + 16 ) ; //FIXME 16 if ( buf - > base[i]==NULL ) return - 1 ; memset ( buf - > base[i] , 128 , size[i] ) ; // no edge if EDEG EMU or not planar YUV , we check for PAL8 redundantly to protect against a exploitable bug regression . . . if ( ( s - > flags & CODEC_FLAG_EMU_EDGE ) || ( s - > pix_fmt == PIX_FMT_PAL8 ) || ! size[2] ) buf - > data[i] = buf - > base[i] ; else buf - > data[i] = buf - > base[i] + ALIGN ( ( buf - > linesize[i] * EDGE_WIDTH > > v_shift ) + ( EDGE_WIDTH > > h_shift ) , STRIDE_ALIGN ) ; } pic - > age= 256 * 256 * 256 * 64 ; } pic - > type= FF_BUFFER_TYPE_INTERNAL ; for ( i=0 ; i < 4 ; i + + ) { pic - > base[i]= buf - > base[i] ; pic - > data[i]= buf - > data[i] ; pic - > linesize[i]= buf - > linesize[i] ; } s - > internal_buffer_count + + ; return 0 ; }",1
"static int tm2_build_huff_table ( TM2Context * ctx , TM2Codes * code ) { TM2Huff huff ; int res = 0 ; huff . val_bits = get_bits ( & ctx - > gb , 5 ) ; huff . max_bits = get_bits ( & ctx - > gb , 5 ) ; huff . min_bits = get_bits ( & ctx - > gb , 5 ) ; huff . nodes = get_bits_long ( & ctx - > gb , 17 ) ; huff . num = 0 ; / * check for correct codes parameters * / if ( ( huff . val_bits < 1 ) || ( huff . val_bits > 32 ) || ( huff . max_bits < 0 ) || ( huff . max_bits > 32 ) ) { av_log ( ctx - > avctx , AV_LOG_ERROR , Incorrect tree parameters - literal length : %i , max code length : %i\n , huff . val_bits , huff . max_bits ) ; return - 1 ; } if ( ( huff . nodes < = 0 ) || ( huff . nodes > 0x10000 ) ) { av_log ( ctx - > avctx , AV_LOG_ERROR , Incorrect number of Huffman tree nodes : %i\n , huff . nodes ) ; return - 1 ; } / * one - node tree * / if ( huff . max_bits == 0 ) huff . max_bits = 1 ; / * allocate space for codes - it is exactly ceil ( nodes / 2 ) entries * / huff . max_num = ( huff . nodes + 1 ) > > 1 ; huff . nums = av_mallocz ( huff . max_num * sizeof ( int ) ) ; huff . bits = av_mallocz ( huff . max_num * sizeof ( uint32_t ) ) ; huff . lens = av_mallocz ( huff . max_num * sizeof ( int ) ) ; if ( tm2_read_tree ( ctx , 0 , 0 , & huff ) == - 1 ) res = - 1 ; if ( huff . num ! = huff . max_num ) { av_log ( ctx - > avctx , AV_LOG_ERROR , Got less codes than expected : %i of %i\n , huff . num , huff . max_num ) ; res = - 1 ; } / * convert codes to vlc_table * / if ( res ! = - 1 ) { int i ; res = init_vlc ( & code - > vlc , huff . max_bits , huff . max_num , huff . lens , sizeof ( int ) , sizeof ( int ) , huff . bits , sizeof ( uint32_t ) , sizeof ( uint32_t ) , 0 ) ; if ( res < 0 ) { av_log ( ctx - > avctx , AV_LOG_ERROR , Cannot build VLC table\n ) ; res = - 1 ; } else res = 0 ; if ( res ! = - 1 ) { code - > bits = huff . max_bits ; code - > length = huff . max_num ; code - > recode = av_malloc ( code - > length * sizeof ( int ) ) ; for ( i = 0 ; i < code - > length ; i + + ) code - > recode[i] = huff . nums[i] ; } } / * free allocated memory * / av_free ( huff . nums ) ; av_free ( huff . bits ) ; av_free ( huff . lens ) ; return res ; }",1
"static int pixlet_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { PixletContext * ctx = avctx - > priv_data ; int i , w , h , width , height , ret , version ; AVFrame * p = data ; ThreadFrame frame = { . f = data } ; uint32_t pktsize ; bytestream2_init ( & ctx - > gb , avpkt - > data , avpkt - > size ) ; pktsize = bytestream2_get_be32 ( & ctx - > gb ) ; if ( pktsize < = 44 || pktsize - 4 > bytestream2_get_bytes_left ( & ctx - > gb ) ) { av_log ( avctx , AV_LOG_ERROR , Invalid packet size % PRIu32 \n , pktsize ) ; } version = bytestream2_get_le32 ( & ctx - > gb ) ; if ( version ! = 1 ) avpriv_request_sample ( avctx , Version %d , version ) ; bytestream2_skip ( & ctx - > gb , 4 ) ; if ( bytestream2_get_be32 ( & ctx - > gb ) ! = 1 ) bytestream2_skip ( & ctx - > gb , 4 ) ; width = bytestream2_get_be32 ( & ctx - > gb ) ; height = bytestream2_get_be32 ( & ctx - > gb ) ; w = FFALIGN ( width , 1 < < ( NB_LEVELS + 1 ) ) ; h = FFALIGN ( height , 1 < < ( NB_LEVELS + 1 ) ) ; ctx - > levels = bytestream2_get_be32 ( & ctx - > gb ) ; if ( ctx - > levels ! = NB_LEVELS ) ctx - > depth = bytestream2_get_be32 ( & ctx - > gb ) ; if ( ctx - > depth < 8 || ctx - > depth > 15 ) { avpriv_request_sample ( avctx , Depth %d , ctx - > depth ) ; } ret = ff_set_dimensions ( avctx , w , h ) ; if ( ret < 0 ) return ret ; avctx - > width = width ; avctx - > height = height ; if ( ctx - > w ! = w || ctx - > h ! = h ) { free_buffers ( avctx ) ; ctx - > w = w ; ctx - > h = h ; ret = init_decoder ( avctx ) ; if ( ret < 0 ) { free_buffers ( avctx ) ; ctx - > w = 0 ; ctx - > h = 0 ; return ret ; } } bytestream2_skip ( & ctx - > gb , 8 ) ; p - > pict_type = AV_PICTURE_TYPE_I ; p - > key_frame = 1 ; p - > color_range = AVCOL_RANGE_JPEG ; ret = ff_thread_get_buffer ( avctx , & frame , 0 ) ; if ( ret < 0 ) return ret ; for ( i = 0 ; i < 3 ; i + + ) { ret = decode_plane ( avctx , i , avpkt , frame . f ) ; if ( ret < 0 ) return ret ; if ( avctx - > flags & AV_CODEC_FLAG_GRAY ) break ; } postprocess_luma ( frame . f , ctx - > w , ctx - > h , ctx - > depth ) ; postprocess_chroma ( frame . f , ctx - > w > > 1 , ctx - > h > > 1 , ctx - > depth ) ; * got_frame = 1 ; return pktsize ; }",1
"static void wmv2_idct_row ( short * b ) { int s1 , s2 ; int a0 , a1 , a2 , a3 , a4 , a5 , a6 , a7 ; / * step 1 * / a1 = W1 * b[1] + W7 * b[7] ; a7 = W7 * b[1] - W1 * b[7] ; a5 = W5 * b[5] + W3 * b[3] ; a3 = W3 * b[5] - W5 * b[3] ; a2 = W2 * b[2] + W6 * b[6] ; a6 = W6 * b[2] - W2 * b[6] ; a0 = W0 * b[0] + W0 * b[4] ; a4 = W0 * b[0] - W0 * b[4] ; / * step 2 * / s1 = ( 181 * ( a1 - a5 + a7 - a3 ) + 128 ) > > 8 ; // 1 , 3 , 5 , 7 s2 = ( 181 * ( a1 - a5 - a7 + a3 ) + 128 ) > > 8 ; / * step 3 * / b[0] = ( a0 + a2 + a1 + a5 + ( 1 < < 7 ) ) > > 8 ; b[1] = ( a4 + a6 + s1 + ( 1 < < 7 ) ) > > 8 ; b[2] = ( a4 - a6 + s2 + ( 1 < < 7 ) ) > > 8 ; b[3] = ( a0 - a2 + a7 + a3 + ( 1 < < 7 ) ) > > 8 ; b[4] = ( a0 - a2 - a7 - a3 + ( 1 < < 7 ) ) > > 8 ; b[5] = ( a4 - a6 - s2 + ( 1 < < 7 ) ) > > 8 ; b[6] = ( a4 + a6 - s1 + ( 1 < < 7 ) ) > > 8 ; b[7] = ( a0 + a2 - a1 - a5 + ( 1 < < 7 ) ) > > 8 ; }",1
"int ff_h264_decode_mb_cavlc ( H264Context * h ) { MpegEncContext * const s = & h - > s ; int mb_xy ; int partition_count ; unsigned int mb_type , cbp ; int dct8x8_allowed= h - > pps . transform_8x8_mode ; int decode_chroma = h - > sps . chroma_format_idc == 1 || h - > sps . chroma_format_idc == 2 ; const int pixel_shift = h - > pixel_shift ; mb_xy = h - > mb_xy = s - > mb_x + s - > mb_y * s - > mb_stride ; tprintf ( s - > avctx , pic : %d mb : %d/%d\n , h - > frame_num , s - > mb_x , s - > mb_y ) ; cbp = 0 ; / * avoid warning . FIXME : find a solution without slowing down the code * / if ( h - > slice_type_nos ! = AV_PICTURE_TYPE_I ) { if ( s - > mb_skip_run== - 1 ) s - > mb_skip_run= get_ue_golomb ( & s - > gb ) ; if ( s - > mb_skip_run - - ) { if ( FRAME_MBAFF & & ( s - > mb_y & 1 ) == 0 ) { if ( s - > mb_skip_run==0 ) h - > mb_mbaff = h - > mb_field_decoding_flag = get_bits1 ( & s - > gb ) ; } decode_mb_skip ( h ) ; return 0 ; } } if ( FRAME_MBAFF ) { if ( ( s - > mb_y & 1 ) == 0 ) h - > mb_mbaff = h - > mb_field_decoding_flag = get_bits1 ( & s - > gb ) ; } h - > prev_mb_skipped= 0 ; mb_type= get_ue_golomb ( & s - > gb ) ; if ( h - > slice_type_nos == AV_PICTURE_TYPE_B ) { if ( mb_type < 23 ) { partition_count= b_mb_type_info[mb_type] . partition_count ; mb_type= b_mb_type_info[mb_type] . type ; } else { mb_type - = 23 ; goto decode_intra_mb ; } } else if ( h - > slice_type_nos == AV_PICTURE_TYPE_P ) { if ( mb_type < 5 ) { partition_count= p_mb_type_info[mb_type] . partition_count ; mb_type= p_mb_type_info[mb_type] . type ; } else { mb_type - = 5 ; goto decode_intra_mb ; } } else { assert ( h - > slice_type_nos == AV_PICTURE_TYPE_I ) ; if ( h - > slice_type == AV_PICTURE_TYPE_SI & & mb_type ) mb_type - - ; decode_intra_mb : if ( mb_type > 25 ) { av_log ( h - > s . avctx , AV_LOG_ERROR , mb_type %d in %c slice too large at %d %d\n , mb_type , av_get_picture_type_char ( h - > slice_type ) , s - > mb_x , s - > mb_y ) ; return - 1 ; } partition_count=0 ; cbp= i_mb_type_info[mb_type] . cbp ; h - > intra16x16_pred_mode= i_mb_type_info[mb_type] . pred_mode ; mb_type= i_mb_type_info[mb_type] . type ; } if ( MB_FIELD ) mb_type |= MB_TYPE_INTERLACED ; h - > slice_table[ mb_xy ]= h - > slice_num ; if ( IS_INTRA_PCM ( mb_type ) ) { unsigned int x ; static const uint16_t mb_sizes[4] = { 256 , 384 , 512 , 768 } ; const int mb_size = mb_sizes[h - > sps . chroma_format_idc] * h - > sps . bit_depth_luma > > 3 ; // We assume these blocks are very rare so we do not optimize it . align_get_bits ( & s - > gb ) ; // The pixels are stored in the same order as levels in h - > mb array . for ( x=0 ; x < mb_size ; x + + ) { ( ( uint8_t * ) h - > mb ) [x]= get_bits ( & s - > gb , 8 ) ; } // In deblocking , the quantizer is 0 s - > current_picture . f . qscale_table[mb_xy] = 0 ; // All coeffs are present memset ( h - > non_zero_count[mb_xy] , 16 , 48 ) ; s - > current_picture . f . mb_type[mb_xy] = mb_type ; return 0 ; } if ( MB_MBAFF ) { h - > ref_count[0] < < = 1 ; h - > ref_count[1] < < = 1 ; } fill_decode_neighbors ( h , mb_type ) ; fill_decode_caches ( h , mb_type ) ; //mb_pred if ( IS_INTRA ( mb_type ) ) { int pred_mode ; // init_top_left_availability ( h ) ; if ( IS_INTRA4x4 ( mb_type ) ) { int i ; int di = 1 ; if ( dct8x8_allowed & & get_bits1 ( & s - > gb ) ) { mb_type |= MB_TYPE_8x8DCT ; di = 4 ; } // fill_intra4x4_pred_table ( h ) ; for ( i=0 ; i < 16 ; i + =di ) { int mode= pred_intra_mode ( h , i ) ; if ( ! get_bits1 ( & s - > gb ) ) { const int rem_mode= get_bits ( & s - > gb , 3 ) ; mode = rem_mode + ( rem_mode > = mode ) ; } if ( di==4 ) fill_rectangle ( & h - > intra4x4_pred_mode_cache[ scan8[i] ] , 2 , 2 , 8 , mode , 1 ) ; else h - > intra4x4_pred_mode_cache[ scan8[i] ] = mode ; } write_back_intra_pred_mode ( h ) ; if ( ff_h264_check_intra4x4_pred_mode ( h ) < 0 ) return - 1 ; } else { h - > intra16x16_pred_mode= ff_h264_check_intra_pred_mode ( h , h - > intra16x16_pred_mode ) ; if ( h - > intra16x16_pred_mode < 0 ) return - 1 ; } if ( decode_chroma ) { pred_mode= ff_h264_check_intra_pred_mode ( h , get_ue_golomb_31 ( & s - > gb ) ) ; if ( pred_mode < 0 ) return - 1 ; h - > chroma_pred_mode= pred_mode ; } else { h - > chroma_pred_mode = DC_128_PRED8x8 ; } } else if ( partition_count==4 ) { int i , j , sub_partition_count[4] , list , ref[2][4] ; if ( h - > slice_type_nos == AV_PICTURE_TYPE_B ) { for ( i=0 ; i < 4 ; i + + ) { h - > sub_mb_type[i]= get_ue_golomb_31 ( & s - > gb ) ; if ( h - > sub_mb_type[i] > =13 ) { av_log ( h - > s . avctx , AV_LOG_ERROR , B sub_mb_type %u out of range at %d %d\n , h - > sub_mb_type[i] , s - > mb_x , s - > mb_y ) ; return - 1 ; } sub_partition_count[i]= b_sub_mb_type_info[ h - > sub_mb_type[i] ] . partition_count ; h - > sub_mb_type[i]= b_sub_mb_type_info[ h - > sub_mb_type[i] ] . type ; } if ( IS_DIRECT ( h - > sub_mb_type[0]|h - > sub_mb_type[1]|h - > sub_mb_type[2]|h - > sub_mb_type[3] ) ) { ff_h264_pred_direct_motion ( h , & mb_type ) ; h - > ref_cache[0][scan8[4]] = h - > ref_cache[1][scan8[4]] = h - > ref_cache[0][scan8[12]] = h - > ref_cache[1][scan8[12]] = PART_NOT_AVAILABLE ; } } else { assert ( h - > slice_type_nos == AV_PICTURE_TYPE_P ) ; //FIXME SP correct ? for ( i=0 ; i < 4 ; i + + ) { h - > sub_mb_type[i]= get_ue_golomb_31 ( & s - > gb ) ; if ( h -",1
static void d3d11va_frames_uninit ( AVHWFramesContext * ctx ) { AVD3D11VAFramesContext * frames_hwctx = ctx - > hwctx ; D3D11VAFramesContext * s = ctx - > internal - > priv ; if ( frames_hwctx - > texture ) ID3D11Texture2D_Release ( frames_hwctx - > texture ) ; if ( s - > staging_texture ) ID3D11Texture2D_Release ( s - > staging_texture ) ; },1
"static void mov_read_chapters ( AVFormatContext * s ) { MOVContext * mov = s - > priv_data ; AVStream * st = NULL ; MOVStreamContext * sc ; int64_t cur_pos ; int i ; for ( i = 0 ; i < s - > nb_streams ; i + + ) if ( s - > streams[i] - > id == mov - > chapter_track ) { st = s - > streams[i] ; break ; } if ( ! st ) { av_log ( s , AV_LOG_ERROR , Referenced QT chapter track not found\n ) ; return ; } st - > discard = AVDISCARD_ALL ; sc = st - > priv_data ; cur_pos = avio_tell ( sc - > pb ) ; for ( i = 0 ; i < st - > nb_index_entries ; i + + ) { AVIndexEntry * sample = & st - > index_entries[i] ; int64_t end = i + 1 < st - > nb_index_entries ? st - > index_entries[i + 1] . timestamp : st - > duration ; uint8_t * title ; uint16_t ch ; int len , title_len ; if ( end < sample - > timestamp ) { av_log ( s , AV_LOG_WARNING , ignoring stream duration which is shorter than chapters\n ) ; end = AV_NOPTS_VALUE ; } if ( avio_seek ( sc - > pb , sample - > pos , SEEK_SET ) ! = sample - > pos ) { av_log ( s , AV_LOG_ERROR , Chapter %d not found in file\n , i ) ; goto finish ; } // the first two bytes are the length of the title len = avio_rb16 ( sc - > pb ) ; if ( len > sample - > size - 2 ) continue ; title_len = 2 * len + 1 ; if ( ! ( title = av_mallocz ( title_len ) ) ) goto finish ; // The samples could theoretically be in any encoding if there ' s an encd // atom following , but in practice are only utf - 8 or utf - 16 , distinguished // instead by the presence of a BOM if ( ! len ) { title[0] = 0 ; } else { ch = avio_rb16 ( sc - > pb ) ; if ( ch == 0xfeff ) avio_get_str16be ( sc - > pb , len , title , title_len ) ; else if ( ch == 0xfffe ) avio_get_str16le ( sc - > pb , len , title , title_len ) ; else { AV_WB16 ( title , ch ) ; if ( len == 1 || len == 2 ) title[len] = 0 ; else avio_get_str ( sc - > pb , INT_MAX , title + 2 , len - 1 ) ; } } avpriv_new_chapter ( s , i , st - > time_base , sample - > timestamp , end , title ) ; av_freep ( & title ) ; } finish : avio_seek ( sc - > pb , cur_pos , SEEK_SET ) ; }",0
"static int msrle_decode_pal4 ( AVCodecContext * avctx , AVFrame * pic , GetByteContext * gb ) { unsigned char rle_code ; unsigned char extra_byte , odd_pixel ; unsigned char stream_byte ; int pixel_ptr = 0 ; int line = avctx - > height - 1 ; int i ; while ( line > = 0 & & pixel_ptr < = avctx - > width ) { if ( bytestream2_get_bytes_left ( gb ) < = 0 ) { av_log ( avctx , AV_LOG_ERROR , MS RLE : bytestream overrun , %dx%d left\n , avctx - > width - pixel_ptr , line ) ; return AVERROR_INVALIDDATA ; } rle_code = stream_byte = bytestream2_get_byteu ( gb ) ; if ( rle_code == 0 ) { / * fetch the next byte to see how to handle escape code * / stream_byte = bytestream2_get_byte ( gb ) ; if ( stream_byte == 0 ) { / * line is done , goto the next one * / line - - ; pixel_ptr = 0 ; } else if ( stream_byte == 1 ) { / * decode is done * / return 0 ; } else if ( stream_byte == 2 ) { / * reposition frame decode coordinates * / stream_byte = bytestream2_get_byte ( gb ) ; pixel_ptr + = stream_byte ; stream_byte = bytestream2_get_byte ( gb ) ; avpriv_request_sample ( avctx , Unused stream byte %X , stream_byte ) ; } else { // copy pixels from encoded stream odd_pixel = stream_byte & 1 ; rle_code = ( stream_byte + 1 ) / 2 ; extra_byte = rle_code & 0x01 ; if ( pixel_ptr + 2 * rle_code - odd_pixel > avctx - > width || bytestream2_get_bytes_left ( gb ) < rle_code ) { av_log ( avctx , AV_LOG_ERROR , MS RLE : frame/stream ptr just went out of bounds ( copy ) \n ) ; return AVERROR_INVALIDDATA ; } for ( i = 0 ; i < rle_code ; i + + ) { if ( pixel_ptr > = avctx - > width ) break ; stream_byte = bytestream2_get_byteu ( gb ) ; pic - > data[0][line * pic - > linesize[0] + pixel_ptr] = stream_byte > > 4 ; pixel_ptr + + ; if ( i + 1 == rle_code & & odd_pixel ) break ; if ( pixel_ptr > = avctx - > width ) break ; pic - > data[0][line * pic - > linesize[0] + pixel_ptr] = stream_byte & 0x0F ; pixel_ptr + + ; } // if the RLE code is odd , skip a byte in the stream if ( extra_byte ) bytestream2_skip ( gb , 1 ) ; } } else { // decode a run of data if ( pixel_ptr + rle_code > avctx - > width + 1 ) { av_log ( avctx , AV_LOG_ERROR , MS RLE : frame ptr just went out of bounds ( run ) %d %d %d\n , pixel_ptr , rle_code , avctx - > width ) ; return AVERROR_INVALIDDATA ; } stream_byte = bytestream2_get_byte ( gb ) ; for ( i = 0 ; i < rle_code ; i + + ) { if ( pixel_ptr > = avctx - > width ) break ; if ( ( i & 1 ) == 0 ) pic - > data[0][line * pic - > linesize[0] + pixel_ptr] = stream_byte > > 4 ; else pic - > data[0][line * pic - > linesize[0] + pixel_ptr] = stream_byte & 0x0F ; pixel_ptr + + ; } } } / * one last sanity check on the way out * / if ( bytestream2_get_bytes_left ( gb ) ) { av_log ( avctx , AV_LOG_ERROR , MS RLE : ended frame decode with %d bytes left over\n , bytestream2_get_bytes_left ( gb ) ) ; return AVERROR_INVALIDDATA ; } return 0 ; }",0
"static void update_initial_durations ( AVFormatContext * s , AVStream * st , int stream_index , int duration ) { AVPacketList * pktl = s - > internal - > packet_buffer ? s - > internal - > packet_buffer : s - > internal - > parse_queue ; int64_t cur_dts = RELATIVE_TS_BASE ; if ( st - > first_dts ! = AV_NOPTS_VALUE ) { if ( st - > update_initial_durations_done ) return ; st - > update_initial_durations_done = 1 ; cur_dts = st - > first_dts ; for ( ; pktl ; pktl = get_next_pkt ( s , st , pktl ) ) { if ( pktl - > pkt . stream_index == stream_index ) { if ( pktl - > pkt . pts ! = pktl - > pkt . dts || pktl - > pkt . dts ! = AV_NOPTS_VALUE || pktl - > pkt . duration ) break ; cur_dts - = duration ; } } if ( pktl & & pktl - > pkt . dts ! = st - > first_dts ) { av_log ( s , AV_LOG_DEBUG , first_dts %s not matching first dts %s ( pts %s , duration % PRId64 ) in the queue\n , av_ts2str ( st - > first_dts ) , av_ts2str ( pktl - > pkt . dts ) , av_ts2str ( pktl - > pkt . pts ) , pktl - > pkt . duration ) ; return ; } if ( ! pktl ) { av_log ( s , AV_LOG_DEBUG , first_dts %s but no packet with dts in the queue\n , av_ts2str ( st - > first_dts ) ) ; return ; } pktl = s - > internal - > packet_buffer ? s - > internal - > packet_buffer : s - > internal - > parse_queue ; st - > first_dts = cur_dts ; } else if ( st - > cur_dts ! = RELATIVE_TS_BASE ) return ; for ( ; pktl ; pktl = get_next_pkt ( s , st , pktl ) ) { if ( pktl - > pkt . stream_index ! = stream_index ) continue ; if ( pktl - > pkt . pts == pktl - > pkt . dts & & ( pktl - > pkt . dts == AV_NOPTS_VALUE || pktl - > pkt . dts == st - > first_dts ) & & ! pktl - > pkt . duration ) { pktl - > pkt . dts = cur_dts ; if ( ! st - > internal - > avctx - > has_b_frames ) pktl - > pkt . pts = cur_dts ; // if ( st - > codecpar - > codec_type ! = AVMEDIA_TYPE_AUDIO ) pktl - > pkt . duration = duration ; } else break ; cur_dts = pktl - > pkt . dts + pktl - > pkt . duration ; } if ( ! pktl ) st - > cur_dts = cur_dts ; }",0
"int poll ( struct pollfd * fds , nfds_t numfds , int timeout ) { fd_set read_set ; fd_set write_set ; fd_set exception_set ; nfds_t i ; int n ; int rc ; ifdef __MINGW32__ if ( numfds > = FD_SETSIZE ) { errno = EINVAL ; return - 1 ; } endif FD_ZERO ( & read_set ) ; FD_ZERO ( & write_set ) ; FD_ZERO ( & exception_set ) ; n = - 1 ; for ( i = 0 ; i < numfds ; i + + ) { if ( fds[i] . fd < 0 ) continue ; ifndef __MINGW32__ if ( fds[i] . fd > = FD_SETSIZE ) { errno = EINVAL ; return - 1 ; } endif if ( fds[i] . events & POLLIN ) FD_SET ( fds[i] . fd , & read_set ) ; if ( fds[i] . events & POLLOUT ) FD_SET ( fds[i] . fd , & write_set ) ; if ( fds[i] . events & POLLERR ) FD_SET ( fds[i] . fd , & exception_set ) ; if ( fds[i] . fd > n ) n = fds[i] . fd ; } ; if ( n == - 1 ) / * Hey ! ? Nothing to poll , in fact ! ! ! * / return 0 ; if ( timeout < 0 ) rc = select ( n + 1 , & read_set , & write_set , & exception_set , NULL ) ; else { struct timeval tv ; tv . tv_sec = timeout / 1000 ; tv . tv_usec = 1000 * ( timeout % 1000 ) ; rc = select ( n + 1 , & read_set , & write_set , & exception_set , & tv ) ; } ; if ( rc < 0 ) return rc ; for ( i = 0 ; i < ( nfds_t ) n ; i + + ) { fds[i] . revents = 0 ; if ( FD_ISSET ( fds[i] . fd , & read_set ) ) fds[i] . revents |= POLLIN ; if ( FD_ISSET ( fds[i] . fd , & write_set ) ) fds[i] . revents |= POLLOUT ; if ( FD_ISSET ( fds[i] . fd , & exception_set ) ) fds[i] . revents |= POLLERR ; } ; return rc ; }",0
"int av_find_best_stream ( AVFormatContext * ic , enum AVMediaType type , int wanted_stream_nb , int related_stream , AVCodec * * decoder_ret , int flags ) { int i , nb_streams = ic - > nb_streams ; int ret = AVERROR_STREAM_NOT_FOUND , best_count = - 1 , best_bitrate = - 1 , best_multiframe = - 1 , count , bitrate , multiframe ; unsigned * program = NULL ; const AVCodec * decoder = NULL , * best_decoder = NULL ; if ( related_stream > = 0 & & wanted_stream_nb < 0 ) { AVProgram * p = av_find_program_from_stream ( ic , NULL , related_stream ) ; if ( p ) { program = p - > stream_index ; nb_streams = p - > nb_stream_indexes ; } } for ( i = 0 ; i < nb_streams ; i + + ) { int real_stream_index = program ? program[i] : i ; AVStream * st = ic - > streams[real_stream_index] ; AVCodecContext * avctx = st - > codec ; if ( avctx - > codec_type ! = type ) continue ; if ( wanted_stream_nb > = 0 & & real_stream_index ! = wanted_stream_nb ) continue ; if ( wanted_stream_nb ! = real_stream_index & & st - > disposition & ( AV_DISPOSITION_HEARING_IMPAIRED | AV_DISPOSITION_VISUAL_IMPAIRED ) ) continue ; if ( type == AVMEDIA_TYPE_AUDIO & & ! avctx - > channels ) continue ; if ( decoder_ret ) { decoder = find_decoder ( ic , st , st - > codec - > codec_id ) ; if ( ! decoder ) { if ( ret < 0 ) ret = AVERROR_DECODER_NOT_FOUND ; continue ; } } count = st - > codec_info_nb_frames ; bitrate = avctx - > bit_rate ; if ( ! bitrate ) bitrate = avctx - > rc_max_rate ; multiframe = FFMIN ( 5 , count ) ; if ( ( best_multiframe > multiframe ) || ( best_multiframe == multiframe & & best_bitrate > bitrate ) || ( best_multiframe == multiframe & & best_bitrate == bitrate & & best_count > = count ) ) continue ; best_count = count ; best_bitrate = bitrate ; best_multiframe = multiframe ; ret = real_stream_index ; best_decoder = decoder ; if ( program & & i == nb_streams - 1 & & ret < 0 ) { program = NULL ; nb_streams = ic - > nb_streams ; / * no related stream found , try again with everything * / i = 0 ; } } if ( decoder_ret ) * decoder_ret = ( AVCodec * ) best_decoder ; return ret ; }",0
"static void pmt_cb ( MpegTSFilter * filter , const uint8_t * section , int section_len ) { MpegTSContext * ts = filter - > u . section_filter . opaque ; SectionHeader h1 , * h = & h1 ; PESContext * pes ; AVStream * st ; const uint8_t * p , * p_end , * desc_list_end , * desc_end ; int program_info_length , pcr_pid , pid , stream_type ; int desc_list_len , desc_len , desc_tag ; int comp_page = 0 , anc_page = 0 ; / * initialize to kill warnings * / char language[4] = { 0 } ; / * initialize to kill warnings * / ifdef DEBUG_SI av_log ( ts - > stream , AV_LOG_DEBUG , PMT : len %i\n , section_len ) ; av_hex_dump_log ( ts - > stream , AV_LOG_DEBUG , ( uint8_t * ) section , section_len ) ; endif p_end = section + section_len - 4 ; p = section ; if ( parse_section_header ( h , & p , p_end ) < 0 ) return ; ifdef DEBUG_SI av_log ( ts - > stream , AV_LOG_DEBUG , sid=0x%x sec_num=%d/%d\n , h - > id , h - > sec_num , h - > last_sec_num ) ; endif if ( h - > tid ! = PMT_TID ) return ; clear_program ( ts , h - > id ) ; pcr_pid = get16 ( & p , p_end ) & 0x1fff ; if ( pcr_pid < 0 ) return ; add_pid_to_pmt ( ts , h - > id , pcr_pid ) ; ifdef DEBUG_SI av_log ( ts - > stream , AV_LOG_DEBUG , pcr_pid=0x%x\n , pcr_pid ) ; endif program_info_length = get16 ( & p , p_end ) & 0xfff ; if ( program_info_length < 0 ) return ; p + = program_info_length ; if ( p > = p_end ) return ; for ( ; ; ) { language[0] = 0 ; st = 0 ; stream_type = get8 ( & p , p_end ) ; if ( stream_type < 0 ) break ; pid = get16 ( & p , p_end ) & 0x1fff ; if ( pid < 0 ) break ; desc_list_len = get16 ( & p , p_end ) & 0xfff ; if ( desc_list_len < 0 ) break ; desc_list_end = p + desc_list_len ; if ( desc_list_end > p_end ) break ; for ( ; ; ) { desc_tag = get8 ( & p , desc_list_end ) ; if ( desc_tag < 0 ) break ; if ( stream_type == STREAM_TYPE_PRIVATE_DATA ) { if ( ( desc_tag == 0x6A ) || ( desc_tag == 0x7A ) ) { / * assume DVB AC - 3 Audio * / stream_type = STREAM_TYPE_AUDIO_AC3 ; } else if ( desc_tag == 0x7B ) { / * DVB DTS audio * / stream_type = STREAM_TYPE_AUDIO_DTS ; } } desc_len = get8 ( & p , desc_list_end ) ; desc_end = p + desc_len ; if ( desc_end > desc_list_end ) break ; ifdef DEBUG_SI av_log ( ts - > stream , AV_LOG_DEBUG , tag : 0x%02x len=%d\n , desc_tag , desc_len ) ; endif switch ( desc_tag ) { case DVB_SUBT_DESCID : if ( stream_type == STREAM_TYPE_PRIVATE_DATA ) stream_type = STREAM_TYPE_SUBTITLE_DVB ; language[0] = get8 ( & p , desc_end ) ; language[1] = get8 ( & p , desc_end ) ; language[2] = get8 ( & p , desc_end ) ; language[3] = 0 ; get8 ( & p , desc_end ) ; comp_page = get16 ( & p , desc_end ) ; anc_page = get16 ( & p , desc_end ) ; break ; case 0x0a : / * ISO 639 language descriptor * / language[0] = get8 ( & p , desc_end ) ; language[1] = get8 ( & p , desc_end ) ; language[2] = get8 ( & p , desc_end ) ; language[3] = 0 ; break ; default : break ; } p = desc_end ; } p = desc_list_end ; ifdef DEBUG_SI av_log ( ts - > stream , AV_LOG_DEBUG , stream_type=%d pid=0x%x\n , stream_type , pid ) ; endif / * now create ffmpeg stream * / switch ( stream_type ) { case STREAM_TYPE_AUDIO_MPEG1 : case STREAM_TYPE_AUDIO_MPEG2 : case STREAM_TYPE_VIDEO_MPEG1 : case STREAM_TYPE_VIDEO_MPEG2 : case STREAM_TYPE_VIDEO_MPEG4 : case STREAM_TYPE_VIDEO_H264 : case STREAM_TYPE_VIDEO_VC1 : case STREAM_TYPE_AUDIO_AAC : case STREAM_TYPE_AUDIO_AC3 : case STREAM_TYPE_AUDIO_DTS : case STREAM_TYPE_SUBTITLE_DVB : if ( ts - > pids[pid] ) { assert ( ts - > pids[pid] - > type == MPEGTS_PES ) ; pes= ts - > pids[pid] - > u . pes_filter . opaque ; st= pes - > st ; } else { pes = add_pes_stream ( ts , pid , pcr_pid , stream_type ) ; if ( pes ) st = new_pes_av_stream ( pes , 0 ) ; } add_pid_to_pmt ( ts , h - > id , pid ) ; if ( st ) av_program_add_stream_index ( ts - > stream , h - > id , st - > index ) ; break ; default : / * we ignore the other streams * / break ; } if ( st ) { if ( language[0] ! = 0 ) { memcpy ( st - > language , language , 4 ) ; } if ( stream_type == STREAM_TYPE_SUBTITLE_DVB ) { st - > codec - > sub_id = ( anc_page < < 16 ) | comp_page ; } } } / * all parameters are there * / ts - > stop_parse + + ; mpegts_close_filter ( ts , filter ) ; }",1
"static inline void RENAME ( yuv2yuvX ) ( SwsContext * c , const int16_t * lumFilter , const int16_t * * lumSrc , int lumFilterSize , const int16_t * chrFilter , const int16_t * * chrSrc , int chrFilterSize , const int16_t * * alpSrc , uint8_t * dest , uint8_t * uDest , uint8_t * vDest , uint8_t * aDest , int dstW , int chrDstW ) { if COMPILE_TEMPLATE_MMX if ( ! ( c - > flags & SWS_BITEXACT ) ) { if ( c - > flags & SWS_ACCURATE_RND ) { if ( uDest ) { YSCALEYUV2YV12X_ACCURATE ( 0 , CHR_MMX_FILTER_OFFSET , uDest , chrDstW ) YSCALEYUV2YV12X_ACCURATE ( AV_STRINGIFY ( VOF ) , CHR_MMX_FILTER_OFFSET , vDest , chrDstW ) } if ( CONFIG_SWSCALE_ALPHA & & aDest ) { YSCALEYUV2YV12X_ACCURATE ( 0 , ALP_MMX_FILTER_OFFSET , aDest , dstW ) } YSCALEYUV2YV12X_ACCURATE ( 0 , LUM_MMX_FILTER_OFFSET , dest , dstW ) } else { if ( uDest ) { YSCALEYUV2YV12X ( 0 , CHR_MMX_FILTER_OFFSET , uDest , chrDstW ) YSCALEYUV2YV12X ( AV_STRINGIFY ( VOF ) , CHR_MMX_FILTER_OFFSET , vDest , chrDstW ) } if ( CONFIG_SWSCALE_ALPHA & & aDest ) { YSCALEYUV2YV12X ( 0 , ALP_MMX_FILTER_OFFSET , aDest , dstW ) } YSCALEYUV2YV12X ( 0 , LUM_MMX_FILTER_OFFSET , dest , dstW ) } return ; } endif if COMPILE_TEMPLATE_ALTIVEC yuv2yuvX_altivec_real ( lumFilter , lumSrc , lumFilterSize , chrFilter , chrSrc , chrFilterSize , dest , uDest , vDest , dstW , chrDstW ) ; else //COMPILE_TEMPLATE_ALTIVEC yuv2yuvXinC ( lumFilter , lumSrc , lumFilterSize , chrFilter , chrSrc , chrFilterSize , alpSrc , dest , uDest , vDest , aDest , dstW , chrDstW ) ; endif // ! COMPILE_TEMPLATE_ALTIVEC }",1
"static inline void vc1_pred_mv_intfr ( VC1Context * v , int n , int dmv_x , int dmv_y , int mvn , int r_x , int r_y , uint8_t * is_intra , int dir ) { MpegEncContext * s = & v - > s ; int xy , wrap , off = 0 ; int A[2] , B[2] , C[2] ; int px , py ; int a_valid = 0 , b_valid = 0 , c_valid = 0 ; int field_a , field_b , field_c ; // 0 : same , 1 : opposit int total_valid , num_samefield , num_oppfield ; int pos_c , pos_b , n_adj ; wrap = s - > b8_stride ; xy = s - > block_index[n] ; if ( s - > mb_intra ) { s - > mv[0][n][0] = s - > current_picture . motion_val[0][xy][0] = 0 ; s - > mv[0][n][1] = s - > current_picture . motion_val[0][xy][1] = 0 ; s - > current_picture . motion_val[1][xy][0] = 0 ; s - > current_picture . motion_val[1][xy][1] = 0 ; if ( mvn == 1 ) { / * duplicate motion data for 1 - MV block * / s - > current_picture . motion_val[0][xy + 1][0] = 0 ; s - > current_picture . motion_val[0][xy + 1][1] = 0 ; s - > current_picture . motion_val[0][xy + wrap][0] = 0 ; s - > current_picture . motion_val[0][xy + wrap][1] = 0 ; s - > current_picture . motion_val[0][xy + wrap + 1][0] = 0 ; s - > current_picture . motion_val[0][xy + wrap + 1][1] = 0 ; v - > luma_mv[s - > mb_x][0] = v - > luma_mv[s - > mb_x][1] = 0 ; s - > current_picture . motion_val[1][xy + 1][0] = 0 ; s - > current_picture . motion_val[1][xy + 1][1] = 0 ; s - > current_picture . motion_val[1][xy + wrap][0] = 0 ; s - > current_picture . motion_val[1][xy + wrap][1] = 0 ; s - > current_picture . motion_val[1][xy + wrap + 1][0] = 0 ; s - > current_picture . motion_val[1][xy + wrap + 1][1] = 0 ; } return ; } off = ( ( n == 0 ) || ( n == 1 ) ) ? 1 : - 1 ; / * predict A * / if ( s - > mb_x || ( n == 1 ) || ( n == 3 ) ) { if ( ( v - > blk_mv_type[xy] ) // current block ( MB ) has a field MV || ( ! v - > blk_mv_type[xy] & & ! v - > blk_mv_type[xy - 1] ) ) { // or both have frame MV A[0] = s - > current_picture . motion_val[dir][xy - 1][0] ; A[1] = s - > current_picture . motion_val[dir][xy - 1][1] ; a_valid = 1 ; } else { // current block has frame mv and cand . has field MV ( so average ) A[0] = ( s - > current_picture . motion_val[dir][xy - 1][0] + s - > current_picture . motion_val[dir][xy - 1 + off * wrap][0] + 1 ) > > 1 ; A[1] = ( s - > current_picture . motion_val[dir][xy - 1][1] + s - > current_picture . motion_val[dir][xy - 1 + off * wrap][1] + 1 ) > > 1 ; a_valid = 1 ; } if ( ! ( n & 1 ) & & v - > is_intra[s - > mb_x - 1] ) { a_valid = 0 ; A[0] = A[1] = 0 ; } } else A[0] = A[1] = 0 ; / * Predict B and C * / B[0] = B[1] = C[0] = C[1] = 0 ; if ( n == 0 || n == 1 || v - > blk_mv_type[xy] ) { if ( ! s - > first_slice_line ) { if ( ! v - > is_intra[s - > mb_x - s - > mb_stride] ) { b_valid = 1 ; n_adj = n | 2 ; pos_b = s - > block_index[n_adj] - 2 * wrap ; if ( v - > blk_mv_type[pos_b] & & v - > blk_mv_type[xy] ) { n_adj = ( n & 2 ) | ( n & 1 ) ; } B[0] = s - > current_picture . motion_val[dir][s - > block_index[n_adj] - 2 * wrap][0] ; B[1] = s - > current_picture . motion_val[dir][s - > block_index[n_adj] - 2 * wrap][1] ; if ( v - > blk_mv_type[pos_b] & & ! v - > blk_mv_type[xy] ) { B[0] = ( B[0] + s - > current_picture . motion_val[dir][s - > block_index[n_adj 2] - 2 * wrap][0] + 1 ) > > 1 ; B[1] = ( B[1] + s - > current_picture . motion_val[dir][s - > block_index[n_adj 2] - 2 * wrap][1] + 1 ) > > 1 ; } } if ( s - > mb_width > 1 ) { if ( ! v - > is_intra[s - > mb_x - s - > mb_stride + 1] ) { c_valid = 1 ; n_adj = 2 ; pos_c = s - > block_index[2] - 2 * wrap + 2 ; if ( v - > blk_mv_type[pos_c] & & v - > blk_mv_type[xy] ) { n_adj = n & 2 ; } C[0] = s - > current_picture . motion_val[dir][s - > block_index[n_adj] - 2 * wrap + 2][0] ; C[1] = s - > current_picture . motion_val[dir][s - > block_index[n_adj] - 2 * wrap + 2][1] ; if ( v - > blk_mv_type[pos_c] & & ! v - > blk_mv_type[xy] ) { C[0] = ( 1 + C[0] + ( s - > current_picture . motion_val[dir][s - > block_index[n_adj 2] - 2 * wrap + 2][0] ) ) > > 1 ; C[1] = ( 1 + C[1] + ( s - > current_picture . motion_val[dir][s - > block_index[n_adj 2] - 2 * wrap + 2][1] ) ) > > 1 ; } if ( s - > mb_x == s - > mb_width - 1 ) { if ( ! v - > is_intra[s - > mb_x - s - > mb_stride - 1] ) { c_valid = 1 ; n_adj = 3 ; pos_c = s - > block_index[3] - 2 * wrap - 2 ; if ( v - > blk_mv_type[pos_c] & & v - > blk_mv_type[xy] ) { n_adj = n | 1 ; } C[0] = s - > current_picture . motion_val[dir][s - > block_index[n_adj] - 2 * wrap - 2][0] ; C[1] = s - > current_picture . motion_val[dir][s - > block_index[n_adj] - 2 * wrap - 2][1] ; if ( v - > blk_mv_type[pos_c] & & ! v - > blk_mv_type[xy] ) { C[0] = ( 1 + C[0] + s - > current_picture . motion_val[dir][s - > block_index[1] - 2 * wrap - 2][0] ) > > 1 ; C[1] = ( 1 + C[1] + s - > current_picture . motion_val[dir][s - > block_index[1] - 2 * wrap - 2][1] ) > > 1 ; } } else c_valid = 0 ; } } } } } else { pos_b = s - > block_index[1] ; b_valid = 1 ; B[0]",1
"const AVOption * av_set_string ( void * obj , const char * name , const char * val ) { const AVOption * o= av_find_opt ( obj , name , NULL , 0 , 0 ) ; if ( o & & o - > offset==0 & & o - > type == FF_OPT_TYPE_CONST & & o - > unit ) { return set_all_opt ( obj , o - > unit , o - > default_val ) ; } if ( ! o || ! val || o - > offset < =0 ) return NULL ; if ( o - > type ! = FF_OPT_TYPE_STRING ) { for ( ; ; ) { int i ; char buf[256] ; int cmd=0 ; double d ; char * error = NULL ; if ( * val == ' + ' || * val == ' - ' ) cmd= * ( val + + ) ; for ( i=0 ; i < sizeof ( buf ) - 1 & & val[i] & & val[i] ! = ' + ' & & val[i] ! = ' - ' ; i + + ) buf[i]= val[i] ; buf[i]=0 ; val + = i ; d = ff_eval2 ( buf , const_values , const_names , NULL , NULL , NULL , NULL , NULL , & error ) ; if ( isnan ( d ) ) { const AVOption * o_named= av_find_opt ( obj , buf , o - > unit , 0 , 0 ) ; if ( o_named & & o_named - > type == FF_OPT_TYPE_CONST ) d= o_named - > default_val ; else if ( ! strcmp ( buf , default ) ) d= o - > default_val ; else if ( ! strcmp ( buf , max ) ) d= o - > max ; else if ( ! strcmp ( buf , min ) ) d= o - > min ; else if ( ! strcmp ( buf , none ) ) d= 0 ; else if ( ! strcmp ( buf , all ) ) d= 0 ; else { if ( ! error ) av_log ( NULL , AV_LOG_ERROR , Unable to parse option value \ %s\ : %s\n , val , error ) ; return NULL ; } } if ( o - > type == FF_OPT_TYPE_FLAGS ) { if ( cmd== ' + ' ) d= av_get_int ( obj , name , NULL ) | ( int64_t ) d ; else if ( cmd== ' - ' ) d= av_get_int ( obj , name , NULL ) & ( int64_t ) d ; } else if ( cmd== ' - ' ) d= - d ; av_set_number ( obj , name , d , 1 , 1 ) ; if ( ! * val ) return o ; } return NULL ; } memcpy ( ( ( uint8_t * ) obj ) + o - > offset , val , sizeof ( val ) ) ; return o ; }",1
"int ff_h2645_extract_rbsp ( const uint8_t * src , int length , H2645NAL * nal , int small_padding ) { int i , si , di ; uint8_t * dst ; int64_t padding = small_padding ? AV_INPUT_BUFFER_PADDING_SIZE : MAX_MBPAIR_SIZE ; nal - > skipped_bytes = 0 ; define STARTCODE_TEST \ if ( i + 2 < length & & src[i + 1] == 0 & & src[i + 2] < = 3 ) { \ if ( src[i + 2] ! = 3 & & src[i + 2] ! = 0 ) { \ / * startcode , so we must be past the end * / \ length = i ; \ } \ break ; \ } if HAVE_FAST_UNALIGNED define FIND_FIRST_ZERO \ if ( i > 0 & & ! src[i] ) \ i - - ; \ while ( src[i] ) \ i + + if HAVE_FAST_64BIT for ( i = 0 ; i + 1 < length ; i + = 9 ) { if ( ! ( ( AV_RN64A ( src + i ) & ( AV_RN64A ( src + i ) - 0x0100010001000101ULL ) ) & 0x8000800080008080ULL ) ) continue ; FIND_FIRST_ZERO ; STARTCODE_TEST ; i - = 7 ; } else for ( i = 0 ; i + 1 < length ; i + = 5 ) { if ( ! ( ( AV_RN32A ( src + i ) & ( AV_RN32A ( src + i ) - 0x01000101U ) ) & 0x80008080U ) ) continue ; FIND_FIRST_ZERO ; STARTCODE_TEST ; i - = 3 ; } endif / * HAVE_FAST_64BIT * / else for ( i = 0 ; i + 1 < length ; i + = 2 ) { if ( src[i] ) continue ; if ( i > 0 & & src[i - 1] == 0 ) i - - ; STARTCODE_TEST ; } endif / * HAVE_FAST_UNALIGNED * / if ( i > = length - 1 & & small_padding ) { // no escaped 0 nal - > data = nal - > raw_data = src ; nal - > size = nal - > raw_size = length ; return length ; } av_fast_malloc ( & nal - > rbsp_buffer , & nal - > rbsp_buffer_size , length + padding ) ; if ( ! nal - > rbsp_buffer ) return AVERROR ( ENOMEM ) ; dst = nal - > rbsp_buffer ; memcpy ( dst , src , i ) ; si = di = i ; while ( si + 2 < length ) { // remove escapes ( very rare 1 : 2 22 ) if ( src[si + 2] > 3 ) { dst[di + + ] = src[si + + ] ; dst[di + + ] = src[si + + ] ; } else if ( src[si] == 0 & & src[si + 1] == 0 & & src[si + 2] ! = 0 ) { if ( src[si + 2] == 3 ) { // escape dst[di + + ] = 0 ; dst[di + + ] = 0 ; si + = 3 ; if ( nal - > skipped_bytes_pos ) { nal - > skipped_bytes + + ; if ( nal - > skipped_bytes_pos_size < nal - > skipped_bytes ) { nal - > skipped_bytes_pos_size * = 2 ; av_assert0 ( nal - > skipped_bytes_pos_size > = nal - > skipped_bytes ) ; av_reallocp_array ( & nal - > skipped_bytes_pos , nal - > skipped_bytes_pos_size , sizeof ( * nal - > skipped_bytes_pos ) ) ; if ( ! nal - > skipped_bytes_pos ) { nal - > skipped_bytes_pos_size = 0 ; return AVERROR ( ENOMEM ) ; } } if ( nal - > skipped_bytes_pos ) nal - > skipped_bytes_pos[nal - > skipped_bytes - 1] = di - 1 ; } continue ; } else // next start code goto nsc ; } dst[di + + ] = src[si + + ] ; } while ( si < length ) dst[di + + ] = src[si + + ] ; nsc : memset ( dst + di , 0 , AV_INPUT_BUFFER_PADDING_SIZE ) ; nal - > data = dst ; nal - > size = di ; nal - > raw_data = src ; nal - > raw_size = si ; return si ; }",1
"static void choose_pixel_fmt ( AVStream * st , AVCodec * codec ) { if ( codec & & codec - > pix_fmts ) { const enum PixelFormat * p= codec - > pix_fmts ; if ( st - > codec - > strict_std_compliance < = FF_COMPLIANCE_UNOFFICIAL ) { if ( st - > codec - > codec_id==CODEC_ID_MJPEG ) { p= ( const enum PixelFormat[] ) { PIX_FMT_YUVJ420P , PIX_FMT_YUVJ422P , PIX_FMT_YUV420P , PIX_FMT_YUV422P , PIX_FMT_NONE } ; } else if ( st - > codec - > codec_id==CODEC_ID_LJPEG ) { p= ( const enum PixelFormat[] ) { PIX_FMT_YUVJ420P , PIX_FMT_YUVJ422P , PIX_FMT_YUVJ444P , PIX_FMT_YUV420P , PIX_FMT_YUV422P , PIX_FMT_YUV444P , PIX_FMT_BGRA , PIX_FMT_NONE } ; } } for ( ; * p ! = - 1 ; p + + ) { if ( * p == st - > codec - > pix_fmt ) break ; } if ( * p == - 1 ) { av_log ( NULL , AV_LOG_WARNING , Incompatible pixel format ' %s ' for codec ' %s ' , auto - selecting format ' %s ' \n , av_pix_fmt_descriptors[st - > codec - > pix_fmt] . name , codec - > name , av_pix_fmt_descriptors[codec - > pix_fmts[0]] . name ) ; st - > codec - > pix_fmt = codec - > pix_fmts[0] ; } } }",1
"static int matroska_read_header ( AVFormatContext * s ) { MatroskaDemuxContext * matroska = s - > priv_data ; EbmlList * attachements_list = & matroska - > attachments ; MatroskaAttachement * attachements ; EbmlList * chapters_list = & matroska - > chapters ; MatroskaChapter * chapters ; MatroskaTrack * tracks ; uint64_t max_start = 0 ; int64_t pos ; Ebml ebml = { 0 } ; AVStream * st ; int i , j , k , res ; matroska - > ctx = s ; / * First read the EBML header . * / if ( ebml_parse ( matroska , ebml_syntax , & ebml ) || ebml . version > EBML_VERSION || ebml . max_size > sizeof ( uint64_t ) || ebml . id_length > sizeof ( uint32_t ) || ebml . doctype_version > 3 ) { av_log ( matroska - > ctx , AV_LOG_ERROR , EBML header using unsupported features\n ( EBML version % PRIu64 , doctype %s , doc version % PRIu64 ) \n , ebml . version , ebml . doctype , ebml . doctype_version ) ; ebml_free ( ebml_syntax , & ebml ) ; return AVERROR_PATCHWELCOME ; } else if ( ebml . doctype_version == 3 ) { av_log ( matroska - > ctx , AV_LOG_WARNING , EBML header using unsupported features\n ( EBML version % PRIu64 , doctype %s , doc version % PRIu64 ) \n , ebml . version , ebml . doctype , ebml . doctype_version ) ; } for ( i = 0 ; i < FF_ARRAY_ELEMS ( matroska_doctypes ) ; i + + ) if ( ! strcmp ( ebml . doctype , matroska_doctypes[i] ) ) break ; if ( i > = FF_ARRAY_ELEMS ( matroska_doctypes ) ) { av_log ( s , AV_LOG_WARNING , Unknown EBML doctype ' %s ' \n , ebml . doctype ) ; } ebml_free ( ebml_syntax , & ebml ) ; / * The next thing is a segment . * / pos = avio_tell ( matroska - > ctx - > pb ) ; res = ebml_parse ( matroska , matroska_segments , matroska ) ; // try resyncing until we find a EBML_STOP type element . while ( res ! = 1 ) { res = matroska_resync ( matroska , pos ) ; if ( res < 0 ) return res ; pos = avio_tell ( matroska - > ctx - > pb ) ; res = ebml_parse ( matroska , matroska_segment , matroska ) ; } matroska_execute_seekhead ( matroska ) ; if ( ! matroska - > time_scale ) matroska - > time_scale = 1000000 ; if ( matroska - > duration ) matroska - > ctx - > duration = matroska - > duration * matroska - > time_scale * 1000 / AV_TIME_BASE ; av_dict_set ( & s - > metadata , title , matroska - > title , 0 ) ; if ( matroska - > date_utc . size == 8 ) matroska_metadata_creation_time ( & s - > metadata , AV_RB64 ( matroska - > date_utc . data ) ) ; tracks = matroska - > tracks . elem ; for ( i=0 ; i < matroska - > tracks . nb_elem ; i + + ) { MatroskaTrack * track = & tracks[i] ; enum CodecID codec_id = CODEC_ID_NONE ; EbmlList * encodings_list = & track - > encodings ; MatroskaTrackEncoding * encodings = encodings_list - > elem ; uint8_t * extradata = NULL ; int extradata_size = 0 ; int extradata_offset = 0 ; uint32_t fourcc = 0 ; AVIOContext b ; / * Apply some sanity checks . * / if ( track - > type ! = MATROSKA_TRACK_TYPE_VIDEO & & track - > type ! = MATROSKA_TRACK_TYPE_AUDIO & & track - > type ! = MATROSKA_TRACK_TYPE_SUBTITLE ) { av_log ( matroska - > ctx , AV_LOG_INFO , Unknown or unsupported track type % PRIu64 \n , track - > type ) ; continue ; } if ( track - > codec_id == NULL ) continue ; if ( track - > type == MATROSKA_TRACK_TYPE_VIDEO ) { if ( ! track - > default_duration ) track - > default_duration = 1000000000/track - > video . frame_rate ; if ( ! track - > video . display_width ) track - > video . display_width = track - > video . pixel_width ; if ( ! track - > video . display_height ) track - > video . display_height = track - > video . pixel_height ; if ( track - > video . color_space . size == 4 ) fourcc = AV_RL32 ( track - > video . color_space . data ) ; } else if ( track - > type == MATROSKA_TRACK_TYPE_AUDIO ) { if ( ! track - > audio . out_samplerate ) track - > audio . out_samplerate = track - > audio . samplerate ; } if ( encodings_list - > nb_elem > 1 ) { av_log ( matroska - > ctx , AV_LOG_ERROR , Multiple combined encodings not supported ) ; } else if ( encodings_list - > nb_elem == 1 ) { if ( encodings[0] . type || ( encodings[0] . compression . algo ! = MATROSKA_TRACK_ENCODING_COMP_HEADERSTRIP & & if CONFIG_ZLIB encodings[0] . compression . algo ! = MATROSKA_TRACK_ENCODING_COMP_ZLIB & & endif if CONFIG_BZLIB encodings[0] . compression . algo ! = MATROSKA_TRACK_ENCODING_COMP_BZLIB & & endif encodings[0] . compression . algo ! = MATROSKA_TRACK_ENCODING_COMP_LZO ) ) { encodings[0] . scope = 0 ; av_log ( matroska - > ctx , AV_LOG_ERROR , Unsupported encoding type ) ; } else if ( track - > codec_priv . size & & encodings[0] . scope & 2 ) { uint8_t * codec_priv = track - > codec_priv . data ; int offset = matroska_decode_buffer ( & track - > codec_priv . data , & track - > codec_priv . size , track ) ; if ( offset < 0 ) { track - > codec_priv . data = NULL ; track - > codec_priv . size = 0 ; av_log ( matroska - > ctx , AV_LOG_ERROR , Failed to decode codec private data\n ) ; } else if ( offset > 0 ) { track - > codec_priv . data = av_malloc ( track - > codec_priv . size + offset ) ; memcpy ( track - > codec_priv . data , encodings[0] . compression . settings . data , offset ) ; memcpy ( track - > codec_priv . data + offset , codec_priv , track - > codec_priv . size ) ; track - > codec_priv . size + = offset ; } if ( codec_priv ! = track - > codec_priv . data ) av_free ( codec_priv ) ; } } for ( j=0 ; ff_mkv_codec_tags[j] . id ! = CODEC_ID_NONE ; j + + ) { if ( ! strncmp ( ff_mkv_codec_tags[j] . str , track - > codec_id , strlen ( ff_mkv_codec_tags[j] . str ) ) ) { codec_id= ff_mkv_codec_tags[j] . id ; break ; } } st = track - > stream = avformat_new_stream ( s , NULL ) ; if ( st == NULL ) return AVERROR ( ENOMEM ) ; if ( ! strcmp ( track -",1
"av_cold int vp56_free ( AVCodecContext * avctx ) { VP56Context * s = avctx - > priv_data ; int pt ; av_freep ( & s - > qscale_table ) ; av_freep ( & s - > above_blocks ) ; av_freep ( & s - > macroblocks ) ; av_freep ( & s - > edge_emu_buffer_alloc ) ; if ( s - > framep[VP56_FRAME_GOLDEN] - > data[0] ) avctx - > release_buffer ( avctx , s - > framep[VP56_FRAME_GOLDEN] ) ; if ( s - > framep[VP56_FRAME_GOLDEN2] - > data[0] ) avctx - > release_buffer ( avctx , s - > framep[VP56_FRAME_GOLDEN2] ) ; if ( s - > framep[VP56_FRAME_PREVIOUS] - > data[0] ) avctx - > release_buffer ( avctx , s - > framep[VP56_FRAME_PREVIOUS] ) ; return 0 ;",1
"static void decode_cdlms ( WmallDecodeCtx * s ) { int c , i ; int cdlms_send_coef = get_bits1 ( & s - > gb ) ; for ( c = 0 ; c < s - > num_channels ; c + + ) { s - > cdlms_ttl[c] = get_bits ( & s - > gb , 3 ) + 1 ; for ( i = 0 ; i < s - > cdlms_ttl[c] ; i + + ) { s - > cdlms[c][i] . order = ( get_bits ( & s - > gb , 7 ) + 1 ) * 8 ; } for ( i = 0 ; i < s - > cdlms_ttl[c] ; i + + ) { s - > cdlms[c][i] . scaling = get_bits ( & s - > gb , 4 ) ; } if ( cdlms_send_coef ) { for ( i = 0 ; i < s - > cdlms_ttl[c] ; i + + ) { int cbits , shift_l , shift_r , j ; cbits = av_log2 ( s - > cdlms[c][i] . order ) ; if ( 1 < < cbits < s - > cdlms[c][i] . order ) cbits + + ; s - > cdlms[c][i] . coefsend = get_bits ( & s - > gb , cbits ) + 1 ; cbits = av_log2 ( s - > cdlms[c][i] . scaling + 1 ) ; if ( 1 < < cbits < s - > cdlms[c][i] . scaling + 1 ) cbits + + ; s - > cdlms[c][i] . bitsend = get_bits ( & s - > gb , cbits ) + 2 ; shift_l = 32 - s - > cdlms[c][i] . bitsend ; shift_r = 32 - 2 - s - > cdlms[c][i] . scaling ; for ( j = 0 ; j < s - > cdlms[c][i] . coefsend ; j + + ) { s - > cdlms[c][i] . coefs[j] = ( get_bits ( & s - > gb , s - > cdlms[c][i] . bitsend ) < < shift_l ) > > shift_r ; } } } } }",1
"static void decode_block_params ( DiracContext * s , DiracArith arith[8] , DiracBlock * block , int stride , int x , int y ) { int i ; block - > ref = pred_block_mode ( block , stride , x , y , DIRAC_REF_MASK_REF1 ) ; block - > ref = dirac_get_arith_bit ( arith , CTX_PMODE_REF1 ) ; if ( s - > num_refs == 2 ) { block - > ref |= pred_block_mode ( block , stride , x , y , DIRAC_REF_MASK_REF2 ) ; block - > ref = dirac_get_arith_bit ( arith , CTX_PMODE_REF2 ) < < 1 ; } if ( ! block - > ref ) { pred_block_dc ( block , stride , x , y ) ; for ( i = 0 ; i < 3 ; i + + ) block - > u . dc[i] + = dirac_get_arith_int ( arith + 1 + i , CTX_DC_F1 , CTX_DC_DATA ) ; return ; } if ( s - > globalmc_flag ) { block - > ref |= pred_block_mode ( block , stride , x , y , DIRAC_REF_MASK_GLOBAL ) ; block - > ref = dirac_get_arith_bit ( arith , CTX_GLOBAL_BLOCK ) < < 2 ; } for ( i = 0 ; i < s - > num_refs ; i + + ) if ( block - > ref & ( i + 1 ) ) { if ( block - > ref & DIRAC_REF_MASK_GLOBAL ) { global_mv ( s , block , x , y , i ) ; } else { pred_mv ( block , stride , x , y , i ) ; block - > u . mv[i][0] + = dirac_get_arith_int ( arith + 4 + 2 * i , CTX_MV_F1 , CTX_MV_DATA ) ; block - > u . mv[i][1] + = dirac_get_arith_int ( arith + 5 + 2 * i , CTX_MV_F1 , CTX_MV_DATA ) ; } } }",1
"static int filter_frame ( AVFilterLink * inlink , AVFrame * picref ) { AVFilterContext * ctx = inlink - > dst ; SignatureContext * sic = ctx - > priv ; StreamContext * sc = & ( sic - > streamcontexts[FF_INLINK_IDX ( inlink ) ] ) ; FineSignature * fs ; static const uint8_t pot3[5] = { 3 * 3 * 3 * 3 , 3 * 3 * 3 , 3 * 3 , 3 , 1 } ; / * indexes of words : 210 , 217 , 219 , 274 , 334 44 , 175 , 233 , 270 , 273 57 , 70 , 103 , 237 , 269 100 , 285 , 295 , 337 , 354 101 , 102 , 111 , 275 , 296 s2usw = sorted to unsorted wordvec : 44 is at index 5 , 57 at index 10 . . . * / static const unsigned int wordvec[25] = { 44 , 57 , 70 , 100 , 101 , 102 , 103 , 111 , 175 , 210 , 217 , 219 , 233 , 237 , 269 , 270 , 273 , 274 , 275 , 285 , 295 , 296 , 334 , 337 , 354 } ; static const uint8_t s2usw[25] = { 5 , 10 , 11 , 15 , 20 , 21 , 12 , 22 , 6 , 0 , 1 , 2 , 7 , 13 , 14 , 8 , 9 , 3 , 23 , 16 , 17 , 24 , 4 , 18 , 19 } ; uint8_t wordt2b[5] = { 0 , 0 , 0 , 0 , 0 } ; / * word ternary to binary * / uint64_t intpic[32][32] ; uint64_t rowcount ; uint8_t * p = picref - > data[0] ; int inti , intj ; int * intjlut ; uint64_t conflist[DIFFELEM_SIZE] ; int f = 0 , g = 0 , w = 0 ; int32_t dh1 = 1 , dh2 = 1 , dw1 = 1 , dw2 = 1 , a , b ; int64_t denom ; int i , j , k , ternary ; uint64_t blocksum ; int blocksize ; int64_t th ; / * threshold * / int64_t sum ; int64_t precfactor = ( sc - > divide ) ? 65536 : BLOCK_LCM ; / * initialize fs * / if ( sc - > curfinesig ) { fs = av_mallocz ( sizeof ( FineSignature ) ) ; if ( ! fs ) return AVERROR ( ENOMEM ) ; sc - > curfinesig - > next = fs ; fs - > prev = sc - > curfinesig ; sc - > curfinesig = fs ; } else { fs = sc - > curfinesig = sc - > finesiglist ; sc - > curcoarsesig1 - > first = fs ; } fs - > pts = picref - > pts ; fs - > index = sc - > lastindex + + ; memset ( intpic , 0 , sizeof ( uint64_t ) * 32 * 32 ) ; intjlut = av_malloc_array ( inlink - > w , sizeof ( int ) ) ; if ( ! intjlut ) return AVERROR ( ENOMEM ) ; for ( i = 0 ; i < inlink - > w ; i + + ) { intjlut[i] = ( i * 32 ) /inlink - > w ; } for ( i = 0 ; i < inlink - > h ; i + + ) { inti = ( i * 32 ) /inlink - > h ; for ( j = 0 ; j < inlink - > w ; j + + ) { intj = intjlut[j] ; intpic[inti][intj] + = p[j] ; } p + = picref - > linesize[0] ; } av_freep ( & intjlut ) ; / * The following calculates a summed area table ( intpic ) and brings the numbers * in intpic to the same denominator . * So you only have to handle the numinator in the following sections . * / dh1 = inlink - > h / 32 ; if ( inlink - > h % 32 ) dh2 = dh1 + 1 ; dw1 = inlink - > w / 32 ; if ( inlink - > w % 32 ) dw2 = dw1 + 1 ; denom = ( sc - > divide ) ? dh1 * dh2 * dw1 * dw2 : 1 ; for ( i = 0 ; i < 32 ; i + + ) { rowcount = 0 ; a = 1 ; if ( dh2 > 1 ) { a = ( ( inlink - > h * ( i + 1 ) ) %32 == 0 ) ? ( inlink - > h * ( i + 1 ) ) /32 - 1 : ( inlink - > h * ( i + 1 ) ) /32 ; a - = ( ( inlink - > h * i ) %32 == 0 ) ? ( inlink - > h * i ) /32 - 1 : ( inlink - > h * i ) /32 ; a = ( a == dh1 ) ? dh2 : dh1 ; } for ( j = 0 ; j < 32 ; j + + ) { b = 1 ; if ( dw2 > 1 ) { b = ( ( inlink - > w * ( j + 1 ) ) %32 == 0 ) ? ( inlink - > w * ( j + 1 ) ) /32 - 1 : ( inlink - > w * ( j + 1 ) ) /32 ; b - = ( ( inlink - > w * j ) %32 == 0 ) ? ( inlink - > w * j ) /32 - 1 : ( inlink - > w * j ) /32 ; b = ( b == dw1 ) ? dw2 : dw1 ; } rowcount + = intpic[i][j] * a * b * precfactor / denom ; if ( i > 0 ) { intpic[i][j] = intpic[i - 1][j] + rowcount ; } else { intpic[i][j] = rowcount ; } } } denom = ( sc - > divide ) ? 1 : dh1 * dh2 * dw1 * dw2 ; for ( i = 0 ; i < ELEMENT_COUNT ; i + + ) { const ElemCat * elemcat = elements[i] ; int64_t * elemsignature ; uint64_t * sortsignature ; elemsignature = av_malloc_array ( elemcat - > elem_count , sizeof ( int64_t ) ) ; if ( ! elemsignature ) return AVERROR ( ENOMEM ) ; sortsignature = av_malloc_array ( elemcat - > elem_count , sizeof ( int64_t ) ) ; if ( ! sortsignature ) return AVERROR ( ENOMEM ) ; for ( j = 0 ; j < elemcat - > elem_count ; j + + ) { blocksum = 0 ; blocksize = 0 ; for ( k = 0 ; k < elemcat - > left_count ; k + + )",1
"int ff_rv34_decode_frame ( AVCodecContext * avctx , void * data , int * got_picture_ptr , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; RV34DecContext * r = avctx - > priv_data ; MpegEncContext * s = & r - > s ; AVFrame * pict = data ; SliceInfo si ; int i ; int slice_count ; const uint8_t * slices_hdr = NULL ; int last = 0 ; / * no supplementary picture * / if ( buf_size == 0 ) { / * special case for last picture * / if ( s - > low_delay==0 & & s - > next_picture_ptr ) { * pict = s - > next_picture_ptr - > f ; s - > next_picture_ptr = NULL ; * got_picture_ptr = 1 ; } return 0 ; } if ( ! avctx - > slice_count ) { slice_count = ( * buf + + ) + 1 ; slices_hdr = buf + 4 ; buf + = 8 * slice_count ; buf_size - = 1 + 8 * slice_count ; } else slice_count = avctx - > slice_count ; //parse first slice header to check whether this frame can be decoded if ( get_slice_offset ( avctx , slices_hdr , 0 ) < 0 || get_slice_offset ( avctx , slices_hdr , 0 ) > buf_size ) { av_log ( avctx , AV_LOG_ERROR , Slice offset is invalid\n ) ; } init_get_bits ( & s - > gb , buf + get_slice_offset ( avctx , slices_hdr , 0 ) , ( buf_size - get_slice_offset ( avctx , slices_hdr , 0 ) ) * 8 ) ; if ( r - > parse_slice_header ( r , & r - > s . gb , & si ) < 0 || si . start ) { av_log ( avctx , AV_LOG_ERROR , First slice header is incorrect\n ) ; } if ( ( ! s - > last_picture_ptr || ! s - > last_picture_ptr - > f . data[0] ) & & si . type == AV_PICTURE_TYPE_B ) { av_log ( avctx , AV_LOG_ERROR , Invalid decoder state : B - frame without reference data . \n ) ; } if ( ( avctx - > skip_frame > = AVDISCARD_NONREF & & si . type==AV_PICTURE_TYPE_B ) || ( avctx - > skip_frame > = AVDISCARD_NONKEY & & si . type ! =AV_PICTURE_TYPE_I ) || avctx - > skip_frame > = AVDISCARD_ALL ) return avpkt - > size ; / * first slice * / if ( si . start == 0 ) { if ( s - > mb_num_left > 0 ) { av_log ( avctx , AV_LOG_ERROR , New frame but still %d MB left . \n , s - > mb_num_left ) ; ff_er_frame_end ( s ) ; ff_MPV_frame_end ( s ) ; } if ( s - > width ! = si . width || s - > height ! = si . height ) { int err ; av_log ( s - > avctx , AV_LOG_WARNING , Changing dimensions to %dx%d\n , si . width , si . height ) ; s - > width = si . width ; s - > height = si . height ; avcodec_set_dimensions ( s - > avctx , s - > width , s - > height ) ; if ( ( err = ff_MPV_common_frame_size_change ( s ) ) < 0 ) return err ; if ( ( err = rv34_decoder_realloc ( r ) ) < 0 ) return err ; } s - > pict_type = si . type ? si . type : AV_PICTURE_TYPE_I ; if ( ff_MPV_frame_start ( s , s - > avctx ) < 0 ) return - 1 ; ff_er_frame_start ( s ) ; if ( ! r - > tmp_b_block_base ) { int i ; r - > tmp_b_block_base = av_malloc ( s - > linesize * 48 ) ; for ( i = 0 ; i < 2 ; i + + ) r - > tmp_b_block_y[i] = r - > tmp_b_block_base + i * 16 * s - > linesize ; for ( i = 0 ; i < 4 ; i + + ) r - > tmp_b_block_uv[i] = r - > tmp_b_block_base + 32 * s - > linesize + ( i > > 1 ) * 8 * s - > uvlinesize + ( i & 1 ) * 16 ; } r - > cur_pts = si . pts ; if ( s - > pict_type ! = AV_PICTURE_TYPE_B ) { r - > last_pts = r - > next_pts ; r - > next_pts = r - > cur_pts ; } else { int refdist = GET_PTS_DIFF ( r - > next_pts , r - > last_pts ) ; int dist0 = GET_PTS_DIFF ( r - > cur_pts , r - > last_pts ) ; int dist1 = GET_PTS_DIFF ( r - > next_pts , r - > cur_pts ) ; if ( ! refdist ) { r - > mv_weight1 = r - > mv_weight2 = r - > weight1 = r - > weight2 = 8192 ; r - > scaled_weight = 0 ; } else { r - > mv_weight1 = ( dist0 < < 14 ) / refdist ; r - > mv_weight2 = ( dist1 < < 14 ) / refdist ; if ( ( r - > mv_weight1|r - > mv_weight2 ) & 511 ) { r - > weight1 = r - > mv_weight1 ; r - > weight2 = r - > mv_weight2 ; r - > scaled_weight = 0 ; } else { r - > weight1 = r - > mv_weight1 > > 9 ; r - > weight2 = r - > mv_weight2 > > 9 ; r - > scaled_weight = 1 ; } } } s - > mb_x = s - > mb_y = 0 ; ff_thread_finish_setup ( s - > avctx ) ; } else if ( HAVE_THREADS & & ( s - > avctx - > active_thread_type & FF_THREAD_FRAME ) ) { av_log ( s - > avctx , AV_LOG_ERROR , Decoder needs full frames in frame multithreading mode ( start MB is %d ) . \n , si . start ) ; } for ( i = 0 ; i < slice_count ; i + + ) { int offset = get_slice_offset ( avctx , slices_hdr , i ) ; int size ; if ( i + 1 == slice_count ) size = buf_size - offset ; else size = get_slice_offset ( avctx , slices_hdr , i + 1 ) - offset ; if ( offset < 0 || offset > buf_size ) { av_log ( avctx , AV_LOG_ERROR , Slice offset is invalid\n ) ; break ; } r - > si . end = s - > mb_width * s - > mb_height ; s - > mb_num_left = r - > s . mb_x + r - > s . mb_y * r - > s . mb_width - r - > si . start ; if",1
"static int flic_decode_frame_15_16BPP ( AVCodecContext * avctx , void * data , int * got_frame , const uint8_t * buf , int buf_size ) { / * Note , the only difference between the 15Bpp and 16Bpp * / / * Format is the pixel format , the packets are processed the same . * / FlicDecodeContext * s = avctx - > priv_data ; GetByteContext g2 ; int pixel_ptr ; unsigned char palette_idx1 ; unsigned int frame_size ; int num_chunks ; unsigned int chunk_size ; int chunk_type ; int i , j , ret ; int lines ; int compressed_lines ; signed short line_packets ; int y_ptr ; int byte_run ; int pixel_skip ; int pixel_countdown ; unsigned char * pixels ; int pixel ; unsigned int pixel_limit ; bytestream2_init ( & g2 , buf , buf_size ) ; if ( ( ret = ff_reget_buffer ( avctx , s - > frame ) ) < 0 ) return ret ; pixels = s - > frame - > data[0] ; pixel_limit = s - > avctx - > height * s - > frame - > linesize[0] ; frame_size = bytestream2_get_le32 ( & g2 ) ; bytestream2_skip ( & g2 , 2 ) ; / * skip the magic number * / num_chunks = bytestream2_get_le16 ( & g2 ) ; bytestream2_skip ( & g2 , 8 ) ; / * skip padding * / if ( frame_size > buf_size ) frame_size = buf_size ; frame_size - = 16 ; / * iterate through the chunks * / while ( ( frame_size > 0 ) & & ( num_chunks > 0 ) & & bytestream2_get_bytes_left ( & g2 ) > = 4 ) { int stream_ptr_after_chunk ; chunk_size = bytestream2_get_le32 ( & g2 ) ; if ( chunk_size > frame_size ) { av_log ( avctx , AV_LOG_WARNING , Invalid chunk_size = %u > frame_size = %u\n , chunk_size , frame_size ) ; chunk_size = frame_size ; } stream_ptr_after_chunk = bytestream2_tell ( & g2 ) - 4 + chunk_size ; chunk_type = bytestream2_get_le16 ( & g2 ) ; switch ( chunk_type ) { case FLI_256_COLOR : case FLI_COLOR : / * For some reason , it seems that non - palettized flics do * include one of these chunks in their first frame . * Why I do not know , it seems rather extraneous . * / ff_dlog ( avctx , Unexpected Palette chunk %d in non - palettized FLC\n , chunk_type ) ; bytestream2_skip ( & g2 , chunk_size - 6 ) ; break ; case FLI_DELTA : case FLI_DTA_LC : y_ptr = 0 ; compressed_lines = bytestream2_get_le16 ( & g2 ) ; while ( compressed_lines > 0 ) { if ( bytestream2_tell ( & g2 ) + 2 > stream_ptr_after_chunk ) break ; line_packets = bytestream2_get_le16 ( & g2 ) ; if ( line_packets < 0 ) { line_packets = - line_packets ; y_ptr + = line_packets * s - > frame - > linesize[0] ; } else { compressed_lines - - ; pixel_ptr = y_ptr ; CHECK_PIXEL_PTR ( 0 ) ; pixel_countdown = s - > avctx - > width ; for ( i = 0 ; i < line_packets ; i + + ) { / * account for the skip bytes * / if ( bytestream2_tell ( & g2 ) + 2 > stream_ptr_after_chunk ) break ; pixel_skip = bytestream2_get_byte ( & g2 ) ; pixel_ptr + = ( pixel_skip * 2 ) ; / * Pixel is 2 bytes wide * / pixel_countdown - = pixel_skip ; byte_run = sign_extend ( bytestream2_get_byte ( & g2 ) , 8 ) ; if ( byte_run < 0 ) { byte_run = - byte_run ; pixel = bytestream2_get_le16 ( & g2 ) ; CHECK_PIXEL_PTR ( 2 * byte_run ) ; for ( j = 0 ; j < byte_run ; j + + , pixel_countdown - = 2 ) { * ( ( signed short * ) ( & pixels[pixel_ptr] ) ) = pixel ; pixel_ptr + = 2 ; } } else { if ( bytestream2_tell ( & g2 ) + 2 * byte_run > stream_ptr_after_chunk ) break ; CHECK_PIXEL_PTR ( 2 * byte_run ) ; for ( j = 0 ; j < byte_run ; j + + , pixel_countdown - - ) { * ( ( signed short * ) ( & pixels[pixel_ptr] ) ) = bytestream2_get_le16 ( & g2 ) ; pixel_ptr + = 2 ; } } } y_ptr + = s - > frame - > linesize[0] ; } } break ; case FLI_LC : av_log ( avctx , AV_LOG_ERROR , Unexpected FLI_LC chunk in non - palettized FLC\n ) ; bytestream2_skip ( & g2 , chunk_size - 6 ) ; break ; case FLI_BLACK : / * set the whole frame to 0x0000 which is black in both 15Bpp and 16Bpp modes . * / memset ( pixels , 0x0000 , s - > frame - > linesize[0] * s - > avctx - > height ) ; break ; case FLI_BRUN : y_ptr = 0 ; for ( lines = 0 ; lines < s - > avctx - > height ; lines + + ) { pixel_ptr = y_ptr ; / * disregard the line packets ; instead , iterate through all * pixels on a row * / bytestream2_skip ( & g2 , 1 ) ; pixel_countdown = ( s - > avctx - > width * 2 ) ; while ( pixel_countdown > 0 ) { if ( bytestream2_tell ( & g2 ) + 1 > stream_ptr_after_chunk ) break ; byte_run = sign_extend ( bytestream2_get_byte ( & g2 ) , 8 ) ; if ( byte_run > 0 ) { palette_idx1 = bytestream2_get_byte ( & g2 ) ; CHECK_PIXEL_PTR ( byte_run ) ; for ( j = 0 ; j < byte_run ; j + + ) { pixels[pixel_ptr + + ] = palette_idx1 ; pixel_countdown - - ; if ( pixel_countdown < 0 ) av_log ( avctx , AV_LOG_ERROR , pixel_countdown < 0 ( %d ) ( linea%d ) \n , pixel_countdown , lines ) ; } } else { / * copy bytes if byte_run < 0 * / byte_run = - byte_run ; if ( bytestream2_tell ( & g2 ) + byte_run > stream_ptr_after_chunk ) break ; CHECK_PIXEL_PTR ( byte_run ) ; for ( j = 0 ; j < byte_run ; j + + ) { palette_idx1 = bytestream2_get_byte ( & g2 ) ; pixels[pixel_ptr + + ] = palette_idx1 ; pixel_countdown - - ; if ( pixel_countdown < 0 ) av_log ( avctx , AV_LOG_ERROR , pixel_countdown < 0 ( %d ) at line %d\n , pixel_countdown , lines ) ; } } } / * Now FLX is strange , in that it is byte as opposed to pixel run length compressed . * This does not give us any good opportunity to perform word endian conversion * during decompression . So if it is required ( i . e . , this is not a LE target , we do * a second pass over the line here , swapping the bytes . * / if HAVE_BIGENDIAN pixel_ptr =",1
"static int w64_read_header ( AVFormatContext * s , AVFormatParameters * ap ) { int64_t size ; AVIOContext * pb = s - > pb ; WAVContext * wav = s - > priv_data ; AVStream * st ; uint8_t guid[16] ; avio_read ( pb , guid , 16 ) ; if ( memcmp ( guid , guid_riff , 16 ) ) return - 1 ; if ( avio_rl64 ( pb ) < 16 + 8 + 16 + 8 + 16 + 8 ) / * riff + wave + fmt + sizes * / return - 1 ; avio_read ( pb , guid , 16 ) ; if ( memcmp ( guid , guid_wave , 16 ) ) { av_log ( s , AV_LOG_ERROR , could not find wave guid\n ) ; return - 1 ; } size = find_guid ( pb , guid_fmt ) ; if ( size < 0 ) { av_log ( s , AV_LOG_ERROR , could not find fmt guid\n ) ; return - 1 ; } st = av_new_stream ( s , 0 ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; / * subtract chunk header size - normal wav file doesn ' t count it * / ff_get_wav_header ( pb , st - > codec , size - 24 ) ; avio_skip ( pb , FFALIGN ( size , INT64_C ( 8 ) ) - size ) ; st - > need_parsing = AVSTREAM_PARSE_FULL ; av_set_pts_info ( st , 64 , 1 , st - > codec - > sample_rate ) ; size = find_guid ( pb , guid_data ) ; if ( size < 0 ) { av_log ( s , AV_LOG_ERROR , could not find data guid\n ) ; return - 1 ; } wav - > data_end = avio_tell ( pb ) + size - 24 ; wav - > w64 = 1 ; return 0 ; }",1
"void rgb15tobgr15 ( const uint8_t * src , uint8_t * dst , long src_size ) { long i ; long num_pixels = src_size > > 1 ; for ( i=0 ; i < num_pixels ; i + + ) { unsigned b , g , r ; register uint16_t rgb ; rgb = src[2 * i] ; r = rgb & 0x1F ; g = ( rgb & 0x3E0 ) > > 5 ; b = ( rgb & 0x7C00 ) > > 10 ; dst[2 * i] = ( b & 0x1F ) | ( ( g & 0x1F ) < < 5 ) | ( ( r & 0x1F ) < < 10 ) ; } }",1
"static int vp8_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { VP8Context * s = avctx - > priv_data ; int ret , mb_x , mb_y , i , y , referenced ; enum AVDiscard skip_thresh ; AVFrame * av_uninit ( curframe ) , * prev_frame ; release_queued_segmaps ( s , 0 ) ; if ( ( ret = decode_frame_header ( s , avpkt - > data , avpkt - > size ) ) < 0 ) return ret ; prev_frame = s - > framep[VP56_FRAME_CURRENT] ; referenced = s - > update_last || s - > update_golden == VP56_FRAME_CURRENT || s - > update_altref == VP56_FRAME_CURRENT ; skip_thresh = ! referenced ? AVDISCARD_NONREF : ! s - > keyframe ? AVDISCARD_NONKEY : AVDISCARD_ALL ; if ( avctx - > skip_frame > = skip_thresh ) { s - > invisible = 1 ; goto skip_decode ; } s - > deblock_filter = s - > filter . level & & avctx - > skip_loop_filter < skip_thresh ; // release no longer referenced frames for ( i = 0 ; i < 5 ; i + + ) if ( s - > frames[i] . data[0] & & & s - > frames[i] ! = prev_frame & & & s - > frames[i] ! = s - > framep[VP56_FRAME_PREVIOUS] & & & s - > frames[i] ! = s - > framep[VP56_FRAME_GOLDEN] & & & s - > frames[i] ! = s - > framep[VP56_FRAME_GOLDEN2] ) vp8_release_frame ( s , & s - > frames[i] , 1 , 0 ) ; // find a free buffer for ( i = 0 ; i < 5 ; i + + ) if ( & s - > frames[i] ! = prev_frame & & & s - > frames[i] ! = s - > framep[VP56_FRAME_PREVIOUS] & & & s - > frames[i] ! = s - > framep[VP56_FRAME_GOLDEN] & & & s - > frames[i] ! = s - > framep[VP56_FRAME_GOLDEN2] ) { curframe = s - > framep[VP56_FRAME_CURRENT] = & s - > frames[i] ; break ; } if ( i == 5 ) { av_log ( avctx , AV_LOG_FATAL , Ran out of free frames ! \n ) ; abort ( ) ; } if ( curframe - > data[0] ) vp8_release_frame ( s , curframe , 1 , 0 ) ; curframe - > key_frame = s - > keyframe ; curframe - > pict_type = s - > keyframe ? AV_PICTURE_TYPE_I : AV_PICTURE_TYPE_P ; curframe - > reference = referenced ? 3 : 0 ; if ( ( ret = vp8_alloc_frame ( s , curframe ) ) ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed ! \n ) ; return ret ; } // check if golden and altref are swapped if ( s - > update_altref ! = VP56_FRAME_NONE ) { s - > next_framep[VP56_FRAME_GOLDEN2] = s - > framep[s - > update_altref] ; } else { s - > next_framep[VP56_FRAME_GOLDEN2] = s - > framep[VP56_FRAME_GOLDEN2] ; } if ( s - > update_golden ! = VP56_FRAME_NONE ) { s - > next_framep[VP56_FRAME_GOLDEN] = s - > framep[s - > update_golden] ; } else { s - > next_framep[VP56_FRAME_GOLDEN] = s - > framep[VP56_FRAME_GOLDEN] ; } if ( s - > update_last ) { s - > next_framep[VP56_FRAME_PREVIOUS] = curframe ; } else { s - > next_framep[VP56_FRAME_PREVIOUS] = s - > framep[VP56_FRAME_PREVIOUS] ; } s - > next_framep[VP56_FRAME_CURRENT] = curframe ; ff_thread_finish_setup ( avctx ) ; // Given that arithmetic probabilities are updated every frame , it ' s quite likely // that the values we have on a random interframe are complete junk if we didn ' t // start decode on a keyframe . So just don ' t display anything rather than junk . if ( ! s - > keyframe & & ( ! s - > framep[VP56_FRAME_PREVIOUS] || ! s - > framep[VP56_FRAME_GOLDEN] || ! s - > framep[VP56_FRAME_GOLDEN2] ) ) { av_log ( avctx , AV_LOG_WARNING , Discarding interframe without a prior keyframe ! \n ) ; return AVERROR_INVALIDDATA ; } s - > linesize = curframe - > linesize[0] ; s - > uvlinesize = curframe - > linesize[1] ; if ( ! s - > edge_emu_buffer ) s - > edge_emu_buffer = av_malloc ( 21 * s - > linesize ) ; memset ( s - > top_nnz , 0 , s - > mb_width * sizeof ( * s - > top_nnz ) ) ; / * Zero macroblock structures for top/top - left prediction from outside the frame . * / memset ( s - > macroblocks + s - > mb_height * 2 - 1 , 0 , ( s - > mb_width + 1 ) * sizeof ( * s - > macroblocks ) ) ; // top edge of 127 for intra prediction if ( ! ( avctx - > flags & CODEC_FLAG_EMU_EDGE ) ) { s - > top_border[0][15] = s - > top_border[0][23] = 127 ; memset ( s - > top_border[1] - 1 , 127 , s - > mb_width * sizeof ( * s - > top_border ) + 1 ) ; } memset ( s - > ref_count , 0 , sizeof ( s - > ref_count ) ) ; if ( s - > keyframe ) memset ( s - > intra4x4_pred_mode_top , DC_PRED , s - > mb_width * 4 ) ; define MARGIN ( 16 < < 2 ) s - > mv_min . y = - MARGIN ; s - > mv_max . y = ( ( s - > mb_height - 1 ) < < 6 ) + MARGIN ; for ( mb_y = 0 ; mb_y < s - > mb_height ; mb_y + + ) { VP56RangeCoder * c = & s - > coeff_partition[mb_y & ( s - > num_coeff_partitions - 1 ) ] ; VP8Macroblock * mb = s - > macroblocks + ( s - > mb_height - mb_y - 1 ) * 2 ; int mb_xy = mb_y * s - > mb_width ; uint8_t * dst[3] = { curframe - > data[0] + 16 * mb_y * s - > linesize , curframe - > data[1] + 8 * mb_y * s - > uvlinesize , curframe - > data[2] + 8 * mb_y * s - > uvlinesize } ; memset ( mb - 1 , 0 , sizeof ( * mb ) ) ; // zero left macroblock memset ( s - > left_nnz , 0 , sizeof ( s - > left_nnz ) ) ; AV_WN32A ( s - > intra4x4_pred_mode_left , DC_PRED * 0x01010101 ) ; // left edge of 129 for intra prediction if ( ! ( avctx - > flags & CODEC_FLAG_EMU_EDGE ) ) { for ( i = 0 ; i < 3 ; i + + ) for ( y = 0 ; y < 16 > > ! ! i ; y + + ) dst[i][y * curframe - > linesize[i] - 1] = 129 ; if ( mb_y == 1 ) // top",1
"static void vp7_luma_dc_wht_c ( int16_t block[4][4][16] , int16_t dc[16] ) { int i , a1 , b1 , c1 , d1 ; int16_t tmp[16] ; for ( i = 0 ; i < 4 ; i + + ) { a1 = ( dc[i * 4 + 0] + dc[i * 4 + 2] ) * 23170 ; b1 = ( dc[i * 4 + 0] - dc[i * 4 + 2] ) * 23170 ; c1 = dc[i * 4 + 1] * 12540 - dc[i * 4 + 3] * 30274 ; d1 = dc[i * 4 + 1] * 30274 + dc[i * 4 + 3] * 12540 ; tmp[i * 4 + 0] = ( a1 + d1 ) > > 14 ; tmp[i * 4 + 3] = ( a1 - d1 ) > > 14 ; tmp[i * 4 + 1] = ( b1 + c1 ) > > 14 ; tmp[i * 4 + 2] = ( b1 - c1 ) > > 14 ; } for ( i = 0 ; i < 4 ; i + + ) { a1 = ( tmp[i + 0] + tmp[i + 8] ) * 23170 ; b1 = ( tmp[i + 0] - tmp[i + 8] ) * 23170 ; c1 = tmp[i + 4] * 12540 - tmp[i + 12] * 30274 ; d1 = tmp[i + 4] * 30274 + tmp[i + 12] * 12540 ; AV_ZERO64 ( dc + i * 4 ) ; block[0][i][0] = ( a1 + d1 + 0x20000 ) > > 18 ; block[3][i][0] = ( a1 - d1 + 0x20000 ) > > 18 ; block[1][i][0] = ( b1 + c1 + 0x20000 ) > > 18 ; block[2][i][0] = ( b1 - c1 + 0x20000 ) > > 18 ; } }",1
"static void generate_noise ( G723_1_Context * p ) { int i , j , idx , t ; int off[SUBFRAMES] ; int signs[SUBFRAMES / 2 * 11] , pos[SUBFRAMES / 2 * 11] ; int tmp[SUBFRAME_LEN * 2] ; int16_t * vector_ptr ; int64_t sum ; int b0 , c , delta , x , shift ; p - > pitch_lag[0] = cng_rand ( & p - > cng_random_seed , 21 ) + 123 ; p - > pitch_lag[1] = cng_rand ( & p - > cng_random_seed , 19 ) + 123 ; for ( i = 0 ; i < SUBFRAMES ; i + + ) { p - > subframe[i] . ad_cb_gain = cng_rand ( & p - > cng_random_seed , 50 ) + 1 ; p - > subframe[i] . ad_cb_lag = cng_adaptive_cb_lag[i] ; } for ( i = 0 ; i < SUBFRAMES / 2 ; i + + ) { t = cng_rand ( & p - > cng_random_seed , 1 < < 13 ) ; off[i * 2] = t & 1 ; off[i * 2 + 1] = ( ( t > > 1 ) & 1 ) + SUBFRAME_LEN ; t > > = 2 ; for ( j = 0 ; j < 11 ; j + + ) { signs[i * 11 + j] = ( t & 1 ) * 2 - 1 < < 14 ; t > > = 1 ; } } idx = 0 ; for ( i = 0 ; i < SUBFRAMES ; i + + ) { for ( j = 0 ; j < SUBFRAME_LEN / 2 ; j + + ) tmp[j] = j ; t = SUBFRAME_LEN / 2 ; for ( j = 0 ; j < pulses[i] ; j + + , idx + + ) { int idx2 = cng_rand ( & p - > cng_random_seed , t ) ; pos[idx] = tmp[idx2] * 2 + off[i] ; tmp[idx2] = tmp[ - - t] ; } } vector_ptr = p - > audio + LPC_ORDER ; memcpy ( vector_ptr , p - > prev_excitation , PITCH_MAX * sizeof ( * p - > excitation ) ) ; for ( i = 0 ; i < SUBFRAMES ; i + = 2 ) { ff_g723_1_gen_acb_excitation ( vector_ptr , vector_ptr , p - > pitch_lag[i > > 1] , & p - > subframe[i] , p - > cur_rate ) ; ff_g723_1_gen_acb_excitation ( vector_ptr + SUBFRAME_LEN , vector_ptr + SUBFRAME_LEN , p - > pitch_lag[i > > 1] , & p - > subframe[i + 1] , p - > cur_rate ) ; t = 0 ; for ( j = 0 ; j < SUBFRAME_LEN * 2 ; j + + ) t |= FFABS ( vector_ptr[j] ) ; t = FFMIN ( t , 0x7FFF ) ; if ( ! t ) { shift = 0 ; } else { shift = - 10 + av_log2 ( t ) ; if ( shift < - 2 ) shift = - 2 ; } sum = 0 ; if ( shift < 0 ) { for ( j = 0 ; j < SUBFRAME_LEN * 2 ; j + + ) { t = vector_ptr[j] < < - shift ; sum + = t * t ; tmp[j] = t ; } } else { for ( j = 0 ; j < SUBFRAME_LEN * 2 ; j + + ) { t = vector_ptr[j] > > shift ; sum + = t * t ; tmp[j] = t ; } } b0 = 0 ; for ( j = 0 ; j < 11 ; j + + ) b0 + = tmp[pos[ ( i / 2 ) * 11 + j]] * signs[ ( i / 2 ) * 11 + j] ; b0 = b0 * 2 * 2979LL + ( 1 < < 29 ) > > 30 ; // approximated division by 11 c = p - > cur_gain * ( p - > cur_gain * SUBFRAME_LEN > > 5 ) ; if ( shift * 2 + 3 > = 0 ) c > > = shift * 2 + 3 ; else c < < = - ( shift * 2 + 3 ) ; c = ( av_clipl_int32 ( sum < < 1 ) - c ) * 2979LL > > 15 ; delta = b0 * b0 * 2 - c ; if ( delta < = 0 ) { x = - b0 ; } else { delta = square_root ( delta ) ; x = delta - b0 ; t = delta + b0 ; if ( FFABS ( t ) < FFABS ( x ) ) x = - t ; } shift + + ; if ( shift < 0 ) x > > = - shift ; else x < < = shift ; x = av_clip ( x , - 10000 , 10000 ) ; for ( j = 0 ; j < 11 ; j + + ) { idx = ( i / 2 ) * 11 + j ; vector_ptr[pos[idx]] = av_clip_int16 ( vector_ptr[pos[idx]] + ( x * signs[idx] > > 15 ) ) ; } / * copy decoded data to serve as a history for the next decoded subframes * / memcpy ( vector_ptr + PITCH_MAX , vector_ptr , sizeof ( * vector_ptr ) * SUBFRAME_LEN * 2 ) ; vector_ptr + = SUBFRAME_LEN * 2 ; } / * Save the excitation for the next frame * / memcpy ( p - > prev_excitation , p - > audio + LPC_ORDER + FRAME_LEN , PITCH_MAX * sizeof ( * p - > excitation ) ) ; }",1
"int av_read_pause ( AVFormatContext * s ) { if ( s - > iformat - > read_pause ) return s - > iformat - > read_pause ( s ) ; if ( s - > pb & & s - > pb - > read_pause ) return av_url_read_fpause ( s - > pb , 1 ) ; return AVERROR ( ENOSYS ) ; }",0
"static int _get_transform_coeffs ( uint8_t * exps , uint8_t * bap , float chcoeff , float * samples , int start , int end , int dith_flag , GetBitContext * gb , dither_state * state ) { int16_t mantissa ; int i ; int gcode ; mant_group l3_grp , l5_grp , l11_grp ; for ( i = 0 ; i < 3 ; i + + ) l3_grp . gcodes[i] = l5_grp . gcodes[i] = l11_grp . gcodes[i] = - 1 ; l3_grp . gcptr = l5_grp . gcptr = 3 ; l11_grp . gcptr = 2 ; i = 0 ; while ( i < start ) samples[i + + ] = 0 ; for ( i = start ; i < end ; i + + ) { switch ( bap[i] ) { case 0 : if ( ! dith_flag ) mantissa = 0 ; else mantissa = dither_int16 ( state ) ; samples[i] = to_float ( exps[i] , mantissa ) * chcoeff ; break ; case 1 : if ( l3_grp . gcptr > 2 ) { gcode = get_bits ( gb , qntztab[1] ) ; if ( gcode > 26 ) return - 1 ; l3_grp . gcodes[0] = gcode / 9 ; l3_grp . gcodes[1] = ( gcode % 9 ) / 3 ; l3_grp . gcodes[2] = ( gcode % 9 ) % 3 ; l3_grp . gcptr = 0 ; } mantissa = l3_q_tab[l3_grp . gcodes[l3_grp . gcptr + + ]] ; samples[i] = to_float ( exps[i] , mantissa ) * chcoeff ; break ; case 2 : if ( l5_grp . gcptr > 2 ) { gcode = get_bits ( gb , qntztab[2] ) ; if ( gcode > 124 ) return - 1 ; l5_grp . gcodes[0] = gcode / 25 ; l5_grp . gcodes[1] = ( gcode % 25 ) / 5 ; l5_grp . gcodes[2] = ( gcode % 25 ) % 5 ; l5_grp . gcptr = 0 ; } mantissa = l5_q_tab[l5_grp . gcodes[l5_grp . gcptr + + ]] ; samples[i] = to_float ( exps[i] , mantissa ) * chcoeff ; break ; case 3 : mantissa = get_bits ( gb , qntztab[3] ) ; if ( mantissa > 6 ) return - 1 ; mantissa = l7_q_tab[mantissa] ; samples[i] = to_float ( exps[i] , mantissa ) ; break ; case 4 : if ( l11_grp . gcptr > 1 ) { gcode = get_bits ( gb , qntztab[4] ) ; if ( gcode > 120 ) return - 1 ; l11_grp . gcodes[0] = gcode / 11 ; l11_grp . gcodes[1] = gcode % 11 ; } mantissa = l11_q_tab[l11_grp . gcodes[l11_grp . gcptr + + ]] ; samples[i] = to_float ( exps[i] , mantissa ) * chcoeff ; break ; case 5 : mantissa = get_bits ( gb , qntztab[5] ) ; if ( mantissa > 14 ) return - 1 ; mantissa = l15_q_tab[mantissa] ; samples[i] = to_float ( exps[i] , mantissa ) * chcoeff ; break ; default : mantissa = get_bits ( gb , qntztab[bap[i]] ) < < ( 16 - qntztab[bap[i]] ) ; samples[i] = to_float ( exps[i] , mantissa ) * chcoeff ; break ; } } i = end ; while ( i < 256 ) samples[i + + ] = 0 ; return 0 ; }",0
"static void DEF ( avg , pixels8_y2 ) ( uint8_t * block , const uint8_t * pixels , ptrdiff_t line_size , int h ) { MOVQ_BFE ( mm6 ) ; __asm__ volatile ( lea ( %3 , %3 ) , %% REG_a \n\t movq ( %1 ) , %%mm0 \n\t . p2align 3 \n\t 1 : \n\t movq ( %1 , %3 ) , %%mm1 \n\t movq ( %1 , %% REG_a ) , %%mm2 \n\t PAVGBP ( %%mm1 , %%mm0 , %%mm4 , %%mm2 , %%mm1 , %%mm5 ) movq ( %2 ) , %%mm3 \n\t PAVGB_MMX ( %%mm3 , %%mm4 , %%mm0 , %%mm6 ) movq ( %2 , %3 ) , %%mm3 \n\t PAVGB_MMX ( %%mm3 , %%mm5 , %%mm1 , %%mm6 ) movq %%mm0 , ( %2 ) \n\t movq %%mm1 , ( %2 , %3 ) \n\t add %% REG_a , %1 \n\t add %% REG_a , %2 \n\t movq ( %1 , %3 ) , %%mm1 \n\t movq ( %1 , %% REG_a ) , %%mm0 \n\t PAVGBP ( %%mm1 , %%mm2 , %%mm4 , %%mm0 , %%mm1 , %%mm5 ) movq ( %2 ) , %%mm3 \n\t PAVGB_MMX ( %%mm3 , %%mm4 , %%mm2 , %%mm6 ) movq ( %2 , %3 ) , %%mm3 \n\t PAVGB_MMX ( %%mm3 , %%mm5 , %%mm1 , %%mm6 ) movq %%mm2 , ( %2 ) \n\t movq %%mm1 , ( %2 , %3 ) \n\t add %% REG_a , %1 \n\t add %% REG_a , %2 \n\t subl 4 , %0 \n\t jnz 1b \n\t : + g ( h ) , + S ( pixels ) , + D ( block ) : r ( ( x86_reg ) line_size ) : REG_a , memory ) ; }",0
"static void decode_array_0000 ( APEContext * ctx , GetBitContext * gb , int32_t * out , APERice * rice , int blockstodecode ) { int i ; int ksummax , ksummin ; rice - > ksum = 0 ; for ( i = 0 ; i < 5 ; i + + ) { out[i] = get_rice_ook ( & ctx - > gb , 10 ) ; rice - > ksum + = out[i] ; } rice - > k = av_log2 ( rice - > ksum / 10 ) + 1 ; for ( ; i < 64 ; i + + ) { out[i] = get_rice_ook ( & ctx - > gb , rice - > k ) ; rice - > ksum + = out[i] ; rice - > k = av_log2 ( rice - > ksum / ( ( i + 1 ) * 2 ) ) + 1 ; } ksummax = 1 < < rice - > k + 7 ; ksummin = rice - > k ? ( 1 < < rice - > k + 6 ) : 0 ; for ( ; i < blockstodecode ; i + + ) { out[i] = get_rice_ook ( & ctx - > gb , rice - > k ) ; rice - > ksum + = out[i] - out[i - 64] ; while ( rice - > ksum < ksummin ) { rice - > k - - ; ksummin = rice - > k ? ksummin > > 1 : 0 ; ksummax > > = 1 ; } while ( rice - > ksum > = ksummax ) { rice - > k + + ; if ( rice - > k > 24 ) ksummax < < = 1 ; ksummin = ksummin ? ksummin < < 1 : 128 ; } } for ( i = 0 ; i < blockstodecode ; i + + ) { if ( out[i] & 1 ) out[i] = ( out[i] > > 1 ) + 1 ; else out[i] = - ( out[i] > > 1 ) ; } }",1
"static void filter_mb_edgeh ( H264Context * h , uint8_t * pix , int stride , int16_t bS[4] , int qp ) { int i , d ; const int index_a = qp + h - > slice_alpha_c0_offset ; const int alpha = ( alpha_table + 52 ) [index_a] ; const int beta = ( beta_table + 52 ) [qp + h - > slice_beta_offset] ; const int pix_next = stride ; if ( bS[0] < 4 ) { int8_t tc[4] ; for ( i=0 ; i < 4 ; i + + ) tc[i] = bS[i] ? ( tc0_table + 52 ) [index_a][bS[i] - 1] : - 1 ; h - > s . dsp . h264_v_loop_filter_luma ( pix , stride , alpha , beta , tc ) ; } else { h - > s . dsp . h264_v_loop_filter_luma_intra ( pix , stride , alpha , beta ) ; } }",0
"static int mov_seek_stream ( AVFormatContext * s , AVStream * st , int64_t timestamp , int flags ) { MOVStreamContext * sc = st - > priv_data ; int sample , time_sample ; int i ; sample = av_index_search_timestamp ( st , timestamp , flags ) ; av_log ( s , AV_LOG_TRACE , stream %d , timestamp % PRId64 , sample %d\n , st - > index , timestamp , sample ) ; if ( sample < 0 & & st - > nb_index_entries & & timestamp < st - > index_entries[0] . timestamp ) sample = 0 ; if ( sample < 0 ) / * not sure what to do * / return AVERROR_INVALIDDATA ; sc - > current_sample = sample ; av_log ( s , AV_LOG_TRACE , stream %d , found sample %d\n , st - > index , sc - > current_sample ) ; / * adjust ctts index * / if ( sc - > ctts_data ) { time_sample = 0 ; for ( i = 0 ; i < sc - > ctts_count ; i + + ) { int next = time_sample + sc - > ctts_data[i] . count ; if ( next > sc - > current_sample ) { sc - > ctts_index = i ; sc - > ctts_sample = sc - > current_sample - time_sample ; break ; } time_sample = next ; } } / * adjust stsd index * / time_sample = 0 ; for ( i = 0 ; i < sc - > stsc_count ; i + + ) { int next = time_sample + mov_get_stsc_samples ( sc , i ) ; if ( next > sc - > current_sample ) { sc - > stsc_index = i ; sc - > stsc_sample = sc - > current_sample - time_sample ; break ; } time_sample = next ; } return sample ; }",1
"static int advanced_decode_i_mbs ( VC9Context * v ) { MpegEncContext * s = & v - > s ; GetBitContext * gb = & v - > s . gb ; int mqdiff , mquant , current_mb = 0 , over_flags_mb = 0 ; for ( s - > mb_y=0 ; s - > mb_y < s - > mb_height ; s - > mb_y + + ) { for ( s - > mb_x=0 ; s - > mb_x < s - > mb_width ; s - > mb_x + + ) { if ( v - > ac_pred_plane . is_raw ) s - > ac_pred = get_bits ( gb , 1 ) ; else s - > ac_pred = v - > ac_pred_plane . data[current_mb] ; if ( v - > condover == 3 & & v - > over_flags_plane . is_raw ) over_flags_mb = get_bits ( gb , 1 ) ; GET_MQUANT ( ) ; / * TODO : lots * / } current_mb + + ; } return 0 ; }",1
"static void imdct12 ( int * out , int * in ) { int in0 , in1 , in2 , in3 , in4 , in5 , t1 , t2 ; in0= in[0 * 3] < < 5 ; in1= ( in[1 * 3] + in[0 * 3] ) < < 5 ; in2= ( in[2 * 3] + in[1 * 3] ) < < 5 ; in3= ( in[3 * 3] + in[2 * 3] ) < < 5 ; in4= ( in[4 * 3] + in[3 * 3] ) < < 5 ; in5= ( in[5 * 3] + in[4 * 3] ) < < 5 ; in5 + = in3 ; in3 + = in1 ; in2= MULH ( 2 * in2 , C3 ) ; in3= MULH ( 2 * in3 , C3 ) ; t1 = in0 - in4 ; t2 = MULL ( in1 - in5 , icos36[4] ) ; out[ 7]= out[10]= t1 + t2 ; out[ 1]= out[ 4]= t1 - t2 ; in0 + = in4 > > 1 ; in4 = in0 + in2 ; in1 + = in5 > > 1 ; in5 = MULL ( in1 + in3 , icos36[1] ) ; out[ 8]= out[ 9]= in4 + in5 ; out[ 2]= out[ 3]= in4 - in5 ; in0 - = in2 ; in1 = MULL ( in1 - in3 , icos36[7] ) ; out[ 0]= out[ 5]= in0 - in1 ; out[ 6]= out[11]= in0 + in1 ; }",1
"static int altivec_uyvy_rgb32 ( SwsContext * c , unsigned char * * in , int * instrides , int srcSliceY , int srcSliceH , unsigned char * * oplanes , int * outstrides ) { int w = c - > srcW ; int h = srcSliceH ; int i , j ; vector unsigned char uyvy ; vector signed short Y , U , V ; vector signed short R0 , G0 , B0 , R1 , G1 , B1 ; vector unsigned char R , G , B ; vector unsigned char * out ; ubyte * img ; img = in[0] ; out = ( vector unsigned char * ) ( oplanes[0] + srcSliceY * outstrides[0] ) ; for ( i=0 ; i < h ; i + + ) { for ( j=0 ; j < w/16 ; j + + ) { uyvy = vec_ld ( 0 , img ) ; U = ( vector signed short ) vec_perm ( uyvy , ( vector unsigned char ) AVV ( 0 ) , demux_u ) ; V = ( vector signed short ) vec_perm ( uyvy , ( vector unsigned char ) AVV ( 0 ) , demux_v ) ; Y = ( vector signed short ) vec_perm ( uyvy , ( vector unsigned char ) AVV ( 0 ) , demux_y ) ; cvtyuvtoRGB ( c , Y , U , V , & R0 , & G0 , & B0 ) ; uyvy = vec_ld ( 16 , img ) ; U = ( vector signed short ) vec_perm ( uyvy , ( vector unsigned char ) AVV ( 0 ) , demux_u ) ; V = ( vector signed short ) vec_perm ( uyvy , ( vector unsigned char ) AVV ( 0 ) , demux_v ) ; Y = ( vector signed short ) vec_perm ( uyvy , ( vector unsigned char ) AVV ( 0 ) , demux_y ) ; cvtyuvtoRGB ( c , Y , U , V , & R1 , & G1 , & B1 ) ; R = vec_packclp ( R0 , R1 ) ; G = vec_packclp ( G0 , G1 ) ; B = vec_packclp ( B0 , B1 ) ; // vec_mstbgr24 ( R , G , B , out ) ; out_rgba ( R , G , B , out ) ; img + = 32 ; } } return srcSliceH ; }",1
"static void start_frame ( AVFilterLink * inlink , AVFilterBufferRef * picref ) { PixdescTestContext * priv = inlink - > dst - > priv ; AVFilterLink * outlink = inlink - > dst - > outputs[0] ; AVFilterBufferRef * outpicref ; int i ; outlink - > out_buf = avfilter_get_video_buffer ( outlink , AV_PERM_WRITE , outlink - > w , outlink - > h ) ; outpicref = outlink - > out_buf ; avfilter_copy_buffer_ref_props ( outpicref , picref ) ; for ( i = 0 ; i < 4 ; i + + ) { int h = outlink - > h ; h = i == 1 || i == 2 ? h > > priv - > pix_desc - > log2_chroma_h : h ; if ( outpicref - > data[i] ) { uint8_t * data = outpicref - > data[i] + ( outpicref - > linesize[i] > 0 ? 0 : outpicref - > linesize[i] * ( h - 1 ) ) ; memset ( data , 0 , FFABS ( outpicref - > linesize[i] ) * h ) ; } } / * copy palette * / if ( priv - > pix_desc - > flags & PIX_FMT_PAL ) memcpy ( outpicref - > data[1] , outpicref - > data[1] , 256 * 4 ) ; avfilter_start_frame ( outlink , avfilter_ref_buffer ( outpicref , 0 ) ) ; }",1
"void av_noreturn exit_program ( int ret ) { int i , j ; for ( i = 0 ; i < nb_filtergraphs ; i + + ) { avfilter_graph_free ( & filtergraphs[i] - > graph ) ; for ( j = 0 ; j < filtergraphs[i] - > nb_inputs ; j + + ) av_freep ( & filtergraphs[i] - > inputs[j] ) ; av_freep ( & filtergraphs[i] - > inputs ) ; for ( j = 0 ; j < filtergraphs[i] - > nb_outputs ; j + + ) av_freep ( & filtergraphs[i] - > outputs[j] ) ; av_freep ( & filtergraphs[i] - > outputs ) ; av_freep ( & filtergraphs[i] ) ; } av_freep ( & filtergraphs ) ; / * close files * / for ( i = 0 ; i < nb_output_files ; i + + ) { AVFormatContext * s = output_files[i] - > ctx ; if ( ! ( s - > oformat - > flags & AVFMT_NOFILE ) & & s - > pb ) avio_close ( s - > pb ) ; avformat_free_context ( s ) ; av_dict_free ( & output_files[i] - > opts ) ; av_freep ( & output_files[i] ) ; } for ( i = 0 ; i < nb_output_streams ; i + + ) { AVBitStreamFilterContext * bsfc = output_streams[i] - > bitstream_filters ; while ( bsfc ) { AVBitStreamFilterContext * next = bsfc - > next ; av_bitstream_filter_close ( bsfc ) ; bsfc = next ; } output_streams[i] - > bitstream_filters = NULL ; if ( output_streams[i] - > output_frame ) { AVFrame * frame = output_streams[i] - > output_frame ; if ( frame - > extended_data ! = frame - > data ) av_freep ( & frame - > extended_data ) ; av_freep ( & frame ) ; } av_freep ( & output_streams[i] - > filtered_frame ) ; av_freep ( & output_streams[i] ) ; } for ( i = 0 ; i < nb_input_files ; i + + ) { avformat_close_input ( & input_files[i] - > ctx ) ; av_freep ( & input_files[i] ) ; } for ( i = 0 ; i < nb_input_streams ; i + + ) { av_freep ( & input_streams[i] - > decoded_frame ) ; av_dict_free ( & input_streams[i] - > opts ) ; free_buffer_pool ( input_streams[i] ) ; av_freep ( & input_streams[i] - > filters ) ; av_freep ( & input_streams[i] ) ; } if ( vstats_file ) fclose ( vstats_file ) ; av_free ( vstats_filename ) ; av_freep ( & input_streams ) ; av_freep ( & input_files ) ; av_freep ( & output_streams ) ; av_freep ( & output_files ) ; uninit_opts ( ) ; av_freep ( & audio_buf ) ; allocated_audio_buf_size = 0 ; av_freep ( & async_buf ) ; allocated_async_buf_size = 0 ; avfilter_uninit ( ) ; avformat_network_deinit ( ) ; if ( received_sigterm ) { av_log ( NULL , AV_LOG_INFO , Received signal %d : terminating . \n , ( int ) received_sigterm ) ; exit ( 255 ) ; } exit ( ret ) ; / * not all OS - es handle main ( ) return value * / }",1
"static int mov_read_aclr ( MOVContext * c , AVIOContext * pb , MOVAtom atom ) { int ret = 0 ; int length = 0 ; uint64_t original_size ; if ( c - > fc - > nb_streams > = 1 ) { AVCodecContext * codec = c - > fc - > streams[c - > fc - > nb_streams - 1] - > codec ; if ( codec - > codec_id == AV_CODEC_ID_H264 ) return 0 ; if ( atom . size == 16 ) { original_size = codec - > extradata_size ; ret = mov_realloc_extradata ( codec , atom ) ; if ( ! ret ) { length = mov_read_atom_into_extradata ( c , pb , atom , codec , codec - > extradata + original_size ) ; if ( length == atom . size ) { const uint8_t range_value = codec - > extradata[original_size + 19] ; switch ( range_value ) { case 1 : codec - > color_range = AVCOL_RANGE_MPEG ; break ; case 2 : codec - > color_range = AVCOL_RANGE_JPEG ; break ; default : av_log ( c , AV_LOG_WARNING , ignored unknown aclr value ( %d ) \n , range_value ) ; break ; } av_dlog ( c , color_range : %d\n , codec - > color_range ) ; } else { / * For some reason the whole atom was not added to the extradata * / av_log ( c , AV_LOG_ERROR , aclr not decoded - incomplete atom\n ) ; } } else { av_log ( c , AV_LOG_ERROR , aclr not decoded - unable to add atom to extradata\n ) ; } } else { av_log ( c , AV_LOG_WARNING , aclr not decoded - unexpected size % PRId64 \n , atom . size ) ; } } return ret ; }",0
"static av_always_inline void filter_level_for_mb ( VP8Context * s , VP8Macroblock * mb , VP8FilterStrength * f ) { int interior_limit , filter_level ; if ( s - > segmentation . enabled ) { filter_level = s - > segmentation . filter_level[s - > segment] ; if ( ! s - > segmentation . absolute_vals ) filter_level + = s - > filter . level ; } else filter_level = s - > filter . level ; if ( s - > lf_delta . enabled ) { filter_level + = s - > lf_delta . ref[mb - > ref_frame] ; filter_level + = s - > lf_delta . mode[mb - > mode] ; } / * Like av_clip for inputs 0 and max , where max is equal to ( 2 n - 1 ) * / define POW2CLIP ( x , max ) ( ( ( x ) & max ) ? ( - ( x ) ) > > 31 & max : ( x ) ) ; filter_level = POW2CLIP ( filter_level , 63 ) ; interior_limit = filter_level ; if ( s - > filter . sharpness ) { interior_limit > > = s - > filter . sharpness > 4 ? 2 : 1 ; interior_limit = FFMIN ( interior_limit , 9 - s - > filter . sharpness ) ; } interior_limit = FFMAX ( interior_limit , 1 ) ; f - > filter_level = filter_level ; f - > inner_limit = interior_limit ; f - > inner_filter = ! mb - > skip || mb - > mode == MODE_I4x4 || mb - > mode == VP8_MVMODE_SPLIT ; }",0
"void rgb15tobgr16 ( const uint8_t * src , uint8_t * dst , long src_size ) { long i ; long num_pixels = src_size > > 1 ; for ( i=0 ; i < num_pixels ; i + + ) { unsigned b , g , r ; register uint16_t rgb ; rgb = src[2 * i] ; r = rgb & 0x1F ; g = ( rgb & 0x3E0 ) > > 5 ; b = ( rgb & 0x7C00 ) > > 10 ; dst[2 * i] = ( b & 0x1F ) | ( ( g & 0x3F ) < < 5 ) | ( ( r & 0x1F ) < < 11 ) ; } }",1
"static int mxf_read_index_table_segment ( MXFIndexTableSegment * segment , ByteIOContext * pb , int tag ) { switch ( tag ) { case 0x3F05 : dprintf ( NULL , EditUnitByteCount %d\n , get_be32 ( pb ) ) ; break ; case 0x3F06 : dprintf ( NULL , IndexSID %d\n , get_be32 ( pb ) ) ; break ; case 0x3F07 : dprintf ( NULL , BodySID %d\n , get_be32 ( pb ) ) ; break ; case 0x3F0B : dprintf ( NULL , IndexEditRate %d/%d\n , get_be32 ( pb ) , get_be32 ( pb ) ) ; break ; case 0x3F0C : dprintf ( NULL , IndexStartPosition %lld\n , get_be64 ( pb ) ) ; break ; case 0x3F0D : dprintf ( NULL , IndexDuration %lld\n , get_be64 ( pb ) ) ; break ; } return 0 ; }",1
"static void yuv2nv12X_c ( SwsContext * c , const int16_t * lumFilter , const int16_t * * lumSrc , int lumFilterSize , const int16_t * chrFilter , const int16_t * * chrUSrc , const int16_t * * chrVSrc , int chrFilterSize , const int16_t * * alpSrc , uint8_t * dest , uint8_t * uDest , uint8_t * vDest , uint8_t * aDest , int dstW , int chrDstW ) { enum PixelFormat dstFormat = c - > dstFormat ; //FIXME Optimize ( just quickly written not optimized . . ) int i ; for ( i=0 ; i < dstW ; i + + ) { int val=1 < < 18 ; int j ; for ( j=0 ; j < lumFilterSize ; j + + ) val + = lumSrc[j][i] * lumFilter[j] ; dest[i]= av_clip_uint8 ( val > > 19 ) ; } if ( ! uDest ) return ; if ( dstFormat == PIX_FMT_NV12 ) for ( i=0 ; i < chrDstW ; i + + ) { int u=1 < < 18 ; int v=1 < < 18 ; int j ; for ( j=0 ; j < chrFilterSize ; j + + ) { u + = chrUSrc[j][i] * chrFilter[j] ; v + = chrVSrc[j][i] * chrFilter[j] ; } uDest[2 * i]= av_clip_uint8 ( u > > 19 ) ; uDest[2 * i + 1]= av_clip_uint8 ( v > > 19 ) ; } else for ( i=0 ; i < chrDstW ; i + + ) { int u=1 < < 18 ; int v=1 < < 18 ; int j ; for ( j=0 ; j < chrFilterSize ; j + + ) { u + = chrUSrc[j][i] * chrFilter[j] ; v + = chrVSrc[j][i] * chrFilter[j] ; } uDest[2 * i]= av_clip_uint8 ( v > > 19 ) ; uDest[2 * i + 1]= av_clip_uint8 ( u > > 19 ) ; } }",0
"static int rv10_decode_packet ( AVCodecContext * avctx , const uint8_t * buf , int buf_size , int buf_size2 ) { MpegEncContext * s = avctx - > priv_data ; int mb_count , mb_pos , left , start_mb_x ; init_get_bits ( & s - > gb , buf , buf_size * 8 ) ; if ( s - > codec_id ==CODEC_ID_RV10 ) mb_count = rv10_decode_picture_header ( s ) ; else mb_count = rv20_decode_picture_header ( s ) ; if ( mb_count < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , HEADER ERROR\n ) ; return - 1 ; } if ( s - > mb_x > = s - > mb_width || s - > mb_y > = s - > mb_height ) { av_log ( s - > avctx , AV_LOG_ERROR , POS ERROR %d %d\n , s - > mb_x , s - > mb_y ) ; return - 1 ; } mb_pos = s - > mb_y * s - > mb_width + s - > mb_x ; left = s - > mb_width * s - > mb_height - mb_pos ; if ( mb_count > left ) { av_log ( s - > avctx , AV_LOG_ERROR , COUNT ERROR\n ) ; return - 1 ; } if ( ( s - > mb_x == 0 & & s - > mb_y == 0 ) || s - > current_picture_ptr==NULL ) { if ( s - > current_picture_ptr ) { //FIXME write parser so we always have complete frames ? ff_er_frame_end ( s ) ; ff_MPV_frame_end ( s ) ; s - > mb_x= s - > mb_y = s - > resync_mb_x = s - > resync_mb_y= 0 ; } if ( ff_MPV_frame_start ( s , avctx ) < 0 ) return - 1 ; ff_er_frame_start ( s ) ; } else { if ( s - > current_picture_ptr - > f . pict_type ! = s - > pict_type ) { av_log ( s - > avctx , AV_LOG_ERROR , Slice type mismatch\n ) ; return - 1 ; } } av_dlog ( avctx , qscale=%d\n , s - > qscale ) ; / * default quantization values * / if ( s - > codec_id== CODEC_ID_RV10 ) { if ( s - > mb_y==0 ) s - > first_slice_line=1 ; } else { s - > first_slice_line=1 ; s - > resync_mb_x= s - > mb_x ; } start_mb_x= s - > mb_x ; s - > resync_mb_y= s - > mb_y ; if ( s - > h263_aic ) { s - > y_dc_scale_table= s - > c_dc_scale_table= ff_aic_dc_scale_table ; } else { s - > y_dc_scale_table= s - > c_dc_scale_table= ff_mpeg1_dc_scale_table ; } if ( s - > modified_quant ) s - > chroma_qscale_table= ff_h263_chroma_qscale_table ; ff_set_qscale ( s , s - > qscale ) ; s - > rv10_first_dc_coded[0] = 0 ; s - > rv10_first_dc_coded[1] = 0 ; s - > rv10_first_dc_coded[2] = 0 ; s - > block_wrap[0]= s - > block_wrap[1]= s - > block_wrap[2]= s - > block_wrap[3]= s - > b8_stride ; s - > block_wrap[4]= s - > block_wrap[5]= s - > mb_stride ; ff_init_block_index ( s ) ; / * decode each macroblock * / for ( s - > mb_num_left= mb_count ; s - > mb_num_left > 0 ; s - > mb_num_left - - ) { int ret ; ff_update_block_index ( s ) ; av_dlog ( avctx , * * mb x=%d y=%d\n , s - > mb_x , s - > mb_y ) ; s - > mv_dir = MV_DIR_FORWARD ; s - > mv_type = MV_TYPE_16X16 ; ret=ff_h263_decode_mb ( s , s - > block ) ; if ( ret ! = SLICE_ERROR & & s - > gb . size_in_bits < get_bits_count ( & s - > gb ) & & 8 * buf_size2 > = get_bits_count ( & s - > gb ) ) { av_log ( avctx , AV_LOG_DEBUG , update size from %d to %d\n , s - > gb . size_in_bits , 8 * buf_size2 ) ; s - > gb . size_in_bits= 8 * buf_size2 ; ret= SLICE_OK ; } if ( ret == SLICE_ERROR || s - > gb . size_in_bits < get_bits_count ( & s - > gb ) ) { av_log ( s - > avctx , AV_LOG_ERROR , ERROR at MB %d %d\n , s - > mb_x , s - > mb_y ) ; return - 1 ; } if ( s - > pict_type ! = AV_PICTURE_TYPE_B ) ff_h263_update_motion_val ( s ) ; ff_MPV_decode_mb ( s , s - > block ) ; if ( s - > loop_filter ) ff_h263_loop_filter ( s ) ; if ( + + s - > mb_x == s - > mb_width ) { s - > mb_x = 0 ; s - > mb_y + + ; ff_init_block_index ( s ) ; } if ( s - > mb_x == s - > resync_mb_x ) s - > first_slice_line=0 ; if ( ret == SLICE_END ) break ; } ff_er_add_slice ( s , start_mb_x , s - > resync_mb_y , s - > mb_x - 1 , s - > mb_y , ER_MB_END ) ; return s - > gb . size_in_bits ; }",1
"static void gmc1_motion ( MpegEncContext * s , uint8_t * dest_y , uint8_t * dest_cb , uint8_t * dest_cr , uint8_t * * ref_picture ) { uint8_t * ptr ; int src_x , src_y , motion_x , motion_y ; ptrdiff_t offset , linesize , uvlinesize ; int emu = 0 ; motion_x = s - > sprite_offset[0][0] ; motion_y = s - > sprite_offset[0][1] ; src_x = s - > mb_x * 16 + ( motion_x > > ( s - > sprite_warping_accuracy + 1 ) ) ; src_y = s - > mb_y * 16 + ( motion_y > > ( s - > sprite_warping_accuracy + 1 ) ) ; motion_x < < = ( 3 - s - > sprite_warping_accuracy ) ; motion_y < < = ( 3 - s - > sprite_warping_accuracy ) ; src_x = av_clip ( src_x , - 16 , s - > width ) ; if ( src_x == s - > width ) motion_x = 0 ; src_y = av_clip ( src_y , - 16 , s - > height ) ; if ( src_y == s - > height ) motion_y = 0 ; linesize = s - > linesize ; uvlinesize = s - > uvlinesize ; ptr = ref_picture[0] + src_y * linesize + src_x ; if ( ( unsigned ) src_x > = FFMAX ( s - > h_edge_pos - 17 , 0 ) || ( unsigned ) src_y > = FFMAX ( s - > v_edge_pos - 17 , 0 ) ) { s - > vdsp . emulated_edge_mc ( s - > sc . edge_emu_buffer , ptr , linesize , linesize , 17 , 17 , src_x , src_y , s - > h_edge_pos , s - > v_edge_pos ) ; ptr = s - > sc . edge_emu_buffer ; } if ( ( motion_x | motion_y ) & 7 ) { s - > mdsp . gmc1 ( dest_y , ptr , linesize , 16 , motion_x & 15 , motion_y & 15 , 128 - s - > no_rounding ) ; s - > mdsp . gmc1 ( dest_y + 8 , ptr + 8 , linesize , 16 , motion_x & 15 , motion_y & 15 , 128 - s - > no_rounding ) ; } else { int dxy ; dxy = ( ( motion_x > > 3 ) & 1 ) | ( ( motion_y > > 2 ) & 2 ) ; if ( s - > no_rounding ) { s - > hdsp . put_no_rnd_pixels_tab[0][dxy] ( dest_y , ptr , linesize , 16 ) ; } else { s - > hdsp . put_pixels_tab[0][dxy] ( dest_y , ptr , linesize , 16 ) ; } } if ( CONFIG_GRAY & & s - > avctx - > flags & AV_CODEC_FLAG_GRAY ) return ; motion_x = s - > sprite_offset[1][0] ; motion_y = s - > sprite_offset[1][1] ; src_x = s - > mb_x * 8 + ( motion_x > > ( s - > sprite_warping_accuracy + 1 ) ) ; src_y = s - > mb_y * 8 + ( motion_y > > ( s - > sprite_warping_accuracy + 1 ) ) ; motion_x < < = ( 3 - s - > sprite_warping_accuracy ) ; motion_y < < = ( 3 - s - > sprite_warping_accuracy ) ; src_x = av_clip ( src_x , - 8 , s - > width > > 1 ) ; if ( src_x == s - > width > > 1 ) motion_x = 0 ; src_y = av_clip ( src_y , - 8 , s - > height > > 1 ) ; if ( src_y == s - > height > > 1 ) motion_y = 0 ; offset = ( src_y * uvlinesize ) + src_x ; ptr = ref_picture[1] + offset ; if ( ( unsigned ) src_x > = FFMAX ( ( s - > h_edge_pos > > 1 ) - 9 , 0 ) || ( unsigned ) src_y > = FFMAX ( ( s - > v_edge_pos > > 1 ) - 9 , 0 ) ) { s - > vdsp . emulated_edge_mc ( s - > sc . edge_emu_buffer , ptr , uvlinesize , uvlinesize , 9 , 9 , src_x , src_y , s - > h_edge_pos > > 1 , s - > v_edge_pos > > 1 ) ; ptr = s - > sc . edge_emu_buffer ; emu = 1 ; } s - > mdsp . gmc1 ( dest_cb , ptr , uvlinesize , 8 , motion_x & 15 , motion_y & 15 , 128 - s - > no_rounding ) ; ptr = ref_picture[2] + offset ; if ( emu ) { s - > vdsp . emulated_edge_mc ( s - > sc . edge_emu_buffer , ptr , uvlinesize , uvlinesize , 9 , 9 , src_x , src_y , s - > h_edge_pos > > 1 , s - > v_edge_pos > > 1 ) ; ptr = s - > sc . edge_emu_buffer ; } s - > mdsp . gmc1 ( dest_cr , ptr , uvlinesize , 8 , motion_x & 15 , motion_y & 15 , 128 - s - > no_rounding ) ; }",1
"static void gxf_write_padding ( ByteIOContext * pb , offset_t to_pad ) { while ( to_pad - - ) { put_byte ( pb , 0 ) ; } }",0
"static int aea_read_header ( AVFormatContext * s ) { AVStream * st = avformat_new_stream ( s , NULL ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; / * Parse the amount of channels and skip to pos 2048 ( 0x800 ) * / avio_skip ( s - > pb , 264 ) ; st - > codec - > channels = avio_r8 ( s - > pb ) ; avio_skip ( s - > pb , 1783 ) ; st - > codec - > codec_type = AVMEDIA_TYPE_AUDIO ; st - > codec - > codec_id = AV_CODEC_ID_ATRAC1 ; st - > codec - > sample_rate = 44100 ; st - > codec - > bit_rate = 292000 ; if ( st - > codec - > channels ! = 1 & & st - > codec - > channels ! = 2 ) { av_log ( s , AV_LOG_ERROR , Channels %d not supported ! \n , st - > codec - > channels ) ; return - 1 ; } st - > codec - > channel_layout = ( st - > codec - > channels == 1 ) ? AV_CH_LAYOUT_MONO : AV_CH_LAYOUT_STEREO ; st - > codec - > block_align = AT1_SU_SIZE * st - > codec - > channels ; return 0 ; }",0
"static int rpl_read_header ( AVFormatContext * s , AVFormatParameters * ap ) { AVIOContext * pb = s - > pb ; RPLContext * rpl = s - > priv_data ; AVStream * vst = NULL , * ast = NULL ; int total_audio_size ; int error = 0 ; uint32_t i ; int32_t audio_format , chunk_catalog_offset , number_of_chunks ; AVRational fps ; char line[RPL_LINE_LENGTH] ; // The header for RPL/ARMovie files is 21 lines of text // containing the various header fields . The fields are always // in the same order , and other text besides the first // number usually isn ' t important . // ( The spec says that there exists some significance // for the text in a few cases ; samples needed . ) error |= read_line ( pb , line , sizeof ( line ) ) ; // ARMovie error |= read_line ( pb , line , sizeof ( line ) ) ; // movie name av_dict_set ( & s - > metadata , title , line , 0 ) ; error |= read_line ( pb , line , sizeof ( line ) ) ; // date/copyright av_dict_set ( & s - > metadata , copyright , line , 0 ) ; error |= read_line ( pb , line , sizeof ( line ) ) ; // author and other av_dict_set ( & s - > metadata , author , line , 0 ) ; // video headers vst = avformat_new_stream ( s , NULL ) ; if ( ! vst ) return AVERROR ( ENOMEM ) ; vst - > codec - > codec_type = AVMEDIA_TYPE_VIDEO ; vst - > codec - > codec_tag = read_line_and_int ( pb , & error ) ; // video format vst - > codec - > width = read_line_and_int ( pb , & error ) ; // video width vst - > codec - > height = read_line_and_int ( pb , & error ) ; // video height vst - > codec - > bits_per_coded_sample = read_line_and_int ( pb , & error ) ; // video bits per sample error |= read_line ( pb , line , sizeof ( line ) ) ; // video frames per second fps = read_fps ( line , & error ) ; avpriv_set_pts_info ( vst , 32 , fps . den , fps . num ) ; // Figure out the video codec switch ( vst - > codec - > codec_tag ) { if 0 case 122 : vst - > codec - > codec_id = CODEC_ID_ESCAPE122 ; break ; endif case 124 : vst - > codec - > codec_id = CODEC_ID_ESCAPE124 ; // The header is wrong here , at least sometimes vst - > codec - > bits_per_coded_sample = 16 ; break ; case 130 : vst - > codec - > codec_id = CODEC_ID_ESCAPE130 ; break ; default : av_log ( s , AV_LOG_WARNING , RPL video format %i not supported yet ! \n , vst - > codec - > codec_tag ) ; vst - > codec - > codec_id = CODEC_ID_NONE ; } // Audio headers // ARMovie supports multiple audio tracks ; I don ' t have any // samples , though . This code will ignore additional tracks . audio_format = read_line_and_int ( pb , & error ) ; // audio format ID if ( audio_format ) { ast = avformat_new_stream ( s , NULL ) ; if ( ! ast ) return AVERROR ( ENOMEM ) ; ast - > codec - > codec_type = AVMEDIA_TYPE_AUDIO ; ast - > codec - > codec_tag = audio_format ; ast - > codec - > sample_rate = read_line_and_int ( pb , & error ) ; // audio bitrate ast - > codec - > channels = read_line_and_int ( pb , & error ) ; // number of audio channels ast - > codec - > bits_per_coded_sample = read_line_and_int ( pb , & error ) ; // audio bits per sample // At least one sample uses 0 for ADPCM , which is really 4 bits // per sample . if ( ast - > codec - > bits_per_coded_sample == 0 ) ast - > codec - > bits_per_coded_sample = 4 ; ast - > codec - > bit_rate = ast - > codec - > sample_rate * ast - > codec - > bits_per_coded_sample * ast - > codec - > channels ; ast - > codec - > codec_id = CODEC_ID_NONE ; switch ( audio_format ) { case 1 : if ( ast - > codec - > bits_per_coded_sample == 16 ) { // 16 - bit audio is always signed ast - > codec - > codec_id = CODEC_ID_PCM_S16LE ; break ; } // There are some other formats listed as legal per the spec ; // samples needed . break ; case 101 : if ( ast - > codec - > bits_per_coded_sample == 8 ) { // The samples with this kind of audio that I have // are all unsigned . ast - > codec - > codec_id = CODEC_ID_PCM_U8 ; break ; } else if ( ast - > codec - > bits_per_coded_sample == 4 ) { ast - > codec - > codec_id = CODEC_ID_ADPCM_IMA_EA_SEAD ; break ; } break ; } if ( ast - > codec - > codec_id == CODEC_ID_NONE ) { av_log ( s , AV_LOG_WARNING , RPL audio format %i not supported yet ! \n , audio_format ) ; } avpriv_set_pts_info ( ast , 32 , 1 , ast - > codec - > bit_rate ) ; } else { for ( i = 0 ; i < 3 ; i + + ) error |= read_line ( pb , line , sizeof ( line ) ) ; } rpl - > frames_per_chunk = read_line_and_int ( pb , & error ) ; // video frames per chunk if ( rpl - > frames_per_chunk > 1 & & vst - > codec - > codec_tag ! = 124 ) av_log ( s , AV_LOG_WARNING , Don ' t know how to split frames for video format %i . Video stream will be broken ! \n , vst - > codec - > codec_tag ) ; number_of_chunks = read_line_and_int ( pb , & error ) ; // number of chunks in the file // The number in the header is actually the index of the last chunk . number_of_chunks + + ; error |= read_line ( pb , line , sizeof ( line ) ) ; // even chunk size in bytes error |= read_line ( pb , line , sizeof ( line ) ) ; // odd chunk size in bytes chunk_catalog_offset = // offset of the chunk catalog read_line_and_int ( pb , & error ) ; // ( file index ) error |= read_line ( pb , line , sizeof ( line ) ) ; // offset to helpful sprite error |= read_line ( pb , line , sizeof ( line ) ) ; // size of helpful sprite error |= read_line ( pb , line , sizeof ( line ) ) ; // offset to key frame list",0
"static int adpcm_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; ADPCMDecodeContext * c = avctx - > priv_data ; ADPCMChannelStatus * cs ; int n , m , channel , i ; int block_predictor[2] ; short * samples ; short * samples_end ; const uint8_t * src ; int st ; / * stereo * / / * DK3 ADPCM accounting variables * / unsigned char last_byte = 0 ; unsigned char nibble ; int decode_top_nibble_next = 0 ; int diff_channel ; / * EA ADPCM state variables * / uint32_t samples_in_chunk ; int32_t previous_left_sample , previous_right_sample ; int32_t current_left_sample , current_right_sample ; int32_t next_left_sample , next_right_sample ; int32_t coeff1l , coeff2l , coeff1r , coeff2r ; uint8_t shift_left , shift_right ; int count1 , count2 ; int coeff[2][2] , shift[2] ; //used in EA MAXIS ADPCM if ( ! buf_size ) return 0 ; //should protect all 4bit ADPCM variants //8 is needed for CODEC_ID_ADPCM_IMA_WAV with 2 channels // if ( * data_size/4 < buf_size + 8 ) return - 1 ; samples = data ; samples_end= samples + * data_size/2 ; * data_size= 0 ; src = buf ; st = avctx - > channels == 2 ? 1 : 0 ; switch ( avctx - > codec - > id ) { case CODEC_ID_ADPCM_IMA_QT : n = buf_size - 2 * avctx - > channels ; for ( channel = 0 ; channel < avctx - > channels ; channel + + ) { int16_t predictor ; int step_index ; cs = & ( c - > status[channel] ) ; / * ( pppppp ) ( piiiiiii ) * / / * Bits 15 - 7 are the _top_ 9 bits of the 16 - bit initial predictor value * / predictor = AV_RB16 ( src ) ; step_index = predictor & 0x7F ; predictor & = 0xFF80 ; src + = 2 ; if ( cs - > step_index == step_index ) { int diff = ( int ) predictor - cs - > predictor ; if ( diff < 0 ) diff = - diff ; if ( diff > 0x7f ) goto update ; } else { update : cs - > step_index = step_index ; cs - > predictor = predictor ; } if ( cs - > step_index > 88 ) { av_log ( avctx , AV_LOG_ERROR , ERROR : step_index = %i\n , cs - > step_index ) ; cs - > step_index = 88 ; } samples = ( short * ) data + channel ; for ( m=32 ; n > 0 & & m > 0 ; n - - , m - - ) { / * in QuickTime , IMA is encoded by chuncks of 34 bytes ( =64 samples ) * / * samples = adpcm_ima_qt_expand_nibble ( cs , src[0] & 0x0F , 3 ) ; samples + = avctx - > channels ; * samples = adpcm_ima_qt_expand_nibble ( cs , src[0] > > 4 , 3 ) ; samples + = avctx - > channels ; src + + ; } } if ( st ) samples - - ; break ; case CODEC_ID_ADPCM_IMA_WAV : if ( avctx - > block_align ! = 0 & & buf_size > avctx - > block_align ) buf_size = avctx - > block_align ; // samples_per_block= ( block_align - 4 * chanels ) * 8 / ( bits_per_sample * chanels ) + 1 ; for ( i=0 ; i < avctx - > channels ; i + + ) { cs = & ( c - > status[i] ) ; cs - > predictor = * samples + + = ( int16_t ) bytestream_get_le16 ( & src ) ; cs - > step_index = * src + + ; if ( cs - > step_index > 88 ) { av_log ( avctx , AV_LOG_ERROR , ERROR : step_index = %i\n , cs - > step_index ) ; cs - > step_index = 88 ; } if ( * src + + ) av_log ( avctx , AV_LOG_ERROR , unused byte should be null but is %d ! ! \n , src[ - 1] ) ; / * unused * / } while ( src < buf + buf_size ) { for ( m=0 ; m < 4 ; m + + ) { for ( i=0 ; i < =st ; i + + ) * samples + + = adpcm_ima_expand_nibble ( & c - > status[i] , src[4 * i] & 0x0F , 3 ) ; for ( i=0 ; i < =st ; i + + ) * samples + + = adpcm_ima_expand_nibble ( & c - > status[i] , src[4 * i] > > 4 , 3 ) ; src + + ; } src + = 4 * st ; } break ; case CODEC_ID_ADPCM_4XM : cs = & ( c - > status[0] ) ; c - > status[0] . predictor= ( int16_t ) bytestream_get_le16 ( & src ) ; if ( st ) { c - > status[1] . predictor= ( int16_t ) bytestream_get_le16 ( & src ) ; } c - > status[0] . step_index= ( int16_t ) bytestream_get_le16 ( & src ) ; if ( st ) { c - > status[1] . step_index= ( int16_t ) bytestream_get_le16 ( & src ) ; } if ( cs - > step_index < 0 ) cs - > step_index = 0 ; if ( cs - > step_index > 88 ) cs - > step_index = 88 ; m= ( buf_size - ( src - buf ) ) > > st ; for ( i=0 ; i < m ; i + + ) { * samples + + = adpcm_ima_expand_nibble ( & c - > status[0] , src[i] & 0x0F , 4 ) ; if ( st ) * samples + + = adpcm_ima_expand_nibble ( & c - > status[1] , src[i + m] & 0x0F , 4 ) ; * samples + + = adpcm_ima_expand_nibble ( & c - > status[0] , src[i] > > 4 , 4 ) ; if ( st ) * samples + + = adpcm_ima_expand_nibble ( & c - > status[1] , src[i + m] > > 4 , 4 ) ; } src + = m < < st ; break ; case CODEC_ID_ADPCM_MS : if ( avctx - > block_align ! = 0 & & buf_size > avctx - > block_align ) buf_size = avctx - > block_align ; n = buf_size - 7 * avctx - > channels ; if ( n < 0 ) return - 1 ; block_predictor[0] = av_clip ( * src + + , 0 , 6 ) ; block_predictor[1] = 0 ; if ( st ) block_predictor[1] = av_clip ( * src + + , 0 , 6 ) ; c - > status[0] . idelta = ( int16_t ) bytestream_get_le16 ( & src ) ; if ( st ) { c - > status[1] . idelta =",0
"static int smacker_decode_header_tree ( SmackVContext * smk , GetBitContext * gb , int * * recodes , int * last , int size ) { int res ; HuffContext huff ; HuffContext tmp1 , tmp2 ; VLC vlc[2] = { { 0 } } ; int escapes[3] ; DBCtx ctx ; int err = 0 ; if ( size > = UINT_MAX > > 4 ) { // ( ( ( size + 3 ) > > 2 ) + 3 ) < < 2 must not overflow av_log ( smk - > avctx , AV_LOG_ERROR , size too large\n ) ; return AVERROR_INVALIDDATA ; } tmp1 . length = 256 ; tmp1 . maxlength = 0 ; tmp1 . current = 0 ; tmp1 . bits = av_mallocz ( 256 * 4 ) ; tmp1 . lengths = av_mallocz ( 256 * sizeof ( int ) ) ; tmp1 . values = av_mallocz ( 256 * sizeof ( int ) ) ; tmp2 . length = 256 ; tmp2 . maxlength = 0 ; tmp2 . current = 0 ; tmp2 . bits = av_mallocz ( 256 * 4 ) ; tmp2 . lengths = av_mallocz ( 256 * sizeof ( int ) ) ; tmp2 . values = av_mallocz ( 256 * sizeof ( int ) ) ; if ( get_bits1 ( gb ) ) { smacker_decode_tree ( gb , & tmp1 , 0 , 0 ) ; skip_bits1 ( gb ) ; if ( tmp1 . current > 1 ) { res = init_vlc ( & vlc[0] , SMKTREE_BITS , tmp1 . length , tmp1 . lengths , sizeof ( int ) , sizeof ( int ) , tmp1 . bits , sizeof ( uint32_t ) , sizeof ( uint32_t ) , INIT_VLC_LE ) ; if ( res < 0 ) { av_log ( smk - > avctx , AV_LOG_ERROR , Cannot build VLC table\n ) ; return AVERROR_INVALIDDATA ; } } } if ( ! vlc[0] . table ) { av_log ( smk - > avctx , AV_LOG_ERROR , Skipping low bytes tree\n ) ; } if ( get_bits1 ( gb ) ) { smacker_decode_tree ( gb , & tmp2 , 0 , 0 ) ; skip_bits1 ( gb ) ; if ( tmp2 . current > 1 ) { res = init_vlc ( & vlc[1] , SMKTREE_BITS , tmp2 . length , tmp2 . lengths , sizeof ( int ) , sizeof ( int ) , tmp2 . bits , sizeof ( uint32_t ) , sizeof ( uint32_t ) , INIT_VLC_LE ) ; if ( res < 0 ) { av_log ( smk - > avctx , AV_LOG_ERROR , Cannot build VLC table\n ) ; return AVERROR_INVALIDDATA ; } } } if ( ! vlc[1] . table ) { av_log ( smk - > avctx , AV_LOG_ERROR , Skipping high bytes tree\n ) ; } escapes[0] = get_bits ( gb , 16 ) ; escapes[1] = get_bits ( gb , 16 ) ; escapes[2] = get_bits ( gb , 16 ) ; last[0] = last[1] = last[2] = - 1 ; ctx . escapes[0] = escapes[0] ; ctx . escapes[1] = escapes[1] ; ctx . escapes[2] = escapes[2] ; ctx . v1 = & vlc[0] ; ctx . v2 = & vlc[1] ; ctx . recode1 = tmp1 . values ; ctx . recode2 = tmp2 . values ; ctx . last = last ; huff . length = ( ( size + 3 ) > > 2 ) + 3 ; huff . maxlength = 0 ; huff . current = 0 ; huff . values = av_mallocz ( huff . length * sizeof ( int ) ) ; if ( smacker_decode_bigtree ( gb , & huff , & ctx ) < 0 ) err = - 1 ; skip_bits1 ( gb ) ; if ( ctx . last[0] == - 1 ) ctx . last[0] = huff . current + + ; if ( ctx . last[1] == - 1 ) ctx . last[1] = huff . current + + ; if ( ctx . last[2] == - 1 ) ctx . last[2] = huff . current + + ; if ( huff . current > huff . length ) { ctx . last[0] = ctx . last[1] = ctx . last[2] = 1 ; av_log ( smk - > avctx , AV_LOG_ERROR , bigtree damaged\n ) ; return AVERROR_INVALIDDATA ; } * recodes = huff . values ; if ( vlc[0] . table ) ff_free_vlc ( & vlc[0] ) ; if ( vlc[1] . table ) ff_free_vlc ( & vlc[1] ) ; av_free ( tmp1 . bits ) ; av_free ( tmp1 . lengths ) ; av_free ( tmp1 . values ) ; av_free ( tmp2 . bits ) ; av_free ( tmp2 . lengths ) ; av_free ( tmp2 . values ) ; return err ; }",0
"int ff_h264_decode_slice_header ( H264Context * h , H264SliceContext * sl , H264Context * h0 ) { unsigned int first_mb_in_slice ; unsigned int pps_id ; int ret ; unsigned int slice_type , tmp , i , j ; int default_ref_list_done = 0 ; int last_pic_structure , last_pic_droppable ; int needs_reinit = 0 ; int field_pic_flag , bottom_field_flag ; h - > qpel_put = h - > h264qpel . put_h264_qpel_pixels_tab ; h - > qpel_avg = h - > h264qpel . avg_h264_qpel_pixels_tab ; first_mb_in_slice = get_ue_golomb ( & h - > gb ) ; if ( first_mb_in_slice == 0 ) { // FIXME better field boundary detection if ( h0 - > current_slice & & h - > cur_pic_ptr & & FIELD_PICTURE ( h ) ) { ff_h264_field_end ( h , sl , 1 ) ; } h0 - > current_slice = 0 ; if ( ! h0 - > first_field ) { if ( h - > cur_pic_ptr & & ! h - > droppable ) { ff_thread_report_progress ( & h - > cur_pic_ptr - > tf , INT_MAX , h - > picture_structure == PICT_BOTTOM_FIELD ) ; } h - > cur_pic_ptr = NULL ; } } slice_type = get_ue_golomb_31 ( & h - > gb ) ; if ( slice_type > 9 ) { av_log ( h - > avctx , AV_LOG_ERROR , slice type %d too large at %d %d\n , slice_type , h - > mb_x , h - > mb_y ) ; return AVERROR_INVALIDDATA ; } if ( slice_type > 4 ) { slice_type - = 5 ; sl - > slice_type_fixed = 1 ; } else sl - > slice_type_fixed = 0 ; slice_type = golomb_to_pict_type[slice_type] ; if ( slice_type == AV_PICTURE_TYPE_I || ( h0 - > current_slice ! = 0 & & slice_type == h0 - > last_slice_type ) ) { default_ref_list_done = 1 ; } sl - > slice_type = slice_type ; sl - > slice_type_nos = slice_type & 3 ; if ( h - > nal_unit_type == NAL_IDR_SLICE & & sl - > slice_type_nos ! = AV_PICTURE_TYPE_I ) { av_log ( h - > avctx , AV_LOG_ERROR , A non - intra slice in an IDR NAL unit . \n ) ; return AVERROR_INVALIDDATA ; } // to make a few old functions happy , it ' s wrong though h - > pict_type = sl - > slice_type ; pps_id = get_ue_golomb ( & h - > gb ) ; if ( pps_id > = MAX_PPS_COUNT ) { av_log ( h - > avctx , AV_LOG_ERROR , pps_id %u out of range\n , pps_id ) ; return AVERROR_INVALIDDATA ; } if ( ! h0 - > pps_buffers[pps_id] ) { av_log ( h - > avctx , AV_LOG_ERROR , non - existing PPS %u referenced\n , pps_id ) ; return AVERROR_INVALIDDATA ; } h - > pps = * h0 - > pps_buffers[pps_id] ; if ( ! h0 - > sps_buffers[h - > pps . sps_id] ) { av_log ( h - > avctx , AV_LOG_ERROR , non - existing SPS %u referenced\n , h - > pps . sps_id ) ; return AVERROR_INVALIDDATA ; } if ( h - > pps . sps_id ! = h - > sps . sps_id || h0 - > sps_buffers[h - > pps . sps_id] - > new ) { h0 - > sps_buffers[h - > pps . sps_id] - > new = 0 ; h - > sps = * h0 - > sps_buffers[h - > pps . sps_id] ; if ( h - > bit_depth_luma ! = h - > sps . bit_depth_luma || h - > chroma_format_idc ! = h - > sps . chroma_format_idc ) { h - > bit_depth_luma = h - > sps . bit_depth_luma ; h - > chroma_format_idc = h - > sps . chroma_format_idc ; needs_reinit = 1 ; } if ( ( ret = ff_h264_set_parameter_from_sps ( h ) ) < 0 ) return ret ; } h - > avctx - > profile = ff_h264_get_profile ( & h - > sps ) ; h - > avctx - > level = h - > sps . level_idc ; h - > avctx - > refs = h - > sps . ref_frame_count ; if ( h - > mb_width ! = h - > sps . mb_width || h - > mb_height ! = h - > sps . mb_height * ( 2 - h - > sps . frame_mbs_only_flag ) ) needs_reinit = 1 ; h - > mb_width = h - > sps . mb_width ; h - > mb_height = h - > sps . mb_height * ( 2 - h - > sps . frame_mbs_only_flag ) ; h - > mb_num = h - > mb_width * h - > mb_height ; h - > mb_stride = h - > mb_width + 1 ; h - > b_stride = h - > mb_width * 4 ; h - > chroma_y_shift = h - > sps . chroma_format_idc < = 1 ; // 400 uses yuv420p h - > width = 16 * h - > mb_width ; h - > height = 16 * h - > mb_height ; ret = init_dimensions ( h ) ; if ( ret < 0 ) return ret ; if ( h - > sps . video_signal_type_present_flag ) { h - > avctx - > color_range = h - > sps . full_range ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG ; if ( h - > sps . colour_description_present_flag ) { if ( h - > avctx - > colorspace ! = h - > sps . colorspace ) needs_reinit = 1 ; h - > avctx - > color_primaries = h - > sps . color_primaries ; h - > avctx - > color_trc = h - > sps . color_trc ; h - > avctx - > colorspace = h - > sps . colorspace ; } } if ( h - > context_initialized & & needs_reinit ) { if ( h ! = h0 ) { av_log ( h - > avctx , AV_LOG_ERROR , changing width %d - > %d / height %d - > %d on slice %d\n , h - > width , h - > avctx - > coded_width , h - > height , h - > avctx - > coded_height , h0 - > current_slice + 1 ) ; return AVERROR_INVALIDDATA ; } ff_h264_flush_change ( h ) ; if ( ( ret = get_pixel_format ( h ) ) < 0 ) return ret ; h - > avctx - > pix_fmt = ret ; av_log ( h - > avctx , AV_LOG_INFO , Reinit context to %dx%d , pix_fmt : %d\n , h - > width , h - > height , h - > avctx - > pix_fmt ) ; if ( ( ret = h264_slice_header_init ( h , 1 ) ) < 0 ) { av_log ( h - > avctx , AV_LOG_ERROR , h264_slice_header_init ( ) failed\n ) ; return ret ; } } if ( ! h - > context_initialized ) { if ( h ! = h0 ) { av_log ( h - >",0
"static int64_t mpegts_get_dts ( AVFormatContext * s , int stream_index , int64_t * ppos , int64_t pos_limit ) { MpegTSContext * ts = s - > priv_data ; int64_t pos ; int pos47 = ts - > pos47_full % ts - > raw_packet_size ; pos = ( ( * ppos + ts - > raw_packet_size - 1 - pos47 ) / ts - > raw_packet_size ) * ts - > raw_packet_size + pos47 ; ff_read_frame_flush ( s ) ; if ( avio_seek ( s - > pb , pos , SEEK_SET ) < 0 ) return AV_NOPTS_VALUE ; while ( pos < pos_limit ) { int ret ; AVPacket pkt ; av_init_packet ( & pkt ) ; ret= av_read_frame ( s , & pkt ) ; if ( ret < 0 ) return AV_NOPTS_VALUE ; av_free_packet ( & pkt ) ; if ( pkt . dts ! = AV_NOPTS_VALUE & & pkt . pos > = 0 ) { ff_reduce_index ( s , pkt . stream_index ) ; av_add_index_entry ( s - > streams[pkt . stream_index] , pkt . pos , pkt . dts , 0 , 0 , AVINDEX_KEYFRAME / * FIXME keyframe ? * / ) ; if ( pkt . stream_index == stream_index ) { * ppos= pkt . pos ; return pkt . dts ; } } pos = pkt . pos ; } return AV_NOPTS_VALUE ; }",0
"static int rv10_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , UINT8 * buf , int buf_size ) { MpegEncContext * s = avctx - > priv_data ; int i , mb_count , mb_pos , left ; DCTELEM block[6][64] ; AVPicture * pict = data ; ifdef DEBUG printf ( * * * * * frame %d size=%d\n , avctx - > frame_number , buf_size ) ; endif / * no supplementary picture * / if ( buf_size == 0 ) { * data_size = 0 ; return 0 ; } init_get_bits ( & s - > gb , buf , buf_size ) ; mb_count = rv10_decode_picture_header ( s ) ; if ( mb_count < 0 ) { ifdef DEBUG printf ( HEADER ERROR\n ) ; endif return - 1 ; } if ( s - > mb_x > = s - > mb_width || s - > mb_y > = s - > mb_height ) { ifdef DEBUG printf ( POS ERROR %d %d\n , s - > mb_x , s - > mb_y ) ; endif return - 1 ; } mb_pos = s - > mb_y * s - > mb_width + s - > mb_x ; left = s - > mb_width * s - > mb_height - mb_pos ; if ( mb_count > left ) { ifdef DEBUG printf ( COUNT ERROR\n ) ; endif return - 1 ; } if ( s - > mb_x == 0 & & s - > mb_y == 0 ) { MPV_frame_start ( s , avctx ) ; } ifdef DEBUG printf ( qscale=%d\n , s - > qscale ) ; endif / * default quantization values * / s - > y_dc_scale = 8 ; s - > c_dc_scale = 8 ; s - > rv10_first_dc_coded[0] = 0 ; s - > rv10_first_dc_coded[1] = 0 ; s - > rv10_first_dc_coded[2] = 0 ; s - > block_wrap[0]= s - > block_wrap[1]= s - > block_wrap[2]= s - > block_wrap[3]= s - > mb_width * 2 + 2 ; s - > block_wrap[4]= s - > block_wrap[5]= s - > mb_width + 2 ; s - > block_index[0]= s - > block_wrap[0] * ( s - > mb_y * 2 + 1 ) - 1 + s - > mb_x * 2 ; s - > block_index[1]= s - > block_wrap[0] * ( s - > mb_y * 2 + 1 ) + s - > mb_x * 2 ; s - > block_index[2]= s - > block_wrap[0] * ( s - > mb_y * 2 + 2 ) - 1 + s - > mb_x * 2 ; s - > block_index[3]= s - > block_wrap[0] * ( s - > mb_y * 2 + 2 ) + s - > mb_x * 2 ; s - > block_index[4]= s - > block_wrap[4] * ( s - > mb_y + 1 ) + s - > block_wrap[0] * ( s - > mb_height * 2 + 2 ) + s - > mb_x ; s - > block_index[5]= s - > block_wrap[4] * ( s - > mb_y + 1 + s - > mb_height + 2 ) + s - > block_wrap[0] * ( s - > mb_height * 2 + 2 ) + s - > mb_x ; / * decode each macroblock * / for ( i=0 ; i < mb_count ; i + + ) { s - > block_index[0] + =2 ; s - > block_index[1] + =2 ; s - > block_index[2] + =2 ; s - > block_index[3] + =2 ; s - > block_index[4] + + ; s - > block_index[5] + + ; ifdef DEBUG printf ( * * mb x=%d y=%d\n , s - > mb_x , s - > mb_y ) ; endif memset ( block , 0 , sizeof ( block ) ) ; s - > mv_dir = MV_DIR_FORWARD ; s - > mv_type = MV_TYPE_16X16 ; if ( h263_decode_mb ( s , block ) < 0 ) { ifdef DEBUG printf ( ERROR\n ) ; endif return - 1 ; } MPV_decode_mb ( s , block ) ; if ( + + s - > mb_x == s - > mb_width ) { s - > mb_x = 0 ; s - > mb_y + + ; s - > block_index[0]= s - > block_wrap[0] * ( s - > mb_y * 2 + 1 ) - 1 ; s - > block_index[1]= s - > block_wrap[0] * ( s - > mb_y * 2 + 1 ) ; s - > block_index[2]= s - > block_wrap[0] * ( s - > mb_y * 2 + 2 ) - 1 ; s - > block_index[3]= s - > block_wrap[0] * ( s - > mb_y * 2 + 2 ) ; s - > block_index[4]= s - > block_wrap[4] * ( s - > mb_y + 1 ) + s - > block_wrap[0] * ( s - > mb_height * 2 + 2 ) ; s - > block_index[5]= s - > block_wrap[4] * ( s - > mb_y + 1 + s - > mb_height + 2 ) + s - > block_wrap[0] * ( s - > mb_height * 2 + 2 ) ; } } if ( s - > mb_x == 0 & & s - > mb_y == s - > mb_height ) { MPV_frame_end ( s ) ; pict - > data[0] = s - > current_picture[0] ; pict - > data[1] = s - > current_picture[1] ; pict - > data[2] = s - > current_picture[2] ; pict - > linesize[0] = s - > linesize ; pict - > linesize[1] = s - > uvlinesize ; pict - > linesize[2] = s - > uvlinesize ; avctx - > quality = s - > qscale ; * data_size = sizeof ( AVPicture ) ; } else { * data_size = 0 ; } return buf_size ; }",1
"static int http_open ( URLContext * h , const char * uri , int flags ) { HTTPContext * s = h - > priv_data ; h - > is_streamed = 1 ; s - > filesize = - 1 ; av_strlcpy ( s - > location , uri , sizeof ( s - > location ) ) ; if ( s - > headers ) { int len = strlen ( s - > headers ) ; if ( len < 2 || strcmp ( \r\n , s - > headers + len - 2 ) ) av_log ( h , AV_LOG_WARNING , No trailing CRLF found in HTTP header . \n ) ; } return http_open_cnx ( h ) ; }",0
"static int standard_decode_picture_primary_header ( VC9Context * v ) { GetBitContext * gb = & v - > s . gb ; int status = 0 ; if ( v - > finterpflag ) v - > interpfrm = get_bits ( gb , 1 ) ; skip_bits ( gb , 2 ) ; //framecnt unused if ( v - > rangered ) v - > rangeredfrm = get_bits ( gb , 1 ) ; v - > s . pict_type = get_bits ( gb , 1 ) ; if ( v - > s . avctx - > max_b_frames ) { if ( ! v - > s . pict_type ) { if ( get_bits ( gb , 1 ) ) v - > s . pict_type = I_TYPE ; else v - > s . pict_type = B_TYPE ; } else v - > s . pict_type = P_TYPE ; } else v - > s . pict_type + + ; switch ( v - > s . pict_type ) { case I_TYPE : status = decode_i_picture_header ( v ) ; break ; case P_TYPE : status = decode_p_picture_primary_header ( v ) ; break ; case BI_TYPE : case B_TYPE : status = decode_b_picture_primary_header ( v ) ; break ; } if ( status == FRAME_SKIPED ) { av_log ( v - > s . avctx , AV_LOG_INFO , Skipping frame . . . \n ) ; return status ; } return 0 ; }",1
"static FFServerIPAddressACL * parse_dynamic_acl ( FFServerStream * stream , HTTPContext * c ) { FILE * f ; char line[1024] ; char cmd[1024] ; FFServerIPAddressACL * acl = NULL ; int line_num = 0 ; const char * p ; f = fopen ( stream - > dynamic_acl , r ) ; if ( ! f ) { perror ( stream - > dynamic_acl ) ; return NULL ; } acl = av_mallocz ( sizeof ( FFServerIPAddressACL ) ) ; / * Build ACL * / for ( ; ; ) { if ( fgets ( line , sizeof ( line ) , f ) == NULL ) break ; line_num + + ; p = line ; while ( av_isspace ( * p ) ) p + + ; if ( * p == ' \0 ' || * p == ' ' ) continue ; ffserver_get_arg ( cmd , sizeof ( cmd ) , & p ) ; if ( ! av_strcasecmp ( cmd , ACL ) ) ffserver_parse_acl_row ( NULL , NULL , acl , p , stream - > dynamic_acl , line_num ) ; } fclose ( f ) ; return acl ; }",0
"int attribute_align_arg sws_scale ( struct SwsContext * c , const uint8_t * const srcSlice[] , const int srcStride[] , int srcSliceY , int srcSliceH , uint8_t * const dst[] , const int dstStride[] ) { int i , ret ; const uint8_t * src2[4] = { srcSlice[0] , srcSlice[1] , srcSlice[2] , srcSlice[3] } ; uint8_t * dst2[4] = { dst[0] , dst[1] , dst[2] , dst[3] } ; uint8_t * rgb0_tmp = NULL ; // do not mess up sliceDir if we have a trailing 0 - size slice if ( srcSliceH == 0 ) return 0 ; if ( ! check_image_pointers ( srcSlice , c - > srcFormat , srcStride ) ) { av_log ( c , AV_LOG_ERROR , bad src image pointers\n ) ; return 0 ; } if ( ! check_image_pointers ( ( const uint8_t * const * ) dst , c - > dstFormat , dstStride ) ) { av_log ( c , AV_LOG_ERROR , bad dst image pointers\n ) ; return 0 ; } if ( c - > sliceDir == 0 & & srcSliceY ! = 0 & & srcSliceY + srcSliceH ! = c - > srcH ) { av_log ( c , AV_LOG_ERROR , Slices start in the middle ! \n ) ; return 0 ; } if ( c - > sliceDir == 0 ) { if ( srcSliceY == 0 ) c - > sliceDir = 1 ; else c - > sliceDir = - 1 ; } if ( usePal ( c - > srcFormat ) ) { for ( i = 0 ; i < 256 ; i + + ) { int p , r , g , b , y , u , v , a = 0xff ; if ( c - > srcFormat == AV_PIX_FMT_PAL8 ) { p = ( ( const uint32_t * ) ( srcSlice[1] ) ) [i] ; a = ( p > > 24 ) & 0xFF ; r = ( p > > 16 ) & 0xFF ; g = ( p > > 8 ) & 0xFF ; b = p & 0xFF ; } else if ( c - > srcFormat == AV_PIX_FMT_RGB8 ) { r = ( i > > 5 ) * 36 ; g = ( ( i > > 2 ) & 7 ) * 36 ; b = ( i & 3 ) * 85 ; } else if ( c - > srcFormat == AV_PIX_FMT_BGR8 ) { b = ( i > > 6 ) * 85 ; g = ( ( i > > 3 ) & 7 ) * 36 ; r = ( i & 7 ) * 36 ; } else if ( c - > srcFormat == AV_PIX_FMT_RGB4_BYTE ) { r = ( i > > 3 ) * 255 ; g = ( ( i > > 1 ) & 3 ) * 85 ; b = ( i & 1 ) * 255 ; } else if ( c - > srcFormat == AV_PIX_FMT_GRAY8 || c - > srcFormat == AV_PIX_FMT_GRAY8A ) { r = g = b = i ; } else { av_assert1 ( c - > srcFormat == AV_PIX_FMT_BGR4_BYTE ) ; b = ( i > > 3 ) * 255 ; g = ( ( i > > 1 ) & 3 ) * 85 ; r = ( i & 1 ) * 255 ; } define RGB2YUV_SHIFT 15 define BY ( ( int ) ( 0 . 114 * 219 / 255 * ( 1 < < RGB2YUV_SHIFT ) + 0 . 5 ) ) define BV ( - ( int ) ( 0 . 081 * 224 / 255 * ( 1 < < RGB2YUV_SHIFT ) + 0 . 5 ) ) define BU ( ( int ) ( 0 . 500 * 224 / 255 * ( 1 < < RGB2YUV_SHIFT ) + 0 . 5 ) ) define GY ( ( int ) ( 0 . 587 * 219 / 255 * ( 1 < < RGB2YUV_SHIFT ) + 0 . 5 ) ) define GV ( - ( int ) ( 0 . 419 * 224 / 255 * ( 1 < < RGB2YUV_SHIFT ) + 0 . 5 ) ) define GU ( - ( int ) ( 0 . 331 * 224 / 255 * ( 1 < < RGB2YUV_SHIFT ) + 0 . 5 ) ) define RY ( ( int ) ( 0 . 299 * 219 / 255 * ( 1 < < RGB2YUV_SHIFT ) + 0 . 5 ) ) define RV ( ( int ) ( 0 . 500 * 224 / 255 * ( 1 < < RGB2YUV_SHIFT ) + 0 . 5 ) ) define RU ( - ( int ) ( 0 . 169 * 224 / 255 * ( 1 < < RGB2YUV_SHIFT ) + 0 . 5 ) ) y = av_clip_uint8 ( ( RY * r + GY * g + BY * b + ( 33 < < ( RGB2YUV_SHIFT - 1 ) ) ) > > RGB2YUV_SHIFT ) ; u = av_clip_uint8 ( ( RU * r + GU * g + BU * b + ( 257 < < ( RGB2YUV_SHIFT - 1 ) ) ) > > RGB2YUV_SHIFT ) ; v = av_clip_uint8 ( ( RV * r + GV * g + BV * b + ( 257 < < ( RGB2YUV_SHIFT - 1 ) ) ) > > RGB2YUV_SHIFT ) ; c - > pal_yuv[i]= y + ( u < < 8 ) + ( v < < 16 ) + ( a < < 24 ) ; switch ( c - > dstFormat ) { case AV_PIX_FMT_BGR32 : if ! HAVE_BIGENDIAN case AV_PIX_FMT_RGB24 : endif c - > pal_rgb[i]= r + ( g < < 8 ) + ( b < < 16 ) + ( a < < 24 ) ; break ; case AV_PIX_FMT_BGR32_1 : if HAVE_BIGENDIAN case AV_PIX_FMT_BGR24 : endif c - > pal_rgb[i]= a + ( r < < 8 ) + ( g < < 16 ) + ( b < < 24 ) ; break ; case AV_PIX_FMT_RGB32_1 : if HAVE_BIGENDIAN case AV_PIX_FMT_RGB24 : endif c - > pal_rgb[i]= a + ( b < < 8 ) + ( g < < 16 ) + ( r < < 24 ) ; break ; case AV_PIX_FMT_RGB32 : if ! HAVE_BIGENDIAN case AV_PIX_FMT_BGR24 : endif default : c - > pal_rgb[i]= b + ( g < < 8 ) + ( r < < 16 ) + ( a < < 24 ) ; } } } if ( c - > src0Alpha & & ! c - > dst0Alpha & & isALPHA ( c - > dstFormat ) ) { uint8_t * base ; int x , y ; rgb0_tmp = av_malloc ( FFABS ( srcStride[0] ) * srcSliceH + 32 ) ; base = srcStride[0] < 0 ? rgb0_tmp - srcStride[0] * ( srcSliceH - 1 ) : rgb0_tmp ; for ( y=0 ; y < srcSliceH ; y + + ) { memcpy ( base",1
"static av_cold int MPA_encode_init ( AVCodecContext * avctx ) { MpegAudioContext * s = avctx - > priv_data ; int freq = avctx - > sample_rate ; int bitrate = avctx - > bit_rate ; int channels = avctx - > channels ; int i , v , table ; float a ; if ( channels < = 0 || channels > 2 ) { av_log ( avctx , AV_LOG_ERROR , encoding %d channel ( s ) is not allowed in mp2\n , channels ) ; return AVERROR ( EINVAL ) ; } bitrate = bitrate / 1000 ; s - > nb_channels = channels ; avctx - > frame_size = MPA_FRAME_SIZE ; avctx - > delay = 512 - 32 + 1 ; / * encoding freq * / s - > lsf = 0 ; for ( i=0 ; i < 3 ; i + + ) { if ( avpriv_mpa_freq_tab[i] == freq ) break ; if ( ( avpriv_mpa_freq_tab[i] / 2 ) == freq ) { s - > lsf = 1 ; break ; } } if ( i == 3 ) { av_log ( avctx , AV_LOG_ERROR , Sampling rate %d is not allowed in mp2\n , freq ) ; return AVERROR ( EINVAL ) ; } s - > freq_index = i ; / * encoding bitrate & frequency * / for ( i=0 ; i < 15 ; i + + ) { if ( avpriv_mpa_bitrate_tab[s - > lsf][1][i] == bitrate ) break ; } if ( i == 15 ) { av_log ( avctx , AV_LOG_ERROR , bitrate %d is not allowed in mp2\n , bitrate ) ; return AVERROR ( EINVAL ) ; } s - > bitrate_index = i ; / * compute total header size & pad bit * / a = ( float ) ( bitrate * 1000 * MPA_FRAME_SIZE ) / ( freq * 8 . 0 ) ; s - > frame_size = ( ( int ) a ) * 8 ; / * frame fractional size to compute padding * / s - > frame_frac = 0 ; s - > frame_frac_incr = ( int ) ( ( a - floor ( a ) ) * 65536 . 0 ) ; / * select the right allocation table * / table = ff_mpa_l2_select_table ( bitrate , s - > nb_channels , freq , s - > lsf ) ; / * number of used subbands * / s - > sblimit = ff_mpa_sblimit_table[table] ; s - > alloc_table = ff_mpa_alloc_tables[table] ; av_dlog ( avctx , %d kb/s , %d Hz , frame_size=%d bits , table=%d , padincr=%x\n , bitrate , freq , s - > frame_size , table , s - > frame_frac_incr ) ; for ( i=0 ; i < s - > nb_channels ; i + + ) s - > samples_offset[i] = 0 ; for ( i=0 ; i < 257 ; i + + ) { int v ; v = ff_mpa_enwindow[i] ; if WFRAC_BITS ! = 16 v = ( v + ( 1 < < ( 16 - WFRAC_BITS - 1 ) ) ) > > ( 16 - WFRAC_BITS ) ; endif s - > filter_bank[i] = v ; if ( ( i & 63 ) ! = 0 ) v = - v ; if ( i ! = 0 ) s - > filter_bank[512 - i] = v ; } for ( i=0 ; i < 64 ; i + + ) { v = ( int ) ( exp2 ( ( 3 - i ) / 3 . 0 ) * ( 1 < < 20 ) ) ; if ( v < = 0 ) v = 1 ; s - > scale_factor_table[i] = v ; if USE_FLOATS s - > scale_factor_inv_table[i] = exp2 ( - ( 3 - i ) / 3 . 0 ) / ( float ) ( 1 < < 20 ) ; else define P 15 s - > scale_factor_shift[i] = 21 - P - ( i / 3 ) ; s - > scale_factor_mult[i] = ( 1 < < P ) * exp2 ( ( i % 3 ) / 3 . 0 ) ; endif } for ( i=0 ; i < 128 ; i + + ) { v = i - 64 ; if ( v < = - 3 ) v = 0 ; else if ( v < 0 ) v = 1 ; else if ( v == 0 ) v = 2 ; else if ( v < 3 ) v = 3 ; else v = 4 ; s - > scale_diff_table[i] = v ; } for ( i=0 ; i < 17 ; i + + ) { v = ff_mpa_quant_bits[i] ; if ( v < 0 ) v = - v ; else v = v * 3 ; s - > total_quant_bits[i] = 12 * v ; } return 0 ; }",1
"static av_cold int vc1_decode_init ( AVCodecContext * avctx ) { VC1Context * v = avctx - > priv_data ; MpegEncContext * s = & v - > s ; GetBitContext gb ; int ret ; / * save the container output size for WMImage * / v - > output_width = avctx - > width ; v - > output_height = avctx - > height ; if ( ! avctx - > extradata_size || ! avctx - > extradata ) return - 1 ; if ( ! ( avctx - > flags & CODEC_FLAG_GRAY ) ) avctx - > pix_fmt = ff_get_format ( avctx , avctx - > codec - > pix_fmts ) ; else avctx - > pix_fmt = AV_PIX_FMT_GRAY8 ; v - > s . avctx = avctx ; if ( ( ret = ff_vc1_init_common ( v ) ) < 0 ) return ret ; // ensure static VLC tables are initialized if ( ( ret = ff_msmpeg4_decode_init ( avctx ) ) < 0 ) return ret ; if ( ( ret = ff_vc1_decode_init_alloc_tables ( v ) ) < 0 ) return ret ; // Hack to ensure the above functions will be called // again once we know all necessary settings . // That this is necessary might indicate a bug . ff_vc1_decode_end ( avctx ) ; ff_blockdsp_init ( & s - > bdsp , avctx ) ; ff_h264chroma_init ( & v - > h264chroma , 8 ) ; ff_qpeldsp_init ( & s - > qdsp ) ; if ( avctx - > codec_id == AV_CODEC_ID_WMV3 || avctx - > codec_id == AV_CODEC_ID_WMV3IMAGE ) { int count = 0 ; // looks like WMV3 has a sequence header stored in the extradata // advanced sequence header may be before the first frame // the last byte of the extradata is a version number , 1 for the // samples we can decode init_get_bits ( & gb , avctx - > extradata , avctx - > extradata_size * 8 ) ; if ( ( ret = ff_vc1_decode_sequence_header ( avctx , v , & gb ) ) < 0 ) return ret ; count = avctx - > extradata_size * 8 - get_bits_count ( & gb ) ; if ( count > 0 ) { av_log ( avctx , AV_LOG_INFO , Extra data : %i bits left , value : %X\n , count , get_bits ( & gb , count ) ) ; } else if ( count < 0 ) { av_log ( avctx , AV_LOG_INFO , Read %i bits in overflow\n , - count ) ; } } else { // VC1/WVC1/WVP2 const uint8_t * start = avctx - > extradata ; uint8_t * end = avctx - > extradata + avctx - > extradata_size ; const uint8_t * next ; int size , buf2_size ; uint8_t * buf2 = NULL ; int seq_initialized = 0 , ep_initialized = 0 ; if ( avctx - > extradata_size < 16 ) { av_log ( avctx , AV_LOG_ERROR , Extradata size too small : %i\n , avctx - > extradata_size ) ; return - 1 ; } buf2 = av_mallocz ( avctx - > extradata_size + FF_INPUT_BUFFER_PADDING_SIZE ) ; start = find_next_marker ( start , end ) ; // in WVC1 extradata first byte is its size , but can be 0 in mkv next = start ; for ( ; next < end ; start = next ) { next = find_next_marker ( start + 4 , end ) ; size = next - start - 4 ; if ( size < = 0 ) continue ; buf2_size = vc1_unescape_buffer ( start + 4 , size , buf2 ) ; init_get_bits ( & gb , buf2 , buf2_size * 8 ) ; switch ( AV_RB32 ( start ) ) { case VC1_CODE_SEQHDR : if ( ( ret = ff_vc1_decode_sequence_header ( avctx , v , & gb ) ) < 0 ) { av_free ( buf2 ) ; return ret ; } seq_initialized = 1 ; break ; case VC1_CODE_ENTRYPOINT : if ( ( ret = ff_vc1_decode_entry_point ( avctx , v , & gb ) ) < 0 ) { av_free ( buf2 ) ; return ret ; } ep_initialized = 1 ; break ; } } av_free ( buf2 ) ; if ( ! seq_initialized || ! ep_initialized ) { av_log ( avctx , AV_LOG_ERROR , Incomplete extradata\n ) ; return - 1 ; } v - > res_sprite = ( avctx - > codec_id == AV_CODEC_ID_VC1IMAGE ) ; } v - > sprite_output_frame = av_frame_alloc ( ) ; if ( ! v - > sprite_output_frame ) avctx - > profile = v - > profile ; if ( v - > profile == PROFILE_ADVANCED ) avctx - > level = v - > level ; avctx - > has_b_frames = ! ! avctx - > max_b_frames ; if ( v - > color_prim == 1 || v - > color_prim == 5 || v - > color_prim == 6 ) avctx - > color_primaries = v - > color_prim ; if ( v - > transfer_char == 1 || v - > transfer_char == 7 ) avctx - > color_trc = v - > transfer_char ; if ( v - > matrix_coef == 1 || v - > matrix_coef == 6 || v - > matrix_coef == 7 ) avctx - > colorspace = v - > matrix_coef ; s - > mb_width = ( avctx - > coded_width + 15 ) > > 4 ; s - > mb_height = ( avctx - > coded_height + 15 ) > > 4 ; if ( v - > profile == PROFILE_ADVANCED || v - > res_fasttx ) { ff_vc1_init_transposed_scantables ( v ) ; } else { memcpy ( v - > zz_8x8 , ff_wmv1_scantable , 4 * 64 ) ; v - > left_blk_sh = 3 ; v - > top_blk_sh = 0 ; } if ( avctx - > codec_id == AV_CODEC_ID_WMV3IMAGE || avctx - > codec_id == AV_CODEC_ID_VC1IMAGE ) { v - > sprite_width = avctx - > coded_width ; v - > sprite_height = avctx - > coded_height ; avctx - > coded_width = avctx - > width = v - > output_width ; avctx - > coded_height = avctx - > height = v - > output_height ; // prevent 16 . 16 overflows if ( v - > sprite_width > 1 < < 14 || v - > sprite_height > 1 < < 14 || v - > output_width > 1 < < 14 || v - > output_height > 1 < < 14 ) return - 1 ; if ( ( v - > sprite_width & 1 ) || ( v - > sprite_height & 1 ) ) { avpriv_request_sample ( avctx , odd sprites support ) ; return AVERROR_PATCHWELCOME ; } } return 0 ; }",1
"int ff_h264_fill_default_ref_list ( H264Context * h ) { int i , len ; if ( h - > slice_type_nos == AV_PICTURE_TYPE_B ) { Picture * sorted[32] ; int cur_poc , list ; int lens[2] ; if ( FIELD_PICTURE ( h ) ) cur_poc = h - > cur_pic_ptr - > field_poc[h - > picture_structure == PICT_BOTTOM_FIELD] ; else cur_poc = h - > cur_pic_ptr - > poc ; for ( list = 0 ; list < 2 ; list + + ) { len = add_sorted ( sorted , h - > short_ref , h - > short_ref_count , cur_poc , 1 list ) ; len + = add_sorted ( sorted + len , h - > short_ref , h - > short_ref_count , cur_poc , 0 list ) ; assert ( len < = 32 ) ; len = build_def_list ( h - > default_ref_list[list] , sorted , len , 0 , h - > picture_structure ) ; len + = build_def_list ( h - > default_ref_list[list] + len , h - > long_ref , 16 , 1 , h - > picture_structure ) ; assert ( len < = 32 ) ; if ( len < h - > ref_count[list] ) memset ( & h - > default_ref_list[list][len] , 0 , sizeof ( Picture ) * ( h - > ref_count[list] - len ) ) ; lens[list] = len ; } if ( lens[0] == lens[1] & & lens[1] > 1 ) { for ( i = 0 ; i < lens[0] & & h - > default_ref_list[0][i] . f . buf[0] - > buffer == h - > default_ref_list[1][i] . f . buf[0] - > buffer ; i + + ) ; if ( i == lens[0] ) { Picture tmp ; COPY_PICTURE ( & tmp , & h - > default_ref_list[1][0] ) ; COPY_PICTURE ( & h - > default_ref_list[1][0] , & h - > default_ref_list[1][1] ) ; COPY_PICTURE ( & h - > default_ref_list[1][1] , & tmp ) ; } } } else { len = build_def_list ( h - > default_ref_list[0] , h - > short_ref , h - > short_ref_count , 0 , h - > picture_structure ) ; len + = build_def_list ( h - > default_ref_list[0] + len , h - > long_ref , 16 , 1 , h - > picture_structure ) ; assert ( len < = 32 ) ; if ( len < h - > ref_count[0] ) memset ( & h - > default_ref_list[0][len] , 0 , sizeof ( Picture ) * ( h - > ref_count[0] - len ) ) ; } ifdef TRACE for ( i = 0 ; i < h - > ref_count[0] ; i + + ) { tprintf ( h - > avctx , List0 : %s fn : %d 0x%p\n , ( h - > default_ref_list[0][i] . long_ref ? LT : ST ) , h - > default_ref_list[0][i] . pic_id , h - > default_ref_list[0][i] . f . data[0] ) ; } if ( h - > slice_type_nos == AV_PICTURE_TYPE_B ) { for ( i = 0 ; i < h - > ref_count[1] ; i + + ) { tprintf ( h - > avctx , List1 : %s fn : %d 0x%p\n , ( h - > default_ref_list[1][i] . long_ref ? LT : ST ) , h - > default_ref_list[1][i] . pic_id , h - > default_ref_list[1][i] . f . data[0] ) ; } } endif return 0 ; }",1
"static void start_frame ( AVFilterLink * link , AVFilterBufferRef * picref ) { AVFilterContext * ctx = link - > dst ; CropContext * crop = ctx - > priv ; AVFilterBufferRef * ref2 ; int i ; picref - > video - > w = crop - > w ; picref - > video - > h = crop - > h ; ref2 = avfilter_ref_buffer ( picref , 0 ) ; crop - > var_values[VAR_T] = picref - > pts == AV_NOPTS_VALUE ? NAN : picref - > pts * av_q2d ( link - > time_base ) ; crop - > var_values[VAR_POS] = picref - > pos == - 1 ? NAN : picref - > pos ; crop - > var_values[VAR_X] = av_expr_eval ( crop - > x_pexpr , crop - > var_values , NULL ) ; crop - > var_values[VAR_Y] = av_expr_eval ( crop - > y_pexpr , crop - > var_values , NULL ) ; crop - > var_values[VAR_X] = av_expr_eval ( crop - > x_pexpr , crop - > var_values , NULL ) ; normalize_double ( & crop - > x , crop - > var_values[VAR_X] ) ; normalize_double ( & crop - > y , crop - > var_values[VAR_Y] ) ; if ( crop - > x < 0 ) crop - > x = 0 ; if ( crop - > y < 0 ) crop - > y = 0 ; if ( ( unsigned ) crop - > x + ( unsigned ) crop - > w > link - > w ) crop - > x = link - > w - crop - > w ; if ( ( unsigned ) crop - > y + ( unsigned ) crop - > h > link - > h ) crop - > y = link - > h - crop - > h ; crop - > x & = ( ( 1 < < crop - > hsub ) - 1 ) ; crop - > y & = ( ( 1 < < crop - > vsub ) - 1 ) ; av_log ( ctx , AV_LOG_DEBUG , n : %d t : %f x : %d y : %d x + w : %d y + h : %d\n , ( int ) crop - > var_values[VAR_N] , crop - > var_values[VAR_T] , crop - > x , crop - > y , crop - > x + crop - > w , crop - > y + crop - > h ) ; ref2 - > data[0] + = crop - > y * ref2 - > linesize[0] ; ref2 - > data[0] + = crop - > x * crop - > max_step[0] ; if ( ! ( av_pix_fmt_descriptors[link - > format] . flags & PIX_FMT_PAL ) ) { for ( i = 1 ; i < 3 ; i + + ) { if ( ref2 - > data[i] ) { ref2 - > data[i] + = ( crop - > y > > crop - > vsub ) * ref2 - > linesize[i] ; ref2 - > data[i] + = ( crop - > x * crop - > max_step[i] ) > > crop - > hsub ; } } } / * alpha plane * / if ( ref2 - > data[3] ) { ref2 - > data[3] + = crop - > y * ref2 - > linesize[3] ; ref2 - > data[3] + = crop - > x * crop - > max_step[3] ; } avfilter_start_frame ( link - > dst - > outputs[0] , ref2 ) ; }",1
"void ff_ass_init ( AVSubtitle * sub ) { memset ( sub , 0 , sizeof ( * sub ) ) ; }",0
"static void guess_palette ( DVDSubContext * ctx , uint32_t * rgba_palette , uint32_t subtitle_color ) { static const uint8_t level_map[4][4] = { // this configuration ( full range , lowest to highest ) in tests // seemed most common , so assume this { 0xff } , { 0x00 , 0xff } , { 0x00 , 0x80 , 0xff } , { 0x00 , 0x55 , 0xaa , 0xff } , } ; uint8_t color_used[16] = { 0 } ; int nb_opaque_colors , i , level , j , r , g , b ; uint8_t * colormap = ctx - > colormap , * alpha = ctx - > alpha ; if ( ctx - > has_palette ) { for ( i = 0 ; i < 4 ; i + + ) rgba_palette[i] = ( ctx - > palette[colormap[i]] & 0x00ffffff ) | ( ( alpha[i] * 17U ) < < 24 ) ; return ; } for ( i = 0 ; i < 4 ; i + + ) rgba_palette[i] = 0 ; nb_opaque_colors = 0 ; for ( i = 0 ; i < 4 ; i + + ) { if ( alpha[i] ! = 0 & & ! color_used[colormap[i]] ) { color_used[colormap[i]] = 1 ; nb_opaque_colors + + ; } } if ( nb_opaque_colors == 0 ) return ; j = 0 ; memset ( color_used , 0 , 16 ) ; for ( i = 0 ; i < 4 ; i + + ) { if ( alpha[i] ! = 0 ) { if ( ! color_used[colormap[i]] ) { level = level_map[nb_opaque_colors - 1][j] ; r = ( ( ( subtitle_color > > 16 ) & 0xff ) * level ) > > 8 ; g = ( ( ( subtitle_color > > 8 ) & 0xff ) * level ) > > 8 ; b = ( ( ( subtitle_color > > 0 ) & 0xff ) * level ) > > 8 ; rgba_palette[i] = b | ( g < < 8 ) | ( r < < 16 ) | ( ( alpha[i] * 17 ) < < 24 ) ; color_used[colormap[i]] = ( i + 1 ) ; j + + ; } else { rgba_palette[i] = ( rgba_palette[color_used[colormap[i]] - 1] & 0x00ffffff ) | ( ( alpha[i] * 17 ) < < 24 ) ; } } } }",1
"int ff_generate_sliding_window_mmcos ( H264Context * h , int first_slice ) { MMCO mmco_temp[MAX_MMCO_COUNT] , * mmco = first_slice ? h - > mmco : mmco_temp ; int mmco_index = 0 , i ; assert ( h - > long_ref_count + h - > short_ref_count < = h - > sps . ref_frame_count ) ; if ( h - > short_ref_count & & h - > long_ref_count + h - > short_ref_count == h - > sps . ref_frame_count & & ! ( FIELD_PICTURE ( h ) & & ! h - > first_field & & h - > cur_pic_ptr - > reference ) ) { mmco[0] . opcode = MMCO_SHORT2UNUSED ; mmco[0] . short_pic_num = h - > short_ref[h - > short_ref_count - 1] - > frame_num ; mmco_index = 1 ; if ( FIELD_PICTURE ( h ) ) { mmco[0] . short_pic_num * = 2 ; mmco[1] . opcode = MMCO_SHORT2UNUSED ; mmco[1] . short_pic_num = mmco[0] . short_pic_num + 1 ; mmco_index = 2 ; } } if ( first_slice ) { h - > mmco_index = mmco_index ; } else if ( ! first_slice & & mmco_index > = 0 & & ( mmco_index ! = h - > mmco_index || ( i = check_opcodes ( h - > mmco , mmco_temp , mmco_index ) ) ) ) { av_log ( h - > avctx , AV_LOG_ERROR , Inconsistent MMCO state between slices [%d , %d , %d]\n , mmco_index , h - > mmco_index , i ) ; return AVERROR_INVALIDDATA ; } return 0 ; }",1
"ImgReSampleContext * img_resample_full_init ( int owidth , int oheight , int iwidth , int iheight , int topBand , int bottomBand , int leftBand , int rightBand , int padtop , int padbottom , int padleft , int padright ) { ImgReSampleContext * s ; s = av_mallocz ( sizeof ( ImgReSampleContext ) ) ; if ( ! s ) s - > line_buf = av_mallocz ( owidth * ( LINE_BUF_HEIGHT + NB_TAPS ) ) ; if ( ! s - > line_buf ) goto fail ; s - > owidth = owidth ; s - > oheight = oheight ; s - > iwidth = iwidth ; s - > iheight = iheight ; s - > topBand = topBand ; s - > bottomBand = bottomBand ; s - > leftBand = leftBand ; s - > rightBand = rightBand ; s - > padtop = padtop ; s - > padbottom = padbottom ; s - > padleft = padleft ; s - > padright = padright ; s - > pad_owidth = owidth - ( padleft + padright ) ; s - > pad_oheight = oheight - ( padtop + padbottom ) ; s - > h_incr = ( ( iwidth - leftBand - rightBand ) * POS_FRAC ) / s - > pad_owidth ; s - > v_incr = ( ( iheight - topBand - bottomBand ) * POS_FRAC ) / s - > pad_oheight ; av_build_filter ( & s - > h_filters[0][0] , ( float ) s - > pad_owidth / ( float ) ( iwidth - leftBand - rightBand ) , NB_TAPS , NB_PHASES , 1 < < FILTER_BITS , 0 ) ; av_build_filter ( & s - > v_filters[0][0] , ( float ) s - > pad_oheight / ( float ) ( iheight - topBand - bottomBand ) , NB_TAPS , NB_PHASES , 1 < < FILTER_BITS , 0 ) ; return s ; fail : av_free ( s ) ; }",1
"static inline void idct4col_add ( uint8_t * dest , int line_size , const DCTELEM * col ) { int c0 , c1 , c2 , c3 , a0 , a1 , a2 , a3 ; const uint8_t * cm = ff_cropTbl + MAX_NEG_CROP ; a0 = col[8 * 0] ; a1 = col[8 * 1] ; a2 = col[8 * 2] ; a3 = col[8 * 3] ; c0 = ( a0 + a2 ) * C3 + ( 1 < < ( C_SHIFT - 1 ) ) ; c2 = ( a0 - a2 ) * C3 + ( 1 < < ( C_SHIFT - 1 ) ) ; c1 = a1 * C1 + a3 * C2 ; c3 = a1 * C2 - a3 * C1 ; dest[0] = cm[dest[0] + ( ( c0 + c1 ) > > C_SHIFT ) ] ; dest + = line_size ; dest[0] = cm[dest[0] + ( ( c2 + c3 ) > > C_SHIFT ) ] ; dest + = line_size ; dest[0] = cm[dest[0] + ( ( c2 - c3 ) > > C_SHIFT ) ] ; dest + = line_size ; dest[0] = cm[dest[0] + ( ( c0 - c1 ) > > C_SHIFT ) ] ; }",1
"void ff_slice_buffer_init ( slice_buffer * buf , int line_count , int max_allocated_lines , int line_width , IDWTELEM * base_buffer ) { int i ; buf - > base_buffer = base_buffer ; buf - > line_count = line_count ; buf - > line_width = line_width ; buf - > data_count = max_allocated_lines ; buf - > line = av_mallocz ( sizeof ( IDWTELEM * ) * line_count ) ; buf - > data_stack = av_malloc ( sizeof ( IDWTELEM * ) * max_allocated_lines ) ; for ( i = 0 ; i < max_allocated_lines ; i + + ) buf - > data_stack[i] = av_malloc ( sizeof ( IDWTELEM ) * line_width ) ; buf - > data_stack_top = max_allocated_lines - 1 ; }",0
int ffurl_get_file_handle ( URLContext * h ) { if ( ! h - > prot - > url_get_file_handle ) return - 1 ; return h - > prot - > url_get_file_handle ( h ) ; },0
"av_cold void ff_rv40dsp_init ( RV34DSPContext * c , DSPContext * dsp ) { ff_rv34dsp_init ( c , dsp ) ; c - > put_pixels_tab[0][ 0] = dsp - > put_h264_qpel_pixels_tab[0][0] ; c - > put_pixels_tab[0][ 1] = put_rv40_qpel16_mc10_c ; c - > put_pixels_tab[0][ 2] = dsp - > put_h264_qpel_pixels_tab[0][2] ; c - > put_pixels_tab[0][ 3] = put_rv40_qpel16_mc30_c ; c - > put_pixels_tab[0][ 4] = put_rv40_qpel16_mc01_c ; c - > put_pixels_tab[0][ 5] = put_rv40_qpel16_mc11_c ; c - > put_pixels_tab[0][ 6] = put_rv40_qpel16_mc21_c ; c - > put_pixels_tab[0][ 7] = put_rv40_qpel16_mc31_c ; c - > put_pixels_tab[0][ 8] = dsp - > put_h264_qpel_pixels_tab[0][8] ; c - > put_pixels_tab[0][ 9] = put_rv40_qpel16_mc12_c ; c - > put_pixels_tab[0][10] = put_rv40_qpel16_mc22_c ; c - > put_pixels_tab[0][11] = put_rv40_qpel16_mc32_c ; c - > put_pixels_tab[0][12] = put_rv40_qpel16_mc03_c ; c - > put_pixels_tab[0][13] = put_rv40_qpel16_mc13_c ; c - > put_pixels_tab[0][14] = put_rv40_qpel16_mc23_c ; c - > put_pixels_tab[0][15] = ff_put_rv40_qpel16_mc33_c ; c - > avg_pixels_tab[0][ 0] = dsp - > avg_h264_qpel_pixels_tab[0][0] ; c - > avg_pixels_tab[0][ 1] = avg_rv40_qpel16_mc10_c ; c - > avg_pixels_tab[0][ 2] = dsp - > avg_h264_qpel_pixels_tab[0][2] ; c - > avg_pixels_tab[0][ 3] = avg_rv40_qpel16_mc30_c ; c - > avg_pixels_tab[0][ 4] = avg_rv40_qpel16_mc01_c ; c - > avg_pixels_tab[0][ 5] = avg_rv40_qpel16_mc11_c ; c - > avg_pixels_tab[0][ 6] = avg_rv40_qpel16_mc21_c ; c - > avg_pixels_tab[0][ 7] = avg_rv40_qpel16_mc31_c ; c - > avg_pixels_tab[0][ 8] = dsp - > avg_h264_qpel_pixels_tab[0][8] ; c - > avg_pixels_tab[0][ 9] = avg_rv40_qpel16_mc12_c ; c - > avg_pixels_tab[0][10] = avg_rv40_qpel16_mc22_c ; c - > avg_pixels_tab[0][11] = avg_rv40_qpel16_mc32_c ; c - > avg_pixels_tab[0][12] = avg_rv40_qpel16_mc03_c ; c - > avg_pixels_tab[0][13] = avg_rv40_qpel16_mc13_c ; c - > avg_pixels_tab[0][14] = avg_rv40_qpel16_mc23_c ; c - > avg_pixels_tab[0][15] = ff_avg_rv40_qpel16_mc33_c ; c - > put_pixels_tab[1][ 0] = dsp - > put_h264_qpel_pixels_tab[1][0] ; c - > put_pixels_tab[1][ 1] = put_rv40_qpel8_mc10_c ; c - > put_pixels_tab[1][ 2] = dsp - > put_h264_qpel_pixels_tab[1][2] ; c - > put_pixels_tab[1][ 3] = put_rv40_qpel8_mc30_c ; c - > put_pixels_tab[1][ 4] = put_rv40_qpel8_mc01_c ; c - > put_pixels_tab[1][ 5] = put_rv40_qpel8_mc11_c ; c - > put_pixels_tab[1][ 6] = put_rv40_qpel8_mc21_c ; c - > put_pixels_tab[1][ 7] = put_rv40_qpel8_mc31_c ; c - > put_pixels_tab[1][ 8] = dsp - > put_h264_qpel_pixels_tab[1][8] ; c - > put_pixels_tab[1][ 9] = put_rv40_qpel8_mc12_c ; c - > put_pixels_tab[1][10] = put_rv40_qpel8_mc22_c ; c - > put_pixels_tab[1][11] = put_rv40_qpel8_mc32_c ; c - > put_pixels_tab[1][12] = put_rv40_qpel8_mc03_c ; c - > put_pixels_tab[1][13] = put_rv40_qpel8_mc13_c ; c - > put_pixels_tab[1][14] = put_rv40_qpel8_mc23_c ; c - > put_pixels_tab[1][15] = ff_put_rv40_qpel8_mc33_c ; c - > avg_pixels_tab[1][ 0] = dsp - > avg_h264_qpel_pixels_tab[1][0] ; c - > avg_pixels_tab[1][ 1] = avg_rv40_qpel8_mc10_c ; c - > avg_pixels_tab[1][ 2] = dsp - > avg_h264_qpel_pixels_tab[1][2] ; c - > avg_pixels_tab[1][ 3] = avg_rv40_qpel8_mc30_c ; c - > avg_pixels_tab[1][ 4] = avg_rv40_qpel8_mc01_c ; c - > avg_pixels_tab[1][ 5] = avg_rv40_qpel8_mc11_c ; c - > avg_pixels_tab[1][ 6] = avg_rv40_qpel8_mc21_c ; c - > avg_pixels_tab[1][ 7] = avg_rv40_qpel8_mc31_c ; c - > avg_pixels_tab[1][ 8] = dsp - > avg_h264_qpel_pixels_tab[1][8] ; c - > avg_pixels_tab[1][ 9] = avg_rv40_qpel8_mc12_c ; c - > avg_pixels_tab[1][10] = avg_rv40_qpel8_mc22_c ; c - > avg_pixels_tab[1][11] = avg_rv40_qpel8_mc32_c ; c - > avg_pixels_tab[1][12] = avg_rv40_qpel8_mc03_c ; c - > avg_pixels_tab[1][13] = avg_rv40_qpel8_mc13_c ; c - > avg_pixels_tab[1][14] = avg_rv40_qpel8_mc23_c ; c - > avg_pixels_tab[1][15] = ff_avg_rv40_qpel8_mc33_c ; c - > put_chroma_pixels_tab[0] = put_rv40_chroma_mc8_c ; c - > put_chroma_pixels_tab[1] = put_rv40_chroma_mc4_c ; c - > avg_chroma_pixels_tab[0] = avg_rv40_chroma_mc8_c ; c - > avg_chroma_pixels_tab[1] = avg_rv40_chroma_mc4_c ; c - > rv40_weight_pixels_tab[0][0] = rv40_weight_func_rnd_16 ; c - > rv40_weight_pixels_tab[0][1] = rv40_weight_func_rnd_8 ; c - > rv40_weight_pixels_tab[1][0] = rv40_weight_func_nornd_16 ; c - > rv40_weight_pixels_tab[1][1] = rv40_weight_func_nornd_8 ; c - > rv40_weak_loop_filter[0] = rv40_h_weak_loop_filter ; c - > rv40_weak_loop_filter[1] = rv40_v_weak_loop_filter ; c - > rv40_strong_loop_filter[0] = rv40_h_strong_loop_filter ; c - > rv40_strong_loop_filter[1] = rv40_v_strong_loop_filter ; c - > rv40_loop_filter_strength[0] = rv40_h_loop_filter_strength ; c - > rv40_loop_filter_strength[1] = rv40_v_loop_filter_strength ; if ( ARCH_X86 ) ff_rv40dsp_init_x86 ( c , dsp ) ; if ( HAVE_NEON ) ff_rv40dsp_init_neon ( c , dsp ) ; }",0
"static int decode_nal_units ( HEVCContext * s , const uint8_t * buf , int length ) { int i , consumed , ret = 0 ; s - > ref = NULL ; s - > eos = 0 ; / * split the input packet into NAL units , so we know the upper bound on the * number of slices in the frame * / s - > nb_nals = 0 ; while ( length > = 4 ) { HEVCNAL * nal ; int extract_length = 0 ; if ( s - > is_nalff ) { int i ; for ( i = 0 ; i < s - > nal_length_size ; i + + ) extract_length = ( extract_length < < 8 ) | buf[i] ; buf + = s - > nal_length_size ; length - = s - > nal_length_size ; if ( extract_length > length ) { av_log ( s - > avctx , AV_LOG_ERROR , Invalid NAL unit size . \n ) ; ret = AVERROR_INVALIDDATA ; goto fail ; } } else { if ( buf[2] == 0 ) { length - - ; buf + + ; continue ; } if ( buf[0] ! = 0 || buf[1] ! = 0 || buf[2] ! = 1 ) { ret = AVERROR_INVALIDDATA ; goto fail ; } buf + = 3 ; length - = 3 ; } if ( ! s - > is_nalff ) extract_length = length ; if ( s - > nals_allocated < s - > nb_nals + 1 ) { int new_size = s - > nals_allocated + 1 ; HEVCNAL * tmp = av_realloc_array ( s - > nals , new_size , sizeof ( * tmp ) ) ; if ( ! tmp ) { ret = AVERROR ( ENOMEM ) ; goto fail ; } s - > nals = tmp ; memset ( s - > nals + s - > nals_allocated , 0 , ( new_size - s - > nals_allocated ) * sizeof ( * tmp ) ) ; av_reallocp_array ( & s - > skipped_bytes_nal , new_size , sizeof ( * s - > skipped_bytes_nal ) ) ; av_reallocp_array ( & s - > skipped_bytes_pos_size_nal , new_size , sizeof ( * s - > skipped_bytes_pos_size_nal ) ) ; av_reallocp_array ( & s - > skipped_bytes_pos_nal , new_size , sizeof ( * s - > skipped_bytes_pos_nal ) ) ; s - > skipped_bytes_pos_size_nal[s - > nals_allocated] = 1024 ; // initial buffer size s - > skipped_bytes_pos_nal[s - > nals_allocated] = av_malloc_array ( s - > skipped_bytes_pos_size_nal[s - > nals_allocated] , sizeof ( * s - > skipped_bytes_pos ) ) ; s - > nals_allocated = new_size ; } s - > skipped_bytes_pos_size = s - > skipped_bytes_pos_size_nal[s - > nb_nals] ; s - > skipped_bytes_pos = s - > skipped_bytes_pos_nal[s - > nb_nals] ; nal = & s - > nals[s - > nb_nals] ; consumed = extract_rbsp ( s , buf , extract_length , nal ) ; s - > skipped_bytes_nal[s - > nb_nals] = s - > skipped_bytes ; s - > skipped_bytes_pos_size_nal[s - > nb_nals] = s - > skipped_bytes_pos_size ; s - > skipped_bytes_pos_nal[s - > nb_nals + + ] = s - > skipped_bytes_pos ; if ( consumed < 0 ) { ret = consumed ; goto fail ; } ret = init_get_bits8 ( & s - > HEVClc - > gb , nal - > data , nal - > size ) ; if ( ret < 0 ) goto fail ; hls_nal_unit ( s ) ; if ( s - > nal_unit_type == NAL_EOS_NUT || s - > nal_unit_type == NAL_EOB_NUT ) s - > eos = 1 ; buf + = consumed ; length - = consumed ; } / * parse the NAL units * / for ( i = 0 ; i < s - > nb_nals ; i + + ) { int ret ; s - > skipped_bytes = s - > skipped_bytes_nal[i] ; s - > skipped_bytes_pos = s - > skipped_bytes_pos_nal[i] ; ret = decode_nal_unit ( s , s - > nals[i] . data , s - > nals[i] . size ) ; if ( ret < 0 ) { av_log ( s - > avctx , AV_LOG_WARNING , Error parsing NAL unit %d . \n , i ) ; if ( s - > avctx - > err_recognition & AV_EF_EXPLODE ) goto fail ; } } fail : if ( s - > ref & & s - > threads_type == FF_THREAD_FRAME ) ff_thread_report_progress ( & s - > ref - > tf , INT_MAX , 0 ) ; return ret ; }",0
"static void ttafilter_init ( TTAContext * s , TTAFilter * c , int32_t shift ) { memset ( c , 0 , sizeof ( TTAFilter ) ) ; if ( s - > pass ) { int i ; for ( i = 0 ; i < 8 ; i + + ) c - > qm[i] = sign_extend ( s - > crc_pass[i] , 8 ) ; } c - > shift = shift ; c - > round = shift_1[shift - 1] ; // c - > round = 1 < < ( shift - 1 ) ; }",0
"static inline int vc1_pred_dc ( MpegEncContext * s , int overlap , int pq , int n , int a_avail , int c_avail , int16_t * * dc_val_ptr , int * dir_ptr ) { int a , b , c , wrap , pred ; int16_t * dc_val ; int mb_pos = s - > mb_x + s - > mb_y * s - > mb_stride ; int q1 , q2 = 0 ; wrap = s - > block_wrap[n] ; dc_val = s - > dc_val[0] + s - > block_index[n] ; / * B A * C X * / c = dc_val[ - 1] ; b = dc_val[ - 1 - wrap] ; a = dc_val[ - wrap] ; / * scale predictors if needed * / q1 = s - > current_picture . f . qscale_table[mb_pos] ; if ( c_avail & & ( n ! = 1 & & n ! = 3 ) ) { q2 = s - > current_picture . f . qscale_table[mb_pos - 1] ; if ( q2 & & q2 ! = q1 ) c = ( c * s - > y_dc_scale_table[q2] * ff_vc1_dqscale[s - > y_dc_scale_table[q1] - 1] + 0x20000 ) > > 18 ; } if ( a_avail & & ( n ! = 2 & & n ! = 3 ) ) { q2 = s - > current_picture . f . qscale_table[mb_pos - s - > mb_stride] ; if ( q2 & & q2 ! = q1 ) a = ( a * s - > y_dc_scale_table[q2] * ff_vc1_dqscale[s - > y_dc_scale_table[q1] - 1] + 0x20000 ) > > 18 ; } if ( a_avail & & c_avail & & ( n ! = 3 ) ) { int off = mb_pos ; if ( n ! = 1 ) off - - ; if ( n ! = 2 ) off - = s - > mb_stride ; q2 = s - > current_picture . f . qscale_table[off] ; if ( q2 & & q2 ! = q1 ) b = ( b * s - > y_dc_scale_table[q2] * ff_vc1_dqscale[s - > y_dc_scale_table[q1] - 1] + 0x20000 ) > > 18 ; } if ( a_avail & & c_avail ) { if ( abs ( a - b ) < = abs ( b - c ) ) { pred = c ; * dir_ptr = 1 ; // left } else { pred = a ; * dir_ptr = 0 ; // top } } else if ( a_avail ) { pred = a ; * dir_ptr = 0 ; // top } else if ( c_avail ) { pred = c ; * dir_ptr = 1 ; // left } else { pred = 0 ; * dir_ptr = 1 ; // left } / * update predictor * / * dc_val_ptr = & dc_val[0] ; return pred ; }",0
static av_cold int qsv_decode_close ( AVCodecContext * avctx ) { QSVOtherContext * s = avctx - > priv_data ; ff_qsv_decode_close ( & s - > qsv ) ; qsv_clear_buffers ( s ) ; av_fifo_free ( s - > packet_fifo ) ; return 0 ; },1
"int ff_ass_split_override_codes ( const ASSCodesCallbacks * callbacks , void * priv , const char * buf ) { const char * text = NULL ; char new_line[2] ; int text_len = 0 ; while ( * buf ) { if ( text & & callbacks - > text & & ( sscanf ( buf , \\%1[nN] , new_line ) == 1 || ! strncmp ( buf , { \\ , 2 ) ) ) { callbacks - > text ( priv , text , text_len ) ; text = NULL ; } if ( sscanf ( buf , \\%1[nN] , new_line ) == 1 ) { if ( callbacks - > new_line ) callbacks - > new_line ( priv , new_line[0] == ' N ' ) ; buf + = 2 ; } else if ( ! strncmp ( buf , { \\ , 2 ) ) { buf + + ; while ( * buf == ' \\ ' ) { char style[2] , c[2] , sep[2] , c_num[2] = 0 , tmp[128] = { 0 } ; unsigned int color = 0xFFFFFFFF ; int len , size = - 1 , an = - 1 , alpha = - 1 ; int x1 , y1 , x2 , y2 , t1 = - 1 , t2 = - 1 ; if ( sscanf ( buf , \\%1[bisu]%1[01\\ } ]%n , style , c , & len ) > 1 ) { int close = c[0] == ' 0 ' ? 1 : c[0] == ' 1 ' ? 0 : - 1 ; len + = close ! = - 1 ; if ( callbacks - > style ) callbacks - > style ( priv , style[0] , close ) ; } else if ( sscanf ( buf , \\c%1[\\ } ]%n , sep , & len ) > 0 || sscanf ( buf , \\c & H%X & %1[\\ } ]%n , & color , sep , & len ) > 1 || sscanf ( buf , \\%1[1234]c%1[\\ } ]%n , c_num , sep , & len ) > 1 || sscanf ( buf , \\%1[1234]c & H%X & %1[\\ } ]%n , c_num , & color , sep , & len ) > 2 ) { if ( callbacks - > color ) callbacks - > color ( priv , color , c_num[0] - ' 0 ' ) ; } else if ( sscanf ( buf , \\alpha%1[\\ } ]%n , sep , & len ) > 0 || sscanf ( buf , \\alpha & H%2X & %1[\\ } ]%n , & alpha , sep , & len ) > 1 || sscanf ( buf , \\%1[1234]a%1[\\ } ]%n , c_num , sep , & len ) > 1 || sscanf ( buf , \\%1[1234]a & H%2X & %1[\\ } ]%n , c_num , & alpha , sep , & len ) > 2 ) { if ( callbacks - > alpha ) callbacks - > alpha ( priv , alpha , c_num[0] - ' 0 ' ) ; } else if ( sscanf ( buf , \\fn%1[\\ } ]%n , sep , & len ) > 0 || sscanf ( buf , \\fn%127[ \\ } ]%1[\\ } ]%n , tmp , sep , & len ) > 1 ) { if ( callbacks - > font_name ) callbacks - > font_name ( priv , tmp[0] ? tmp : NULL ) ; } else if ( sscanf ( buf , \\fs%1[\\ } ]%n , sep , & len ) > 0 || sscanf ( buf , \\fs%u%1[\\ } ]%n , & size , sep , & len ) > 1 ) { if ( callbacks - > font_size ) callbacks - > font_size ( priv , size ) ; } else if ( sscanf ( buf , \\a%1[\\ } ]%n , sep , & len ) > 0 || sscanf ( buf , \\a%2u%1[\\ } ]%n , & an , sep , & len ) > 1 || sscanf ( buf , \\an%1[\\ } ]%n , sep , & len ) > 0 || sscanf ( buf , \\an%1u%1[\\ } ]%n , & an , sep , & len ) > 1 ) { if ( an ! = - 1 & & buf[2] ! = ' n ' ) an = ( an & 3 ) + ( an & 4 ? 6 : an & 8 ? 3 : 0 ) ; if ( callbacks - > alignment ) callbacks - > alignment ( priv , an ) ; } else if ( sscanf ( buf , \\r%1[\\ } ]%n , sep , & len ) > 0 || sscanf ( buf , \\r%127[ \\ } ]%1[\\ } ]%n , tmp , sep , & len ) > 1 ) { if ( callbacks - > cancel_overrides ) callbacks - > cancel_overrides ( priv , tmp ) ; } else if ( sscanf ( buf , \\move ( %d , %d , %d , %d ) %1[\\ } ]%n , & x1 , & y1 , & x2 , & y2 , sep , & len ) > 4 || sscanf ( buf , \\move ( %d , %d , %d , %d , %d , %d ) %1[\\ } ]%n , & x1 , & y1 , & x2 , & y2 , & t1 , & t2 , sep , & len ) > 6 ) { if ( callbacks - > move ) callbacks - > move ( priv , x1 , y1 , x2 , y2 , t1 , t2 ) ; } else if ( sscanf ( buf , \\pos ( %d , %d ) %1[\\ } ]%n , & x1 , & y1 , sep , & len ) > 2 ) { if ( callbacks - > move ) callbacks - > move ( priv , x1 , y1 , x1 , y1 , - 1 , - 1 ) ; } else if ( sscanf ( buf , \\org ( %d , %d ) %1[\\ } ]%n , & x1 , & y1 , sep , & len ) > 2 ) { if ( callbacks - > origin ) callbacks - > origin ( priv , x1 , y1 ) ; } else { len = strcspn ( buf + 1 , \\ } ) + 2 ; / * skip unknown code * / } buf + = len - 1 ; } if ( * buf + + ! = ' } ' ) return AVERROR_INVALIDDATA ; } else { if ( ! text ) { text = buf ; text_len = 1 ; } else text_len + + ; buf + + ; } } if ( text & & callbacks - > text ) callbacks - > text ( priv , text , text_len ) ; if ( callbacks - > end ) callbacks - > end ( priv ) ; return 0 ; }",1
"int avio_get_str ( AVIOContext * s , int maxlen , char * buf , int buflen ) { int i ; // reserve 1 byte for terminating 0 buflen = FFMIN ( buflen - 1 , maxlen ) ; for ( i = 0 ; i < buflen ; i + + ) if ( ! ( buf[i] = avio_r8 ( s ) ) ) return i + 1 ; if ( buflen ) buf[i] = 0 ; for ( ; i < maxlen ; i + + ) if ( ! avio_r8 ( s ) ) return i + 1 ; return maxlen ; }",0
"static int RENAME ( swScale ) ( SwsContext * c , const uint8_t * src[] , int srcStride[] , int srcSliceY , int srcSliceH , uint8_t * dst[] , int dstStride[] ) { / * load a few things into local vars to make the code more readable ? and faster * / const int srcW= c - > srcW ; const int dstW= c - > dstW ; const int dstH= c - > dstH ; const int chrDstW= c - > chrDstW ; const int chrSrcW= c - > chrSrcW ; const int lumXInc= c - > lumXInc ; const int chrXInc= c - > chrXInc ; const enum PixelFormat dstFormat= c - > dstFormat ; const int flags= c - > flags ; int16_t * vLumFilterPos= c - > vLumFilterPos ; int16_t * vChrFilterPos= c - > vChrFilterPos ; int16_t * hLumFilterPos= c - > hLumFilterPos ; int16_t * hChrFilterPos= c - > hChrFilterPos ; int16_t * vLumFilter= c - > vLumFilter ; int16_t * vChrFilter= c - > vChrFilter ; int16_t * hLumFilter= c - > hLumFilter ; int16_t * hChrFilter= c - > hChrFilter ; int32_t * lumMmxFilter= c - > lumMmxFilter ; int32_t * chrMmxFilter= c - > chrMmxFilter ; int32_t av_unused * alpMmxFilter= c - > alpMmxFilter ; const int vLumFilterSize= c - > vLumFilterSize ; const int vChrFilterSize= c - > vChrFilterSize ; const int hLumFilterSize= c - > hLumFilterSize ; const int hChrFilterSize= c - > hChrFilterSize ; int16_t * * lumPixBuf= c - > lumPixBuf ; int16_t * * chrPixBuf= c - > chrPixBuf ; int16_t * * alpPixBuf= c - > alpPixBuf ; const int vLumBufSize= c - > vLumBufSize ; const int vChrBufSize= c - > vChrBufSize ; uint8_t * formatConvBuffer= c - > formatConvBuffer ; const int chrSrcSliceY= srcSliceY > > c - > chrSrcVSubSample ; const int chrSrcSliceH= - ( ( - srcSliceH ) > > c - > chrSrcVSubSample ) ; int lastDstY ; uint32_t * pal=c - > pal_yuv ; / * vars which will change and which we need to store back in the context * / int dstY= c - > dstY ; int lumBufIndex= c - > lumBufIndex ; int chrBufIndex= c - > chrBufIndex ; int lastInLumBuf= c - > lastInLumBuf ; int lastInChrBuf= c - > lastInChrBuf ; if ( isPacked ( c - > srcFormat ) ) { src[0]= src[1]= src[2]= src[3]= src[0] ; srcStride[0]= srcStride[1]= srcStride[2]= srcStride[3]= srcStride[0] ; } srcStride[1] < < = c - > vChrDrop ; srcStride[2] < < = c - > vChrDrop ; DEBUG_BUFFERS ( swScale ( ) %p[%d] %p[%d] %p[%d] %p[%d] - > %p[%d] %p[%d] %p[%d] %p[%d]\n , src[0] , srcStride[0] , src[1] , srcStride[1] , src[2] , srcStride[2] , src[3] , srcStride[3] , dst[0] , dstStride[0] , dst[1] , dstStride[1] , dst[2] , dstStride[2] , dst[3] , dstStride[3] ) ; DEBUG_BUFFERS ( srcSliceY : %d srcSliceH : %d dstY : %d dstH : %d\n , srcSliceY , srcSliceH , dstY , dstH ) ; DEBUG_BUFFERS ( vLumFilterSize : %d vLumBufSize : %d vChrFilterSize : %d vChrBufSize : %d\n , vLumFilterSize , vLumBufSize , vChrFilterSize , vChrBufSize ) ; if ( dstStride[0]%8 ! =0 || dstStride[1]%8 ! =0 || dstStride[2]%8 ! =0 || dstStride[3]%8 ! = 0 ) { static int warnedAlready=0 ; //FIXME move this into the context perhaps if ( flags & SWS_PRINT_INFO & & ! warnedAlready ) { av_log ( c , AV_LOG_WARNING , Warning : dstStride is not aligned ! \n - > cannot do aligned memory accesses anymore\n ) ; warnedAlready=1 ; } } / * Note the user might start scaling the picture in the middle so this will not get executed . This is not really intended but works currently , so people might do it . * / if ( srcSliceY ==0 ) { lumBufIndex= - 1 ; chrBufIndex= - 1 ; dstY=0 ; lastInLumBuf= - 1 ; lastInChrBuf= - 1 ; } lastDstY= dstY ; for ( ; dstY < dstH ; dstY + + ) { unsigned char * dest =dst[0] + dstStride[0] * dstY ; const int chrDstY= dstY > > c - > chrDstVSubSample ; unsigned char * uDest=dst[1] + dstStride[1] * chrDstY ; unsigned char * vDest=dst[2] + dstStride[2] * chrDstY ; unsigned char * aDest= ( CONFIG_SWSCALE_ALPHA & & alpPixBuf ) ? dst[3] + dstStride[3] * dstY : NULL ; const int firstLumSrcY= vLumFilterPos[dstY] ; //First line needed as input const int firstLumSrcY2= vLumFilterPos[FFMIN ( dstY | ( ( 1 < < c - > chrDstVSubSample ) - 1 ) , dstH - 1 ) ] ; const int firstChrSrcY= vChrFilterPos[chrDstY] ; //First line needed as input int lastLumSrcY= firstLumSrcY + vLumFilterSize - 1 ; // Last line needed as input int lastLumSrcY2=firstLumSrcY2 + vLumFilterSize - 1 ; // Last line needed as input int lastChrSrcY= firstChrSrcY + vChrFilterSize - 1 ; // Last line needed as input int enough_lines ; //handle holes ( FAST_BILINEAR & weird filters ) if ( firstLumSrcY > lastInLumBuf ) lastInLumBuf= firstLumSrcY - 1 ; if ( firstChrSrcY > lastInChrBuf ) lastInChrBuf= firstChrSrcY - 1 ; assert ( firstLumSrcY > = lastInLumBuf - vLumBufSize + 1 ) ; assert ( firstChrSrcY > = lastInChrBuf - vChrBufSize + 1 ) ; DEBUG_BUFFERS ( dstY : %d\n , dstY ) ; DEBUG_BUFFERS ( \tfirstLumSrcY : %d lastLumSrcY : %d lastInLumBuf : %d\n , firstLumSrcY , lastLumSrcY , lastInLumBuf ) ; DEBUG_BUFFERS ( \tfirstChrSrcY : %d lastChrSrcY : %d lastInChrBuf : %d\n , firstChrSrcY , lastChrSrcY , lastInChrBuf ) ; // Do we have enough lines in this slice to output the dstY line enough_lines = lastLumSrcY2 < srcSliceY + srcSliceH & & lastChrSrcY < - ( ( - srcSliceY - srcSliceH ) > > c - > chrSrcVSubSample ) ; if ( ! enough_lines ) { lastLumSrcY = srcSliceY + srcSliceH - 1 ; lastChrSrcY = chrSrcSliceY + chrSrcSliceH - 1 ; DEBUG_BUFFERS ( buffering slice : lastLumSrcY %d lastChrSrcY %d\n , lastLumSrcY , lastChrSrcY ) ; } //Do horizontal scaling while ( lastInLumBuf < lastLumSrcY ) { const uint8_t * src1= src[0] + ( lastInLumBuf + 1 - srcSliceY ) * srcStride[0] ; const uint8_t * src2= src[3] + ( lastInLumBuf + 1 - srcSliceY ) * srcStride[3] ; lumBufIndex + + ; assert ( lumBufIndex < 2 * vLumBufSize ) ; assert ( lastInLumBuf + 1 - srcSliceY < srcSliceH ) ; assert ( lastInLumBuf + 1 - srcSliceY > = 0 ) ; RENAME ( hyscale ) ( c , lumPixBuf[ lumBufIndex ] , dstW , src1 , srcW , lumXInc , hLumFilter , hLumFilterPos , hLumFilterSize , formatConvBuffer , pal , 0 ) ; if ( CONFIG_SWSCALE_ALPHA & & alpPixBuf ) RENAME ( hyscale ) ( c , alpPixBuf[ lumBufIndex ] , dstW , src2 , srcW , lumXInc , hLumFilter , hLumFilterPos , hLumFilterSize , formatConvBuffer , pal , 1 ) ; lastInLumBuf + + ; DEBUG_BUFFERS ( \t\tlumBufIndex %d : lastInLumBuf : %d\n , lumBufIndex , lastInLumBuf ) ; } while ( lastInChrBuf < lastChrSrcY ) { const uint8_t * src1= src[1] + ( lastInChrBuf + 1 - chrSrcSliceY ) * srcStride[1] ; const uint8_t * src2= src[2]",0
"static inline int wv_unpack_mono ( WavpackFrameContext * s , GetBitContext * gb , void * dst , const int type ) { int i , j , count = 0 ; int last , t ; int A , S , T ; int pos = s - > pos ; uint32_t crc = s - > sc . crc ; uint32_t crc_extra_bits = s - > extra_sc . crc ; int16_t * dst16 = dst ; int32_t * dst32 = dst ; float * dstfl = dst ; s - > one = s - > zero = s - > zeroes = 0 ; do { T = wv_get_value ( s , gb , 0 , & last ) ; S = 0 ; if ( last ) break ; for ( i = 0 ; i < s - > terms ; i + + ) { t = s - > decorr[i] . value ; if ( t > 8 ) { if ( t & 1 ) A = 2U * s - > decorr[i] . samplesA[0] - s - > decorr[i] . samplesA[1] ; else A = ( int ) ( 3U * s - > decorr[i] . samplesA[0] - s - > decorr[i] . samplesA[1] ) > > 1 ; s - > decorr[i] . samplesA[1] = s - > decorr[i] . samplesA[0] ; j = 0 ; } else { A = s - > decorr[i] . samplesA[pos] ; j = ( pos + t ) & 7 ; } if ( type ! = AV_SAMPLE_FMT_S16P ) S = T + ( ( s - > decorr[i] . weightA * ( int64_t ) A + 512 ) > > 10 ) ; else S = T + ( ( s - > decorr[i] . weightA * A + 512 ) > > 10 ) ; if ( A & & T ) s - > decorr[i] . weightA - = ( ( ( ( T A ) > > 30 ) & 2 ) - 1 ) * s - > decorr[i] . delta ; s - > decorr[i] . samplesA[j] = T = S ; } pos = ( pos + 1 ) & 7 ; crc = crc * 3 + S ; if ( type == AV_SAMPLE_FMT_FLTP ) { * dstfl + + = wv_get_value_float ( s , & crc_extra_bits , S ) ; } else if ( type == AV_SAMPLE_FMT_S32P ) { * dst32 + + = wv_get_value_integer ( s , & crc_extra_bits , S ) ; } else { * dst16 + + = wv_get_value_integer ( s , & crc_extra_bits , S ) ; } count + + ; } while ( ! last & & count < s - > samples ) ; wv_reset_saved_context ( s ) ; if ( last & & count < s - > samples ) { int size = av_get_bytes_per_sample ( type ) ; memset ( ( uint8_t * ) dst + count * size , 0 , ( s - > samples - count ) * size ) ; } if ( s - > avctx - > err_recognition & AV_EF_CRCCHECK ) { int ret = wv_check_crc ( s , crc , crc_extra_bits ) ; if ( ret < 0 & & s - > avctx - > err_recognition & AV_EF_EXPLODE ) return ret ; } return 0 ; }",1
"static void sample_queue_push ( HintSampleQueue * queue , uint8_t * data , int size , int sample ) { / * No need to keep track of smaller samples , since describing them * with immediates is more efficient . * / if ( size < = 14 ) return ; if ( ! queue - > samples || queue - > len > = queue - > size ) { HintSample * samples ; samples = av_realloc ( queue - > samples , sizeof ( HintSample ) * ( queue - > size + 10 ) ) ; if ( ! samples ) return ; queue - > size + = 10 ; queue - > samples = samples ; } queue - > samples[queue - > len] . data = data ; queue - > samples[queue - > len] . size = size ; queue - > samples[queue - > len] . sample_number = sample ; queue - > samples[queue - > len] . offset = 0 ; queue - > samples[queue - > len] . own_data = 0 ; queue - > len + + ; }",1
"void ff_mov_close_hinting ( MOVTrack * track ) { AVFormatContext * rtp_ctx = track - > rtp_ctx ; uint8_t * ptr ; av_freep ( & track - > enc ) ; sample_queue_free ( & track - > sample_queue ) ; if ( ! rtp_ctx ) return ; if ( rtp_ctx - > pb ) { av_write_trailer ( rtp_ctx ) ; url_close_dyn_buf ( rtp_ctx - > pb , & ptr ) ; av_free ( ptr ) ; } av_metadata_free ( & rtp_ctx - > streams[0] - > metadata ) ; av_metadata_free ( & rtp_ctx - > metadata ) ; av_free ( rtp_ctx - > streams[0] ) ; av_freep ( & rtp_ctx ) ; }",1
"static void compute_scale_factors ( unsigned char scale_code[SBLIMIT] , unsigned char scale_factors[SBLIMIT][3] , int sb_samples[3][12][SBLIMIT] , int sblimit ) { int * p , vmax , v , n , i , j , k , code ; int index , d1 , d2 ; unsigned char * sf = & scale_factors[0][0] ; for ( j=0 ; j < sblimit ; j + + ) { for ( i=0 ; i < 3 ; i + + ) { / * find the max absolute value * / p = & sb_samples[i][0][j] ; vmax = abs ( * p ) ; for ( k=1 ; k < 12 ; k + + ) { p + = SBLIMIT ; v = abs ( * p ) ; if ( v > vmax ) vmax = v ; } / * compute the scale factor index using log 2 computations * / if ( vmax > 0 ) { n = av_log2 ( vmax ) ; / * n is the position of the MSB of vmax . now use at most 2 compares to find the index * / index = ( 21 - n ) * 3 - 3 ; if ( index > = 0 ) { while ( vmax < = scale_factor_table[index + 1] ) index + + ; } else { index = 0 ; / * very unlikely case of overflow * / } } else { index = 62 ; / * value 63 is not allowed * / } if 0 printf ( %2d : %d in=%x %x %d\n , j , i , vmax , scale_factor_table[index] , index ) ; endif / * store the scale factor * / assert ( index > =0 & & index < = 63 ) ; sf[i] = index ; } / * compute the transmission factor : look if the scale factors are close enough to each other * / d1 = scale_diff_table[sf[0] - sf[1] + 64] ; d2 = scale_diff_table[sf[1] - sf[2] + 64] ; / * handle the 25 cases * / switch ( d1 * 5 + d2 ) { case 0 * 5 + 0 : case 0 * 5 + 4 : case 3 * 5 + 4 : case 4 * 5 + 0 : case 4 * 5 + 4 : code = 0 ; break ; case 0 * 5 + 1 : case 0 * 5 + 2 : case 4 * 5 + 1 : case 4 * 5 + 2 : code = 3 ; sf[2] = sf[1] ; break ; case 0 * 5 + 3 : case 4 * 5 + 3 : code = 3 ; sf[1] = sf[2] ; break ; case 1 * 5 + 0 : case 1 * 5 + 4 : case 2 * 5 + 4 : code = 1 ; sf[1] = sf[0] ; break ; case 1 * 5 + 1 : case 1 * 5 + 2 : case 2 * 5 + 0 : case 2 * 5 + 1 : case 2 * 5 + 2 : code = 2 ; sf[1] = sf[2] = sf[0] ; break ; case 2 * 5 + 3 : case 3 * 5 + 3 : code = 2 ; sf[0] = sf[1] = sf[2] ; break ; case 3 * 5 + 0 : case 3 * 5 + 1 : case 3 * 5 + 2 : code = 2 ; sf[0] = sf[2] = sf[1] ; break ; case 1 * 5 + 3 : code = 2 ; if ( sf[0] > sf[2] ) sf[0] = sf[2] ; sf[1] = sf[2] = sf[0] ; break ; default : assert ( 0 ) ; //cannot happen code = 0 ; / * kill warning * / } if 0 printf ( %d : %2d %2d %2d %d %d - > %d\n , j , sf[0] , sf[1] , sf[2] , d1 , d2 , code ) ; endif scale_code[j] = code ; sf + = 3 ; } }",1
"static inline int mpeg4_decode_block ( MpegEncContext * s , DCTELEM * block , int n , int coded , int intra ) { int level , i , last , run ; int dc_pred_dir ; RLTable * rl ; RL_VLC_ELEM * rl_vlc ; const UINT8 * scan_table ; int qmul , qadd ; if ( intra ) { / * DC coef * / if ( s - > partitioned_frame ) { level = s - > dc_val[0][ s - > block_index[n] ] ; if ( n < 4 ) level= ( level + ( s - > y_dc_scale > > 1 ) ) /s - > y_dc_scale ; //FIXME optimizs else level= ( level + ( s - > c_dc_scale > > 1 ) ) /s - > c_dc_scale ; dc_pred_dir= ( s - > pred_dir_table[s - > mb_x + s - > mb_y * s - > mb_width] < < n ) & 32 ; } else { level = mpeg4_decode_dc ( s , n , & dc_pred_dir ) ; if ( level < 0 ) return - 1 ; } block[0] = level ; i = 0 ; if ( ! coded ) goto not_coded ; rl = & rl_intra ; rl_vlc = rl_intra . rl_vlc[0] ; if ( s - > ac_pred ) { if ( dc_pred_dir == 0 ) scan_table = s - > intra_v_scantable . permutated ; / * left * / else scan_table = s - > intra_h_scantable . permutated ; / * top * / } else { scan_table = s - > intra_scantable . permutated ; } qmul=1 ; qadd=0 ; } else { i = - 1 ; if ( ! coded ) { s - > block_last_index[n] = i ; return 0 ; } rl = & rl_inter ; scan_table = s - > intra_scantable . permutated ; if ( s - > mpeg_quant ) { qmul=1 ; qadd=0 ; rl_vlc = rl_inter . rl_vlc[0] ; } else { qmul = s - > qscale < < 1 ; qadd = ( s - > qscale - 1 ) | 1 ; rl_vlc = rl_inter . rl_vlc[s - > qscale] ; } } { OPEN_READER ( re , & s - > gb ) ; for ( ; ; ) { UPDATE_CACHE ( re , & s - > gb ) ; GET_RL_VLC ( level , run , re , & s - > gb , rl_vlc , TEX_VLC_BITS , 2 ) ; if ( level==0 ) { int cache ; cache= GET_CACHE ( re , & s - > gb ) ; / * escape * / if ( cache & 0x80000000 ) { if ( cache & 0x40000000 ) { / * third escape * / SKIP_CACHE ( re , & s - > gb , 2 ) ; last= SHOW_UBITS ( re , & s - > gb , 1 ) ; SKIP_CACHE ( re , & s - > gb , 1 ) ; run= SHOW_UBITS ( re , & s - > gb , 6 ) ; LAST_SKIP_CACHE ( re , & s - > gb , 6 ) ; SKIP_COUNTER ( re , & s - > gb , 2 + 1 + 6 ) ; UPDATE_CACHE ( re , & s - > gb ) ; if ( SHOW_UBITS ( re , & s - > gb , 1 ) ==0 ) { fprintf ( stderr , 1 . marker bit missing in 3 . esc\n ) ; return - 1 ; } ; SKIP_CACHE ( re , & s - > gb , 1 ) ; level= SHOW_SBITS ( re , & s - > gb , 12 ) ; SKIP_CACHE ( re , & s - > gb , 12 ) ; if ( SHOW_UBITS ( re , & s - > gb , 1 ) ==0 ) { fprintf ( stderr , 2 . marker bit missing in 3 . esc\n ) ; return - 1 ; } ; LAST_SKIP_CACHE ( re , & s - > gb , 1 ) ; SKIP_COUNTER ( re , & s - > gb , 1 + 12 + 1 ) ; if ( level * s - > qscale > 1024 || level * s - > qscale < - 1024 ) { fprintf ( stderr , |level| overflow in 3 . esc , qp=%d\n , s - > qscale ) ; return - 1 ; } if 1 { const int abs_level= ABS ( level ) ; if ( abs_level < =MAX_LEVEL & & run < =MAX_RUN & & ( ( s - > workaround_bugs & FF_BUG_AC_VLC ) ==0 ) ) { const int run1= run - rl - > max_run[last][abs_level] - 1 ; if ( abs_level < = rl - > max_level[last][run] ) { fprintf ( stderr , illegal 3 . esc , vlc encoding possible\n ) ; return - 1 ; } if ( abs_level < = rl - > max_level[last][run] * 2 ) { fprintf ( stderr , illegal 3 . esc , esc 1 encoding possible\n ) ; return - 1 ; } if ( run1 > = 0 & & abs_level < = rl - > max_level[last][run1] ) { fprintf ( stderr , illegal 3 . esc , esc 2 encoding possible\n ) ; return - 1 ; } } } endif if ( level > 0 ) level= level * qmul + qadd ; else level= level * qmul - qadd ; i + = run + 1 ; if ( last ) i + =192 ; } else { / * second escape * / if MIN_CACHE_BITS < 20 LAST_SKIP_BITS ( re , & s - > gb , 2 ) ; UPDATE_CACHE ( re , & s - > gb ) ; else SKIP_BITS ( re , & s - > gb , 2 ) ; endif GET_RL_VLC ( level , run , re , & s - > gb , rl_vlc , TEX_VLC_BITS , 2 ) ; i + = run + rl - > max_run[run > > 7][level/qmul] + 1 ; //FIXME opt indexing level = ( level SHOW_SBITS ( re , & s - > gb , 1 ) ) - SHOW_SBITS ( re , & s - > gb , 1 ) ; LAST_SKIP_BITS ( re , & s - > gb , 1 ) ; } } else { / * first escape * / if MIN_CACHE_BITS < 19 LAST_SKIP_BITS ( re , & s - > gb , 1 ) ; UPDATE_CACHE ( re , & s - > gb ) ; else SKIP_BITS ( re , & s - > gb , 1 ) ; endif GET_RL_VLC ( level , run , re , & s - > gb , rl_vlc , TEX_VLC_BITS , 2 ) ; i + = run ; level = level + rl - > max_level[run > > 7][ ( run - 1 ) & 63] * qmul ; //FIXME opt indexing level = ( level SHOW_SBITS ( re , & s - > gb , 1 ) ) - SHOW_SBITS ( re , & s - > gb , 1",1
"static int parse_vtrk ( AVFormatContext * s , FourxmDemuxContext * fourxm , uint8_t * buf , int size ) { AVStream * st ; / * check that there is enough data * / if ( size ! = vtrk_SIZE ) { return AVERROR_INVALIDDATA ; } / * allocate a new AVStream * / st = avformat_new_stream ( s , NULL ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; avpriv_set_pts_info ( st , 60 , 1 , fourxm - > fps ) ; fourxm - > video_stream_index = st - > index ; st - > codec - > codec_type = AVMEDIA_TYPE_VIDEO ; st - > codec - > codec_id = AV_CODEC_ID_4XM ; st - > codec - > extradata_size = 4 ; st - > codec - > extradata = av_malloc ( 4 ) ; AV_WL32 ( st - > codec - > extradata , AV_RL32 ( buf + 16 ) ) ; st - > codec - > width = AV_RL32 ( buf + 36 ) ; st - > codec - > height = AV_RL32 ( buf + 40 ) ; return 0 ; }",1
"int ff_mpeg4audio_get_config ( MPEG4AudioConfig * c , const uint8_t * buf , int buf_size ) { GetBitContext gb ; int specific_config_bitindex ; init_get_bits ( & gb , buf , buf_size * 8 ) ; c - > object_type = get_object_type ( & gb ) ; c - > sample_rate = get_sample_rate ( & gb , & c - > sampling_index ) ; c - > chan_config = get_bits ( & gb , 4 ) ; if ( c - > chan_config < FF_ARRAY_ELEMS ( ff_mpeg4audio_channels ) ) c - > channels = ff_mpeg4audio_channels[c - > chan_config] ; c - > sbr = - 1 ; if ( c - > object_type == AOT_SBR || ( c - > object_type == AOT_PS & & // check for W6132 Annex YYYY draft MP3onMP4 ! ( show_bits ( & gb , 3 ) & 0x03 & & ! ( show_bits ( & gb , 9 ) & 0x3F ) ) ) ) { c - > ext_object_type = AOT_SBR ; c - > sbr = 1 ; c - > ext_sample_rate = get_sample_rate ( & gb , & c - > ext_sampling_index ) ; c - > object_type = get_object_type ( & gb ) ; if ( c - > object_type == AOT_ER_BSAC ) c - > ext_chan_config = get_bits ( & gb , 4 ) ; } else { c - > ext_object_type = AOT_NULL ; c - > ext_sample_rate = 0 ; } specific_config_bitindex = get_bits_count ( & gb ) ; if ( c - > object_type == AOT_ALS ) { skip_bits ( & gb , 5 ) ; if ( show_bits_long ( & gb , 24 ) ! = MKBETAG ( ' \0 ' , ' A ' , ' L ' , ' S ' ) ) skip_bits_long ( & gb , 24 ) ; specific_config_bitindex = get_bits_count ( & gb ) ; if ( parse_config_ALS ( & gb , c ) ) return - 1 ; } if ( c - > ext_object_type ! = AOT_SBR ) { int bits_left = buf_size * 8 - get_bits_count ( & gb ) ; for ( ; bits_left > 15 ; bits_left - - ) { if ( show_bits ( & gb , 11 ) == 0x2b7 ) { // sync extension get_bits ( & gb , 11 ) ; c - > ext_object_type = get_object_type ( & gb ) ; if ( c - > ext_object_type == AOT_SBR & & ( c - > sbr = get_bits1 ( & gb ) ) == 1 ) c - > ext_sample_rate = get_sample_rate ( & gb , & c - > ext_sampling_index ) ; break ; } else get_bits1 ( & gb ) ; // skip 1 bit } } return specific_config_bitindex ; }",0
"void ff_hevc_luma_mv_mvp_mode ( HEVCContext * s , int x0 , int y0 , int nPbW , int nPbH , int log2_cb_size , int part_idx , int merge_idx , MvField * mv , int mvp_lx_flag , int LX ) { HEVCLocalContext * lc = s - > HEVClc ; MvField * tab_mvf = s - > ref - > tab_mvf ; int isScaledFlag_L0 = 0 ; int availableFlagLXA0 = 1 ; int availableFlagLXB0 = 1 ; int numMVPCandLX = 0 ; int min_pu_width = s - > sps - > min_pu_width ; int xA0 , yA0 ; int is_available_a0 ; int xA1 , yA1 ; int is_available_a1 ; int xB0 , yB0 ; int is_available_b0 ; int xB1 , yB1 ; int is_available_b1 ; int xB2 , yB2 ; int is_available_b2 ; Mv mvpcand_list[2] = { { 0 } } ; Mv mxA ; Mv mxB ; int ref_idx_curr = 0 ; int ref_idx = 0 ; int pred_flag_index_l0 ; int pred_flag_index_l1 ; const int cand_bottom_left = lc - > na . cand_bottom_left ; const int cand_left = lc - > na . cand_left ; const int cand_up_left = lc - > na . cand_up_left ; const int cand_up = lc - > na . cand_up ; const int cand_up_right = lc - > na . cand_up_right_sap ; ref_idx_curr = LX ; ref_idx = mv - > ref_idx[LX] ; pred_flag_index_l0 = LX ; pred_flag_index_l1 = ! LX ; // left bottom spatial candidate xA0 = x0 - 1 ; yA0 = y0 + nPbH ; is_available_a0 = AVAILABLE ( cand_bottom_left , A0 ) & & yA0 < s - > sps - > height & & PRED_BLOCK_AVAILABLE ( A0 ) ; //left spatial merge candidate xA1 = x0 - 1 ; yA1 = y0 + nPbH - 1 ; is_available_a1 = AVAILABLE ( cand_left , A1 ) ; if ( is_available_a0 || is_available_a1 ) isScaledFlag_L0 = 1 ; if ( is_available_a0 ) { if ( MP_MX ( A0 , pred_flag_index_l0 , mxA ) ) { goto b_candidates ; } if ( MP_MX ( A0 , pred_flag_index_l1 , mxA ) ) { goto b_candidates ; } } if ( is_available_a1 ) { if ( MP_MX ( A1 , pred_flag_index_l0 , mxA ) ) { goto b_candidates ; } if ( MP_MX ( A1 , pred_flag_index_l1 , mxA ) ) { goto b_candidates ; } } if ( is_available_a0 ) { if ( MP_MX_LT ( A0 , pred_flag_index_l0 , mxA ) ) { goto b_candidates ; } if ( MP_MX_LT ( A0 , pred_flag_index_l1 , mxA ) ) { goto b_candidates ; } } if ( is_available_a1 ) { if ( MP_MX_LT ( A1 , pred_flag_index_l0 , mxA ) ) { goto b_candidates ; } if ( MP_MX_LT ( A1 , pred_flag_index_l1 , mxA ) ) { goto b_candidates ; } } availableFlagLXA0 = 0 ; b_candidates : // B candidates // above right spatial merge candidate xB0 = x0 + nPbW ; yB0 = y0 - 1 ; is_available_b0 = AVAILABLE ( cand_up_right , B0 ) & & xB0 < s - > sps - > width & & PRED_BLOCK_AVAILABLE ( B0 ) ; // above spatial merge candidate xB1 = x0 + nPbW - 1 ; yB1 = y0 - 1 ; is_available_b1 = AVAILABLE ( cand_up , B1 ) ; // above left spatial merge candidate xB2 = x0 - 1 ; yB2 = y0 - 1 ; is_available_b2 = AVAILABLE ( cand_up_left , B2 ) ; // above right spatial merge candidate if ( is_available_b0 ) { if ( MP_MX ( B0 , pred_flag_index_l0 , mxB ) ) { goto scalef ; } if ( MP_MX ( B0 , pred_flag_index_l1 , mxB ) ) { goto scalef ; } } // above spatial merge candidate if ( is_available_b1 ) { if ( MP_MX ( B1 , pred_flag_index_l0 , mxB ) ) { goto scalef ; } if ( MP_MX ( B1 , pred_flag_index_l1 , mxB ) ) { goto scalef ; } } // above left spatial merge candidate if ( is_available_b2 ) { if ( MP_MX ( B2 , pred_flag_index_l0 , mxB ) ) { goto scalef ; } if ( MP_MX ( B2 , pred_flag_index_l1 , mxB ) ) { goto scalef ; } } availableFlagLXB0 = 0 ; scalef : if ( ! isScaledFlag_L0 ) { if ( availableFlagLXB0 ) { availableFlagLXA0 = 1 ; mxA = mxB ; } availableFlagLXB0 = 0 ; // XB0 and L1 if ( is_available_b0 ) { availableFlagLXB0 = MP_MX_LT ( B0 , pred_flag_index_l0 , mxB ) ; if ( ! availableFlagLXB0 ) availableFlagLXB0 = MP_MX_LT ( B0 , pred_flag_index_l1 , mxB ) ; } if ( is_available_b1 & & ! availableFlagLXB0 ) { availableFlagLXB0 = MP_MX_LT ( B1 , pred_flag_index_l0 , mxB ) ; if ( ! availableFlagLXB0 ) availableFlagLXB0 = MP_MX_LT ( B1 , pred_flag_index_l1 , mxB ) ; } if ( is_available_b2 & & ! availableFlagLXB0 ) { availableFlagLXB0 = MP_MX_LT ( B2 , pred_flag_index_l0 , mxB ) ; if ( ! availableFlagLXB0 ) availableFlagLXB0 = MP_MX_LT ( B2 , pred_flag_index_l1 , mxB ) ; } } if ( availableFlagLXA0 ) mvpcand_list[numMVPCandLX + + ] = mxA ; if ( availableFlagLXB0 & & ( ! availableFlagLXA0 || mxA . x ! = mxB . x || mxA . y ! = mxB . y ) ) mvpcand_list[numMVPCandLX + + ] = mxB ; //temporal motion vector prediction candidate if ( numMVPCandLX < 2 & & s - > sh . slice_temporal_mvp_enabled_flag & & mvp_lx_flag == numMVPCandLX ) { Mv mv_col ; int available_col = temporal_luma_motion_vector ( s , x0 , y0 , nPbW , nPbH , ref_idx , & mv_col , LX ) ; if ( available_col ) mvpcand_list[numMVPCandLX + + ] = mv_col ; } mv - > mv[LX] = mvpcand_list[mvp_lx_flag] ; }",0
"static int vc1_decode_intra_block ( VC1Context * v , DCTELEM block[64] , int n , int coded , int mquant , int codingset ) { GetBitContext * gb = & v - > s . gb ; MpegEncContext * s = & v - > s ; int dc_pred_dir = 0 ; / * Direction of the DC prediction used * / int run_diff , i ; int16_t * dc_val ; int16_t * ac_val , * ac_val2 ; int dcdiff ; int mb_pos = s - > mb_x + s - > mb_y * s - > mb_stride ; int a_avail = v - > a_avail , c_avail = v - > c_avail ; int use_pred = s - > ac_pred ; int scale ; int q1 , q2 = 0 ; / * XXX : Guard against dumb values of mquant * / mquant = ( mquant < 1 ) ? 0 : ( ( mquant > 31 ) ? 31 : mquant ) ; / * Set DC scale - y and c use the same * / s - > y_dc_scale = s - > y_dc_scale_table[mquant] ; s - > c_dc_scale = s - > c_dc_scale_table[mquant] ; / * Get DC differential * / if ( n < 4 ) { dcdiff = get_vlc2 ( & s - > gb , ff_msmp4_dc_luma_vlc[s - > dc_table_index] . table , DC_VLC_BITS , 3 ) ; } else { dcdiff = get_vlc2 ( & s - > gb , ff_msmp4_dc_chroma_vlc[s - > dc_table_index] . table , DC_VLC_BITS , 3 ) ; } if ( dcdiff < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , Illegal DC VLC\n ) ; return - 1 ; } if ( dcdiff ) { if ( dcdiff == 119 / * ESC index value * / ) { / * TODO : Optimize * / if ( mquant == 1 ) dcdiff = get_bits ( gb , 10 ) ; else if ( mquant == 2 ) dcdiff = get_bits ( gb , 9 ) ; else dcdiff = get_bits ( gb , 8 ) ; } else { if ( mquant == 1 ) dcdiff = ( dcdiff < < 2 ) + get_bits ( gb , 2 ) - 3 ; else if ( mquant == 2 ) dcdiff = ( dcdiff < < 1 ) + get_bits ( gb , 1 ) - 1 ; } if ( get_bits ( gb , 1 ) ) dcdiff = - dcdiff ; } / * Prediction * / dcdiff + = vc1_pred_dc ( & v - > s , v - > overlap , mquant , n , a_avail , c_avail , & dc_val , & dc_pred_dir ) ; * dc_val = dcdiff ; / * Store the quantized DC coeff , used for prediction * / if ( n < 4 ) { block[0] = dcdiff * s - > y_dc_scale ; } else { block[0] = dcdiff * s - > c_dc_scale ; } / * Skip ? * / run_diff = 0 ; i = 0 ; //AC Decoding i = 1 ; / * check if AC is needed at all and adjust direction if needed * / if ( ! a_avail ) dc_pred_dir = 1 ; if ( ! c_avail ) dc_pred_dir = 0 ; if ( ! a_avail & & ! c_avail ) use_pred = 0 ; ac_val = s - > ac_val[0][0] + s - > block_index[n] * 16 ; ac_val2 = ac_val ; scale = mquant * 2 + v - > halfpq ; if ( dc_pred_dir ) //left ac_val - = 16 ; else //top ac_val - = 16 * s - > block_wrap[n] ; q1 = s - > current_picture . qscale_table[mb_pos] ; if ( dc_pred_dir & & c_avail ) q2 = s - > current_picture . qscale_table[mb_pos - 1] ; if ( ! dc_pred_dir & & a_avail ) q2 = s - > current_picture . qscale_table[mb_pos - s - > mb_stride] ; if ( n & & n < 4 ) q2 = q1 ; if ( coded ) { int last = 0 , skip , value ; const int8_t * zz_table ; int k ; zz_table = vc1_simple_progressive_8x8_zz ; while ( ! last ) { vc1_decode_ac_coeff ( v , & last , & skip , & value , codingset ) ; i + = skip ; if ( i > 63 ) break ; block[zz_table[i + + ]] = value ; } / * apply AC prediction if needed * / if ( use_pred ) { / * scale predictors if needed * / if ( q2 & & q1 ! =q2 ) { q1 = q1 * 2 + ( ( q1 == v - > pq ) ? v - > halfpq : 0 ) - 1 ; q2 = q2 * 2 + ( ( q2 == v - > pq ) ? v - > halfpq : 0 ) - 1 ; if ( dc_pred_dir ) { //left for ( k = 1 ; k < 8 ; k + + ) block[k < < 3] + = ( ac_val[k] * q2 * vc1_dqscale[q1 - 1] + 0x20000 ) > > 18 ; } else { //top for ( k = 1 ; k < 8 ; k + + ) block[k] + = ( ac_val[k + 8] * q2 * vc1_dqscale[q1 - 1] + 0x20000 ) > > 18 ; } } else { if ( dc_pred_dir ) { //left for ( k = 1 ; k < 8 ; k + + ) block[k < < 3] + = ac_val[k] ; } else { //top for ( k = 1 ; k < 8 ; k + + ) block[k] + = ac_val[k + 8] ; } } } / * save AC coeffs for further prediction * / for ( k = 1 ; k < 8 ; k + + ) { ac_val2[k] = block[k < < 3] ; ac_val2[k + 8] = block[k] ; } / * scale AC coeffs * / for ( k = 1 ; k < 64 ; k + + ) if ( block[k] ) { block[k] * = scale ; if ( ! v - > pquantizer ) block[k] + = ( block[k] < 0 ) ? - mquant : mquant ; } if ( use_pred ) i = 63 ; } else { // no AC coeffs int k ; memset ( ac_val2 , 0 , 16 * 2 ) ; if ( dc_pred_dir ) { //left if ( use_pred ) { memcpy ( ac_val2 , ac_val , 8 * 2 ) ; if ( q2 & & q1 ! =q2 ) { q1 = q1 * 2 + ( ( q1 == v - > pq ) ? v - > halfpq : 0 ) - 1 ; q2 = q2 * 2 + ( ( q2 == v - > pq ) ? v - > halfpq : 0 ) - 1 ; for ( k = 1 ; k < 8 ; k + + ) ac_val2[k] = (",1
"static int can_safely_read ( GetBitContext * gb , uint64_t bits ) { return get_bits_left ( gb ) > = bits ; }",0
static int tta_probe ( AVProbeData * p ) { const uint8_t * d = p - > buf ; if ( p - > buf_size < 4 ) return 0 ; if ( d[0] == ' T ' & & d[1] == ' T ' & & d[2] == ' A ' & & d[3] == ' 1 ' ) return 80 ; return 0 ; },0
"static void list_formats ( AVFormatContext * ctx , int type ) { const struct video_data * s = ctx - > priv_data ; struct v4l2_fmtdesc vfd = { . type = V4L2_BUF_TYPE_VIDEO_CAPTURE } ; while ( ! v4l2_ioctl ( s - > fd , VIDIOC_ENUM_FMT , & vfd ) ) { enum AVCodecID codec_id = avpriv_fmt_v4l2codec ( vfd . pixelformat ) ; enum AVPixelFormat pix_fmt = avpriv_fmt_v4l2ff ( vfd . pixelformat , codec_id ) ; vfd . index + + ; if ( ! ( vfd . flags & V4L2_FMT_FLAG_COMPRESSED ) & & type & V4L_RAWFORMATS ) { const char * fmt_name = av_get_pix_fmt_name ( pix_fmt ) ; av_log ( ctx , AV_LOG_INFO , Raw : %9s : %20s : , fmt_name ? fmt_name : Unsupported , vfd . description ) ; } else if ( vfd . flags & V4L2_FMT_FLAG_COMPRESSED & & type & V4L_COMPFORMATS ) { AVCodec * codec = avcodec_find_decoder ( codec_id ) ; av_log ( ctx , AV_LOG_INFO , Compressed : %9s : %20s : , codec ? codec - > name : Unsupported , vfd . description ) ; } else { continue ; } ifdef V4L2_FMT_FLAG_EMULATED if ( vfd . flags & V4L2_FMT_FLAG_EMULATED ) av_log ( ctx , AV_LOG_INFO , Emulated : ) ; endif if HAVE_STRUCT_V4L2_FRMIVALENUM_DISCRETE list_framesizes ( ctx , vfd . pixelformat ) ; endif av_log ( ctx , AV_LOG_INFO , \n ) ; } }",0
"static int cinepak_decode_strip ( CinepakContext * s , cvid_strip * strip , const uint8_t * data , int size ) { const uint8_t * eod = ( data + size ) ; int chunk_id , chunk_size ; / * coordinate sanity checks * / if ( strip - > x1 > = s - > width || strip - > x2 > s - > width || strip - > y1 > = s - > height || strip - > y2 > s - > height || strip - > x1 > = strip - > x2 || strip - > y1 > = strip - > y2 ) return - 1 ; while ( ( data + 4 ) < = eod ) { chunk_id = data[0] ; chunk_size = AV_RB24 ( & data[1] ) - 4 ; if ( chunk_size < 0 ) return - 1 ; data + = 4 ; chunk_size = ( ( data + chunk_size ) > eod ) ? ( eod - data ) : chunk_size ; switch ( chunk_id ) { case 0x20 : case 0x21 : case 0x24 : case 0x25 : cinepak_decode_codebook ( strip - > v4_codebook , chunk_id , chunk_size , data ) ; break ; case 0x22 : case 0x23 : case 0x26 : case 0x27 : cinepak_decode_codebook ( strip - > v1_codebook , chunk_id , chunk_size , data ) ; break ; case 0x30 : case 0x31 : case 0x32 : return cinepak_decode_vectors ( s , strip , chunk_id , chunk_size , data ) ; } data + = chunk_size ; } return - 1 ; }",0
"static int gen_sub_bitmap ( TeletextContext * ctx , AVSubtitleRect * sub_rect , vbi_page * page , int chop_top ) { int resx = page - > columns * BITMAP_CHAR_WIDTH ; int resy = ( page - > rows - chop_top ) * BITMAP_CHAR_HEIGHT ; uint8_t ci , cmax = 0 ; int ret ; vbi_char * vc = page - > text + ( chop_top * page - > columns ) ; vbi_char * vcend = page - > text + ( page - > rows * page - > columns ) ; for ( ; vc < vcend ; vc + + ) { if ( vc - > opacity ! = VBI_TRANSPARENT_SPACE ) { cmax = VBI_NB_COLORS ; break ; } } if ( cmax == 0 ) { av_log ( ctx , AV_LOG_DEBUG , dropping empty page %3x\n , page - > pgno ) ; sub_rect - > type = SUBTITLE_NONE ; return 0 ; } if ( ( ret = avpicture_alloc ( & sub_rect - > pict , AV_PIX_FMT_PAL8 , resx , resy ) ) < 0 ) return ret ; // Yes , we want to allocate the palette on our own because AVSubtitle works this way sub_rect - > pict . data[1] = NULL ; vbi_draw_vt_page_region ( page , VBI_PIXFMT_PAL8 , sub_rect - > pict . data[0] , sub_rect - > pict . linesize[0] , 0 , chop_top , page - > columns , page - > rows - chop_top , / * reveal * / 1 , / * flash * / 1 ) ; fix_transparency ( ctx , sub_rect , page , chop_top , cmax , resx , resy ) ; sub_rect - > x = ctx - > x_offset ; sub_rect - > y = ctx - > y_offset + chop_top * BITMAP_CHAR_HEIGHT ; sub_rect - > w = resx ; sub_rect - > h = resy ; sub_rect - > nb_colors = ( int ) cmax + 1 ; sub_rect - > pict . data[1] = av_mallocz ( AVPALETTE_SIZE ) ; if ( ! sub_rect - > pict . data[1] ) { av_freep ( & sub_rect - > pict . data[0] ) ; return AVERROR ( ENOMEM ) ; } for ( ci = 0 ; ci < cmax ; ci + + ) { int r , g , b , a ; r = VBI_R ( page - > color_map[ci] ) ; g = VBI_G ( page - > color_map[ci] ) ; b = VBI_B ( page - > color_map[ci] ) ; a = VBI_A ( page - > color_map[ci] ) ; ( ( uint32_t * ) sub_rect - > pict . data[1] ) [ci] = RGBA ( r , g , b , a ) ; av_dlog ( ctx , palette %0x\n , ( ( uint32_t * ) sub_rect - > pict . data[1] ) [ci] ) ; } ( ( uint32_t * ) sub_rect - > pict . data[1] ) [cmax] = RGBA ( 0 , 0 , 0 , 0 ) ; sub_rect - > type = SUBTITLE_BITMAP ; return 0 ; }",0
"static int ast_write_header ( AVFormatContext * s ) { ASTMuxContext * ast = s - > priv_data ; AVIOContext * pb = s - > pb ; AVCodecContext * enc ; unsigned int codec_tag ; if ( s - > nb_streams == 1 ) { enc = s - > streams[0] - > codec ; } else { av_log ( s , AV_LOG_ERROR , only one stream is supported\n ) ; return AVERROR ( EINVAL ) ; } if ( enc - > codec_id == AV_CODEC_ID_ADPCM_AFC ) { av_log ( s , AV_LOG_ERROR , muxing ADPCM AFC is not implemented\n ) ; return AVERROR_PATCHWELCOME ; } codec_tag = ff_codec_get_tag ( ff_codec_ast_tags , enc - > codec_id ) ; if ( ! codec_tag ) { av_log ( s , AV_LOG_ERROR , unsupported codec\n ) ; return AVERROR ( EINVAL ) ; } if ( ast - > loopstart & & ast - > loopend & & ast - > loopstart > = ast - > loopend ) { av_log ( s , AV_LOG_ERROR , loopend can ' t be less or equal to loopstart\n ) ; return AVERROR ( EINVAL ) ; } / * Convert milliseconds to samples * / CHECK_LOOP ( start ) CHECK_LOOP ( end ) ffio_wfourcc ( pb , STRM ) ; ast - > size = avio_tell ( pb ) ; avio_wb32 ( pb , 0 ) ; / * File size minus header * / avio_wb16 ( pb , codec_tag ) ; avio_wb16 ( pb , 16 ) ; / * Bit depth * / avio_wb16 ( pb , enc - > channels ) ; avio_wb16 ( pb , 0xFFFF ) ; avio_wb32 ( pb , enc - > sample_rate ) ; ast - > samples = avio_tell ( pb ) ; avio_wb32 ( pb , 0 ) ; / * Number of samples * / avio_wb32 ( pb , 0 ) ; / * Loopstart * / avio_wb32 ( pb , 0 ) ; / * Loopend * / avio_wb32 ( pb , 0 ) ; / * Size of first block * / / * Unknown * / avio_wb32 ( pb , 0 ) ; avio_wl32 ( pb , 0x7F ) ; avio_wb64 ( pb , 0 ) ; avio_wb64 ( pb , 0 ) ; avio_wb32 ( pb , 0 ) ; avio_flush ( pb ) ; return 0 ; }",0
"static int read_old_huffman_tables ( HYuvContext * s ) { GetBitContext gb ; int i ; init_get_bits ( & gb , classic_shift_luma , classic_shift_luma_table_size * 8 ) ; if ( read_len_table ( s - > len[0] , & gb ) < 0 ) return - 1 ; init_get_bits ( & gb , classic_shift_chroma , classic_shift_chroma_table_size * 8 ) ; if ( read_len_table ( s - > len[1] , & gb ) < 0 ) return - 1 ; for ( i=0 ; i < 256 ; i + + ) s - > bits[0][i] = classic_add_luma [i] ; for ( i=0 ; i < 256 ; i + + ) s - > bits[1][i] = classic_add_chroma[i] ; if ( s - > bitstream_bpp > = 24 ) { memcpy ( s - > bits[1] , s - > bits[0] , 256 * sizeof ( uint32_t ) ) ; memcpy ( s - > len[1] , s - > len [0] , 256 * sizeof ( uint8_t ) ) ; } memcpy ( s - > bits[2] , s - > bits[1] , 256 * sizeof ( uint32_t ) ) ; memcpy ( s - > len[2] , s - > len [1] , 256 * sizeof ( uint8_t ) ) ; for ( i = 0 ; i < 3 ; i + + ) { ff_free_vlc ( & s - > vlc[i] ) ; init_vlc ( & s - > vlc[i] , VLC_BITS , 256 , s - > len[i] , 1 , 1 , s - > bits[i] , 4 , 4 , 0 ) ; } generate_joint_tables ( s ) ; return 0 ; }",0
"static int decode_ics_info ( AACContext * ac , IndividualChannelStream * ics , GetBitContext * gb ) { const MPEG4AudioConfig * const m4ac = & ac - > oc[1] . m4ac ; const int aot = m4ac - > object_type ; const int sampling_index = m4ac - > sampling_index ; if ( aot ! = AOT_ER_AAC_ELD ) { if ( get_bits1 ( gb ) ) { av_log ( ac - > avctx , AV_LOG_ERROR , Reserved bit set . \n ) ; return AVERROR_INVALIDDATA ; } ics - > window_sequence[1] = ics - > window_sequence[0] ; ics - > window_sequence[0] = get_bits ( gb , 2 ) ; if ( aot == AOT_ER_AAC_LD & & ics - > window_sequence[0] ! = ONLY_LONG_SEQUENCE ) { av_log ( ac - > avctx , AV_LOG_ERROR , AAC LD is only defined for ONLY_LONG_SEQUENCE but window sequence %d found . \n , ics - > window_sequence[0] ) ; ics - > window_sequence[0] = ONLY_LONG_SEQUENCE ; return AVERROR_INVALIDDATA ; } ics - > use_kb_window[1] = ics - > use_kb_window[0] ; ics - > use_kb_window[0] = get_bits1 ( gb ) ; } ics - > num_window_groups = 1 ; ics - > group_len[0] = 1 ; if ( ics - > window_sequence[0] == EIGHT_SHORT_SEQUENCE ) { int i ; ics - > max_sfb = get_bits ( gb , 4 ) ; for ( i = 0 ; i < 7 ; i + + ) { if ( get_bits1 ( gb ) ) { ics - > group_len[ics - > num_window_groups - 1] + + ; } else { ics - > num_window_groups + + ; ics - > group_len[ics - > num_window_groups - 1] = 1 ; } } ics - > num_windows = 8 ; ics - > swb_offset = ff_swb_offset_128[sampling_index] ; ics - > num_swb = ff_aac_num_swb_128[sampling_index] ; ics - > tns_max_bands = ff_tns_max_bands_128[sampling_index] ; ics - > predictor_present = 0 ; } else { ics - > max_sfb = get_bits ( gb , 6 ) ; ics - > num_windows = 1 ; if ( aot == AOT_ER_AAC_LD || aot == AOT_ER_AAC_ELD ) { if ( m4ac - > frame_length_short ) { ics - > swb_offset = ff_swb_offset_480[sampling_index] ; ics - > num_swb = ff_aac_num_swb_480[sampling_index] ; ics - > tns_max_bands = ff_tns_max_bands_480[sampling_index] ; } else { ics - > swb_offset = ff_swb_offset_512[sampling_index] ; ics - > num_swb = ff_aac_num_swb_512[sampling_index] ; ics - > tns_max_bands = ff_tns_max_bands_512[sampling_index] ; } if ( ! ics - > num_swb || ! ics - > swb_offset ) return AVERROR_BUG ; } else { ics - > swb_offset = ff_swb_offset_1024[sampling_index] ; ics - > num_swb = ff_aac_num_swb_1024[sampling_index] ; ics - > tns_max_bands = ff_tns_max_bands_1024[sampling_index] ; } if ( aot ! = AOT_ER_AAC_ELD ) { ics - > predictor_present = get_bits1 ( gb ) ; ics - > predictor_reset_group = 0 ; } if ( ics - > predictor_present ) { if ( aot == AOT_AAC_MAIN ) { if ( decode_prediction ( ac , ics , gb ) ) { return AVERROR_INVALIDDATA ; } } else if ( aot == AOT_AAC_LC || aot == AOT_ER_AAC_LC ) { av_log ( ac - > avctx , AV_LOG_ERROR , Prediction is not allowed in AAC - LC . \n ) ; return AVERROR_INVALIDDATA ; } else { if ( aot == AOT_ER_AAC_LD ) { av_log ( ac - > avctx , AV_LOG_ERROR , LTP in ER AAC LD not yet implemented . \n ) ; return AVERROR_PATCHWELCOME ; } if ( ( ics - > ltp . present = get_bits ( gb , 1 ) ) ) decode_ltp ( & ics - > ltp , gb , ics - > max_sfb ) ; } } } if ( ics - > max_sfb > ics - > num_swb ) { av_log ( ac - > avctx , AV_LOG_ERROR , Number of scalefactor bands in group ( %d ) exceeds limit ( %d ) . \n , ics - > max_sfb , ics - > num_swb ) ; return AVERROR_INVALIDDATA ; } return 0 ; }",1
"static void dvbsub_parse_region_segment ( AVCodecContext * avctx , uint8_t * buf , int buf_size ) { DVBSubContext * ctx = ( DVBSubContext * ) avctx - > priv_data ; uint8_t * buf_end = buf + buf_size ; int region_id , object_id ; DVBSubRegion * region ; DVBSubObject * object ; DVBSubObjectDisplay * display ; int fill ; if ( buf_size < 10 ) return ; region_id = * buf + + ; region = get_region ( ctx , region_id ) ; if ( region == NULL ) { region = av_mallocz ( sizeof ( DVBSubRegion ) ) ; region - > id = region_id ; region - > next = ctx - > region_list ; ctx - > region_list = region ; fill = ( ( * buf + + ) > > 3 ) & 1 ; region - > width = AV_RB16 ( buf ) ; buf + = 2 ; region - > height = AV_RB16 ( buf ) ; buf + = 2 ; if ( region - > width * region - > height ! = region - > buf_size ) { if ( region - > pbuf ! = 0 ) av_free ( region - > pbuf ) ; region - > buf_size = region - > width * region - > height ; region - > pbuf = av_malloc ( region - > buf_size ) ; fill = 1 ; region - > depth = 1 < < ( ( ( * buf + + ) > > 2 ) & 7 ) ; region - > clut = * buf + + ; if ( region - > depth == 8 ) region - > bgcolour = * buf + + ; else { buf + = 1 ; if ( region - > depth == 4 ) region - > bgcolour = ( ( ( * buf + + ) > > 4 ) & 15 ) ; else region - > bgcolour = ( ( ( * buf + + ) > > 2 ) & 3 ) ; ifdef DEBUG av_log ( avctx , AV_LOG_INFO , Region %d , ( %dx%d ) \n , region_id , region - > width , region - > height ) ; endif if ( fill ) { memset ( region - > pbuf , region - > bgcolour , region - > buf_size ) ; ifdef DEBUG av_log ( avctx , AV_LOG_INFO , Fill region ( %d ) \n , region - > bgcolour ) ; endif delete_region_display_list ( ctx , region ) ; while ( buf + 5 < buf_end ) { object_id = AV_RB16 ( buf ) ; buf + = 2 ; object = get_object ( ctx , object_id ) ; if ( object == NULL ) { object = av_mallocz ( sizeof ( DVBSubObject ) ) ; object - > id = object_id ; object - > next = ctx - > object_list ; ctx - > object_list = object ; object - > type = ( * buf ) > > 6 ; display = av_mallocz ( sizeof ( DVBSubObjectDisplay ) ) ; display - > object_id = object_id ; display - > region_id = region_id ; display - > x_pos = AV_RB16 ( buf ) & 0xfff ; buf + = 2 ; display - > y_pos = AV_RB16 ( buf ) & 0xfff ; buf + = 2 ; if ( ( object - > type == 1 || object - > type == 2 ) & & buf + 1 < buf_end ) { display - > fgcolour = * buf + + ; display - > bgcolour = * buf + + ; display - > region_list_next = region - > display_list ; region - > display_list = display ; display - > object_list_next = object - > display_list ; object - > display_list = display ;",1
"int ff_unlock_avcodec ( const AVCodec * codec ) { if ( codec - > caps_internal & FF_CODEC_CAP_INIT_THREADSAFE || ! codec - > init ) return 0 ; av_assert0 ( ff_avcodec_locked ) ; ff_avcodec_locked = 0 ; atomic_fetch_add ( & entangled_thread_counter , - 1 ) ; if ( lockmgr_cb ) { if ( ( * lockmgr_cb ) ( & codec_mutex , AV_LOCK_RELEASE ) ) return - 1 ; } return 0 ; }",1
"static inline void copy ( LZOContext * c , int cnt ) { register const uint8_t * src = c - > in ; register uint8_t * dst = c - > out ; if ( cnt > c - > in_end - src ) { cnt = FFMAX ( c - > in_end - src , 0 ) ; c - > error |= AV_LZO_INPUT_DEPLETED ; } if ( cnt > c - > out_end - dst ) { cnt = FFMAX ( c - > out_end - dst , 0 ) ; c - > error |= AV_LZO_OUTPUT_FULL ; } if defined ( INBUF_PADDED ) & & defined ( OUTBUF_PADDED ) AV_COPY32U ( dst , src ) ; src + = 4 ; dst + = 4 ; cnt - = 4 ; if ( cnt > 0 ) endif memcpy ( dst , src , cnt ) ; c - > in = src + cnt ; c - > out = dst + cnt ; }",1
"static int mxf_read_generic_descriptor ( void * arg , AVIOContext * pb , int tag , int size , UID uid ) { MXFDescriptor * descriptor = arg ; switch ( tag ) { case 0x3F01 : descriptor - > sub_descriptors_count = avio_rb32 ( pb ) ; if ( descriptor - > sub_descriptors_count > = UINT_MAX / sizeof ( UID ) ) return - 1 ; descriptor - > sub_descriptors_refs = av_malloc ( descriptor - > sub_descriptors_count * sizeof ( UID ) ) ; if ( ! descriptor - > sub_descriptors_refs ) return - 1 ; avio_skip ( pb , 4 ) ; / * useless size of objects , always 16 according to specs * / avio_read ( pb , ( uint8_t * ) descriptor - > sub_descriptors_refs , descriptor - > sub_descriptors_count * sizeof ( UID ) ) ; break ; case 0x3004 : avio_read ( pb , descriptor - > essence_container_ul , 16 ) ; break ; case 0x3006 : descriptor - > linked_track_id = avio_rb32 ( pb ) ; break ; case 0x3201 : / * PictureEssenceCoding * / avio_read ( pb , descriptor - > essence_codec_ul , 16 ) ; break ; case 0x3203 : descriptor - > width = avio_rb32 ( pb ) ; break ; case 0x3202 : descriptor - > height = avio_rb32 ( pb ) ; break ; case 0x320E : descriptor - > aspect_ratio . num = avio_rb32 ( pb ) ; descriptor - > aspect_ratio . den = avio_rb32 ( pb ) ; break ; case 0x3D03 : descriptor - > sample_rate . num = avio_rb32 ( pb ) ; descriptor - > sample_rate . den = avio_rb32 ( pb ) ; break ; case 0x3D06 : / * SoundEssenceCompression * / avio_read ( pb , descriptor - > essence_codec_ul , 16 ) ; break ; case 0x3D07 : descriptor - > channels = avio_rb32 ( pb ) ; break ; case 0x3D01 : descriptor - > bits_per_sample = avio_rb32 ( pb ) ; break ; case 0x3401 : mxf_read_pixel_layout ( pb , descriptor ) ; break ; default : / * Private uid used by SONY C0023S01 . mxf * / if ( IS_KLV_KEY ( uid , mxf_sony_mpeg4_extradata ) ) { descriptor - > extradata = av_malloc ( size + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! descriptor - > extradata ) return - 1 ; descriptor - > extradata_size = size ; avio_read ( pb , descriptor - > extradata , size ) ; } break ; } return 0 ; }",1
"static int fir_channel ( AVFilterContext * ctx , void * arg , int ch , int nb_jobs ) { AudioFIRContext * s = ctx - > priv ; const float * src = ( const float * ) s - > in[0] - > extended_data[ch] ; int index1 = ( s - > index + 1 ) % 3 ; int index2 = ( s - > index + 2 ) % 3 ; float * sum = s - > sum[ch] ; AVFrame * out = arg ; float * block ; float * dst ; int n , i , j ; memset ( sum , 0 , sizeof ( * sum ) * s - > fft_length ) ; block = s - > block[ch] + s - > part_index * s - > block_size ; memset ( block , 0 , sizeof ( * block ) * s - > fft_length ) ; s - > fdsp - > vector_fmul_scalar ( block + s - > part_size , src , s - > dry_gain , s - > nb_samples ) ; emms_c ( ) ; av_rdft_calc ( s - > rdft[ch] , block ) ; block[2 * s - > part_size] = block[1] ; block[1] = 0 ; j = s - > part_index ; for ( i = 0 ; i < s - > nb_partitions ; i + + ) { const int coffset = i * s - > coeff_size ; const FFTComplex * coeff = s - > coeff[ch * ! s - > one2many] + coffset ; block = s - > block[ch] + j * s - > block_size ; s - > fcmul_add ( sum , block , ( const float * ) coeff , s - > part_size ) ; if ( j == 0 ) j = s - > nb_partitions ; j - - ; } sum[1] = sum[2 * s - > part_size] ; av_rdft_calc ( s - > irdft[ch] , sum ) ; dst = ( float * ) s - > buffer - > extended_data[ch] + index1 * s - > part_size ; for ( n = 0 ; n < s - > part_size ; n + + ) { dst[n] + = sum[n] ; } dst = ( float * ) s - > buffer - > extended_data[ch] + index2 * s - > part_size ; memcpy ( dst , sum + s - > part_size , s - > part_size * sizeof ( * dst ) ) ; dst = ( float * ) s - > buffer - > extended_data[ch] + s - > index * s - > part_size ; if ( out ) { float * ptr = ( float * ) out - > extended_data[ch] ; s - > fdsp - > vector_fmul_scalar ( ptr , dst , s - > gain * s - > wet_gain , out - > nb_samples ) ; emms_c ( ) ; } return 0 ; }",0
"static int aiff_read_packet ( AVFormatContext * s , AVPacket * pkt ) { AVStream * st = s - > streams[0] ; AIFFInputContext * aiff = s - > priv_data ; int64_t max_size ; int res , size ; / * calculate size of remaining data * / max_size = aiff - > data_end - avio_tell ( s - > pb ) ; if ( max_size < = 0 ) return AVERROR_EOF ; / * Now for that packet * / if ( st - > codec - > block_align > = 17 ) // GSM , QCLP , IMA4 size = st - > codec - > block_align ; else size = ( MAX_SIZE / st - > codec - > block_align ) * st - > codec - > block_align ; size = FFMIN ( max_size , size ) ; res = av_get_packet ( s - > pb , pkt , size ) ; if ( res < 0 ) return res ; if ( size > = st - > codec - > block_align ) pkt - > flags & = AV_PKT_FLAG_CORRUPT ; / * Only one stream in an AIFF file * / pkt - > stream_index = 0 ; pkt - > duration = ( res / st - > codec - > block_align ) * aiff - > block_duration ; return 0 ; }",0
"static int get_riff ( AVFormatContext * s , AVIOContext * pb ) { AVIContext * avi = s - > priv_data ; char header[8] ; int i ; / * check RIFF header * / avio_read ( pb , header , 4 ) ; avi - > riff_end = avio_rl32 ( pb ) ; / * RIFF chunk size * / avi - > riff_end + = avio_tell ( pb ) ; / * RIFF chunk end * / avio_read ( pb , header + 4 , 4 ) ; for ( i = 0 ; avi_headers[i][0] ; i + + ) if ( ! memcmp ( header , avi_headers[i] , 8 ) ) break ; if ( ! avi_headers[i][0] ) return AVERROR_INVALIDDATA ; if ( header[7] == 0x19 ) av_log ( s , AV_LOG_INFO , This file has been generated by a totally broken muxer . \n ) ; return 0 ; }",1
"int opt_default ( const char * opt , const char * arg ) { const AVOption * oc , * of , * os , * oswr ; char opt_stripped[128] ; const char * p ; const AVClass * cc = avcodec_get_class ( ) , * fc = avformat_get_class ( ) , * sc , * swr_class ; if ( ! ( p = strchr ( opt , ' : ' ) ) ) p = opt + strlen ( opt ) ; av_strlcpy ( opt_stripped , opt , FFMIN ( sizeof ( opt_stripped ) , p - opt + 1 ) ) ; if ( ( oc = av_opt_find ( & cc , opt_stripped , NULL , 0 , AV_OPT_SEARCH_CHILDREN | AV_OPT_SEARCH_FAKE_OBJ ) ) || ( ( opt[0] == ' v ' || opt[0] == ' a ' || opt[0] == ' s ' ) & & ( oc = av_opt_find ( & cc , opt + 1 , NULL , 0 , AV_OPT_SEARCH_FAKE_OBJ ) ) ) ) av_dict_set ( & codec_opts , opt , arg , FLAGS ( oc ) ) ; if ( ( of = av_opt_find ( & fc , opt , NULL , 0 , AV_OPT_SEARCH_CHILDREN | AV_OPT_SEARCH_FAKE_OBJ ) ) ) av_dict_set ( & format_opts , opt , arg , FLAGS ( of ) ) ; if CONFIG_SWSCALE sc = sws_get_class ( ) ; if ( ( os = av_opt_find ( & sc , opt , NULL , 0 , AV_OPT_SEARCH_CHILDREN | AV_OPT_SEARCH_FAKE_OBJ ) ) ) { // XXX we only support sws_flags , not arbitrary sws options int ret = av_opt_set ( sws_opts , opt , arg , 0 ) ; if ( ret < 0 ) { av_log ( NULL , AV_LOG_ERROR , Error setting option %s . \n , opt ) ; return ret ; } } endif swr_class = swr_get_class ( ) ; if ( ! oc & & ! of & & ! os & & ( oswr = av_opt_find ( & swr_class , opt , NULL , 0 , AV_OPT_SEARCH_CHILDREN | AV_OPT_SEARCH_FAKE_OBJ ) ) ) { int ret = av_opt_set ( swr_opts , opt , arg , 0 ) ; if ( ret < 0 ) { av_log ( NULL , AV_LOG_ERROR , Error setting option %s . \n , opt ) ; return ret ; } } if ( oc || of || os || oswr ) return 0 ; av_log ( NULL , AV_LOG_ERROR , Unrecognized option ' %s ' \n , opt ) ; return AVERROR_OPTION_NOT_FOUND ; }",1
"static int decode_segment ( TAKDecContext * s , int8_t mode , int32_t * decoded , int len ) { struct CParam code ; GetBitContext * gb = & s - > gb ; int i ; if ( ! mode ) { memset ( decoded , 0 , len * sizeof ( * decoded ) ) ; return 0 ; } if ( mode > FF_ARRAY_ELEMS ( xcodes ) ) return AVERROR_INVALIDDATA ; code = xcodes[mode - 1] ; for ( i = 0 ; i < len ; i + + ) { int x = get_bits_long ( gb , code . init ) ; if ( x > = code . escape & & get_bits1 ( gb ) ) { x |= 1 < < code . init ; if ( x > = code . aescape ) { int scale = get_unary ( gb , 1 , 9 ) ; if ( scale == 9 ) { int scale_bits = get_bits ( gb , 3 ) ; if ( scale_bits > 0 ) { if ( scale_bits == 7 ) { scale_bits + = get_bits ( gb , 5 ) ; if ( scale_bits > 29 ) return AVERROR_INVALIDDATA ; } scale = get_bits_long ( gb , scale_bits ) + 1 ; x + = code . scale * scale ; } x + = code . bias ; } else x + = code . scale * scale - code . escape ; } else x - = code . escape ; } decoded[i] = ( x > > 1 ) - ( x & 1 ) ; } return 0 ; }",1
"static int paf_video_decode ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * pkt ) { PAFVideoDecContext * c = avctx - > priv_data ; uint8_t code , * dst , * end ; int i , frame , ret ; if ( pkt - > size < 2 ) return AVERROR_INVALIDDATA ; bytestream2_init ( & c - > gb , pkt - > data , pkt - > size ) ; code = bytestream2_get_byte ( & c - > gb ) ; if ( ( code & 0xF ) > 4 ) { avpriv_request_sample ( avctx , unknown/invalid code ) ; return AVERROR_INVALIDDATA ; } if ( ( ret = ff_reget_buffer ( avctx , c - > pic ) ) < 0 ) return ret ; if ( code & 0x20 ) { // frame is keyframe for ( i = 0 ; i < 4 ; i + + ) memset ( c - > frame[i] , 0 , c - > frame_size ) ; memset ( c - > pic - > data[1] , 0 , AVPALETTE_SIZE ) ; c - > current_frame = 0 ; c - > pic - > key_frame = 1 ; c - > pic - > pict_type = AV_PICTURE_TYPE_I ; } else { c - > pic - > key_frame = 0 ; c - > pic - > pict_type = AV_PICTURE_TYPE_P ; } if ( code & 0x40 ) { // palette update uint32_t * out = ( uint32_t * ) c - > pic - > data[1] ; int index , count ; index = bytestream2_get_byte ( & c - > gb ) ; count = bytestream2_get_byte ( & c - > gb ) + 1 ; if ( index + count > 256 ) return AVERROR_INVALIDDATA ; if ( bytestream2_get_bytes_left ( & c - > gb ) < 3 * count ) return AVERROR_INVALIDDATA ; out + = index ; for ( i = 0 ; i < count ; i + + ) { unsigned r , g , b ; r = bytestream2_get_byteu ( & c - > gb ) ; r = r < < 2 | r > > 4 ; g = bytestream2_get_byteu ( & c - > gb ) ; g = g < < 2 | g > > 4 ; b = bytestream2_get_byteu ( & c - > gb ) ; b = b < < 2 | b > > 4 ; * out + + = ( 0xFFU < < 24 ) | ( r < < 16 ) | ( g < < 8 ) | b ; } c - > pic - > palette_has_changed = 1 ; } switch ( code & 0x0F ) { case 0 : / * Block - based motion compensation using 4x4 blocks with either * horizontal or vertical vectors ; might incorporate VQ as well . * / if ( ( ret = decode_0 ( c , pkt - > data , code ) ) < 0 ) return ret ; break ; case 1 : / * Uncompressed data . This mode specifies that ( width * height ) bytes * should be copied directly from the encoded buffer into the output . * / dst = c - > frame[c - > current_frame] ; // possibly chunk length data bytestream2_skip ( & c - > gb , 2 ) ; if ( bytestream2_get_bytes_left ( & c - > gb ) < c - > video_size ) return AVERROR_INVALIDDATA ; bytestream2_get_bufferu ( & c - > gb , dst , c - > video_size ) ; break ; case 2 : / * Copy reference frame : Consume the next byte in the stream as the * reference frame ( which should be 0 , 1 , 2 , or 3 , and should not be * the same as the current frame number ) . * / frame = bytestream2_get_byte ( & c - > gb ) ; if ( frame > 3 ) return AVERROR_INVALIDDATA ; if ( frame ! = c - > current_frame ) memcpy ( c - > frame[c - > current_frame] , c - > frame[frame] , c - > frame_size ) ; break ; case 4 : / * Run length encoding . * / dst = c - > frame[c - > current_frame] ; end = dst + c - > video_size ; bytestream2_skip ( & c - > gb , 2 ) ; while ( dst < end ) { int8_t code ; int count ; if ( bytestream2_get_bytes_left ( & c - > gb ) < 2 ) return AVERROR_INVALIDDATA ; code = bytestream2_get_byteu ( & c - > gb ) ; count = FFABS ( code ) + 1 ; if ( dst + count > end ) return AVERROR_INVALIDDATA ; if ( code < 0 ) memset ( dst , bytestream2_get_byteu ( & c - > gb ) , count ) ; else bytestream2_get_buffer ( & c - > gb , dst , count ) ; dst + = count ; } break ; default : av_assert0 ( 0 ) ; } av_image_copy_plane ( c - > pic - > data[0] , c - > pic - > linesize[0] , c - > frame[c - > current_frame] , c - > width , c - > width , c - > height ) ; c - > current_frame = ( c - > current_frame + 1 ) & 3 ; if ( ( ret = av_frame_ref ( data , c - > pic ) ) < 0 ) return ret ; * got_frame = 1 ; return pkt - > size ; }",1
"int avresample_get_matrix ( AVAudioResampleContext * avr , double * matrix , int stride ) { int in_channels , out_channels , i , o ; in_channels = av_get_channel_layout_nb_channels ( avr - > in_channel_layout ) ; out_channels = av_get_channel_layout_nb_channels ( avr - > out_channel_layout ) ; if ( in_channels < 0 || in_channels > AVRESAMPLE_MAX_CHANNELS || out_channels < 0 || out_channels > AVRESAMPLE_MAX_CHANNELS ) { av_log ( avr , AV_LOG_ERROR , Invalid channel layouts\n ) ; return AVERROR ( EINVAL ) ; } switch ( avr - > mix_coeff_type ) { case AV_MIX_COEFF_TYPE_Q8 : if ( ! avr - > am - > matrix_q8[0] ) { av_log ( avr , AV_LOG_ERROR , matrix is not set\n ) ; return AVERROR ( EINVAL ) ; } for ( o = 0 ; o < out_channels ; o + + ) for ( i = 0 ; i < in_channels ; i + + ) matrix[o * stride + i] = avr - > am - > matrix_q8[o][i] / 256 . 0 ; break ; case AV_MIX_COEFF_TYPE_Q15 : if ( ! avr - > am - > matrix_q15[0] ) { av_log ( avr , AV_LOG_ERROR , matrix is not set\n ) ; return AVERROR ( EINVAL ) ; } for ( o = 0 ; o < out_channels ; o + + ) for ( i = 0 ; i < in_channels ; i + + ) matrix[o * stride + i] = avr - > am - > matrix_q15[o][i] / 32768 . 0 ; break ; case AV_MIX_COEFF_TYPE_FLT : if ( ! avr - > am - > matrix_flt[0] ) { av_log ( avr , AV_LOG_ERROR , matrix is not set\n ) ; return AVERROR ( EINVAL ) ; } for ( o = 0 ; o < out_channels ; o + + ) for ( i = 0 ; i < in_channels ; i + + ) matrix[o * stride + i] = avr - > am - > matrix_flt[o][i] ; break ; default : av_log ( avr , AV_LOG_ERROR , Invalid mix coeff type\n ) ; return AVERROR ( EINVAL ) ; } return 0 ; }",1
"static int parse_packet ( AVFormatContext * s , AVPacket * pkt , int stream_index ) { AVPacket out_pkt = { 0 } , flush_pkt = { 0 } ; AVStream * st = s - > streams[stream_index] ; uint8_t * data = pkt ? pkt - > data : NULL ; int size = pkt ? pkt - > size : 0 ; int ret = 0 , got_output = 0 ; if ( ! pkt ) { av_init_packet ( & flush_pkt ) ; pkt = & flush_pkt ; got_output = 1 ; } while ( size > 0 || ( pkt == & flush_pkt & & got_output ) ) { int len ; av_init_packet ( & out_pkt ) ; len = av_parser_parse2 ( st - > parser , st - > codec , & out_pkt . data , & out_pkt . size , data , size , pkt - > pts , pkt - > dts , pkt - > pos ) ; pkt - > pts = pkt - > dts = AV_NOPTS_VALUE ; / * increment read pointer * / data + = len ; size - = len ; got_output = ! ! out_pkt . size ; if ( ! out_pkt . size ) continue ; if ( pkt - > side_data ) { out_pkt . side_data = pkt - > side_data ; out_pkt . side_data_elems = pkt - > side_data_elems ; pkt - > side_data = NULL ; pkt - > side_data_elems = 0 ; } / * set the duration * / out_pkt . duration = 0 ; if ( st - > codec - > codec_type == AVMEDIA_TYPE_AUDIO ) { if ( st - > codec - > sample_rate > 0 ) { out_pkt . duration = av_rescale_q_rnd ( st - > parser - > duration , ( AVRational ) { 1 , st - > codec - > sample_rate } , st - > time_base , AV_ROUND_DOWN ) ; } } out_pkt . stream_index = st - > index ; out_pkt . pts = st - > parser - > pts ; out_pkt . dts = st - > parser - > dts ; out_pkt . pos = st - > parser - > pos ; if ( st - > parser - > key_frame == 1 || ( st - > parser - > key_frame == - 1 & & st - > parser - > pict_type == AV_PICTURE_TYPE_I ) ) out_pkt . flags |= AV_PKT_FLAG_KEY ; compute_pkt_fields ( s , st , st - > parser , & out_pkt ) ; if ( ( s - > iformat - > flags & AVFMT_GENERIC_INDEX ) & & out_pkt . flags & AV_PKT_FLAG_KEY ) { ff_reduce_index ( s , st - > index ) ; av_add_index_entry ( st , st - > parser - > frame_offset , out_pkt . dts , 0 , 0 , AVINDEX_KEYFRAME ) ; } if ( out_pkt . data == pkt - > data & & out_pkt . size == pkt - > size ) { out_pkt . buf = pkt - > buf ; pkt - > buf = NULL ; } if ( ( ret = av_dup_packet ( & out_pkt ) ) < 0 ) goto fail ; if ( ! add_to_pktbuf ( & s - > internal - > parse_queue , & out_pkt , & s - > internal - > parse_queue_end ) ) { av_packet_unref ( & out_pkt ) ; ret = AVERROR ( ENOMEM ) ; goto fail ; } } / * end of the stream = > close and free the parser * / if ( pkt == & flush_pkt ) { av_parser_close ( st - > parser ) ; st - > parser = NULL ; } fail : av_packet_unref ( pkt ) ; return ret ; }",0
"int avpriv_dv_produce_packet ( DVDemuxContext * c , AVPacket * pkt , uint8_t * buf , int buf_size , int64_t pos ) { int size , i ; uint8_t * ppcm[4] = { 0 } ; if ( buf_size < DV_PROFILE_BYTES || ! ( c - > sys = avpriv_dv_frame_profile ( c - > sys , buf , buf_size ) ) || buf_size < c - > sys - > frame_size ) { return - 1 ; / * Broken frame , or not enough data * / } / * Queueing audio packet * / / * FIXME : in case of no audio/bad audio we have to do something * / size = dv_extract_audio_info ( c , buf ) ; for ( i = 0 ; i < c - > ach ; i + + ) { c - > audio_pkt[i] . pos = pos ; c - > audio_pkt[i] . size = size ; c - > audio_pkt[i] . pts = c - > abytes * 30000 * 8 / c - > ast[i] - > codec - > bit_rate ; ppcm[i] = c - > audio_buf[i] ; } dv_extract_audio ( buf , ppcm , c - > sys ) ; / * We work with 720p frames split in half , thus even frames have * channels 0 , 1 and odd 2 , 3 . * / if ( c - > sys - > height == 720 ) { if ( buf[1] & 0x0C ) { c - > audio_pkt[2] . size = c - > audio_pkt[3] . size = 0 ; } else { c - > audio_pkt[0] . size = c - > audio_pkt[1] . size = 0 ; c - > abytes + = size ; } } else { c - > abytes + = size ; } / * Now it ' s time to return video packet * / size = dv_extract_video_info ( c , buf ) ; av_init_packet ( pkt ) ; pkt - > data = buf ; pkt - > pos = pos ; pkt - > size = size ; pkt - > flags |= AV_PKT_FLAG_KEY ; pkt - > stream_index = c - > vst - > id ; pkt - > pts = c - > frames ; c - > frames + + ; return size ; }",1
"static int gdv_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { GDVContext * gdv = avctx - > priv_data ; GetByteContext * gb = & gdv - > gb ; PutByteContext * pb = & gdv - > pb ; AVFrame * frame = data ; int ret , i , pal_size ; const uint8_t * pal = av_packet_get_side_data ( avpkt , AV_PKT_DATA_PALETTE , & pal_size ) ; int compression ; unsigned flags ; uint8_t * dst ; if ( ( ret = ff_get_buffer ( avctx , frame , 0 ) ) < 0 ) return ret ; if ( pal & & pal_size == AVPALETTE_SIZE ) memcpy ( gdv - > pal , pal , AVPALETTE_SIZE ) ; bytestream2_init ( gb , avpkt - > data , avpkt - > size ) ; bytestream2_init_writer ( pb , gdv - > frame , gdv - > frame_size ) ; flags = bytestream2_get_le32 ( gb ) ; compression = flags & 0xF ; rescale ( gdv , gdv - > frame , avctx - > width , avctx - > height , ! ! ( flags & 0x10 ) , ! ! ( flags & 0x20 ) ) ; switch ( compression ) { case 1 : memset ( gdv - > frame + PREAMBLE_SIZE , 0 , gdv - > frame_size - PREAMBLE_SIZE ) ; case 0 : if ( bytestream2_get_bytes_left ( gb ) < 256 * 3 ) return AVERROR_INVALIDDATA ; for ( i = 0 ; i < 256 ; i + + ) { unsigned r = bytestream2_get_byte ( gb ) ; unsigned g = bytestream2_get_byte ( gb ) ; unsigned b = bytestream2_get_byte ( gb ) ; gdv - > pal[i] = 0xFFU < < 24 | r < < 18 | g < < 10 | b < < 2 ; } break ; case 2 : ret = decompress_2 ( avctx ) ; break ; case 3 : break ; case 5 : ret = decompress_5 ( avctx , flags > > 8 ) ; break ; case 6 : ret = decompress_68 ( avctx , flags > > 8 , 0 ) ; break ; case 8 : ret = decompress_68 ( avctx , flags > > 8 , 1 ) ; break ; default : return AVERROR_INVALIDDATA ; } memcpy ( frame - > data[1] , gdv - > pal , AVPALETTE_SIZE ) ; dst = frame - > data[0] ; if ( ! gdv - > scale_v & & ! gdv - > scale_h ) { int sidx = PREAMBLE_SIZE , didx = 0 ; int y , x ; for ( y = 0 ; y < avctx - > height ; y + + ) { for ( x = 0 ; x < avctx - > width ; x + + ) { dst[x + didx] = gdv - > frame[x + sidx] ; } sidx + = avctx - > width ; didx + = frame - > linesize[0] ; } } else { int sidx = PREAMBLE_SIZE , didx = 0 ; int y , x ; for ( y = 0 ; y < avctx - > height ; y + + ) { if ( ! gdv - > scale_v ) { for ( x = 0 ; x < avctx - > width ; x + + ) { dst[didx + x] = gdv - > frame[sidx + x] ; } } else { for ( x = 0 ; x < avctx - > width ; x + + ) { dst[didx + x] = gdv - > frame[sidx + x/2] ; } } if ( ! gdv - > scale_h || ( ( y & 1 ) == 1 ) ) { sidx + = ! gdv - > scale_v ? avctx - > width : avctx - > width/2 ; } didx + = frame - > linesize[0] ; } } * got_frame = 1 ; return ret < 0 ? ret : avpkt - > size ; }",1
"int ff_rle_encode ( uint8_t * outbuf , int out_size , const uint8_t * ptr , int bpp , int w , int add_rep , int xor_rep , int add_raw , int xor_raw ) { int count , x ; uint8_t * out = outbuf ; for ( x = 0 ; x < w ; x + = count ) { / * see if we can encode the next set of pixels with RLE * / if ( ( count = count_pixels ( ptr , w - x , bpp , 1 ) ) > 1 ) { if ( out + bpp + 1 > outbuf + out_size ) return - 1 ; * out + + = ( count xor_rep ) + add_rep ; memcpy ( out , ptr , bpp ) ; out + = bpp ; } else { / * fall back on uncompressed * / count = count_pixels ( ptr , w - x , bpp , 0 ) ; * out + + = ( count xor_raw ) + add_raw ; if ( out + bpp * count > outbuf + out_size ) return - 1 ; memcpy ( out , ptr , bpp * count ) ; out + = bpp * count ; } ptr + = count * bpp ; } return out - outbuf ; }",0
"static void stream_component_close ( VideoState * is , int stream_index ) { AVFormatContext * ic = is - > ic ; AVCodecContext * avctx ; if ( stream_index < 0 || stream_index > = ic - > nb_streams ) return ; avctx = ic - > streams[stream_index] - > codec ; switch ( avctx - > codec_type ) { case AVMEDIA_TYPE_AUDIO : packet_queue_abort ( & is - > audioq ) ; SDL_CloseAudio ( ) ; packet_queue_flush ( & is - > audioq ) ; av_free_packet ( & is - > audio_pkt ) ; if ( is - > swr_ctx ) swr_free ( & is - > swr_ctx ) ; av_freep ( & is - > audio_buf1 ) ; is - > audio_buf = NULL ; av_freep ( & is - > frame ) ; if ( is - > rdft ) { av_rdft_end ( is - > rdft ) ; av_freep ( & is - > rdft_data ) ; is - > rdft = NULL ; is - > rdft_bits = 0 ; } break ; case AVMEDIA_TYPE_VIDEO : packet_queue_abort ( & is - > videoq ) ; / * note : we also signal this mutex to make sure we deblock the video thread in all cases * / SDL_LockMutex ( is - > pictq_mutex ) ; SDL_CondSignal ( is - > pictq_cond ) ; SDL_UnlockMutex ( is - > pictq_mutex ) ; SDL_WaitThread ( is - > video_tid , NULL ) ; packet_queue_flush ( & is - > videoq ) ; break ; case AVMEDIA_TYPE_SUBTITLE : packet_queue_abort ( & is - > subtitleq ) ; / * note : we also signal this mutex to make sure we deblock the video thread in all cases * / SDL_LockMutex ( is - > subpq_mutex ) ; is - > subtitle_stream_changed = 1 ; SDL_CondSignal ( is - > subpq_cond ) ; SDL_UnlockMutex ( is - > subpq_mutex ) ; SDL_WaitThread ( is - > subtitle_tid , NULL ) ; packet_queue_flush ( & is - > subtitleq ) ; break ; default : break ; } ic - > streams[stream_index] - > discard = AVDISCARD_ALL ; avcodec_close ( avctx ) ; if CONFIG_AVFILTER free_buffer_pool ( & is - > buffer_pool ) ; endif switch ( avctx - > codec_type ) { case AVMEDIA_TYPE_AUDIO : is - > audio_st = NULL ; is - > audio_stream = - 1 ; break ; case AVMEDIA_TYPE_VIDEO : is - > video_st = NULL ; is - > video_stream = - 1 ; break ; case AVMEDIA_TYPE_SUBTITLE : is - > subtitle_st = NULL ; is - > subtitle_stream = - 1 ; break ; default : break ; } }",0
"static inline int mpeg1_decode_block_inter ( MpegEncContext * s , int16_t * block , int n ) { int level , i , j , run ; RLTable * rl = & ff_rl_mpeg1 ; uint8_t * const scantable = s - > intra_scantable . permutated ; const uint16_t * quant_matrix = s - > inter_matrix ; const int qscale = s - > qscale ; { OPEN_READER ( re , & s - > gb ) ; i = - 1 ; // special case for first coefficient , no need to add second VLC table UPDATE_CACHE ( re , & s - > gb ) ; if ( ( ( int32_t ) GET_CACHE ( re , & s - > gb ) ) < 0 ) { level = ( 3 * qscale * quant_matrix[0] ) > > 5 ; level = ( level - 1 ) | 1 ; if ( GET_CACHE ( re , & s - > gb ) & 0x40000000 ) level = - level ; block[0] = level ; i + + ; SKIP_BITS ( re , & s - > gb , 2 ) ; if ( ( ( int32_t ) GET_CACHE ( re , & s - > gb ) ) < = ( int32_t ) 0xBFFFFFFF ) goto end ; } / * now quantify & encode AC coefficients * / for ( ; ; ) { GET_RL_VLC ( level , run , re , & s - > gb , rl - > rl_vlc[0] , TEX_VLC_BITS , 2 , 0 ) ; if ( level ! = 0 ) { i + = run ; j = scantable[i] ; level = ( ( level * 2 + 1 ) * qscale * quant_matrix[j] ) > > 5 ; level = ( level - 1 ) | 1 ; level = ( level SHOW_SBITS ( re , & s - > gb , 1 ) ) - SHOW_SBITS ( re , & s - > gb , 1 ) ; SKIP_BITS ( re , & s - > gb , 1 ) ; } else { / * escape * / run = SHOW_UBITS ( re , & s - > gb , 6 ) + 1 ; LAST_SKIP_BITS ( re , & s - > gb , 6 ) ; UPDATE_CACHE ( re , & s - > gb ) ; level = SHOW_SBITS ( re , & s - > gb , 8 ) ; SKIP_BITS ( re , & s - > gb , 8 ) ; if ( level == - 128 ) { level = SHOW_UBITS ( re , & s - > gb , 8 ) - 256 ; SKIP_BITS ( re , & s - > gb , 8 ) ; } else if ( level == 0 ) { level = SHOW_UBITS ( re , & s - > gb , 8 ) ; SKIP_BITS ( re , & s - > gb , 8 ) ; } i + = run ; j = scantable[i] ; if ( level < 0 ) { level = - level ; level = ( ( level * 2 + 1 ) * qscale * quant_matrix[j] ) > > 5 ; level = ( level - 1 ) | 1 ; level = - level ; } else { level = ( ( level * 2 + 1 ) * qscale * quant_matrix[j] ) > > 5 ; level = ( level - 1 ) | 1 ; } } if ( i > 63 ) { av_log ( s - > avctx , AV_LOG_ERROR , ac - tex damaged at %d %d\n , s - > mb_x , s - > mb_y ) ; return - 1 ; } block[j] = level ; if ( ( ( int32_t ) GET_CACHE ( re , & s - > gb ) ) < = ( int32_t ) 0xBFFFFFFF ) break ; UPDATE_CACHE ( re , & s - > gb ) ; } end : LAST_SKIP_BITS ( re , & s - > gb , 2 ) ; CLOSE_READER ( re , & s - > gb ) ; } s - > block_last_index[n] = i ; return 0 ; }",1
"int check_tm_pred4x4_mode ( int mode , int mb_x , int mb_y ) { if ( ! mb_x ) { return mb_y ? VERT_VP8_PRED : DC_129_PRED ; } else { return mb_y ? mode : HOR_VP8_PRED ; } }",1
"static void vp8_decode_mv_mb_modes ( AVCodecContext * avctx , VP8Frame * curframe , VP8Frame * prev_frame ) { VP8Context * s = avctx - > priv_data ; int mb_x , mb_y ; s - > mv_min . y = - MARGIN ; s - > mv_max . y = ( ( s - > mb_height - 1 ) < < 6 ) + MARGIN ; for ( mb_y = 0 ; mb_y < s - > mb_height ; mb_y + + ) { VP8Macroblock * mb = s - > macroblocks_base + ( ( s - > mb_width + 1 ) * ( mb_y + 1 ) + 1 ) ; int mb_xy = mb_y * s - > mb_width ; AV_WN32A ( s - > intra4x4_pred_mode_left , DC_PRED * 0x01010101 ) ; s - > mv_min . x = - MARGIN ; s - > mv_max . x = ( ( s - > mb_width - 1 ) < < 6 ) + MARGIN ; for ( mb_x = 0 ; mb_x < s - > mb_width ; mb_x + + , mb_xy + + , mb + + ) { if ( mb_y == 0 ) AV_WN32A ( ( mb - s - > mb_width - 1 ) - > intra4x4_pred_mode_top , DC_PRED * 0x01010101 ) ; decode_mb_mode ( s , mb , mb_x , mb_y , curframe - > seg_map - > data + mb_xy , prev_frame & & prev_frame - > seg_map ? prev_frame - > seg_map - > data + mb_xy : NULL , 1 ) ; s - > mv_min . x - = 64 ; s - > mv_max . x - = 64 ; } s - > mv_min . y - = 64 ; s - > mv_max . y - = 64 ; } }",1
"static av_always_inline void mc_luma_scaled ( VP9Context * s , vp9_scaled_mc_func smc , vp9_mc_func ( * mc ) [2] , uint8_t * dst , ptrdiff_t dst_stride , const uint8_t * ref , ptrdiff_t ref_stride , ThreadFrame * ref_frame , ptrdiff_t y , ptrdiff_t x , const VP56mv * in_mv , int px , int py , int pw , int ph , int bw , int bh , int w , int h , int bytesperpixel , const uint16_t * scale , const uint8_t * step ) { if ( s - > s . frames[CUR_FRAME] . tf . f - > width == ref_frame - > f - > width & & s - > s . frames[CUR_FRAME] . tf . f - > height == ref_frame - > f - > height ) { mc_luma_unscaled ( s , mc , dst , dst_stride , ref , ref_stride , ref_frame , y , x , in_mv , bw , bh , w , h , bytesperpixel ) ; } else { define scale_mv ( n , dim ) ( ( ( int64_t ) ( n ) * scale[dim] ) > > 14 ) int mx , my ; int refbw_m1 , refbh_m1 ; int th ; VP56mv mv ; mv . x = av_clip ( in_mv - > x , - ( x + pw - px + 4 ) * 8 , ( s - > cols * 8 - x + px + 3 ) * 8 ) ; mv . y = av_clip ( in_mv - > y , - ( y + ph - py + 4 ) * 8 , ( s - > rows * 8 - y + py + 3 ) * 8 ) ; // BUG libvpx seems to scale the two components separately . This introduces // rounding errors but we have to reproduce them to be exactly compatible // with the output from libvpx . . . mx = scale_mv ( mv . x * 2 , 0 ) + scale_mv ( x * 16 , 0 ) ; my = scale_mv ( mv . y * 2 , 1 ) + scale_mv ( y * 16 , 1 ) ; y = my > > 4 ; x = mx > > 4 ; ref + = y * ref_stride + x * bytesperpixel ; mx & = 15 ; my & = 15 ; refbw_m1 = ( ( bw - 1 ) * step[0] + mx ) > > 4 ; refbh_m1 = ( ( bh - 1 ) * step[1] + my ) > > 4 ; // FIXME bilinear filter only needs 0/1 pixels , not 3/4 // we use + 7 because the last 7 pixels of each sbrow can be changed in // the longest loopfilter of the next sbrow th = ( y + refbh_m1 + 4 + 7 ) > > 6 ; ff_thread_await_progress ( ref_frame , FFMAX ( th , 0 ) , 0 ) ; if ( x < 3 || y < 3 || x + 4 > = w - refbw_m1 || y + 4 > = h - refbh_m1 ) { s - > vdsp . emulated_edge_mc ( s - > edge_emu_buffer , ref - 3 * ref_stride - 3 * bytesperpixel , 288 , ref_stride , refbw_m1 + 8 , refbh_m1 + 8 , x - 3 , y - 3 , w , h ) ; ref = s - > edge_emu_buffer + 3 * 288 + 3 * bytesperpixel ; ref_stride = 288 ; } smc ( dst , dst_stride , ref , ref_stride , bh , mx , my , step[0] , step[1] ) ; } }",1
"static void vc1_inv_trans_4x4_c ( uint8_t * dest , int linesize , DCTELEM * block ) { int i ; register int t1 , t2 , t3 , t4 ; DCTELEM * src , * dst ; const uint8_t * cm = ff_cropTbl + MAX_NEG_CROP ; src = block ; dst = block ; for ( i = 0 ; i < 4 ; i + + ) { t1 = 17 * ( src[0] + src[2] ) + 4 ; t2 = 17 * ( src[0] - src[2] ) + 4 ; t3 = 22 * src[1] + 10 * src[3] ; t4 = 22 * src[3] - 10 * src[1] ; dst[0] = ( t1 + t3 ) > > 3 ; dst[1] = ( t2 - t4 ) > > 3 ; dst[2] = ( t2 + t4 ) > > 3 ; dst[3] = ( t1 - t3 ) > > 3 ; src + = 8 ; dst + = 8 ; } src = block ; for ( i = 0 ; i < 4 ; i + + ) { t1 = 17 * ( src[ 0] + src[16] ) + 64 ; t2 = 17 * ( src[ 0] - src[16] ) + 64 ; t3 = 22 * src[ 8] + 10 * src[24] ; t4 = 22 * src[24] - 10 * src[ 8] ; dest[0 * linesize] = cm[dest[0 * linesize] + ( ( t1 + t3 ) > > 7 ) ] ; dest[1 * linesize] = cm[dest[1 * linesize] + ( ( t2 - t4 ) > > 7 ) ] ; dest[2 * linesize] = cm[dest[2 * linesize] + ( ( t2 + t4 ) > > 7 ) ] ; dest[3 * linesize] = cm[dest[3 * linesize] + ( ( t1 - t3 ) > > 7 ) ] ; src + + ; dest + + ; } }",1
"int ff_draw_init ( FFDrawContext * draw , enum PixelFormat format , unsigned flags ) { const AVPixFmtDescriptor * desc = & av_pix_fmt_descriptors[format] ; const AVComponentDescriptor * c ; unsigned i , nb_planes = 0 ; int pixelstep[MAX_PLANES] = { 0 } ; if ( ! desc - > name ) return AVERROR ( EINVAL ) ; if ( desc - > flags & ( PIX_FMT_PLANAR | PIX_FMT_RGB ) ) return AVERROR ( ENOSYS ) ; for ( i = 0 ; i < desc - > nb_components ; i + + ) { c = & desc - > comp[i] ; / * for now , only 8 - bits formats * / if ( c - > depth_minus1 ! = 8 - 1 ) return AVERROR ( ENOSYS ) ; if ( c - > plane > = MAX_PLANES ) return AVERROR ( ENOSYS ) ; / * strange interleaving * / if ( pixelstep[c - > plane] ! = 0 & & pixelstep[c - > plane] ! = c - > step_minus1 + 1 ) return AVERROR ( ENOSYS ) ; pixelstep[c - > plane] = c - > step_minus1 + 1 ; if ( pixelstep[c - > plane] > = 8 ) return AVERROR ( ENOSYS ) ; nb_planes = FFMAX ( nb_planes , c - > plane + 1 ) ; } if ( ( desc - > log2_chroma_w || desc - > log2_chroma_h ) & & nb_planes < 3 ) return AVERROR ( ENOSYS ) ; / * exclude NV12 and NV21 * / memset ( draw , 0 , sizeof ( * draw ) ) ; draw - > desc = desc ; draw - > format = format ; draw - > nb_planes = nb_planes ; memcpy ( draw - > pixelstep , pixelstep , sizeof ( draw - > pixelstep ) ) ; if ( nb_planes > = 3 & & ! ( desc - > flags & PIX_FMT_RGB ) ) { draw - > hsub[1] = draw - > hsub[2] = draw - > hsub_max = desc - > log2_chroma_w ; draw - > vsub[1] = draw - > vsub[2] = draw - > vsub_max = desc - > log2_chroma_h ; } for ( i = 0 ; i < ( ( desc - > nb_components - 1 ) | 1 ) ; i + + ) draw - > comp_mask[desc - > comp[i] . plane] |= 1 < < ( desc - > comp[i] . offset_plus1 - 1 ) ; return 0 ; }",1
"static struct ResampleContext * create ( struct ResampleContext * c , int out_rate , int in_rate , int filter_size , int phase_shift , int linear , double cutoff , enum AVSampleFormat format , enum SwrFilterType filter_type , double kaiser_beta , double precision , int cheby , int exact_rational ) { soxr_error_t error ; soxr_datatype_t type = format == AV_SAMPLE_FMT_S16P ? SOXR_INT16_S : format == AV_SAMPLE_FMT_S16 ? SOXR_INT16_I : format == AV_SAMPLE_FMT_S32P ? SOXR_INT32_S : format == AV_SAMPLE_FMT_S32 ? SOXR_INT32_I : format == AV_SAMPLE_FMT_FLTP ? SOXR_FLOAT32_S : format == AV_SAMPLE_FMT_FLT ? SOXR_FLOAT32_I : format == AV_SAMPLE_FMT_DBLP ? SOXR_FLOAT64_S : format == AV_SAMPLE_FMT_DBL ? SOXR_FLOAT64_I : ( soxr_datatype_t ) - 1 ; soxr_io_spec_t io_spec = soxr_io_spec ( type , type ) ; soxr_quality_spec_t q_spec = soxr_quality_spec ( ( int ) ( ( precision - 2 ) /4 ) , ( SOXR_HI_PREC_CLOCK|SOXR_ROLLOFF_NONE ) * ! ! cheby ) ; q_spec . precision = linear ? 0 : precision ; if ! defined SOXR_VERSION / * Deprecated March 2013 : * / q_spec . bw_pc = cutoff ? FFMAX ( FFMIN ( cutoff , . 995 ) , . 8 ) * 100 : q_spec . bw_pc ; else q_spec . passband_end = cutoff ? FFMAX ( FFMIN ( cutoff , . 995 ) , . 8 ) : q_spec . passband_end ; endif soxr_delete ( ( soxr_t ) c ) ; c = ( struct ResampleContext * ) soxr_create ( in_rate , out_rate , 0 , & error , & io_spec , & q_spec , 0 ) ; if ( ! c ) av_log ( NULL , AV_LOG_ERROR , soxr_create : %s\n , error ) ; return c ; }",1
av_cold void ff_dct_init_mmx ( DCTContext * s ) { if HAVE_YASM int has_vectors = av_get_cpu_flags ( ) ; if ( has_vectors & AV_CPU_FLAG_SSE & & HAVE_SSE ) s - > dct32 = ff_dct32_float_sse ; if ( has_vectors & AV_CPU_FLAG_SSE2 & & HAVE_SSE ) s - > dct32 = ff_dct32_float_sse2 ; if ( has_vectors & AV_CPU_FLAG_AVX & & HAVE_AVX ) s - > dct32 = ff_dct32_float_avx ; endif },0
"int ff_reget_buffer ( AVCodecContext * avctx , AVFrame * frame ) { AVFrame * tmp ; int ret ; av_assert0 ( avctx - > codec_type == AVMEDIA_TYPE_VIDEO ) ; if ( ! frame - > data[0] ) return ff_get_buffer ( avctx , frame , AV_GET_BUFFER_FLAG_REF ) ; if ( av_frame_is_writable ( frame ) ) { frame - > pkt_pts = avctx - > internal - > pkt ? avctx - > internal - > pkt - > pts : AV_NOPTS_VALUE ; frame - > reordered_opaque = avctx - > reordered_opaque ; return 0 ; } tmp = av_frame_alloc ( ) ; if ( ! tmp ) return AVERROR ( ENOMEM ) ; av_frame_move_ref ( tmp , frame ) ; ret = ff_get_buffer ( avctx , frame , AV_GET_BUFFER_FLAG_REF ) ; if ( ret < 0 ) { av_frame_free ( & tmp ) ; return ret ; } av_frame_copy ( frame , tmp ) ; av_frame_free ( & tmp ) ; return 0 ; }",0
"static void mxf_write_cdci_common ( AVFormatContext * s , AVStream * st , const UID key , unsigned size ) { MXFStreamContext * sc = st - > priv_data ; AVIOContext * pb = s - > pb ; int stored_height = ( st - > codec - > height + 15 ) /16 * 16 ; int display_height ; int f1 , f2 ; unsigned desc_size = size + 8 + 8 + 8 + 8 + 8 + 8 + 5 + 16 + sc - > interlaced * 4 + 12 + 20 ; if ( sc - > interlaced & & sc - > field_dominance ) desc_size + = 5 ; mxf_write_generic_desc ( s , st , key , desc_size ) ; mxf_write_local_tag ( pb , 4 , 0x3203 ) ; avio_wb32 ( pb , st - > codec - > width ) ; mxf_write_local_tag ( pb , 4 , 0x3202 ) ; avio_wb32 ( pb , stored_height > > sc - > interlaced ) ; mxf_write_local_tag ( pb , 4 , 0x3209 ) ; avio_wb32 ( pb , st - > codec - > width ) ; if ( st - > codec - > height == 608 ) // PAL + VBI display_height = 576 ; else if ( st - > codec - > height == 512 ) // NTSC + VBI display_height = 486 ; else display_height = st - > codec - > height ; mxf_write_local_tag ( pb , 4 , 0x3208 ) ; avio_wb32 ( pb , display_height > > sc - > interlaced ) ; // component depth mxf_write_local_tag ( pb , 4 , 0x3301 ) ; avio_wb32 ( pb , sc - > component_depth ) ; // horizontal subsampling mxf_write_local_tag ( pb , 4 , 0x3302 ) ; avio_wb32 ( pb , 2 ) ; // frame layout mxf_write_local_tag ( pb , 1 , 0x320C ) ; avio_w8 ( pb , sc - > interlaced ) ; // video line map switch ( st - > codec - > height ) { case 576 : f1 = 23 ; f2 = st - > codec - > codec_id == AV_CODEC_ID_DVVIDEO ? 335 : 336 ; break ; case 608 : f1 = 7 ; f2 = 320 ; break ; case 480 : f1 = 20 ; f2 = st - > codec - > codec_id == AV_CODEC_ID_DVVIDEO ? 285 : 283 ; break ; case 512 : f1 = 7 ; f2 = 270 ; break ; case 720 : f1 = 26 ; f2 = 0 ; break ; // progressive case 1080 : f1 = 21 ; f2 = 584 ; break ; default : f1 = 0 ; f2 = 0 ; break ; } if ( ! sc - > interlaced ) { f2 = 0 ; f1 * = 2 ; } mxf_write_local_tag ( pb , 12 + sc - > interlaced * 4 , 0x320D ) ; avio_wb32 ( pb , sc - > interlaced ? 2 : 1 ) ; avio_wb32 ( pb , 4 ) ; avio_wb32 ( pb , f1 ) ; if ( sc - > interlaced ) avio_wb32 ( pb , f2 ) ; mxf_write_local_tag ( pb , 8 , 0x320E ) ; avio_wb32 ( pb , sc - > aspect_ratio . num ) ; avio_wb32 ( pb , sc - > aspect_ratio . den ) ; mxf_write_local_tag ( pb , 16 , 0x3201 ) ; avio_write ( pb , * sc - > codec_ul , 16 ) ; if ( sc - > interlaced & & sc - > field_dominance ) { mxf_write_local_tag ( pb , 1 , 0x3212 ) ; avio_w8 ( pb , sc - > field_dominance ) ; } }",0
"static av_always_inline void h264_filter_mb_fast_internal ( H264Context * h , H264SliceContext * sl , int mb_x , int mb_y , uint8_t * img_y , uint8_t * img_cb , uint8_t * img_cr , unsigned int linesize , unsigned int uvlinesize , int pixel_shift ) { int chroma = ! ( CONFIG_GRAY & & ( h - > flags & CODEC_FLAG_GRAY ) ) ; int chroma444 = CHROMA444 ( h ) ; int chroma422 = CHROMA422 ( h ) ; int mb_xy = h - > mb_xy ; int left_type = sl - > left_type[LTOP] ; int top_type = sl - > top_type ; int qp_bd_offset = 6 * ( h - > sps . bit_depth_luma - 8 ) ; int a = 52 + h - > slice_alpha_c0_offset - qp_bd_offset ; int b = 52 + h - > slice_beta_offset - qp_bd_offset ; int mb_type = h - > cur_pic . mb_type[mb_xy] ; int qp = h - > cur_pic . qscale_table[mb_xy] ; int qp0 = h - > cur_pic . qscale_table[mb_xy - 1] ; int qp1 = h - > cur_pic . qscale_table[sl - > top_mb_xy] ; int qpc = get_chroma_qp ( h , 0 , qp ) ; int qpc0 = get_chroma_qp ( h , 0 , qp0 ) ; int qpc1 = get_chroma_qp ( h , 0 , qp1 ) ; qp0 = ( qp + qp0 + 1 ) > > 1 ; qp1 = ( qp + qp1 + 1 ) > > 1 ; qpc0 = ( qpc + qpc0 + 1 ) > > 1 ; qpc1 = ( qpc + qpc1 + 1 ) > > 1 ; if ( IS_INTRA ( mb_type ) ) { static const int16_t bS4[4] = { 4 , 4 , 4 , 4 } ; static const int16_t bS3[4] = { 3 , 3 , 3 , 3 } ; const int16_t * bSH = FIELD_PICTURE ( h ) ? bS3 : bS4 ; if ( left_type ) filter_mb_edgev ( & img_y[4 * 0 < < pixel_shift] , linesize , bS4 , qp0 , a , b , h , 1 ) ; if ( IS_8x8DCT ( mb_type ) ) { filter_mb_edgev ( & img_y[4 * 2 < < pixel_shift] , linesize , bS3 , qp , a , b , h , 0 ) ; if ( top_type ) { filter_mb_edgeh ( & img_y[4 * 0 * linesize] , linesize , bSH , qp1 , a , b , h , 1 ) ; } filter_mb_edgeh ( & img_y[4 * 2 * linesize] , linesize , bS3 , qp , a , b , h , 0 ) ; } else { filter_mb_edgev ( & img_y[4 * 1 < < pixel_shift] , linesize , bS3 , qp , a , b , h , 0 ) ; filter_mb_edgev ( & img_y[4 * 2 < < pixel_shift] , linesize , bS3 , qp , a , b , h , 0 ) ; filter_mb_edgev ( & img_y[4 * 3 < < pixel_shift] , linesize , bS3 , qp , a , b , h , 0 ) ; if ( top_type ) { filter_mb_edgeh ( & img_y[4 * 0 * linesize] , linesize , bSH , qp1 , a , b , h , 1 ) ; } filter_mb_edgeh ( & img_y[4 * 1 * linesize] , linesize , bS3 , qp , a , b , h , 0 ) ; filter_mb_edgeh ( & img_y[4 * 2 * linesize] , linesize , bS3 , qp , a , b , h , 0 ) ; filter_mb_edgeh ( & img_y[4 * 3 * linesize] , linesize , bS3 , qp , a , b , h , 0 ) ; } if ( chroma ) { if ( chroma444 ) { if ( left_type ) { filter_mb_edgev ( & img_cb[4 * 0 < < pixel_shift] , linesize , bS4 , qpc0 , a , b , h , 1 ) ; filter_mb_edgev ( & img_cr[4 * 0 < < pixel_shift] , linesize , bS4 , qpc0 , a , b , h , 1 ) ; } if ( IS_8x8DCT ( mb_type ) ) { filter_mb_edgev ( & img_cb[4 * 2 < < pixel_shift] , linesize , bS3 , qpc , a , b , h , 0 ) ; filter_mb_edgev ( & img_cr[4 * 2 < < pixel_shift] , linesize , bS3 , qpc , a , b , h , 0 ) ; if ( top_type ) { filter_mb_edgeh ( & img_cb[4 * 0 * linesize] , linesize , bSH , qpc1 , a , b , h , 1 ) ; filter_mb_edgeh ( & img_cr[4 * 0 * linesize] , linesize , bSH , qpc1 , a , b , h , 1 ) ; } filter_mb_edgeh ( & img_cb[4 * 2 * linesize] , linesize , bS3 , qpc , a , b , h , 0 ) ; filter_mb_edgeh ( & img_cr[4 * 2 * linesize] , linesize , bS3 , qpc , a , b , h , 0 ) ; } else { filter_mb_edgev ( & img_cb[4 * 1 < < pixel_shift] , linesize , bS3 , qpc , a , b , h , 0 ) ; filter_mb_edgev ( & img_cr[4 * 1 < < pixel_shift] , linesize , bS3 , qpc , a , b , h , 0 ) ; filter_mb_edgev ( & img_cb[4 * 2 < < pixel_shift] , linesize , bS3 , qpc , a , b , h , 0 ) ; filter_mb_edgev ( & img_cr[4 * 2 < < pixel_shift] , linesize , bS3 , qpc , a , b , h , 0 ) ; filter_mb_edgev ( & img_cb[4 * 3 < < pixel_shift] , linesize , bS3 , qpc , a , b , h , 0 ) ; filter_mb_edgev ( & img_cr[4 * 3 < < pixel_shift] , linesize , bS3 , qpc , a , b , h , 0 ) ; if ( top_type ) { filter_mb_edgeh ( & img_cb[4 * 0 * linesize] , linesize , bSH , qpc1 , a , b , h , 1 ) ; filter_mb_edgeh ( & img_cr[4 * 0 * linesize] , linesize , bSH , qpc1 , a , b , h , 1 ) ; } filter_mb_edgeh ( & img_cb[4 * 1 * linesize] , linesize , bS3 , qpc , a , b , h , 0 ) ; filter_mb_edgeh ( & img_cr[4 * 1 * linesize] , linesize , bS3 , qpc , a , b , h , 0 ) ; filter_mb_edgeh ( & img_cb[4 * 2 * linesize] , linesize , bS3 , qpc , a , b , h , 0 ) ; filter_mb_edgeh ( & img_cr[4 * 2 * linesize] , linesize , bS3 , qpc , a , b , h , 0 ) ; filter_mb_edgeh ( & img_cb[4 * 3 * linesize] , linesize , bS3 , qpc , a , b , h , 0 ) ; filter_mb_edgeh ( & img_cr[4 * 3 * linesize] , linesize , bS3 , qpc , a , b , h , 0 ) ;",0
"static int mpc7_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame_ptr , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; MPCContext * c = avctx - > priv_data ; GetBitContext gb ; uint8_t * bits ; int i , ch ; int mb = - 1 ; Band * bands = c - > bands ; int off , ret ; int bits_used , bits_avail ; memset ( bands , 0 , sizeof ( * bands ) * ( c - > maxbands + 1 ) ) ; if ( buf_size < = 4 ) { av_log ( avctx , AV_LOG_ERROR , Too small buffer passed ( %i bytes ) \n , buf_size ) ; return AVERROR ( EINVAL ) ; } / * get output buffer * / c - > frame . nb_samples = buf[1] ? c - > lastframelen : MPC_FRAME_SIZE ; if ( ( ret = avctx - > get_buffer ( avctx , & c - > frame ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed\n ) ; return ret ; } bits = av_malloc ( ( ( buf_size - 1 ) & 3 ) + FF_INPUT_BUFFER_PADDING_SIZE ) ; c - > dsp . bswap_buf ( ( uint32_t * ) bits , ( const uint32_t * ) ( buf + 4 ) , ( buf_size - 4 ) > > 2 ) ; init_get_bits ( & gb , bits , ( buf_size - 4 ) * 8 ) ; skip_bits_long ( & gb , buf[0] ) ; / * read subband indexes * / for ( i = 0 ; i < = c - > maxbands ; i + + ) { for ( ch = 0 ; ch < 2 ; ch + + ) { int t = 4 ; if ( i ) t = get_vlc2 ( & gb , hdr_vlc . table , MPC7_HDR_BITS , 1 ) - 5 ; if ( t == 4 ) bands[i] . res[ch] = get_bits ( & gb , 4 ) ; else bands[i] . res[ch] = bands[i - 1] . res[ch] + t ; } if ( bands[i] . res[0] || bands[i] . res[1] ) { mb = i ; if ( c - > MSS ) bands[i] . msf = get_bits1 ( & gb ) ; } } / * get scale indexes coding method * / for ( i = 0 ; i < = mb ; i + + ) for ( ch = 0 ; ch < 2 ; ch + + ) if ( bands[i] . res[ch] ) bands[i] . scfi[ch] = get_vlc2 ( & gb , scfi_vlc . table , MPC7_SCFI_BITS , 1 ) ; / * get scale indexes * / for ( i = 0 ; i < = mb ; i + + ) { for ( ch = 0 ; ch < 2 ; ch + + ) { if ( bands[i] . res[ch] ) { bands[i] . scf_idx[ch][2] = c - > oldDSCF[ch][i] ; bands[i] . scf_idx[ch][0] = get_scale_idx ( & gb , bands[i] . scf_idx[ch][2] ) ; switch ( bands[i] . scfi[ch] ) { case 0 : bands[i] . scf_idx[ch][1] = get_scale_idx ( & gb , bands[i] . scf_idx[ch][0] ) ; bands[i] . scf_idx[ch][2] = get_scale_idx ( & gb , bands[i] . scf_idx[ch][1] ) ; break ; case 1 : bands[i] . scf_idx[ch][1] = get_scale_idx ( & gb , bands[i] . scf_idx[ch][0] ) ; bands[i] . scf_idx[ch][2] = bands[i] . scf_idx[ch][1] ; break ; case 2 : bands[i] . scf_idx[ch][1] = bands[i] . scf_idx[ch][0] ; bands[i] . scf_idx[ch][2] = get_scale_idx ( & gb , bands[i] . scf_idx[ch][1] ) ; break ; case 3 : bands[i] . scf_idx[ch][2] = bands[i] . scf_idx[ch][1] = bands[i] . scf_idx[ch][0] ; break ; } c - > oldDSCF[ch][i] = bands[i] . scf_idx[ch][2] ; } } } / * get quantizers * / memset ( c - > Q , 0 , sizeof ( c - > Q ) ) ; off = 0 ; for ( i = 0 ; i < BANDS ; i + + , off + = SAMPLES_PER_BAND ) for ( ch = 0 ; ch < 2 ; ch + + ) idx_to_quant ( c , & gb , bands[i] . res[ch] , c - > Q[ch] + off ) ; ff_mpc_dequantize_and_synth ( c , mb , c - > frame . data[0] , 2 ) ; av_free ( bits ) ; bits_used = get_bits_count ( & gb ) ; bits_avail = ( buf_size - 4 ) * 8 ; if ( ! buf[1] & & ( ( bits_avail < bits_used ) || ( bits_used + 32 < = bits_avail ) ) ) { av_log ( NULL , 0 , Error decoding frame : used %i of %i bits\n , bits_used , bits_avail ) ; return - 1 ; } if ( c - > frames_to_skip ) { c - > frames_to_skip - - ; * got_frame_ptr = 0 ; return buf_size ; } * got_frame_ptr = 1 ; * ( AVFrame * ) data = c - > frame ; return buf_size ; }",1
"uint8_t * ff_AMediaCodec_getOutputBuffer ( FFAMediaCodec * codec , size_t idx , size_t * out_size ) { uint8_t * ret = NULL ; JNIEnv * env = NULL ; jobject buffer = NULL ; JNI_GET_ENV_OR_RETURN ( env , codec , NULL ) ; if ( codec - > has_get_i_o_buffer ) { buffer = ( * env ) - > CallObjectMethod ( env , codec - > object , codec - > jfields . get_output_buffer_id , idx ) ; if ( ff_jni_exception_check ( env , 1 , codec ) < 0 ) { goto fail ; } } else { if ( ! codec - > output_buffers ) { codec - > output_buffers = ( * env ) - > CallObjectMethod ( env , codec - > object , codec - > jfields . get_output_buffers_id ) ; if ( ff_jni_exception_check ( env , 1 , codec ) < 0 ) { goto fail ; } codec - > output_buffers = ( * env ) - > NewGlobalRef ( env , codec - > output_buffers ) ; if ( ff_jni_exception_check ( env , 1 , codec ) < 0 ) { goto fail ; } } buffer = ( * env ) - > GetObjectArrayElement ( env , codec - > output_buffers , idx ) ; if ( ff_jni_exception_check ( env , 1 , codec ) < 0 ) { goto fail ; } } ret = ( * env ) - > GetDirectBufferAddress ( env , buffer ) ; * out_size = ( * env ) - > GetDirectBufferCapacity ( env , buffer ) ; fail : if ( buffer ) { ( * env ) - > DeleteLocalRef ( env , buffer ) ; } return ret ; }",1
"static int try_decode_video_frame ( AVCodecContext * codec_ctx , AVPacket * pkt , int decode ) { int ret = 0 ; int got_frame = 0 ; AVFrame * frame = NULL ; int skip_frame = codec_ctx - > skip_frame ; if ( ! avcodec_is_open ( codec_ctx ) ) { const AVCodec * codec = avcodec_find_decoder ( codec_ctx - > codec_id ) ; ret = avcodec_open2 ( codec_ctx , codec , NULL ) ; if ( ret < 0 ) { av_log ( codec_ctx , AV_LOG_ERROR , Failed to open codec\n ) ; goto end ; } } frame = av_frame_alloc ( ) ; if ( ! frame ) { av_log ( NULL , AV_LOG_ERROR , Failed to allocate frame\n ) ; goto end ; } if ( ! decode & & codec_ctx - > codec - > caps_internal & FF_CODEC_CAP_SKIP_FRAME_FILL_PARAM ) { codec_ctx - > skip_frame = AVDISCARD_ALL ; } do { ret = avcodec_decode_video2 ( codec_ctx , frame , & got_frame , pkt ) ; av_assert0 ( decode || ( ! decode & & ! got_frame ) ) ; if ( ret < 0 ) break ; pkt - > data + = ret ; pkt - > size - = ret ; if ( got_frame ) { break ; } } while ( pkt - > size > 0 ) ; end : codec_ctx - > skip_frame = skip_frame ; av_frame_free ( & frame ) ; return ret ; }",1
"static int tiff_decode_tag ( TiffContext * s , AVFrame * frame ) { unsigned tag , type , count , off , value = 0 , value2 = 0 ; int i , start ; int pos ; int ret ; double * dp ; ret = ff_tread_tag ( & s - > gb , s - > le , & tag , & type , & count , & start ) ; if ( ret < 0 ) { goto end ; } off = bytestream2_tell ( & s - > gb ) ; if ( count == 1 ) { switch ( type ) { case TIFF_BYTE : case TIFF_SHORT : case TIFF_LONG : value = ff_tget ( & s - > gb , type , s - > le ) ; break ; case TIFF_RATIONAL : value = ff_tget ( & s - > gb , TIFF_LONG , s - > le ) ; value2 = ff_tget ( & s - > gb , TIFF_LONG , s - > le ) ; break ; case TIFF_STRING : if ( count < = 4 ) { break ; } default : value = UINT_MAX ; } } switch ( tag ) { case TIFF_WIDTH : s - > width = value ; break ; case TIFF_HEIGHT : s - > height = value ; break ; case TIFF_BPP : s - > bppcount = count ; if ( count > 4 ) { av_log ( s - > avctx , AV_LOG_ERROR , This format is not supported ( bpp=%d , %d components ) \n , s - > bpp , count ) ; return AVERROR_INVALIDDATA ; } if ( count == 1 ) s - > bpp = value ; else { switch ( type ) { case TIFF_BYTE : case TIFF_SHORT : case TIFF_LONG : s - > bpp = 0 ; if ( bytestream2_get_bytes_left ( & s - > gb ) < type_sizes[type] * count ) return AVERROR_INVALIDDATA ; for ( i = 0 ; i < count ; i + + ) s - > bpp + = ff_tget ( & s - > gb , type , s - > le ) ; break ; default : s - > bpp = - 1 ; } } break ; case TIFF_SAMPLES_PER_PIXEL : if ( count ! = 1 ) { av_log ( s - > avctx , AV_LOG_ERROR , Samples per pixel requires a single value , many provided\n ) ; return AVERROR_INVALIDDATA ; } if ( value > 4U ) { av_log ( s - > avctx , AV_LOG_ERROR , Samples per pixel %d is too large\n , value ) ; return AVERROR_INVALIDDATA ; } if ( s - > bppcount == 1 ) s - > bpp * = value ; s - > bppcount = value ; break ; case TIFF_COMPR : s - > compr = value ; s - > predictor = 0 ; switch ( s - > compr ) { case TIFF_RAW : case TIFF_PACKBITS : case TIFF_LZW : case TIFF_CCITT_RLE : break ; case TIFF_G3 : case TIFF_G4 : s - > fax_opts = 0 ; break ; case TIFF_DEFLATE : case TIFF_ADOBE_DEFLATE : if CONFIG_ZLIB break ; else av_log ( s - > avctx , AV_LOG_ERROR , Deflate : ZLib not compiled in\n ) ; return AVERROR ( ENOSYS ) ; endif case TIFF_JPEG : case TIFF_NEWJPEG : avpriv_report_missing_feature ( s - > avctx , JPEG compression ) ; return AVERROR_PATCHWELCOME ; case TIFF_LZMA : if CONFIG_LZMA break ; else av_log ( s - > avctx , AV_LOG_ERROR , LZMA not compiled in\n ) ; return AVERROR ( ENOSYS ) ; endif default : av_log ( s - > avctx , AV_LOG_ERROR , Unknown compression method %i\n , s - > compr ) ; return AVERROR_INVALIDDATA ; } break ; case TIFF_ROWSPERSTRIP : if ( ! value || ( type == TIFF_LONG & & value == UINT_MAX ) ) value = s - > height ; s - > rps = FFMIN ( value , s - > height ) ; break ; case TIFF_STRIP_OFFS : if ( count == 1 ) { s - > strippos = 0 ; s - > stripoff = value ; } else s - > strippos = off ; s - > strips = count ; if ( s - > strips == 1 ) s - > rps = s - > height ; s - > sot = type ; break ; case TIFF_STRIP_SIZE : if ( count == 1 ) { s - > stripsizesoff = 0 ; s - > stripsize = value ; s - > strips = 1 ; } else { s - > stripsizesoff = off ; } s - > strips = count ; s - > sstype = type ; break ; case TIFF_XRES : case TIFF_YRES : set_sar ( s , tag , value , value2 ) ; break ; case TIFF_TILE_BYTE_COUNTS : case TIFF_TILE_LENGTH : case TIFF_TILE_OFFSETS : case TIFF_TILE_WIDTH : av_log ( s - > avctx , AV_LOG_ERROR , Tiled images are not supported\n ) ; return AVERROR_PATCHWELCOME ; break ; case TIFF_PREDICTOR : s - > predictor = value ; break ; case TIFF_PHOTOMETRIC : switch ( value ) { case TIFF_PHOTOMETRIC_WHITE_IS_ZERO : case TIFF_PHOTOMETRIC_BLACK_IS_ZERO : case TIFF_PHOTOMETRIC_RGB : case TIFF_PHOTOMETRIC_PALETTE : case TIFF_PHOTOMETRIC_YCBCR : s - > photometric = value ; break ; case TIFF_PHOTOMETRIC_ALPHA_MASK : case TIFF_PHOTOMETRIC_SEPARATED : case TIFF_PHOTOMETRIC_CIE_LAB : case TIFF_PHOTOMETRIC_ICC_LAB : case TIFF_PHOTOMETRIC_ITU_LAB : case TIFF_PHOTOMETRIC_CFA : case TIFF_PHOTOMETRIC_LOG_L : case TIFF_PHOTOMETRIC_LOG_LUV : case TIFF_PHOTOMETRIC_LINEAR_RAW : avpriv_report_missing_feature ( s - > avctx , PhotometricInterpretation 0x%04X , value ) ; return AVERROR_PATCHWELCOME ; default : av_log ( s - > avctx , AV_LOG_ERROR , PhotometricInterpretation %u is unknown\n , value ) ; return AVERROR_INVALIDDATA ; } break ; case TIFF_FILL_ORDER : if ( value < 1 || value > 2 ) { av_log ( s - > avctx , AV_LOG_ERROR , Unknown FillOrder value %d , trying default one\n , value ) ; value = 1 ; } s - > fill_order = value - 1 ; break ; case TIFF_PAL : { GetByteContext pal_gb[3] ; off = type_sizes[type] ; if ( count / 3 > 256 || bytestream2_get_bytes_left ( & s - > gb ) < count / 3 * off * 3 ) return AVERROR_INVALIDDATA ; pal_gb[0] = pal_gb[1] = pal_gb[2] = s - > gb ; bytestream2_skip ( & pal_gb[1] , count / 3 * off ) ; bytestream2_skip ( & pal_gb[2] , count / 3 * off * 2 ) ; off = ( type_sizes[type] - 1 ) < < 3 ; for ( i = 0 ; i < count / 3 ; i + + ) { uint32_t p = 0xFF000000 ; p |= ( ff_tget ( & pal_gb[0] , type , s - > le ) > > off ) < < 16 ; p |= ( ff_tget ( & pal_gb[1] , type , s - > le ) > > off ) < < 8 ; p |= ff_tget ( & pal_gb[2] , type , s - > le ) > >",0
"static int reap_filters ( void ) { AVFilterBufferRef * picref ; AVFrame * filtered_frame = NULL ; int i ; int64_t frame_pts ; / * Reap all buffers present in the buffer sinks * / for ( i = 0 ; i < nb_output_streams ; i + + ) { OutputStream * ost = output_streams[i] ; OutputFile * of = output_files[ost - > file_index] ; int ret = 0 ; if ( ! ost - > filter ) continue ; if ( ! ost - > filtered_frame & & ! ( ost - > filtered_frame = avcodec_alloc_frame ( ) ) ) { return AVERROR ( ENOMEM ) ; } else avcodec_get_frame_defaults ( ost - > filtered_frame ) ; filtered_frame = ost - > filtered_frame ; while ( 1 ) { ret = av_buffersink_get_buffer_ref ( ost - > filter - > filter , & picref , AV_BUFFERSINK_FLAG_NO_REQUEST ) ; if ( ret < 0 ) { if ( ret ! = AVERROR ( EAGAIN ) & & ret ! = AVERROR_EOF ) { char buf[256] ; av_strerror ( ret , buf , sizeof ( buf ) ) ; av_log ( NULL , AV_LOG_WARNING , Error in av_buffersink_get_buffer_ref ( ) : %s\n , buf ) ; frame_pts = AV_NOPTS_VALUE ; if ( picref - > pts ! = AV_NOPTS_VALUE ) { filtered_frame - > pts = frame_pts = av_rescale_q ( picref - > pts , ost - > filter - > filter - > inputs[0] - > time_base , ost - > st - > codec - > time_base ) - av_rescale_q ( of - > start_time , AV_TIME_BASE_Q , ost - > st - > codec - > time_base ) ; if ( of - > start_time & & filtered_frame - > pts < 0 ) { avfilter_unref_buffer ( picref ) ; continue ; //if ( ost - > source_index > = 0 ) // * filtered_frame= * input_streams[ost - > source_index] - > decoded_frame ; //for me_threshold switch ( ost - > filter - > filter - > inputs[0] - > type ) { case AVMEDIA_TYPE_VIDEO : avfilter_copy_buf_props ( filtered_frame , picref ) ; filtered_frame - > pts = frame_pts ; if ( ! ost - > frame_aspect_ratio ) ost - > st - > codec - > sample_aspect_ratio = picref - > video - > sample_aspect_ratio ; do_video_out ( of - > ctx , ost , filtered_frame ) ; case AVMEDIA_TYPE_AUDIO : avfilter_copy_buf_props ( filtered_frame , picref ) ; filtered_frame - > pts = frame_pts ; do_audio_out ( of - > ctx , ost , filtered_frame ) ; default : // TODO support subtitle filters av_assert0 ( 0 ) ; avfilter_unref_buffer ( picref ) ; return 0 ;",1
"static av_always_inline void hl_decode_mb_predict_luma ( H264Context * h , int mb_type , int is_h264 , int simple , int transform_bypass , int pixel_shift , int * block_offset , int linesize , uint8_t * dest_y , int p ) { MpegEncContext * const s = & h - > s ; void ( * idct_add ) ( uint8_t * dst , DCTELEM * block , int stride ) ; void ( * idct_dc_add ) ( uint8_t * dst , DCTELEM * block , int stride ) ; int i ; int qscale = p == 0 ? s - > qscale : h - > chroma_qp[p - 1] ; block_offset + = 16 * p ; if ( IS_INTRA4x4 ( mb_type ) ) { if ( simple || ! s - > encoding ) { if ( IS_8x8DCT ( mb_type ) ) { if ( transform_bypass ) { idct_dc_add = idct_add = s - > dsp . add_pixels8 ; } else { idct_dc_add = h - > h264dsp . h264_idct8_dc_add ; idct_add = h - > h264dsp . h264_idct8_add ; } for ( i=0 ; i < 16 ; i + =4 ) { uint8_t * const ptr= dest_y + block_offset[i] ; const int dir= h - > intra4x4_pred_mode_cache[ scan8[i] ] ; if ( transform_bypass & & h - > sps . profile_idc==244 & & dir < =1 ) { h - > hpc . pred8x8l_add[dir] ( ptr , h - > mb + ( i * 16 + p * 256 < < pixel_shift ) , linesize ) ; } else { const int nnz = h - > non_zero_count_cache[ scan8[i + p * 16] ] ; h - > hpc . pred8x8l[ dir ] ( ptr , ( h - > topleft_samples_available < < i ) & 0x8000 , ( h - > topright_samples_available < < i ) & 0x4000 , linesize ) ; if ( nnz ) { if ( nnz == 1 & & dctcoef_get ( h - > mb , pixel_shift , i * 16 + p * 256 ) ) idct_dc_add ( ptr , h - > mb + ( i * 16 + p * 256 < < pixel_shift ) , linesize ) ; else idct_add ( ptr , h - > mb + ( i * 16 + p * 256 < < pixel_shift ) , linesize ) ; } } } } else { if ( transform_bypass ) { idct_dc_add = idct_add = s - > dsp . add_pixels4 ; } else { idct_dc_add = h - > h264dsp . h264_idct_dc_add ; idct_add = h - > h264dsp . h264_idct_add ; } for ( i=0 ; i < 16 ; i + + ) { uint8_t * const ptr= dest_y + block_offset[i] ; const int dir= h - > intra4x4_pred_mode_cache[ scan8[i] ] ; if ( transform_bypass & & h - > sps . profile_idc==244 & & dir < =1 ) { h - > hpc . pred4x4_add[dir] ( ptr , h - > mb + ( i * 16 + p * 256 < < pixel_shift ) , linesize ) ; } else { uint8_t * topright ; int nnz , tr ; uint64_t tr_high ; if ( dir == DIAG_DOWN_LEFT_PRED || dir == VERT_LEFT_PRED ) { const int topright_avail= ( h - > topright_samples_available < < i ) & 0x8000 ; assert ( s - > mb_y || linesize < = block_offset[i] ) ; if ( ! topright_avail ) { if ( pixel_shift ) { tr_high= ( ( uint16_t * ) ptr ) [3 - linesize/2] * 0x0001000100010001ULL ; topright= ( uint8_t * ) & tr_high ; } else { tr= ptr[3 - linesize] * 0x01010101 ; topright= ( uint8_t * ) & tr ; } } else topright= ptr + ( 4 < < pixel_shift ) - linesize ; } else topright= NULL ; h - > hpc . pred4x4[ dir ] ( ptr , topright , linesize ) ; nnz = h - > non_zero_count_cache[ scan8[i + p * 16] ] ; if ( nnz ) { if ( is_h264 ) { if ( nnz == 1 & & dctcoef_get ( h - > mb , pixel_shift , i * 16 + p * 256 ) ) idct_dc_add ( ptr , h - > mb + ( i * 16 + p * 256 < < pixel_shift ) , linesize ) ; else idct_add ( ptr , h - > mb + ( i * 16 + p * 256 < < pixel_shift ) , linesize ) ; } else ff_svq3_add_idct_c ( ptr , h - > mb + i * 16 + p * 256 , linesize , qscale , 0 ) ; } } } } } } else { h - > hpc . pred16x16[ h - > intra16x16_pred_mode ] ( dest_y , linesize ) ; if ( is_h264 ) { if ( h - > non_zero_count_cache[ scan8[LUMA_DC_BLOCK_INDEX + p] ] ) { if ( ! transform_bypass ) h - > h264dsp . h264_luma_dc_dequant_idct ( h - > mb + ( p * 256 < < pixel_shift ) , h - > mb_luma_dc[p] , h - > dequant4_coeff[p][qscale][0] ) ; else { static const uint8_t dc_mapping[16] = { 0 * 16 , 1 * 16 , 4 * 16 , 5 * 16 , 2 * 16 , 3 * 16 , 6 * 16 , 7 * 16 , 8 * 16 , 9 * 16 , 12 * 16 , 13 * 16 , 10 * 16 , 11 * 16 , 14 * 16 , 15 * 16 } ; for ( i = 0 ; i < 16 ; i + + ) dctcoef_set ( h - > mb + p * 256 , pixel_shift , dc_mapping[i] , dctcoef_get ( h - > mb_luma_dc[p] , pixel_shift , i ) ) ; } } } else ff_svq3_luma_dc_dequant_idct_c ( h - > mb + p * 256 , h - > mb_luma_dc[p] , qscale ) ; } }",1
"static int adx_read_packet ( AVFormatContext * s , AVPacket * pkt ) { ADXDemuxerContext * c = s - > priv_data ; AVCodecContext * avctx = s - > streams[0] - > codec ; int ret , size ; size = BLOCK_SIZE * avctx - > channels ; pkt - > pos = avio_tell ( s - > pb ) ; pkt - > stream_index = 0 ; ret = av_get_packet ( s - > pb , pkt , size ) ; if ( ret ! = size ) { av_free_packet ( pkt ) ; return ret < 0 ? ret : AVERROR ( EIO ) ; if ( AV_RB16 ( pkt - > data ) & 0x8000 ) { av_free_packet ( pkt ) ; return AVERROR_EOF ; pkt - > size = size ; pkt - > duration = 1 ; pkt - > pts = ( pkt - > pos - c - > header_size ) / size ; return 0 ;",1
"yuv2rgb_1_c_template ( SwsContext * c , const uint16_t * buf0 , const uint16_t * ubuf0 , const uint16_t * ubuf1 , const uint16_t * vbuf0 , const uint16_t * vbuf1 , const uint16_t * abuf0 , uint8_t * dest , int dstW , int uvalpha , enum PixelFormat dstFormat , int flags , int y , enum PixelFormat target , int hasAlpha ) { int i ; if ( uvalpha < 2048 ) { for ( i = 0 ; i < ( dstW > > 1 ) ; i + + ) { int Y1 = buf0[i * 2] > > 7 ; int Y2 = buf0[i * 2 + 1] > > 7 ; int U = ubuf1[i] > > 7 ; int V = vbuf1[i] > > 7 ; int A1 , A2 ; const void * r = c - > table_rV[V] , * g = ( c - > table_gU[U] + c - > table_gV[V] ) , * b = c - > table_bU[U] ; if ( hasAlpha ) { A1 = abuf0[i * 2 ] > > 7 ; A2 = abuf0[i * 2 + 1] > > 7 ; } yuv2rgb_write ( dest , i , Y1 , Y2 , U , V , hasAlpha ? A1 : 0 , hasAlpha ? A2 : 0 , r , g , b , y , target , hasAlpha ) ; } } else { for ( i = 0 ; i < ( dstW > > 1 ) ; i + + ) { int Y1 = buf0[i * 2] > > 7 ; int Y2 = buf0[i * 2 + 1] > > 7 ; int U = ( ubuf0[i] + ubuf1[i] ) > > 8 ; int V = ( vbuf0[i] + vbuf1[i] ) > > 8 ; int A1 , A2 ; const void * r = c - > table_rV[V] , * g = ( c - > table_gU[U] + c - > table_gV[V] ) , * b = c - > table_bU[U] ; if ( hasAlpha ) { A1 = abuf0[i * 2 ] > > 7 ; A2 = abuf0[i * 2 + 1] > > 7 ; } yuv2rgb_write ( dest , i , Y1 , Y2 , U , V , hasAlpha ? A1 : 0 , hasAlpha ? A2 : 0 , r , g , b , y , target , hasAlpha ) ; } } }",0
"static int put_flac_codecpriv ( AVFormatContext * s , ByteIOContext * pb , AVCodecContext * codec ) { // if the extradata_size is greater than FLAC_STREAMINFO_SIZE , // assume that it ' s in Matroska format already if ( codec - > extradata_size < FLAC_STREAMINFO_SIZE ) { av_log ( s , AV_LOG_ERROR , Invalid FLAC extradata\n ) ; return - 1 ; } else if ( codec - > extradata_size == FLAC_STREAMINFO_SIZE ) { // only the streaminfo packet put_buffer ( pb , fLaC , 4 ) ; put_byte ( pb , 0x80 ) ; put_be24 ( pb , FLAC_STREAMINFO_SIZE ) ; } else if ( memcmp ( fLaC , codec - > extradata , 4 ) ) { av_log ( s , AV_LOG_ERROR , Invalid FLAC extradata\n ) ; return - 1 ; } put_buffer ( pb , codec - > extradata , codec - > extradata_size ) ; return 0 ; }",0
"int avcodec_open ( AVCodecContext * avctx , AVCodec * codec ) { int ret ; if ( avctx - > codec ) return - 1 ; avctx - > codec = codec ; avctx - > codec_id = codec - > id ; avctx - > frame_number = 0 ; if ( codec - > priv_data_size > 0 ) { avctx - > priv_data = av_mallocz ( codec - > priv_data_size ) ; if ( ! avctx - > priv_data ) return - ENOMEM ; } else { avctx - > priv_data = NULL ; } if ( avctx - > coded_width & & avctx - > coded_height ) avcodec_set_dimensions ( avctx , avctx - > coded_width , avctx - > coded_height ) ; else if ( avctx - > width & & avctx - > height ) avcodec_set_dimensions ( avctx , avctx - > width , avctx - > height ) ; if ( ( avctx - > coded_width||avctx - > coded_height ) & & avcodec_check_dimensions ( avctx , avctx - > coded_width , avctx - > coded_height ) ) { av_freep ( & avctx - > priv_data ) ; return - 1 ; } ret = avctx - > codec - > init ( avctx ) ; if ( ret < 0 ) { av_freep ( & avctx - > priv_data ) ; return ret ; } return 0 ; }",0
"static inline void RENAME ( yv12touyvy ) ( const uint8_t * ysrc , const uint8_t * usrc , const uint8_t * vsrc , uint8_t * dst , long width , long height , long lumStride , long chromStride , long dstStride ) { //FIXME interpolate chroma RENAME ( yuvPlanartouyvy ) ( ysrc , usrc , vsrc , dst , width , height , lumStride , chromStride , dstStride , 2 ) ; }",0
"static int decode_block_coeffs_internal ( VP56RangeCoder * r , int16_t block[16] , uint8_t probs[16][3][NUM_DCT_TOKENS - 1] , int i , uint8_t * token_prob , int16_t qmul[2] ) { VP56RangeCoder c = * r ; goto skip_eob ; do { int coeff ; if ( ! vp56_rac_get_prob_branchy ( & c , token_prob[0] ) ) // DCT_EOB break ; skip_eob : if ( ! vp56_rac_get_prob_branchy ( & c , token_prob[1] ) ) { // DCT_0 if ( + + i == 16 ) break ; // invalid input ; blocks should end with EOB token_prob = probs[i][0] ; goto skip_eob ; } if ( ! vp56_rac_get_prob_branchy ( & c , token_prob[2] ) ) { // DCT_1 coeff = 1 ; token_prob = probs[i + 1][1] ; } else { if ( ! vp56_rac_get_prob_branchy ( & c , token_prob[3] ) ) { // DCT 2 , 3 , 4 coeff = vp56_rac_get_prob_branchy ( & c , token_prob[4] ) ; if ( coeff ) coeff + = vp56_rac_get_prob ( & c , token_prob[5] ) ; coeff + = 2 ; } else { // DCT_CAT * if ( ! vp56_rac_get_prob_branchy ( & c , token_prob[6] ) ) { if ( ! vp56_rac_get_prob_branchy ( & c , token_prob[7] ) ) { // DCT_CAT1 coeff = 5 + vp56_rac_get_prob ( & c , vp8_dct_cat1_prob[0] ) ; } else { // DCT_CAT2 coeff = 7 ; coeff + = vp56_rac_get_prob ( & c , vp8_dct_cat2_prob[0] ) < < 1 ; coeff + = vp56_rac_get_prob ( & c , vp8_dct_cat2_prob[1] ) ; } } else { // DCT_CAT3 and up int a = vp56_rac_get_prob ( & c , token_prob[8] ) ; int b = vp56_rac_get_prob ( & c , token_prob[9 + a] ) ; int cat = ( a < < 1 ) + b ; coeff = 3 + ( 8 < < cat ) ; coeff + = vp8_rac_get_coeff ( & c , ff_vp8_dct_cat_prob[cat] ) ; } } token_prob = probs[i + 1][2] ; } block[zigzag_scan[i]] = ( vp8_rac_get ( & c ) ? - coeff : coeff ) * qmul[ ! ! i] ; } while ( + + i < 16 ) ; * r = c ; return i ; }",1
"static void imdct12 ( INTFLOAT * out , INTFLOAT * in ) { INTFLOAT in0 , in1 , in2 , in3 , in4 , in5 , t1 , t2 ; in0 = in[0 * 3] ; in1 = in[1 * 3] + in[0 * 3] ; in2 = in[2 * 3] + in[1 * 3] ; in3 = in[3 * 3] + in[2 * 3] ; in4 = in[4 * 3] + in[3 * 3] ; in5 = in[5 * 3] + in[4 * 3] ; in5 + = in3 ; in3 + = in1 ; in2 = MULH3 ( in2 , C3 , 2 ) ; in3 = MULH3 ( in3 , C3 , 4 ) ; t1 = in0 - in4 ; t2 = MULH3 ( in1 - in5 , C4 , 2 ) ; out[ 7] = out[10] = t1 + t2 ; out[ 1] = out[ 4] = t1 - t2 ; in0 + = SHR ( in4 , 1 ) ; in4 = in0 + in2 ; in5 + = 2 * in1 ; in1 = MULH3 ( in5 + in3 , C5 , 1 ) ; out[ 8] = out[ 9] = in4 + in1 ; out[ 2] = out[ 3] = in4 - in1 ; in0 - = in2 ; in5 = MULH3 ( in5 - in3 , C6 , 2 ) ; out[ 0] = out[ 5] = in0 - in5 ; out[ 6] = out[11] = in0 + in5 ; }",1
"static int hwupload_query_formats ( AVFilterContext * avctx ) { HWUploadContext * ctx = avctx - > priv ; AVHWFramesConstraints * constraints = NULL ; const enum AVPixelFormat * input_pix_fmts , * output_pix_fmts ; AVFilterFormats * input_formats = NULL ; int err , i ; if ( ! avctx - > hw_device_ctx ) { av_log ( ctx , AV_LOG_ERROR , A hardware device reference is required to upload frames to . \n ) ; return AVERROR ( EINVAL ) ; } ctx - > hwdevice_ref = av_buffer_ref ( avctx - > hw_device_ctx ) ; if ( ! ctx - > hwdevice_ref ) return AVERROR ( ENOMEM ) ; ctx - > hwdevice = ( AVHWDeviceContext * ) ctx - > hwdevice_ref - > data ; constraints = av_hwdevice_get_hwframe_constraints ( ctx - > hwdevice_ref , NULL ) ; if ( ! constraints ) { err = AVERROR ( EINVAL ) ; goto fail ; } input_pix_fmts = constraints - > valid_sw_formats ; output_pix_fmts = constraints - > valid_hw_formats ; input_formats = ff_make_format_list ( output_pix_fmts ) ; if ( ! input_formats ) { err = AVERROR ( ENOMEM ) ; goto fail ; } if ( input_pix_fmts ) { for ( i = 0 ; input_pix_fmts[i] ! = AV_PIX_FMT_NONE ; i + + ) { err = ff_add_format ( & input_formats , input_pix_fmts[i] ) ; if ( err < 0 ) { ff_formats_unref ( & input_formats ) ; goto fail ; } } } ff_formats_ref ( input_formats , & avctx - > inputs[0] - > out_formats ) ; ff_formats_ref ( ff_make_format_list ( output_pix_fmts ) , & avctx - > outputs[0] - > in_formats ) ; av_hwframe_constraints_free ( & constraints ) ; return 0 ; fail : av_buffer_unref ( & ctx - > hwdevice_ref ) ; av_hwframe_constraints_free ( & constraints ) ; return err ; }",1
"static void start_children ( FFStream * feed ) { if ( no_launch ) return ; for ( ; feed ; feed = feed - > next ) { if ( feed - > child_argv & & ! feed - > pid ) { feed - > pid_start = time ( 0 ) ; feed - > pid = fork ( ) ; if ( feed - > pid < 0 ) { fprintf ( stderr , Unable to create children\n ) ; exit ( 1 ) ; } if ( ! feed - > pid ) { / * In child * / char pathname[1024] ; char * slash ; int i ; for ( i = 3 ; i < 256 ; i + + ) { close ( i ) ; } if ( ! ffserver_debug ) { i = open ( /dev/null , O_RDWR ) ; if ( i ) dup2 ( i , 0 ) ; dup2 ( i , 1 ) ; dup2 ( i , 2 ) ; if ( i ) close ( i ) ; } pstrcpy ( pathname , sizeof ( pathname ) , my_program_name ) ; slash = strrchr ( pathname , ' / ' ) ; if ( ! slash ) { slash = pathname ; } else { slash + + ; } strcpy ( slash , ffmpeg ) ; / * This is needed to make relative pathnames work * / chdir ( my_program_dir ) ; execvp ( pathname , feed - > child_argv ) ; _exit ( 1 ) ; } } } }",1
"static int dxa_read_header ( AVFormatContext * s , AVFormatParameters * ap ) { AVIOContext * pb = s - > pb ; DXAContext * c = s - > priv_data ; AVStream * st , * ast ; uint32_t tag ; int32_t fps ; int w , h ; int num , den ; int flags ; tag = avio_rl32 ( pb ) ; if ( tag ! = MKTAG ( ' D ' , ' E ' , ' X ' , ' A ' ) ) return - 1 ; flags = avio_r8 ( pb ) ; c - > frames = avio_rb16 ( pb ) ; if ( ! c - > frames ) { av_log ( s , AV_LOG_ERROR , File contains no frames ? ? ? \n ) ; return - 1 ; } fps = avio_rb32 ( pb ) ; if ( fps > 0 ) { den = 1000 ; num = fps ; } else if ( fps < 0 ) { den = 100000 ; num = - fps ; } else { den = 10 ; num = 1 ; } w = avio_rb16 ( pb ) ; h = avio_rb16 ( pb ) ; c - > has_sound = 0 ; st = av_new_stream ( s , 0 ) ; if ( ! st ) return - 1 ; // Parse WAV data header if ( avio_rl32 ( pb ) == MKTAG ( ' W ' , ' A ' , ' V ' , ' E ' ) ) { uint32_t size , fsize ; c - > has_sound = 1 ; size = avio_rb32 ( pb ) ; c - > vidpos = avio_tell ( pb ) + size ; avio_skip ( pb , 16 ) ; fsize = avio_rl32 ( pb ) ; ast = av_new_stream ( s , 0 ) ; if ( ! ast ) return - 1 ; ff_get_wav_header ( pb , ast - > codec , fsize ) ; // find ' data ' chunk while ( avio_tell ( pb ) < c - > vidpos & & ! pb - > eof_reached ) { tag = avio_rl32 ( pb ) ; fsize = avio_rl32 ( pb ) ; if ( tag == MKTAG ( ' d ' , ' a ' , ' t ' , ' a ' ) ) break ; avio_skip ( pb , fsize ) ; } c - > bpc = ( fsize + c - > frames - 1 ) / c - > frames ; if ( ast - > codec - > block_align ) c - > bpc = ( ( c - > bpc + ast - > codec - > block_align - 1 ) / ast - > codec - > block_align ) * ast - > codec - > block_align ; c - > bytes_left = fsize ; c - > wavpos = avio_tell ( pb ) ; avio_seek ( pb , c - > vidpos , SEEK_SET ) ; } / * now we are ready : build format streams * / st - > codec - > codec_type = AVMEDIA_TYPE_VIDEO ; st - > codec - > codec_id = CODEC_ID_DXA ; st - > codec - > width = w ; st - > codec - > height = h ; av_reduce ( & den , & num , den , num , ( 1UL < < 31 ) - 1 ) ; av_set_pts_info ( st , 33 , num , den ) ; / * flags & 0x80 means that image is interlaced , * flags & 0x40 means that image has double height * either way set true height * / if ( flags & 0xC0 ) { st - > codec - > height > > = 1 ; } c - > readvid = ! c - > has_sound ; c - > vidpos = avio_tell ( pb ) ; s - > start_time = 0 ; s - > duration = ( int64_t ) c - > frames * AV_TIME_BASE * num / den ; av_log ( s , AV_LOG_DEBUG , %d frame ( s ) \n , c - > frames ) ; return 0 ; }",1
"static int get_cv_color_primaries ( AVCodecContext * avctx , CFStringRef * primaries ) { enum AVColorPrimaries pri = avctx - > color_primaries ; switch ( pri ) { case AVCOL_PRI_UNSPECIFIED : * primaries = NULL ; break ; case AVCOL_PRI_BT709 : * primaries = kCVImageBufferColorPrimaries_ITU_R_709_2 ; break ; case AVCOL_PRI_BT2020 : * primaries = kCVImageBufferColorPrimaries_ITU_R_2020 ; break ; default : av_log ( avctx , AV_LOG_ERROR , Color primaries %s is not supported . \n , av_color_primaries_name ( pri ) ) ; * primaries = NULL ; return - 1 ; } return 0 ; }",0
"int ff_h264_check_intra_pred_mode ( H264Context * h , int mode ) { MpegEncContext * const s = & h - > s ; static const int8_t top [7]= { LEFT_DC_PRED8x8 , 1 , - 1 , - 1 } ; static const int8_t left[7]= { TOP_DC_PRED8x8 , - 1 , 2 , - 1 , DC_128_PRED8x8 } ; if ( mode > 6U ) { av_log ( h - > s . avctx , AV_LOG_ERROR , out of range intra chroma pred mode at %d %d\n , s - > mb_x , s - > mb_y ) ; return - 1 ; } if ( ! ( h - > top_samples_available & 0x8000 ) ) { mode= top[ mode ] ; if ( mode < 0 ) { av_log ( h - > s . avctx , AV_LOG_ERROR , top block unavailable for requested intra mode at %d %d\n , s - > mb_x , s - > mb_y ) ; return - 1 ; } } if ( ( h - > left_samples_available & 0x8080 ) ! = 0x8080 ) { mode= left[ mode ] ; if ( h - > left_samples_available & 0x8080 ) { //mad cow disease mode , aka MBAFF + constrained_intra_pred mode= ALZHEIMER_DC_L0T_PRED8x8 + ( ! ( h - > left_samples_available & 0x8000 ) ) + 2 * ( mode == DC_128_PRED8x8 ) ; } if ( mode < 0 ) { av_log ( h - > s . avctx , AV_LOG_ERROR , left block unavailable for requested intra mode at %d %d\n , s - > mb_x , s - > mb_y ) ; return - 1 ; } } return mode ; }",0
"static void avc_wgt_4x4multiple_msa ( uint8_t * data , int32_t stride , int32_t height , int32_t log2_denom , int32_t src_weight , int32_t offset_in ) { uint8_t cnt ; uint32_t data0 , data1 , data2 , data3 ; v16u8 zero = { 0 } ; v16u8 src0 , src1 , src2 , src3 ; v8u16 temp0 , temp1 , temp2 , temp3 ; v8i16 wgt , denom , offset ; offset_in < < = ( log2_denom ) ; if ( log2_denom ) { offset_in + = ( 1 < < ( log2_denom - 1 ) ) ; } wgt = __msa_fill_h ( src_weight ) ; offset = __msa_fill_h ( offset_in ) ; denom = __msa_fill_h ( log2_denom ) ; for ( cnt = height / 4 ; cnt - - ; ) { LOAD_4WORDS_WITH_STRIDE ( data , stride , data0 , data1 , data2 , data3 ) ; src0 = ( v16u8 ) __msa_fill_w ( data0 ) ; src1 = ( v16u8 ) __msa_fill_w ( data1 ) ; src2 = ( v16u8 ) __msa_fill_w ( data2 ) ; src3 = ( v16u8 ) __msa_fill_w ( data3 ) ; ILVR_B_4VECS_UH ( src0 , src1 , src2 , src3 , zero , zero , zero , zero , temp0 , temp1 , temp2 , temp3 ) ; temp0 * = wgt ; temp1 * = wgt ; temp2 * = wgt ; temp3 * = wgt ; ADDS_S_H_4VECS_UH ( temp0 , offset , temp1 , offset , temp2 , offset , temp3 , offset , temp0 , temp1 , temp2 , temp3 ) ; MAXI_S_H_4VECS_UH ( temp0 , temp1 , temp2 , temp3 , 0 ) ; SRL_H_4VECS_UH ( temp0 , temp1 , temp2 , temp3 , temp0 , temp1 , temp2 , temp3 , denom ) ; SAT_U_H_4VECS_UH ( temp0 , temp1 , temp2 , temp3 , 7 ) ; PCKEV_B_STORE_4_BYTES_4 ( temp0 , temp1 , temp2 , temp3 , data , stride ) ; data + = ( 4 * stride ) ; } }",0
"static void FUNC ( flac_decorrelate_indep_c ) ( uint8_t * * out , int32_t * * in , int channels , int len , int shift ) { sample * samples = ( sample * ) OUT ( out ) ; int i , j ; for ( j = 0 ; j < len ; j + + ) for ( i = 0 ; i < channels ; i + + ) S ( samples , i , j ) = in[i][j] < < shift ; }",0
"void ff_MPV_frame_end ( MpegEncContext * s ) { int i ; / * redraw edges for the frame if decoding didn ' t complete * / // just to make sure that all data is rendered . if ( CONFIG_MPEG_XVMC_DECODER & & s - > avctx - > xvmc_acceleration ) { ff_xvmc_field_end ( s ) ; } else if ( ( s - > error_count || s - > encoding || ! ( s - > avctx - > codec - > capabilities & CODEC_CAP_DRAW_HORIZ_BAND ) ) & & ! s - > avctx - > hwaccel & & ! ( s - > avctx - > codec - > capabilities & CODEC_CAP_HWACCEL_VDPAU ) & & s - > unrestricted_mv & & s - > current_picture . f . reference & & ! s - > intra_only & & ! ( s - > flags & CODEC_FLAG_EMU_EDGE ) ) { int hshift = av_pix_fmt_descriptors[s - > avctx - > pix_fmt] . log2_chroma_w ; int vshift = av_pix_fmt_descriptors[s - > avctx - > pix_fmt] . log2_chroma_h ; s - > dsp . draw_edges ( s - > current_picture . f . data[0] , s - > current_picture . f . linesize[0] , s - > h_edge_pos , s - > v_edge_pos , EDGE_WIDTH , EDGE_WIDTH , EDGE_TOP | EDGE_BOTTOM ) ; s - > dsp . draw_edges ( s - > current_picture . f . data[1] , s - > current_picture . f . linesize[1] , s - > h_edge_pos > > hshift , s - > v_edge_pos > > vshift , EDGE_WIDTH > > hshift , EDGE_WIDTH > > vshift , EDGE_TOP | EDGE_BOTTOM ) ; s - > dsp . draw_edges ( s - > current_picture . f . data[2] , s - > current_picture . f . linesize[2] , s - > h_edge_pos > > hshift , s - > v_edge_pos > > vshift , EDGE_WIDTH > > hshift , EDGE_WIDTH > > vshift , EDGE_TOP | EDGE_BOTTOM ) ; } emms_c ( ) ; s - > last_pict_type = s - > pict_type ; s - > last_lambda_for [s - > pict_type] = s - > current_picture_ptr - > f . quality ; if ( s - > pict_type ! = AV_PICTURE_TYPE_B ) { s - > last_non_b_pict_type = s - > pict_type ; } if 0 / * copy back current_picture variables * / for ( i = 0 ; i < MAX_PICTURE_COUNT ; i + + ) { if ( s - > picture[i] . f . data[0] == s - > current_picture . f . data[0] ) { s - > picture[i] = s - > current_picture ; break ; } } assert ( i < MAX_PICTURE_COUNT ) ; endif if ( s - > encoding ) { / * release non - reference frames * / for ( i = 0 ; i < s - > picture_count ; i + + ) { if ( s - > picture[i] . f . data[0] & & ! s - > picture[i] . f . reference / * & & s - > picture[i] . type ! = FF_BUFFER_TYPE_SHARED * / ) { free_frame_buffer ( s , & s - > picture[i] ) ; } } } // clear copies , to avoid confusion if 0 memset ( & s - > last_picture , 0 , sizeof ( Picture ) ) ; memset ( & s - > next_picture , 0 , sizeof ( Picture ) ) ; memset ( & s - > current_picture , 0 , sizeof ( Picture ) ) ; endif s - > avctx - > coded_frame = & s - > current_picture_ptr - > f ; if ( s - > codec_id ! = AV_CODEC_ID_H264 & & s - > current_picture . f . reference ) { ff_thread_report_progress ( & s - > current_picture_ptr - > f , INT_MAX , 0 ) ; } }",1
"static int mov_open_dref ( MOVContext * c , AVIOContext * * pb , const char * src , MOVDref * ref , AVIOInterruptCB * int_cb ) { AVOpenCallback open_func = c - > fc - > open_cb ; if ( ! open_func ) open_func = ffio_open2_wrapper ; / * try relative path , we do not try the absolute because it can leak information about our system to an attacker * / if ( ref - > nlvl_to > 0 & & ref - > nlvl_from > 0 & & ref - > path[0] ! = ' / ' ) { char filename[1025] ; const char * src_path ; int i , l ; / * find a source dir * / src_path = strrchr ( src , ' / ' ) ; if ( src_path ) src_path + + ; else src_path = src ; / * find a next level down to target * / for ( i = 0 , l = strlen ( ref - > path ) - 1 ; l > = 0 ; l - - ) if ( ref - > path[l] == ' / ' ) { if ( i == ref - > nlvl_to - 1 ) break ; else i + + ; } / * compose filename if next level down to target was found * / if ( i == ref - > nlvl_to - 1 & & src_path - src < sizeof ( filename ) ) { memcpy ( filename , src , src_path - src ) ; filename[src_path - src] = 0 ; for ( i = 1 ; i < ref - > nlvl_from ; i + + ) av_strlcat ( filename , . . / , sizeof ( filename ) ) ; av_strlcat ( filename , ref - > path + l + 1 , sizeof ( filename ) ) ; if ( ! c - > use_absolute_path & & ! c - > fc - > open_cb ) if ( strstr ( ref - > path + l + 1 , . . ) || ref - > nlvl_from > 1 ) return AVERROR ( ENOENT ) ; if ( strlen ( filename ) + 1 == sizeof ( filename ) ) return AVERROR ( ENOENT ) ; if ( ! open_func ( c - > fc , pb , filename , AVIO_FLAG_READ , int_cb , NULL ) ) return 0 ; } } else if ( c - > use_absolute_path ) { av_log ( c - > fc , AV_LOG_WARNING , Using absolute path on user request , this is a possible security issue\n ) ; if ( ! open_func ( c - > fc , pb , ref - > path , AVIO_FLAG_READ , int_cb , NULL ) ) return 0 ; } else if ( c - > fc - > open_cb ) { if ( ! open_func ( c - > fc , pb , ref - > path , AVIO_FLAG_READ , int_cb , NULL ) ) return 0 ; } else { av_log ( c - > fc , AV_LOG_ERROR , Absolute path %s not tried for security reasons , set demuxer option use_absolute_path to allow absolute paths\n , ref - > path ) ; } return AVERROR ( ENOENT ) ; }",0
"static void filter_mb_edgev ( H264Context * h , uint8_t * pix , int stride , int16_t bS[4] , int qp ) { int i , d ; const int index_a = qp + h - > slice_alpha_c0_offset ; const int alpha = ( alpha_table + 52 ) [index_a] ; const int beta = ( beta_table + 52 ) [qp + h - > slice_beta_offset] ; if ( bS[0] < 4 ) { int8_t tc[4] ; for ( i=0 ; i < 4 ; i + + ) tc[i] = bS[i] ? ( tc0_table + 52 ) [index_a][bS[i] - 1] : - 1 ; h - > s . dsp . h264_h_loop_filter_luma ( pix , stride , alpha , beta , tc ) ; } else { h - > s . dsp . h264_h_loop_filter_luma_intra ( pix , stride , alpha , beta ) ; } }",0
"static void selfTest ( uint8_t * src[4] , int stride[4] , int w , int h ) { enum PixelFormat srcFormat , dstFormat ; int srcW , srcH , dstW , dstH ; int flags ; for ( srcFormat = 0 ; srcFormat < PIX_FMT_NB ; srcFormat + + ) { for ( dstFormat = 0 ; dstFormat < PIX_FMT_NB ; dstFormat + + ) { printf ( %s - > %s\n , sws_format_name ( srcFormat ) , sws_format_name ( dstFormat ) ) ; fflush ( stdout ) ; srcW= w ; srcH= h ; for ( dstW=w - w/3 ; dstW < = 4 * w/3 ; dstW + = w/3 ) { for ( dstH=h - h/3 ; dstH < = 4 * h/3 ; dstH + = h/3 ) { for ( flags=1 ; flags < 33 ; flags * =2 ) { int res ; res = doTest ( src , stride , w , h , srcFormat , dstFormat , srcW , srcH , dstW , dstH , flags ) ; if ( res < 0 ) { dstW = 4 * w / 3 ; dstH = 4 * h / 3 ; flags = 33 ; } } } } } } }",0
"void ff_eac3_apply_spectral_extension ( AC3DecodeContext * s ) { int bin , bnd , ch , i ; uint8_t wrapflag[SPX_MAX_BANDS]= { 1 , 0 , } , num_copy_sections , copy_sizes[SPX_MAX_BANDS] ; float rms_energy[SPX_MAX_BANDS] ; / * Set copy index mapping table . Set wrap flags to apply a notch filter at wrap points later on . * / bin = s - > spx_dst_start_freq ; num_copy_sections = 0 ; for ( bnd = 0 ; bnd < s - > num_spx_bands ; bnd + + ) { int copysize ; int bandsize = s - > spx_band_sizes[bnd] ; if ( bin + bandsize > s - > spx_src_start_freq ) { copy_sizes[num_copy_sections + + ] = bin - s - > spx_dst_start_freq ; bin = s - > spx_dst_start_freq ; wrapflag[bnd] = 1 ; } for ( i = 0 ; i < bandsize ; i + = copysize ) { if ( bin == s - > spx_src_start_freq ) { copy_sizes[num_copy_sections + + ] = bin - s - > spx_dst_start_freq ; bin = s - > spx_dst_start_freq ; } copysize = FFMIN ( bandsize - i , s - > spx_src_start_freq - bin ) ; bin + = copysize ; } } copy_sizes[num_copy_sections + + ] = bin - s - > spx_dst_start_freq ; for ( ch = 1 ; ch < = s - > fbw_channels ; ch + + ) { if ( ! s - > channel_uses_spx[ch] ) continue ; / * Copy coeffs from normal bands to extension bands * / bin = s - > spx_src_start_freq ; for ( i = 0 ; i < num_copy_sections ; i + + ) { memcpy ( & s - > transform_coeffs[ch][bin] , & s - > transform_coeffs[ch][s - > spx_dst_start_freq] , copy_sizes[i] * sizeof ( float ) ) ; bin + = copy_sizes[i] ; } / * Calculate RMS energy for each SPX band . * / bin = s - > spx_src_start_freq ; for ( bnd = 0 ; bnd < s - > num_spx_bands ; bnd + + ) { int bandsize = s - > spx_band_sizes[bnd] ; float accum = 0 . 0f ; for ( i = 0 ; i < bandsize ; i + + ) { float coeff = s - > transform_coeffs[ch][bin + + ] ; accum + = coeff * coeff ; } rms_energy[bnd] = sqrtf ( accum / bandsize ) ; } / * Apply a notch filter at transitions between normal and extension bands and at all wrap points . * / if ( s - > spx_atten_code[ch] > = 0 ) { const float * atten_tab = ff_eac3_spx_atten_tab[s - > spx_atten_code[ch]] ; bin = s - > spx_src_start_freq - 2 ; for ( bnd = 0 ; bnd < s - > num_spx_bands ; bnd + + ) { if ( wrapflag[bnd] ) { float * coeffs = & s - > transform_coeffs[ch][bin] ; coeffs[0] * = atten_tab[0] ; coeffs[1] * = atten_tab[1] ; coeffs[2] * = atten_tab[2] ; coeffs[3] * = atten_tab[1] ; coeffs[4] * = atten_tab[0] ; } bin + = s - > spx_band_sizes[bnd] ; } } / * Apply noise - blended coefficient scaling based on previously calculated RMS energy , blending factors , and SPX coordinates for each band . * / bin = s - > spx_src_start_freq ; for ( bnd = 0 ; bnd < s - > num_spx_bands ; bnd + + ) { float nscale = s - > spx_noise_blend[ch][bnd] * rms_energy[bnd] * ( 1 . 0f / INT32_MIN ) ; float sscale = s - > spx_signal_blend[ch][bnd] ; for ( i = 0 ; i < s - > spx_band_sizes[bnd] ; i + + ) { float noise = nscale * ( int32_t ) av_lfg_get ( & s - > dith_state ) ; s - > transform_coeffs[ch][bin] * = sscale ; s - > transform_coeffs[ch][bin + + ] + = noise ; } } } }",1
"static int add_crc_to_array ( uint32_t crc , int64_t pts ) { if ( size_of_array < = number_of_elements ) { if ( size_of_array == 0 ) size_of_array = 10 ; size_of_array * = 2 ; crc_array = av_realloc ( crc_array , size_of_array * sizeof ( uint32_t ) ) ; pts_array = av_realloc ( pts_array , size_of_array * sizeof ( int64_t ) ) ; if ( ( crc_array == NULL ) || ( pts_array == NULL ) ) { av_log ( NULL , AV_LOG_ERROR , Can ' t allocate array to store crcs\n ) ; return AVERROR ( ENOMEM ) ; } } crc_array[number_of_elements] = crc ; pts_array[number_of_elements] = pts ; number_of_elements + + ; return 0 ; }",1
"static av_cold void init_mv_penalty_and_fcode ( MpegEncContext * s ) { int f_code ; int mv ; for ( f_code=1 ; f_code < =MAX_FCODE ; f_code + + ) { for ( mv= - MAX_MV ; mv < =MAX_MV ; mv + + ) { int len ; if ( mv==0 ) len= ff_mvtab[0][1] ; else { int val , bit_size , code ; bit_size = f_code - 1 ; val=mv ; if ( val < 0 ) val = - val ; val - - ; code = ( val > > bit_size ) + 1 ; if ( code < 33 ) { len= ff_mvtab[code][1] + 1 + bit_size ; } else { len= ff_mvtab[32][1] + av_log2 ( code > > 5 ) + 2 + bit_size ; } } mv_penalty[f_code][mv + MAX_MV]= len ; } } for ( f_code=MAX_FCODE ; f_code > 0 ; f_code - - ) { for ( mv= - ( 16 < < f_code ) ; mv < ( 16 < < f_code ) ; mv + + ) { fcode_tab[mv + MAX_MV]= f_code ; } } for ( mv=0 ; mv < MAX_MV * 2 + 1 ; mv + + ) { umv_fcode_tab[mv]= 1 ; } }",0
"static av_always_inline int setup_classifs ( vorbis_context * vc , vorbis_residue * vr , uint8_t * do_not_decode , unsigned ch_used , int partition_count ) { int p , j , i ; unsigned c_p_c = vc - > codebooks[vr - > classbook] . dimensions ; unsigned inverse_class = ff_inverse[vr - > classifications] ; unsigned temp , temp2 ; for ( p = 0 , j = 0 ; j < ch_used ; + + j ) { if ( ! do_not_decode[j] ) { temp = get_vlc2 ( & vc - > gb , vc - > codebooks[vr - > classbook] . vlc . table , vc - > codebooks[vr - > classbook] . nb_bits , 3 ) ; av_dlog ( NULL , Classword : %u\n , temp ) ; assert ( vr - > classifications > 1 & & temp < = 65536 ) ; //needed for inverse[] for ( i = 0 ; i < c_p_c ; + + i ) { temp2 = ( ( ( uint64_t ) temp ) * inverse_class ) > > 32 ; if ( partition_count + c_p_c - 1 - i < vr - > ptns_to_read ) vr - > classifs[p + partition_count + c_p_c - 1 - i] = temp - temp2 * vr - > classifications ; temp = temp2 ; } } p + = vr - > ptns_to_read ; } return 0 ; }",0
"static uint32_t adler32 ( uint32_t adler , const uint8_t * buf , unsigned int len ) { unsigned long s1 = adler & 0xffff ; unsigned long s2 = ( adler > > 16 ) & 0xffff ; int k ; if ( buf == NULL ) return 1L ; while ( len > 0 ) { k = len < NMAX ? len : NMAX ; len - = k ; while ( k > = 16 ) { DO16 ( buf ) ; k - = 16 ; } if ( k ! = 0 ) do { DO1 ( buf ) ; } while ( - - k ) ; s1 %= BASE ; s2 %= BASE ; } return ( s2 < < 16 ) | s1 ; }",0
"static int mc_subpel ( DiracContext * s , DiracBlock * block , const uint8_t * src[5] , int x , int y , int ref , int plane ) { Plane * p = & s - > plane[plane] ; uint8_t * * ref_hpel = s - > ref_pics[ref] - > hpel[plane] ; int motion_x = block - > u . mv[ref][0] ; int motion_y = block - > u . mv[ref][1] ; int mx , my , i , epel , nplanes = 0 ; if ( plane ) { motion_x > > = s - > chroma_x_shift ; motion_y > > = s - > chroma_y_shift ; } mx = motion_x & ( - 1 < < s - > mv_precision ) ; my = motion_y & ( - 1 < < s - > mv_precision ) ; motion_x > > = s - > mv_precision ; motion_y > > = s - > mv_precision ; / * normalize subpel coordinates to epel * / / * TODO : template this function ? * / mx < < = 3 - s - > mv_precision ; my < < = 3 - s - > mv_precision ; x + = motion_x ; y + = motion_y ; epel = ( mx|my ) & 1 ; / * hpel position * / if ( ! ( ( mx|my ) & 3 ) ) { nplanes = 1 ; src[0] = ref_hpel[ ( my > > 1 ) + ( mx > > 2 ) ] + y * p - > stride + x ; } else { / * qpel or epel * / nplanes = 4 ; for ( i = 0 ; i < 4 ; i + + ) src[i] = ref_hpel[i] + y * p - > stride + x ; / * if we ' re interpolating in the right/bottom halves , adjust the planes as needed we increment x/y because the edge changes for half of the pixels * / if ( mx > 4 ) { src[0] + = 1 ; src[2] + = 1 ; x + + ; } if ( my > 4 ) { src[0] + = p - > stride ; src[1] + = p - > stride ; y + + ; } / * hpel planes are : [0] : F [1] : H [2] : V [3] : C * / if ( ! epel ) { / * check if we really only need 2 planes since either mx or my is a hpel position . ( epel weights of 0 handle this there ) * / if ( ! ( mx & 3 ) ) { / * mx == 0 : average [0] and [2] mx == 4 : average [1] and [3] * / src[ ! mx] = src[2 + ! ! mx] ; nplanes = 2 ; } else if ( ! ( my & 3 ) ) { src[0] = src[ ( my > > 1 ) ] ; src[1] = src[ ( my > > 1 ) + 1] ; nplanes = 2 ; } } else { / * adjust the ordering if needed so the weights work * / if ( mx > 4 ) { FFSWAP ( const uint8_t * , src[0] , src[1] ) ; FFSWAP ( const uint8_t * , src[2] , src[3] ) ; } if ( my > 4 ) { FFSWAP ( const uint8_t * , src[0] , src[2] ) ; FFSWAP ( const uint8_t * , src[1] , src[3] ) ; } src[4] = epel_weights[my & 3][mx & 3] ; } } / * fixme : v/h _edge_pos * / if ( ( unsigned ) x > p - > width + EDGE_WIDTH/2 - p - > xblen || ( unsigned ) y > p - > height + EDGE_WIDTH/2 - p - > yblen ) { for ( i = 0 ; i < nplanes ; i + + ) { ff_emulated_edge_mc ( s - > edge_emu_buffer[i] , src[i] , p - > stride , p - > xblen , p - > yblen , x , y , p - > width + EDGE_WIDTH/2 , p - > height + EDGE_WIDTH/2 ) ; src[i] = s - > edge_emu_buffer[i] ; } } return ( nplanes > > 1 ) + epel ; }",0
"void event_loop ( void ) { SDL_Event event ; double incr , pos , frac ; for ( ; ; ) { SDL_WaitEvent ( & event ) ; switch ( event . type ) { case SDL_KEYDOWN : switch ( event . key . keysym . sym ) { case SDLK_ESCAPE : case SDLK_q : do_exit ( ) ; break ; case SDLK_f : toggle_full_screen ( ) ; break ; case SDLK_p : case SDLK_SPACE : toggle_pause ( ) ; break ; case SDLK_s : //S : Step to next frame step_to_next_frame ( ) ; break ; case SDLK_a : if ( cur_stream ) stream_cycle_channel ( cur_stream , CODEC_TYPE_AUDIO ) ; break ; case SDLK_v : if ( cur_stream ) stream_cycle_channel ( cur_stream , CODEC_TYPE_VIDEO ) ; break ; case SDLK_w : toggle_audio_display ( ) ; break ; case SDLK_LEFT : incr = - 10 . 0 ; goto do_seek ; case SDLK_RIGHT : incr = 10 . 0 ; goto do_seek ; case SDLK_UP : incr = 60 . 0 ; goto do_seek ; case SDLK_DOWN : incr = - 60 . 0 ; do_seek : if ( cur_stream ) { pos = get_master_clock ( cur_stream ) ; printf ( %f %f %d %d %d %d\n , ( float ) pos , ( float ) incr , cur_stream - > av_sync_type == AV_SYNC_VIDEO_MASTER , cur_stream - > av_sync_type == AV_SYNC_AUDIO_MASTER , cur_stream - > video_st , cur_stream - > audio_st ) ; pos + = incr ; stream_seek ( cur_stream , ( int64_t ) ( pos * AV_TIME_BASE ) ) ; } break ; default : break ; } break ; case SDL_MOUSEBUTTONDOWN : if ( cur_stream ) { int ns , hh , mm , ss ; int tns , thh , tmm , tss ; tns = cur_stream - > ic - > duration/1000000LL ; thh = tns/3600 ; tmm = ( tns%3600 ) /60 ; tss = ( tns%60 ) ; frac = ( double ) event . button . x/ ( double ) cur_stream - > width ; ns = frac * tns ; hh = ns/3600 ; mm = ( ns%3600 ) /60 ; ss = ( ns%60 ) ; fprintf ( stderr , Seek to %2 . 0f%% ( %2d : %02d : %02d ) of total duration ( %2d : %02d : %02d ) \n , frac * 100 , hh , mm , ss , thh , tmm , tss ) ; stream_seek ( cur_stream , ( int64_t ) ( cur_stream - > ic - > start_time + frac * cur_stream - > ic - > duration ) ) ; } break ; case SDL_VIDEORESIZE : if ( cur_stream ) { screen = SDL_SetVideoMode ( event . resize . w , event . resize . h , 0 , SDL_HWSURFACE|SDL_RESIZABLE|SDL_ASYNCBLIT|SDL_HWACCEL ) ; cur_stream - > width = event . resize . w ; cur_stream - > height = event . resize . h ; } break ; case SDL_QUIT : case FF_QUIT_EVENT : do_exit ( ) ; break ; case FF_ALLOC_EVENT : alloc_picture ( event . user . data1 ) ; break ; case FF_REFRESH_EVENT : video_refresh_timer ( event . user . data1 ) ; break ; default : break ; } } }",0
"static int mov_write_ilst_tag ( AVIOContext * pb , MOVMuxContext * mov , AVFormatContext * s ) { int64_t pos = avio_tell ( pb ) ; avio_wb32 ( pb , 0 ) ; / * size * / ffio_wfourcc ( pb , ilst ) ; mov_write_string_metadata ( s , pb , \251nam , title , 1 ) ; mov_write_string_metadata ( s , pb , \251ART , artist , 1 ) ; mov_write_string_metadata ( s , pb , aART , album_artist , 1 ) ; mov_write_string_metadata ( s , pb , \251wrt , composer , 1 ) ; mov_write_string_metadata ( s , pb , \251alb , album , 1 ) ; mov_write_string_metadata ( s , pb , \251day , date , 1 ) ; mov_write_string_tag ( pb , \251too , LIBAVFORMAT_IDENT , 0 , 1 ) ; mov_write_string_metadata ( s , pb , \251cmt , comment , 1 ) ; mov_write_string_metadata ( s , pb , \251gen , genre , 1 ) ; mov_write_string_metadata ( s , pb , \251cpy , copyright , 1 ) ; mov_write_string_metadata ( s , pb , \251grp , grouping , 1 ) ; mov_write_string_metadata ( s , pb , \251lyr , lyrics , 1 ) ; mov_write_string_metadata ( s , pb , desc , description , 1 ) ; mov_write_string_metadata ( s , pb , ldes , synopsis , 1 ) ; mov_write_string_metadata ( s , pb , tvsh , show , 1 ) ; mov_write_string_metadata ( s , pb , tven , episode_id , 1 ) ; mov_write_string_metadata ( s , pb , tvnn , network , 1 ) ; mov_write_trkn_tag ( pb , mov , s ) ; return update_size ( pb , pos ) ; }",0
static int gif_read_close ( AVFormatContext * s1 ) { GifState * s = s1 - > priv_data ; av_free ( s - > image_buf ) ; return 0 ; },1
"static int pnm_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; PNMContext * const s = avctx - > priv_data ; AVFrame * const p = data ; int i , j , n , linesize , h , upgrade = 0 , is_mono = 0 ; unsigned char * ptr ; int components , sample_len , ret ; unsigned int maskval = 0 ; s - > bytestream_start = s - > bytestream = ( uint8_t * ) buf ; s - > bytestream_end = ( uint8_t * ) buf + buf_size ; if ( ( ret = ff_pnm_decode_header ( avctx , s ) ) < 0 ) return ret ; if ( ( ret = ff_get_buffer ( avctx , p , 0 ) ) < 0 ) return ret ; p - > pict_type = AV_PICTURE_TYPE_I ; p - > key_frame = 1 ; switch ( avctx - > pix_fmt ) { default : return AVERROR ( EINVAL ) ; case AV_PIX_FMT_RGBA64BE : n = avctx - > width * 8 ; components=4 ; sample_len=16 ; goto do_read ; case AV_PIX_FMT_RGB48BE : n = avctx - > width * 6 ; components=3 ; sample_len=16 ; goto do_read ; case AV_PIX_FMT_RGBA : n = avctx - > width * 4 ; components=4 ; sample_len=8 ; goto do_read ; case AV_PIX_FMT_RGB24 : n = avctx - > width * 3 ; components=3 ; sample_len=8 ; goto do_read ; case AV_PIX_FMT_GRAY8 : n = avctx - > width ; components=1 ; sample_len=8 ; if ( s - > maxval < 255 ) { upgrade = 1 ; maskval = ( 2 < < av_log2 ( s - > maxval ) ) - 1 ; } goto do_read ; case AV_PIX_FMT_GRAY8A : n = avctx - > width * 2 ; components=2 ; sample_len=8 ; goto do_read ; case AV_PIX_FMT_GRAY16BE : case AV_PIX_FMT_GRAY16LE : n = avctx - > width * 2 ; components=1 ; sample_len=16 ; if ( s - > maxval < 65535 ) { upgrade = 2 ; maskval = ( 2 < < av_log2 ( s - > maxval ) ) - 1 ; } goto do_read ; case AV_PIX_FMT_MONOWHITE : case AV_PIX_FMT_MONOBLACK : n = ( avctx - > width + 7 ) > > 3 ; components=1 ; sample_len=1 ; is_mono = 1 ; do_read : ptr = p - > data[0] ; linesize = p - > linesize[0] ; if ( s - > bytestream + n * avctx - > height > s - > bytestream_end ) return AVERROR_INVALIDDATA ; if ( s - > type < 4 || ( is_mono & & s - > type==7 ) ) { for ( i=0 ; i < avctx - > height ; i + + ) { PutBitContext pb ; init_put_bits ( & pb , ptr , linesize ) ; for ( j=0 ; j < avctx - > width * components ; j + + ) { unsigned int c=0 ; int v=0 ; if ( s - > type < 4 ) while ( s - > bytestream < s - > bytestream_end & & ( * s - > bytestream < ' 0 ' || * s - > bytestream > ' 9 ' ) ) s - > bytestream + + ; if ( s - > bytestream > = s - > bytestream_end ) return AVERROR_INVALIDDATA ; if ( is_mono ) { / * read a single digit * / v = ( * s - > bytestream + + ) & 1 ; } else { / * read a sequence of digits * / do { v = 10 * v + c ; c = ( * s - > bytestream + + ) - ' 0 ' ; } while ( c < = 9 ) ; } put_bits ( & pb , sample_len , ( ( ( 1 < < sample_len ) - 1 ) * v + ( s - > maxval > > 1 ) ) /s - > maxval ) ; } flush_put_bits ( & pb ) ; ptr + = linesize ; } } else { for ( i = 0 ; i < avctx - > height ; i + + ) { if ( ! upgrade ) memcpy ( ptr , s - > bytestream , n ) ; else if ( upgrade == 1 ) { unsigned int j , f = ( 255 * 128 + s - > maxval / 2 ) / s - > maxval ; for ( j = 0 ; j < n ; j + + ) ptr[j] = ( ( s - > bytestream[j] & maskval ) * f + 64 ) > > 7 ; } else if ( upgrade == 2 ) { unsigned int j , v , f = ( 65535 * 32768 + s - > maxval / 2 ) / s - > maxval ; for ( j = 0 ; j < n / 2 ; j + + ) { v = av_be2ne16 ( ( ( uint16_t * ) s - > bytestream ) [j] ) & maskval ; ( ( uint16_t * ) ptr ) [j] = ( v * f + 16384 ) > > 15 ; } } s - > bytestream + = n ; ptr + = linesize ; } } break ; case AV_PIX_FMT_YUV420P : case AV_PIX_FMT_YUV420P9BE : case AV_PIX_FMT_YUV420P10BE : { unsigned char * ptr1 , * ptr2 ; n = avctx - > width ; ptr = p - > data[0] ; linesize = p - > linesize[0] ; if ( s - > maxval > = 256 ) n * = 2 ; if ( s - > bytestream + n * avctx - > height * 3 / 2 > s - > bytestream_end ) return AVERROR_INVALIDDATA ; for ( i = 0 ; i < avctx - > height ; i + + ) { memcpy ( ptr , s - > bytestream , n ) ; s - > bytestream + = n ; ptr + = linesize ; } ptr1 = p - > data[1] ; ptr2 = p - > data[2] ; n > > = 1 ; h = avctx - > height > > 1 ; for ( i = 0 ; i < h ; i + + ) { memcpy ( ptr1 , s - > bytestream , n ) ; s - > bytestream + = n ; memcpy ( ptr2 , s - > bytestream , n ) ; s - > bytestream + = n ; ptr1 + = p - > linesize[1] ; ptr2 + = p - > linesize[2] ; } } break ; case AV_PIX_FMT_YUV420P16 : { uint16_t * ptr1 , * ptr2 ; const int f = ( 65535 * 32768 + s - > maxval / 2 ) / s - > maxval ; unsigned int j ,",1
"int ff_audio_mix_get_matrix ( AudioMix * am , double * matrix , int stride ) { int i , o ; if ( am - > in_channels < = 0 || am - > in_channels > AVRESAMPLE_MAX_CHANNELS || am - > out_channels < = 0 || am - > out_channels > AVRESAMPLE_MAX_CHANNELS ) { av_log ( am , AV_LOG_ERROR , Invalid channel counts\n ) ; return AVERROR ( EINVAL ) ; } define GET_MATRIX_CONVERT ( suffix , scale ) \ if ( ! am - > matrix_ suffix[0] ) { \ av_log ( am , AV_LOG_ERROR , matrix is not set\n ) ; \ return AVERROR ( EINVAL ) ; \ } \ for ( o = 0 ; o < am - > out_channels ; o + + ) \ for ( i = 0 ; i < am - > in_channels ; i + + ) \ matrix[o * stride + i] = am - > matrix_ suffix[o][i] * ( scale ) ; switch ( am - > coeff_type ) { case AV_MIX_COEFF_TYPE_Q8 : GET_MATRIX_CONVERT ( q8 , 1 . 0 / 256 . 0 ) ; break ; case AV_MIX_COEFF_TYPE_Q15 : GET_MATRIX_CONVERT ( q15 , 1 . 0 / 32768 . 0 ) ; break ; case AV_MIX_COEFF_TYPE_FLT : GET_MATRIX_CONVERT ( flt , 1 . 0 ) ; break ; default : av_log ( am , AV_LOG_ERROR , Invalid mix coeff type\n ) ; return AVERROR ( EINVAL ) ; } return 0 ; }",0
"static int link_filter_inouts ( AVFilterContext * filt_ctx , AVFilterInOut * * curr_inputs , AVFilterInOut * * open_inputs , void * log_ctx ) { int pad , ret ; for ( pad = 0 ; pad < filt_ctx - > input_count ; pad + + ) { AVFilterInOut * p = * curr_inputs ; if ( p ) * curr_inputs = ( * curr_inputs ) - > next ; else if ( ! ( p = av_mallocz ( sizeof ( * p ) ) ) ) return AVERROR ( ENOMEM ) ; if ( p - > filter_ctx ) { if ( ( ret = link_filter ( p - > filter_ctx , p - > pad_idx , filt_ctx , pad , log_ctx ) ) < 0 ) return ret ; av_free ( p - > name ) ; av_free ( p ) ; } else { p - > filter_ctx = filt_ctx ; p - > pad_idx = pad ; append_inout ( open_inputs , & p ) ; } } if ( * curr_inputs ) { av_log ( log_ctx , AV_LOG_ERROR , Too many inputs specified for the \ %s\ filter . \n , filt_ctx - > filter - > name ) ; return AVERROR ( EINVAL ) ; } pad = filt_ctx - > output_count ; while ( pad - - ) { AVFilterInOut * currlinkn = av_mallocz ( sizeof ( AVFilterInOut ) ) ; if ( ! currlinkn ) return AVERROR ( ENOMEM ) ; currlinkn - > filter_ctx = filt_ctx ; currlinkn - > pad_idx = pad ; insert_inout ( curr_inputs , currlinkn ) ; } return 0 ; }",0
"static void blend_image_rgba ( AVFilterContext * ctx , AVFrame * dst , const AVFrame * src , int x , int y ) { blend_image_packed_rgb ( ctx , dst , src , 1 , x , y , 0 ) ; }",0
"static inline void RENAME ( yuv2yuv1 ) ( SwsContext * c , const int16_t * lumSrc , const int16_t * chrUSrc , const int16_t * chrVSrc , const int16_t * alpSrc , uint8_t * dest , uint8_t * uDest , uint8_t * vDest , uint8_t * aDest , int dstW , int chrDstW ) { int p= 4 ; const uint8_t * src[4]= { alpSrc + dstW , lumSrc + dstW , chrUSrc + chrDstW , chrVSrc + chrDstW } ; uint8_t * dst[4]= { aDest , dest , uDest , vDest } ; x86_reg counter[4]= { dstW , dstW , chrDstW , chrDstW } ; while ( p - - ) { if ( dst[p] ) { __asm__ volatile ( mov %2 , %% REG_a \n\t . p2align 4 \n\t / * FIXME Unroll ? * / 1 : \n\t movq ( %0 , %% REG_a , 2 ) , %%mm0 \n\t movq 8 ( %0 , %% REG_a , 2 ) , %%mm1 \n\t psraw 7 , %%mm0 \n\t psraw 7 , %%mm1 \n\t packuswb %%mm1 , %%mm0 \n\t MOVNTQ ( %%mm0 , ( %1 , %%REGa ) ) add 8 , %% REG_a \n\t jnc 1b \n\t : : r ( src[p] ) , r ( dst[p] + counter[p] ) , g ( - counter[p] ) : % REG_a ) ; } } }",0
"static inline void RENAME ( rgb15to16 ) ( const uint8_t * src , uint8_t * dst , long src_size ) { register const uint8_t * s=src ; register uint8_t * d=dst ; register const uint8_t * end ; const uint8_t * mm_end ; end = s + src_size ; if COMPILE_TEMPLATE_MMX __asm__ volatile ( PREFETCH %0 : : m ( * s ) ) ; __asm__ volatile ( movq %0 , %%mm4 : : m ( mask15s ) ) ; mm_end = end - 15 ; while ( s < mm_end ) { __asm__ volatile ( PREFETCH 32%1 \n\t movq %1 , %%mm0 \n\t movq 8%1 , %%mm2 \n\t movq %%mm0 , %%mm1 \n\t movq %%mm2 , %%mm3 \n\t pand %%mm4 , %%mm0 \n\t pand %%mm4 , %%mm2 \n\t paddw %%mm1 , %%mm0 \n\t paddw %%mm3 , %%mm2 \n\t MOVNTQ %%mm0 , %0 \n\t MOVNTQ %%mm2 , 8%0 : =m ( * d ) : m ( * s ) ) ; d + =16 ; s + =16 ; } __asm__ volatile ( SFENCE : : : memory ) ; __asm__ volatile ( EMMS : : : memory ) ; endif mm_end = end - 3 ; while ( s < mm_end ) { register unsigned x= * ( ( const uint32_t * ) s ) ; * ( ( uint32_t * ) d ) = ( x & 0x7FFF7FFF ) + ( x & 0x7FE07FE0 ) ; d + =4 ; s + =4 ; } if ( s < end ) { register unsigned short x= * ( ( const uint16_t * ) s ) ; * ( ( uint16_t * ) d ) = ( x & 0x7FFF ) + ( x & 0x7FE0 ) ; } }",0
"void ff_vdpau_mpeg_picture_complete ( MpegEncContext * s , const uint8_t * buf , int buf_size , int slice_count ) { struct vdpau_render_state * render , * last , * next ; int i ; render = ( struct vdpau_render_state * ) s - > current_picture_ptr - > data[0] ; assert ( render ) ; / * fill VdpPictureInfoMPEG1Or2 struct * / render - > info . mpeg . picture_structure = s - > picture_structure ; render - > info . mpeg . picture_coding_type = s - > pict_type ; render - > info . mpeg . intra_dc_precision = s - > intra_dc_precision ; render - > info . mpeg . frame_pred_frame_dct = s - > frame_pred_frame_dct ; render - > info . mpeg . concealment_motion_vectors = s - > concealment_motion_vectors ; render - > info . mpeg . intra_vlc_format = s - > intra_vlc_format ; render - > info . mpeg . alternate_scan = s - > alternate_scan ; render - > info . mpeg . q_scale_type = s - > q_scale_type ; render - > info . mpeg . top_field_first = s - > top_field_first ; render - > info . mpeg . full_pel_forward_vector = s - > full_pel[0] ; // MPEG - 1 only . Set 0 for MPEG - 2 render - > info . mpeg . full_pel_backward_vector = s - > full_pel[1] ; // MPEG - 1 only . Set 0 for MPEG - 2 render - > info . mpeg . f_code[0][0] = s - > mpeg_f_code[0][0] ; // For MPEG - 1 fill both horiz . & vert . render - > info . mpeg . f_code[0][1] = s - > mpeg_f_code[0][1] ; render - > info . mpeg . f_code[1][0] = s - > mpeg_f_code[1][0] ; render - > info . mpeg . f_code[1][1] = s - > mpeg_f_code[1][1] ; for ( i = 0 ; i < 64 ; + + i ) { render - > info . mpeg . intra_quantizer_matrix[i] = s - > intra_matrix[i] ; render - > info . mpeg . non_intra_quantizer_matrix[i] = s - > inter_matrix[i] ; } render - > info . mpeg . forward_reference = VDP_INVALID_HANDLE ; render - > info . mpeg . backward_reference = VDP_INVALID_HANDLE ; switch ( s - > pict_type ) { case FF_B_TYPE : next = ( struct vdpau_render_state * ) s - > next_picture . data[0] ; assert ( next ) ; render - > info . mpeg . backward_reference = next - > surface ; // no return here , going to set forward prediction case FF_P_TYPE : last = ( struct vdpau_render_state * ) s - > last_picture . data[0] ; if ( ! last ) // FIXME : Does this test make sense ? last = render ; // predict second field from the first render - > info . mpeg . forward_reference = last - > surface ; } ff_vdpau_add_data_chunk ( s , buf , buf_size ) ; render - > info . mpeg . slice_count = slice_count ; if ( slice_count ) ff_draw_horiz_band ( s , 0 , s - > avctx - > height ) ; render - > bitstream_buffers_used = 0 ; }",1
"static int open_input_stream ( HTTPContext * c , const char * info ) { char buf[128] ; char input_filename[1024] ; AVFormatContext * s = NULL ; int buf_size , i , ret ; int64_t stream_pos ; / * find file name * / if ( c - > stream - > feed ) { strcpy ( input_filename , c - > stream - > feed - > feed_filename ) ; buf_size = FFM_PACKET_SIZE ; / * compute position ( absolute time ) * / if ( av_find_info_tag ( buf , sizeof ( buf ) , date , info ) ) { if ( ( ret = av_parse_time ( & stream_pos , buf , 0 ) ) < 0 ) { http_log ( Invalid date specification ' %s ' for stream\n , buf ) ; return ret ; } } else if ( av_find_info_tag ( buf , sizeof ( buf ) , buffer , info ) ) { int prebuffer = strtol ( buf , 0 , 10 ) ; stream_pos = av_gettime ( ) - prebuffer * ( int64_t ) 1000000 ; } else stream_pos = av_gettime ( ) - c - > stream - > prebuffer * ( int64_t ) 1000 ; } else { strcpy ( input_filename , c - > stream - > feed_filename ) ; buf_size = 0 ; / * compute position ( relative time ) * / if ( av_find_info_tag ( buf , sizeof ( buf ) , date , info ) ) { if ( ( ret = av_parse_time ( & stream_pos , buf , 1 ) ) < 0 ) { http_log ( Invalid date specification ' %s ' for stream\n , buf ) ; return ret ; } } else stream_pos = 0 ; } if ( ! input_filename[0] ) { http_log ( No filename was specified for stream\n ) ; return AVERROR ( EINVAL ) ; } / * open stream * / ret = avformat_open_input ( & s , input_filename , c - > stream - > ifmt , & c - > stream - > in_opts ) ; if ( ret < 0 ) { http_log ( Could not open input ' %s ' : %s\n , input_filename , av_err2str ( ret ) ) ; return ret ; } / * set buffer size * / if ( buf_size > 0 ) { ret = ffio_set_buf_size ( s - > pb , buf_size ) ; if ( ret < 0 ) { http_log ( Failed to set buffer size\n ) ; return ret ; } } s - > flags |= AVFMT_FLAG_GENPTS ; c - > fmt_in = s ; if ( strcmp ( s - > iformat - > name , ffm ) & & ( ret = avformat_find_stream_info ( c - > fmt_in , NULL ) ) < 0 ) { http_log ( Could not find stream info for input ' %s ' \n , input_filename ) ; avformat_close_input ( & s ) ; return ret ; } / * choose stream as clock source ( we favor the video stream if * present ) for packet sending * / c - > pts_stream_index = 0 ; for ( i=0 ; i < c - > stream - > nb_streams ; i + + ) { if ( c - > pts_stream_index == 0 & & c - > stream - > streams[i] - > codecpar - > codec_type == AVMEDIA_TYPE_VIDEO ) { c - > pts_stream_index = i ; } } if ( c - > fmt_in - > iformat - > read_seek ) av_seek_frame ( c - > fmt_in , - 1 , stream_pos , 0 ) ; / * set the start time ( needed for maxtime and RTP packet timing ) * / c - > start_time = cur_time ; c - > first_pts = AV_NOPTS_VALUE ; return 0 ; }",1
"static int decode_5 ( SANMVideoContext * ctx ) { if HAVE_BIGENDIAN uint16_t * frm ; int npixels ; endif uint8_t * dst = ( uint8_t * ) ctx - > frm0 ; if ( rle_decode ( ctx , dst , ctx - > buf_size ) ) return AVERROR_INVALIDDATA ; if HAVE_BIGENDIAN npixels = ctx - > npixels ; frm = ctx - > frm0 ; while ( npixels - - ) * frm + + = av_bswap16 ( * frm ) ; endif return 0 ; }",1
"static void vc1_inv_trans_4x8_c ( uint8_t * dest , int linesize , DCTELEM * block ) { int i ; register int t1 , t2 , t3 , t4 , t5 , t6 , t7 , t8 ; DCTELEM * src , * dst ; const uint8_t * cm = ff_cropTbl + MAX_NEG_CROP ; src = block ; dst = block ; for ( i = 0 ; i < 8 ; i + + ) { t1 = 17 * ( src[0] + src[2] ) + 4 ; t2 = 17 * ( src[0] - src[2] ) + 4 ; t3 = 22 * src[1] + 10 * src[3] ; t4 = 22 * src[3] - 10 * src[1] ; dst[0] = ( t1 + t3 ) > > 3 ; dst[1] = ( t2 - t4 ) > > 3 ; dst[2] = ( t2 + t4 ) > > 3 ; dst[3] = ( t1 - t3 ) > > 3 ; src + = 8 ; dst + = 8 ; } src = block ; for ( i = 0 ; i < 4 ; i + + ) { t1 = 12 * ( src[ 0] + src[32] ) + 64 ; t2 = 12 * ( src[ 0] - src[32] ) + 64 ; t3 = 16 * src[16] + 6 * src[48] ; t4 = 6 * src[16] - 16 * src[48] ; t5 = t1 + t3 ; t6 = t2 + t4 ; t7 = t2 - t4 ; t8 = t1 - t3 ; t1 = 16 * src[ 8] + 15 * src[24] + 9 * src[40] + 4 * src[56] ; t2 = 15 * src[ 8] - 4 * src[24] - 16 * src[40] - 9 * src[56] ; t3 = 9 * src[ 8] - 16 * src[24] + 4 * src[40] + 15 * src[56] ; t4 = 4 * src[ 8] - 9 * src[24] + 15 * src[40] - 16 * src[56] ; dest[0 * linesize] = cm[dest[0 * linesize] + ( ( t5 + t1 ) > > 7 ) ] ; dest[1 * linesize] = cm[dest[1 * linesize] + ( ( t6 + t2 ) > > 7 ) ] ; dest[2 * linesize] = cm[dest[2 * linesize] + ( ( t7 + t3 ) > > 7 ) ] ; dest[3 * linesize] = cm[dest[3 * linesize] + ( ( t8 + t4 ) > > 7 ) ] ; dest[4 * linesize] = cm[dest[4 * linesize] + ( ( t8 - t4 + 1 ) > > 7 ) ] ; dest[5 * linesize] = cm[dest[5 * linesize] + ( ( t7 - t3 + 1 ) > > 7 ) ] ; dest[6 * linesize] = cm[dest[6 * linesize] + ( ( t6 - t2 + 1 ) > > 7 ) ] ; dest[7 * linesize] = cm[dest[7 * linesize] + ( ( t5 - t1 + 1 ) > > 7 ) ] ; src + + ; dest + + ; } }",1
"static av_cold int decode_init ( WMAProDecodeCtx * s , AVCodecContext * avctx ) { uint8_t * edata_ptr = avctx - > extradata ; unsigned int channel_mask ; int i , bits ; int log2_max_num_subframes ; int num_possible_block_sizes ; if ( avctx - > codec_id == AV_CODEC_ID_XMA1 || avctx - > codec_id == AV_CODEC_ID_XMA2 ) avctx - > block_align = 2048 ; if ( ! avctx - > block_align ) { av_log ( avctx , AV_LOG_ERROR , block_align is not set\n ) ; return AVERROR ( EINVAL ) ; } s - > avctx = avctx ; s - > fdsp = avpriv_float_dsp_alloc ( avctx - > flags & AV_CODEC_FLAG_BITEXACT ) ; if ( ! s - > fdsp ) return AVERROR ( ENOMEM ) ; init_put_bits ( & s - > pb , s - > frame_data , MAX_FRAMESIZE ) ; avctx - > sample_fmt = AV_SAMPLE_FMT_FLTP ; / * * dump the extradata * / av_log ( avctx , AV_LOG_DEBUG , extradata : \n ) ; for ( i = 0 ; i < avctx - > extradata_size ; i + + ) av_log ( avctx , AV_LOG_DEBUG , [%x] , avctx - > extradata[i] ) ; av_log ( avctx , AV_LOG_DEBUG , \n ) ; if ( avctx - > codec_id == AV_CODEC_ID_XMA2 & & ( ! avctx - > extradata || avctx - > extradata_size > = 6 ) ) { s - > decode_flags = 0x10d6 ; channel_mask = avctx - > extradata ? AV_RL32 ( edata_ptr + 2 ) : 0 ; s - > bits_per_sample = 16 ; } else if ( avctx - > codec_id == AV_CODEC_ID_XMA1 ) { s - > decode_flags = 0x10d6 ; s - > bits_per_sample = 16 ; channel_mask = 0 ; } else if ( avctx - > codec_id == AV_CODEC_ID_WMAPRO & & avctx - > extradata_size > = 18 ) { s - > decode_flags = AV_RL16 ( edata_ptr + 14 ) ; channel_mask = AV_RL32 ( edata_ptr + 2 ) ; s - > bits_per_sample = AV_RL16 ( edata_ptr ) ; if ( s - > bits_per_sample > 32 || s - > bits_per_sample < 1 ) { avpriv_request_sample ( avctx , bits per sample is %d , s - > bits_per_sample ) ; return AVERROR_PATCHWELCOME ; } } else { avpriv_request_sample ( avctx , Unknown extradata size ) ; return AVERROR_PATCHWELCOME ; } if ( avctx - > codec_id ! = AV_CODEC_ID_WMAPRO & & avctx - > channels > 2 ) { s - > nb_channels = 2 ; } else { s - > nb_channels = avctx - > channels ; } / * * generic init * / s - > log2_frame_size = av_log2 ( avctx - > block_align ) + 4 ; if ( s - > log2_frame_size > 25 ) { avpriv_request_sample ( avctx , Large block align ) ; return AVERROR_PATCHWELCOME ; } / * * frame info * / if ( avctx - > codec_id ! = AV_CODEC_ID_WMAPRO ) s - > skip_frame = 0 ; else s - > skip_frame = 1 ; / * skip first frame * / s - > packet_loss = 1 ; s - > len_prefix = ( s - > decode_flags & 0x40 ) ; / * * get frame len * / if ( avctx - > codec_id == AV_CODEC_ID_WMAPRO ) { bits = ff_wma_get_frame_len_bits ( avctx - > sample_rate , 3 , s - > decode_flags ) ; if ( bits > WMAPRO_BLOCK_MAX_BITS ) { avpriv_request_sample ( avctx , 14 - bit block sizes ) ; return AVERROR_PATCHWELCOME ; } s - > samples_per_frame = 1 < < bits ; } else { s - > samples_per_frame = 512 ; } / * * subframe info * / log2_max_num_subframes = ( ( s - > decode_flags & 0x38 ) > > 3 ) ; s - > max_num_subframes = 1 < < log2_max_num_subframes ; if ( s - > max_num_subframes == 16 || s - > max_num_subframes == 4 ) s - > max_subframe_len_bit = 1 ; s - > subframe_len_bits = av_log2 ( log2_max_num_subframes ) + 1 ; num_possible_block_sizes = log2_max_num_subframes + 1 ; s - > min_samples_per_subframe = s - > samples_per_frame / s - > max_num_subframes ; s - > dynamic_range_compression = ( s - > decode_flags & 0x80 ) ; if ( s - > max_num_subframes > MAX_SUBFRAMES ) { av_log ( avctx , AV_LOG_ERROR , invalid number of subframes % PRId8 \n , s - > max_num_subframes ) ; return AVERROR_INVALIDDATA ; } if ( s - > min_samples_per_subframe < WMAPRO_BLOCK_MIN_SIZE ) { av_log ( avctx , AV_LOG_ERROR , min_samples_per_subframe of %d too small\n , s - > min_samples_per_subframe ) ; return AVERROR_INVALIDDATA ; } if ( s - > avctx - > sample_rate < = 0 ) { av_log ( avctx , AV_LOG_ERROR , invalid sample rate\n ) ; return AVERROR_INVALIDDATA ; } if ( s - > nb_channels < = 0 ) { av_log ( avctx , AV_LOG_ERROR , invalid number of channels %d\n , s - > nb_channels ) ; return AVERROR_INVALIDDATA ; } else if ( s - > nb_channels > WMAPRO_MAX_CHANNELS ) { avpriv_request_sample ( avctx , More than %d channels , WMAPRO_MAX_CHANNELS ) ; return AVERROR_PATCHWELCOME ; } / * * init previous block len * / for ( i = 0 ; i < s - > nb_channels ; i + + ) s - > channel[i] . prev_block_len = s - > samples_per_frame ; / * * extract lfe channel position * / s - > lfe_channel = - 1 ; if ( channel_mask & 8 ) { unsigned int mask ; for ( mask = 1 ; mask < 16 ; mask < < = 1 ) { if ( channel_mask & mask ) + + s - > lfe_channel ; } } INIT_VLC_STATIC ( & sf_vlc , SCALEVLCBITS , HUFF_SCALE_SIZE , scale_huffbits , 1 , 1 , scale_huffcodes , 2 , 2 , 616 ) ; INIT_VLC_STATIC ( & sf_rl_vlc , VLCBITS , HUFF_SCALE_RL_SIZE , scale_rl_huffbits , 1 , 1 , scale_rl_huffcodes , 4 , 4 , 1406 ) ; INIT_VLC_STATIC ( & coef_vlc[0] , VLCBITS , HUFF_COEF0_SIZE , coef0_huffbits , 1 , 1 , coef0_huffcodes , 4 , 4 , 2108 ) ; INIT_VLC_STATIC ( & coef_vlc[1] , VLCBITS , HUFF_COEF1_SIZE , coef1_huffbits , 1 , 1 , coef1_huffcodes , 4 , 4 , 3912 ) ; INIT_VLC_STATIC ( & vec4_vlc , VLCBITS , HUFF_VEC4_SIZE , vec4_huffbits , 1 , 1 , vec4_huffcodes , 2 , 2 , 604 ) ; INIT_VLC_STATIC ( & vec2_vlc , VLCBITS , HUFF_VEC2_SIZE , vec2_huffbits , 1 , 1 , vec2_huffcodes , 2 , 2 , 562 ) ; INIT_VLC_STATIC ( & vec1_vlc , VLCBITS , HUFF_VEC1_SIZE , vec1_huffbits , 1 , 1 , vec1_huffcodes , 2 , 2 , 562 ) ; / * * calculate number of scale factor bands and their offsets for every possible block size * / for ( i = 0 ; i < num_possible_block_sizes ; i + + ) { int subframe_len = s - > samples_per_frame > > i ; int x ; int band = 1 ; int",1
"static void implicit_weight_table ( const H264Context * h , H264SliceContext * sl , int field ) { int ref0 , ref1 , i , cur_poc , ref_start , ref_count0 , ref_count1 ; for ( i = 0 ; i < 2 ; i + + ) { sl - > luma_weight_flag[i] = 0 ; sl - > chroma_weight_flag[i] = 0 ; } if ( field < 0 ) { if ( h - > picture_structure == PICT_FRAME ) { cur_poc = h - > cur_pic_ptr - > poc ; } else { cur_poc = h - > cur_pic_ptr - > field_poc[h - > picture_structure - 1] ; } if ( sl - > ref_count[0] == 1 & & sl - > ref_count[1] == 1 & & ! FRAME_MBAFF ( h ) & & sl - > ref_list[0][0] . poc + sl - > ref_list[1][0] . poc == 2 * cur_poc ) { sl - > use_weight = 0 ; sl - > use_weight_chroma = 0 ; return ; } ref_start = 0 ; ref_count0 = sl - > ref_count[0] ; ref_count1 = sl - > ref_count[1] ; } else { cur_poc = h - > cur_pic_ptr - > field_poc[field] ; ref_start = 16 ; ref_count0 = 16 + 2 * sl - > ref_count[0] ; ref_count1 = 16 + 2 * sl - > ref_count[1] ; } sl - > use_weight = 2 ; sl - > use_weight_chroma = 2 ; sl - > luma_log2_weight_denom = 5 ; sl - > chroma_log2_weight_denom = 5 ; for ( ref0 = ref_start ; ref0 < ref_count0 ; ref0 + + ) { int poc0 = sl - > ref_list[0][ref0] . poc ; for ( ref1 = ref_start ; ref1 < ref_count1 ; ref1 + + ) { int w = 32 ; if ( ! sl - > ref_list[0][ref0] . parent - > long_ref & & ! sl - > ref_list[1][ref1] . parent - > long_ref ) { int poc1 = sl - > ref_list[1][ref1] . poc ; int td = av_clip_int8 ( poc1 - poc0 ) ; if ( td ) { int tb = av_clip_int8 ( cur_poc - poc0 ) ; int tx = ( 16384 + ( FFABS ( td ) > > 1 ) ) / td ; int dist_scale_factor = ( tb * tx + 32 ) > > 8 ; if ( dist_scale_factor > = - 64 & & dist_scale_factor < = 128 ) w = 64 - dist_scale_factor ; } } if ( field < 0 ) { sl - > implicit_weight[ref0][ref1][0] = sl - > implicit_weight[ref0][ref1][1] = w ; } else { sl - > implicit_weight[ref0][ref1][field] = w ; } } } }",1
"static void dnxhd_decode_dct_block_8 ( const DNXHDContext * ctx , RowContext * row , int n ) { dnxhd_decode_dct_block ( ctx , row , n , 4 , 32 , 6 ) ; }",1
"int ff_h264_decode_slice_header ( H264Context * h , H264SliceContext * sl ) { unsigned int first_mb_in_slice ; unsigned int pps_id ; int ret ; unsigned int slice_type , tmp , i , j ; int last_pic_structure , last_pic_droppable ; int must_reinit ; int needs_reinit = 0 ; int field_pic_flag , bottom_field_flag ; int first_slice = sl == h - > slice_ctx & & ! h - > current_slice ; int frame_num , picture_structure , droppable ; PPS * pps ; h - > qpel_put = h - > h264qpel . put_h264_qpel_pixels_tab ; h - > qpel_avg = h - > h264qpel . avg_h264_qpel_pixels_tab ; first_mb_in_slice = get_ue_golomb_long ( & sl - > gb ) ; if ( first_mb_in_slice == 0 ) { // FIXME better field boundary detection if ( h - > current_slice ) { if ( h - > cur_pic_ptr & & FIELD_PICTURE ( h ) & & h - > first_field ) { ff_h264_field_end ( h , sl , 1 ) ; h - > current_slice = 0 ; } else if ( h - > cur_pic_ptr & & ! FIELD_PICTURE ( h ) & & ! h - > first_field & & h - > nal_unit_type == NAL_IDR_SLICE ) { av_log ( h , AV_LOG_WARNING , Broken frame packetizing\n ) ; ff_h264_field_end ( h , sl , 1 ) ; h - > current_slice = 0 ; ff_thread_report_progress ( & h - > cur_pic_ptr - > tf , INT_MAX , 0 ) ; ff_thread_report_progress ( & h - > cur_pic_ptr - > tf , INT_MAX , 1 ) ; h - > cur_pic_ptr = NULL ; } else return AVERROR_INVALIDDATA ; } if ( ! h - > first_field ) { if ( h - > cur_pic_ptr & & ! h - > droppable ) { ff_thread_report_progress ( & h - > cur_pic_ptr - > tf , INT_MAX , h - > picture_structure == PICT_BOTTOM_FIELD ) ; } h - > cur_pic_ptr = NULL ; } } slice_type = get_ue_golomb_31 ( & sl - > gb ) ; if ( slice_type > 9 ) { av_log ( h - > avctx , AV_LOG_ERROR , slice type %d too large at %d\n , slice_type , first_mb_in_slice ) ; return AVERROR_INVALIDDATA ; } if ( slice_type > 4 ) { slice_type - = 5 ; sl - > slice_type_fixed = 1 ; } else sl - > slice_type_fixed = 0 ; slice_type = golomb_to_pict_type[slice_type] ; sl - > slice_type = slice_type ; sl - > slice_type_nos = slice_type & 3 ; if ( h - > nal_unit_type == NAL_IDR_SLICE & & sl - > slice_type_nos ! = AV_PICTURE_TYPE_I ) { av_log ( h - > avctx , AV_LOG_ERROR , A non - intra slice in an IDR NAL unit . \n ) ; return AVERROR_INVALIDDATA ; } if ( ( h - > avctx - > skip_frame > = AVDISCARD_NONREF & & ! h - > nal_ref_idc ) || ( h - > avctx - > skip_frame > = AVDISCARD_BIDIR & & sl - > slice_type_nos == AV_PICTURE_TYPE_B ) || ( h - > avctx - > skip_frame > = AVDISCARD_NONINTRA & & sl - > slice_type_nos ! = AV_PICTURE_TYPE_I ) || ( h - > avctx - > skip_frame > = AVDISCARD_NONKEY & & h - > nal_unit_type ! = NAL_IDR_SLICE ) || h - > avctx - > skip_frame > = AVDISCARD_ALL ) { return SLICE_SKIPED ; } // to make a few old functions happy , it ' s wrong though h - > pict_type = sl - > slice_type ; pps_id = get_ue_golomb ( & sl - > gb ) ; if ( pps_id > = MAX_PPS_COUNT ) { av_log ( h - > avctx , AV_LOG_ERROR , pps_id %u out of range\n , pps_id ) ; return AVERROR_INVALIDDATA ; } if ( ! h - > pps_buffers[pps_id] ) { av_log ( h - > avctx , AV_LOG_ERROR , non - existing PPS %u referenced\n , pps_id ) ; return AVERROR_INVALIDDATA ; } if ( h - > au_pps_id > = 0 & & pps_id ! = h - > au_pps_id ) { av_log ( h - > avctx , AV_LOG_ERROR , PPS change from %d to %d forbidden\n , h - > au_pps_id , pps_id ) ; return AVERROR_INVALIDDATA ; } pps = h - > pps_buffers[pps_id] ; if ( ! h - > sps_buffers[pps - > sps_id] ) { av_log ( h - > avctx , AV_LOG_ERROR , non - existing SPS %u referenced\n , h - > pps . sps_id ) ; return AVERROR_INVALIDDATA ; } if ( first_slice ) h - > pps = * h - > pps_buffers[pps_id] ; if ( pps - > sps_id ! = h - > sps . sps_id || pps - > sps_id ! = h - > current_sps_id || h - > sps_buffers[pps - > sps_id] - > new ) { if ( ! first_slice ) { av_log ( h - > avctx , AV_LOG_ERROR , SPS changed in the middle of the frame\n ) ; return AVERROR_INVALIDDATA ; } h - > sps = * h - > sps_buffers[h - > pps . sps_id] ; if ( h - > mb_width ! = h - > sps . mb_width || h - > mb_height ! = h - > sps . mb_height * ( 2 - h - > sps . frame_mbs_only_flag ) || h - > cur_bit_depth_luma ! = h - > sps . bit_depth_luma || h - > cur_chroma_format_idc ! = h - > sps . chroma_format_idc ) needs_reinit = 1 ; if ( h - > bit_depth_luma ! = h - > sps . bit_depth_luma || h - > chroma_format_idc ! = h - > sps . chroma_format_idc ) { h - > bit_depth_luma = h - > sps . bit_depth_luma ; h - > chroma_format_idc = h - > sps . chroma_format_idc ; needs_reinit = 1 ; } if ( ( ret = ff_h264_set_parameter_from_sps ( h ) ) < 0 ) return ret ; } h - > avctx - > profile = ff_h264_get_profile ( & h - > sps ) ; h - > avctx - > level = h - > sps . level_idc ; h - > avctx - > refs = h - > sps . ref_frame_count ; must_reinit = ( h - > context_initialized & & ( 16 * h - > sps . mb_width ! = h - > avctx - > coded_width || 16 * h - > sps . mb_height * ( 2 - h - > sps . frame_mbs_only_flag ) ! = h - > avctx - > coded_height || h - > cur_bit_depth_luma ! = h - > sps . bit_depth_luma || h - > cur_chroma_format_idc ! = h - > sps . chroma_format_idc || h - > mb_width ! = h - > sps . mb_width || h - > mb_height ! = h - > sps . mb_height * ( 2 - h - > sps . frame_mbs_only_flag ) ) ) ; if ( h - > avctx - > pix_fmt == AV_PIX_FMT_NONE || ( non_j_pixfmt ( h - > avctx - > pix_fmt ) ! =",1
"static int wv_get_value ( WavpackFrameContext * ctx , GetBitContext * gb , int channel , int * last ) { int t , t2 ; int sign , base , add , ret ; WvChannel * c = & ctx - > ch[channel] ; * last = 0 ; if ( ( ctx - > ch[0] . median[0] < 2U ) & & ( ctx - > ch[1] . median[0] < 2U ) & & ! ctx - > zero & & ! ctx - > one ) { if ( ctx - > zeroes ) { ctx - > zeroes - - ; if ( ctx - > zeroes ) { c - > slow_level - = LEVEL_DECAY ( c - > slow_level ) ; return 0 ; } else { t = get_unary_0_33 ( gb ) ; if ( t > = 2 ) { if ( get_bits_left ( gb ) < t - 1 ) t = get_bits ( gb , t - 1 ) | ( 1 < < ( t - 1 ) ) ; } else { if ( get_bits_left ( gb ) < 0 ) ctx - > zeroes = t ; if ( ctx - > zeroes ) { memset ( ctx - > ch[0] . median , 0 , sizeof ( ctx - > ch[0] . median ) ) ; memset ( ctx - > ch[1] . median , 0 , sizeof ( ctx - > ch[1] . median ) ) ; c - > slow_level - = LEVEL_DECAY ( c - > slow_level ) ; return 0 ; if ( ctx - > zero ) { t = 0 ; ctx - > zero = 0 ; } else { t = get_unary_0_33 ( gb ) ; if ( get_bits_left ( gb ) < 0 ) if ( t == 16 ) { t2 = get_unary_0_33 ( gb ) ; if ( t2 < 2 ) { if ( get_bits_left ( gb ) < 0 ) t + = t2 ; } else { if ( get_bits_left ( gb ) < t2 - 1 ) t + = get_bits ( gb , t2 - 1 ) | ( 1 < < ( t2 - 1 ) ) ; if ( ctx - > one ) { ctx - > one = t & 1 ; t = ( t > > 1 ) + 1 ; } else { ctx - > one = t & 1 ; t > > = 1 ; ctx - > zero = ! ctx - > one ; if ( ctx - > hybrid & & ! channel ) update_error_limit ( ctx ) ; if ( ! t ) { base = 0 ; add = GET_MED ( 0 ) - 1 ; DEC_MED ( 0 ) ; } else if ( t == 1 ) { base = GET_MED ( 0 ) ; add = GET_MED ( 1 ) - 1 ; INC_MED ( 0 ) ; DEC_MED ( 1 ) ; } else if ( t == 2 ) { base = GET_MED ( 0 ) + GET_MED ( 1 ) ; add = GET_MED ( 2 ) - 1 ; INC_MED ( 0 ) ; INC_MED ( 1 ) ; DEC_MED ( 2 ) ; } else { base = GET_MED ( 0 ) + GET_MED ( 1 ) + GET_MED ( 2 ) * ( t - 2 ) ; add = GET_MED ( 2 ) - 1 ; INC_MED ( 0 ) ; INC_MED ( 1 ) ; INC_MED ( 2 ) ; if ( ! c - > error_limit ) { ret = base + get_tail ( gb , add ) ; if ( get_bits_left ( gb ) < = 0 ) } else { int mid = ( base * 2 + add + 1 ) > > 1 ; while ( add > c - > error_limit ) { if ( get_bits_left ( gb ) < = 0 ) if ( get_bits1 ( gb ) ) { add - = ( mid - base ) ; base = mid ; } else add = mid - base - 1 ; mid = ( base * 2 + add + 1 ) > > 1 ; ret = mid ; sign = get_bits1 ( gb ) ; if ( ctx - > hybrid_bitrate ) c - > slow_level + = wp_log2 ( ret ) - LEVEL_DECAY ( c - > slow_level ) ; return sign ? ret : ret ; error : * last = 1 ; return 0 ;",1
"static void http_write_packet ( void * opaque , unsigned char * buf , int size ) { HTTPContext * c = opaque ; if ( c - > buffer_ptr == c - > buffer_end || ! c - > buffer_ptr ) c - > buffer_ptr = c - > buffer_end = c - > buffer ; if ( c - > buffer_end - c - > buffer + size > IOBUFFER_MAX_SIZE ) abort ( ) ; memcpy ( c - > buffer_end , buf , size ) ; c - > buffer_end + = size ; }",1
"static int http_read_stream ( URLContext * h , uint8_t * buf , int size ) { HTTPContext * s = h - > priv_data ; int err , new_location ; if ( ! s - > hd ) return AVERROR_EOF ; if ( s - > end_chunked_post & & ! s - > end_header ) { err = http_read_header ( h , & new_location ) ; if ( err < 0 ) return err ; } if ( s - > chunksize > = 0 ) { if ( ! s - > chunksize ) { char line[32] ; for ( ; ; ) { do { if ( ( err = http_get_line ( s , line , sizeof ( line ) ) ) < 0 ) return err ; } while ( ! * line ) ; / * skip CR LF from last chunk * / s - > chunksize = strtoll ( line , NULL , 16 ) ; av_log ( NULL , AV_LOG_TRACE , Chunked encoding data size : % PRId64 ' \n , s - > chunksize ) ; if ( ! s - > chunksize ) return 0 ; break ; } } size = FFMIN ( size , s - > chunksize ) ; } if CONFIG_ZLIB if ( s - > compressed ) return http_buf_read_compressed ( h , buf , size ) ; endif / * CONFIG_ZLIB * / return http_buf_read ( h , buf , size ) ; }",1
"static int lag_read_prob_header ( lag_rac * rac , GetBitContext * gb ) { int i , j , scale_factor ; unsigned prob , cumulative_target ; unsigned cumul_prob = 0 ; unsigned scaled_cumul_prob = 0 ; rac - > prob[0] = 0 ; rac - > prob[257] = UINT_MAX ; / * Read probabilities from bitstream * / for ( i = 1 ; i < 257 ; i + + ) { if ( lag_decode_prob ( gb , & rac - > prob[i] ) < 0 ) { av_log ( rac - > avctx , AV_LOG_ERROR , Invalid probability encountered . \n ) ; return - 1 ; } if ( ( uint64_t ) cumul_prob + rac - > prob[i] > UINT_MAX ) { av_log ( rac - > avctx , AV_LOG_ERROR , Integer overflow encountered in cumulative probability calculation . \n ) ; return - 1 ; } cumul_prob + = rac - > prob[i] ; if ( ! rac - > prob[i] ) { if ( lag_decode_prob ( gb , & prob ) ) { av_log ( rac - > avctx , AV_LOG_ERROR , Invalid probability run encountered . \n ) ; return - 1 ; } if ( prob > 256 - i ) prob = 256 - i ; for ( j = 0 ; j < prob ; j + + ) rac - > prob[ + + i] = 0 ; } } if ( ! cumul_prob ) { av_log ( rac - > avctx , AV_LOG_ERROR , All probabilities are 0 ! \n ) ; return - 1 ; } / * Scale probabilities so cumulative probability is an even power of 2 . * / scale_factor = av_log2 ( cumul_prob ) ; if ( cumul_prob & ( cumul_prob - 1 ) ) { uint64_t mul = softfloat_reciprocal ( cumul_prob ) ; for ( i = 1 ; i < = 128 ; i + + ) { rac - > prob[i] = softfloat_mul ( rac - > prob[i] , mul ) ; scaled_cumul_prob + = rac - > prob[i] ; } if ( scaled_cumul_prob < = 0 ) { av_log ( rac - > avctx , AV_LOG_ERROR , Scaled probabilities invalid\n ) ; return AVERROR_INVALIDDATA ; } for ( ; i < 257 ; i + + ) { rac - > prob[i] = softfloat_mul ( rac - > prob[i] , mul ) ; scaled_cumul_prob + = rac - > prob[i] ; } scale_factor + + ; cumulative_target = 1 < < scale_factor ; if ( scaled_cumul_prob > cumulative_target ) { av_log ( rac - > avctx , AV_LOG_ERROR , Scaled probabilities are larger than target ! \n ) ; return - 1 ; } scaled_cumul_prob = cumulative_target - scaled_cumul_prob ; for ( i = 1 ; scaled_cumul_prob ; i = ( i & 0x7f ) + 1 ) { if ( rac - > prob[i] ) { rac - > prob[i] + + ; scaled_cumul_prob - - ; } / * Comment from reference source : * if ( b & 0x80 == 0 ) { // order of operations is ' wrong ' ; it has been left this way * // since the compression change is negligible and fixing it * // breaks backwards compatibility * b = - ( signed int ) b ; * b & = 0xFF ; * } else { * b + + ; * b & = 0x7f ; * } * / } } rac - > scale = scale_factor ; / * Fill probability array with cumulative probability for each symbol . * / for ( i = 1 ; i < 257 ; i + + ) rac - > prob[i] + = rac - > prob[i - 1] ; return 0 ; }",1
static inline void downmix_2f_2r_to_stereo ( float * samples ) { int i ; for ( i = 0 ; i < 256 ; i + + ) { samples[i] + = samples[i + 512] ; samples[i + 256] = samples[i + 768] ; samples[i + 512] = samples[i + 768] = 0 ; } },0
"static int video_read_header ( AVFormatContext * s , AVFormatParameters * ap ) { AVStream * st ; st = av_new_stream ( s , 0 ) ; if ( ! st ) return AVERROR_NOMEM ; st - > codec - > codec_type = CODEC_TYPE_VIDEO ; st - > codec - > codec_id = s - > iformat - > value ; st - > need_parsing = 1 ; / * for mjpeg , specify frame rate * / / * for mpeg4 specify it too ( most mpeg4 streams dont have the fixed_vop_rate set . . . ) * / if ( ap & & ap - > time_base . num ) { av_set_pts_info ( st , 64 , ap - > time_base . num , ap - > time_base . den ) ; } else if ( st - > codec - > codec_id == CODEC_ID_MJPEG || st - > codec - > codec_id == CODEC_ID_MPEG4 || st - > codec - > codec_id == CODEC_ID_H264 ) { av_set_pts_info ( st , 64 , 1 , 25 ) ; } return 0 ; }",0
"static int vp3_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , uint8_t * buf , int buf_size ) { Vp3DecodeContext * s = avctx - > priv_data ; GetBitContext gb ; static int counter = 0 ; int i ; init_get_bits ( & gb , buf , buf_size * 8 ) ; if ( s - > theora & & get_bits1 ( & gb ) ) { if 1 av_log ( avctx , AV_LOG_ERROR , Header packet passed to frame decoder , skipping\n ) ; return - 1 ; else int ptype = get_bits ( & gb , 7 ) ; skip_bits ( & gb , 6 * 8 ) ; / * theora * / switch ( ptype ) { case 1 : theora_decode_comments ( avctx , gb ) ; break ; case 2 : theora_decode_tables ( avctx , gb ) ; init_dequantizer ( s ) ; break ; default : av_log ( avctx , AV_LOG_ERROR , Unknown Theora config packet : %d\n , ptype ) ; } return buf_size ; endif } s - > keyframe = ! get_bits1 ( & gb ) ; if ( ! s - > theora ) skip_bits ( & gb , 1 ) ; s - > last_quality_index = s - > quality_index ; s - > quality_index = get_bits ( & gb , 6 ) ; if ( s - > theora > = 0x030200 ) skip_bits1 ( & gb ) ; if ( s - > avctx - > debug & FF_DEBUG_PICT_INFO ) av_log ( s - > avctx , AV_LOG_INFO , VP3 %sframe %d : Q index = %d\n , s - > keyframe ? key : , counter , s - > quality_index ) ; counter + + ; if ( s - > quality_index ! = s - > last_quality_index ) { init_dequantizer ( s ) ; init_loop_filter ( s ) ; } if ( s - > keyframe ) { if ( ! s - > theora ) { skip_bits ( & gb , 4 ) ; / * width code * / skip_bits ( & gb , 4 ) ; / * height code * / if ( s - > version ) { s - > version = get_bits ( & gb , 5 ) ; if ( counter == 1 ) av_log ( s - > avctx , AV_LOG_DEBUG , VP version : %d\n , s - > version ) ; } } if ( s - > version || s - > theora ) { if ( get_bits1 ( & gb ) ) av_log ( s - > avctx , AV_LOG_ERROR , Warning , unsupported keyframe coding type ? ! \n ) ; skip_bits ( & gb , 2 ) ; / * reserved ? * / } if ( s - > last_frame . data[0] == s - > golden_frame . data[0] ) { if ( s - > golden_frame . data[0] ) avctx - > release_buffer ( avctx , & s - > golden_frame ) ; s - > last_frame= s - > golden_frame ; / * ensure that we catch any access to this released frame * / } else { if ( s - > golden_frame . data[0] ) avctx - > release_buffer ( avctx , & s - > golden_frame ) ; if ( s - > last_frame . data[0] ) avctx - > release_buffer ( avctx , & s - > last_frame ) ; } s - > golden_frame . reference = 3 ; if ( avctx - > get_buffer ( avctx , & s - > golden_frame ) < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , vp3 : get_buffer ( ) failed\n ) ; return - 1 ; } / * golden frame is also the current frame * / memcpy ( & s - > current_frame , & s - > golden_frame , sizeof ( AVFrame ) ) ; / * time to figure out pixel addresses ? * / if ( ! s - > pixel_addresses_inited ) { if ( ! s - > flipped_image ) vp3_calculate_pixel_addresses ( s ) ; else theora_calculate_pixel_addresses ( s ) ; } } else { / * allocate a new current frame * / s - > current_frame . reference = 3 ; if ( avctx - > get_buffer ( avctx , & s - > current_frame ) < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , vp3 : get_buffer ( ) failed\n ) ; return - 1 ; } } s - > current_frame . qscale_table= s - > qscale_table ; //FIXME allocate individual tables per AVFrame s - > current_frame . qstride= 0 ; { START_TIMER init_frame ( s , & gb ) ; STOP_TIMER ( init_frame ) } if KEYFRAMES_ONLY if ( ! s - > keyframe ) { memcpy ( s - > current_frame . data[0] , s - > golden_frame . data[0] , s - > current_frame . linesize[0] * s - > height ) ; memcpy ( s - > current_frame . data[1] , s - > golden_frame . data[1] , s - > current_frame . linesize[1] * s - > height / 2 ) ; memcpy ( s - > current_frame . data[2] , s - > golden_frame . data[2] , s - > current_frame . linesize[2] * s - > height / 2 ) ; } else { endif { START_TIMER if ( unpack_superblocks ( s , & gb ) ) { av_log ( s - > avctx , AV_LOG_ERROR , error in unpack_superblocks\n ) ; return - 1 ; } STOP_TIMER ( unpack_superblocks ) } { START_TIMER if ( unpack_modes ( s , & gb ) ) { av_log ( s - > avctx , AV_LOG_ERROR , error in unpack_modes\n ) ; return - 1 ; } STOP_TIMER ( unpack_modes ) } { START_TIMER if ( unpack_vectors ( s , & gb ) ) { av_log ( s - > avctx , AV_LOG_ERROR , error in unpack_vectors\n ) ; return - 1 ; } STOP_TIMER ( unpack_vectors ) } { START_TIMER if ( unpack_dct_coeffs ( s , & gb ) ) { av_log ( s - > avctx , AV_LOG_ERROR , error in unpack_dct_coeffs\n ) ; return - 1 ; } STOP_TIMER ( unpack_dct_coeffs ) } { START_TIMER reverse_dc_prediction ( s , 0 , s - > fragment_width , s - > fragment_height ) ; if ( ( avctx - > flags & CODEC_FLAG_GRAY ) == 0 ) { reverse_dc_prediction ( s , s - > u_fragment_start , s - > fragment_width / 2 , s - > fragment_height / 2 ) ; reverse_dc_prediction ( s , s - > v_fragment_start , s - > fragment_width / 2 , s - > fragment_height / 2 ) ; } STOP_TIMER ( reverse_dc_prediction ) } { START_TIMER for ( i = 0 ; i < s - > macroblock_height ; i + + ) render_slice ( s , i ) ; STOP_TIMER ( render_fragments ) } { START_TIMER apply_loop_filter ( s ) ; STOP_TIMER ( apply_loop_filter ) } if KEYFRAMES_ONLY } endif * data_size=sizeof ( AVFrame",0
"void ff_h264_direct_dist_scale_factor ( H264Context * const h ) { const int poc = h - > cur_pic_ptr - > field_poc[h - > picture_structure == PICT_BOTTOM_FIELD] ; const int poc1 = h - > ref_list[1][0] . poc ; int i , field ; if ( FRAME_MBAFF ( h ) ) for ( field = 0 ; field < 2 ; field + + ) { const int poc = h - > cur_pic_ptr - > field_poc[field] ; const int poc1 = h - > ref_list[1][0] . field_poc[field] ; for ( i = 0 ; i < 2 * h - > ref_count[0] ; i + + ) h - > dist_scale_factor_field[field][i field] = get_scale_factor ( h , poc , poc1 , i + 16 ) ; } for ( i = 0 ; i < h - > ref_count[0] ; i + + ) h - > dist_scale_factor[i] = get_scale_factor ( h , poc , poc1 , i ) ; }",0
"static int read_packet ( AVFormatContext * s , AVPacket * pkt ) { PAFDemuxContext * p = s - > priv_data ; AVIOContext * pb = s - > pb ; uint32_t count , offset ; int size , i ; if ( p - > current_frame > = p - > nb_frames ) return AVERROR_EOF ; if ( url_feof ( pb ) ) return AVERROR_EOF ; if ( p - > got_audio ) { if ( av_new_packet ( pkt , p - > audio_size ) < 0 ) return AVERROR ( ENOMEM ) ; memcpy ( pkt - > data , p - > temp_audio_frame , p - > audio_size ) ; pkt - > duration = PAF_SOUND_SAMPLES * ( p - > audio_size / PAF_SOUND_FRAME_SIZE ) ; pkt - > flags |= AV_PKT_FLAG_KEY ; pkt - > stream_index = 1 ; p - > got_audio = 0 ; return pkt - > size ; } count = ( p - > current_frame == 0 ) ? p - > preload_count : p - > blocks_count_table[p - > current_frame - 1] ; for ( i = 0 ; i < count ; i + + ) { if ( p - > current_frame_block > = p - > frame_blks ) return AVERROR_INVALIDDATA ; offset = p - > blocks_offset_table[p - > current_frame_block] & ( 1U < < 31 ) ; if ( p - > blocks_offset_table[p - > current_frame_block] & ( 1U < < 31 ) ) { if ( offset > p - > audio_size - p - > buffer_size ) return AVERROR_INVALIDDATA ; avio_read ( pb , p - > audio_frame + offset , p - > buffer_size ) ; if ( offset == ( p - > max_audio_blks - 2 ) * p - > buffer_size ) { memcpy ( p - > temp_audio_frame , p - > audio_frame , p - > audio_size ) ; p - > got_audio = 1 ; } } else { if ( offset > p - > video_size - p - > buffer_size ) return AVERROR_INVALIDDATA ; avio_read ( pb , p - > video_frame + offset , p - > buffer_size ) ; } p - > current_frame_block + + ; } size = p - > video_size - p - > frames_offset_table[p - > current_frame] ; if ( size < 1 ) return AVERROR_INVALIDDATA ; if ( av_new_packet ( pkt , size ) < 0 ) return AVERROR ( ENOMEM ) ; pkt - > stream_index = 0 ; pkt - > duration = 1 ; memcpy ( pkt - > data , p - > video_frame + p - > frames_offset_table[p - > current_frame] , size ) ; if ( pkt - > data[0] & 0x20 ) pkt - > flags |= AV_PKT_FLAG_KEY ; p - > current_frame + + ; return pkt - > size ; }",1
"AVFormatContext * ff_rtp_chain_mux_open ( AVFormatContext * s , AVStream * st , URLContext * handle , int packet_size ) { AVFormatContext * rtpctx ; int ret ; AVOutputFormat * rtp_format = av_guess_format ( rtp , NULL , NULL ) ; if ( ! rtp_format ) return NULL ; / * Allocate an AVFormatContext for each output stream * / rtpctx = avformat_alloc_context ( ) ; if ( ! rtpctx ) return NULL ; rtpctx - > oformat = rtp_format ; if ( ! av_new_stream ( rtpctx , 0 ) ) { av_free ( rtpctx ) ; return NULL ; } / * Copy the max delay setting ; the rtp muxer reads this . * / rtpctx - > max_delay = s - > max_delay ; / * Copy other stream parameters . * / rtpctx - > streams[0] - > sample_aspect_ratio = st - > sample_aspect_ratio ; / * Set the synchronized start time . * / rtpctx - > start_time_realtime = s - > start_time_realtime ; / * Remove the local codec , link to the original codec * context instead , to give the rtp muxer access to * codec parameters . * / av_free ( rtpctx - > streams[0] - > codec ) ; rtpctx - > streams[0] - > codec = st - > codec ; if ( handle ) { url_fdopen ( & rtpctx - > pb , handle ) ; } else url_open_dyn_packet_buf ( & rtpctx - > pb , packet_size ) ; ret = av_write_header ( rtpctx ) ; if ( ret ) { if ( handle ) { url_fclose ( rtpctx - > pb ) ; } else { uint8_t * ptr ; url_close_dyn_buf ( rtpctx - > pb , & ptr ) ; av_free ( ptr ) ; } av_free ( rtpctx - > streams[0] ) ; av_free ( rtpctx ) ; return NULL ; } / * Copy the RTP AVStream timebase back to the original AVStream * / st - > time_base = rtpctx - > streams[0] - > time_base ; return rtpctx ; }",1
"static void rm_read_audio_stream_info ( AVFormatContext * s , AVStream * st , int read_all ) { RMContext * rm = s - > priv_data ; ByteIOContext * pb = & s - > pb ; char buf[256] ; uint32_t version ; int i ; / * ra type header * / version = get_be32 ( pb ) ; / * version * / if ( ( ( version > > 16 ) & 0xff ) == 3 ) { int64_t startpos = url_ftell ( pb ) ; / * very old version * / for ( i = 0 ; i < 14 ; i + + ) get_byte ( pb ) ; get_str8 ( pb , s - > title , sizeof ( s - > title ) ) ; get_str8 ( pb , s - > author , sizeof ( s - > author ) ) ; get_str8 ( pb , s - > copyright , sizeof ( s - > copyright ) ) ; get_str8 ( pb , s - > comment , sizeof ( s - > comment ) ) ; if ( ( startpos + ( version & 0xffff ) ) > = url_ftell ( pb ) + 2 ) { // fourcc ( should always be lpcJ ) get_byte ( pb ) ; get_str8 ( pb , buf , sizeof ( buf ) ) ; // Skip extra header crap ( this should never happen ) if ( ( startpos + ( version & 0xffff ) ) > url_ftell ( pb ) ) url_fskip ( pb , ( version & 0xffff ) + startpos - url_ftell ( pb ) ) ; st - > codec - > sample_rate = 8000 ; st - > codec - > channels = 1 ; st - > codec - > codec_type = CODEC_TYPE_AUDIO ; st - > codec - > codec_id = CODEC_ID_RA_144 ; } else { int flavor , sub_packet_h , coded_framesize , sub_packet_size ; / * old version ( 4 ) * / get_be32 ( pb ) ; / * . ra4 * / get_be32 ( pb ) ; / * data size * / get_be16 ( pb ) ; / * version2 * / get_be32 ( pb ) ; / * header size * / flavor= get_be16 ( pb ) ; / * add codec info / flavor * / rm - > coded_framesize = coded_framesize = get_be32 ( pb ) ; / * coded frame size * / get_be32 ( pb ) ; / * ? ? ? * / get_be32 ( pb ) ; / * ? ? ? * / get_be32 ( pb ) ; / * ? ? ? * / rm - > sub_packet_h = sub_packet_h = get_be16 ( pb ) ; / * 1 * / st - > codec - > block_align= get_be16 ( pb ) ; / * frame size * / rm - > sub_packet_size = sub_packet_size = get_be16 ( pb ) ; / * sub packet size * / get_be16 ( pb ) ; / * ? ? ? * / if ( ( ( version > > 16 ) & 0xff ) == 5 ) { get_be16 ( pb ) ; get_be16 ( pb ) ; get_be16 ( pb ) ; } st - > codec - > sample_rate = get_be16 ( pb ) ; get_be32 ( pb ) ; st - > codec - > channels = get_be16 ( pb ) ; if ( ( ( version > > 16 ) & 0xff ) == 5 ) { get_be32 ( pb ) ; buf[0] = get_byte ( pb ) ; buf[1] = get_byte ( pb ) ; buf[2] = get_byte ( pb ) ; buf[3] = get_byte ( pb ) ; buf[4] = 0 ; } else { get_str8 ( pb , buf , sizeof ( buf ) ) ; / * desc * / get_str8 ( pb , buf , sizeof ( buf ) ) ; / * desc * / st - > codec - > codec_type = CODEC_TYPE_AUDIO ; if ( ! strcmp ( buf , dnet ) ) { st - > codec - > codec_id = CODEC_ID_AC3 ; } else if ( ! strcmp ( buf , 28_8 ) ) { st - > codec - > codec_id = CODEC_ID_RA_288 ; st - > codec - > extradata_size= 0 ; rm - > audio_framesize = st - > codec - > block_align ; st - > codec - > block_align = coded_framesize ; rm - > audiobuf = av_malloc ( rm - > audio_framesize * sub_packet_h ) ; } else if ( ! strcmp ( buf , cook ) ) { int codecdata_length , i ; get_be16 ( pb ) ; get_byte ( pb ) ; if ( ( ( version > > 16 ) & 0xff ) == 5 ) get_byte ( pb ) ; codecdata_length = get_be32 ( pb ) ; if ( codecdata_length + FF_INPUT_BUFFER_PADDING_SIZE < = ( unsigned ) codecdata_length ) { av_log ( s , AV_LOG_ERROR , codecdata_length too large\n ) ; st - > codec - > codec_id = CODEC_ID_COOK ; st - > codec - > extradata_size= codecdata_length ; st - > codec - > extradata= av_mallocz ( st - > codec - > extradata_size + FF_INPUT_BUFFER_PADDING_SIZE ) ; for ( i = 0 ; i < codecdata_length ; i + + ) ( ( uint8_t * ) st - > codec - > extradata ) [i] = get_byte ( pb ) ; rm - > audio_framesize = st - > codec - > block_align ; st - > codec - > block_align = rm - > sub_packet_size ; rm - > audiobuf = av_malloc ( rm - > audio_framesize * sub_packet_h ) ; } else { st - > codec - > codec_id = CODEC_ID_NONE ; pstrcpy ( st - > codec - > codec_name , sizeof ( st - > codec - > codec_name ) , buf ) ; if ( read_all ) { get_byte ( pb ) ; get_byte ( pb ) ; get_byte ( pb ) ; get_str8 ( pb , s - > title , sizeof ( s - > title ) ) ; get_str8 ( pb , s - > author , sizeof ( s - > author ) ) ; get_str8 ( pb , s - > copyright , sizeof ( s - > copyright ) ) ; get_str8 ( pb , s - > comment , sizeof ( s - > comment ) ) ;",1
"static int vc1test_write_header ( AVFormatContext * s ) { AVCodecContext * avc = s - > streams[0] - > codec ; AVIOContext * pb = s - > pb ; if ( avc - > codec_id ! = CODEC_ID_WMV3 ) { av_log ( s , AV_LOG_ERROR , Only WMV3 is accepted ! \n ) ; return - 1 ; } avio_wl24 ( pb , 0 ) ; //frames count will be here avio_w8 ( pb , 0xC5 ) ; avio_wl32 ( pb , 4 ) ; avio_write ( pb , avc - > extradata , 4 ) ; avio_wl32 ( pb , avc - > height ) ; avio_wl32 ( pb , avc - > width ) ; avio_wl32 ( pb , 0xC ) ; avio_wl24 ( pb , 0 ) ; // hrd_buffer avio_w8 ( pb , 0x80 ) ; // level|cbr|res1 avio_wl32 ( pb , 0 ) ; // hrd_rate if ( s - > streams[0] - > r_frame_rate . den & & s - > streams[0] - > r_frame_rate . num == 1 ) avio_wl32 ( pb , s - > streams[0] - > r_frame_rate . den ) ; else avio_wl32 ( pb , 0xFFFFFFFF ) ; //variable framerate avpriv_set_pts_info ( s - > streams[0] , 32 , 1 , 1000 ) ; return 0 ; }",1
static int caca_write_trailer ( AVFormatContext * s ) { CACAContext * c = s - > priv_data ; av_freep ( & c - > window_title ) ; caca_free_dither ( c - > dither ) ; caca_free_display ( c - > display ) ; caca_free_canvas ( c - > canvas ) ; return 0 ; },1
"int av_parse_cpu_flags ( const char * s ) { define CPUFLAG_MMXEXT ( AV_CPU_FLAG_MMX | AV_CPU_FLAG_MMXEXT | AV_CPU_FLAG_CMOV ) define CPUFLAG_3DNOW ( AV_CPU_FLAG_3DNOW | AV_CPU_FLAG_MMX ) define CPUFLAG_3DNOWEXT ( AV_CPU_FLAG_3DNOWEXT | CPUFLAG_3DNOW ) define CPUFLAG_SSE ( AV_CPU_FLAG_SSE | CPUFLAG_MMXEXT ) define CPUFLAG_SSE2 ( AV_CPU_FLAG_SSE2 | CPUFLAG_SSE ) define CPUFLAG_SSE2SLOW ( AV_CPU_FLAG_SSE2SLOW | CPUFLAG_SSE2 ) define CPUFLAG_SSE3 ( AV_CPU_FLAG_SSE3 | CPUFLAG_SSE2 ) define CPUFLAG_SSE3SLOW ( AV_CPU_FLAG_SSE3SLOW | CPUFLAG_SSE3 ) define CPUFLAG_SSSE3 ( AV_CPU_FLAG_SSSE3 | CPUFLAG_SSE3 ) define CPUFLAG_SSE4 ( AV_CPU_FLAG_SSE4 | CPUFLAG_SSSE3 ) define CPUFLAG_SSE42 ( AV_CPU_FLAG_SSE42 | CPUFLAG_SSE4 ) define CPUFLAG_AVX ( AV_CPU_FLAG_AVX | CPUFLAG_SSE42 ) define CPUFLAG_AVXSLOW ( AV_CPU_FLAG_AVXSLOW | CPUFLAG_AVX ) define CPUFLAG_XOP ( AV_CPU_FLAG_XOP | CPUFLAG_AVX ) define CPUFLAG_FMA3 ( AV_CPU_FLAG_FMA3 | CPUFLAG_AVX ) define CPUFLAG_FMA4 ( AV_CPU_FLAG_FMA4 | CPUFLAG_AVX ) define CPUFLAG_AVX2 ( AV_CPU_FLAG_AVX2 | CPUFLAG_AVX ) define CPUFLAG_BMI2 ( AV_CPU_FLAG_BMI2 | AV_CPU_FLAG_BMI1 ) static const AVOption cpuflags_opts[] = { { flags , NULL , 0 , AV_OPT_TYPE_FLAGS , { . i64 = 0 } , INT64_MIN , INT64_MAX , . unit = flags } , if ARCH_PPC { altivec , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = AV_CPU_FLAG_ALTIVEC } , . unit = flags } , elif ARCH_X86 { mmx , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = AV_CPU_FLAG_MMX } , . unit = flags } , { mmxext , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = CPUFLAG_MMXEXT } , . unit = flags } , { sse , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = CPUFLAG_SSE } , . unit = flags } , { sse2 , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = CPUFLAG_SSE2 } , . unit = flags } , { sse2slow , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = CPUFLAG_SSE2SLOW } , . unit = flags } , { sse3 , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = CPUFLAG_SSE3 } , . unit = flags } , { sse3slow , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = CPUFLAG_SSE3SLOW } , . unit = flags } , { ssse3 , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = CPUFLAG_SSSE3 } , . unit = flags } , { atom , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = AV_CPU_FLAG_ATOM } , . unit = flags } , { sse4 . 1 , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = CPUFLAG_SSE4 } , . unit = flags } , { sse4 . 2 , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = CPUFLAG_SSE42 } , . unit = flags } , { avx , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = CPUFLAG_AVX } , . unit = flags } , { avxslow , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = CPUFLAG_AVXSLOW } , . unit = flags } , { xop , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = CPUFLAG_XOP } , . unit = flags } , { fma3 , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = CPUFLAG_FMA3 } , . unit = flags } , { fma4 , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = CPUFLAG_FMA4 } , . unit = flags } , { avx2 , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = CPUFLAG_AVX2 } , . unit = flags } , { bmi1 , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = AV_CPU_FLAG_BMI1 } , . unit = flags } , { bmi2 , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = CPUFLAG_BMI2 } , . unit = flags } , { 3dnow , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = CPUFLAG_3DNOW } , . unit = flags } , { 3dnowext , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = CPUFLAG_3DNOWEXT } , . unit = flags } , { cmov , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = AV_CPU_FLAG_CMOV } , . unit = flags } , elif ARCH_ARM { armv5te , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = AV_CPU_FLAG_ARMV5TE } , . unit = flags } , { armv6 , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = AV_CPU_FLAG_ARMV6 } , . unit = flags } , { armv6t2 , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = AV_CPU_FLAG_ARMV6T2 } , . unit = flags } , { vfp , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = AV_CPU_FLAG_VFP } , . unit = flags } , { vfpv3 , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = AV_CPU_FLAG_VFPV3 } , . unit = flags } , { neon , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = AV_CPU_FLAG_NEON } , . unit = flags } , elif ARCH_AARCH64 { armv8 , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = AV_CPU_FLAG_ARMV8 } , . unit = flags } , { neon , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = AV_CPU_FLAG_NEON } , . unit = flags } , { vfp , NULL , 0 , AV_OPT_TYPE_CONST , { . i64 = AV_CPU_FLAG_VFP } , . unit = flags } , endif { NULL } , } ; static const AVClass class = { . class_name = cpuflags , . item_name = av_default_item_name , . option = cpuflags_opts , . version = LIBAVUTIL_VERSION_INT , } ; int flags = 0 , ret ; const AVClass * pclass = & class ; if ( ( ret = av_opt_eval_flags ( & pclass , & cpuflags_opts[0] , s , & flags ) ) < 0 ) return ret ; return flags & INT_MAX ; }",1
"void mpeg1_init_vlc ( MpegEncContext * s ) { static int done = 0 ; if ( ! done ) { init_vlc ( & dc_lum_vlc , 9 , 12 , vlc_dc_lum_bits , 1 , 1 , vlc_dc_lum_code , 2 , 2 ) ; init_vlc ( & dc_chroma_vlc , 9 , 12 , vlc_dc_chroma_bits , 1 , 1 , vlc_dc_chroma_code , 2 , 2 ) ; init_vlc ( & mv_vlc , 9 , 17 , & mbMotionVectorTable[0][1] , 2 , 1 , & mbMotionVectorTable[0][0] , 2 , 1 ) ; init_vlc ( & mbincr_vlc , 9 , 35 , & mbAddrIncrTable[0][1] , 2 , 1 , & mbAddrIncrTable[0][0] , 2 , 1 ) ; init_vlc ( & mb_pat_vlc , 9 , 63 , & mbPatTable[0][1] , 2 , 1 , & mbPatTable[0][0] , 2 , 1 ) ; init_vlc ( & mb_ptype_vlc , 6 , 32 , & table_mb_ptype[0][1] , 2 , 1 , & table_mb_ptype[0][0] , 2 , 1 ) ; init_vlc ( & mb_btype_vlc , 6 , 32 , & table_mb_btype[0][1] , 2 , 1 , & table_mb_btype[0][0] , 2 , 1 ) ; init_rl ( & rl_mpeg1 ) ; init_rl ( & rl_mpeg2 ) ; / * cannot use generic init because we must add the EOB code * / init_vlc ( & rl_mpeg1 . vlc , 9 , rl_mpeg1 . n + 2 , & rl_mpeg1 . table_vlc[0][1] , 4 , 2 , & rl_mpeg1 . table_vlc[0][0] , 4 , 2 ) ; init_vlc ( & rl_mpeg2 . vlc , 9 , rl_mpeg2 . n + 2 , & rl_mpeg2 . table_vlc[0][1] , 4 , 2 , & rl_mpeg2 . table_vlc[0][0] , 4 , 2 ) ; } }",1
"static int encode_bitstream ( FlashSVContext * s , const AVFrame * p , uint8_t * buf , int buf_size , int block_width , int block_height , uint8_t * previous_frame , int * I_frame ) { PutBitContext pb ; int h_blocks , v_blocks , h_part , v_part , i , j ; int buf_pos , res ; int pred_blocks = 0 ; init_put_bits ( & pb , buf , buf_size * 8 ) ; put_bits ( & pb , 4 , block_width / 16 - 1 ) ; put_bits ( & pb , 12 , s - > image_width ) ; put_bits ( & pb , 4 , block_height / 16 - 1 ) ; put_bits ( & pb , 12 , s - > image_height ) ; flush_put_bits ( & pb ) ; buf_pos = 4 ; h_blocks = s - > image_width / block_width ; h_part = s - > image_width % block_width ; v_blocks = s - > image_height / block_height ; v_part = s - > image_height % block_height ; / * loop over all block columns * / for ( j = 0 ; j < v_blocks + ( v_part ? 1 : 0 ) ; j + + ) { int y_pos = j * block_height ; // vertical position in frame int cur_blk_height = ( j < v_blocks ) ? block_height : v_part ; / * loop over all block rows * / for ( i = 0 ; i < h_blocks + ( h_part ? 1 : 0 ) ; i + + ) { int x_pos = i * block_width ; // horizontal position in frame int cur_blk_width = ( i < h_blocks ) ? block_width : h_part ; int ret = Z_OK ; uint8_t * ptr = buf + buf_pos ; / * copy the block to the temp buffer before compression * ( if it differs from the previous frame ' s block ) * / res = copy_region_enc ( p - > data[0] , s - > tmpblock , s - > image_height - ( y_pos + cur_blk_height + 1 ) , x_pos , cur_blk_height , cur_blk_width , p - > linesize[0] , previous_frame ) ; if ( res || * I_frame ) { unsigned long zsize = 3 * block_width * block_height ; ret = compress2 ( ptr + 2 , & zsize , s - > tmpblock , 3 * cur_blk_width * cur_blk_height , 9 ) ; //ret = deflateReset ( & s - > zstream ) ; if ( ret ! = Z_OK ) av_log ( s - > avctx , AV_LOG_ERROR , error while compressing block %dx%d\n , i , j ) ; bytestream_put_be16 ( & ptr , zsize ) ; buf_pos + = zsize + 2 ; av_dlog ( s - > avctx , buf_pos = %d\n , buf_pos ) ; } else { pred_blocks + + ; bytestream_put_be16 ( & ptr , 0 ) ; buf_pos + = 2 ; } } } if ( pred_blocks ) * I_frame = 0 ; else * I_frame = 1 ; return buf_pos ; }",1
"static int smc_decode_init ( AVCodecContext * avctx ) { SmcContext * s = avctx - > priv_data ; s - > avctx = avctx ; avctx - > pix_fmt = PIX_FMT_PAL8 ; dsputil_init ( & s - > dsp , avctx ) ; s - > frame . data[0] = NULL ; return 0 ; }",0
"int ff_mov_add_hinted_packet ( AVFormatContext * s , AVPacket * pkt , int track_index , int sample ) { MOVMuxContext * mov = s - > priv_data ; MOVTrack * trk = & mov - > tracks[track_index] ; AVFormatContext * rtp_ctx = trk - > rtp_ctx ; uint8_t * buf = NULL ; int size ; AVIOContext * hintbuf = NULL ; AVPacket hint_pkt ; int ret = 0 , count ; if ( ! rtp_ctx ) return AVERROR ( ENOENT ) ; if ( ! rtp_ctx - > pb ) return AVERROR ( ENOMEM ) ; sample_queue_push ( & trk - > sample_queue , pkt , sample ) ; / * Feed the packet to the RTP muxer * / ff_write_chained ( rtp_ctx , 0 , pkt , s ) ; / * Fetch the output from the RTP muxer , open a new output buffer * for next time . * / size = avio_close_dyn_buf ( rtp_ctx - > pb , & buf ) ; if ( ( ret = url_open_dyn_packet_buf ( & rtp_ctx - > pb , RTP_MAX_PACKET_SIZE ) ) < 0 ) goto done ; if ( size < = 0 ) goto done ; / * Open a buffer for writing the hint * / if ( ( ret = avio_open_dyn_buf ( & hintbuf ) ) < 0 ) goto done ; av_init_packet ( & hint_pkt ) ; count = write_hint_packets ( hintbuf , buf , size , trk , & hint_pkt . dts ) ; av_freep ( & buf ) ; / * Write the hint data into the hint track * / hint_pkt . size = size = avio_close_dyn_buf ( hintbuf , & buf ) ; hint_pkt . data = buf ; hint_pkt . pts = hint_pkt . dts ; hint_pkt . stream_index = track_index ; if ( pkt - > flags & AV_PKT_FLAG_KEY ) hint_pkt . flags |= AV_PKT_FLAG_KEY ; if ( count > 0 ) ff_mov_write_packet ( s , & hint_pkt ) ; done : av_free ( buf ) ; sample_queue_retain ( & trk - > sample_queue ) ; return ret ; }",0
"static void decode_lowdelay ( DiracContext * s ) { AVCodecContext * avctx = s - > avctx ; int slice_x , slice_y , bytes , bufsize ; const uint8_t * buf ; struct lowdelay_slice * slices ; int slice_num = 0 ; slices = av_mallocz_array ( s - > lowdelay . num_x , s - > lowdelay . num_y * sizeof ( struct lowdelay_slice ) ) ; align_get_bits ( & s - > gb ) ; / * [DIRAC_STD] 13 . 5 . 2 Slices . slice ( sx , sy ) * / buf = s - > gb . buffer + get_bits_count ( & s - > gb ) /8 ; bufsize = get_bits_left ( & s - > gb ) ; for ( slice_y = 0 ; bufsize > 0 & & slice_y < s - > lowdelay . num_y ; slice_y + + ) for ( slice_x = 0 ; bufsize > 0 & & slice_x < s - > lowdelay . num_x ; slice_x + + ) { bytes = ( slice_num + 1 ) * s - > lowdelay . bytes . num / s - > lowdelay . bytes . den - slice_num * s - > lowdelay . bytes . num / s - > lowdelay . bytes . den ; slices[slice_num] . bytes = bytes ; slices[slice_num] . slice_x = slice_x ; slices[slice_num] . slice_y = slice_y ; init_get_bits ( & slices[slice_num] . gb , buf , bufsize ) ; slice_num + + ; buf + = bytes ; bufsize - = bytes * 8 ; } avctx - > execute ( avctx , decode_lowdelay_slice , slices , NULL , slice_num , sizeof ( struct lowdelay_slice ) ) ; / * [DIRAC_STD] 13 . 5 . 2 Slices * / intra_dc_prediction ( & s - > plane[0] . band[0][0] ) ; / * [DIRAC_STD] 13 . 3 intra_dc_prediction ( ) * / intra_dc_prediction ( & s - > plane[1] . band[0][0] ) ; / * [DIRAC_STD] 13 . 3 intra_dc_prediction ( ) * / intra_dc_prediction ( & s - > plane[2] . band[0][0] ) ; / * [DIRAC_STD] 13 . 3 intra_dc_prediction ( ) * / av_free ( slices ) ; }",0
"static void copy_video_props ( AVFilterBufferRefVideoProps * dst , AVFilterBufferRefVideoProps * src ) { * dst = * src ; if ( src - > qp_table ) { int qsize = src - > qp_table_size ; dst - > qp_table = av_malloc ( qsize ) ; memcpy ( dst - > qp_table , src - > qp_table , qsize ) ; } }",1
"int attribute_align_arg avcodec_encode_audio2 ( AVCodecContext * avctx , AVPacket * avpkt , const AVFrame * frame , int * got_packet_ptr ) { int ret ; int user_packet = ! ! avpkt - > data ; int nb_samples ; * got_packet_ptr = 0 ; if ( ! ( avctx - > codec - > capabilities & CODEC_CAP_DELAY ) & & ! frame ) { av_free_packet ( avpkt ) ; av_init_packet ( avpkt ) ; avpkt - > size = 0 ; return 0 ; } / * check for valid frame size * / if ( frame ) { nb_samples = frame - > nb_samples ; if ( avctx - > codec - > capabilities & CODEC_CAP_SMALL_LAST_FRAME ) { if ( nb_samples > avctx - > frame_size ) return AVERROR ( EINVAL ) ; } else if ( ! ( avctx - > codec - > capabilities & CODEC_CAP_VARIABLE_FRAME_SIZE ) ) { if ( nb_samples ! = avctx - > frame_size ) return AVERROR ( EINVAL ) ; } } else { nb_samples = avctx - > frame_size ; } if ( avctx - > codec - > encode2 ) { ret = avctx - > codec - > encode2 ( avctx , avpkt , frame , got_packet_ptr ) ; if ( ! ret & & * got_packet_ptr ) { if ( ! ( avctx - > codec - > capabilities & CODEC_CAP_DELAY ) ) { if ( avpkt - > pts == AV_NOPTS_VALUE ) avpkt - > pts = frame - > pts ; if ( ! avpkt - > duration ) avpkt - > duration = ff_samples_to_time_base ( avctx , frame - > nb_samples ) ; } avpkt - > dts = avpkt - > pts ; } else { avpkt - > size = 0 ; } } else { / * for compatibility with encoders not supporting encode2 ( ) , we need to allocate a packet buffer if the user has not provided one or check the size otherwise * / int fs_tmp = 0 ; int buf_size = avpkt - > size ; if ( ! user_packet ) { if ( avctx - > codec - > capabilities & CODEC_CAP_VARIABLE_FRAME_SIZE ) { av_assert0 ( av_get_bits_per_sample ( avctx - > codec_id ) ! = 0 ) ; buf_size = nb_samples * avctx - > channels * av_get_bits_per_sample ( avctx - > codec_id ) / 8 ; } else { / * this is a guess as to the required size . if an encoder needs more than this , it should probably implement encode2 ( ) * / buf_size = 2 * avctx - > frame_size * avctx - > channels * av_get_bytes_per_sample ( avctx - > sample_fmt ) ; buf_size + = FF_MIN_BUFFER_SIZE ; } } if ( ( ret = ff_alloc_packet ( avpkt , buf_size ) ) ) return ret ; / * Encoders using AVCodec . encode ( ) that support CODEC_CAP_SMALL_LAST_FRAME require avctx - > frame_size to be set to the smaller size when encoding the last frame . This code can be removed once all encoders supporting CODEC_CAP_SMALL_LAST_FRAME use encode2 ( ) * / if ( ( avctx - > codec - > capabilities & CODEC_CAP_SMALL_LAST_FRAME ) & & nb_samples < avctx - > frame_size ) { fs_tmp = avctx - > frame_size ; avctx - > frame_size = nb_samples ; } / * encode the frame * / ret = avctx - > codec - > encode ( avctx , avpkt - > data , avpkt - > size , frame ? frame - > data[0] : NULL ) ; if ( ret > = 0 ) { if ( ! ret ) { / * no output . if the packet data was allocated by libavcodec , free it * / if ( ! user_packet ) av_freep ( & avpkt - > data ) ; } else { if ( avctx - > coded_frame ) avpkt - > pts = avpkt - > dts = avctx - > coded_frame - > pts ; / * Set duration for final small packet . This can be removed once all encoders supporting CODEC_CAP_SMALL_LAST_FRAME use encode2 ( ) * / if ( fs_tmp ) { avpkt - > duration = ff_samples_to_time_base ( avctx , avctx - > frame_size ) ; } } avpkt - > size = ret ; * got_packet_ptr = ( ret > 0 ) ; ret = 0 ; } if ( fs_tmp ) avctx - > frame_size = fs_tmp ; } if ( ! ret ) { if ( ! user_packet & & avpkt - > data ) { uint8_t * new_data = av_realloc ( avpkt - > data , avpkt - > size ) ; if ( new_data ) avpkt - > data = new_data ; } avctx - > frame_number + + ; } if ( ret < 0 || ! * got_packet_ptr ) av_free_packet ( avpkt ) ; / * NOTE : if we add any audio encoders which output non - keyframe packets , this needs to be moved to the encoders , but for now we can do it here to simplify things * / avpkt - > flags |= AV_PKT_FLAG_KEY ; return ret ; }",1
"static int matroska_parse_frame ( MatroskaDemuxContext * matroska , MatroskaTrack * track , AVStream * st , uint8_t * data , int pkt_size , uint64_t timecode , uint64_t duration , int64_t pos , int is_keyframe ) { MatroskaTrackEncoding * encodings = track - > encodings . elem ; uint8_t * pkt_data = data ; int offset = 0 , res ; AVPacket * pkt ; if ( encodings & & encodings - > scope & 1 ) { res = matroska_decode_buffer ( & pkt_data , & pkt_size , track ) ; if ( res < 0 ) return res ; } if ( st - > codec - > codec_id == AV_CODEC_ID_WAVPACK ) { uint8_t * wv_data ; res = matroska_parse_wavpack ( track , pkt_data , & wv_data , & pkt_size ) ; if ( res < 0 ) { av_log ( matroska - > ctx , AV_LOG_ERROR , Error parsing a wavpack block . \n ) ; goto fail ; } if ( pkt_data ! = data ) pkt_data = wv_data ; } if ( st - > codec - > codec_id == AV_CODEC_ID_PRORES ) offset = 8 ; pkt = av_mallocz ( sizeof ( AVPacket ) ) ; / * XXX : prevent data copy . . . * / if ( av_new_packet ( pkt , pkt_size + offset ) < 0 ) { av_free ( pkt ) ; return AVERROR ( ENOMEM ) ; } if ( st - > codec - > codec_id == AV_CODEC_ID_PRORES ) { uint8_t * buf = pkt - > data ; bytestream_put_be32 ( & buf , pkt_size ) ; bytestream_put_be32 ( & buf , MKBETAG ( ' i ' , ' c ' , ' p ' , ' f ' ) ) ; } memcpy ( pkt - > data + offset , pkt_data , pkt_size ) ; if ( pkt_data ! = data ) av_free ( pkt_data ) ; pkt - > flags = is_keyframe ; pkt - > stream_index = st - > index ; if ( track - > ms_compat ) pkt - > dts = timecode ; else pkt - > pts = timecode ; pkt - > pos = pos ; if ( st - > codec - > codec_id == AV_CODEC_ID_TEXT ) pkt - > convergence_duration = duration ; else if ( track - > type ! = MATROSKA_TRACK_TYPE_SUBTITLE ) pkt - > duration = duration ; if ( st - > codec - > codec_id == AV_CODEC_ID_SSA ) matroska_fix_ass_packet ( matroska , pkt , duration ) ; if ( matroska - > prev_pkt & & timecode ! = AV_NOPTS_VALUE & & matroska - > prev_pkt - > pts == timecode & & matroska - > prev_pkt - > stream_index == st - > index & & st - > codec - > codec_id == AV_CODEC_ID_SSA ) matroska_merge_packets ( matroska - > prev_pkt , pkt ) ; else { dynarray_add ( & matroska - > packets , & matroska - > num_packets , pkt ) ; matroska - > prev_pkt = pkt ; } return 0 ; fail : if ( pkt_data ! = data ) return res ; }",1
"void * av_fast_realloc ( void * ptr , unsigned int * size , unsigned int min_size ) { if ( min_size < * size ) return ptr ; * size= 17 * min_size/16 + 32 ; return av_realloc ( ptr , * size ) ; }",1
"static int get_video_frame ( VideoState * is , AVFrame * frame , int64_t * pts , AVPacket * pkt , int * serial ) { int got_picture ; if ( packet_queue_get ( & is - > videoq , pkt , 1 , serial ) < 0 ) return - 1 ; if ( pkt - > data == flush_pkt . data ) { avcodec_flush_buffers ( is - > video_st - > codec ) ; SDL_LockMutex ( is - > pictq_mutex ) ; // Make sure there are no long delay timers ( ideally we should just flush the queue but that ' s harder ) while ( is - > pictq_size & & ! is - > videoq . abort_request ) { SDL_CondWait ( is - > pictq_cond , is - > pictq_mutex ) ; } is - > video_current_pos = - 1 ; is - > frame_last_pts = AV_NOPTS_VALUE ; is - > frame_last_duration = 0 ; is - > frame_timer = ( double ) av_gettime ( ) / 1000000 . 0 ; is - > frame_last_dropped_pts = AV_NOPTS_VALUE ; SDL_UnlockMutex ( is - > pictq_mutex ) ; return 0 ; } if ( avcodec_decode_video2 ( is - > video_st - > codec , frame , & got_picture , pkt ) < 0 ) return 0 ; if ( got_picture ) { int ret = 1 ; if ( decoder_reorder_pts == - 1 ) { * pts = av_frame_get_best_effort_timestamp ( frame ) ; } else if ( decoder_reorder_pts ) { * pts = frame - > pkt_pts ; } else { * pts = frame - > pkt_dts ; } if ( * pts == AV_NOPTS_VALUE ) { * pts = 0 ; } if ( framedrop > 0 || ( framedrop & & get_master_sync_type ( is ) ! = AV_SYNC_VIDEO_MASTER ) ) { SDL_LockMutex ( is - > pictq_mutex ) ; if ( is - > frame_last_pts ! = AV_NOPTS_VALUE & & * pts ) { double clockdiff = get_video_clock ( is ) - get_master_clock ( is ) ; double dpts = av_q2d ( is - > video_st - > time_base ) * * pts ; double ptsdiff = dpts - is - > frame_last_pts ; if ( fabs ( clockdiff ) < AV_NOSYNC_THRESHOLD & & ptsdiff > 0 & & ptsdiff < AV_NOSYNC_THRESHOLD & & clockdiff + ptsdiff - is - > frame_last_filter_delay < 0 ) { is - > frame_last_dropped_pos = pkt - > pos ; is - > frame_last_dropped_pts = dpts ; is - > frame_drops_early + + ; ret = 0 ; } } SDL_UnlockMutex ( is - > pictq_mutex ) ; } return ret ; } return 0 ; }",0
"int ff_fft_init ( FFTContext * s , int nbits , int inverse ) { int i , j , m , n ; float alpha , c1 , s1 , s2 ; int shuffle = 0 ; int av_unused has_vectors ; s - > nbits = nbits ; n = 1 < < nbits ; s - > exptab = av_malloc ( ( n / 2 ) * sizeof ( FFTComplex ) ) ; if ( ! s - > exptab ) goto fail ; s - > revtab = av_malloc ( n * sizeof ( uint16_t ) ) ; if ( ! s - > revtab ) goto fail ; s - > inverse = inverse ; s2 = inverse ? 1 . 0 : - 1 . 0 ; for ( i=0 ; i < ( n/2 ) ; i + + ) { alpha = 2 * M_PI * ( float ) i / ( float ) n ; c1 = cos ( alpha ) ; s1 = sin ( alpha ) * s2 ; s - > exptab[i] . re = c1 ; s - > exptab[i] . im = s1 ; } s - > fft_calc = ff_fft_calc_c ; s - > imdct_calc = ff_imdct_calc ; s - > imdct_half = ff_imdct_half ; s - > exptab1 = NULL ; ifdef HAVE_MMX has_vectors = mm_support ( ) ; shuffle = 1 ; if ( has_vectors & MM_3DNOWEXT ) { / * 3DNowEx for K7/K8 * / s - > imdct_calc = ff_imdct_calc_3dn2 ; s - > fft_calc = ff_fft_calc_3dn2 ; } else if ( has_vectors & MM_3DNOW ) { / * 3DNow ! for K6 - 2/3 * / s - > fft_calc = ff_fft_calc_3dn ; } else if ( has_vectors & MM_SSE ) { / * SSE for P3/P4 * / s - > imdct_calc = ff_imdct_calc_sse ; s - > imdct_half = ff_imdct_half_sse ; s - > fft_calc = ff_fft_calc_sse ; } else { shuffle = 0 ; } elif defined HAVE_ALTIVEC & & ! defined ALTIVEC_USE_REFERENCE_C_CODE has_vectors = mm_support ( ) ; if ( has_vectors & MM_ALTIVEC ) { s - > fft_calc = ff_fft_calc_altivec ; shuffle = 1 ; } endif / * compute constant table for HAVE_SSE version * / if ( shuffle ) { int np , nblocks , np2 , l ; FFTComplex * q ; np = 1 < < nbits ; nblocks = np > > 3 ; np2 = np > > 1 ; s - > exptab1 = av_malloc ( np * 2 * sizeof ( FFTComplex ) ) ; if ( ! s - > exptab1 ) goto fail ; q = s - > exptab1 ; do { for ( l = 0 ; l < np2 ; l + = 2 * nblocks ) { * q + + = s - > exptab[l] ; * q + + = s - > exptab[l + nblocks] ; q - > re = - s - > exptab[l] . im ; q - > im = s - > exptab[l] . re ; q + + ; q - > re = - s - > exptab[l + nblocks] . im ; q - > im = s - > exptab[l + nblocks] . re ; q + + ; } nblocks = nblocks > > 1 ; } while ( nblocks ! = 0 ) ; av_freep ( & s - > exptab ) ; } / * compute bit reverse table * / for ( i=0 ; i < n ; i + + ) { m=0 ; for ( j=0 ; j < nbits ; j + + ) { m |= ( ( i > > j ) & 1 ) < < ( nbits - j - 1 ) ; } s - > revtab[i]=m ; } return 0 ; fail : av_freep ( & s - > revtab ) ; av_freep ( & s - > exptab ) ; av_freep ( & s - > exptab1 ) ; return - 1 ; }",1
"static void write_mainheader ( NUTContext * nut , AVIOContext * bc ) { int i , j , tmp_pts , tmp_flags , tmp_stream , tmp_mul , tmp_size , tmp_fields , tmp_head_idx ; int64_t tmp_match ; ff_put_v ( bc , nut - > version ) ; if ( nut - > version > 3 ) ff_put_v ( bc , nut - > minor_version ) ; ff_put_v ( bc , nut - > avf - > nb_streams ) ; ff_put_v ( bc , nut - > max_distance ) ; ff_put_v ( bc , nut - > time_base_count ) ; for ( i = 0 ; i < nut - > time_base_count ; i + + ) { ff_put_v ( bc , nut - > time_base[i] . num ) ; ff_put_v ( bc , nut - > time_base[i] . den ) ; } tmp_pts = 0 ; tmp_mul = 1 ; tmp_stream = 0 ; tmp_match = 1 - ( 1LL < < 62 ) ; tmp_head_idx = 0 ; for ( i = 0 ; i < 256 ; ) { tmp_fields = 0 ; tmp_size = 0 ; // tmp_res=0 ; if ( tmp_pts ! = nut - > frame_code[i] . pts_delta ) tmp_fields = 1 ; if ( tmp_mul ! = nut - > frame_code[i] . size_mul ) tmp_fields = 2 ; if ( tmp_stream ! = nut - > frame_code[i] . stream_id ) tmp_fields = 3 ; if ( tmp_size ! = nut - > frame_code[i] . size_lsb ) tmp_fields = 4 ; // if ( tmp_res ! = nut - > frame_code[i] . res ) tmp_fields=5 ; if ( tmp_head_idx ! = nut - > frame_code[i] . header_idx ) tmp_fields = 8 ; tmp_pts = nut - > frame_code[i] . pts_delta ; tmp_flags = nut - > frame_code[i] . flags ; tmp_stream = nut - > frame_code[i] . stream_id ; tmp_mul = nut - > frame_code[i] . size_mul ; tmp_size = nut - > frame_code[i] . size_lsb ; // tmp_res = nut - > frame_code[i] . res ; tmp_head_idx = nut - > frame_code[i] . header_idx ; for ( j = 0 ; i < 256 ; j + + , i + + ) { if ( i == ' N ' ) { j - - ; continue ; } if ( nut - > frame_code[i] . pts_delta ! = tmp_pts || nut - > frame_code[i] . flags ! = tmp_flags || nut - > frame_code[i] . stream_id ! = tmp_stream || nut - > frame_code[i] . size_mul ! = tmp_mul || nut - > frame_code[i] . size_lsb ! = tmp_size + j || // nut - > frame_code[i] . res ! = tmp_res || nut - > frame_code[i] . header_idx ! = tmp_head_idx ) break ; } if ( j ! = tmp_mul - tmp_size ) tmp_fields = 6 ; ff_put_v ( bc , tmp_flags ) ; ff_put_v ( bc , tmp_fields ) ; if ( tmp_fields > 0 ) put_s ( bc , tmp_pts ) ; if ( tmp_fields > 1 ) ff_put_v ( bc , tmp_mul ) ; if ( tmp_fields > 2 ) ff_put_v ( bc , tmp_stream ) ; if ( tmp_fields > 3 ) ff_put_v ( bc , tmp_size ) ; if ( tmp_fields > 4 ) ff_put_v ( bc , 0 / * tmp_res * / ) ; if ( tmp_fields > 5 ) ff_put_v ( bc , j ) ; if ( tmp_fields > 6 ) ff_put_v ( bc , tmp_match ) ; if ( tmp_fields > 7 ) ff_put_v ( bc , tmp_head_idx ) ; } ff_put_v ( bc , nut - > header_count - 1 ) ; for ( i = 1 ; i < nut - > header_count ; i + + ) { ff_put_v ( bc , nut - > header_len[i] ) ; avio_write ( bc , nut - > header[i] , nut - > header_len[i] ) ; } // flags had been effectively introduced in version 4 if ( nut - > version > NUT_STABLE_VERSION ) ff_put_v ( bc , nut - > flags ) ; }",0
"static void flat_print_key_prefix ( WriterContext * wctx ) { FlatContext * flat = wctx - > priv ; const struct section * parent_section = wctx - > section[wctx - > level - 1] ; printf ( %s , flat - > section_header[wctx - > level] . str ) ; if ( parent_section - > flags & SECTION_FLAG_IS_ARRAY ) { int n = parent_section - > id == SECTION_ID_PACKETS_AND_FRAMES ? wctx - > nb_section_packet_frame : wctx - > nb_item[wctx - > level - 1] ; printf ( %d%s , n , flat - > sep_str ) ; } }",0
"static int mov_text_decode_frame ( AVCodecContext * avctx , void * data , int * got_sub_ptr , AVPacket * avpkt ) { AVSubtitle * sub = data ; MovTextContext * m = avctx - > priv_data ; int ret ; AVBPrint buf ; char * ptr = avpkt - > data ; char * end ; int text_length , tsmb_type , ret_tsmb ; uint64_t tsmb_size ; const uint8_t * tsmb ; if ( ! ptr || avpkt - > size < 2 ) return AVERROR_INVALIDDATA ; / * * A packet of size two with value zero is an empty subtitle * used to mark the end of the previous non - empty subtitle . * We can just drop them here as we have duration information * already . If the value is non - zero , then it ' s technically a * bad packet . * / if ( avpkt - > size == 2 ) return AV_RB16 ( ptr ) == 0 ? 0 : AVERROR_INVALIDDATA ; / * * The first two bytes of the packet are the length of the text string * In complex cases , there are style descriptors appended to the string * so we can ' t just assume the packet size is the string size . * / text_length = AV_RB16 ( ptr ) ; end = ptr + FFMIN ( 2 + text_length , avpkt - > size ) ; ptr + = 2 ; tsmb_size = 0 ; m - > tracksize = 2 + text_length ; m - > style_entries = 0 ; m - > box_flags = 0 ; m - > count_s = 0 ; // Note that the spec recommends lines be no longer than 2048 characters . av_bprint_init ( & buf , 0 , AV_BPRINT_SIZE_UNLIMITED ) ; if ( text_length + 2 ! = avpkt - > size ) { while ( m - > tracksize + 8 < = avpkt - > size ) { // A box is a minimum of 8 bytes . tsmb = ptr + m - > tracksize - 2 ; tsmb_size = AV_RB32 ( tsmb ) ; tsmb + = 4 ; tsmb_type = AV_RB32 ( tsmb ) ; tsmb + = 4 ; if ( tsmb_size == 1 ) { if ( m - > tracksize + 16 > avpkt - > size ) break ; tsmb_size = AV_RB64 ( tsmb ) ; tsmb + = 8 ; m - > size_var = 16 ; } else m - > size_var = 8 ; //size_var is equal to 8 or 16 depending on the size of box if ( tsmb_size == 0 ) { av_log ( avctx , AV_LOG_ERROR , tsmb_size is 0\n ) ; return AVERROR_INVALIDDATA ; } if ( tsmb_size > avpkt - > size - m - > tracksize ) break ; for ( size_t i = 0 ; i < box_count ; i + + ) { if ( tsmb_type == box_types[i] . type ) { if ( m - > tracksize + m - > size_var + box_types[i] . base_size > avpkt - > size ) break ; ret_tsmb = box_types[i] . decode ( tsmb , m , avpkt ) ; if ( ret_tsmb == - 1 ) break ; } } m - > tracksize = m - > tracksize + tsmb_size ; } text_to_ass ( & buf , ptr , end , m ) ; } else text_to_ass ( & buf , ptr , end , m ) ; ret = ff_ass_add_rect ( sub , buf . str , m - > readorder + + , 0 , NULL , NULL ) ; av_bprint_finalize ( & buf , NULL ) ; if ( ret < 0 ) return ret ; * got_sub_ptr = sub - > num_rects > 0 ; return avpkt - > size ; }",1
"static int ra144_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame_ptr , AVPacket * avpkt ) { AVFrame * frame = data ; const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; static const uint8_t sizes[LPC_ORDER] = { 6 , 5 , 5 , 4 , 4 , 3 , 3 , 3 , 3 , 2 } ; unsigned int refl_rms[NBLOCKS] ; // RMS of the reflection coefficients int16_t block_coefs[NBLOCKS][LPC_ORDER] ; // LPC coefficients of each sub - block unsigned int lpc_refl[LPC_ORDER] ; // LPC reflection coefficients of the frame int i , j ; int ret ; int16_t * samples ; unsigned int energy ; RA144Context * ractx = avctx - > priv_data ; GetBitContext gb ; if ( buf_size < FRAME_SIZE ) { av_log ( avctx , AV_LOG_ERROR , Frame too small ( %d bytes ) . Truncated file ? \n , buf_size ) ; * got_frame_ptr = 0 ; return AVERROR_INVALIDDATA ; } / * get output buffer * / frame - > nb_samples = NBLOCKS * BLOCKSIZE ; if ( ( ret = ff_get_buffer ( avctx , frame , 0 ) ) < 0 ) return ret ; samples = ( int16_t * ) frame - > data[0] ; init_get_bits8 ( & gb , buf , FRAME_SIZE ) ; for ( i = 0 ; i < LPC_ORDER ; i + + ) lpc_refl[i] = ff_lpc_refl_cb[i][get_bits ( & gb , sizes[i] ) ] ; ff_eval_coefs ( ractx - > lpc_coef[0] , lpc_refl ) ; ractx - > lpc_refl_rms[0] = ff_rms ( lpc_refl ) ; energy = ff_energy_tab[get_bits ( & gb , 5 ) ] ; refl_rms[0] = ff_interp ( ractx , block_coefs[0] , 1 , 1 , ractx - > old_energy ) ; refl_rms[1] = ff_interp ( ractx , block_coefs[1] , 2 , energy < = ractx - > old_energy , ff_t_sqrt ( energy * ractx - > old_energy ) > > 12 ) ; refl_rms[2] = ff_interp ( ractx , block_coefs[2] , 3 , 0 , energy ) ; refl_rms[3] = ff_rescale_rms ( ractx - > lpc_refl_rms[0] , energy ) ; ff_int_to_int16 ( block_coefs[3] , ractx - > lpc_coef[0] ) ; for ( i=0 ; i < NBLOCKS ; i + + ) { do_output_subblock ( ractx , block_coefs[i] , refl_rms[i] , & gb ) ; for ( j=0 ; j < BLOCKSIZE ; j + + ) * samples + + = av_clip_int16 ( ractx - > curr_sblock[j + 10] < < 2 ) ; } ractx - > old_energy = energy ; ractx - > lpc_refl_rms[1] = ractx - > lpc_refl_rms[0] ; FFSWAP ( unsigned int * , ractx - > lpc_coef[0] , ractx - > lpc_coef[1] ) ; * got_frame_ptr = 1 ; return FRAME_SIZE ; }",1
"static int sdp_parse_fmtp_config_h264 ( AVStream * stream , PayloadContext * h264_data , char * attr , char * value ) { AVCodecContext * codec = stream - > codec ; assert ( codec - > codec_id == CODEC_ID_H264 ) ; assert ( h264_data ! = NULL ) ; if ( ! strcmp ( attr , packetization - mode ) ) { av_log ( codec , AV_LOG_DEBUG , RTP Packetization Mode : %d\n , atoi ( value ) ) ; h264_data - > packetization_mode = atoi ( value ) ; / * * Packetization Mode : * 0 or not present : Single NAL mode ( Only nals from 1 - 23 are allowed ) * 1 : Non - interleaved Mode : 1 - 23 , 24 ( STAP - A ) , 28 ( FU - A ) are allowed . * 2 : Interleaved Mode : 25 ( STAP - B ) , 26 ( MTAP16 ) , 27 ( MTAP24 ) , 28 ( FU - A ) , * and 29 ( FU - B ) are allowed . * / if ( h264_data - > packetization_mode > 1 ) av_log ( codec , AV_LOG_ERROR , Interleaved RTP mode is not supported yet . ) ; } else if ( ! strcmp ( attr , profile - level - id ) ) { if ( strlen ( value ) == 6 ) { char buffer[3] ; // 6 characters=3 bytes , in hex . uint8_t profile_idc ; uint8_t profile_iop ; uint8_t level_idc ; buffer[0] = value[0] ; buffer[1] = value[1] ; buffer[2] = ' \0 ' ; profile_idc = strtol ( buffer , NULL , 16 ) ; buffer[0] = value[2] ; buffer[1] = value[3] ; profile_iop = strtol ( buffer , NULL , 16 ) ; buffer[0] = value[4] ; buffer[1] = value[5] ; level_idc = strtol ( buffer , NULL , 16 ) ; av_log ( codec , AV_LOG_DEBUG , RTP Profile IDC : %x Profile IOP : %x Level : %x\n , profile_idc , profile_iop , level_idc ) ; h264_data - > profile_idc = profile_idc ; h264_data - > profile_iop = profile_iop ; h264_data - > level_idc = level_idc ; } } else if ( ! strcmp ( attr , sprop - parameter - sets ) ) { codec - > extradata_size = 0 ; codec - > extradata = NULL ; while ( * value ) { char base64packet[1024] ; uint8_t decoded_packet[1024] ; int packet_size ; char * dst = base64packet ; while ( * value & & * value ! = ' , ' & & ( dst - base64packet ) < sizeof ( base64packet ) - 1 ) { * dst + + = * value + + ; } * dst + + = ' \0 ' ; if ( * value == ' , ' ) value + + ; packet_size = av_base64_decode ( decoded_packet , base64packet , sizeof ( decoded_packet ) ) ; if ( packet_size > 0 ) { uint8_t * dest = av_malloc ( packet_size + sizeof ( start_sequence ) + codec - > extradata_size + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! dest ) { av_log ( codec , AV_LOG_ERROR , Unable to allocate memory for extradata ! ) ; return AVERROR ( ENOMEM ) ; } if ( codec - > extradata_size ) { memcpy ( dest , codec - > extradata , codec - > extradata_size ) ; av_free ( codec - > extradata ) ; } memcpy ( dest + codec - > extradata_size , start_sequence , sizeof ( start_sequence ) ) ; memcpy ( dest + codec - > extradata_size + sizeof ( start_sequence ) , decoded_packet , packet_size ) ; memset ( dest + codec - > extradata_size + sizeof ( start_sequence ) + packet_size , 0 , FF_INPUT_BUFFER_PADDING_SIZE ) ; codec - > extradata = dest ; codec - > extradata_size + = sizeof ( start_sequence ) + packet_size ; } } av_log ( codec , AV_LOG_DEBUG , Extradata set to %p ( size : %d ) ! , codec - > extradata , codec - > extradata_size ) ; } return 0 ; }",1
"static int decode_sequence_header_adv ( VC1Context * v , GetBitContext * gb ) { v - > res_rtm_flag = 1 ; v - > level = get_bits ( gb , 3 ) ; if ( v - > level > = 5 ) { av_log ( v - > s . avctx , AV_LOG_ERROR , Reserved LEVEL %i\n , v - > level ) ; } v - > chromaformat = get_bits ( gb , 2 ) ; if ( v - > chromaformat ! = 1 ) { av_log ( v - > s . avctx , AV_LOG_ERROR , Only 4 : 2 : 0 chroma format supported\n ) ; return - 1 ; } // ( fps - 2 ) /4 ( - > 30 ) v - > frmrtq_postproc = get_bits ( gb , 3 ) ; //common // ( bitrate - 32kbps ) /64kbps v - > bitrtq_postproc = get_bits ( gb , 5 ) ; //common v - > postprocflag = get_bits1 ( gb ) ; //common v - > s . avctx - > coded_width = ( get_bits ( gb , 12 ) + 1 ) < < 1 ; v - > s . avctx - > coded_height = ( get_bits ( gb , 12 ) + 1 ) < < 1 ; v - > s . avctx - > width = v - > s . avctx - > coded_width ; v - > s . avctx - > height = v - > s . avctx - > coded_height ; v - > broadcast = get_bits1 ( gb ) ; v - > interlace = get_bits1 ( gb ) ; v - > tfcntrflag = get_bits1 ( gb ) ; v - > finterpflag = get_bits1 ( gb ) ; skip_bits1 ( gb ) ; // reserved av_log ( v - > s . avctx , AV_LOG_DEBUG , Advanced Profile level %i : \nfrmrtq_postproc=%i , bitrtq_postproc=%i\n LoopFilter=%i , ChromaFormat=%i , Pulldown=%i , Interlace : %i\n TFCTRflag=%i , FINTERPflag=%i\n , v - > level , v - > frmrtq_postproc , v - > bitrtq_postproc , v - > s . loop_filter , v - > chromaformat , v - > broadcast , v - > interlace , v - > tfcntrflag , v - > finterpflag ) ; v - > psf = get_bits1 ( gb ) ; if ( v - > psf ) { //PsF , 6 . 1 . 13 av_log ( v - > s . avctx , AV_LOG_ERROR , Progressive Segmented Frame mode : not supported ( yet ) \n ) ; return - 1 ; } v - > s . max_b_frames = v - > s . avctx - > max_b_frames = 7 ; if ( get_bits1 ( gb ) ) { //Display Info - decoding is not affected by it int w , h , ar = 0 ; av_log ( v - > s . avctx , AV_LOG_DEBUG , Display extended info : \n ) ; w = get_bits ( gb , 14 ) + 1 ; h = get_bits ( gb , 14 ) + 1 ; av_log ( v - > s . avctx , AV_LOG_DEBUG , Display dimensions : %ix%i\n , w , h ) ; if ( get_bits1 ( gb ) ) ar = get_bits ( gb , 4 ) ; if ( ar & & ar < 14 ) { v - > s . avctx - > sample_aspect_ratio = ff_vc1_pixel_aspect[ar] ; } else if ( ar == 15 ) { w = get_bits ( gb , 8 ) + 1 ; h = get_bits ( gb , 8 ) + 1 ; v - > s . avctx - > sample_aspect_ratio = ( AVRational ) { w , h } ; } else { av_reduce ( & v - > s . avctx - > sample_aspect_ratio . num , & v - > s . avctx - > sample_aspect_ratio . den , v - > s . avctx - > height * w , v - > s . avctx - > width * h , 1 < < 30 ) ; } av_log ( v - > s . avctx , AV_LOG_DEBUG , Aspect : %i : %i\n , v - > s . avctx - > sample_aspect_ratio . num , v - > s . avctx - > sample_aspect_ratio . den ) ; if ( get_bits1 ( gb ) ) { //framerate stuff if ( get_bits1 ( gb ) ) { v - > s . avctx - > time_base . num = 32 ; v - > s . avctx - > time_base . den = get_bits ( gb , 16 ) + 1 ; } else { int nr , dr ; nr = get_bits ( gb , 8 ) ; dr = get_bits ( gb , 4 ) ; if ( nr & & nr < 8 & & dr & & dr < 3 ) { v - > s . avctx - > time_base . num = ff_vc1_fps_dr[dr - 1] ; v - > s . avctx - > time_base . den = ff_vc1_fps_nr[nr - 1] * 1000 ; } } if ( v - > broadcast ) { // Pulldown may be present v - > s . avctx - > time_base . den * = 2 ; v - > s . avctx - > ticks_per_frame = 2 ; } } if ( get_bits1 ( gb ) ) { v - > color_prim = get_bits ( gb , 8 ) ; v - > transfer_char = get_bits ( gb , 8 ) ; v - > matrix_coef = get_bits ( gb , 8 ) ; } } v - > hrd_param_flag = get_bits1 ( gb ) ; if ( v - > hrd_param_flag ) { int i ; v - > hrd_num_leaky_buckets = get_bits ( gb , 5 ) ; skip_bits ( gb , 4 ) ; //bitrate exponent skip_bits ( gb , 4 ) ; //buffer size exponent for ( i = 0 ; i < v - > hrd_num_leaky_buckets ; i + + ) { skip_bits ( gb , 16 ) ; //hrd_rate[n] skip_bits ( gb , 16 ) ; //hrd_buffer[n] } } return 0 ; }",0
"void opt_input_file ( const char * filename ) { AVFormatContext * ic ; AVFormatParameters params , * ap = & params ; int err , i , ret , rfps ; / * get default parameters from command line * / memset ( ap , 0 , sizeof ( * ap ) ) ; ap - > sample_rate = audio_sample_rate ; ap - > channels = audio_channels ; ap - > frame_rate = frame_rate ; ap - > width = frame_width ; ap - > height = frame_height ; / * open the input file with generic libav function * / err = av_open_input_file ( & ic , filename , file_iformat , 0 , ap ) ; if ( err < 0 ) { print_error ( filename , err ) ; exit ( 1 ) ; } / * If not enough info to get the stream parameters , we decode the first frames to get it . ( used in mpeg case for example ) * / ret = av_find_stream_info ( ic ) ; if ( ret < 0 ) { fprintf ( stderr , %s : could not find codec parameters\n , filename ) ; exit ( 1 ) ; } / * update the current parameters so that they match the one of the input stream * / for ( i=0 ; i < ic - > nb_streams ; i + + ) { AVCodecContext * enc = & ic - > streams[i] - > codec ; switch ( enc - > codec_type ) { case CODEC_TYPE_AUDIO : //fprintf ( stderr , \nInput Audio channels : %d , enc - > channels ) ; audio_channels = enc - > channels ; audio_sample_rate = enc - > sample_rate ; break ; case CODEC_TYPE_VIDEO : frame_height = enc - > height ; frame_width = enc - > width ; rfps = ic - > streams[i] - > r_frame_rate ; if ( enc - > frame_rate ! = rfps ) { fprintf ( stderr , \nSeems that stream %d comes from film source : %2 . 2f - > %2 . 2f\n , i , ( float ) enc - > frame_rate / FRAME_RATE_BASE , ( float ) rfps / FRAME_RATE_BASE ) ; } / * update the current frame rate to match the stream frame rate * / frame_rate = rfps ; break ; default : abort ( ) ; } } input_files[nb_input_files] = ic ; / * dump the file content * / dump_format ( ic , nb_input_files , filename , 0 ) ; nb_input_files + + ; file_iformat = NULL ; file_oformat = NULL ; }",0
"static int parse_iplconvkernel ( IplConvKernel * * kernel , char * buf , void * log_ctx ) { char shape_filename[128] = , shape_str[32] = rect ; int cols = 0 , rows = 0 , anchor_x = 0 , anchor_y = 0 , shape = CV_SHAPE_RECT ; int * values = NULL , ret ; sscanf ( buf , %dx%d + %dx%d/%32[ =]=%127s , & cols , & rows , & anchor_x , & anchor_y , shape_str , shape_filename ) ; if ( ! strcmp ( shape_str , rect ) ) shape = CV_SHAPE_RECT ; else if ( ! strcmp ( shape_str , cross ) ) shape = CV_SHAPE_CROSS ; else if ( ! strcmp ( shape_str , ellipse ) ) shape = CV_SHAPE_ELLIPSE ; else if ( ! strcmp ( shape_str , custom ) ) { shape = CV_SHAPE_CUSTOM ; if ( ( ret = read_shape_from_file ( & cols , & rows , & values , shape_filename , log_ctx ) ) < 0 ) return ret ; } else { av_log ( log_ctx , AV_LOG_ERROR , Shape unspecified or type ' %s ' unknown . \n , shape_str ) ; return AVERROR ( EINVAL ) ; } if ( rows < = 0 || cols < = 0 ) { av_log ( log_ctx , AV_LOG_ERROR , Invalid non - positive values for shape size %dx%d\n , cols , rows ) ; return AVERROR ( EINVAL ) ; } if ( anchor_x < 0 || anchor_y < 0 || anchor_x > = cols || anchor_y > = rows ) { av_log ( log_ctx , AV_LOG_ERROR , Shape anchor %dx%d is not inside the rectangle with size %dx%d . \n , anchor_x , anchor_y , cols , rows ) ; return AVERROR ( EINVAL ) ; } * kernel = cvCreateStructuringElementEx ( cols , rows , anchor_x , anchor_y , shape , values ) ; av_freep ( & values ) ; if ( ! * kernel ) return AVERROR ( ENOMEM ) ; av_log ( log_ctx , AV_LOG_VERBOSE , Structuring element : w : %d h : %d x : %d y : %d shape : %s\n , rows , cols , anchor_x , anchor_y , shape_str ) ; return 0 ; }",1
"static int encode_apng ( AVCodecContext * avctx , AVPacket * pkt , const AVFrame * pict , int * got_packet ) { PNGEncContext * s = avctx - > priv_data ; int ret ; int enc_row_size ; size_t max_packet_size ; APNGFctlChunk fctl_chunk = { 0 } ; if ( pict & & avctx - > codec_id == AV_CODEC_ID_APNG & & s - > color_type == PNG_COLOR_TYPE_PALETTE ) { uint32_t checksum = av_crc ( av_crc_get_table ( AV_CRC_32_IEEE_LE ) , 0U , pict - > data[1] , 256 * sizeof ( uint32_t ) ) ; if ( avctx - > frame_number == 0 ) { s - > palette_checksum = checksum ; } else if ( checksum ! = s - > palette_checksum ) { av_log ( avctx , AV_LOG_ERROR , Input contains more than one unique palette . APNG does not support multiple palettes . \n ) ; return - 1 ; } } enc_row_size = deflateBound ( & s - > zstream , ( avctx - > width * s - > bits_per_pixel + 7 ) > > 3 ) ; max_packet_size = AV_INPUT_BUFFER_MIN_SIZE + // headers avctx - > height * ( enc_row_size + ( 4 + 12 ) * ( ( ( int64_t ) enc_row_size + IOBUF_SIZE - 1 ) / IOBUF_SIZE ) // fdAT * ceil ( enc_row_size / IOBUF_SIZE ) ) ; if ( max_packet_size > INT_MAX ) return AVERROR ( ENOMEM ) ; if ( avctx - > frame_number == 0 ) { s - > bytestream = avctx - > extradata = av_malloc ( FF_MIN_BUFFER_SIZE ) ; if ( ! avctx - > extradata ) return AVERROR ( ENOMEM ) ; ret = encode_headers ( avctx , pict ) ; if ( ret < 0 ) return ret ; avctx - > extradata_size = s - > bytestream - avctx - > extradata ; s - > last_frame_packet = av_malloc ( max_packet_size ) ; if ( ! s - > last_frame_packet ) return AVERROR ( ENOMEM ) ; } else if ( s - > last_frame ) { ret = ff_alloc_packet2 ( avctx , pkt , max_packet_size , 0 ) ; if ( ret < 0 ) return ret ; memcpy ( pkt - > data , s - > last_frame_packet , s - > last_frame_packet_size ) ; pkt - > size = s - > last_frame_packet_size ; pkt - > pts = pkt - > dts = s - > last_frame - > pts ; } if ( pict ) { s - > bytestream_start = s - > bytestream = s - > last_frame_packet ; s - > bytestream_end = s - > bytestream + max_packet_size ; // We ' re encoding the frame first , so we have to do a bit of shuffling around // to have the image data write to the correct place in the buffer fctl_chunk . sequence_number = s - > sequence_number ; + + s - > sequence_number ; s - > bytestream + = 26 + 12 ; ret = apng_encode_frame ( avctx , pict , & fctl_chunk , & s - > last_frame_fctl ) ; if ( ret < 0 ) return ret ; fctl_chunk . delay_num = 0 ; // delay filled in during muxing fctl_chunk . delay_den = 0 ; } else { s - > last_frame_fctl . dispose_op = APNG_DISPOSE_OP_NONE ; } if ( s - > last_frame ) { uint8_t * last_fctl_chunk_start = pkt - > data ; uint8_t buf[26] ; AV_WB32 ( buf + 0 , s - > last_frame_fctl . sequence_number ) ; AV_WB32 ( buf + 4 , s - > last_frame_fctl . width ) ; AV_WB32 ( buf + 8 , s - > last_frame_fctl . height ) ; AV_WB32 ( buf + 12 , s - > last_frame_fctl . x_offset ) ; AV_WB32 ( buf + 16 , s - > last_frame_fctl . y_offset ) ; AV_WB16 ( buf + 20 , s - > last_frame_fctl . delay_num ) ; AV_WB16 ( buf + 22 , s - > last_frame_fctl . delay_den ) ; buf[24] = s - > last_frame_fctl . dispose_op ; buf[25] = s - > last_frame_fctl . blend_op ; png_write_chunk ( & last_fctl_chunk_start , MKTAG ( ' f ' , ' c ' , ' T ' , ' L ' ) , buf , 26 ) ; * got_packet = 1 ; } if ( pict ) { if ( ! s - > last_frame ) { s - > last_frame = av_frame_alloc ( ) ; if ( ! s - > last_frame ) return AVERROR ( ENOMEM ) ; } else if ( s - > last_frame_fctl . dispose_op ! = APNG_DISPOSE_OP_PREVIOUS ) { if ( ! s - > prev_frame ) { s - > prev_frame = av_frame_alloc ( ) ; if ( ! s - > prev_frame ) return AVERROR ( ENOMEM ) ; s - > prev_frame - > format = pict - > format ; s - > prev_frame - > width = pict - > width ; s - > prev_frame - > height = pict - > height ; if ( ( ret = av_frame_get_buffer ( s - > prev_frame , 32 ) ) < 0 ) return ret ; } // Do disposal , but not blending memcpy ( s - > prev_frame - > data[0] , s - > last_frame - > data[0] , s - > last_frame - > linesize[0] * s - > last_frame - > height ) ; if ( s - > last_frame_fctl . dispose_op == APNG_DISPOSE_OP_BACKGROUND ) { uint32_t y ; uint8_t bpp = ( s - > bits_per_pixel + 7 ) > > 3 ; for ( y = s - > last_frame_fctl . y_offset ; y < s - > last_frame_fctl . y_offset + s - > last_frame_fctl . height ; + + y ) { size_t row_start = s - > last_frame - > linesize[0] * y + bpp * s - > last_frame_fctl . x_offset ; memset ( s - > prev_frame - > data[0] + row_start , 0 , bpp * s - > last_frame_fctl . width ) ; } } } av_frame_unref ( s - > last_frame ) ; ret = av_frame_ref ( s - > last_frame , ( AVFrame * ) pict ) ; if ( ret < 0 ) return ret ; s - > last_frame_fctl = fctl_chunk ; s - > last_frame_packet_size = s - > bytestream - s - > bytestream_start ; } else { av_frame_free ( & s - > last_frame ) ; } return 0 ; }",1
"void decode_mb_mode ( VP8Context * s , VP8Macroblock * mb , int mb_x , int mb_y , uint8_t * segment , uint8_t * ref ) { VP56RangeCoder * c = & s - > c ; if ( s - > segmentation . update_map ) * segment = vp8_rac_get_tree ( c , vp8_segmentid_tree , s - > prob - > segmentid ) ; else * segment = ref ? * ref : * segment ; s - > segment = * segment ; mb - > skip = s - > mbskip_enabled ? vp56_rac_get_prob ( c , s - > prob - > mbskip ) : 0 ; if ( s - > keyframe ) { mb - > mode = vp8_rac_get_tree ( c , vp8_pred16x16_tree_intra , vp8_pred16x16_prob_intra ) ; if ( mb - > mode == MODE_I4x4 ) { decode_intra4x4_modes ( s , c , mb_x , 1 ) ; } else { const uint32_t modes = vp8_pred4x4_mode[mb - > mode] * 0x01010101u ; AV_WN32A ( s - > intra4x4_pred_mode_top + 4 * mb_x , modes ) ; AV_WN32A ( s - > intra4x4_pred_mode_left , modes ) ; } s - > chroma_pred_mode = vp8_rac_get_tree ( c , vp8_pred8x8c_tree , vp8_pred8x8c_prob_intra ) ; mb - > ref_frame = VP56_FRAME_CURRENT ; } else if ( vp56_rac_get_prob_branchy ( c , s - > prob - > intra ) ) { // inter MB , 16 . 2 if ( vp56_rac_get_prob_branchy ( c , s - > prob - > last ) ) mb - > ref_frame = vp56_rac_get_prob ( c , s - > prob - > golden ) ? VP56_FRAME_GOLDEN2 / * altref * / : VP56_FRAME_GOLDEN ; else mb - > ref_frame = VP56_FRAME_PREVIOUS ; s - > ref_count[mb - > ref_frame - 1] + + ; // motion vectors , 16 . 3 decode_mvs ( s , mb , mb_x , mb_y ) ; } else { // intra MB , 16 . 1 mb - > mode = vp8_rac_get_tree ( c , vp8_pred16x16_tree_inter , s - > prob - > pred16x16 ) ; if ( mb - > mode == MODE_I4x4 ) decode_intra4x4_modes ( s , c , mb_x , 0 ) ; s - > chroma_pred_mode = vp8_rac_get_tree ( c , vp8_pred8x8c_tree , s - > prob - > pred8x8c ) ; mb - > ref_frame = VP56_FRAME_CURRENT ; mb - > partitioning = VP8_SPLITMVMODE_NONE ; AV_ZERO32 ( & mb - > bmv[0] ) ; } }",1
"static int amovie_request_frame ( AVFilterLink * outlink ) { MovieContext * movie = outlink - > src - > priv ; int ret ; if ( movie - > is_done ) return AVERROR_EOF ; if ( ( ret = amovie_get_samples ( outlink ) ) < 0 ) return ret ; avfilter_filter_samples ( outlink , avfilter_ref_buffer ( movie - > samplesref , 0 ) ) ; avfilter_unref_buffer ( movie - > samplesref ) ; movie - > samplesref = NULL ; return 0 ; }",1
"inline static void RENAME ( hcscale ) ( uint16_t * dst , long dstWidth , uint8_t * src1 , uint8_t * src2 , int srcW , int xInc , int flags , int canMMX2BeUsed , int16_t * hChrFilter , int16_t * hChrFilterPos , int hChrFilterSize , void * funnyUVCode , int srcFormat , uint8_t * formatConvBuffer , int16_t * mmx2Filter , int32_t * mmx2FilterPos , uint8_t * pal ) { if ( srcFormat==PIX_FMT_YUYV422 ) { RENAME ( yuy2ToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( srcFormat==PIX_FMT_UYVY422 ) { RENAME ( uyvyToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( srcFormat==PIX_FMT_RGB32 ) { RENAME ( bgr32ToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( srcFormat==PIX_FMT_BGR24 ) { RENAME ( bgr24ToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( srcFormat==PIX_FMT_BGR565 ) { RENAME ( bgr16ToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( srcFormat==PIX_FMT_BGR555 ) { RENAME ( bgr15ToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( srcFormat==PIX_FMT_BGR32 ) { RENAME ( rgb32ToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( srcFormat==PIX_FMT_RGB24 ) { RENAME ( rgb24ToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( srcFormat==PIX_FMT_RGB565 ) { RENAME ( rgb16ToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( srcFormat==PIX_FMT_RGB555 ) { RENAME ( rgb15ToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( isGray ( srcFormat ) ) { return ; } else if ( srcFormat==PIX_FMT_RGB8 || srcFormat==PIX_FMT_BGR8 || srcFormat==PIX_FMT_PAL8 || srcFormat==PIX_FMT_BGR4_BYTE || srcFormat==PIX_FMT_RGB4_BYTE ) { RENAME ( palToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW , pal ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } ifdef HAVE_MMX // use the new MMX scaler if the mmx2 can ' t be used ( its faster than the x86asm one ) if ( ! ( flags & SWS_FAST_BILINEAR ) || ( ! canMMX2BeUsed ) ) else if ( ! ( flags & SWS_FAST_BILINEAR ) ) endif { RENAME ( hScale ) ( dst , dstWidth , src1 , srcW , xInc , hChrFilter , hChrFilterPos , hChrFilterSize ) ; RENAME ( hScale ) ( dst + 2048 , dstWidth , src2 , srcW , xInc , hChrFilter , hChrFilterPos , hChrFilterSize ) ; } else // Fast Bilinear upscale / crap downscale { if defined ( ARCH_X86 ) ifdef HAVE_MMX2 int i ; if defined ( PIC ) uint64_t ebxsave __attribute__ ( ( aligned ( 8 ) ) ) ; endif if ( canMMX2BeUsed ) { asm volatile ( if defined ( PIC ) mov %% REG_b , %6 \n\t endif pxor %%mm7 , %%mm7 \n\t mov %0 , %% REG_c \n\t mov %1 , %% REG_D \n\t mov %2 , %% REG_d \n\t mov %3 , %% REG_b \n\t xor %% REG_a , %% REG_a \n\t // i PREFETCH ( %% REG_c ) \n\t PREFETCH 32 ( %% REG_c ) \n\t PREFETCH 64 ( %% REG_c ) \n\t ifdef ARCH_X86_64 define FUNNY_UV_CODE \ movl ( %% REG_b ) , %%esi \n\t \ call * %4 \n\t \ movl ( %% REG_b , %% REG_a ) , %%esi\n\t \ add %% REG_S , %% REG_c \n\t \ add %% REG_a , %% REG_D \n\t \ xor %% REG_a , %% REG_a \n\t \ else define FUNNY_UV_CODE \ movl ( %% REG_b ) , %%esi \n\t \ call * %4 \n\t \ addl ( %% REG_b , %% REG_a ) , %% REG_c \n\t \ add %% REG_a , %% REG_D \n\t \ xor %% REG_a , %% REG_a \n\t \ endif FUNNY_UV_CODE FUNNY_UV_CODE FUNNY_UV_CODE FUNNY_UV_CODE xor %% REG_a , %% REG_a \n\t // i mov %5 , %% REG_c \n\t // src mov %1 , %% REG_D \n\t // buf1 add 4096 , %% REG_D \n\t PREFETCH ( %% REG_c ) \n\t PREFETCH 32 ( %% REG_c ) \n\t PREFETCH 64 ( %% REG_c ) \n\t FUNNY_UV_CODE FUNNY_UV_CODE FUNNY_UV_CODE FUNNY_UV_CODE if defined ( PIC ) mov %6 , %% REG_b \n\t endif : : m ( src1 ) , m ( dst ) , m ( mmx2Filter ) , m ( mmx2FilterPos ) , m ( funnyUVCode ) , m ( src2 ) if defined ( PIC ) , m ( ebxsave ) endif : % REG_a , % REG_c , % REG_d , % REG_S , % REG_D if ! defined ( PIC ) , % REG_b endif ) ; for ( i=dstWidth - 1 ; ( i * xInc ) > > 16 > =srcW - 1 ; i - - ) { // printf ( %d %d %d\n , dstWidth , i , srcW ) ; dst[i] = src1[srcW - 1] * 128 ; dst[i + 2048] = src2[srcW - 1] * 128 ; } } else { endif long xInc_shr16 = ( long ) ( xInc > > 16 ) ; uint16_t xInc_mask = xInc & 0xffff ; asm volatile ( xor %% REG_a , %% REG_a \n\t // i xor %% REG_d , %% REG_d \n\t // xx xorl %%ecx , %%ecx \n\t // 2 * xalpha ASMALIGN ( 4 ) 1 : \n\t mov %0 , %% REG_S \n\t movzbl ( %% REG_S , %% REG_d ) , %%edi \n\t //src[xx] movzbl 1 ( %% REG_S , %% REG_d ) , %%esi \n\t //src[xx + 1] subl %%edi , %%esi \n\t //src[xx + 1] - src[xx] imull %%ecx , %%esi \n\t // ( src[xx + 1] - src[xx] ) * 2 * xalpha shll 16 , %%edi \n\t addl %%edi , %%esi \n\t //src[xx + 1] * 2 * xalpha + src[xx] * ( 1 - 2 * xalpha ) mov %1 , %% REG_D \n\t shrl 9 , %%esi \n\t movw %%si , ( %% REG_D , %% REG_a , 2 ) \n\t movzbl ( %5 , %% REG_d ) , %%edi \n\t //src[xx] movzbl 1 ( %5 , %% REG_d ) , %%esi \n\t //src[xx + 1] subl %%edi , %%esi \n\t //src[xx + 1] - src[xx] imull %%ecx , %%esi \n\t // ( src[xx + 1] - src[xx] ) * 2 * xalpha shll 16 , %%edi \n\t addl %%edi , %%esi \n\t //src[xx",1
"static int wavpack_decode_block ( AVCodecContext * avctx , int block_no , void * data , int * got_frame_ptr , const uint8_t * buf , int buf_size ) { WavpackContext * wc = avctx - > priv_data ; WavpackFrameContext * s ; void * samples = data ; int samplecount ; int got_terms = 0 , got_weights = 0 , got_samples = 0 , got_entropy = 0 , got_bs = 0 , got_float = 0 ; int got_hybrid = 0 ; const uint8_t * orig_buf = buf ; const uint8_t * buf_end = buf + buf_size ; int i , j , id , size , ssize , weights , t ; int bpp , chan , chmask ; if ( buf_size == 0 ) { * got_frame_ptr = 0 ; return 0 ; } if ( block_no > = wc - > fdec_num & & wv_alloc_frame_context ( wc ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , Error creating frame decode context\n ) ; return - 1 ; } s = wc - > fdec[block_no] ; if ( ! s ) { av_log ( avctx , AV_LOG_ERROR , Context for block %d is not present\n , block_no ) ; return - 1 ; } memset ( s - > decorr , 0 , MAX_TERMS * sizeof ( Decorr ) ) ; memset ( s - > ch , 0 , sizeof ( s - > ch ) ) ; s - > extra_bits = 0 ; s - > and = s - > or = s - > shift = 0 ; s - > got_extra_bits = 0 ; if ( ! wc - > mkv_mode ) { s - > samples = AV_RL32 ( buf ) ; buf + = 4 ; if ( ! s - > samples ) { * got_frame_ptr = 0 ; return 0 ; } } else { s - > samples = wc - > samples ; } s - > frame_flags = AV_RL32 ( buf ) ; buf + = 4 ; if ( s - > frame_flags & 0x80 ) { avctx - > sample_fmt = AV_SAMPLE_FMT_FLT ; } else if ( ( s - > frame_flags & 0x03 ) < = 1 ) { avctx - > sample_fmt = AV_SAMPLE_FMT_S16 ; } else { avctx - > sample_fmt = AV_SAMPLE_FMT_S32 ; } bpp = av_get_bytes_per_sample ( avctx - > sample_fmt ) ; samples = ( uint8_t * ) samples + bpp * wc - > ch_offset ; s - > stereo = ! ( s - > frame_flags & WV_MONO ) ; s - > stereo_in = ( s - > frame_flags & WV_FALSE_STEREO ) ? 0 : s - > stereo ; s - > joint = s - > frame_flags & WV_JOINT_STEREO ; s - > hybrid = s - > frame_flags & WV_HYBRID_MODE ; s - > hybrid_bitrate = s - > frame_flags & WV_HYBRID_BITRATE ; s - > hybrid_maxclip = 1 < < ( ( ( ( s - > frame_flags & 0x03 ) + 1 ) < < 3 ) - 1 ) ; s - > post_shift = 8 * ( bpp - 1 - ( s - > frame_flags & 0x03 ) ) + ( ( s - > frame_flags > > 13 ) & 0x1f ) ; s - > CRC = AV_RL32 ( buf ) ; buf + = 4 ; if ( wc - > mkv_mode ) buf + = 4 ; //skip block size ; wc - > ch_offset + = 1 + s - > stereo ; // parse metadata blocks while ( buf < buf_end ) { id = * buf + + ; size = * buf + + ; if ( id & WP_IDF_LONG ) { size |= ( * buf + + ) < < 8 ; size |= ( * buf + + ) < < 16 ; } size < < = 1 ; // size is specified in words ssize = size ; if ( id & WP_IDF_ODD ) size - - ; if ( size < 0 ) { av_log ( avctx , AV_LOG_ERROR , Got incorrect block %02X with size %i\n , id , size ) ; break ; } if ( buf + ssize > buf_end ) { av_log ( avctx , AV_LOG_ERROR , Block size %i is out of bounds\n , size ) ; break ; } if ( id & WP_IDF_IGNORE ) { buf + = ssize ; continue ; } switch ( id & WP_IDF_MASK ) { case WP_ID_DECTERMS : if ( size > MAX_TERMS ) { av_log ( avctx , AV_LOG_ERROR , Too many decorrelation terms\n ) ; s - > terms = 0 ; buf + = ssize ; continue ; } s - > terms = size ; for ( i = 0 ; i < s - > terms ; i + + ) { s - > decorr[s - > terms - i - 1] . value = ( * buf & 0x1F ) - 5 ; s - > decorr[s - > terms - i - 1] . delta = * buf > > 5 ; buf + + ; } got_terms = 1 ; break ; case WP_ID_DECWEIGHTS : if ( ! got_terms ) { av_log ( avctx , AV_LOG_ERROR , No decorrelation terms met\n ) ; continue ; } weights = size > > s - > stereo_in ; if ( weights > MAX_TERMS || weights > s - > terms ) { av_log ( avctx , AV_LOG_ERROR , Too many decorrelation weights\n ) ; buf + = ssize ; continue ; } for ( i = 0 ; i < weights ; i + + ) { t = ( int8_t ) ( * buf + + ) ; s - > decorr[s - > terms - i - 1] . weightA = t < < 3 ; if ( s - > decorr[s - > terms - i - 1] . weightA > 0 ) s - > decorr[s - > terms - i - 1] . weightA + = ( s - > decorr[s - > terms - i - 1] . weightA + 64 ) > > 7 ; if ( s - > stereo_in ) { t = ( int8_t ) ( * buf + + ) ; s - > decorr[s - > terms - i - 1] . weightB = t < < 3 ; if ( s - > decorr[s - > terms - i - 1] . weightB > 0 ) s - > decorr[s - > terms - i - 1] . weightB + = ( s - > decorr[s - > terms - i - 1] . weightB + 64 ) > > 7 ; } } got_weights = 1 ; break ; case WP_ID_DECSAMPLES : if ( ! got_terms ) { av_log ( avctx , AV_LOG_ERROR , No decorrelation terms met\n ) ; continue ; } t = 0 ; for ( i = s - > terms - 1 ; ( i > = 0 ) & & ( t <",1
"int ff_put_wav_header ( AVFormatContext * s , AVIOContext * pb , AVCodecParameters * par , int flags ) { int bps , blkalign , bytespersec , frame_size ; int hdrsize ; int64_t hdrstart = avio_tell ( pb ) ; int waveformatextensible ; uint8_t temp[256] ; uint8_t * riff_extradata = temp ; uint8_t * riff_extradata_start = temp ; if ( ! par - > codec_tag || par - > codec_tag > 0xffff ) return - 1 ; / * We use the known constant frame size for the codec if known , otherwise * fall back on using AVCodecContext . frame_size , which is not as reliable * for indicating packet duration . * / frame_size = av_get_audio_frame_duration2 ( par , par - > block_align ) ; waveformatextensible = ( par - > channels > 2 & & par - > channel_layout ) || par - > sample_rate > 48000 || par - > codec_id == AV_CODEC_ID_EAC3 || av_get_bits_per_sample ( par - > codec_id ) > 16 ; if ( waveformatextensible ) avio_wl16 ( pb , 0xfffe ) ; else avio_wl16 ( pb , par - > codec_tag ) ; avio_wl16 ( pb , par - > channels ) ; avio_wl32 ( pb , par - > sample_rate ) ; if ( par - > codec_id == AV_CODEC_ID_ATRAC3 || par - > codec_id == AV_CODEC_ID_G723_1 || par - > codec_id == AV_CODEC_ID_MP2 || par - > codec_id == AV_CODEC_ID_MP3 || par - > codec_id == AV_CODEC_ID_GSM_MS ) { bps = 0 ; } else { if ( ! ( bps = av_get_bits_per_sample ( par - > codec_id ) ) ) { if ( par - > bits_per_coded_sample ) bps = par - > bits_per_coded_sample ; else bps = 16 ; // default to 16 } } if ( bps ! = par - > bits_per_coded_sample & & par - > bits_per_coded_sample ) { av_log ( s , AV_LOG_WARNING , requested bits_per_coded_sample ( %d ) and actually stored ( %d ) differ\n , par - > bits_per_coded_sample , bps ) ; } if ( par - > codec_id == AV_CODEC_ID_MP2 ) { blkalign = ( 144 * par - > bit_rate - 1 ) /par - > sample_rate + 1 ; } else if ( par - > codec_id == AV_CODEC_ID_MP3 ) { blkalign = 576 * ( par - > sample_rate < = ( 24000 + 32000 ) /2 ? 1 : 2 ) ; } else if ( par - > codec_id == AV_CODEC_ID_AC3 ) { blkalign = 3840 ; / * maximum bytes per frame * / } else if ( par - > codec_id == AV_CODEC_ID_AAC ) { blkalign = 768 * par - > channels ; / * maximum bytes per frame * / } else if ( par - > codec_id == AV_CODEC_ID_G723_1 ) { blkalign = 24 ; } else if ( par - > block_align ! = 0 ) { / * specified by the codec * / blkalign = par - > block_align ; } else blkalign = bps * par - > channels / av_gcd ( 8 , bps ) ; if ( par - > codec_id == AV_CODEC_ID_PCM_U8 || par - > codec_id == AV_CODEC_ID_PCM_S24LE || par - > codec_id == AV_CODEC_ID_PCM_S32LE || par - > codec_id == AV_CODEC_ID_PCM_F32LE || par - > codec_id == AV_CODEC_ID_PCM_F64LE || par - > codec_id == AV_CODEC_ID_PCM_S16LE ) { bytespersec = par - > sample_rate * blkalign ; } else if ( par - > codec_id == AV_CODEC_ID_G723_1 ) { bytespersec = 800 ; } else { bytespersec = par - > bit_rate / 8 ; } avio_wl32 ( pb , bytespersec ) ; / * bytes per second * / avio_wl16 ( pb , blkalign ) ; / * block align * / avio_wl16 ( pb , bps ) ; / * bits per sample * / if ( par - > codec_id == AV_CODEC_ID_MP3 ) { bytestream_put_le16 ( & riff_extradata , 1 ) ; / * wID * / bytestream_put_le32 ( & riff_extradata , 2 ) ; / * fdwFlags * / bytestream_put_le16 ( & riff_extradata , 1152 ) ; / * nBlockSize * / bytestream_put_le16 ( & riff_extradata , 1 ) ; / * nFramesPerBlock * / bytestream_put_le16 ( & riff_extradata , 1393 ) ; / * nCodecDelay * / } else if ( par - > codec_id == AV_CODEC_ID_MP2 ) { / * fwHeadLayer * / bytestream_put_le16 ( & riff_extradata , 2 ) ; / * dwHeadBitrate * / bytestream_put_le32 ( & riff_extradata , par - > bit_rate ) ; / * fwHeadMode * / bytestream_put_le16 ( & riff_extradata , par - > channels == 2 ? 1 : 8 ) ; / * fwHeadModeExt * / bytestream_put_le16 ( & riff_extradata , 0 ) ; / * wHeadEmphasis * / bytestream_put_le16 ( & riff_extradata , 1 ) ; / * fwHeadFlags * / bytestream_put_le16 ( & riff_extradata , 16 ) ; / * dwPTSLow * / bytestream_put_le32 ( & riff_extradata , 0 ) ; / * dwPTSHigh * / bytestream_put_le32 ( & riff_extradata , 0 ) ; } else if ( par - > codec_id == AV_CODEC_ID_G723_1 ) { bytestream_put_le32 ( & riff_extradata , 0x9ace0002 ) ; / * extradata needed for msacm g723 . 1 codec * / bytestream_put_le32 ( & riff_extradata , 0xaea2f732 ) ; bytestream_put_le16 ( & riff_extradata , 0xacde ) ; } else if ( par - > codec_id == AV_CODEC_ID_GSM_MS || par - > codec_id == AV_CODEC_ID_ADPCM_IMA_WAV ) { / * wSamplesPerBlock * / bytestream_put_le16 ( & riff_extradata , frame_size ) ; } else if ( par - > extradata_size ) { riff_extradata_start = par - > extradata ; riff_extradata = par - > extradata + par - > extradata_size ; } / * write WAVEFORMATEXTENSIBLE extensions * / if ( waveformatextensible ) { int write_channel_mask = ! ( flags & FF_PUT_WAV_HEADER_SKIP_CHANNELMASK ) & & ( s - > strict_std_compliance < FF_COMPLIANCE_NORMAL || par - > channel_layout < 0x40000 ) ; / * 22 is WAVEFORMATEXTENSIBLE size * / avio_wl16 ( pb , riff_extradata - riff_extradata_start + 22 ) ; / * ValidBitsPerSample || SamplesPerBlock || Reserved * / avio_wl16 ( pb , bps ) ; / * dwChannelMask * / avio_wl32 ( pb , write_channel_mask ? par - > channel_layout : 0 ) ; / * GUID + next 3 * / if ( par - > codec_id == AV_CODEC_ID_EAC3 ) { ff_put_guid ( pb , ff_get_codec_guid ( par - > codec_id , ff_codec_wav_guids ) ) ; } else { avio_wl32 ( pb , par - > codec_tag ) ; avio_wl32 ( pb , 0x00100000 ) ; avio_wl32 ( pb , 0xAA000080 ) ; avio_wl32 ( pb , 0x719B3800 ) ; } } else if ( ( flags & FF_PUT_WAV_HEADER_FORCE_WAVEFORMATEX ) || par - > codec_tag ! = 0x0001 / * PCM * / || riff_extradata - riff_extradata_start ) { / * WAVEFORMATEX * / avio_wl16 ( pb , riff_extradata - riff_extradata_start ) ; / * cbSize * / } / * else PCMWAVEFORMAT * / avio_write ( pb , riff_extradata_start , riff_extradata - riff_extradata_start ) ; hdrsize = avio_tell ( pb ) - hdrstart ; if ( hdrsize & 1 ) { hdrsize +",1
"static av_cold int join_init ( AVFilterContext * ctx ) { JoinContext * s = ctx - > priv ; int ret , i ; if ( ! ( s - > channel_layout = av_get_channel_layout ( s - > channel_layout_str ) ) ) { av_log ( ctx , AV_LOG_ERROR , Error parsing channel layout ' %s ' . \n , s - > channel_layout_str ) ; return AVERROR ( EINVAL ) ; } s - > nb_channels = av_get_channel_layout_nb_channels ( s - > channel_layout ) ; s - > channels = av_mallocz_array ( s - > nb_channels , sizeof ( * s - > channels ) ) ; s - > buffers = av_mallocz_array ( s - > nb_channels , sizeof ( * s - > buffers ) ) ; s - > input_frames = av_mallocz_array ( s - > inputs , sizeof ( * s - > input_frames ) ) ; if ( ! s - > channels || ! s - > buffers|| ! s - > input_frames ) return AVERROR ( ENOMEM ) ; for ( i = 0 ; i < s - > nb_channels ; i + + ) { s - > channels[i] . out_channel = av_channel_layout_extract_channel ( s - > channel_layout , i ) ; s - > channels[i] . input = - 1 ; } if ( ( ret = parse_maps ( ctx ) ) < 0 ) return ret ; for ( i = 0 ; i < s - > inputs ; i + + ) { char name[32] ; AVFilterPad pad = { 0 } ; snprintf ( name , sizeof ( name ) , input%d , i ) ; pad . type = AVMEDIA_TYPE_AUDIO ; pad . name = av_strdup ( name ) ; if ( ! pad . name ) return AVERROR ( ENOMEM ) ; pad . filter_frame = filter_frame ; pad . needs_fifo = 1 ; ff_insert_inpad ( ctx , i , & pad ) ; } return 0 ; }",1
static void idr ( H264Context * h ) { int i ; ff_h264_remove_all_refs ( h ) ; h - > prev_frame_num= - 1 ; h - > prev_frame_num_offset= 0 ; h - > prev_poc_msb= 1 < < 16 ; h - > prev_poc_lsb= 0 ; for ( i = 0 ; i < MAX_DELAYED_PIC_COUNT ; i + + ) h - > last_pocs[i] = INT_MIN ; },0
"static void do_audio_out ( AVFormatContext * s , OutputStream * ost , AVFrame * frame ) { AVCodecContext * enc = ost - > st - > codec ; AVPacket pkt ; int got_packet = 0 ; av_init_packet ( & pkt ) ; pkt . data = NULL ; pkt . size = 0 ; if 0 if ( ! check_recording_time ( ost ) ) return ; endif if ( frame - > pts == AV_NOPTS_VALUE || audio_sync_method < 0 ) frame - > pts = ost - > sync_opts ; ost - > sync_opts = frame - > pts + frame - > nb_samples ; av_assert0 ( pkt . size || ! pkt . data ) ; update_benchmark ( NULL ) ; if ( avcodec_encode_audio2 ( enc , & pkt , frame , & got_packet ) < 0 ) { av_log ( NULL , AV_LOG_FATAL , Audio encoding failed ( avcodec_encode_audio2 ) \n ) ; exit_program ( 1 ) ; } update_benchmark ( encode_audio %d . %d , ost - > file_index , ost - > index ) ; if ( got_packet ) { if ( pkt . pts ! = AV_NOPTS_VALUE ) pkt . pts = av_rescale_q ( pkt . pts , enc - > time_base , ost - > st - > time_base ) ; if ( pkt . dts ! = AV_NOPTS_VALUE ) pkt . dts = av_rescale_q ( pkt . dts , enc - > time_base , ost - > st - > time_base ) ; if ( pkt . duration > 0 ) pkt . duration = av_rescale_q ( pkt . duration , enc - > time_base , ost - > st - > time_base ) ; if ( debug_ts ) { av_log ( NULL , AV_LOG_INFO , encoder - > type : audio pkt_pts : %s pkt_pts_time : %s pkt_dts : %s pkt_dts_time : %s\n , av_ts2str ( pkt . pts ) , av_ts2timestr ( pkt . pts , & ost - > st - > time_base ) , av_ts2str ( pkt . dts ) , av_ts2timestr ( pkt . dts , & ost - > st - > time_base ) ) ; } write_frame ( s , & pkt , ost ) ; audio_size + = pkt . size ; av_free_packet ( & pkt ) ; } }",0
static av_cold int Faac_encode_close ( AVCodecContext * avctx ) { FaacAudioContext * s = avctx - > priv_data ; av_freep ( & avctx - > coded_frame ) ; av_freep ( & avctx - > extradata ) ; faacEncClose ( s - > faac_handle ) ; return 0 ; },0
"static av_cold int v4l2_encode_init ( AVCodecContext * avctx ) { V4L2m2mContext * s = avctx - > priv_data ; V4L2Context * capture = & s - > capture ; V4L2Context * output = & s - > output ; int ret ; / * common settings output/capture * / output - > height = capture - > height = avctx - > height ; output - > width = capture - > width = avctx - > width ; / * output context * / output - > av_codec_id = AV_CODEC_ID_RAWVIDEO ; output - > av_pix_fmt = avctx - > pix_fmt ; / * capture context * / capture - > av_codec_id = avctx - > codec_id ; capture - > av_pix_fmt = AV_PIX_FMT_NONE ; ret = ff_v4l2_m2m_codec_init ( avctx ) ; if ( ret ) { av_log ( avctx , AV_LOG_ERROR , can ' t configure encoder\n ) ; return ret ; } return v4l2_prepare_encoder ( s ) ; }",1
AVD3D11VAContext * av_d3d11va_alloc_context ( void ) { AVD3D11VAContext * res = av_mallocz ( sizeof ( AVD3D11VAContext ) ) ; res - > context_mutex = INVALID_HANDLE_VALUE ; return res ; },1
"static int cudaupload_query_formats ( AVFilterContext * ctx ) { int ret ; static const enum AVPixelFormat input_pix_fmts[] = { AV_PIX_FMT_NV12 , AV_PIX_FMT_YUV420P , AV_PIX_FMT_YUV444P , AV_PIX_FMT_NONE , } ; static const enum AVPixelFormat output_pix_fmts[] = { AV_PIX_FMT_CUDA , AV_PIX_FMT_NONE , } ; AVFilterFormats * in_fmts = ff_make_format_list ( input_pix_fmts ) ; AVFilterFormats * out_fmts = ff_make_format_list ( output_pix_fmts ) ; ret = ff_formats_ref ( in_fmts , & ctx - > inputs[0] - > out_formats ) ; if ( ret < 0 ) return ret ; ret = ff_formats_ref ( out_fmts , & ctx - > outputs[0] - > in_formats ) ; if ( ret < 0 ) return ret ; return 0 ; }",1
"static int encode_tile ( Jpeg2000EncoderContext * s , Jpeg2000Tile * tile , int tileno ) { int compno , reslevelno , bandno , ret ; Jpeg2000T1Context t1 ; Jpeg2000CodingStyle * codsty = & s - > codsty ; for ( compno = 0 ; compno < s - > ncomponents ; compno + + ) { Jpeg2000Component * comp = s - > tile[tileno] . comp + compno ; av_log ( s - > avctx , AV_LOG_DEBUG , dwt\n ) ; if ( ( ret = ff_dwt_encode ( & comp - > dwt , comp - > i_data ) ) < 0 ) return ret ; av_log ( s - > avctx , AV_LOG_DEBUG , after dwt - > tier1\n ) ; for ( reslevelno = 0 ; reslevelno < codsty - > nreslevels ; reslevelno + + ) { Jpeg2000ResLevel * reslevel = comp - > reslevel + reslevelno ; for ( bandno = 0 ; bandno < reslevel - > nbands ; bandno + + ) { Jpeg2000Band * band = reslevel - > band + bandno ; Jpeg2000Prec * prec = band - > prec ; // we support only 1 precinct per band ATM in the encoder int cblkx , cblky , cblkno=0 , xx0 , x0 , xx1 , y0 , yy0 , yy1 , bandpos ; yy0 = bandno == 0 ? 0 : comp - > reslevel[reslevelno - 1] . coord[1][1] - comp - > reslevel[reslevelno - 1] . coord[1][0] ; y0 = yy0 ; yy1 = FFMIN ( ff_jpeg2000_ceildivpow2 ( band - > coord[1][0] + 1 , band - > log2_cblk_height ) < < band - > log2_cblk_height , band - > coord[1][1] ) - band - > coord[1][0] + yy0 ; if ( band - > coord[0][0] == band - > coord[0][1] || band - > coord[1][0] == band - > coord[1][1] ) continue ; bandpos = bandno + ( reslevelno > 0 ) ; for ( cblky = 0 ; cblky < prec - > nb_codeblocks_height ; cblky + + ) { if ( reslevelno == 0 || bandno == 1 ) xx0 = 0 ; else xx0 = comp - > reslevel[reslevelno - 1] . coord[0][1] - comp - > reslevel[reslevelno - 1] . coord[0][0] ; x0 = xx0 ; xx1 = FFMIN ( ff_jpeg2000_ceildivpow2 ( band - > coord[0][0] + 1 , band - > log2_cblk_width ) < < band - > log2_cblk_width , band - > coord[0][1] ) - band - > coord[0][0] + xx0 ; for ( cblkx = 0 ; cblkx < prec - > nb_codeblocks_width ; cblkx + + , cblkno + + ) { int y , x ; if ( codsty - > transform == FF_DWT53 ) { for ( y = yy0 ; y < yy1 ; y + + ) { int * ptr = t1 . data[y - yy0] ; for ( x = xx0 ; x < xx1 ; x + + ) { * ptr + + = comp - > i_data[ ( comp - > coord[0][1] - comp - > coord[0][0] ) * y + x] < < NMSEDEC_FRACBITS ; } } } else { for ( y = yy0 ; y < yy1 ; y + + ) { int * ptr = t1 . data[y - yy0] ; for ( x = xx0 ; x < xx1 ; x + + ) { * ptr = ( comp - > i_data[ ( comp - > coord[0][1] - comp - > coord[0][0] ) * y + x] ) ; * ptr = ( int64_t ) * ptr * ( int64_t ) ( 16384 * 65536 / band - > i_stepsize ) > > 15 - NMSEDEC_FRACBITS ; ptr + + ; } } } encode_cblk ( s , & t1 , prec - > cblk + cblkno , tile , xx1 - xx0 , yy1 - yy0 , bandpos , codsty - > nreslevels - reslevelno - 1 ) ; xx0 = xx1 ; xx1 = FFMIN ( xx1 + ( 1 < < band - > log2_cblk_width ) , band - > coord[0][1] - band - > coord[0][0] + x0 ) ; } yy0 = yy1 ; yy1 = FFMIN ( yy1 + ( 1 < < band - > log2_cblk_height ) , band - > coord[1][1] - band - > coord[1][0] + y0 ) ; } } } av_log ( s - > avctx , AV_LOG_DEBUG , after tier1\n ) ; } av_log ( s - > avctx , AV_LOG_DEBUG , rate control\n ) ; truncpasses ( s , tile ) ; if ( ( ret = encode_packets ( s , tile , tileno ) ) < 0 ) return ret ; av_log ( s - > avctx , AV_LOG_DEBUG , after rate control\n ) ; return 0 ; }",0
"static int nvdec_vp9_decode_slice ( AVCodecContext * avctx , const uint8_t * buffer , uint32_t size ) { NVDECContext * ctx = avctx - > internal - > hwaccel_priv_data ; void * tmp ; tmp = av_fast_realloc ( ctx - > slice_offsets , & ctx - > slice_offsets_allocated , ( ctx - > nb_slices + 1 ) * sizeof ( * ctx - > slice_offsets ) ) ; if ( ! tmp ) return AVERROR ( ENOMEM ) ; ctx - > slice_offsets = tmp ; if ( ! ctx - > bitstream ) ctx - > bitstream = ( uint8_t * ) buffer ; ctx - > slice_offsets[ctx - > nb_slices] = buffer - ctx - > bitstream ; ctx - > bitstream_len + = size ; ctx - > nb_slices + + ; return 0 ; }",0
"static void check_mct ( uint8_t * ref0 , uint8_t * ref1 , uint8_t * ref2 , uint8_t * new0 , uint8_t * new1 , uint8_t * new2 ) { declare_func ( void , void * src0 , void * src1 , void * src2 , int csize ) ; randomize_buffers ( ) ; call_ref ( ref0 , ref1 , ref2 , BUF_SIZE / sizeof ( int32_t ) ) ; call_new ( new0 , new1 , new2 , BUF_SIZE / sizeof ( int32_t ) ) ; if ( memcmp ( ref0 , new0 , BUF_SIZE ) || memcmp ( ref1 , new1 , BUF_SIZE ) || memcmp ( ref2 , new2 , BUF_SIZE ) ) fail ( ) ; bench_new ( new0 , new1 , new2 , BUF_SIZE / sizeof ( int32_t ) ) ; }",0
"static void FUNCC ( ff_h264_add_pixels4 ) ( uint8_t * _dst , int16_t * _src , int stride ) { int i ; pixel * dst = ( pixel * ) _dst ; dctcoef * src = ( dctcoef * ) _src ; stride /= sizeof ( pixel ) ; for ( i = 0 ; i < 4 ; i + + ) { dst[0] + = src[0] ; dst[1] + = src[1] ; dst[2] + = src[2] ; dst[3] + = src[3] ; dst + = stride ; src + = 4 ; } memset ( _src , 0 , sizeof ( dctcoef ) * 16 ) ; }",1
"static void abort_codec_experimental ( AVCodec * c , int encoder ) { const char * codec_string = encoder ? encoder : decoder ; AVCodec * codec ; av_log ( NULL , AV_LOG_FATAL , %s ' %s ' is experimental and might produce bad results . \nAdd ' - strict experimental ' if you want to use it . \n , codec_string , c - > name ) ; codec = encoder ? avcodec_find_encoder ( c - > id ) : avcodec_find_decoder ( c - > id ) ; if ( ! ( codec - > capabilities & CODEC_CAP_EXPERIMENTAL ) ) av_log ( NULL , AV_LOG_FATAL , Or use the non experimental %s ' %s ' . \n , codec_string , codec - > name ) ; exit ( 1 ) ; }",1
static inline void downmix_2f_2r_to_mono ( float * samples ) { int i ; for ( i = 0 ; i < 256 ; i + + ) { samples[i] + = ( samples[i + 256] + samples[i + 512] + samples[i + 768] ) ; samples[i + 256] = samples[i + 512] = samples[i + 768] = 0 ; } },0
"static int mxf_read_header ( AVFormatContext * s ) { MXFContext * mxf = s - > priv_data ; KLVPacket klv ; int64_t essence_offset = 0 ; int ret ; mxf - > last_forward_tell = INT64_MAX ; mxf - > edit_units_per_packet = 1 ; if ( ! mxf_read_sync ( s - > pb , mxf_header_partition_pack_key , 14 ) ) { av_log ( s , AV_LOG_ERROR , could not find header partition pack key\n ) ; return AVERROR_INVALIDDATA ; } avio_seek ( s - > pb , - 14 , SEEK_CUR ) ; mxf - > fc = s ; mxf - > run_in = avio_tell ( s - > pb ) ; mxf_read_random_index_pack ( s ) ; while ( ! url_feof ( s - > pb ) ) { const MXFMetadataReadTableEntry * metadata ; if ( klv_read_packet ( & klv , s - > pb ) < 0 ) { / * EOF - seek to previous partition or stop * / if ( mxf_parse_handle_partition_or_eof ( mxf ) < = 0 ) break ; else continue ; } PRINT_KEY ( s , read header , klv . key ) ; av_dlog ( s , size % PRIu64 offset % PRIx64 \n , klv . length , klv . offset ) ; if ( IS_KLV_KEY ( klv . key , mxf_encrypted_triplet_key ) || IS_KLV_KEY ( klv . key , mxf_essence_element_key ) || IS_KLV_KEY ( klv . key , mxf_avid_essence_element_key ) || IS_KLV_KEY ( klv . key , mxf_system_item_key ) ) { if ( ! mxf - > current_partition ) { av_log ( mxf - > fc , AV_LOG_ERROR , found essence prior to first PartitionPack\n ) ; return AVERROR_INVALIDDATA ; } if ( ! mxf - > current_partition - > essence_offset ) { / * for OP1a we compute essence_offset * for OPAtom we point essence_offset after the KL ( usually op1a_essence_offset + 20 or 25 ) * TODO : for OP1a we could eliminate this entire if statement , always stopping parsing at op1a_essence_offset * for OPAtom we still need the actual essence_offset though ( the KL ' s length can vary ) * / int64_t op1a_essence_offset = round_to_kag ( mxf - > current_partition - > this_partition + mxf - > current_partition - > pack_length , mxf - > current_partition - > kag_size ) + round_to_kag ( mxf - > current_partition - > header_byte_count , mxf - > current_partition - > kag_size ) + round_to_kag ( mxf - > current_partition - > index_byte_count , mxf - > current_partition - > kag_size ) ; if ( mxf - > op == OPAtom ) { / * point essence_offset to the actual data * OPAtom has all the essence in one big KLV * / mxf - > current_partition - > essence_offset = avio_tell ( s - > pb ) ; mxf - > current_partition - > essence_length = klv . length ; } else { / * NOTE : op1a_essence_offset may be less than to klv . offset ( C0023S01 . mxf ) * / mxf - > current_partition - > essence_offset = op1a_essence_offset ; } } if ( ! essence_offset ) essence_offset = klv . offset ; / * seek to footer , previous partition or stop * / if ( mxf_parse_handle_essence ( mxf ) < = 0 ) break ; continue ; } else if ( ! memcmp ( klv . key , mxf_header_partition_pack_key , 13 ) & & klv . key[13] > = 2 & & klv . key[13] < = 4 & & mxf - > current_partition ) { / * next partition pack - keep going , seek to previous partition or stop * / if ( mxf_parse_handle_partition_or_eof ( mxf ) < = 0 ) break ; else if ( mxf - > parsing_backward ) continue ; / * we ' re still parsing forward . proceed to parsing this partition pack * / } for ( metadata = mxf_metadata_read_table ; metadata - > read ; metadata + + ) { if ( IS_KLV_KEY ( klv . key , metadata - > key ) ) { int res ; if ( klv . key[5] == 0x53 ) { res = mxf_read_local_tags ( mxf , & klv , metadata - > read , metadata - > ctx_size , metadata - > type ) ; } else { uint64_t next = avio_tell ( s - > pb ) + klv . length ; res = metadata - > read ( mxf , s - > pb , 0 , klv . length , klv . key , klv . offset ) ; / * only seek forward , else this can loop for a long time * / if ( avio_tell ( s - > pb ) > next ) { av_log ( s , AV_LOG_ERROR , read past end of KLV % PRIx64 \n , klv . offset ) ; return AVERROR_INVALIDDATA ; } avio_seek ( s - > pb , next , SEEK_SET ) ; } if ( res < 0 ) { av_log ( s , AV_LOG_ERROR , error reading header metadata\n ) ; return res ; } break ; } } if ( ! metadata - > read ) avio_skip ( s - > pb , klv . length ) ; } / * FIXME avoid seek * / if ( ! essence_offset ) { av_log ( s , AV_LOG_ERROR , no essence\n ) ; return AVERROR_INVALIDDATA ; } avio_seek ( s - > pb , essence_offset , SEEK_SET ) ; mxf_compute_essence_containers ( mxf ) ; / * we need to do this before computing the index tables * to be able to fill in zero IndexDurations with st - > duration * / if ( ( ret = mxf_parse_structural_metadata ( mxf ) ) < 0 ) goto fail ; if ( ( ret = mxf_compute_index_tables ( mxf ) ) < 0 ) goto fail ; if ( mxf - > nb_index_tables > 1 ) { / * TODO : look up which IndexSID to use via EssenceContainerData * / av_log ( mxf - > fc , AV_LOG_INFO , got %i index tables - only the first one ( IndexSID %i ) will be used\n , mxf - > nb_index_tables , mxf - > index_tables[0] . index_sid ) ; } else if ( mxf - > nb_index_tables == 0 & & mxf - > op == OPAtom ) { av_log ( mxf - > fc , AV_LOG_ERROR , cannot demux OPAtom without an index\n ) ; ret = AVERROR_INVALIDDATA ; goto fail ; } mxf_handle_small_eubc ( s ) ; return 0 ; fail : mxf_read_close ( s ) ; return ret ; }",0
static inline void downmix_3f_1r_to_dolby ( float * samples ) { int i ; for ( i = 0 ; i < 256 ; i + + ) { samples[i] + = ( samples[i + 256] - samples[i + 768] ) ; samples[i + 256] + = ( samples[i + 512] + samples[i + 768] ) ; samples[i + 512] = samples[i + 768] = 0 ; } },0
"void compute_images_mse ( PSNRContext * s , const uint8_t * main_data[4] , const int main_linesizes[4] , const uint8_t * ref_data[4] , const int ref_linesizes[4] , int w , int h , double mse[4] ) { int i , c , j ; for ( c = 0 ; c < s - > nb_components ; c + + ) { const int outw = s - > planewidth[c] ; const int outh = s - > planeheight[c] ; const uint8_t * main_line = main_data[c] ; const uint8_t * ref_line = ref_data[c] ; const int ref_linesize = ref_linesizes[c] ; const int main_linesize = main_linesizes[c] ; int m = 0 ; for ( i = 0 ; i < outh ; i + + ) { for ( j = 0 ; j < outw ; j + + ) m + = pow2 ( main_line[j] - ref_line[j] ) ; ref_line + = ref_linesize ; main_line + = main_linesize ; } mse[c] = m / ( double ) ( outw * outh ) ; } }",1
"static inline void hyscale_fast_c ( SwsContext * c , int16_t * dst , int dstWidth , const uint8_t * src , int srcW , int xInc ) { int i ; unsigned int xpos=0 ; for ( i=0 ; i < dstWidth ; i + + ) { register unsigned int xx=xpos > > 16 ; register unsigned int xalpha= ( xpos & 0xFFFF ) > > 9 ; dst[i]= ( src[xx] < < 7 ) + ( src[xx + 1] - src[xx] ) * xalpha ; xpos + =xInc ; } }",1
"static int standard_decode_i_mbs ( VC9Context * v ) { GetBitContext * gb = & v - > s . gb ; MpegEncContext * s = & v - > s ; int current_mb = 0 ; / * MB/Block Position info * / uint8_t cbpcy[4] , previous_cbpcy[4] , predicted_cbpcy , * p_cbpcy / * Pointer to skip some math * / ; / * Reset CBPCY predictors * / memset ( v - > previous_line_cbpcy , 0 , s - > mb_stride < < 2 ) ; / * Select ttmb table depending on pq * / if ( v - > pq < 5 ) v - > ttmb_vlc = & vc9_ttmb_vlc[0] ; else if ( v - > pq < 13 ) v - > ttmb_vlc = & vc9_ttmb_vlc[1] ; else v - > ttmb_vlc = & vc9_ttmb_vlc[2] ; for ( s - > mb_y=0 ; s - > mb_y < s - > mb_height ; s - > mb_y + + ) { / * Init CBPCY for line * / * ( ( uint32_t * ) previous_cbpcy ) = 0x00000000 ; p_cbpcy = v - > previous_line_cbpcy + 4 ; for ( s - > mb_x=0 ; s - > mb_x < s - > mb_width ; s - > mb_x + + , p_cbpcy + = 4 ) { / * Get CBPCY * / GET_CBPCY ( ff_msmp4_mb_i_vlc . table , MB_INTRA_VLC_BITS ) ; s - > ac_pred = get_bits ( gb , 1 ) ; / * TODO : Decode blocks from that mb wrt cbpcy * / / * Update for next block * / if TRACE > 2 av_log ( s - > avctx , AV_LOG_DEBUG , Block %4i : p_cbpcy=%i%i%i%i , previous_cbpcy=%i%i%i%i , cbpcy=%i%i%i%i\n , current_mb , p_cbpcy[0] , p_cbpcy[1] , p_cbpcy[2] , p_cbpcy[3] , previous_cbpcy[0] , previous_cbpcy[1] , previous_cbpcy[2] , previous_cbpcy[3] , cbpcy[0] , cbpcy[1] , cbpcy[2] , cbpcy[3] ) ; endif * ( ( uint32_t * ) p_cbpcy ) = * ( ( uint32_t * ) previous_cbpcy ) ; * ( ( uint32_t * ) previous_cbpcy ) = * ( ( uint32_t * ) cbpcy ) ; current_mb + + ; } } return 0 ; }",1
"static int ape_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame_ptr , AVPacket * avpkt ) { AVFrame * frame = data ; const uint8_t * buf = avpkt - > data ; APEContext * s = avctx - > priv_data ; uint8_t * sample8 ; int16_t * sample16 ; int32_t * sample24 ; int i , ch , ret ; int blockstodecode ; / * this should never be negative , but bad things will happen if it is , so check it just to make sure . * / av_assert0 ( s - > samples > = 0 ) ; if ( ! s - > samples ) { uint32_t nblocks , offset ; int buf_size ; if ( ! avpkt - > size ) { * got_frame_ptr = 0 ; return 0 ; } if ( avpkt - > size < 8 ) { av_log ( avctx , AV_LOG_ERROR , Packet is too small\n ) ; return AVERROR_INVALIDDATA ; } buf_size = avpkt - > size & 3 ; if ( buf_size ! = avpkt - > size ) { av_log ( avctx , AV_LOG_WARNING , packet size is not a multiple of 4 . extra bytes at the end will be skipped . \n ) ; } if ( s - > fileversion < 3950 ) // previous versions overread two bytes buf_size + = 2 ; av_fast_padded_malloc ( & s - > data , & s - > data_size , buf_size ) ; if ( ! s - > data ) return AVERROR ( ENOMEM ) ; s - > bdsp . bswap_buf ( ( uint32_t * ) s - > data , ( const uint32_t * ) buf , buf_size > > 2 ) ; memset ( s - > data + ( buf_size & 3 ) , 0 , buf_size & 3 ) ; s - > ptr = s - > data ; s - > data_end = s - > data + buf_size ; nblocks = bytestream_get_be32 ( & s - > ptr ) ; offset = bytestream_get_be32 ( & s - > ptr ) ; if ( s - > fileversion > = 3900 ) { if ( offset > 3 ) { av_log ( avctx , AV_LOG_ERROR , Incorrect offset passed\n ) ; s - > data = NULL ; return AVERROR_INVALIDDATA ; } if ( s - > data_end - s - > ptr < offset ) { av_log ( avctx , AV_LOG_ERROR , Packet is too small\n ) ; return AVERROR_INVALIDDATA ; } s - > ptr + = offset ; } else { if ( ( ret = init_get_bits8 ( & s - > gb , s - > ptr , s - > data_end - s - > ptr ) ) < 0 ) return ret ; if ( s - > fileversion > 3800 ) skip_bits_long ( & s - > gb , offset * 8 ) ; else skip_bits_long ( & s - > gb , offset ) ; } if ( ! nblocks || nblocks > INT_MAX ) { av_log ( avctx , AV_LOG_ERROR , Invalid sample count : % PRIu32 . \n , nblocks ) ; return AVERROR_INVALIDDATA ; } s - > samples = nblocks ; / * Initialize the frame decoder * / if ( init_frame_decoder ( s ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , Error reading frame header\n ) ; return AVERROR_INVALIDDATA ; } } if ( ! s - > data ) { * got_frame_ptr = 0 ; return avpkt - > size ; } blockstodecode = FFMIN ( s - > blocks_per_loop , s - > samples ) ; // for old files coefficients were not interleaved , // so we need to decode all of them at once if ( s - > fileversion < 3930 ) blockstodecode = s - > samples ; / * reallocate decoded sample buffer if needed * / av_fast_malloc ( & s - > decoded_buffer , & s - > decoded_size , 2 * FFALIGN ( blockstodecode , 8 ) * sizeof ( * s - > decoded_buffer ) ) ; if ( ! s - > decoded_buffer ) return AVERROR ( ENOMEM ) ; memset ( s - > decoded_buffer , 0 , s - > decoded_size ) ; s - > decoded[0] = s - > decoded_buffer ; s - > decoded[1] = s - > decoded_buffer + FFALIGN ( blockstodecode , 8 ) ; / * get output buffer * / frame - > nb_samples = blockstodecode ; if ( ( ret = ff_get_buffer ( avctx , frame , 0 ) ) < 0 ) return ret ; s - > error=0 ; if ( ( s - > channels == 1 ) || ( s - > frameflags & APE_FRAMECODE_PSEUDO_STEREO ) ) ape_unpack_mono ( s , blockstodecode ) ; else ape_unpack_stereo ( s , blockstodecode ) ; emms_c ( ) ; if ( s - > error ) { s - > samples=0 ; av_log ( avctx , AV_LOG_ERROR , Error decoding frame\n ) ; return AVERROR_INVALIDDATA ; } switch ( s - > bps ) { case 8 : for ( ch = 0 ; ch < s - > channels ; ch + + ) { sample8 = ( uint8_t * ) frame - > data[ch] ; for ( i = 0 ; i < blockstodecode ; i + + ) * sample8 + + = ( s - > decoded[ch][i] + 0x80 ) & 0xff ; } break ; case 16 : for ( ch = 0 ; ch < s - > channels ; ch + + ) { sample16 = ( int16_t * ) frame - > data[ch] ; for ( i = 0 ; i < blockstodecode ; i + + ) * sample16 + + = s - > decoded[ch][i] ; } break ; case 24 : for ( ch = 0 ; ch < s - > channels ; ch + + ) { sample24 = ( int32_t * ) frame - > data[ch] ; for ( i = 0 ; i < blockstodecode ; i + + ) * sample24 + + = s - > decoded[ch][i] < < 8 ; } break ; } s - > samples - = blockstodecode ; * got_frame_ptr = 1 ; return ! s - > samples ? avpkt - > size : 0 ; }",0
"static int decode_plane ( UtvideoContext * c , int plane_no , uint8_t * dst , int step , int stride , int width , int height , const uint8_t * src , int src_size , int use_pred ) { int i , j , slice , pix ; int sstart , send ; VLC vlc ; GetBitContext gb ; int prev ; const int cmask = ( ! plane_no & & c - > avctx - > pix_fmt == PIX_FMT_YUV420P ) ; if ( build_huff ( src , & vlc ) ) { av_log ( c - > avctx , AV_LOG_ERROR , Cannot build Huffman codes\n ) ; return AVERROR_INVALIDDATA ; } src + = 256 ; src_size - = 256 ; send = 0 ; for ( slice = 0 ; slice < c - > slices ; slice + + ) { uint8_t * dest ; int slice_data_start , slice_data_end , slice_size ; sstart = send ; send = ( height * ( slice + 1 ) / c - > slices ) & cmask ; dest = dst + sstart * stride ; // slice offset and size validation was done earlier slice_data_start = slice ? AV_RL32 ( src + slice * 4 - 4 ) : 0 ; slice_data_end = AV_RL32 ( src + slice * 4 ) ; slice_size = slice_data_end - slice_data_start ; if ( ! slice_size ) { for ( j = sstart ; j < send ; j + + ) { for ( i = 0 ; i < width * step ; i + = step ) dest[i] = 0x80 ; dest + = stride ; } continue ; } memcpy ( c - > slice_bits , src + slice_data_start + c - > slices * 4 , slice_size ) ; memset ( c - > slice_bits + slice_size , 0 , FF_INPUT_BUFFER_PADDING_SIZE ) ; c - > dsp . bswap_buf ( ( uint32_t * ) c - > slice_bits , ( uint32_t * ) c - > slice_bits , ( slice_data_end - slice_data_start + 3 ) > > 2 ) ; init_get_bits ( & gb , c - > slice_bits , slice_size * 8 ) ; prev = 0x80 ; for ( j = sstart ; j < send ; j + + ) { for ( i = 0 ; i < width * step ; i + = step ) { if ( get_bits_left ( & gb ) < = 0 ) { av_log ( c - > avctx , AV_LOG_ERROR , Slice decoding ran out of bits\n ) ; goto fail ; } pix = get_vlc2 ( & gb , vlc . table , vlc . bits , 4 ) ; if ( pix < 0 ) { av_log ( c - > avctx , AV_LOG_ERROR , Decoding error\n ) ; goto fail ; } if ( use_pred ) { prev + = pix ; pix = prev ; } dest[i] = pix ; } dest + = stride ; } if ( get_bits_left ( & gb ) > 32 ) av_log ( c - > avctx , AV_LOG_WARNING , %d bits left after decoding slice\n , get_bits_left ( & gb ) ) ; } free_vlc ( & vlc ) ; return 0 ; fail : free_vlc ( & vlc ) ; return AVERROR_INVALIDDATA ; }",0
"static int mov_read_dac3 ( MOVContext * c , AVIOContext * pb , MOVAtom atom ) { AVStream * st ; enum AVAudioServiceType * ast ; int ac3info , acmod , lfeon , bsmod ; if ( c - > fc - > nb_streams < 1 ) return 0 ; st = c - > fc - > streams[c - > fc - > nb_streams - 1] ; ast = ( enum AVAudioServiceType * ) ff_stream_new_side_data ( st , AV_PKT_DATA_AUDIO_SERVICE_TYPE , sizeof ( * ast ) ) ; if ( ! ast ) return AVERROR ( ENOMEM ) ; ac3info = avio_rb24 ( pb ) ; bsmod = ( ac3info > > 14 ) & 0x7 ; acmod = ( ac3info > > 11 ) & 0x7 ; lfeon = ( ac3info > > 10 ) & 0x1 ; st - > codec - > channels = ( ( int[] ) { 2 , 1 , 2 , 3 , 3 , 4 , 4 , 5 } ) [acmod] + lfeon ; st - > codec - > channel_layout = avpriv_ac3_channel_layout_tab[acmod] ; if ( lfeon ) st - > codec - > channel_layout |= AV_CH_LOW_FREQUENCY ; * ast = bsmod ; if ( st - > codec - > channels > 1 & & bsmod == 0x7 ) * ast = AV_AUDIO_SERVICE_TYPE_KARAOKE ; st - > codec - > audio_service_type = * ast ; return 0 ; }",0
"static int set_pix_fmt ( AVCodecContext * avctx , struct vpx_image * img , int has_alpha_channel ) { if VPX_IMAGE_ABI_VERSION > = 3 static const enum AVColorSpace colorspaces[8] = { AVCOL_SPC_UNSPECIFIED , AVCOL_SPC_BT470BG , AVCOL_SPC_BT709 , AVCOL_SPC_SMPTE170M , AVCOL_SPC_SMPTE240M , AVCOL_SPC_BT2020_NCL , AVCOL_SPC_RESERVED , AVCOL_SPC_RGB , } ; if VPX_IMAGE_ABI_VERSION > = 4 static const enum AVColorRange color_ranges[] = { AVCOL_RANGE_MPEG , AVCOL_RANGE_JPEG } ; avctx - > color_range = color_ranges[img - > range] ; endif avctx - > colorspace = colorspaces[img - > cs] ; endif if ( avctx - > codec_id == AV_CODEC_ID_VP8 & & img - > fmt ! = VPX_IMG_FMT_I420 ) return AVERROR_INVALIDDATA ; switch ( img - > fmt ) { case VPX_IMG_FMT_I420 : if ( avctx - > codec_id == AV_CODEC_ID_VP9 ) avctx - > profile = FF_PROFILE_VP9_0 ; avctx - > pix_fmt = has_alpha_channel ? AV_PIX_FMT_YUVA420P : AV_PIX_FMT_YUV420P ; return 0 ; if CONFIG_LIBVPX_VP9_DECODER case VPX_IMG_FMT_I422 : avctx - > profile = FF_PROFILE_VP9_1 ; avctx - > pix_fmt = AV_PIX_FMT_YUV422P ; return 0 ; if VPX_IMAGE_ABI_VERSION > = 3 case VPX_IMG_FMT_I440 : avctx - > profile = FF_PROFILE_VP9_1 ; avctx - > pix_fmt = AV_PIX_FMT_YUV440P ; return 0 ; endif case VPX_IMG_FMT_I444 : avctx - > profile = FF_PROFILE_VP9_1 ; if VPX_IMAGE_ABI_VERSION > = 3 avctx - > pix_fmt = avctx - > colorspace == AVCOL_SPC_RGB ? AV_PIX_FMT_GBRP : AV_PIX_FMT_YUV444P ; else avctx - > pix_fmt = AV_PIX_FMT_YUV444P ; endif return 0 ; ifdef VPX_IMG_FMT_HIGHBITDEPTH case VPX_IMG_FMT_I42016 : avctx - > profile = FF_PROFILE_VP9_2 ; if ( img - > bit_depth == 10 ) { avctx - > pix_fmt = AV_PIX_FMT_YUV420P10 ; return 0 ; } else if ( img - > bit_depth == 12 ) { avctx - > pix_fmt = AV_PIX_FMT_YUV420P12 ; return 0 ; } else { return AVERROR_INVALIDDATA ; } case VPX_IMG_FMT_I42216 : avctx - > profile = FF_PROFILE_VP9_3 ; if ( img - > bit_depth == 10 ) { avctx - > pix_fmt = AV_PIX_FMT_YUV422P10 ; return 0 ; } else if ( img - > bit_depth == 12 ) { avctx - > pix_fmt = AV_PIX_FMT_YUV422P12 ; return 0 ; } else { return AVERROR_INVALIDDATA ; } if VPX_IMAGE_ABI_VERSION > = 3 case VPX_IMG_FMT_I44016 : avctx - > profile = FF_PROFILE_VP9_3 ; if ( img - > bit_depth == 10 ) { avctx - > pix_fmt = AV_PIX_FMT_YUV440P10 ; return 0 ; } else if ( img - > bit_depth == 12 ) { avctx - > pix_fmt = AV_PIX_FMT_YUV440P12 ; return 0 ; } else { return AVERROR_INVALIDDATA ; } endif case VPX_IMG_FMT_I44416 : avctx - > profile = FF_PROFILE_VP9_3 ; if ( img - > bit_depth == 10 ) { if VPX_IMAGE_ABI_VERSION > = 3 avctx - > pix_fmt = avctx - > colorspace == AVCOL_SPC_RGB ? AV_PIX_FMT_GBRP10 : AV_PIX_FMT_YUV444P10 ; else avctx - > pix_fmt = AV_PIX_FMT_YUV444P10 ; endif return 0 ; } else if ( img - > bit_depth == 12 ) { if VPX_IMAGE_ABI_VERSION > = 3 avctx - > pix_fmt = avctx - > colorspace == AVCOL_SPC_RGB ? AV_PIX_FMT_GBRP12 : AV_PIX_FMT_YUV444P12 ; else avctx - > pix_fmt = AV_PIX_FMT_YUV444P12 ; endif return 0 ; } else { return AVERROR_INVALIDDATA ; } endif endif default : return AVERROR_INVALIDDATA ; } }",0
"static int mpsub_probe ( AVProbeData * p ) { const char * ptr = p - > buf ; const char * ptr_end = p - > buf + p - > buf_size ; while ( ptr < ptr_end ) { if ( ! memcmp ( ptr , FORMAT=TIME , 11 ) ) return AVPROBE_SCORE_EXTENSION ; if ( ! memcmp ( ptr , FORMAT= , 7 ) ) return AVPROBE_SCORE_EXTENSION / 3 ; ptr + = strcspn ( ptr , \n ) + 1 ; } return 0 ; }",1
"void MPV_common_init_altivec ( MpegEncContext * s ) { if ( s - > avctx - > lowres==0 ) { if ( ( s - > avctx - > idct_algo == FF_IDCT_AUTO ) || ( s - > avctx - > idct_algo == FF_IDCT_ALTIVEC ) ) { s - > dsp . idct_put = idct_put_altivec ; s - > dsp . idct_add = idct_add_altivec ; s - > dsp . idct_permutation_type = FF_TRANSPOSE_IDCT_PERM ; } } // Test to make sure that the dct required alignments are met . if ( ( ( ( long ) ( s - > q_intra_matrix ) & 0x0f ) ! = 0 ) || ( ( ( long ) ( s - > q_inter_matrix ) & 0x0f ) ! = 0 ) ) { av_log ( s - > avctx , AV_LOG_INFO , Internal Error : q - matrix blocks must be 16 - byte aligned to use AltiVec DCT . Reverting to non - AltiVec version . \n ) ; return ; } if ( ( ( long ) ( s - > intra_scantable . inverse ) & 0x0f ) ! = 0 ) { av_log ( s - > avctx , AV_LOG_INFO , Internal Error : scan table blocks must be 16 - byte aligned to use AltiVec DCT . Reverting to non - AltiVec version . \n ) ; return ; } if ( ( s - > avctx - > dct_algo == FF_DCT_AUTO ) || ( s - > avctx - > dct_algo == FF_DCT_ALTIVEC ) ) { if 0 / * seems to cause trouble under some circumstances * / s - > dct_quantize = dct_quantize_altivec ; endif s - > dct_unquantize_h263_intra = dct_unquantize_h263_altivec ; s - > dct_unquantize_h263_inter = dct_unquantize_h263_altivec ; } }",1
"static int configure_output_filter ( FilterGraph * fg , OutputFilter * ofilter , AVFilterInOut * out ) { char * pix_fmts ; AVCodecContext * codec = ofilter - > ost - > st - > codec ; AVFilterContext * last_filter = out - > filter_ctx ; int pad_idx = out - > pad_idx ; int ret ; AVBufferSinkParams * buffersink_params = av_buffersink_params_alloc ( ) ; if FF_API_OLD_VSINK_API ret = avfilter_graph_create_filter ( & ofilter - > filter , avfilter_get_by_name ( buffersink ) , out , NULL , NULL , fg - > graph ) ; else ret = avfilter_graph_create_filter ( & ofilter - > filter , avfilter_get_by_name ( buffersink ) , out , NULL , buffersink_params , fg - > graph ) ; endif av_freep ( & buffersink_params ) ; if ( ret < 0 ) return ret ; if ( codec - > width || codec - > height ) { char args[255] ; AVFilterContext * filter ; snprintf ( args , sizeof ( args ) , %d : %d : flags=0x%X , codec - > width , codec - > height , ( unsigned ) ofilter - > ost - > sws_flags ) ; if ( ( ret = avfilter_graph_create_filter ( & filter , avfilter_get_by_name ( scale ) , NULL , args , NULL , fg - > graph ) ) < 0 ) return ret ; if ( ( ret = avfilter_link ( last_filter , pad_idx , filter , 0 ) ) < 0 ) return ret ; last_filter = filter ; pad_idx = 0 ; } if ( ( pix_fmts = choose_pixel_fmts ( ofilter - > ost ) ) ) { AVFilterContext * filter ; if ( ( ret = avfilter_graph_create_filter ( & filter , avfilter_get_by_name ( format ) , format , pix_fmts , NULL , fg - > graph ) ) < 0 ) return ret ; if ( ( ret = avfilter_link ( last_filter , pad_idx , filter , 0 ) ) < 0 ) return ret ; last_filter = filter ; pad_idx = 0 ; av_freep ( & pix_fmts ) ; } if ( ( ret = avfilter_link ( last_filter , pad_idx , ofilter - > filter , 0 ) ) < 0 ) return ret ; return 0 ; }",1
"static int eightsvx_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame_ptr , AVPacket * avpkt ) { EightSvxContext * esc = avctx - > priv_data ; int n , out_data_size , ret ; uint8_t * src , * dst ; / * decode and interleave the first packet * / if ( ! esc - > samples & & avpkt ) { uint8_t * deinterleaved_samples , * p = NULL ; esc - > samples_size = ! esc - > table ? avpkt - > size : avctx - > channels + ( avpkt - > size - avctx - > channels ) * 2 ; if ( ! ( esc - > samples = av_malloc ( esc - > samples_size ) ) ) return AVERROR ( ENOMEM ) ; / * decompress * / if ( esc - > table ) { const uint8_t * buf = avpkt - > data ; uint8_t * dst ; int buf_size = avpkt - > size ; int i , n = esc - > samples_size ; if ( buf_size < 2 ) { av_log ( avctx , AV_LOG_ERROR , packet size is too small\n ) ; return AVERROR ( EINVAL ) ; } if ( ! ( deinterleaved_samples = av_mallocz ( n ) ) ) return AVERROR ( ENOMEM ) ; dst = p = deinterleaved_samples ; / * the uncompressed starting value is contained in the first byte * / dst = deinterleaved_samples ; for ( i = 0 ; i < avctx - > channels ; i + + ) { delta_decode ( dst , buf + 1 , buf_size / avctx - > channels - 1 , buf[0] , esc - > table ) ; buf + = buf_size / avctx - > channels ; dst + = n / avctx - > channels - 1 ; } } else { deinterleaved_samples = avpkt - > data ; } if ( avctx - > channels == 2 ) interleave_stereo ( esc - > samples , deinterleaved_samples , esc - > samples_size ) ; else memcpy ( esc - > samples , deinterleaved_samples , esc - > samples_size ) ; av_freep ( & p ) ; } / * get output buffer * / av_assert1 ( ! ( esc - > samples_size % avctx - > channels || esc - > samples_idx % avctx - > channels ) ) ; esc - > frame . nb_samples = FFMIN ( MAX_FRAME_SIZE , esc - > samples_size - esc - > samples_idx ) / avctx - > channels ; if ( ( ret = avctx - > get_buffer ( avctx , & esc - > frame ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed\n ) ; return ret ; } * got_frame_ptr = 1 ; * ( AVFrame * ) data = esc - > frame ; dst = esc - > frame . data[0] ; src = esc - > samples + esc - > samples_idx ; out_data_size = esc - > frame . nb_samples * avctx - > channels ; for ( n = out_data_size ; n > 0 ; n - - ) * dst + + = * src + + + 128 ; esc - > samples_idx + = out_data_size ; return esc - > table ? ( avctx - > frame_number == 0 ) * 2 + out_data_size / 2 : out_data_size ; }",1
"static void int8x8_fmul_int32_c ( float * dst , const int8_t * src , int scale ) { float fscale = scale / 16 . 0 ; int i ; for ( i = 0 ; i < 8 ; i + + ) dst[i] = src[i] * fscale ; }",0
"static int ftp_auth ( FTPContext * s ) { const char * user = NULL , * pass = NULL ; char * end = NULL , buf[CONTROL_BUFFER_SIZE] , credencials[CREDENTIALS_BUFFER_SIZE] ; int err ; const int user_codes[] = { 331 , 230 , 0 } ; const int pass_codes[] = { 230 , 0 } ; / * Authentication may be repeated , original string has to be saved * / av_strlcpy ( credencials , s - > credencials , sizeof ( credencials ) ) ; user = av_strtok ( credencials , : , & end ) ; pass = av_strtok ( end , : , & end ) ; if ( ! user ) { user = anonymous ; pass = s - > anonymous_password ? s - > anonymous_password : nopassword ; } snprintf ( buf , sizeof ( buf ) , USER %s\r\n , user ) ; err = ftp_send_command ( s , buf , user_codes , NULL ) ; if ( err == 331 ) { if ( pass ) { snprintf ( buf , sizeof ( buf ) , PASS %s\r\n , pass ) ; err = ftp_send_command ( s , buf , pass_codes , NULL ) ; } else return AVERROR ( EACCES ) ; } if ( ! err ) return AVERROR ( EACCES ) ; return 0 ; }",0
"int ff_celp_lp_synthesis_filter ( int16_t * out , const int16_t * filter_coeffs , const int16_t * in , int buffer_length , int filter_length , int stop_on_overflow , int shift , int rounder ) { int i , n ; for ( n = 0 ; n < buffer_length ; n + + ) { int sum = rounder ; for ( i = 1 ; i < = filter_length ; i + + ) sum - = filter_coeffs[i - 1] * out[n - i] ; sum = ( ( sum > > 12 ) + in[n] ) > > shift ; if ( sum + 0x8000 > 0xFFFFU ) { if ( stop_on_overflow ) return 1 ; sum = ( sum > > 31 ) 32767 ; } out[n] = sum ; } return 0 ; }",0
"static int push_samples ( AVFilterLink * outlink ) { ASNSContext * asns = outlink - > src - > priv ; AVFrame * outsamples = NULL ; int ret , nb_out_samples , nb_pad_samples ; if ( asns - > pad ) { nb_out_samples = av_audio_fifo_size ( asns - > fifo ) ? asns - > nb_out_samples : 0 ; nb_pad_samples = nb_out_samples - FFMIN ( nb_out_samples , av_audio_fifo_size ( asns - > fifo ) ) ; } else { nb_out_samples = FFMIN ( asns - > nb_out_samples , av_audio_fifo_size ( asns - > fifo ) ) ; nb_pad_samples = 0 ; } if ( ! nb_out_samples ) return 0 ; outsamples = ff_get_audio_buffer ( outlink , nb_out_samples ) ; av_assert0 ( outsamples ) ; av_audio_fifo_read ( asns - > fifo , ( void * * ) outsamples - > extended_data , nb_out_samples ) ; if ( nb_pad_samples ) av_samples_set_silence ( outsamples - > extended_data , nb_out_samples - nb_pad_samples , nb_pad_samples , av_get_channel_layout_nb_channels ( outlink - > channel_layout ) , outlink - > format ) ; outsamples - > nb_samples = nb_out_samples ; outsamples - > channel_layout = outlink - > channel_layout ; outsamples - > sample_rate = outlink - > sample_rate ; outsamples - > pts = asns - > next_out_pts ; if ( asns - > next_out_pts ! = AV_NOPTS_VALUE ) asns - > next_out_pts + = nb_out_samples ; ret = ff_filter_frame ( outlink , outsamples ) ; if ( ret < 0 ) return ret ; asns - > req_fullfilled = 1 ; return nb_out_samples ; }",0
"static void truemotion1_decode_16bit ( TrueMotion1Context * s ) { int y ; int pixels_left ; / * remaining pixels on this line * / unsigned int predictor_pair ; unsigned int horiz_pred ; unsigned int * vert_pred ; unsigned int * current_pixel_pair ; unsigned char * current_line = s - > frame - > data[0] ; int keyframe = s - > flags & FLAG_KEYFRAME ; / * these variables are for managing the stream of macroblock change bits * / const unsigned char * mb_change_bits = s - > mb_change_bits ; unsigned char mb_change_byte ; unsigned char mb_change_byte_mask ; int mb_change_index ; / * these variables are for managing the main index stream * / int index_stream_index = 0 ; / * yes , the index into the index stream * / int index ; / * clean out the line buffer * / memset ( s - > vert_pred , 0 , s - > avctx - > width * sizeof ( unsigned int ) ) ; GET_NEXT_INDEX ( ) ; for ( y = 0 ; y < s - > avctx - > height ; y + + ) { / * re - init variables for the next line iteration * / horiz_pred = 0 ; current_pixel_pair = ( unsigned int * ) current_line ; vert_pred = s - > vert_pred ; mb_change_index = 0 ; mb_change_byte = mb_change_bits[mb_change_index + + ] ; mb_change_byte_mask = 0x01 ; pixels_left = s - > avctx - > width ; while ( pixels_left > 0 ) { if ( keyframe || ( ( mb_change_byte & mb_change_byte_mask ) == 0 ) ) { switch ( y & 3 ) { case 0 : / * if macroblock width is 2 , apply C - Y - C - Y ; else * apply C - Y - Y * / if ( s - > block_width == 2 ) { APPLY_C_PREDICTOR ( ) ; APPLY_Y_PREDICTOR ( ) ; OUTPUT_PIXEL_PAIR ( ) ; APPLY_C_PREDICTOR ( ) ; APPLY_Y_PREDICTOR ( ) ; OUTPUT_PIXEL_PAIR ( ) ; } else { APPLY_C_PREDICTOR ( ) ; APPLY_Y_PREDICTOR ( ) ; OUTPUT_PIXEL_PAIR ( ) ; APPLY_Y_PREDICTOR ( ) ; OUTPUT_PIXEL_PAIR ( ) ; } break ; case 1 : case 3 : / * always apply 2 Y predictors on these iterations * / APPLY_Y_PREDICTOR ( ) ; OUTPUT_PIXEL_PAIR ( ) ; APPLY_Y_PREDICTOR ( ) ; OUTPUT_PIXEL_PAIR ( ) ; break ; case 2 : / * this iteration might be C - Y - C - Y , Y - Y , or C - Y - Y * depending on the macroblock type * / if ( s - > block_type == BLOCK_2x2 ) { APPLY_C_PREDICTOR ( ) ; APPLY_Y_PREDICTOR ( ) ; OUTPUT_PIXEL_PAIR ( ) ; APPLY_C_PREDICTOR ( ) ; APPLY_Y_PREDICTOR ( ) ; OUTPUT_PIXEL_PAIR ( ) ; } else if ( s - > block_type == BLOCK_4x2 ) { APPLY_C_PREDICTOR ( ) ; APPLY_Y_PREDICTOR ( ) ; OUTPUT_PIXEL_PAIR ( ) ; APPLY_Y_PREDICTOR ( ) ; OUTPUT_PIXEL_PAIR ( ) ; } else { APPLY_Y_PREDICTOR ( ) ; OUTPUT_PIXEL_PAIR ( ) ; APPLY_Y_PREDICTOR ( ) ; OUTPUT_PIXEL_PAIR ( ) ; } break ; } } else { / * skip ( copy ) four pixels , but reassign the horizontal * predictor * / * vert_pred + + = * current_pixel_pair + + ; horiz_pred = * current_pixel_pair - * vert_pred ; * vert_pred + + = * current_pixel_pair + + ; } if ( ! keyframe ) { mb_change_byte_mask < < = 1 ; / * next byte * / if ( ! mb_change_byte_mask ) { mb_change_byte = mb_change_bits[mb_change_index + + ] ; mb_change_byte_mask = 0x01 ; } } pixels_left - = 4 ; } / * next change row * / if ( ( ( y + 1 ) & 3 ) == 0 ) mb_change_bits + = s - > mb_change_bits_row_size ; current_line + = s - > frame - > linesize[0] ; } }",0
"av_cold void dsputil_init ( DSPContext * c , AVCodecContext * avctx ) { int i ; ff_check_alignment ( ) ; if CONFIG_ENCODERS if ( avctx - > bits_per_raw_sample == 10 ) { c - > fdct = ff_jpeg_fdct_islow_10 ; c - > fdct248 = ff_fdct248_islow_10 ; } else { if ( avctx - > dct_algo==FF_DCT_FASTINT ) { c - > fdct = fdct_ifast ; c - > fdct248 = fdct_ifast248 ; } else if ( avctx - > dct_algo==FF_DCT_FAAN ) { c - > fdct = ff_faandct ; c - > fdct248 = ff_faandct248 ; } else { c - > fdct = ff_jpeg_fdct_islow_8 ; //slow/accurate/default c - > fdct248 = ff_fdct248_islow_8 ; } } endif //CONFIG_ENCODERS if ( avctx - > lowres==1 ) { c - > idct_put= ff_jref_idct4_put ; c - > idct_add= ff_jref_idct4_add ; c - > idct = j_rev_dct4 ; c - > idct_permutation_type= FF_NO_IDCT_PERM ; } else if ( avctx - > lowres==2 ) { c - > idct_put= ff_jref_idct2_put ; c - > idct_add= ff_jref_idct2_add ; c - > idct = j_rev_dct2 ; c - > idct_permutation_type= FF_NO_IDCT_PERM ; } else if ( avctx - > lowres==3 ) { c - > idct_put= ff_jref_idct1_put ; c - > idct_add= ff_jref_idct1_add ; c - > idct = j_rev_dct1 ; c - > idct_permutation_type= FF_NO_IDCT_PERM ; } else { if ( avctx - > bits_per_raw_sample == 10 ) { c - > idct_put = ff_simple_idct_put_10 ; c - > idct_add = ff_simple_idct_add_10 ; c - > idct = ff_simple_idct_10 ; c - > idct_permutation_type = FF_NO_IDCT_PERM ; } else { if ( avctx - > idct_algo==FF_IDCT_INT ) { c - > idct_put= ff_jref_idct_put ; c - > idct_add= ff_jref_idct_add ; c - > idct = j_rev_dct ; c - > idct_permutation_type= FF_LIBMPEG2_IDCT_PERM ; } else if ( ( CONFIG_VP3_DECODER || CONFIG_VP5_DECODER || CONFIG_VP6_DECODER ) & & avctx - > idct_algo==FF_IDCT_VP3 ) { c - > idct_put= ff_vp3_idct_put_c ; c - > idct_add= ff_vp3_idct_add_c ; c - > idct = ff_vp3_idct_c ; c - > idct_permutation_type= FF_NO_IDCT_PERM ; } else if ( avctx - > idct_algo==FF_IDCT_WMV2 ) { c - > idct_put= ff_wmv2_idct_put_c ; c - > idct_add= ff_wmv2_idct_add_c ; c - > idct = ff_wmv2_idct_c ; c - > idct_permutation_type= FF_NO_IDCT_PERM ; } else if ( avctx - > idct_algo==FF_IDCT_FAAN ) { c - > idct_put= ff_faanidct_put ; c - > idct_add= ff_faanidct_add ; c - > idct = ff_faanidct ; c - > idct_permutation_type= FF_NO_IDCT_PERM ; } else if ( CONFIG_EATGQ_DECODER & & avctx - > idct_algo==FF_IDCT_EA ) { c - > idct_put= ff_ea_idct_put_c ; c - > idct_permutation_type= FF_NO_IDCT_PERM ; } else { //accurate/default c - > idct_put = ff_simple_idct_put_8 ; c - > idct_add = ff_simple_idct_add_8 ; c - > idct = ff_simple_idct_8 ; c - > idct_permutation_type= FF_NO_IDCT_PERM ; } } } c - > diff_pixels = diff_pixels_c ; c - > put_pixels_clamped = ff_put_pixels_clamped_c ; c - > put_signed_pixels_clamped = ff_put_signed_pixels_clamped_c ; c - > add_pixels_clamped = ff_add_pixels_clamped_c ; c - > sum_abs_dctelem = sum_abs_dctelem_c ; c - > gmc1 = gmc1_c ; c - > gmc = ff_gmc_c ; c - > pix_sum = pix_sum_c ; c - > pix_norm1 = pix_norm1_c ; c - > fill_block_tab[0] = fill_block16_c ; c - > fill_block_tab[1] = fill_block8_c ; / * TODO [0] 16 [1] 8 * / c - > pix_abs[0][0] = pix_abs16_c ; c - > pix_abs[0][1] = pix_abs16_x2_c ; c - > pix_abs[0][2] = pix_abs16_y2_c ; c - > pix_abs[0][3] = pix_abs16_xy2_c ; c - > pix_abs[1][0] = pix_abs8_c ; c - > pix_abs[1][1] = pix_abs8_x2_c ; c - > pix_abs[1][2] = pix_abs8_y2_c ; c - > pix_abs[1][3] = pix_abs8_xy2_c ; c - > put_tpel_pixels_tab[ 0] = put_tpel_pixels_mc00_c ; c - > put_tpel_pixels_tab[ 1] = put_tpel_pixels_mc10_c ; c - > put_tpel_pixels_tab[ 2] = put_tpel_pixels_mc20_c ; c - > put_tpel_pixels_tab[ 4] = put_tpel_pixels_mc01_c ; c - > put_tpel_pixels_tab[ 5] = put_tpel_pixels_mc11_c ; c - > put_tpel_pixels_tab[ 6] = put_tpel_pixels_mc21_c ; c - > put_tpel_pixels_tab[ 8] = put_tpel_pixels_mc02_c ; c - > put_tpel_pixels_tab[ 9] = put_tpel_pixels_mc12_c ; c - > put_tpel_pixels_tab[10] = put_tpel_pixels_mc22_c ; c - > avg_tpel_pixels_tab[ 0] = avg_tpel_pixels_mc00_c ; c - > avg_tpel_pixels_tab[ 1] = avg_tpel_pixels_mc10_c ; c - > avg_tpel_pixels_tab[ 2] = avg_tpel_pixels_mc20_c ; c - > avg_tpel_pixels_tab[ 4] = avg_tpel_pixels_mc01_c ; c - > avg_tpel_pixels_tab[ 5] = avg_tpel_pixels_mc11_c ; c - > avg_tpel_pixels_tab[ 6] = avg_tpel_pixels_mc21_c ; c - > avg_tpel_pixels_tab[ 8] = avg_tpel_pixels_mc02_c ; c - > avg_tpel_pixels_tab[ 9] = avg_tpel_pixels_mc12_c ; c - > avg_tpel_pixels_tab[10] = avg_tpel_pixels_mc22_c ; define dspfunc ( PFX , IDX , NUM ) \ c - > PFX _pixels_tab[IDX][ 0] = PFX NUM _mc00_c ; \ c - > PFX _pixels_tab[IDX][ 1] = PFX NUM _mc10_c ; \ c - > PFX _pixels_tab[IDX][ 2] = PFX NUM _mc20_c ; \ c - > PFX _pixels_tab[IDX][ 3] = PFX NUM _mc30_c ; \ c - > PFX _pixels_tab[IDX][ 4] = PFX NUM _mc01_c ; \ c - > PFX _pixels_tab[IDX][ 5] = PFX NUM _mc11_c ; \ c - > PFX _pixels_tab[IDX][ 6] = PFX NUM _mc21_c ; \ c - > PFX _pixels_tab[IDX][ 7] = PFX NUM _mc31_c ; \ c - > PFX _pixels_tab[IDX][ 8] = PFX NUM _mc02_c ; \ c - > PFX _pixels_tab[IDX][ 9] = PFX NUM _mc12_c ; \ c - > PFX _pixels_tab[IDX][10] = PFX NUM _mc22_c ; \ c - > PFX _pixels_tab[IDX][11] = PFX NUM _mc32_c ; \ c - > PFX _pixels_tab[IDX][12] = PFX NUM _mc03_c ; \ c - > PFX _pixels_tab[IDX][13] = PFX NUM _mc13_c ; \ c - > PFX _pixels_tab[IDX][14] = PFX NUM _mc23_c ; \ c - > PFX _pixels_tab[IDX][15] = PFX NUM _mc33_c dspfunc ( put_qpel , 0 , 16 ) ; dspfunc ( put_no_rnd_qpel , 0 , 16 ) ; dspfunc ( avg_qpel , 0 , 16 ) ; / * dspfunc ( avg_no_rnd_qpel , 0 , 16 ) ; * / dspfunc ( put_qpel , 1 , 8 ) ; dspfunc ( put_no_rnd_qpel , 1 , 8 ) ; dspfunc ( avg_qpel , 1 , 8 ) ; / * dspfunc ( avg_no_rnd_qpel , 1 , 8 ) ; * / undef dspfunc if CONFIG_MLP_DECODER || CONFIG_TRUEHD_DECODER ff_mlp_init ( c , avctx ) ; endif if CONFIG_WMV2_DECODER || CONFIG_VC1_DECODER ff_intrax8dsp_init ( c , avctx ) ; endif c - > put_mspel_pixels_tab[0]= ff_put_pixels8x8_c ; c - > put_mspel_pixels_tab[1]= put_mspel8_mc10_c ; c - > put_mspel_pixels_tab[2]= put_mspel8_mc20_c ; c - > put_mspel_pixels_tab[3]= put_mspel8_mc30_c ; c - > put_mspel_pixels_tab[4]= put_mspel8_mc02_c ; c - > put_mspel_pixels_tab[5]= put_mspel8_mc12_c ; c - > put_mspel_pixels_tab[6]= put_mspel8_mc22_c ; c - > put_mspel_pixels_tab[7]= put_mspel8_mc32_c ; define SET_CMP_FUNC ( name ) \ c - > name[0]= name 16_c ; \ c - > name[1]= name 8x8_c ; SET_CMP_FUNC ( hadamard8_diff ) c - > hadamard8_diff[4]= hadamard8_intra16_c ; c - > hadamard8_diff[5]= hadamard8_intra8x8_c ; SET_CMP_FUNC ( dct_sad ) SET_CMP_FUNC ( dct_max ) if CONFIG_GPL SET_CMP_FUNC ( dct264_sad ) endif c - > sad[0]= pix_abs16_c ; c - > sad[1]= pix_abs8_c ; c - > sse[0]= sse16_c ; c - > sse[1]= sse8_c ; c - > sse[2]= sse4_c ; SET_CMP_FUNC ( quant_psnr ) SET_CMP_FUNC ( rd ) SET_CMP_FUNC ( bit ) c - > vsad[0]=",0
"static void decode ( GetByteContext * gb , RangeCoder * rc , unsigned cumFreq , unsigned freq , unsigned total_freq ) { rc - > code - = cumFreq * rc - > range ; rc - > range * = freq ; while ( rc - > range < TOP & & bytestream2_get_bytes_left ( gb ) > 0 ) { unsigned byte = bytestream2_get_byte ( gb ) ; rc - > code = ( rc - > code < < 8 ) | byte ; rc - > range < < = 8 ; } }",0
"int ff_thread_get_buffer ( AVCodecContext * avctx , ThreadFrame * f , int flags ) { PerThreadContext * p = avctx - > internal - > thread_ctx ; int err ; f - > owner = avctx ; if ( ! ( avctx - > active_thread_type & FF_THREAD_FRAME ) ) return ff_get_buffer ( avctx , f - > f , flags ) ; if ( atomic_load ( & p - > state ) ! = STATE_SETTING_UP & & ( avctx - > codec - > update_thread_context || ! avctx - > thread_safe_callbacks ) ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) cannot be called after ff_thread_finish_setup ( ) \n ) ; return - 1 ; } if ( avctx - > internal - > allocate_progress ) { atomic_int * progress ; f - > progress = av_buffer_alloc ( 2 * sizeof ( * progress ) ) ; if ( ! f - > progress ) { return AVERROR ( ENOMEM ) ; } progress = ( atomic_int * ) f - > progress - > data ; atomic_store ( & progress[0] , - 1 ) ; atomic_store ( & progress[1] , - 1 ) ; } pthread_mutex_lock ( & p - > parent - > buffer_mutex ) ; if ( avctx - > thread_safe_callbacks || avctx - > get_buffer2 == avcodec_default_get_buffer2 ) { err = ff_get_buffer ( avctx , f - > f , flags ) ; } else { p - > requested_frame = f - > f ; p - > requested_flags = flags ; atomic_store_explicit ( & p - > state , STATE_GET_BUFFER , memory_order_release ) ; pthread_mutex_lock ( & p - > progress_mutex ) ; pthread_cond_signal ( & p - > progress_cond ) ; while ( atomic_load ( & p - > state ) ! = STATE_SETTING_UP ) pthread_cond_wait ( & p - > progress_cond , & p - > progress_mutex ) ; err = p - > result ; pthread_mutex_unlock ( & p - > progress_mutex ) ; } if ( ! avctx - > thread_safe_callbacks & & ! avctx - > codec - > update_thread_context ) ff_thread_finish_setup ( avctx ) ; if ( err ) av_buffer_unref ( & f - > progress ) ; pthread_mutex_unlock ( & p - > parent - > buffer_mutex ) ; return err ; }",0
"static int open_url ( AVFormatContext * s , AVIOContext * * pb , const char * url , AVDictionary * opts , AVDictionary * opts2 , int * is_http ) { HLSContext * c = s - > priv_data ; AVDictionary * tmp = NULL ; const char * proto_name = NULL ; int ret ; av_dict_copy ( & tmp , opts , 0 ) ; av_dict_copy ( & tmp , opts2 , 0 ) ; if ( av_strstart ( url , crypto , NULL ) ) { if ( url[6] == ' + ' || url[6] == ' : ' ) proto_name = avio_find_protocol_name ( url + 7 ) ; } if ( ! proto_name ) proto_name = avio_find_protocol_name ( url ) ; if ( ! proto_name ) return AVERROR_INVALIDDATA ; // only http ( s ) & file are allowed if ( av_strstart ( proto_name , file , NULL ) ) { if ( strcmp ( c - > allowed_extensions , ALL ) & & ! av_match_ext ( url , c - > allowed_extensions ) ) { av_log ( s , AV_LOG_ERROR , Filename extension of \ ' %s\ ' is not a common multimedia extension , blocked for security reasons . \n If you wish to override this adjust allowed_extensions , you can set it to \ ' ALL\ ' to allow all\n , url ) ; return AVERROR_INVALIDDATA ; } } else if ( av_strstart ( proto_name , http , NULL ) ) { ; } else return AVERROR_INVALIDDATA ; if ( ! strncmp ( proto_name , url , strlen ( proto_name ) ) & & url[strlen ( proto_name ) ] == ' : ' ) ; else if ( av_strstart ( url , crypto , NULL ) & & ! strncmp ( proto_name , url + 7 , strlen ( proto_name ) ) & & url[7 + strlen ( proto_name ) ] == ' : ' ) ; else if ( strcmp ( proto_name , file ) || ! strncmp ( url , file , , 5 ) ) return AVERROR_INVALIDDATA ; if ( c - > http_persistent & & * pb & & av_strstart ( proto_name , http , NULL ) ) { ret = open_url_keepalive ( c - > ctx , pb , url ) ; if ( ret == AVERROR_EXIT ) { return ret ; } else if ( ret < 0 ) { if ( ret ! = AVERROR_EOF ) av_log ( s , AV_LOG_WARNING , keepalive request failed for ' %s ' , retrying with new connection : %s\n , url , av_err2str ( ret ) ) ; ret = s - > io_open ( s , pb , url , AVIO_FLAG_READ , & tmp ) ; } } else { ret = s - > io_open ( s , pb , url , AVIO_FLAG_READ , & tmp ) ; } if ( ret > = 0 ) { // update cookies on http response with setcookies . char * new_cookies = NULL ; if ( ! ( s - > flags & AVFMT_FLAG_CUSTOM_IO ) ) av_opt_get ( * pb , cookies , AV_OPT_SEARCH_CHILDREN , ( uint8_t * * ) & new_cookies ) ; if ( new_cookies ) { av_free ( c - > cookies ) ; c - > cookies = new_cookies ; } av_dict_set ( & opts , cookies , c - > cookies , 0 ) ; } av_dict_free ( & tmp ) ; if ( is_http ) * is_http = av_strstart ( proto_name , http , NULL ) ; return ret ; }",0
"static inline void RENAME ( rgb15tobgr24 ) ( const uint8_t * src , uint8_t * dst , long src_size ) { const uint16_t * end ; if COMPILE_TEMPLATE_MMX const uint16_t * mm_end ; endif uint8_t * d = dst ; const uint16_t * s = ( const uint16_t * ) src ; end = s + src_size/2 ; if COMPILE_TEMPLATE_MMX __asm__ volatile ( PREFETCH %0 : : m ( * s ) : memory ) ; mm_end = end - 7 ; while ( s < mm_end ) { __asm__ volatile ( PREFETCH 32%1 \n\t movq %1 , %%mm0 \n\t movq %1 , %%mm1 \n\t movq %1 , %%mm2 \n\t pand %2 , %%mm0 \n\t pand %3 , %%mm1 \n\t pand %4 , %%mm2 \n\t psllq 3 , %%mm0 \n\t psrlq 2 , %%mm1 \n\t psrlq 7 , %%mm2 \n\t movq %%mm0 , %%mm3 \n\t movq %%mm1 , %%mm4 \n\t movq %%mm2 , %%mm5 \n\t punpcklwd %5 , %%mm0 \n\t punpcklwd %5 , %%mm1 \n\t punpcklwd %5 , %%mm2 \n\t punpckhwd %5 , %%mm3 \n\t punpckhwd %5 , %%mm4 \n\t punpckhwd %5 , %%mm5 \n\t psllq 8 , %%mm1 \n\t psllq 16 , %%mm2 \n\t por %%mm1 , %%mm0 \n\t por %%mm2 , %%mm0 \n\t psllq 8 , %%mm4 \n\t psllq 16 , %%mm5 \n\t por %%mm4 , %%mm3 \n\t por %%mm5 , %%mm3 \n\t movq %%mm0 , %%mm6 \n\t movq %%mm3 , %%mm7 \n\t movq 8%1 , %%mm0 \n\t movq 8%1 , %%mm1 \n\t movq 8%1 , %%mm2 \n\t pand %2 , %%mm0 \n\t pand %3 , %%mm1 \n\t pand %4 , %%mm2 \n\t psllq 3 , %%mm0 \n\t psrlq 2 , %%mm1 \n\t psrlq 7 , %%mm2 \n\t movq %%mm0 , %%mm3 \n\t movq %%mm1 , %%mm4 \n\t movq %%mm2 , %%mm5 \n\t punpcklwd %5 , %%mm0 \n\t punpcklwd %5 , %%mm1 \n\t punpcklwd %5 , %%mm2 \n\t punpckhwd %5 , %%mm3 \n\t punpckhwd %5 , %%mm4 \n\t punpckhwd %5 , %%mm5 \n\t psllq 8 , %%mm1 \n\t psllq 16 , %%mm2 \n\t por %%mm1 , %%mm0 \n\t por %%mm2 , %%mm0 \n\t psllq 8 , %%mm4 \n\t psllq 16 , %%mm5 \n\t por %%mm4 , %%mm3 \n\t por %%mm5 , %%mm3 \n\t : =m ( * d ) : m ( * s ) , m ( mask15b ) , m ( mask15g ) , m ( mask15r ) , m ( mmx_null ) : memory ) ; / * borrowed 32 to 24 * / __asm__ volatile ( movq %%mm0 , %%mm4 \n\t movq %%mm3 , %%mm5 \n\t movq %%mm6 , %%mm0 \n\t movq %%mm7 , %%mm1 \n\t movq %%mm4 , %%mm6 \n\t movq %%mm5 , %%mm7 \n\t movq %%mm0 , %%mm2 \n\t movq %%mm1 , %%mm3 \n\t STORE_BGR24_MMX : =m ( * d ) : m ( * s ) : memory ) ; d + = 24 ; s + = 8 ; } __asm__ volatile ( SFENCE : : : memory ) ; __asm__ volatile ( EMMS : : : memory ) ; endif while ( s < end ) { register uint16_t bgr ; bgr = * s + + ; * d + + = ( bgr & 0x1F ) < < 3 ; * d + + = ( bgr & 0x3E0 ) > > 2 ; * d + + = ( bgr & 0x7C00 ) > > 7 ; } }",0
"static int rv10_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; MpegEncContext * s = avctx - > priv_data ; int i ; AVFrame * pict = data ; int slice_count ; const uint8_t * slices_hdr = NULL ; av_dlog ( avctx , * * * * * frame %d size=%d\n , avctx - > frame_number , buf_size ) ; / * no supplementary picture * / if ( buf_size == 0 ) { return 0 ; } if ( ! avctx - > slice_count ) { slice_count = ( * buf + + ) + 1 ; slices_hdr = buf + 4 ; buf + = 8 * slice_count ; } else slice_count = avctx - > slice_count ; for ( i=0 ; i < slice_count ; i + + ) { int offset= get_slice_offset ( avctx , slices_hdr , i ) ; int size , size2 ; if ( i + 1 == slice_count ) size= buf_size - offset ; else size= get_slice_offset ( avctx , slices_hdr , i + 1 ) - offset ; if ( i + 2 > = slice_count ) size2= buf_size - offset ; else size2= get_slice_offset ( avctx , slices_hdr , i + 2 ) - offset ; if ( rv10_decode_packet ( avctx , buf + offset , size , size2 ) > 8 * size ) i + + ; } if ( s - > current_picture_ptr ! = NULL & & s - > mb_y > =s - > mb_height ) { ff_er_frame_end ( s ) ; MPV_frame_end ( s ) ; if ( s - > pict_type == AV_PICTURE_TYPE_B || s - > low_delay ) { * pict= * ( AVFrame * ) s - > current_picture_ptr ; } else if ( s - > last_picture_ptr ! = NULL ) { * pict= * ( AVFrame * ) s - > last_picture_ptr ; } if ( s - > last_picture_ptr || s - > low_delay ) { * data_size = sizeof ( AVFrame ) ; ff_print_debug_info ( s , pict ) ; } s - > current_picture_ptr= NULL ; //so we can detect if frame_end wasnt called ( find some nicer solution . . . ) } return buf_size ; }",1
"static void output_client_manifest ( struct VideoFiles * files , const char * basename , int split ) { char filename[1000] ; FILE * out ; int i , j ; if ( split ) snprintf ( filename , sizeof ( filename ) , Manifest ) ; else snprintf ( filename , sizeof ( filename ) , %s . ismc , basename ) ; out = fopen ( filename , w ) ; if ( ! out ) { perror ( filename ) ; return ; } fprintf ( out , < ? xml version=\ 1 . 0\ encoding=\ utf - 8\ ? > \n ) ; fprintf ( out , < SmoothStreamingMedia MajorVersion=\ 2\ MinorVersion=\ 0\ Duration=\ % PRId64 \ > \n , files - > duration * 10 ) ; if ( files - > video_file > = 0 ) { struct VideoFile * vf = files - > files[files - > video_file] ; int index = 0 ; fprintf ( out , \t < StreamIndex Type=\ video\ QualityLevels=\ %d\ Chunks=\ %d\ Url=\ QualityLevels ( { bitrate } ) /Fragments ( video= { start time } ) \ > \n , files - > nb_video_files , vf - > chunks ) ; for ( i = 0 ; i < files - > nb_files ; i + + ) { vf = files - > files[i] ; if ( ! vf - > is_video ) continue ; fprintf ( out , \t\t < QualityLevel Index=\ %d\ Bitrate=\ %d\ FourCC=\ %s\ MaxWidth=\ %d\ MaxHeight=\ %d\ CodecPrivateData=\ , index , vf - > bitrate , vf - > fourcc , vf - > width , vf - > height ) ; for ( j = 0 ; j < vf - > codec_private_size ; j + + ) fprintf ( out , %02X , vf - > codec_private[j] ) ; fprintf ( out , \ / > \n ) ; index + + ; } vf = files - > files[files - > video_file] ; for ( i = 0 ; i < vf - > chunks ; i + + ) fprintf ( out , \t\t < c n=\ %d\ d=\ %d\ / > \n , i , vf - > offsets[i] . duration ) ; fprintf ( out , \t < /StreamIndex > \n ) ; } if ( files - > audio_file > = 0 ) { struct VideoFile * vf = files - > files[files - > audio_file] ; int index = 0 ; fprintf ( out , \t < StreamIndex Type=\ audio\ QualityLevels=\ %d\ Chunks=\ %d\ Url=\ QualityLevels ( { bitrate } ) /Fragments ( audio= { start time } ) \ > \n , files - > nb_audio_files , vf - > chunks ) ; for ( i = 0 ; i < files - > nb_files ; i + + ) { vf = files - > files[i] ; if ( ! vf - > is_audio ) continue ; fprintf ( out , \t\t < QualityLevel Index=\ %d\ Bitrate=\ %d\ FourCC=\ %s\ SamplingRate=\ %d\ Channels=\ %d\ BitsPerSample=\ 16\ PacketSize=\ %d\ AudioTag=\ %d\ CodecPrivateData=\ , index , vf - > bitrate , vf - > fourcc , vf - > sample_rate , vf - > channels , vf - > blocksize , vf - > tag ) ; for ( j = 0 ; j < vf - > codec_private_size ; j + + ) fprintf ( out , %02X , vf - > codec_private[j] ) ; fprintf ( out , \ / > \n ) ; index + + ; } vf = files - > files[files - > audio_file] ; for ( i = 0 ; i < vf - > chunks ; i + + ) fprintf ( out , \t\t < c n=\ %d\ d=\ %d\ / > \n , i , vf - > offsets[i] . duration ) ; fprintf ( out , \t < /StreamIndex > \n ) ; } fprintf ( out , < /SmoothStreamingMedia > \n ) ; fclose ( out ) ; }",1
"static int aa_read_header ( AVFormatContext * s ) { int i , j , idx , largest_idx = - 1 ; uint32_t nkey , nval , toc_size , npairs , header_seed , start ; char key[128] , val[128] , codec_name[64] = { 0 } ; uint8_t output[24] , dst[8] , src[8] ; int64_t largest_size = - 1 , current_size = - 1 ; struct toc_entry { uint32_t offset ; uint32_t size ; } TOC[MAX_TOC_ENTRIES] ; uint32_t header_key_part[4] ; uint8_t header_key[16] ; AADemuxContext * c = s - > priv_data ; AVIOContext * pb = s - > pb ; AVStream * st ; / * parse . aa header * / avio_skip ( pb , 4 ) ; // file size avio_skip ( pb , 4 ) ; // magic string toc_size = avio_rb32 ( pb ) ; // TOC size avio_skip ( pb , 4 ) ; // unidentified integer if ( toc_size > MAX_TOC_ENTRIES ) return AVERROR_INVALIDDATA ; for ( i = 0 ; i < toc_size ; i + + ) { // read TOC avio_skip ( pb , 4 ) ; // TOC entry index TOC[i] . offset = avio_rb32 ( pb ) ; // block offset TOC[i] . size = avio_rb32 ( pb ) ; // block size } avio_skip ( pb , 24 ) ; // header termination block ( ignored ) npairs = avio_rb32 ( pb ) ; // read dictionary entries if ( npairs > MAX_DICTIONARY_ENTRIES ) return AVERROR_INVALIDDATA ; for ( i = 0 ; i < npairs ; i + + ) { memset ( val , 0 , sizeof ( val ) ) ; memset ( key , 0 , sizeof ( key ) ) ; avio_skip ( pb , 1 ) ; // unidentified integer nkey = avio_rb32 ( pb ) ; // key string length nval = avio_rb32 ( pb ) ; // value string length if ( nkey > sizeof ( key ) ) { avio_skip ( pb , nkey ) ; } else { avio_read ( pb , key , nkey ) ; // key string } if ( nval > sizeof ( val ) ) { avio_skip ( pb , nval ) ; } else { avio_read ( pb , val , nval ) ; // value string } if ( ! strcmp ( key , codec ) ) { av_log ( s , AV_LOG_DEBUG , Codec is < %s > \n , val ) ; strncpy ( codec_name , val , sizeof ( codec_name ) - 1 ) ; } if ( ! strcmp ( key , HeaderSeed ) ) { av_log ( s , AV_LOG_DEBUG , HeaderSeed is < %s > \n , val ) ; header_seed = atoi ( val ) ; } if ( ! strcmp ( key , HeaderKey ) ) { // this looks like 1234567890 1234567890 1234567890 1234567890 av_log ( s , AV_LOG_DEBUG , HeaderKey is < %s > \n , val ) ; sscanf ( val , %u%u%u%u , & header_key_part[0] , & header_key_part[1] , & header_key_part[2] , & header_key_part[3] ) ; for ( idx = 0 ; idx < 4 ; idx + + ) { AV_WB32 ( & header_key[idx * 4] , header_key_part[idx] ) ; // convert each part to BE ! } av_log ( s , AV_LOG_DEBUG , Processed HeaderKey is ) ; for ( i = 0 ; i < 16 ; i + + ) av_log ( s , AV_LOG_DEBUG , %02x , header_key[i] ) ; av_log ( s , AV_LOG_DEBUG , \n ) ; } } / * verify fixed key * / if ( c - > aa_fixed_key_len ! = 16 ) { av_log ( s , AV_LOG_ERROR , aa_fixed_key value needs to be 16 bytes ! \n ) ; return AVERROR ( EINVAL ) ; } / * verify codec * / if ( ( c - > codec_second_size = get_second_size ( codec_name ) ) == - 1 ) { av_log ( s , AV_LOG_ERROR , unknown codec < %s > ! \n , codec_name ) ; return AVERROR ( EINVAL ) ; } / * decryption key derivation * / c - > tea_ctx = av_tea_alloc ( ) ; if ( ! c - > tea_ctx ) return AVERROR ( ENOMEM ) ; av_tea_init ( c - > tea_ctx , c - > aa_fixed_key , 16 ) ; output[0] = output[1] = 0 ; // purely for padding purposes memcpy ( output + 2 , header_key , 16 ) ; idx = 0 ; for ( i = 0 ; i < 3 ; i + + ) { // TEA CBC with weird mixed endianness AV_WB32 ( src , header_seed ) ; AV_WB32 ( src + 4 , header_seed + 1 ) ; header_seed + = 2 ; av_tea_crypt ( c - > tea_ctx , dst , src , 1 , NULL , 0 ) ; // TEA ECB encrypt for ( j = 0 ; j < TEA_BLOCK_SIZE & & idx < 18 ; j + =1 , idx + =1 ) { output[idx] = output[idx] dst[j] ; } } memcpy ( c - > file_key , output + 2 , 16 ) ; // skip first 2 bytes of output av_log ( s , AV_LOG_DEBUG , File key is ) ; for ( i = 0 ; i < 16 ; i + + ) av_log ( s , AV_LOG_DEBUG , %02x , c - > file_key[i] ) ; av_log ( s , AV_LOG_DEBUG , \n ) ; / * decoder setup * / st = avformat_new_stream ( s , NULL ) ; if ( ! st ) { av_freep ( & c - > tea_ctx ) ; return AVERROR ( ENOMEM ) ; } st - > codec - > codec_type = AVMEDIA_TYPE_AUDIO ; if ( ! strcmp ( codec_name , mp332 ) ) { st - > codec - > codec_id = AV_CODEC_ID_MP3 ; st - > codec - > sample_rate = 22050 ; st - > need_parsing = AVSTREAM_PARSE_FULL_RAW ; st - > start_time = 0 ; } else if ( ! strcmp ( codec_name , acelp85 ) ) { st - > codec - > codec_id = AV_CODEC_ID_SIPR ; st - > codec - > block_align = 19 ; st - > codec - > channels = 1 ; st - > codec - > sample_rate = 8500 ; } else if ( ! strcmp ( codec_name , acelp16 ) ) { st - > codec - > codec_id = AV_CODEC_ID_SIPR ; st - > codec - > block_align = 20 ; st - > codec - > channels = 1 ; st - > codec - > sample_rate = 16000 ; } / * determine , and jump to audio start offset * / for ( i = 1 ; i < toc_size ; i + + ) { // skip the first entry ! current_size = TOC[i] . size ; if ( current_size > largest_size ) { largest_idx = i ; largest_size = current_size ; } } start = TOC[largest_idx] . offset ; avio_seek ( pb , start , SEEK_SET ) ; c - > current_chapter_size = 0",0
"vorbis_comment ( AVFormatContext * as , uint8_t * buf , int size ) { const uint8_t * p = buf ; const uint8_t * end = buf + size ; unsigned s , n , j ; if ( size < 8 ) / * must have vendor_length and user_comment_list_length * / return - 1 ; s = bytestream_get_le32 ( & p ) ; if ( end - p < s ) return - 1 ; p + = s ; n = bytestream_get_le32 ( & p ) ; while ( p < end & & n > 0 ) { const char * t , * v ; int tl , vl ; s = bytestream_get_le32 ( & p ) ; if ( end - p < s ) break ; t = p ; p + = s ; n - - ; v = memchr ( t , ' = ' , s ) ; if ( ! v ) continue ; tl = v - t ; vl = s - tl - 1 ; v + + ; if ( tl & & vl ) { char * tt , * ct ; tt = av_malloc ( tl + 1 ) ; ct = av_malloc ( vl + 1 ) ; if ( ! tt || ! ct ) { av_freep ( & tt ) ; av_freep ( & ct ) ; av_log ( as , AV_LOG_WARNING , out - of - memory error . skipping VorbisComment tag . \n ) ; continue ; } for ( j = 0 ; j < tl ; j + + ) tt[j] = toupper ( t[j] ) ; tt[tl] = 0 ; memcpy ( ct , v , vl ) ; ct[vl] = 0 ; av_metadata_set ( & as - > metadata , tt , ct ) ; av_freep ( & tt ) ; av_freep ( & ct ) ; } } if ( p ! = end ) av_log ( as , AV_LOG_INFO , %ti bytes of comment header remain\n , end - p ) ; if ( n > 0 ) av_log ( as , AV_LOG_INFO , truncated comment header , %i comments not found\n , n ) ; return 0 ; }",1
"static float get_band_cost_ESC_mips ( struct AACEncContext * s , PutBitContext * pb , const float * in , const float * scaled , int size , int scale_idx , int cb , const float lambda , const float uplim , int * bits ) { const float Q34 = ff_aac_pow34sf_tab[POW_SF2_ZERO - scale_idx + SCALE_ONE_POS - SCALE_DIV_512] ; const float IQ = ff_aac_pow2sf_tab [POW_SF2_ZERO + scale_idx - SCALE_ONE_POS + SCALE_DIV_512] ; const float CLIPPED_ESCAPE = 165140 . 0f * IQ ; int i ; float cost = 0 ; int qc1 , qc2 , qc3 , qc4 ; int curbits = 0 ; uint8_t * p_bits = ( uint8_t * ) ff_aac_spectral_bits[cb - 1] ; float * p_codes = ( float * ) ff_aac_codebook_vectors[cb - 1] ; for ( i = 0 ; i < size ; i + = 4 ) { const float * vec , * vec2 ; int curidx , curidx2 ; float t1 , t2 , t3 , t4 ; float di1 , di2 , di3 , di4 ; int cond0 , cond1 , cond2 , cond3 ; int c1 , c2 , c3 , c4 ; int t6 , t7 ; qc1 = scaled[i ] * Q34 + ROUND_STANDARD ; qc2 = scaled[i + 1] * Q34 + ROUND_STANDARD ; qc3 = scaled[i + 2] * Q34 + ROUND_STANDARD ; qc4 = scaled[i + 3] * Q34 + ROUND_STANDARD ; __asm__ volatile ( . set push \n\t . set noreorder \n\t ori %[t6] , zero , 15 \n\t ori %[t7] , zero , 16 \n\t shll_s . w %[c1] , %[qc1] , 18 \n\t shll_s . w %[c2] , %[qc2] , 18 \n\t shll_s . w %[c3] , %[qc3] , 18 \n\t shll_s . w %[c4] , %[qc4] , 18 \n\t srl %[c1] , %[c1] , 18 \n\t srl %[c2] , %[c2] , 18 \n\t srl %[c3] , %[c3] , 18 \n\t srl %[c4] , %[c4] , 18 \n\t slt %[cond0] , %[t6] , %[qc1] \n\t slt %[cond1] , %[t6] , %[qc2] \n\t slt %[cond2] , %[t6] , %[qc3] \n\t slt %[cond3] , %[t6] , %[qc4] \n\t movn %[qc1] , %[t7] , %[cond0] \n\t movn %[qc2] , %[t7] , %[cond1] \n\t movn %[qc3] , %[t7] , %[cond2] \n\t movn %[qc4] , %[t7] , %[cond3] \n\t . set pop \n\t : [qc1] + r ( qc1 ) , [qc2] + r ( qc2 ) , [qc3] + r ( qc3 ) , [qc4] + r ( qc4 ) , [cond0] = & r ( cond0 ) , [cond1] = & r ( cond1 ) , [cond2] = & r ( cond2 ) , [cond3] = & r ( cond3 ) , [c1] = & r ( c1 ) , [c2] = & r ( c2 ) , [c3] = & r ( c3 ) , [c4] = & r ( c4 ) , [t6] = & r ( t6 ) , [t7] = & r ( t7 ) ) ; curidx = 17 * qc1 ; curidx + = qc2 ; curidx2 = 17 * qc3 ; curidx2 + = qc4 ; curbits + = p_bits[curidx] ; curbits + = esc_sign_bits[curidx] ; vec = & p_codes[curidx * 2] ; curbits + = p_bits[curidx2] ; curbits + = esc_sign_bits[curidx2] ; vec2 = & p_codes[curidx2 * 2] ; curbits + = ( av_log2 ( c1 ) * 2 - 3 ) & ( - cond0 ) ; curbits + = ( av_log2 ( c2 ) * 2 - 3 ) & ( - cond1 ) ; curbits + = ( av_log2 ( c3 ) * 2 - 3 ) & ( - cond2 ) ; curbits + = ( av_log2 ( c4 ) * 2 - 3 ) & ( - cond3 ) ; t1 = fabsf ( in[i ] ) ; t2 = fabsf ( in[i + 1] ) ; t3 = fabsf ( in[i + 2] ) ; t4 = fabsf ( in[i + 3] ) ; if ( cond0 ) { if ( t1 > = CLIPPED_ESCAPE ) { di1 = t1 - CLIPPED_ESCAPE ; } else { di1 = t1 - c1 * cbrtf ( c1 ) * IQ ; } } else di1 = t1 - vec[0] * IQ ; if ( cond1 ) { if ( t2 > = CLIPPED_ESCAPE ) { di2 = t2 - CLIPPED_ESCAPE ; } else { di2 = t2 - c2 * cbrtf ( c2 ) * IQ ; } } else di2 = t2 - vec[1] * IQ ; if ( cond2 ) { if ( t3 > = CLIPPED_ESCAPE ) { di3 = t3 - CLIPPED_ESCAPE ; } else { di3 = t3 - c3 * cbrtf ( c3 ) * IQ ; } } else di3 = t3 - vec2[0] * IQ ; if ( cond3 ) { if ( t4 > = CLIPPED_ESCAPE ) { di4 = t4 - CLIPPED_ESCAPE ; } else { di4 = t4 - c4 * cbrtf ( c4 ) * IQ ; } } else di4 = t4 - vec2[1] * IQ ; cost + = di1 * di1 + di2 * di2 + di3 * di3 + di4 * di4 ; } if ( bits ) * bits = curbits ; return cost * lambda + curbits ; }",1
static PayloadContext * h264_new_context ( void ) { PayloadContext * data = av_mallocz ( sizeof ( PayloadContext ) + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( data ) { data - > cookie = MAGIC_COOKIE ; } return data ; },1
"static inline int parse_nal_units ( AVCodecParserContext * s , AVCodecContext * avctx , const uint8_t * buf , int buf_size ) { H264Context * h = s - > priv_data ; const uint8_t * buf_end = buf + buf_size ; unsigned int pps_id ; unsigned int slice_type ; int state ; const uint8_t * ptr ; / * set some sane default values * / s - > pict_type = FF_I_TYPE ; s - > key_frame = 0 ; h - > s . avctx= avctx ; h - > sei_recovery_frame_cnt = - 1 ; h - > sei_dpb_output_delay = 0 ; h - > sei_cpb_removal_delay = - 1 ; h - > sei_buffering_period_present = 0 ; for ( ; ; ) { int src_length , dst_length , consumed ; buf = ff_find_start_code ( buf , buf_end , & state ) ; if ( buf > = buf_end ) break ; - - buf ; src_length = buf_end - buf ; switch ( state & 0x1f ) { case NAL_SLICE : case NAL_IDR_SLICE : // Do not walk the whole buffer just to decode slice header if ( src_length > 20 ) src_length = 20 ; break ; } ptr= ff_h264_decode_nal ( h , buf , & dst_length , & consumed , src_length ) ; if ( ptr==NULL || dst_length < 0 ) break ; init_get_bits ( & h - > s . gb , ptr , 8 * dst_length ) ; switch ( h - > nal_unit_type ) { case NAL_SPS : ff_h264_decode_seq_parameter_set ( h ) ; break ; case NAL_PPS : ff_h264_decode_picture_parameter_set ( h , h - > s . gb . size_in_bits ) ; break ; case NAL_SEI : ff_h264_decode_sei ( h ) ; break ; case NAL_IDR_SLICE : s - > key_frame = 1 ; / * fall through * / case NAL_SLICE : get_ue_golomb ( & h - > s . gb ) ; // skip first_mb_in_slice slice_type = get_ue_golomb_31 ( & h - > s . gb ) ; s - > pict_type = golomb_to_pict_type[slice_type % 5] ; if ( h - > sei_recovery_frame_cnt > = 0 ) { / * key frame , since recovery_frame_cnt is set * / s - > key_frame = 1 ; } pps_id= get_ue_golomb ( & h - > s . gb ) ; if ( pps_id > =MAX_PPS_COUNT ) { av_log ( h - > s . avctx , AV_LOG_ERROR , pps_id out of range\n ) ; return - 1 ; } if ( ! h - > pps_buffers[pps_id] ) { av_log ( h - > s . avctx , AV_LOG_ERROR , non - existing PPS referenced\n ) ; return - 1 ; } h - > pps= * h - > pps_buffers[pps_id] ; if ( ! h - > sps_buffers[h - > pps . sps_id] ) { av_log ( h - > s . avctx , AV_LOG_ERROR , non - existing SPS referenced\n ) ; return - 1 ; } h - > sps = * h - > sps_buffers[h - > pps . sps_id] ; h - > frame_num = get_bits ( & h - > s . gb , h - > sps . log2_max_frame_num ) ; if ( h - > sps . frame_mbs_only_flag ) { h - > s . picture_structure= PICT_FRAME ; } else { if ( get_bits1 ( & h - > s . gb ) ) { //field_pic_flag h - > s . picture_structure= PICT_TOP_FIELD + get_bits1 ( & h - > s . gb ) ; //bottom_field_flag } else { h - > s . picture_structure= PICT_FRAME ; } } if ( h - > sps . pic_struct_present_flag ) { switch ( h - > sei_pic_struct ) { case SEI_PIC_STRUCT_TOP_FIELD : case SEI_PIC_STRUCT_BOTTOM_FIELD : s - > repeat_pict = 0 ; break ; case SEI_PIC_STRUCT_FRAME : case SEI_PIC_STRUCT_TOP_BOTTOM : case SEI_PIC_STRUCT_BOTTOM_TOP : s - > repeat_pict = 1 ; break ; case SEI_PIC_STRUCT_TOP_BOTTOM_TOP : case SEI_PIC_STRUCT_BOTTOM_TOP_BOTTOM : s - > repeat_pict = 2 ; break ; case SEI_PIC_STRUCT_FRAME_DOUBLING : s - > repeat_pict = 3 ; break ; case SEI_PIC_STRUCT_FRAME_TRIPLING : s - > repeat_pict = 5 ; break ; default : s - > repeat_pict = h - > s . picture_structure == PICT_FRAME ? 1 : 0 ; break ; } } else { s - > repeat_pict = h - > s . picture_structure == PICT_FRAME ? 1 : 0 ; } return 0 ; / * no need to evaluate the rest * / } buf + = consumed ; } / * didn ' t find a picture ! * / av_log ( h - > s . avctx , AV_LOG_ERROR , missing picture in access unit\n ) ; return - 1 ; }",1
"static av_cold int atrac3_decode_init ( AVCodecContext * avctx ) { int i , ret ; int version , delay , samples_per_frame , frame_factor ; const uint8_t * edata_ptr = avctx - > extradata ; ATRAC3Context * q = avctx - > priv_data ; if ( avctx - > channels < = 0 || avctx - > channels > 2 ) { av_log ( avctx , AV_LOG_ERROR , Channel configuration error ! \n ) ; } / * Take care of the codec - specific extradata . * / if ( avctx - > extradata_size == 14 ) { / * Parse the extradata , WAV format * / av_log ( avctx , AV_LOG_DEBUG , [0 - 1] %d\n , bytestream_get_le16 ( & edata_ptr ) ) ; // Unknown value always 1 edata_ptr + = 4 ; // samples per channel q - > coding_mode = bytestream_get_le16 ( & edata_ptr ) ; av_log ( avctx , AV_LOG_DEBUG , [8 - 9] %d\n , bytestream_get_le16 ( & edata_ptr ) ) ; //Dupe of coding mode frame_factor = bytestream_get_le16 ( & edata_ptr ) ; // Unknown always 1 av_log ( avctx , AV_LOG_DEBUG , [12 - 13] %d\n , bytestream_get_le16 ( & edata_ptr ) ) ; // Unknown always 0 / * setup * / samples_per_frame = SAMPLES_PER_FRAME * avctx - > channels ; version = 4 ; delay = 0x88E ; q - > coding_mode = q - > coding_mode ? JOINT_STEREO : STEREO ; q - > scrambled_stream = 0 ; if ( avctx - > block_align ! = 96 * avctx - > channels * frame_factor & & avctx - > block_align ! = 152 * avctx - > channels * frame_factor & & avctx - > block_align ! = 192 * avctx - > channels * frame_factor ) { av_log ( avctx , AV_LOG_ERROR , Unknown frame/channel/frame_factor configuration %d/%d/%d\n , avctx - > block_align , avctx - > channels , frame_factor ) ; return AVERROR_INVALIDDATA ; } } else if ( avctx - > extradata_size == 10 ) { / * Parse the extradata , RM format . * / version = bytestream_get_be32 ( & edata_ptr ) ; samples_per_frame = bytestream_get_be16 ( & edata_ptr ) ; delay = bytestream_get_be16 ( & edata_ptr ) ; q - > coding_mode = bytestream_get_be16 ( & edata_ptr ) ; q - > scrambled_stream = 1 ; } else { av_log ( NULL , AV_LOG_ERROR , Unknown extradata size %d . \n , avctx - > extradata_size ) ; } / * Check the extradata * / if ( version ! = 4 ) { av_log ( avctx , AV_LOG_ERROR , Version %d ! = 4 . \n , version ) ; return AVERROR_INVALIDDATA ; } if ( samples_per_frame ! = SAMPLES_PER_FRAME & & samples_per_frame ! = SAMPLES_PER_FRAME * 2 ) { av_log ( avctx , AV_LOG_ERROR , Unknown amount of samples per frame %d . \n , samples_per_frame ) ; return AVERROR_INVALIDDATA ; } if ( delay ! = 0x88E ) { av_log ( avctx , AV_LOG_ERROR , Unknown amount of delay %x ! = 0x88E . \n , delay ) ; return AVERROR_INVALIDDATA ; } if ( q - > coding_mode == STEREO ) av_log ( avctx , AV_LOG_DEBUG , Normal stereo detected . \n ) ; else if ( q - > coding_mode == JOINT_STEREO ) av_log ( avctx , AV_LOG_DEBUG , Joint stereo detected . \n ) ; else { av_log ( avctx , AV_LOG_ERROR , Unknown channel coding mode %x ! \n , q - > coding_mode ) ; return AVERROR_INVALIDDATA ; } if ( avctx - > block_align > = UINT_MAX / 2 ) q - > decoded_bytes_buffer = av_mallocz ( FFALIGN ( avctx - > block_align , 4 ) + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( q - > decoded_bytes_buffer == NULL ) return AVERROR ( ENOMEM ) ; avctx - > sample_fmt = AV_SAMPLE_FMT_FLTP ; / * initialize the MDCT transform * / if ( ( ret = ff_mdct_init ( & q - > mdct_ctx , 9 , 1 , 1 . 0 / 32768 ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , Error initializing MDCT\n ) ; av_freep ( & q - > decoded_bytes_buffer ) ; return ret ; } / * init the joint - stereo decoding data * / q - > weighting_delay[0] = 0 ; q - > weighting_delay[1] = 7 ; q - > weighting_delay[2] = 0 ; q - > weighting_delay[3] = 7 ; q - > weighting_delay[4] = 0 ; q - > weighting_delay[5] = 7 ; for ( i = 0 ; i < 4 ; i + + ) { q - > matrix_coeff_index_prev[i] = 3 ; q - > matrix_coeff_index_now[i] = 3 ; q - > matrix_coeff_index_next[i] = 3 ; } avpriv_float_dsp_init ( & q - > fdsp , avctx - > flags & CODEC_FLAG_BITEXACT ) ; ff_fmt_convert_init ( & q - > fmt_conv , avctx ) ; q - > units = av_mallocz ( sizeof ( * q - > units ) * avctx - > channels ) ; if ( ! q - > units ) { atrac3_decode_close ( avctx ) ; return AVERROR ( ENOMEM ) ; } avcodec_get_frame_defaults ( & q - > frame ) ; avctx - > coded_frame = & q - > frame ; return 0 ; }",1
"static void ff_h264_idct_add16_sse2 ( uint8_t * dst , const int * block_offset , DCTELEM * block , int stride , const uint8_t nnzc[6 * 8] ) { int i ; for ( i=0 ; i < 16 ; i + =2 ) if ( nnzc[ scan8[i + 0] ]|nnzc[ scan8[i + 1] ] ) ff_x264_add8x4_idct_sse2 ( dst + block_offset[i] , block + i * 16 , stride ) ; }",0
"static int mpeg4_decode_sprite_trajectory ( Mpeg4DecContext * ctx , GetBitContext * gb ) { MpegEncContext * s = & ctx - > m ; int a = 2 < < s - > sprite_warping_accuracy ; int rho = 3 - s - > sprite_warping_accuracy ; int r = 16 / a ; int alpha = 0 ; int beta = 0 ; int w = s - > width ; int h = s - > height ; int min_ab , i , w2 , h2 , w3 , h3 ; int sprite_ref[4][2] ; int virtual_ref[2][2] ; // only true for rectangle shapes const int vop_ref[4][2] = { { 0 , 0 } , { s - > width , 0 } , { 0 , s - > height } , { s - > width , s - > height } } ; int d[4][2] = { { 0 , 0 } , { 0 , 0 } , { 0 , 0 } , { 0 , 0 } } ; if ( w < = 0 || h < = 0 ) return AVERROR_INVALIDDATA ; for ( i = 0 ; i < ctx - > num_sprite_warping_points ; i + + ) { int length ; int x = 0 , y = 0 ; length = get_vlc2 ( gb , sprite_trajectory . table , SPRITE_TRAJ_VLC_BITS , 3 ) ; if ( length > 0 ) x = get_xbits ( gb , length ) ; if ( ! ( ctx - > divx_version == 500 & & ctx - > divx_build == 413 ) ) check_marker ( s - > avctx , gb , before sprite_trajectory ) ; length = get_vlc2 ( gb , sprite_trajectory . table , SPRITE_TRAJ_VLC_BITS , 3 ) ; if ( length > 0 ) y = get_xbits ( gb , length ) ; check_marker ( s - > avctx , gb , after sprite_trajectory ) ; ctx - > sprite_traj[i][0] = d[i][0] = x ; ctx - > sprite_traj[i][1] = d[i][1] = y ; for ( ; i < 4 ; i + + ) ctx - > sprite_traj[i][0] = ctx - > sprite_traj[i][1] = 0 ; while ( ( 1 < < alpha ) < w ) alpha + + ; while ( ( 1 < < beta ) < h ) beta + + ; / * typo in the MPEG - 4 std for the definition of w ' and h ' * / w2 = 1 < < alpha ; h2 = 1 < < beta ; // Note , the 4th point isn ' t used for GMC if ( ctx - > divx_version == 500 & & ctx - > divx_build == 413 ) { sprite_ref[0][0] = a * vop_ref[0][0] + d[0][0] ; sprite_ref[0][1] = a * vop_ref[0][1] + d[0][1] ; sprite_ref[1][0] = a * vop_ref[1][0] + d[0][0] + d[1][0] ; sprite_ref[1][1] = a * vop_ref[1][1] + d[0][1] + d[1][1] ; sprite_ref[2][0] = a * vop_ref[2][0] + d[0][0] + d[2][0] ; sprite_ref[2][1] = a * vop_ref[2][1] + d[0][1] + d[2][1] ; } else { sprite_ref[0][0] = ( a > > 1 ) * ( 2 * vop_ref[0][0] + d[0][0] ) ; sprite_ref[0][1] = ( a > > 1 ) * ( 2 * vop_ref[0][1] + d[0][1] ) ; sprite_ref[1][0] = ( a > > 1 ) * ( 2 * vop_ref[1][0] + d[0][0] + d[1][0] ) ; sprite_ref[1][1] = ( a > > 1 ) * ( 2 * vop_ref[1][1] + d[0][1] + d[1][1] ) ; sprite_ref[2][0] = ( a > > 1 ) * ( 2 * vop_ref[2][0] + d[0][0] + d[2][0] ) ; sprite_ref[2][1] = ( a > > 1 ) * ( 2 * vop_ref[2][1] + d[0][1] + d[2][1] ) ; / * sprite_ref[3][0] = ( a > > 1 ) * ( 2 * vop_ref[3][0] + d[0][0] + d[1][0] + d[2][0] + d[3][0] ) ; * sprite_ref[3][1] = ( a > > 1 ) * ( 2 * vop_ref[3][1] + d[0][1] + d[1][1] + d[2][1] + d[3][1] ) ; * / / * This is mostly identical to the MPEG - 4 std ( and is totally unreadable * because of that . . . ) . Perhaps it should be reordered to be more readable . * The idea behind this virtual_ref mess is to be able to use shifts later * per pixel instead of divides so the distance between points is converted * from w & h based to w2 & h2 based which are of the 2 x form . * / virtual_ref[0][0] = 16 * ( vop_ref[0][0] + w2 ) + ROUNDED_DIV ( ( ( w - w2 ) * ( r * sprite_ref[0][0] - 16 * vop_ref[0][0] ) + w2 * ( r * sprite_ref[1][0] - 16 * vop_ref[1][0] ) ) , w ) ; virtual_ref[0][1] = 16 * vop_ref[0][1] + ROUNDED_DIV ( ( ( w - w2 ) * ( r * sprite_ref[0][1] - 16 * vop_ref[0][1] ) + w2 * ( r * sprite_ref[1][1] - 16 * vop_ref[1][1] ) ) , w ) ; virtual_ref[1][0] = 16 * vop_ref[0][0] + ROUNDED_DIV ( ( ( h - h2 ) * ( r * sprite_ref[0][0] - 16 * vop_ref[0][0] ) + h2 * ( r * sprite_ref[2][0] - 16 * vop_ref[2][0] ) ) , h ) ; virtual_ref[1][1] = 16 * ( vop_ref[0][1] + h2 ) + ROUNDED_DIV ( ( ( h - h2 ) * ( r * sprite_ref[0][1] - 16 * vop_ref[0][1] ) + h2 * ( r * sprite_ref[2][1] - 16 * vop_ref[2][1] ) ) , h ) ; switch ( ctx - > num_sprite_warping_points ) { case 0 : s - > sprite_offset[0][0] = s - > sprite_offset[0][1] = s - > sprite_offset[1][0] = s - > sprite_offset[1][1] = 0 ; s - > sprite_delta[0][0] = a ; s - > sprite_delta[0][1] = s - > sprite_delta[1][0] = 0 ; s - > sprite_delta[1][1] = a ; ctx - > sprite_shift[0] = ctx - > sprite_shift[1] = 0 ; break ; case 1 : // GMC only s - > sprite_offset[0][0] = sprite_ref[0][0] - a * vop_ref[0][0] ; s - > sprite_offset[0][1] = sprite_ref[0][1] - a * vop_ref[0][1] ; s - > sprite_offset[1][0] = ( ( sprite_ref[0][0] > > 1 ) | ( sprite_ref[0][0] & 1 ) ) - a * ( vop_ref[0][0] / 2 ) ; s - > sprite_offset[1][1] = ( ( sprite_ref[0][1] > > 1 ) | ( sprite_ref[0][1] & 1 ) ) - a * ( vop_ref[0][1] / 2 ) ; s - > sprite_delta[0][0] = a ; s - > sprite_delta[0][1] = s - > sprite_delta[1][0] = 0 ; s - > sprite_delta[1][1] = a ; ctx - > sprite_shift[0] = ctx - > sprite_shift[1] = 0 ; break ; case 2 : s - > sprite_offset[0][0] = ( sprite_ref[0][0] < < ( alpha + rho ) ) + ( - r * sprite_ref[0][0] + virtual_ref[0][0] ) * ( - vop_ref[0][0] ) + ( r * sprite_ref[0][1] - virtual_ref[0][1] ) * ( - vop_ref[0][1] ) + ( 1 < < ( alpha + rho - 1 ) ) ; s - > sprite_offset[0][1] = ( sprite_ref[0][1] <",1
"static int ff_filter_frame_framed ( AVFilterLink * link , AVFrame * frame ) { int ( * filter_frame ) ( AVFilterLink * , AVFrame * ) ; AVFilterContext * dstctx = link - > dst ; AVFilterPad * dst = link - > dstpad ; AVFrame * out ; int ret ; AVFilterCommand * cmd= link - > dst - > command_queue ; int64_t pts ; if ( link - > closed ) { av_frame_free ( & frame ) ; return AVERROR_EOF ; } if ( ! ( filter_frame = dst - > filter_frame ) ) filter_frame = default_filter_frame ; / * copy the frame if needed * / if ( dst - > needs_writable & & ! av_frame_is_writable ( frame ) ) { av_log ( link - > dst , AV_LOG_DEBUG , Copying data in avfilter . \n ) ; / * Maybe use ff_copy_buffer_ref instead ? * / switch ( link - > type ) { case AVMEDIA_TYPE_VIDEO : out = ff_get_video_buffer ( link , link - > w , link - > h ) ; break ; case AVMEDIA_TYPE_AUDIO : out = ff_get_audio_buffer ( link , frame - > nb_samples ) ; break ; default : ret = AVERROR ( EINVAL ) ; goto fail ; } if ( ! out ) { ret = AVERROR ( ENOMEM ) ; goto fail ; } ret = av_frame_copy_props ( out , frame ) ; if ( ret < 0 ) goto fail ; switch ( link - > type ) { case AVMEDIA_TYPE_VIDEO : av_image_copy ( out - > data , out - > linesize , ( const uint8_t * * ) frame - > data , frame - > linesize , frame - > format , frame - > width , frame - > height ) ; break ; case AVMEDIA_TYPE_AUDIO : av_samples_copy ( out - > extended_data , frame - > extended_data , 0 , 0 , frame - > nb_samples , av_get_channel_layout_nb_channels ( frame - > channel_layout ) , frame - > format ) ; break ; default : ret = AVERROR ( EINVAL ) ; goto fail ; } av_frame_free ( & frame ) ; } else out = frame ; while ( cmd & & cmd - > time < = out - > pts * av_q2d ( link - > time_base ) ) { av_log ( link - > dst , AV_LOG_DEBUG , Processing command time : %f command : %s arg : %s\n , cmd - > time , cmd - > command , cmd - > arg ) ; avfilter_process_command ( link - > dst , cmd - > command , cmd - > arg , 0 , 0 , cmd - > flags ) ; ff_command_queue_pop ( link - > dst ) ; cmd= link - > dst - > command_queue ; } pts = out - > pts ; if ( dstctx - > enable_str ) { int64_t pos = av_frame_get_pkt_pos ( out ) ; dstctx - > var_values[VAR_N] = link - > frame_count ; dstctx - > var_values[VAR_T] = pts == AV_NOPTS_VALUE ? NAN : pts * av_q2d ( link - > time_base ) ; dstctx - > var_values[VAR_POS] = pos == - 1 ? NAN : pos ; dstctx - > is_disabled = fabs ( av_expr_eval ( dstctx - > enable , dstctx - > var_values , NULL ) ) < 0 . 5 ; if ( dstctx - > is_disabled & & ( dstctx - > filter - > flags & AVFILTER_FLAG_SUPPORT_TIMELINE_GENERIC ) ) filter_frame = default_filter_frame ; } ret = filter_frame ( link , out ) ; link - > frame_count + + ; link - > frame_requested = 0 ; ff_update_link_current_pts ( link , pts ) ; return ret ; fail : av_frame_free ( & out ) ; av_frame_free ( & frame ) ; return ret ; }",1
"static inline void FUNC ( idctRowCondDC ) ( int16_t * row , int extra_shift ) { int a0 , a1 , a2 , a3 , b0 , b1 , b2 , b3 ; if HAVE_FAST_64BIT define ROW0_MASK ( 0xffffLL < < 48 * HAVE_BIGENDIAN ) if ( ( ( ( ( uint64_t * ) row ) [0] & ROW0_MASK ) | ( ( uint64_t * ) row ) [1] ) == 0 ) { uint64_t temp ; if ( DC_SHIFT - extra_shift > 0 ) { temp = ( row[0] < < ( DC_SHIFT - extra_shift ) ) & 0xffff ; } else { temp = ( row[0] > > ( extra_shift - DC_SHIFT ) ) & 0xffff ; } temp + = temp < < 16 ; temp + = temp < < 32 ; ( ( uint64_t * ) row ) [0] = temp ; ( ( uint64_t * ) row ) [1] = temp ; return ; } else if ( ! ( ( ( uint32_t * ) row ) [1] | ( ( uint32_t * ) row ) [2] | ( ( uint32_t * ) row ) [3] | row[1] ) ) { uint32_t temp ; if ( DC_SHIFT - extra_shift > 0 ) { temp = ( row[0] < < ( DC_SHIFT - extra_shift ) ) & 0xffff ; } else { temp = ( row[0] > > ( extra_shift - DC_SHIFT ) ) & 0xffff ; } temp + = temp < < 16 ; ( ( uint32_t * ) row ) [0]= ( ( uint32_t * ) row ) [1] = ( ( uint32_t * ) row ) [2]= ( ( uint32_t * ) row ) [3] = temp ; return ; } endif a0 = ( W4 * row[0] ) + ( 1 < < ( ROW_SHIFT - 1 ) ) ; a1 = a0 ; a2 = a0 ; a3 = a0 ; a0 + = W2 * row[2] ; a1 + = W6 * row[2] ; a2 - = W6 * row[2] ; a3 - = W2 * row[2] ; b0 = MUL ( W1 , row[1] ) ; MAC ( b0 , W3 , row[3] ) ; b1 = MUL ( W3 , row[1] ) ; MAC ( b1 , - W7 , row[3] ) ; b2 = MUL ( W5 , row[1] ) ; MAC ( b2 , - W1 , row[3] ) ; b3 = MUL ( W7 , row[1] ) ; MAC ( b3 , - W5 , row[3] ) ; if ( AV_RN64A ( row + 4 ) ) { a0 + = W4 * row[4] + W6 * row[6] ; a1 + = - W4 * row[4] - W2 * row[6] ; a2 + = - W4 * row[4] + W2 * row[6] ; a3 + = W4 * row[4] - W6 * row[6] ; MAC ( b0 , W5 , row[5] ) ; MAC ( b0 , W7 , row[7] ) ; MAC ( b1 , - W1 , row[5] ) ; MAC ( b1 , - W5 , row[7] ) ; MAC ( b2 , W7 , row[5] ) ; MAC ( b2 , W3 , row[7] ) ; MAC ( b3 , W3 , row[5] ) ; MAC ( b3 , - W1 , row[7] ) ; } row[0] = ( a0 + b0 ) > > ( ROW_SHIFT + extra_shift ) ; row[7] = ( a0 - b0 ) > > ( ROW_SHIFT + extra_shift ) ; row[1] = ( a1 + b1 ) > > ( ROW_SHIFT + extra_shift ) ; row[6] = ( a1 - b1 ) > > ( ROW_SHIFT + extra_shift ) ; row[2] = ( a2 + b2 ) > > ( ROW_SHIFT + extra_shift ) ; row[5] = ( a2 - b2 ) > > ( ROW_SHIFT + extra_shift ) ; row[3] = ( a3 + b3 ) > > ( ROW_SHIFT + extra_shift ) ; row[4] = ( a3 - b3 ) > > ( ROW_SHIFT + extra_shift ) ; }",0
"static int mov_read_chap ( MOVContext * c , AVIOContext * pb , MOVAtom atom ) { c - > chapter_track = avio_rb32 ( pb ) ; return 0 ; }",0
"static int io_write_data_type ( void * opaque , uint8_t * buf , int size , enum AVIODataMarkerType type , int64_t time ) { char timebuf[30] , content[5] = { 0 } ; const char * str ; switch ( type ) { case AVIO_DATA_MARKER_HEADER : str = header ; break ; case AVIO_DATA_MARKER_SYNC_POINT : str = sync ; break ; case AVIO_DATA_MARKER_BOUNDARY_POINT : str = boundary ; break ; case AVIO_DATA_MARKER_UNKNOWN : str = unknown ; break ; case AVIO_DATA_MARKER_TRAILER : str = trailer ; break ; } if ( time == AV_NOPTS_VALUE ) snprintf ( timebuf , sizeof ( timebuf ) , nopts ) ; else snprintf ( timebuf , sizeof ( timebuf ) , % PRId64 , time ) ; // There can be multiple header/trailer callbacks , only log the box type // for header at out_size == 0 if ( type ! = AVIO_DATA_MARKER_UNKNOWN & & type ! = AVIO_DATA_MARKER_TRAILER & & ( type ! = AVIO_DATA_MARKER_HEADER || out_size == 0 ) & & size > = 8 ) memcpy ( content , & buf[4] , 4 ) ; else snprintf ( content , sizeof ( content ) , - ) ; printf ( write_data len %d , time %s , type %s atom %s\n , size , timebuf , str , content ) ; return io_write ( opaque , buf , size ) ; }",1
"static void release_buffer ( AVCodecContext * avctx , AVFrame * pic ) { int i ; CVPixelBufferRef cv_buffer = ( CVPixelBufferRef ) pic - > data[3] ; CVPixelBufferUnlockBaseAddress ( cv_buffer , 0 ) ; CVPixelBufferRelease ( cv_buffer ) ; for ( i = 0 ; i < 4 ; i + + ) pic - > data[i] = NULL ; }",1
"static void final ( Real144_internal * glob , short * i1 , short * i2 , void * out , int * statbuf , int len ) { int x , sum ; int buffer[10] ; short * ptr ; short * ptr2 ; memcpy ( glob - > work , statbuf , 20 ) ; memcpy ( glob - > work + 10 , i2 , len * 2 ) ; buffer[9] = i1[0] ; buffer[8] = i1[1] ; buffer[7] = i1[2] ; buffer[6] = i1[3] ; buffer[5] = i1[4] ; buffer[4] = i1[5] ; buffer[3] = i1[6] ; buffer[2] = i1[7] ; buffer[1] = i1[8] ; buffer[0] = i1[9] ; ptr2 = ( ptr = glob - > work ) + len ; while ( ptr < ptr2 ) { for ( sum=0 , x=0 ; x < =9 ; x + + ) sum + = buffer[x] * ( ptr[x] ) ; sum = sum > > 12 ; x = ptr[10] - sum ; if ( x < - 32768 || x > 32767 ) { memset ( out , 0 , len * 2 ) ; memset ( statbuf , 0 , 20 ) ; return ; } ptr[10] = x ; ptr + + ; } memcpy ( out , ptr + 10 - len , len * 2 ) ; memcpy ( statbuf , ptr , 20 ) ; }",0
"AVOption * av_set_string ( void * obj , const char * name , const char * val ) { AVOption * o= find_opt ( obj , name ) ; if ( ! o || ! val || o - > offset < =0 ) return NULL ; if ( o - > type ! = FF_OPT_TYPE_STRING ) { double d=0 , tmp_d ; for ( ; ; ) { int i ; char buf[256] , * tail ; for ( i=0 ; i < sizeof ( buf ) - 1 & & val[i] & & val[i] ! = ' + ' ; i + + ) buf[i]= val[i] ; buf[i]=0 ; val + = i ; tmp_d= av_parse_num ( buf , & tail ) ; if ( tail > buf ) d + = tmp_d ; else { AVOption * o_named= find_opt ( obj , buf ) ; if ( o_named & & o_named - > type == FF_OPT_TYPE_CONST ) d + = o_named - > default_val ; else if ( ! strcmp ( buf , default ) ) d + = o - > default_val ; else if ( ! strcmp ( buf , max ) ) d + = o - > max ; else if ( ! strcmp ( buf , min ) ) d + = o - > min ; else return NULL ; } if ( * val == ' + ' ) val + + ; if ( ! * val ) return av_set_number ( obj , name , d , 1 , 1 ) ; } return NULL ; } memcpy ( ( ( uint8_t * ) obj ) + o - > offset , val , sizeof ( val ) ) ; return o ; }",0
"static AVBufferRef * vaapi_encode_alloc_output_buffer ( void * opaque , int size ) { AVCodecContext * avctx = opaque ; VAAPIEncodeContext * ctx = avctx - > priv_data ; VABufferID buffer_id ; VAStatus vas ; AVBufferRef * ref ; // The output buffer size is fixed , so it needs to be large enough // to hold the largest possible compressed frame . We assume here // that the uncompressed frame plus some header data is an upper // bound on that . vas = vaCreateBuffer ( ctx - > hwctx - > display , ctx - > va_context , VAEncCodedBufferType , 3 * ctx - > aligned_width * ctx - > aligned_height + ( 1 < < 16 ) , 1 , 0 , & buffer_id ) ; if ( vas ! = VA_STATUS_SUCCESS ) { av_log ( avctx , AV_LOG_ERROR , Failed to create bitstream output buffer : %d ( %s ) . \n , vas , vaErrorStr ( vas ) ) ; return NULL ; } av_log ( avctx , AV_LOG_DEBUG , Allocated output buffer % x\n , buffer_id ) ; ref = av_buffer_create ( ( uint8_t * ) ( uintptr_t ) buffer_id , sizeof ( buffer_id ) , & vaapi_encode_free_output_buffer , avctx , AV_BUFFER_FLAG_READONLY ) ; if ( ! ref ) { vaDestroyBuffer ( ctx - > hwctx - > display , buffer_id ) ; return NULL ; } return ref ; }",0
"static int ffm_write_header ( AVFormatContext * s ) { FFMContext * ffm = s - > priv_data ; AVStream * st ; ByteIOContext * pb = s - > pb ; AVCodecContext * codec ; int bit_rate , i ; ffm - > packet_size = FFM_PACKET_SIZE ; / * header * / put_le32 ( pb , MKTAG ( ' F ' , ' F ' , ' M ' , ' 1 ' ) ) ; put_be32 ( pb , ffm - > packet_size ) ; / * XXX : store write position in other file ? * / put_be64 ( pb , ffm - > packet_size ) ; / * current write position * / put_be32 ( pb , s - > nb_streams ) ; bit_rate = 0 ; for ( i=0 ; i < s - > nb_streams ; i + + ) { st = s - > streams[i] ; bit_rate + = st - > codec - > bit_rate ; } put_be32 ( pb , bit_rate ) ; / * list of streams * / for ( i=0 ; i < s - > nb_streams ; i + + ) { st = s - > streams[i] ; av_set_pts_info ( st , 64 , 1 , 1000000 ) ; codec = st - > codec ; / * generic info * / put_be32 ( pb , codec - > codec_id ) ; put_byte ( pb , codec - > codec_type ) ; put_be32 ( pb , codec - > bit_rate ) ; put_be32 ( pb , st - > quality ) ; put_be32 ( pb , codec - > flags ) ; put_be32 ( pb , codec - > flags2 ) ; put_be32 ( pb , codec - > debug ) ; / * specific info * / switch ( codec - > codec_type ) { case CODEC_TYPE_VIDEO : put_be32 ( pb , codec - > time_base . num ) ; put_be32 ( pb , codec - > time_base . den ) ; put_be16 ( pb , codec - > width ) ; put_be16 ( pb , codec - > height ) ; put_be16 ( pb , codec - > gop_size ) ; put_be32 ( pb , codec - > pix_fmt ) ; put_byte ( pb , codec - > qmin ) ; put_byte ( pb , codec - > qmax ) ; put_byte ( pb , codec - > max_qdiff ) ; put_be16 ( pb , ( int ) ( codec - > qcompress * 10000 . 0 ) ) ; put_be16 ( pb , ( int ) ( codec - > qblur * 10000 . 0 ) ) ; put_be32 ( pb , codec - > bit_rate_tolerance ) ; put_strz ( pb , codec - > rc_eq ) ; put_be32 ( pb , codec - > rc_max_rate ) ; put_be32 ( pb , codec - > rc_min_rate ) ; put_be32 ( pb , codec - > rc_buffer_size ) ; put_be64 ( pb , av_dbl2int ( codec - > i_quant_factor ) ) ; put_be64 ( pb , av_dbl2int ( codec - > b_quant_factor ) ) ; put_be64 ( pb , av_dbl2int ( codec - > i_quant_offset ) ) ; put_be64 ( pb , av_dbl2int ( codec - > b_quant_offset ) ) ; put_be32 ( pb , codec - > dct_algo ) ; put_be32 ( pb , codec - > strict_std_compliance ) ; put_be32 ( pb , codec - > max_b_frames ) ; put_be32 ( pb , codec - > luma_elim_threshold ) ; put_be32 ( pb , codec - > chroma_elim_threshold ) ; put_be32 ( pb , codec - > mpeg_quant ) ; put_be32 ( pb , codec - > intra_dc_precision ) ; put_be32 ( pb , codec - > me_method ) ; put_be32 ( pb , codec - > mb_decision ) ; put_be32 ( pb , codec - > nsse_weight ) ; put_be32 ( pb , codec - > frame_skip_cmp ) ; put_be64 ( pb , av_dbl2int ( codec - > rc_buffer_aggressivity ) ) ; put_be32 ( pb , codec - > codec_tag ) ; break ; case CODEC_TYPE_AUDIO : put_be32 ( pb , codec - > sample_rate ) ; put_le16 ( pb , codec - > channels ) ; put_le16 ( pb , codec - > frame_size ) ; break ; default : return - 1 ; } } / * hack to have real time * / if ( ffm_nopts ) ffm - > start_time = 0 ; else ffm - > start_time = av_gettime ( ) ; / * flush until end of block reached * / while ( ( url_ftell ( pb ) % ffm - > packet_size ) ! = 0 ) put_byte ( pb , 0 ) ; put_flush_packet ( pb ) ; / * init packet mux * / ffm - > packet_ptr = ffm - > packet ; ffm - > packet_end = ffm - > packet + ffm - > packet_size - FFM_HEADER_SIZE ; assert ( ffm - > packet_end > = ffm - > packet ) ; ffm - > frame_offset = 0 ; ffm - > pts = 0 ; ffm - > first_packet = 1 ; return 0 ; }",0
"static av_cold int mpeg_mc_decode_init ( AVCodecContext * avctx ) { if ( avctx - > thread_count > 1 ) return - 1 ; if ( ! ( avctx - > slice_flags & SLICE_FLAG_CODED_ORDER ) ) return - 1 ; if ( ! ( avctx - > slice_flags & SLICE_FLAG_ALLOW_FIELD ) ) { av_dlog ( avctx , mpeg12 . c : XvMC decoder will work better if SLICE_FLAG_ALLOW_FIELD is set\n ) ; } mpeg_decode_init ( avctx ) ; avctx - > pix_fmt = PIX_FMT_XVMC_MPEG2_IDCT ; avctx - > xvmc_acceleration = 2 ; //2 - the blocks are packed ! return 0 ; }",0
"static int avs_read_packet ( AVFormatContext * s , AVPacket * pkt ) { AvsFormat * avs = s - > priv_data ; int sub_type = 0 , size = 0 ; AvsBlockType type = AVS_NONE ; int palette_size = 0 ; uint8_t palette[4 + 3 * 256] ; int ret ; if ( avs - > remaining_audio_size > 0 ) if ( avs_read_audio_packet ( s , pkt ) > 0 ) return 0 ; while ( 1 ) { if ( avs - > remaining_frame_size < = 0 ) { if ( ! avio_rl16 ( s - > pb ) ) / * found EOF * / return AVERROR ( EIO ) ; avs - > remaining_frame_size = avio_rl16 ( s - > pb ) - 4 ; } while ( avs - > remaining_frame_size > 0 ) { sub_type = avio_r8 ( s - > pb ) ; type = avio_r8 ( s - > pb ) ; size = avio_rl16 ( s - > pb ) ; if ( size < 4 ) return AVERROR_INVALIDDATA ; avs - > remaining_frame_size - = size ; switch ( type ) { case AVS_PALETTE : if ( size - 4 > sizeof ( palette ) ) return AVERROR_INVALIDDATA ; ret = avio_read ( s - > pb , palette , size - 4 ) ; if ( ret < size - 4 ) return AVERROR ( EIO ) ; palette_size = size ; break ; case AVS_VIDEO : if ( ! avs - > st_video ) { avs - > st_video = avformat_new_stream ( s , NULL ) ; if ( avs - > st_video == NULL ) return AVERROR ( ENOMEM ) ; avs - > st_video - > codec - > codec_type = AVMEDIA_TYPE_VIDEO ; avs - > st_video - > codec - > codec_id = AV_CODEC_ID_AVS ; avs - > st_video - > codec - > width = avs - > width ; avs - > st_video - > codec - > height = avs - > height ; avs - > st_video - > codec - > bits_per_coded_sample=avs - > bits_per_sample ; avs - > st_video - > nb_frames = avs - > nb_frames ; avs - > st_video - > avg_frame_rate = ( AVRational ) { avs - > fps , 1 } ; } return avs_read_video_packet ( s , pkt , type , sub_type , size , palette , palette_size ) ; case AVS_AUDIO : if ( ! avs - > st_audio ) { avs - > st_audio = avformat_new_stream ( s , NULL ) ; if ( avs - > st_audio == NULL ) return AVERROR ( ENOMEM ) ; avs - > st_audio - > codec - > codec_type = AVMEDIA_TYPE_AUDIO ; } avs - > remaining_audio_size = size - 4 ; size = avs_read_audio_packet ( s , pkt ) ; if ( size ! = 0 ) return size ; break ; default : avio_skip ( s - > pb , size - 4 ) ; } } } }",0
"static inline int wv_get_value_integer ( WavpackFrameContext * s , uint32_t * crc , int S ) { int bit ; if ( s - > extra_bits ) { S < < = s - > extra_bits ; if ( s - > got_extra_bits ) { S |= get_bits ( & s - > gb_extra_bits , s - > extra_bits ) ; * crc = * crc * 9 + ( S & 0xffff ) * 3 + ( ( unsigned ) S > > 16 ) ; } } bit = ( S & s - > and ) | s - > or ; return ( ( ( S + bit ) < < s - > shift ) - bit ) < < s - > post_shift ; }",1
"static int bfi_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , const uint8_t * buf , int buf_size ) { BFIContext * bfi = avctx - > priv_data ; uint8_t * dst = bfi - > dst ; uint8_t * src , * dst_offset , colour1 , colour2 ; uint8_t * frame_end = bfi - > dst + avctx - > width * avctx - > height ; uint32_t * pal ; int i , j , height = avctx - > height ; if ( bfi - > frame . data[0] ) avctx - > release_buffer ( avctx , & bfi - > frame ) ; bfi - > frame . reference = 1 ; if ( avctx - > get_buffer ( avctx , & bfi - > frame ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed\n ) ; return - 1 ; } / * Set frame parameters and palette , if necessary * / if ( ! avctx - > frame_number ) { bfi - > frame . pict_type = FF_I_TYPE ; bfi - > frame . key_frame = 1 ; / * Setting the palette * / if ( avctx - > extradata_size > 768 ) { av_log ( NULL , AV_LOG_ERROR , Palette is too large . \n ) ; return - 1 ; } pal = ( uint32_t * ) bfi - > frame . data[1] ; for ( i = 0 ; i < avctx - > extradata_size / 3 ; i + + ) { int shift = 16 ; * pal = 0 ; for ( j = 0 ; j < 3 ; j + + , shift - = 8 ) * pal + = ( ( avctx - > extradata[i * 3 + j] < < 2 ) | ( avctx - > extradata[i * 3 + j] > > 4 ) ) < < shift ; pal + + ; } bfi - > frame . palette_has_changed = 1 ; } else { bfi - > frame . pict_type = FF_P_TYPE ; bfi - > frame . key_frame = 0 ; } buf + = 4 ; //Unpacked size , not required . while ( dst ! = frame_end ) { static const uint8_t lentab[4]= { 0 , 2 , 0 , 1 } ; unsigned int byte = * buf + + , offset ; unsigned int code = byte > > 6 ; unsigned int length = byte & 0xC0 ; / * Get length and offset ( if required ) * / if ( length == 0 ) { if ( code == 1 ) { length = bytestream_get_byte ( & buf ) ; offset = bytestream_get_le16 ( & buf ) ; } else { length = bytestream_get_le16 ( & buf ) ; if ( code == 2 & & length == 0 ) break ; } } else { if ( code == 1 ) offset = bytestream_get_byte ( & buf ) ; } / * Do boundary check * / if ( dst + ( length < < lentab[code] ) > frame_end ) break ; switch ( code ) { case 0 : //Normal Chain bytestream_get_buffer ( & buf , dst , length ) ; dst + = length ; break ; case 1 : //Back Chain dst_offset = dst - offset ; length * = 4 ; //Convert dwords to bytes . if ( dst_offset < bfi - > dst ) break ; while ( length - - ) * dst + + = * dst_offset + + ; break ; case 2 : //Skip Chain dst + = length ; break ; case 3 : //Fill Chain colour1 = bytestream_get_byte ( & buf ) ; colour2 = bytestream_get_byte ( & buf ) ; while ( length - - ) { * dst + + = colour1 ; * dst + + = colour2 ; } break ; } } src = bfi - > dst ; dst = bfi - > frame . data[0] ; while ( height - - ) { memcpy ( dst , src , avctx - > width ) ; src + = avctx - > width ; dst + = bfi - > frame . linesize[0] ; } * data_size = sizeof ( AVFrame ) ; * ( AVFrame * ) data = bfi - > frame ; return buf_size ; }",1
"static int mxf_read_seek ( AVFormatContext * s , int stream_index , int64_t sample_time , int flags ) { AVStream * st = s - > streams[stream_index] ; int64_t seconds ; MXFContext * mxf = s - > priv_data ; int64_t seekpos ; int ret ; MXFIndexTable * t ; if ( mxf - > nb_index_tables < = 0 ) { if ( ! s - > bit_rate ) return AVERROR_INVALIDDATA ; if ( sample_time < 0 ) sample_time = 0 ; seconds = av_rescale ( sample_time , st - > time_base . num , st - > time_base . den ) ; if ( ( ret = avio_seek ( s - > pb , ( s - > bit_rate * seconds ) > > 3 , SEEK_SET ) ) < 0 ) return ret ; ff_update_cur_dts ( s , st , sample_time ) ; mxf - > current_edit_unit = sample_time ; } else { t = & mxf - > index_tables[0] ; / * clamp above zero , else ff_index_search_timestamp ( ) returns negative * this also means we allow seeking before the start * / sample_time = FFMAX ( sample_time , 0 ) ; if ( t - > fake_index ) { / * behave as if we have a proper index * / if ( ( sample_time = ff_index_search_timestamp ( t - > fake_index , t - > nb_ptses , sample_time , flags ) ) < 0 ) return sample_time ; } else { / * no IndexEntryArray ( one or more CBR segments ) * make sure we don ' t seek past the end * / sample_time = FFMIN ( sample_time , st - > duration - 1 ) ; } if ( ( ret = mxf_edit_unit_absolute_offset ( mxf , t , sample_time , & sample_time , & seekpos , 1 ) ) < < 0 ) return ret ; ff_update_cur_dts ( s , st , sample_time ) ; mxf - > current_edit_unit = sample_time ; avio_seek ( s - > pb , seekpos , SEEK_SET ) ; } return 0 ; }",0
"static int thread_execute ( AVCodecContext * avctx , action_func * func , void * arg , int * ret , int job_count , int job_size ) { SliceThreadContext * c = avctx - > internal - > thread_ctx ; int dummy_ret ; if ( ! ( avctx - > active_thread_type & FF_THREAD_SLICE ) || avctx - > thread_count < = 1 ) return avcodec_default_execute ( avctx , func , arg , ret , job_count , job_size ) ; if ( job_count < = 0 ) return 0 ; pthread_mutex_lock ( & c - > current_job_lock ) ; c - > current_job = avctx - > thread_count ; c - > job_count = job_count ; c - > job_size = job_size ; c - > args = arg ; c - > func = func ; if ( ret ) { c - > rets = ret ; c - > rets_count = job_count ; } else { c - > rets = & dummy_ret ; c - > rets_count = 1 ; } c - > current_execute + + ; pthread_cond_broadcast ( & c - > current_job_cond ) ; thread_park_workers ( c , avctx - > thread_count ) ; return 0 ; }",0
"static void chs_assemble_msbs_lsbs ( DCAXllDecoder * s , DCAXllChSet * c , int band ) { DCAXllBand * b = & c - > bands[band] ; int n , ch , nsamples = s - > nframesamples ; for ( ch = 0 ; ch < c - > nchannels ; ch + + ) { int shift = chs_get_lsb_width ( s , c , band , ch ) ; if ( shift ) { int32_t * msb = b - > msb_sample_buffer[ch] ; if ( b - > nscalablelsbs[ch] ) { int32_t * lsb = b - > lsb_sample_buffer[ch] ; int adj = b - > bit_width_adjust[ch] ; for ( n = 0 ; n < nsamples ; n + + ) msb[n] = msb[n] * ( 1 < < shift ) + ( lsb[n] < < adj ) ; } else { for ( n = 0 ; n < nsamples ; n + + ) msb[n] = msb[n] * ( 1 < < shift ) ; } } } }",1
"static av_cold int vqa_decode_init ( AVCodecContext * avctx ) { VqaContext * s = avctx - > priv_data ; unsigned char * vqa_header ; int i , j , codebook_index ; s - > avctx = avctx ; avctx - > pix_fmt = PIX_FMT_PAL8 ; / * make sure the extradata made it * / if ( s - > avctx - > extradata_size ! = VQA_HEADER_SIZE ) { av_log ( s - > avctx , AV_LOG_ERROR , VQA video : expected extradata size of %d\n , VQA_HEADER_SIZE ) ; return - 1 ; } / * load up the VQA parameters from the header * / vqa_header = ( unsigned char * ) s - > avctx - > extradata ; s - > vqa_version = vqa_header[0] ; s - > width = AV_RL16 ( & vqa_header[6] ) ; s - > height = AV_RL16 ( & vqa_header[8] ) ; if ( av_image_check_size ( s - > width , s - > height , 0 , avctx ) ) { s - > width= s - > height= 0 ; return - 1 ; } s - > vector_width = vqa_header[10] ; s - > vector_height = vqa_header[11] ; s - > partial_count = s - > partial_countdown = vqa_header[13] ; / * the vector dimensions have to meet very stringent requirements * / if ( ( s - > vector_width ! = 4 ) || ( ( s - > vector_height ! = 2 ) & & ( s - > vector_height ! = 4 ) ) ) { / * return without further initialization * / return - 1 ; } / * allocate codebooks * / s - > codebook_size = MAX_CODEBOOK_SIZE ; s - > codebook = av_malloc ( s - > codebook_size ) ; if ( ! s - > codebook ) goto fail ; s - > next_codebook_buffer = av_malloc ( s - > codebook_size ) ; if ( ! s - > next_codebook_buffer ) goto fail ; / * allocate decode buffer * / s - > decode_buffer_size = ( s - > width / s - > vector_width ) * ( s - > height / s - > vector_height ) * 2 ; s - > decode_buffer = av_malloc ( s - > decode_buffer_size ) ; if ( ! s - > decode_buffer ) goto fail ; / * initialize the solid - color vectors * / if ( s - > vector_height == 4 ) { codebook_index = 0xFF00 * 16 ; for ( i = 0 ; i < 256 ; i + + ) for ( j = 0 ; j < 16 ; j + + ) s - > codebook[codebook_index + + ] = i ; } else { codebook_index = 0xF00 * 8 ; for ( i = 0 ; i < 256 ; i + + ) for ( j = 0 ; j < 8 ; j + + ) s - > codebook[codebook_index + + ] = i ; } s - > next_codebook_buffer_index = 0 ; s - > frame . data[0] = NULL ; return 0 ; fail : av_freep ( & s - > codebook ) ; av_freep ( & s - > next_codebook_buffer ) ; av_freep ( & s - > decode_buffer ) ; return AVERROR ( ENOMEM ) ; }",1
"static void init_multbl2 ( uint8_t tbl[1024] , const int c[4] , const uint8_t * log8 , const uint8_t * alog8 , const uint8_t * sbox ) { int i , j ; for ( i = 0 ; i < 1024 ; i + + ) { int x = sbox[i > > 2] ; if ( x ) tbl[i] = alog8[log8[x] + log8[c[i & 3]]] ; } if ! CONFIG_SMALL for ( j = 256 ; j < 1024 ; j + + ) for ( i = 0 ; i < 4 ; i + + ) tbl[4 * j + i] = tbl[4 * j + ( ( i - 1 ) & 3 ) - 1024] ; endif }",1
"static int t27 ( InterplayACMContext * s , unsigned ind , unsigned col ) { GetBitContext * gb = & s - > gb ; unsigned i , b ; int n1 , n2 , n3 ; for ( i = 0 ; i < s - > rows ; i + + ) { / * b = ( x1 ) + ( x2 * 5 ) + ( x3 * 25 ) * / b = get_bits ( gb , 7 ) ; n1 = ( mul_3x5[b] & 0x0F ) - 2 ; n2 = ( ( mul_3x5[b] > > 4 ) & 0x0F ) - 2 ; n3 = ( ( mul_3x5[b] > > 8 ) & 0x0F ) - 2 ; set_pos ( s , i + + , col , n1 ) ; if ( i > = s - > rows ) break ; set_pos ( s , i + + , col , n2 ) ; if ( i > = s - > rows ) break ; set_pos ( s , i , col , n3 ) ; return 0 ;",1
"static int decode_residual ( H264Context * h , GetBitContext * gb , DCTELEM * block , int n , const uint8_t * scantable , const uint32_t * qmul , int max_coeff ) { MpegEncContext * const s = & h - > s ; static const int coeff_token_table_index[17]= { 0 , 0 , 1 , 1 , 2 , 2 , 2 , 2 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 } ; int level[16] ; int zeros_left , coeff_token , total_coeff , i , trailing_ones , run_before ; //FIXME put trailing_onex into the context if ( max_coeff < = 8 ) { if ( max_coeff == 4 ) coeff_token = get_vlc2 ( gb , chroma_dc_coeff_token_vlc . table , CHROMA_DC_COEFF_TOKEN_VLC_BITS , 1 ) ; else coeff_token = get_vlc2 ( gb , chroma422_dc_coeff_token_vlc . table , CHROMA422_DC_COEFF_TOKEN_VLC_BITS , 1 ) ; total_coeff= coeff_token > > 2 ; } else { if ( n > = LUMA_DC_BLOCK_INDEX ) { total_coeff= pred_non_zero_count ( h , ( n - LUMA_DC_BLOCK_INDEX ) * 16 ) ; coeff_token= get_vlc2 ( gb , coeff_token_vlc[ coeff_token_table_index[total_coeff] ] . table , COEFF_TOKEN_VLC_BITS , 2 ) ; total_coeff= coeff_token > > 2 ; } else { total_coeff= pred_non_zero_count ( h , n ) ; coeff_token= get_vlc2 ( gb , coeff_token_vlc[ coeff_token_table_index[total_coeff] ] . table , COEFF_TOKEN_VLC_BITS , 2 ) ; total_coeff= coeff_token > > 2 ; } } h - > non_zero_count_cache[ scan8[n] ]= total_coeff ; //FIXME set last_non_zero ? if ( total_coeff==0 ) return 0 ; if ( total_coeff > ( unsigned ) max_coeff ) { av_log ( h - > s . avctx , AV_LOG_ERROR , corrupted macroblock %d %d ( total_coeff=%d ) \n , s - > mb_x , s - > mb_y , total_coeff ) ; return - 1 ; } trailing_ones= coeff_token & 3 ; tprintf ( h - > s . avctx , trailing : %d , total : %d\n , trailing_ones , total_coeff ) ; assert ( total_coeff < =16 ) ; i = show_bits ( gb , 3 ) ; skip_bits ( gb , trailing_ones ) ; level[0] = 1 - ( ( i & 4 ) > > 1 ) ; level[1] = 1 - ( ( i & 2 ) ) ; level[2] = 1 - ( ( i & 1 ) < < 1 ) ; if ( trailing_ones < total_coeff ) { int mask , prefix ; int suffix_length = total_coeff > 10 & trailing_ones < 3 ; int bitsi= show_bits ( gb , LEVEL_TAB_BITS ) ; int level_code= cavlc_level_tab[suffix_length][bitsi][0] ; skip_bits ( gb , cavlc_level_tab[suffix_length][bitsi][1] ) ; if ( level_code > = 100 ) { prefix= level_code - 100 ; if ( prefix == LEVEL_TAB_BITS ) prefix + = get_level_prefix ( gb ) ; //first coefficient has suffix_length equal to 0 or 1 if ( prefix < 14 ) { //FIXME try to build a large unified VLC table for all this if ( suffix_length ) level_code= ( prefix < < 1 ) + get_bits1 ( gb ) ; //part else level_code= prefix ; //part } else if ( prefix==14 ) { if ( suffix_length ) level_code= ( prefix < < 1 ) + get_bits1 ( gb ) ; //part else level_code= prefix + get_bits ( gb , 4 ) ; //part } else { level_code= 30 + get_bits ( gb , prefix - 3 ) ; //part if ( prefix > =16 ) { if ( prefix > 25 + 3 ) { av_log ( h - > s . avctx , AV_LOG_ERROR , Invalid level prefix\n ) ; return - 1 ; } level_code + = ( 1 < < ( prefix - 3 ) ) - 4096 ; } } if ( trailing_ones < 3 ) level_code + = 2 ; suffix_length = 2 ; mask= - ( level_code & 1 ) ; level[trailing_ones]= ( ( ( 2 + level_code ) > > 1 ) mask ) - mask ; } else { level_code + = ( ( level_code > > 31 ) |1 ) & - ( trailing_ones < 3 ) ; suffix_length = 1 + ( level_code + 3U > 6U ) ; level[trailing_ones]= level_code ; } //remaining coefficients have suffix_length > 0 for ( i=trailing_ones + 1 ; i < total_coeff ; i + + ) { static const unsigned int suffix_limit[7] = { 0 , 3 , 6 , 12 , 24 , 48 , INT_MAX } ; int bitsi= show_bits ( gb , LEVEL_TAB_BITS ) ; level_code= cavlc_level_tab[suffix_length][bitsi][0] ; skip_bits ( gb , cavlc_level_tab[suffix_length][bitsi][1] ) ; if ( level_code > = 100 ) { prefix= level_code - 100 ; if ( prefix == LEVEL_TAB_BITS ) { prefix + = get_level_prefix ( gb ) ; } if ( prefix < 15 ) { level_code = ( prefix < < suffix_length ) + get_bits ( gb , suffix_length ) ; } else { level_code = ( 15 < < suffix_length ) + get_bits ( gb , prefix - 3 ) ; if ( prefix > =16 ) level_code + = ( 1 < < ( prefix - 3 ) ) - 4096 ; } mask= - ( level_code & 1 ) ; level_code= ( ( ( 2 + level_code ) > > 1 ) mask ) - mask ; } level[i]= level_code ; suffix_length + = suffix_limit[suffix_length] + level_code > 2U * suffix_limit[suffix_length] ; } } if ( total_coeff == max_coeff ) zeros_left=0 ; else { if ( max_coeff < = 8 ) { if ( max_coeff == 4 ) zeros_left = get_vlc2 ( gb , chroma_dc_total_zeros_vlc[total_coeff - 1] . table , CHROMA_DC_TOTAL_ZEROS_VLC_BITS , 1 ) ; else zeros_left = get_vlc2 ( gb , chroma422_dc_total_zeros_vlc[total_coeff - 1] . table , CHROMA422_DC_TOTAL_ZEROS_VLC_BITS , 1 ) ; } else { zeros_left= get_vlc2 ( gb , total_zeros_vlc[total_coeff - 1] . table , TOTAL_ZEROS_VLC_BITS , 1 ) ; } } define STORE_BLOCK ( type ) \ scantable + = zeros_left + total_coeff - 1 ; \ if ( n > = LUMA_DC_BLOCK_INDEX ) { \ ( ( type * ) block ) [ * scantable] = level[0] ; \ for ( i=1 ; i < total_coeff & & zeros_left > 0 ; i + + ) { \ if ( zeros_left < 7 ) \ run_before= get_vlc2 ( gb , run_vlc[zeros_left - 1] . table , RUN_VLC_BITS , 1 ) ; \ else \ run_before= get_vlc2 ( gb , run7_vlc . table , RUN7_VLC_BITS , 2 ) ; \ zeros_left - = run_before ; \ scantable - = 1 + run_before ; \ ( ( type * ) block ) [ * scantable]= level[i] ; \ } \ for ( ; i < total_coeff ; i + + ) { \ scantable - - ; \ ( ( type * ) block ) [ * scantable]= level[i] ; \ } \ } else { \ ( ( type * ) block ) [ * scantable] = ( ( int ) ( level[0] * qmul[ * scantable] + 32 ) ) > > 6 ; \ for ( i=1 ; i < total_coeff & & zeros_left > 0 ; i + + ) { \",1
"static AVFrame * hwmap_get_buffer ( AVFilterLink * inlink , int w , int h ) { AVFilterContext * avctx = inlink - > dst ; AVFilterLink * outlink = avctx - > outputs[0] ; HWMapContext * ctx = avctx - > priv ; if ( ctx - > map_backwards ) { AVFrame * src , * dst ; int err ; src = ff_get_video_buffer ( outlink , w , h ) ; if ( ! src ) { av_log ( avctx , AV_LOG_ERROR , Failed to allocate source frame for software mapping . \n ) ; return NULL ; } dst = av_frame_alloc ( ) ; if ( ! dst ) { av_frame_free ( & src ) ; return NULL ; } err = av_hwframe_map ( dst , src , ctx - > mode ) ; if ( err ) { av_log ( avctx , AV_LOG_ERROR , Failed to map frame to software : %d . \n , err ) ; av_frame_free ( & src ) ; av_frame_free ( & dst ) ; return NULL ; } av_frame_free ( & src ) ; return dst ; } else { return ff_default_get_video_buffer ( inlink , w , h ) ; } }",1
"static int decode_wdlt ( uint8_t * frame , int width , int height , const uint8_t * src , const uint8_t * src_end ) { const uint8_t * frame_end = frame + width * height ; uint8_t * line_ptr ; int count , i , v , lines , segments ; lines = bytestream_get_le16 ( & src ) ; if ( lines > height || src > = src_end ) return - 1 ; while ( lines - - ) { segments = bytestream_get_le16 ( & src ) ; while ( ( segments & 0xC000 ) == 0xC000 ) { unsigned delta = - ( ( int16_t ) segments * width ) ; if ( frame_end - frame < = delta ) return - 1 ; frame + = delta ; segments = bytestream_get_le16 ( & src ) ; } if ( segments & 0x8000 ) { frame[width - 1] = segments & 0xFF ; segments = bytestream_get_le16 ( & src ) ; } line_ptr = frame ; frame + = width ; while ( segments - - ) { if ( src_end - src < 2 ) return - 1 ; if ( frame - line_ptr < = * src ) return - 1 ; line_ptr + = * src + + ; count = ( int8_t ) * src + + ; if ( count > = 0 ) { if ( frame - line_ptr < count * 2 || src_end - src < count * 2 ) return - 1 ; bytestream_get_buffer ( & src , line_ptr , count * 2 ) ; line_ptr + = count * 2 ; } else { count = - count ; if ( frame - line_ptr < count * 2 || src_end - src < 2 ) return - 1 ; v = bytestream_get_le16 ( & src ) ; for ( i = 0 ; i < count ; i + + ) bytestream_put_le16 ( & line_ptr , v ) ; } } } return 0 ; }",1
"av_cold void ff_vp8dsp_init_x86 ( VP8DSPContext * c ) { mm_flags = mm_support ( ) ; if HAVE_YASM if ( mm_flags & FF_MM_MMX ) { c - > vp8_idct_dc_add = ff_vp8_idct_dc_add_mmx ; c - > vp8_idct_add = ff_vp8_idct_add_mmx ; c - > put_vp8_epel_pixels_tab[0][0][0] = c - > put_vp8_bilinear_pixels_tab[0][0][0] = ff_put_vp8_pixels16_mmx ; c - > put_vp8_epel_pixels_tab[1][0][0] = c - > put_vp8_bilinear_pixels_tab[1][0][0] = ff_put_vp8_pixels8_mmx ; c - > vp8_v_loop_filter_simple = ff_vp8_v_loop_filter_simple_mmx ; c - > vp8_h_loop_filter_simple = ff_vp8_h_loop_filter_simple_mmx ; c - > vp8_v_loop_filter16y_inner = ff_vp8_v_loop_filter16y_inner_mmx ; c - > vp8_h_loop_filter16y_inner = ff_vp8_h_loop_filter16y_inner_mmx ; c - > vp8_v_loop_filter8uv_inner = ff_vp8_v_loop_filter8uv_inner_mmx ; c - > vp8_h_loop_filter8uv_inner = ff_vp8_h_loop_filter8uv_inner_mmx ; } / * note that 4 - tap width=16 functions are missing because w=16 * is only used for luma , and luma is always a copy or sixtap . * / if ( mm_flags & FF_MM_MMX2 ) { c - > vp8_luma_dc_wht = ff_vp8_luma_dc_wht_mmxext ; VP8_LUMA_MC_FUNC ( 0 , 16 , mmxext ) ; VP8_MC_FUNC ( 1 , 8 , mmxext ) ; VP8_MC_FUNC ( 2 , 4 , mmxext ) ; VP8_BILINEAR_MC_FUNC ( 0 , 16 , mmxext ) ; VP8_BILINEAR_MC_FUNC ( 1 , 8 , mmxext ) ; VP8_BILINEAR_MC_FUNC ( 2 , 4 , mmxext ) ; c - > vp8_v_loop_filter_simple = ff_vp8_v_loop_filter_simple_mmxext ; c - > vp8_h_loop_filter_simple = ff_vp8_h_loop_filter_simple_mmxext ; c - > vp8_v_loop_filter16y_inner = ff_vp8_v_loop_filter16y_inner_mmxext ; c - > vp8_h_loop_filter16y_inner = ff_vp8_h_loop_filter16y_inner_mmxext ; c - > vp8_v_loop_filter8uv_inner = ff_vp8_v_loop_filter8uv_inner_mmxext ; c - > vp8_h_loop_filter8uv_inner = ff_vp8_h_loop_filter8uv_inner_mmxext ; } if ( mm_flags & FF_MM_SSE ) { c - > put_vp8_epel_pixels_tab[0][0][0] = c - > put_vp8_bilinear_pixels_tab[0][0][0] = ff_put_vp8_pixels16_sse ; } if ( mm_flags & FF_MM_SSE2 ) { VP8_LUMA_MC_FUNC ( 0 , 16 , sse2 ) ; VP8_MC_FUNC ( 1 , 8 , sse2 ) ; VP8_BILINEAR_MC_FUNC ( 0 , 16 , sse2 ) ; VP8_BILINEAR_MC_FUNC ( 1 , 8 , sse2 ) ; c - > vp8_v_loop_filter_simple = ff_vp8_v_loop_filter_simple_sse2 ; c - > vp8_h_loop_filter_simple = ff_vp8_h_loop_filter_simple_sse2 ; c - > vp8_v_loop_filter16y_inner = ff_vp8_v_loop_filter16y_inner_sse2 ; c - > vp8_h_loop_filter16y_inner = ff_vp8_h_loop_filter16y_inner_sse2 ; c - > vp8_v_loop_filter8uv_inner = ff_vp8_v_loop_filter8uv_inner_sse2 ; c - > vp8_h_loop_filter8uv_inner = ff_vp8_h_loop_filter8uv_inner_sse2 ; } if ( mm_flags & FF_MM_SSSE3 ) { VP8_LUMA_MC_FUNC ( 0 , 16 , ssse3 ) ; VP8_MC_FUNC ( 1 , 8 , ssse3 ) ; VP8_MC_FUNC ( 2 , 4 , ssse3 ) ; VP8_BILINEAR_MC_FUNC ( 0 , 16 , ssse3 ) ; VP8_BILINEAR_MC_FUNC ( 1 , 8 , ssse3 ) ; VP8_BILINEAR_MC_FUNC ( 2 , 4 , ssse3 ) ; } if ( mm_flags & FF_MM_SSE4 ) { c - > vp8_idct_dc_add = ff_vp8_idct_dc_add_sse4 ; } endif }",0
"PIX_SAD ( mmxext ) endif / * HAVE_INLINE_ASM * / av_cold void ff_dsputil_init_pix_mmx ( DSPContext * c , AVCodecContext * avctx ) { if HAVE_INLINE_ASM int cpu_flags = av_get_cpu_flags ( ) ; if ( INLINE_MMX ( cpu_flags ) ) { c - > pix_abs[0][0] = sad16_mmx ; c - > pix_abs[0][1] = sad16_x2_mmx ; c - > pix_abs[0][2] = sad16_y2_mmx ; c - > pix_abs[0][3] = sad16_xy2_mmx ; c - > pix_abs[1][0] = sad8_mmx ; c - > pix_abs[1][1] = sad8_x2_mmx ; c - > pix_abs[1][2] = sad8_y2_mmx ; c - > pix_abs[1][3] = sad8_xy2_mmx ; c - > sad[0] = sad16_mmx ; c - > sad[1] = sad8_mmx ; } if ( INLINE_MMXEXT ( cpu_flags ) ) { c - > pix_abs[0][0] = sad16_mmxext ; c - > pix_abs[1][0] = sad8_mmxext ; c - > sad[0] = sad16_mmxext ; c - > sad[1] = sad8_mmxext ; if ( ! ( avctx - > flags & CODEC_FLAG_BITEXACT ) ) { c - > pix_abs[0][1] = sad16_x2_mmxext ; c - > pix_abs[0][2] = sad16_y2_mmxext ; c - > pix_abs[0][3] = sad16_xy2_mmxext ; c - > pix_abs[1][1] = sad8_x2_mmxext ; c - > pix_abs[1][2] = sad8_y2_mmxext ; c - > pix_abs[1][3] = sad8_xy2_mmxext ; } } if ( INLINE_SSE2 ( cpu_flags ) & & ! ( cpu_flags & AV_CPU_FLAG_3DNOW ) & & avctx - > codec_id ! = AV_CODEC_ID_SNOW ) { c - > sad[0] = sad16_sse2 ; } endif / * HAVE_INLINE_ASM * / }",0
"static int xan_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , uint8_t * buf , int buf_size ) { XanContext * s = avctx - > priv_data ; AVPaletteControl * palette_control = avctx - > palctrl ; int keyframe = 0 ; if ( palette_control - > palette_changed ) { / * load the new palette and reset the palette control * / xan_wc3_build_palette ( s , palette_control - > palette ) ; / * If pal8 we clear flag when we copy palette * / if ( s - > avctx - > pix_fmt ! = PIX_FMT_PAL8 ) palette_control - > palette_changed = 0 ; keyframe = 1 ; } if ( avctx - > get_buffer ( avctx , & s - > current_frame ) ) { av_log ( s - > avctx , AV_LOG_ERROR , Xan Video : get_buffer ( ) failed\n ) ; return - 1 ; } s - > current_frame . reference = 3 ; s - > buf = buf ; s - > size = buf_size ; if ( avctx - > codec - > id == CODEC_ID_XAN_WC3 ) xan_wc3_decode_frame ( s ) ; else if ( avctx - > codec - > id == CODEC_ID_XAN_WC4 ) xan_wc4_decode_frame ( s ) ; / * release the last frame if it is allocated * / if ( s - > last_frame . data[0] ) avctx - > release_buffer ( avctx , & s - > last_frame ) ; / * shuffle frames * / s - > last_frame = s - > current_frame ; * data_size = sizeof ( AVFrame ) ; * ( AVFrame * ) data = s - > current_frame ; / * always report that the buffer was completely consumed * / return buf_size ; }",0
"static av_cold int libopenjpeg_encode_init ( AVCodecContext * avctx ) { LibOpenJPEGContext * ctx = avctx - > priv_data ; int err = 0 ; opj_set_default_encoder_parameters ( & ctx - > enc_params ) ; if HAVE_OPENJPEG_2_1_OPENJPEG_H switch ( ctx - > cinema_mode ) { case OPJ_CINEMA2K_24 : ctx - > enc_params . rsiz = OPJ_PROFILE_CINEMA_2K ; ctx - > enc_params . max_cs_size = OPJ_CINEMA_24_CS ; ctx - > enc_params . max_comp_size = OPJ_CINEMA_24_COMP ; break ; case OPJ_CINEMA2K_48 : ctx - > enc_params . rsiz = OPJ_PROFILE_CINEMA_2K ; ctx - > enc_params . max_cs_size = OPJ_CINEMA_48_CS ; ctx - > enc_params . max_comp_size = OPJ_CINEMA_48_COMP ; break ; case OPJ_CINEMA4K_24 : ctx - > enc_params . rsiz = OPJ_PROFILE_CINEMA_4K ; ctx - > enc_params . max_cs_size = OPJ_CINEMA_24_CS ; ctx - > enc_params . max_comp_size = OPJ_CINEMA_24_COMP ; break ; } switch ( ctx - > profile ) { case OPJ_CINEMA2K : if ( ctx - > enc_params . rsiz == OPJ_PROFILE_CINEMA_4K ) { err = AVERROR ( EINVAL ) ; break ; } ctx - > enc_params . rsiz = OPJ_PROFILE_CINEMA_2K ; break ; case OPJ_CINEMA4K : if ( ctx - > enc_params . rsiz == OPJ_PROFILE_CINEMA_2K ) { err = AVERROR ( EINVAL ) ; break ; } ctx - > enc_params . rsiz = OPJ_PROFILE_CINEMA_4K ; break ; } if ( err ) { av_log ( avctx , AV_LOG_ERROR , Invalid parameter pairing : cinema_mode and profile conflict . \n ) ; goto fail ; } else ctx - > enc_params . cp_rsiz = ctx - > profile ; ctx - > enc_params . cp_cinema = ctx - > cinema_mode ; endif if ( ! ctx - > numresolution ) { ctx - > numresolution = 6 ; while ( FFMIN ( avctx - > width , avctx - > height ) > > ctx - > numresolution < 1 ) ctx - > numresolution - - ; } ctx - > enc_params . mode = ! ! avctx - > global_quality ; ctx - > enc_params . prog_order = ctx - > prog_order ; ctx - > enc_params . numresolution = ctx - > numresolution ; ctx - > enc_params . cp_disto_alloc = ctx - > disto_alloc ; ctx - > enc_params . cp_fixed_alloc = ctx - > fixed_alloc ; ctx - > enc_params . cp_fixed_quality = ctx - > fixed_quality ; ctx - > enc_params . tcp_numlayers = ctx - > numlayers ; ctx - > enc_params . tcp_rates[0] = FFMAX ( avctx - > compression_level , 0 ) * 2 ; if ( ctx - > cinema_mode > 0 ) { cinema_parameters ( & ctx - > enc_params ) ; } if OPENJPEG_MAJOR_VERSION == 1 ctx - > image = mj2_create_image ( avctx , & ctx - > enc_params ) ; if ( ! ctx - > image ) { av_log ( avctx , AV_LOG_ERROR , Error creating the mj2 image\n ) ; err = AVERROR ( EINVAL ) ; goto fail ; } endif // OPENJPEG_MAJOR_VERSION == 1 return 0 ; fail : if OPENJPEG_MAJOR_VERSION == 1 opj_image_destroy ( ctx - > image ) ; ctx - > image = NULL ; endif // OPENJPEG_MAJOR_VERSION == 1 return err ; }",0
"static void init_filter_param ( AVFilterContext * ctx , FilterParam * fp , const char * effect_type , int width ) { int z ; const char * effect ; effect = fp - > amount == 0 ? none : fp - > amount < 0 ? blur : sharpen ; av_log ( ctx , AV_LOG_VERBOSE , effect : %s type : %s msize_x : %d msize_y : %d amount : %0 . 2f\n , effect , effect_type , fp - > msize_x , fp - > msize_y , fp - > amount / 65535 . 0 ) ; for ( z = 0 ; z < 2 * fp - > steps_y ; z + + ) fp - > sc[z] = av_malloc ( sizeof ( * ( fp - > sc[z] ) ) * ( width + 2 * fp - > steps_x ) ) ; }",0
"static inline void FUNC ( idctRowCondDC_extrashift ) ( int16_t * row , int extra_shift ) else static inline void FUNC ( idctRowCondDC ) ( int16_t * row , int extra_shift ) endif { int a0 , a1 , a2 , a3 , b0 , b1 , b2 , b3 ; if HAVE_FAST_64BIT define ROW0_MASK ( 0xffffLL < < 48 * HAVE_BIGENDIAN ) if ( ( ( ( ( uint64_t * ) row ) [0] & ROW0_MASK ) | ( ( uint64_t * ) row ) [1] ) == 0 ) { uint64_t temp ; if ( DC_SHIFT - extra_shift > = 0 ) { temp = ( row[0] * ( 1 < < ( DC_SHIFT - extra_shift ) ) ) & 0xffff ; } else { temp = ( ( row[0] + ( 1 < < ( extra_shift - DC_SHIFT - 1 ) ) ) > > ( extra_shift - DC_SHIFT ) ) & 0xffff ; } temp + = temp * ( 1 < < 16 ) ; temp + = temp * ( ( uint64_t ) 1 < < 32 ) ; ( ( uint64_t * ) row ) [0] = temp ; ( ( uint64_t * ) row ) [1] = temp ; return ; } else if ( ! ( ( ( uint32_t * ) row ) [1] | ( ( uint32_t * ) row ) [2] | ( ( uint32_t * ) row ) [3] | row[1] ) ) { uint32_t temp ; if ( DC_SHIFT - extra_shift > = 0 ) { temp = ( row[0] * ( 1 < < ( DC_SHIFT - extra_shift ) ) ) & 0xffff ; } else { temp = ( ( row[0] + ( 1 < < ( extra_shift - DC_SHIFT - 1 ) ) ) > > ( extra_shift - DC_SHIFT ) ) & 0xffff ; } temp + = temp * ( 1 < < 16 ) ; ( ( uint32_t * ) row ) [0]= ( ( uint32_t * ) row ) [1] = ( ( uint32_t * ) row ) [2]= ( ( uint32_t * ) row ) [3] = temp ; return ; } endif a0 = ( W4 * row[0] ) + ( 1 < < ( ROW_SHIFT + extra_shift - 1 ) ) ; a1 = a0 ; a2 = a0 ; a3 = a0 ; a0 + = W2 * row[2] ; a1 + = W6 * row[2] ; a2 - = W6 * row[2] ; a3 - = W2 * row[2] ; b0 = MUL ( W1 , row[1] ) ; MAC ( b0 , W3 , row[3] ) ; b1 = MUL ( W3 , row[1] ) ; MAC ( b1 , - W7 , row[3] ) ; b2 = MUL ( W5 , row[1] ) ; MAC ( b2 , - W1 , row[3] ) ; b3 = MUL ( W7 , row[1] ) ; MAC ( b3 , - W5 , row[3] ) ; if ( AV_RN64A ( row + 4 ) ) { a0 + = W4 * row[4] + W6 * row[6] ; a1 + = - W4 * row[4] - W2 * row[6] ; a2 + = - W4 * row[4] + W2 * row[6] ; a3 + = W4 * row[4] - W6 * row[6] ; MAC ( b0 , W5 , row[5] ) ; MAC ( b0 , W7 , row[7] ) ; MAC ( b1 , - W1 , row[5] ) ; MAC ( b1 , - W5 , row[7] ) ; MAC ( b2 , W7 , row[5] ) ; MAC ( b2 , W3 , row[7] ) ; MAC ( b3 , W3 , row[5] ) ; MAC ( b3 , - W1 , row[7] ) ; } row[0] = ( a0 + b0 ) > > ( ROW_SHIFT + extra_shift ) ; row[7] = ( a0 - b0 ) > > ( ROW_SHIFT + extra_shift ) ; row[1] = ( a1 + b1 ) > > ( ROW_SHIFT + extra_shift ) ; row[6] = ( a1 - b1 ) > > ( ROW_SHIFT + extra_shift ) ; row[2] = ( a2 + b2 ) > > ( ROW_SHIFT + extra_shift ) ; row[5] = ( a2 - b2 ) > > ( ROW_SHIFT + extra_shift ) ; row[3] = ( a3 + b3 ) > > ( ROW_SHIFT + extra_shift ) ; row[4] = ( a3 - b3 ) > > ( ROW_SHIFT + extra_shift ) ; }",0
"static int mov_read_stco ( MOVContext * c , AVIOContext * pb , MOVAtom atom ) { AVStream * st ; MOVStreamContext * sc ; unsigned int i , entries ; if ( c - > fc - > nb_streams < 1 ) return 0 ; st = c - > fc - > streams[c - > fc - > nb_streams - 1] ; sc = st - > priv_data ; avio_r8 ( pb ) ; / * version * / avio_rb24 ( pb ) ; / * flags * / entries = avio_rb32 ( pb ) ; if ( ! entries ) return 0 ; if ( entries > = UINT_MAX/sizeof ( int64_t ) ) return AVERROR_INVALIDDATA ; sc - > chunk_offsets = av_malloc ( entries * sizeof ( int64_t ) ) ; if ( ! sc - > chunk_offsets ) return AVERROR ( ENOMEM ) ; sc - > chunk_count = entries ; if ( atom . type == MKTAG ( ' s ' , ' t ' , ' c ' , ' o ' ) ) for ( i=0 ; i < entries ; i + + ) sc - > chunk_offsets[i] = avio_rb32 ( pb ) ; else if ( atom . type == MKTAG ( ' c ' , ' o ' , ' 6 ' , ' 4 ' ) ) for ( i=0 ; i < entries ; i + + ) sc - > chunk_offsets[i] = avio_rb64 ( pb ) ; else return AVERROR_INVALIDDATA ; return 0 ; }",0
"static void blur ( uint8_t * dst , const int dst_linesize , const uint8_t * src , const int src_linesize , const int w , const int h , FilterParam * fp ) { int x , y ; FilterParam f = * fp ; const int radius = f . dist_width/2 ; const uint8_t * const src2[NB_PLANES] = { src } ; int src2_linesize[NB_PLANES] = { src_linesize } ; uint8_t * dst2[NB_PLANES] = { f . pre_filter_buf } ; int dst2_linesize[NB_PLANES] = { f . pre_filter_linesize } ; sws_scale ( f . pre_filter_context , src2 , src2_linesize , 0 , h , dst2 , dst2_linesize ) ; define UPDATE_FACTOR do { \ int factor ; \ factor = f . color_diff_coeff[COLOR_DIFF_COEFF_SIZE/2 + pre_val - \ f . pre_filter_buf[ix + iy * f . pre_filter_linesize]] * f . dist_coeff[dx + dy * f . dist_linesize] ; \ sum + = src[ix + iy * src_linesize] * factor ; \ div + = factor ; \ } while ( 0 ) for ( y = 0 ; y < h ; y + + ) { for ( x = 0 ; x < w ; x + + ) { int sum = 0 ; int div = 0 ; int dy ; const int pre_val = f . pre_filter_buf[x + y * f . pre_filter_linesize] ; if ( x > = radius & & x < w - radius ) { for ( dy = 0 ; dy < radius * 2 + 1 ; dy + + ) { int dx ; int iy = y + dy - radius ; if ( iy < 0 ) iy = - iy ; else if ( iy > = h ) iy = h + h - iy - 1 ; for ( dx = 0 ; dx < radius * 2 + 1 ; dx + + ) { const int ix = x + dx - radius ; UPDATE_FACTOR ; } } } else { for ( dy = 0 ; dy < radius * 2 + 1 ; dy + + ) { int dx ; int iy = y + dy - radius ; if ( iy < 0 ) iy = - iy ; else if ( iy > = h ) iy = h + h - iy - 1 ; for ( dx = 0 ; dx < radius * 2 + 1 ; dx + + ) { int ix = x + dx - radius ; if ( ix < 0 ) ix = - ix ; else if ( ix > = w ) ix = w + w - ix - 1 ; UPDATE_FACTOR ; } } } dst[x + y * dst_linesize] = ( sum + div/2 ) / div ; } } }",0
"static inline void decode_subblock ( DCTELEM * dst , int code , const int is_block2 , GetBitContext * gb , VLC * vlc , int q ) { int coeffs[4] ; coeffs[0] = modulo_three_table[code][0] ; coeffs[1] = modulo_three_table[code][1] ; coeffs[2] = modulo_three_table[code][2] ; coeffs[3] = modulo_three_table[code][3] ; decode_coeff ( dst , coeffs[0] , 3 , gb , vlc , q ) ; if ( is_block2 ) { decode_coeff ( dst + 8 , coeffs[1] , 2 , gb , vlc , q ) ; decode_coeff ( dst + 1 , coeffs[2] , 2 , gb , vlc , q ) ; } else { decode_coeff ( dst + 1 , coeffs[1] , 2 , gb , vlc , q ) ; decode_coeff ( dst + 8 , coeffs[2] , 2 , gb , vlc , q ) ; } decode_coeff ( dst + 9 , coeffs[3] , 2 , gb , vlc , q ) ; }",0
"static int process_metadata ( AVFormatContext * s , uint8_t * name , uint16_t name_len , uint16_t val_len , uint16_t type , AVDictionary * * met ) { int ret ; ff_asf_guid guid ; if ( val_len ) { switch ( type ) { case ASF_UNICODE : asf_read_value ( s , name , name_len , val_len , type , met ) ; break ; case ASF_BYTE_ARRAY : if ( ! strcmp ( name , WM/Picture ) ) // handle cover art asf_read_picture ( s , val_len ) ; else if ( ! strcmp ( name , ID3 ) ) // handle ID3 tag get_id3_tag ( s , val_len ) ; else asf_read_value ( s , name , name_len , val_len , type , met ) ; break ; case ASF_GUID : ff_get_guid ( s - > pb , & guid ) ; break ; default : if ( ( ret = asf_read_generic_value ( s , name , name_len , type , met ) ) < 0 ) return ret ; break ; } } av_freep ( & name ) ; return 0 ; }",1
"static void add_bytes_l2_c ( uint8_t * dst , uint8_t * src1 , uint8_t * src2 , int w ) { long i ; for ( i = 0 ; i < = w - sizeof ( long ) ; i + = sizeof ( long ) ) { long a = * ( long * ) ( src1 + i ) ; long b = * ( long * ) ( src2 + i ) ; * ( long * ) ( dst + i ) = ( ( a & pb_7f ) + ( b & pb_7f ) ) ( ( a b ) & pb_80 ) ; } for ( ; i < w ; i + + ) dst[i] = src1[i] + src2[i] ; }",0
void av_set_cpu_flags_mask ( int mask ) { cpu_flags = get_cpu_flags ( ) & mask ; },1
"static int decode_header_trees ( SmackVContext * smk ) { GetBitContext gb ; int mmap_size , mclr_size , full_size , type_size , ret ; mmap_size = AV_RL32 ( smk - > avctx - > extradata ) ; mclr_size = AV_RL32 ( smk - > avctx - > extradata + 4 ) ; full_size = AV_RL32 ( smk - > avctx - > extradata + 8 ) ; type_size = AV_RL32 ( smk - > avctx - > extradata + 12 ) ; init_get_bits8 ( & gb , smk - > avctx - > extradata + 16 , smk - > avctx - > extradata_size - 16 ) ; if ( ! get_bits1 ( & gb ) ) { av_log ( smk - > avctx , AV_LOG_INFO , Skipping MMAP tree\n ) ; smk - > mmap_tbl = av_malloc ( sizeof ( int ) * 2 ) ; if ( ! smk - > mmap_tbl ) return AVERROR ( ENOMEM ) ; smk - > mmap_tbl[0] = 0 ; smk - > mmap_last[0] = smk - > mmap_last[1] = smk - > mmap_last[2] = 1 ; } else { ret = smacker_decode_header_tree ( smk , & gb , & smk - > mmap_tbl , smk - > mmap_last , mmap_size ) ; if ( ret < 0 ) return ret ; } if ( ! get_bits1 ( & gb ) ) { av_log ( smk - > avctx , AV_LOG_INFO , Skipping MCLR tree\n ) ; smk - > mclr_tbl = av_malloc ( sizeof ( int ) * 2 ) ; if ( ! smk - > mclr_tbl ) return AVERROR ( ENOMEM ) ; smk - > mclr_tbl[0] = 0 ; smk - > mclr_last[0] = smk - > mclr_last[1] = smk - > mclr_last[2] = 1 ; } else { ret = smacker_decode_header_tree ( smk , & gb , & smk - > mclr_tbl , smk - > mclr_last , mclr_size ) ; if ( ret < 0 ) return ret ; } if ( ! get_bits1 ( & gb ) ) { av_log ( smk - > avctx , AV_LOG_INFO , Skipping FULL tree\n ) ; smk - > full_tbl = av_malloc ( sizeof ( int ) * 2 ) ; if ( ! smk - > full_tbl ) return AVERROR ( ENOMEM ) ; smk - > full_tbl[0] = 0 ; smk - > full_last[0] = smk - > full_last[1] = smk - > full_last[2] = 1 ; } else { ret = smacker_decode_header_tree ( smk , & gb , & smk - > full_tbl , smk - > full_last , full_size ) ; if ( ret < 0 ) return ret ; } if ( ! get_bits1 ( & gb ) ) { av_log ( smk - > avctx , AV_LOG_INFO , Skipping TYPE tree\n ) ; smk - > type_tbl = av_malloc ( sizeof ( int ) * 2 ) ; if ( ! smk - > type_tbl ) return AVERROR ( ENOMEM ) ; smk - > type_tbl[0] = 0 ; smk - > type_last[0] = smk - > type_last[1] = smk - > type_last[2] = 1 ; } else { ret = smacker_decode_header_tree ( smk , & gb , & smk - > type_tbl , smk - > type_last , type_size ) ; if ( ret < 0 ) return ret ; } return 0 ; }",1
"static int decode_init_thread_copy ( AVCodecContext * avctx ) { H264Context * h = avctx - > priv_data ; int ret ; if ( ! avctx - > internal - > is_copy ) return 0 ; memset ( h - > sps_buffers , 0 , sizeof ( h - > sps_buffers ) ) ; memset ( h - > pps_buffers , 0 , sizeof ( h - > pps_buffers ) ) ; ret = h264_init_context ( avctx , h ) ; if ( ret < 0 ) return ret ; h - > context_initialized = 0 ; return 0 ; }",0
"av_cold static int auto_matrix ( SwrContext * s ) { int i , j , out_i ; double matrix[64][64]= { { 0 } } ; int64_t unaccounted , in_ch_layout , out_ch_layout ; double maxcoef=0 ; char buf[128] ; const int matrix_encoding = s - > matrix_encoding ; float maxval ; in_ch_layout = clean_layout ( s , s - > in_ch_layout ) ; if ( ! sane_layout ( in_ch_layout ) ) { av_get_channel_layout_string ( buf , sizeof ( buf ) , - 1 , s - > in_ch_layout ) ; av_log ( s , AV_LOG_ERROR , Input channel layout ' %s ' is not supported\n , buf ) ; return AVERROR ( EINVAL ) ; } out_ch_layout = clean_layout ( s , s - > out_ch_layout ) ; if ( ! sane_layout ( out_ch_layout ) ) { av_get_channel_layout_string ( buf , sizeof ( buf ) , - 1 , s - > out_ch_layout ) ; av_log ( s , AV_LOG_ERROR , Output channel layout ' %s ' is not supported\n , buf ) ; return AVERROR ( EINVAL ) ; } memset ( s - > matrix , 0 , sizeof ( s - > matrix ) ) ; for ( i=0 ; i < 64 ; i + + ) { if ( in_ch_layout & out_ch_layout & ( 1ULL < < i ) ) matrix[i][i]= 1 . 0 ; } unaccounted= in_ch_layout & out_ch_layout ; //FIXME implement dolby surround //FIXME implement full ac3 if ( unaccounted & AV_CH_FRONT_CENTER ) { if ( ( out_ch_layout & AV_CH_LAYOUT_STEREO ) == AV_CH_LAYOUT_STEREO ) { if ( in_ch_layout & AV_CH_LAYOUT_STEREO ) { matrix[ FRONT_LEFT][FRONT_CENTER] + = s - > clev ; matrix[FRONT_RIGHT][FRONT_CENTER] + = s - > clev ; } else { matrix[ FRONT_LEFT][FRONT_CENTER] + = M_SQRT1_2 ; matrix[FRONT_RIGHT][FRONT_CENTER] + = M_SQRT1_2 ; } } else av_assert0 ( 0 ) ; } if ( unaccounted & AV_CH_LAYOUT_STEREO ) { if ( out_ch_layout & AV_CH_FRONT_CENTER ) { matrix[FRONT_CENTER][ FRONT_LEFT] + = M_SQRT1_2 ; matrix[FRONT_CENTER][FRONT_RIGHT] + = M_SQRT1_2 ; if ( in_ch_layout & AV_CH_FRONT_CENTER ) matrix[FRONT_CENTER][ FRONT_CENTER] = s - > clev * sqrt ( 2 ) ; } else av_assert0 ( 0 ) ; } if ( unaccounted & AV_CH_BACK_CENTER ) { if ( out_ch_layout & AV_CH_BACK_LEFT ) { matrix[ BACK_LEFT][BACK_CENTER] + = M_SQRT1_2 ; matrix[BACK_RIGHT][BACK_CENTER] + = M_SQRT1_2 ; } else if ( out_ch_layout & AV_CH_SIDE_LEFT ) { matrix[ SIDE_LEFT][BACK_CENTER] + = M_SQRT1_2 ; matrix[SIDE_RIGHT][BACK_CENTER] + = M_SQRT1_2 ; } else if ( out_ch_layout & AV_CH_FRONT_LEFT ) { if ( matrix_encoding == AV_MATRIX_ENCODING_DOLBY || matrix_encoding == AV_MATRIX_ENCODING_DPLII ) { if ( unaccounted & ( AV_CH_BACK_LEFT | AV_CH_SIDE_LEFT ) ) { matrix[FRONT_LEFT ][BACK_CENTER] - = s - > slev * M_SQRT1_2 ; matrix[FRONT_RIGHT][BACK_CENTER] + = s - > slev * M_SQRT1_2 ; } else { matrix[FRONT_LEFT ][BACK_CENTER] - = s - > slev ; matrix[FRONT_RIGHT][BACK_CENTER] + = s - > slev ; } } else { matrix[ FRONT_LEFT][BACK_CENTER] + = s - > slev * M_SQRT1_2 ; matrix[FRONT_RIGHT][BACK_CENTER] + = s - > slev * M_SQRT1_2 ; } } else if ( out_ch_layout & AV_CH_FRONT_CENTER ) { matrix[ FRONT_CENTER][BACK_CENTER] + = s - > slev * M_SQRT1_2 ; } else av_assert0 ( 0 ) ; } if ( unaccounted & AV_CH_BACK_LEFT ) { if ( out_ch_layout & AV_CH_BACK_CENTER ) { matrix[BACK_CENTER][ BACK_LEFT] + = M_SQRT1_2 ; matrix[BACK_CENTER][BACK_RIGHT] + = M_SQRT1_2 ; } else if ( out_ch_layout & AV_CH_SIDE_LEFT ) { if ( in_ch_layout & AV_CH_SIDE_LEFT ) { matrix[ SIDE_LEFT][ BACK_LEFT] + = M_SQRT1_2 ; matrix[SIDE_RIGHT][BACK_RIGHT] + = M_SQRT1_2 ; } else { matrix[ SIDE_LEFT][ BACK_LEFT] + = 1 . 0 ; matrix[SIDE_RIGHT][BACK_RIGHT] + = 1 . 0 ; } } else if ( out_ch_layout & AV_CH_FRONT_LEFT ) { if ( matrix_encoding == AV_MATRIX_ENCODING_DOLBY ) { matrix[FRONT_LEFT ][BACK_LEFT ] - = s - > slev * M_SQRT1_2 ; matrix[FRONT_LEFT ][BACK_RIGHT] - = s - > slev * M_SQRT1_2 ; matrix[FRONT_RIGHT][BACK_LEFT ] + = s - > slev * M_SQRT1_2 ; matrix[FRONT_RIGHT][BACK_RIGHT] + = s - > slev * M_SQRT1_2 ; } else if ( matrix_encoding == AV_MATRIX_ENCODING_DPLII ) { matrix[FRONT_LEFT ][BACK_LEFT ] - = s - > slev * SQRT3_2 ; matrix[FRONT_LEFT ][BACK_RIGHT] - = s - > slev * M_SQRT1_2 ; matrix[FRONT_RIGHT][BACK_LEFT ] + = s - > slev * M_SQRT1_2 ; matrix[FRONT_RIGHT][BACK_RIGHT] + = s - > slev * SQRT3_2 ; } else { matrix[ FRONT_LEFT][ BACK_LEFT] + = s - > slev ; matrix[FRONT_RIGHT][BACK_RIGHT] + = s - > slev ; } } else if ( out_ch_layout & AV_CH_FRONT_CENTER ) { matrix[ FRONT_CENTER][BACK_LEFT ] + = s - > slev * M_SQRT1_2 ; matrix[ FRONT_CENTER][BACK_RIGHT] + = s - > slev * M_SQRT1_2 ; } else av_assert0 ( 0 ) ; } if ( unaccounted & AV_CH_SIDE_LEFT ) { if ( out_ch_layout & AV_CH_BACK_LEFT ) { / * if back channels do not exist in the input , just copy side channels to back channels , otherwise mix side into back * / if ( in_ch_layout & AV_CH_BACK_LEFT ) { matrix[BACK_LEFT ][SIDE_LEFT ] + = M_SQRT1_2 ; matrix[BACK_RIGHT][SIDE_RIGHT] + = M_SQRT1_2 ; } else { matrix[BACK_LEFT ][SIDE_LEFT ] + = 1 . 0 ; matrix[BACK_RIGHT][SIDE_RIGHT] + = 1 . 0 ; } } else if ( out_ch_layout & AV_CH_BACK_CENTER ) { matrix[BACK_CENTER][ SIDE_LEFT] + = M_SQRT1_2 ; matrix[BACK_CENTER][SIDE_RIGHT] + = M_SQRT1_2 ; } else if ( out_ch_layout & AV_CH_FRONT_LEFT ) { if ( matrix_encoding == AV_MATRIX_ENCODING_DOLBY ) { matrix[FRONT_LEFT ][SIDE_LEFT ] - = s - > slev * M_SQRT1_2 ; matrix[FRONT_LEFT ][SIDE_RIGHT] - = s - > slev * M_SQRT1_2 ; matrix[FRONT_RIGHT][SIDE_LEFT ] + = s - > slev * M_SQRT1_2 ; matrix[FRONT_RIGHT][SIDE_RIGHT] + = s - > slev * M_SQRT1_2 ; } else if ( matrix_encoding == AV_MATRIX_ENCODING_DPLII ) { matrix[FRONT_LEFT ][SIDE_LEFT ] - = s - > slev * SQRT3_2 ; matrix[FRONT_LEFT ][SIDE_RIGHT] - = s - > slev * M_SQRT1_2 ; matrix[FRONT_RIGHT][SIDE_LEFT ] + = s - > slev * M_SQRT1_2 ; matrix[FRONT_RIGHT][SIDE_RIGHT] + = s - > slev * SQRT3_2 ; } else { matrix[ FRONT_LEFT][ SIDE_LEFT] + = s - > slev ; matrix[FRONT_RIGHT][SIDE_RIGHT] + = s - > slev ; } } else if ( out_ch_layout & AV_CH_FRONT_CENTER ) { matrix[ FRONT_CENTER][SIDE_LEFT ] + = s - > slev * M_SQRT1_2 ; matrix[ FRONT_CENTER][SIDE_RIGHT] + = s - > slev * M_SQRT1_2 ; } else av_assert0 ( 0 ) ; } if ( unaccounted & AV_CH_FRONT_LEFT_OF_CENTER ) { if ( out_ch_layout & AV_CH_FRONT_LEFT ) { matrix[ FRONT_LEFT][ FRONT_LEFT_OF_CENTER] + = 1 . 0 ; matrix[FRONT_RIGHT][FRONT_RIGHT_OF_CENTER] + = 1 . 0 ; } else if ( out_ch_layout & AV_CH_FRONT_CENTER ) { matrix[ FRONT_CENTER][ FRONT_LEFT_OF_CENTER] + = M_SQRT1_2 ; matrix[ FRONT_CENTER][FRONT_RIGHT_OF_CENTER] + = M_SQRT1_2 ; } else av_assert0 ( 0 ) ; } / * mix LFE into front left/right or center * / if ( unaccounted & AV_CH_LOW_FREQUENCY ) { if ( out_ch_layout & AV_CH_FRONT_CENTER ) { matrix[FRONT_CENTER][LOW_FREQUENCY] + = s - > lfe_mix_level ; } else if ( out_ch_layout & AV_CH_FRONT_LEFT ) { matrix[FRONT_LEFT ][LOW_FREQUENCY] + = s - > lfe_mix_level * M_SQRT1_2 ; matrix[FRONT_RIGHT][LOW_FREQUENCY] + = s - > lfe_mix_level * M_SQRT1_2 ; } else av_assert0 ( 0 ) ; } for ( out_i=i=0 ; i < 64 ; i + + ) { double sum=0",0
"static inline void RENAME ( rgb32tobgr16 ) ( const uint8_t * src , uint8_t * dst , int src_size ) { const uint8_t * s = src ; const uint8_t * end ; const uint8_t * mm_end ; uint16_t * d = ( uint16_t * ) dst ; end = s + src_size ; __asm__ volatile ( PREFETCH %0 : : m ( * src ) : memory ) ; __asm__ volatile ( movq %0 , %%mm7 \n\t movq %1 , %%mm6 \n\t : : m ( red_16mask ) , m ( green_16mask ) ) ; mm_end = end - 15 ; while ( s < mm_end ) { __asm__ volatile ( PREFETCH 32%1 \n\t movd %1 , %%mm0 \n\t movd 4%1 , %%mm3 \n\t punpckldq 8%1 , %%mm0 \n\t punpckldq 12%1 , %%mm3 \n\t movq %%mm0 , %%mm1 \n\t movq %%mm0 , %%mm2 \n\t movq %%mm3 , %%mm4 \n\t movq %%mm3 , %%mm5 \n\t psllq 8 , %%mm0 \n\t psllq 8 , %%mm3 \n\t pand %%mm7 , %%mm0 \n\t pand %%mm7 , %%mm3 \n\t psrlq 5 , %%mm1 \n\t psrlq 5 , %%mm4 \n\t pand %%mm6 , %%mm1 \n\t pand %%mm6 , %%mm4 \n\t psrlq 19 , %%mm2 \n\t psrlq 19 , %%mm5 \n\t pand %2 , %%mm2 \n\t pand %2 , %%mm5 \n\t por %%mm1 , %%mm0 \n\t por %%mm4 , %%mm3 \n\t por %%mm2 , %%mm0 \n\t por %%mm5 , %%mm3 \n\t psllq 16 , %%mm3 \n\t por %%mm3 , %%mm0 \n\t MOVNTQ %%mm0 , %0 \n\t : =m ( * d ) : m ( * s ) , m ( blue_16mask ) : memory ) ; d + = 4 ; s + = 16 ; } __asm__ volatile ( SFENCE : : : memory ) ; __asm__ volatile ( EMMS : : : memory ) ; while ( s < end ) { register int rgb = * ( const uint32_t * ) s ; s + = 4 ; * d + + = ( ( rgb & 0xF8 ) < < 8 ) + ( ( rgb & 0xFC00 ) > > 5 ) + ( ( rgb & 0xF80000 ) > > 19 ) ; } }",1
"static int decode_pic ( AVSContext * h ) { int ret ; int skip_count = - 1 ; enum cavs_mb mb_type ; if ( ! h - > top_qp ) { av_log ( h - > avctx , AV_LOG_ERROR , No sequence header decoded yet\n ) ; return AVERROR_INVALIDDATA ; } av_frame_unref ( h - > cur . f ) ; skip_bits ( & h - > gb , 16 ) ; //bbv_dwlay if ( h - > stc == PIC_PB_START_CODE ) { h - > cur . f - > pict_type = get_bits ( & h - > gb , 2 ) + AV_PICTURE_TYPE_I ; if ( h - > cur . f - > pict_type > AV_PICTURE_TYPE_B ) { av_log ( h - > avctx , AV_LOG_ERROR , illegal picture type\n ) ; return AVERROR_INVALIDDATA ; } / * make sure we have the reference frames we need * / if ( ! h - > DPB[0] . f - > data[0] || ( ! h - > DPB[1] . f - > data[0] & & h - > cur . f - > pict_type == AV_PICTURE_TYPE_B ) ) return AVERROR_INVALIDDATA ; } else { h - > cur . f - > pict_type = AV_PICTURE_TYPE_I ; if ( get_bits1 ( & h - > gb ) ) skip_bits ( & h - > gb , 24 ) ; //time_code / * old sample clips were all progressive and no low_delay , bump stream revision if detected otherwise * / if ( h - > low_delay || ! ( show_bits ( & h - > gb , 9 ) & 1 ) ) h - > stream_revision = 1 ; / * similarly test top_field_first and repeat_first_field * / else if ( show_bits ( & h - > gb , 11 ) & 3 ) h - > stream_revision = 1 ; if ( h - > stream_revision > 0 ) skip_bits ( & h - > gb , 1 ) ; //marker_bit } ret = ff_get_buffer ( h - > avctx , h - > cur . f , h - > cur . f - > pict_type == AV_PICTURE_TYPE_B ? 0 : AV_GET_BUFFER_FLAG_REF ) ; if ( ret < 0 ) return ret ; if ( ! h - > edge_emu_buffer ) { int alloc_size = FFALIGN ( FFABS ( h - > cur . f - > linesize[0] ) + 32 , 32 ) ; h - > edge_emu_buffer = av_mallocz ( alloc_size * 2 * 24 ) ; if ( ! h - > edge_emu_buffer ) return AVERROR ( ENOMEM ) ; } if ( ( ret = ff_cavs_init_pic ( h ) ) < 0 ) return ret ; h - > cur . poc = get_bits ( & h - > gb , 8 ) * 2 ; / * get temporal distances and MV scaling factors * / if ( h - > cur . f - > pict_type ! = AV_PICTURE_TYPE_B ) { h - > dist[0] = ( h - > cur . poc - h - > DPB[0] . poc ) & 511 ; } else { h - > dist[0] = ( h - > DPB[0] . poc - h - > cur . poc ) & 511 ; } h - > dist[1] = ( h - > cur . poc - h - > DPB[1] . poc ) & 511 ; h - > scale_den[0] = h - > dist[0] ? 512/h - > dist[0] : 0 ; h - > scale_den[1] = h - > dist[1] ? 512/h - > dist[1] : 0 ; if ( h - > cur . f - > pict_type == AV_PICTURE_TYPE_B ) { h - > sym_factor = h - > dist[0] * h - > scale_den[1] ; if ( FFABS ( h - > sym_factor ) > 32768 ) { av_log ( h - > avctx , AV_LOG_ERROR , sym_factor %d too large\n , h - > sym_factor ) ; return AVERROR_INVALIDDATA ; } } else { h - > direct_den[0] = h - > dist[0] ? 16384 / h - > dist[0] : 0 ; h - > direct_den[1] = h - > dist[1] ? 16384 / h - > dist[1] : 0 ; } if ( h - > low_delay ) get_ue_golomb ( & h - > gb ) ; //bbv_check_times h - > progressive = get_bits1 ( & h - > gb ) ; h - > pic_structure = 1 ; if ( ! h - > progressive ) h - > pic_structure = get_bits1 ( & h - > gb ) ; if ( ! h - > pic_structure & & h - > stc == PIC_PB_START_CODE ) skip_bits1 ( & h - > gb ) ; //advanced_pred_mode_disable skip_bits1 ( & h - > gb ) ; //top_field_first skip_bits1 ( & h - > gb ) ; //repeat_first_field h - > pic_qp_fixed = h - > qp_fixed = get_bits1 ( & h - > gb ) ; h - > qp = get_bits ( & h - > gb , 6 ) ; if ( h - > cur . f - > pict_type == AV_PICTURE_TYPE_I ) { if ( ! h - > progressive & & ! h - > pic_structure ) skip_bits1 ( & h - > gb ) ; //what is this ? skip_bits ( & h - > gb , 4 ) ; //reserved bits } else { if ( ! ( h - > cur . f - > pict_type == AV_PICTURE_TYPE_B & & h - > pic_structure == 1 ) ) h - > ref_flag = get_bits1 ( & h - > gb ) ; skip_bits ( & h - > gb , 4 ) ; //reserved bits h - > skip_mode_flag = get_bits1 ( & h - > gb ) ; } h - > loop_filter_disable = get_bits1 ( & h - > gb ) ; if ( ! h - > loop_filter_disable & & get_bits1 ( & h - > gb ) ) { h - > alpha_offset = get_se_golomb ( & h - > gb ) ; h - > beta_offset = get_se_golomb ( & h - > gb ) ; } else { h - > alpha_offset = h - > beta_offset = 0 ; } if ( h - > cur . f - > pict_type == AV_PICTURE_TYPE_I ) { do { check_for_slice ( h ) ; decode_mb_i ( h , 0 ) ; } while ( ff_cavs_next_mb ( h ) ) ; } else if ( h - > cur . f - > pict_type == AV_PICTURE_TYPE_P ) { do { if ( check_for_slice ( h ) ) skip_count = - 1 ; if ( h - > skip_mode_flag & & ( skip_count < 0 ) ) skip_count = get_ue_golomb ( & h - > gb ) ; if ( h - > skip_mode_flag & & skip_count - - ) { decode_mb_p ( h , P_SKIP ) ; } else { mb_type = get_ue_golomb ( & h - > gb ) + P_SKIP + h - > skip_mode_flag ; if ( mb_type",1
"static int decode_cell ( Indeo3DecodeContext * ctx , AVCodecContext * avctx , Plane * plane , Cell * cell , const uint8_t * data_ptr , const uint8_t * last_ptr ) { int x , mv_x , mv_y , mode , vq_index , prim_indx , second_indx ; int zoom_fac ; int offset , error = 0 , swap_quads[2] ; uint8_t code , * block , * ref_block = 0 ; const vqEntry * delta[2] ; const uint8_t * data_start = data_ptr ; / * get coding mode and VQ table index from the VQ descriptor byte * / code = * data_ptr + + ; mode = code > > 4 ; vq_index = code & 0xF ; / * setup output and reference pointers * / offset = ( cell - > ypos < < 2 ) * plane - > pitch + ( cell - > xpos < < 2 ) ; block = plane - > pixels[ctx - > buf_sel] + offset ; if ( ! cell - > mv_ptr ) { / * use previous line as reference for INTRA cells * / ref_block = block - plane - > pitch ; } else if ( mode > = 10 ) { / * for mode 10 and 11 INTER first copy the predicted cell into the current one * / / * so we don ' t need to do data copying for each RLE code later * / copy_cell ( ctx , plane , cell ) ; } else { / * set the pointer to the reference pixels for modes 0 - 4 INTER * / mv_y = cell - > mv_ptr[0] ; mv_x = cell - > mv_ptr[1] ; offset + = mv_y * plane - > pitch + mv_x ; ref_block = plane - > pixels[ctx - > buf_sel 1] + offset ; / * select VQ tables as follows : * / / * modes 0 and 3 use only the primary table for all lines in a block * / / * while modes 1 and 4 switch between primary and secondary tables on alternate lines * / if ( mode == 1 || mode == 4 ) { code = ctx - > alt_quant[vq_index] ; prim_indx = ( code > > 4 ) + ctx - > cb_offset ; second_indx = ( code & 0xF ) + ctx - > cb_offset ; } else { vq_index + = ctx - > cb_offset ; prim_indx = second_indx = vq_index ; if ( prim_indx > = 24 || second_indx > = 24 ) { av_log ( avctx , AV_LOG_ERROR , Invalid VQ table indexes ! Primary : %d , secondary : %d ! \n , prim_indx , second_indx ) ; delta[0] = & vq_tab[second_indx] ; delta[1] = & vq_tab[prim_indx] ; swap_quads[0] = second_indx > = 16 ; swap_quads[1] = prim_indx > = 16 ; / * requantize the prediction if VQ index of this cell differs from VQ index * / / * of the predicted cell in order to avoid overflows . * / if ( vq_index > = 8 & & ref_block ) { for ( x = 0 ; x < cell - > width < < 2 ; x + + ) ref_block[x] = requant_tab[vq_index & 7][ref_block[x]] ; error = IV3_NOERR ; switch ( mode ) { case 0 : / * - - - - - - - - - - - - - - - - - - MODES 0 & 1 ( 4x4 block processing ) - - - - - - - - - - - - - - - - - - - - * / case 1 : case 3 : / * - - - - - - - - - - - - - - - - - - MODES 3 & 4 ( 4x8 block processing ) - - - - - - - - - - - - - - - - - - - - * / case 4 : if ( mode > = 3 & & cell - > mv_ptr ) { av_log ( avctx , AV_LOG_ERROR , Attempt to apply Mode 3/4 to an INTER cell ! \n ) ; zoom_fac = mode > = 3 ; error = decode_cell_data ( cell , block , ref_block , plane - > pitch , 0 , zoom_fac , mode , delta , swap_quads , & data_ptr , last_ptr ) ; break ; case 10 : / * - - - - - - - - - - - - - - - - - - - - MODE 10 ( 8x8 block processing ) - - - - - - - - - - - - - - - - - - - - - * / case 11 : / * - - - - - - - - - - - - - - - - - MODE 11 ( 4x8 INTER block processing ) - - - - - - - - - - - - - - - - - - * / if ( mode == 10 & & ! cell - > mv_ptr ) { / * MODE 10 INTRA processing * / error = decode_cell_data ( cell , block , ref_block , plane - > pitch , 1 , 1 , mode , delta , swap_quads , & data_ptr , last_ptr ) ; } else { / * mode 10 and 11 INTER processing * / if ( mode == 11 & & ! cell - > mv_ptr ) { av_log ( avctx , AV_LOG_ERROR , Attempt to use Mode 11 for an INTRA cell ! \n ) ; zoom_fac = mode == 10 ; error = decode_cell_data ( cell , block , ref_block , plane - > pitch , zoom_fac , 1 , mode , delta , swap_quads , & data_ptr , last_ptr ) ; break ; default : av_log ( avctx , AV_LOG_ERROR , Unsupported coding mode : %d\n , mode ) ; } //switch mode switch ( error ) { case IV3_BAD_RLE : av_log ( avctx , AV_LOG_ERROR , Mode %d : RLE code %X is not allowed at the current line\n , mode , data_ptr[ - 1] ) ; case IV3_BAD_DATA : av_log ( avctx , AV_LOG_ERROR , Mode %d : invalid VQ data\n , mode ) ; case IV3_BAD_COUNTER : av_log ( avctx , AV_LOG_ERROR , Mode %d : RLE - FB invalid counter : %d\n , mode , code ) ; case IV3_UNSUPPORTED : av_log ( avctx , AV_LOG_ERROR , Mode %d : unsupported RLE code : %X\n , mode , data_ptr[ - 1] ) ; case IV3_OUT_OF_DATA : av_log ( avctx , AV_LOG_ERROR , Mode %d : attempt to read past end of buffer\n , mode ) ; return data_ptr - data_start ; / * report number of bytes consumed from the input buffer * /",1
"void ff_riff_write_info_tag ( AVIOContext * pb , const char * tag , const char * str ) { int len = strlen ( str ) ; if ( len > 0 ) { len + + ; ffio_wfourcc ( pb , tag ) ; avio_wl32 ( pb , len ) ; avio_put_str ( pb , str ) ; if ( len & 1 ) avio_w8 ( pb , 0 ) ; } }",1
"static int mjpegb_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; MJpegDecodeContext * s = avctx - > priv_data ; const uint8_t * buf_end , * buf_ptr ; GetBitContext hgb ; / * for the header * / uint32_t dqt_offs , dht_offs , sof_offs , sos_offs , second_field_offs ; uint32_t field_size , sod_offs ; int ret ; buf_ptr = buf ; buf_end = buf + buf_size ; s - > got_picture = 0 ; read_header : / * reset on every SOI * / s - > restart_interval = 0 ; s - > restart_count = 0 ; s - > mjpb_skiptosod = 0 ; if ( buf_end - buf_ptr > = 1 < < 28 ) return AVERROR_INVALIDDATA ; init_get_bits ( & hgb , buf_ptr , / * buf_size * / ( buf_end - buf_ptr ) * 8 ) ; skip_bits ( & hgb , 32 ) ; / * reserved zeros * / if ( get_bits_long ( & hgb , 32 ) ! = MKBETAG ( ' m ' , ' j ' , ' p ' , ' g ' ) ) { av_log ( avctx , AV_LOG_WARNING , not mjpeg - b ( bad fourcc ) \n ) ; return AVERROR_INVALIDDATA ; } field_size = get_bits_long ( & hgb , 32 ) ; / * field size * / av_log ( avctx , AV_LOG_DEBUG , field size : 0x%x\n , field_size ) ; skip_bits ( & hgb , 32 ) ; / * padded field size * / second_field_offs = read_offs ( avctx , & hgb , buf_end - buf_ptr , second_field_offs is %d and size is %d\n ) ; av_log ( avctx , AV_LOG_DEBUG , second field offs : 0x%x\n , second_field_offs ) ; dqt_offs = read_offs ( avctx , & hgb , buf_end - buf_ptr , dqt is %d and size is %d\n ) ; av_log ( avctx , AV_LOG_DEBUG , dqt offs : 0x%x\n , dqt_offs ) ; if ( dqt_offs ) { init_get_bits ( & s - > gb , buf_ptr + dqt_offs , ( buf_end - ( buf_ptr + dqt_offs ) ) * 8 ) ; s - > start_code = DQT ; if ( ff_mjpeg_decode_dqt ( s ) < 0 & & ( avctx - > err_recognition & AV_EF_EXPLODE ) ) return AVERROR_INVALIDDATA ; } dht_offs = read_offs ( avctx , & hgb , buf_end - buf_ptr , dht is %d and size is %d\n ) ; av_log ( avctx , AV_LOG_DEBUG , dht offs : 0x%x\n , dht_offs ) ; if ( dht_offs ) { init_get_bits ( & s - > gb , buf_ptr + dht_offs , ( buf_end - ( buf_ptr + dht_offs ) ) * 8 ) ; s - > start_code = DHT ; ff_mjpeg_decode_dht ( s ) ; } sof_offs = read_offs ( avctx , & hgb , buf_end - buf_ptr , sof is %d and size is %d\n ) ; av_log ( avctx , AV_LOG_DEBUG , sof offs : 0x%x\n , sof_offs ) ; if ( sof_offs ) { init_get_bits ( & s - > gb , buf_ptr + sof_offs , ( buf_end - ( buf_ptr + sof_offs ) ) * 8 ) ; s - > start_code = SOF0 ; if ( ff_mjpeg_decode_sof ( s ) < 0 ) return - 1 ; } sos_offs = read_offs ( avctx , & hgb , buf_end - buf_ptr , sos is %d and size is %d\n ) ; av_log ( avctx , AV_LOG_DEBUG , sos offs : 0x%x\n , sos_offs ) ; sod_offs = read_offs ( avctx , & hgb , buf_end - buf_ptr , sof is %d and size is %d\n ) ; av_log ( avctx , AV_LOG_DEBUG , sod offs : 0x%x\n , sod_offs ) ; if ( sos_offs ) { init_get_bits ( & s - > gb , buf_ptr + sos_offs , 8 * FFMIN ( field_size , buf_end - buf_ptr - sos_offs ) ) ; s - > mjpb_skiptosod = ( sod_offs - sos_offs - show_bits ( & s - > gb , 16 ) ) ; s - > start_code = SOS ; if ( ff_mjpeg_decode_sos ( s , NULL , NULL ) < 0 & & ( avctx - > err_recognition & AV_EF_EXPLODE ) ) return AVERROR_INVALIDDATA ; } if ( s - > interlaced ) { s - > bottom_field = 1 ; / * if not bottom field , do not output image yet * / if ( s - > bottom_field ! = s - > interlace_polarity & & second_field_offs ) { buf_ptr = buf + second_field_offs ; goto read_header ; } } //XXX FIXME factorize , this looks very similar to the EOI code if ( ! s - > got_picture ) { av_log ( avctx , AV_LOG_WARNING , no picture\n ) ; return buf_size ; } if ( ( ret = av_frame_ref ( data , s - > picture_ptr ) ) < 0 ) return ret ; * got_frame = 1 ; if ( ! s - > lossless & & avctx - > debug & FF_DEBUG_QP ) { av_log ( avctx , AV_LOG_DEBUG , QP : %d\n , FFMAX3 ( s - > qscale[0] , s - > qscale[1] , s - > qscale[2] ) ) ; } return buf_size ; }",1
"static int hqx_decode_frame ( AVCodecContext * avctx , void * data , int * got_picture_ptr , AVPacket * avpkt ) { HQXContext * ctx = avctx - > priv_data ; uint8_t * src = avpkt - > data ; uint32_t info_tag ; int data_start ; int i , ret ; if ( avpkt - > size < 4 + 4 ) { av_log ( avctx , AV_LOG_ERROR , Frame is too small %d . \n , avpkt - > size ) ; return AVERROR_INVALIDDATA ; } info_tag = AV_RL32 ( src ) ; if ( info_tag == MKTAG ( ' I ' , ' N ' , ' F ' , ' O ' ) ) { int info_offset = AV_RL32 ( src + 4 ) ; if ( info_offset > UINT32_MAX - 8 || info_offset + 8 > avpkt - > size ) { av_log ( avctx , AV_LOG_ERROR , Invalid INFO header offset : 0x%08 PRIX32 is too large . \n , info_offset ) ; return AVERROR_INVALIDDATA ; } ff_canopus_parse_info_tag ( avctx , src + 8 , info_offset ) ; info_offset + = 8 ; src + = info_offset ; } data_start = src - avpkt - > data ; ctx - > data_size = avpkt - > size - data_start ; ctx - > src = src ; ctx - > pic = data ; if ( ctx - > data_size < HQX_HEADER_SIZE ) { av_log ( avctx , AV_LOG_ERROR , Frame too small . \n ) ; return AVERROR_INVALIDDATA ; } if ( src[0] ! = ' H ' || src[1] ! = ' Q ' ) { av_log ( avctx , AV_LOG_ERROR , Not an HQX frame . \n ) ; return AVERROR_INVALIDDATA ; } ctx - > interlaced = ! ( src[2] & 0x80 ) ; ctx - > format = src[2] & 7 ; ctx - > dcb = ( src[3] & 3 ) + 8 ; ctx - > width = AV_RB16 ( src + 4 ) ; ctx - > height = AV_RB16 ( src + 6 ) ; for ( i = 0 ; i < 17 ; i + + ) ctx - > slice_off[i] = AV_RB24 ( src + 8 + i * 3 ) ; if ( ctx - > dcb == 8 ) { av_log ( avctx , AV_LOG_ERROR , Invalid DC precision %d . \n , ctx - > dcb ) ; return AVERROR_INVALIDDATA ; } ret = av_image_check_size ( ctx - > width , ctx - > height , 0 , avctx ) ; if ( ret < 0 ) { av_log ( avctx , AV_LOG_ERROR , Invalid stored dimenstions %dx%d . \n , ctx - > width , ctx - > height ) ; return AVERROR_INVALIDDATA ; } avctx - > coded_width = FFALIGN ( ctx - > width , 16 ) ; avctx - > coded_height = FFALIGN ( ctx - > height , 16 ) ; avctx - > width = ctx - > width ; avctx - > height = ctx - > height ; avctx - > bits_per_raw_sample = 10 ; switch ( ctx - > format ) { case HQX_422 : avctx - > pix_fmt = AV_PIX_FMT_YUV422P16 ; ctx - > decode_func = hqx_decode_422 ; break ; case HQX_444 : avctx - > pix_fmt = AV_PIX_FMT_YUV444P16 ; ctx - > decode_func = hqx_decode_444 ; break ; case HQX_422A : avctx - > pix_fmt = AV_PIX_FMT_YUVA422P16 ; ctx - > decode_func = hqx_decode_422a ; break ; case HQX_444A : avctx - > pix_fmt = AV_PIX_FMT_YUVA444P16 ; ctx - > decode_func = hqx_decode_444a ; break ; default : av_log ( avctx , AV_LOG_ERROR , Invalid format : %d . \n , ctx - > format ) ; return AVERROR_INVALIDDATA ; } ret = ff_get_buffer ( avctx , ctx - > pic , 0 ) ; if ( ret < 0 ) { av_log ( avctx , AV_LOG_ERROR , Could not allocate buffer . \n ) ; return ret ; } avctx - > execute2 ( avctx , decode_slice_thread , NULL , NULL , 16 ) ; ctx - > pic - > key_frame = 1 ; ctx - > pic - > pict_type = AV_PICTURE_TYPE_I ; * got_picture_ptr = 1 ; return avpkt - > size ; }",0
"static av_cold int vaapi_encode_mjpeg_init_internal ( AVCodecContext * avctx ) { static const VAConfigAttrib default_config_attributes[] = { { . type = VAConfigAttribRTFormat , . value = VA_RT_FORMAT_YUV420 } , { . type = VAConfigAttribEncPackedHeaders , . value = VA_ENC_PACKED_HEADER_SEQUENCE } , } ; VAAPIEncodeContext * ctx = avctx - > priv_data ; VAAPIEncodeMJPEGContext * priv = ctx - > priv_data ; int i ; ctx - > va_profile = VAProfileJPEGBaseline ; ctx - > va_entrypoint = VAEntrypointEncPicture ; ctx - > input_width = avctx - > width ; ctx - > input_height = avctx - > height ; ctx - > aligned_width = FFALIGN ( ctx - > input_width , 8 ) ; ctx - > aligned_height = FFALIGN ( ctx - > input_height , 8 ) ; for ( i = 0 ; i < FF_ARRAY_ELEMS ( default_config_attributes ) ; i + + ) { ctx - > config_attributes[ctx - > nb_config_attributes + + ] = default_config_attributes[i] ; } priv - > quality = avctx - > global_quality ; if ( priv - > quality < 1 || priv - > quality > 100 ) { av_log ( avctx , AV_LOG_ERROR , Invalid quality value %d ( must be 1 - 100 ) . \n , priv - > quality ) ; return AVERROR ( EINVAL ) ; } vaapi_encode_mjpeg_init_tables ( avctx ) ; return 0 ; }",0
"static int configure_input_audio_filter ( FilterGraph * fg , InputFilter * ifilter , AVFilterInOut * in ) { AVFilterContext * last_filter ; const AVFilter * abuffer_filt = avfilter_get_by_name ( abuffer ) ; InputStream * ist = ifilter - > ist ; InputFile * f = input_files[ist - > file_index] ; char args[255] , name[255] ; int ret , pad_idx = 0 ; snprintf ( args , sizeof ( args ) , time_base=%d/%d : sample_rate=%d : sample_fmt=%s : channel_layout=0x% PRIx64 , 1 , ist - > st - > codec - > sample_rate , ist - > st - > codec - > sample_rate , av_get_sample_fmt_name ( ist - > st - > codec - > sample_fmt ) , ist - > st - > codec - > channel_layout ) ; snprintf ( name , sizeof ( name ) , graph %d input from stream %d : %d , fg - > index , ist - > file_index , ist - > st - > index ) ; if ( ( ret = avfilter_graph_create_filter ( & ifilter - > filter , abuffer_filt , name , args , NULL , fg - > graph ) ) < 0 ) return ret ; last_filter = ifilter - > filter ; if ( audio_sync_method > 0 ) { AVFilterContext * async ; int len = 0 ; av_log ( NULL , AV_LOG_WARNING , - async has been deprecated . Used the asyncts audio filter instead . \n ) ; if ( audio_sync_method > 1 ) len + = snprintf ( args + len , sizeof ( args ) - len , compensate=1 : max_comp=%d : , audio_sync_method ) ; snprintf ( args + len , sizeof ( args ) - len , min_delta=%f , audio_drift_threshold ) ; snprintf ( name , sizeof ( name ) , graph %d audio sync for input stream %d : %d , fg - > index , ist - > file_index , ist - > st - > index ) ; ret = avfilter_graph_create_filter ( & async , avfilter_get_by_name ( asyncts ) , name , args , NULL , fg - > graph ) ; if ( ret < 0 ) return ret ; ret = avfilter_link ( last_filter , 0 , async , 0 ) ; if ( ret < 0 ) return ret ; last_filter = async ; } if ( audio_volume ! = 256 ) { AVFilterContext * volume ; av_log ( NULL , AV_LOG_WARNING , - vol has been deprecated . Use the volume audio filter instead . \n ) ; snprintf ( args , sizeof ( args ) , volume=%f , audio_volume / 256 . 0 ) ; snprintf ( name , sizeof ( name ) , graph %d volume for input stream %d : %d , fg - > index , ist - > file_index , ist - > st - > index ) ; ret = avfilter_graph_create_filter ( & volume , avfilter_get_by_name ( volume ) , name , args , NULL , fg - > graph ) ; if ( ret < 0 ) return ret ; ret = avfilter_link ( last_filter , 0 , volume , 0 ) ; if ( ret < 0 ) return ret ; last_filter = volume ; } snprintf ( name , sizeof ( name ) , trim for input stream %d : %d , ist - > file_index , ist - > st - > index ) ; ret = insert_trim ( ( ( f - > start_time == AV_NOPTS_VALUE ) || ! f - > accurate_seek ) ? AV_NOPTS_VALUE : 0 , INT64_MAX , & last_filter , & pad_idx , name ) ; if ( ret < 0 ) return ret ; if ( ( ret = avfilter_link ( last_filter , 0 , in - > filter_ctx , in - > pad_idx ) ) < 0 ) return ret ; return 0 ; }",0
"static int mpegts_write_packet_internal ( AVFormatContext * s , AVPacket * pkt ) { AVStream * st = s - > streams[pkt - > stream_index] ; int size = pkt - > size ; uint8_t * buf = pkt - > data ; uint8_t * data = NULL ; MpegTSWrite * ts = s - > priv_data ; MpegTSWriteStream * ts_st = st - > priv_data ; const uint64_t delay = av_rescale ( s - > max_delay , 90000 , AV_TIME_BASE ) * 2 ; int64_t dts = AV_NOPTS_VALUE , pts = AV_NOPTS_VALUE ; if ( ts - > reemit_pat_pmt ) { av_log ( s , AV_LOG_WARNING , resend_headers option is deprecated , use - mpegts_flags resend_headers\n ) ; ts - > reemit_pat_pmt = 0 ; ts - > flags |= MPEGTS_FLAG_REEMIT_PAT_PMT ; } if ( ts - > flags & MPEGTS_FLAG_REEMIT_PAT_PMT ) { ts - > pat_packet_count = ts - > pat_packet_period - 1 ; ts - > sdt_packet_count = ts - > sdt_packet_period - 1 ; ts - > flags & = MPEGTS_FLAG_REEMIT_PAT_PMT ; } if ( pkt - > pts ! = AV_NOPTS_VALUE ) pts = pkt - > pts + delay ; if ( pkt - > dts ! = AV_NOPTS_VALUE ) dts = pkt - > dts + delay ; if ( ts_st - > first_pts_check & & pts == AV_NOPTS_VALUE ) { av_log ( s , AV_LOG_ERROR , first pts value must set\n ) ; return AVERROR ( EINVAL ) ; } ts_st - > first_pts_check = 0 ; if ( st - > codec - > codec_id == AV_CODEC_ID_H264 ) { const uint8_t * p = buf , * buf_end = p + size ; uint32_t state = - 1 ; if ( pkt - > size < 5 || AV_RB32 ( pkt - > data ) ! = 0x0000001 ) { av_log ( s , AV_LOG_ERROR , H . 264 bitstream malformed , no startcode found , use - bsf h264_mp4toannexb\n ) ; return AVERROR ( EINVAL ) ; } do { p = avpriv_find_start_code ( p , buf_end , & state ) ; av_dlog ( s , nal %d\n , state & 0x1f ) ; } while ( p < buf_end & & ( state & 0x1f ) ! = 9 & & ( state & 0x1f ) ! = 5 & & ( state & 0x1f ) ! = 1 ) ; if ( ( state & 0x1f ) ! = 9 ) { // AUD NAL data = av_malloc ( pkt - > size + 6 ) ; if ( ! data ) return AVERROR ( ENOMEM ) ; memcpy ( data + 6 , pkt - > data , pkt - > size ) ; AV_WB32 ( data , 0x00000001 ) ; data[4] = 0x09 ; data[5] = 0xf0 ; // any slice type ( 0xe ) + rbsp stop one bit buf = data ; size = pkt - > size + 6 ; } } else if ( st - > codec - > codec_id == AV_CODEC_ID_AAC ) { if ( pkt - > size < 2 ) { av_log ( s , AV_LOG_ERROR , AAC packet too short\n ) ; return AVERROR ( EINVAL ) ; } if ( ( AV_RB16 ( pkt - > data ) & 0xfff0 ) ! = 0xfff0 ) { int ret ; AVPacket pkt2 ; if ( ! ts_st - > amux ) { av_log ( s , AV_LOG_ERROR , AAC bitstream not in ADTS format and extradata missing\n ) ; return AVERROR ( EINVAL ) ; } av_init_packet ( & pkt2 ) ; pkt2 . data = pkt - > data ; pkt2 . size = pkt - > size ; ret = avio_open_dyn_buf ( & ts_st - > amux - > pb ) ; if ( ret < 0 ) return AVERROR ( ENOMEM ) ; ret = av_write_frame ( ts_st - > amux , & pkt2 ) ; if ( ret < 0 ) { avio_close_dyn_buf ( ts_st - > amux - > pb , & data ) ; ts_st - > amux - > pb = NULL ; av_free ( data ) ; return ret ; } size = avio_close_dyn_buf ( ts_st - > amux - > pb , & data ) ; ts_st - > amux - > pb = NULL ; buf = data ; } } if ( st - > codec - > codec_type ! = AVMEDIA_TYPE_AUDIO ) { // for video and subtitle , write a single pes packet mpegts_write_pes ( s , st , buf , size , pts , dts , pkt - > flags & AV_PKT_FLAG_KEY ) ; av_free ( data ) ; return 0 ; } if ( ts_st - > payload_size + size > ts - > pes_payload_size ) { if ( ts_st - > payload_size ) { mpegts_write_pes ( s , st , ts_st - > payload , ts_st - > payload_size , ts_st - > payload_pts , ts_st - > payload_dts , ts_st - > payload_flags & AV_PKT_FLAG_KEY ) ; ts_st - > payload_size = 0 ; } if ( size > ts - > pes_payload_size ) { mpegts_write_pes ( s , st , buf , size , pts , dts , pkt - > flags & AV_PKT_FLAG_KEY ) ; av_free ( data ) ; return 0 ; } } if ( ! ts_st - > payload_size ) { ts_st - > payload_pts = pts ; ts_st - > payload_dts = dts ; ts_st - > payload_flags = pkt - > flags ; } memcpy ( ts_st - > payload + ts_st - > payload_size , buf , size ) ; ts_st - > payload_size + = size ; av_free ( data ) ; return 0 ; }",0
"static int dca_subsubframe ( DCAContext * s , int base_channel , int block_index ) { int k , l ; int subsubframe = s - > current_subsubframe ; const float * quant_step_table ; / * FIXME * / float ( * subband_samples ) [DCA_SUBBANDS][8] = s - > subband_samples[block_index] ; LOCAL_ALIGNED_16 ( int32_t , block , [8 * DCA_SUBBANDS] ) ; / * * Audio data * / / * Select quantization step size table * / if ( s - > bit_rate_index == 0x1f ) quant_step_table = lossless_quant_d ; else quant_step_table = lossy_quant_d ; for ( k = base_channel ; k < s - > prim_channels ; k + + ) { float rscale[DCA_SUBBANDS] ; if ( get_bits_left ( & s - > gb ) < 0 ) return AVERROR_INVALIDDATA ; for ( l = 0 ; l < s - > vq_start_subband[k] ; l + + ) { int m ; / * Select the mid - tread linear quantizer * / int abits = s - > bitalloc[k][l] ; float quant_step_size = quant_step_table[abits] ; / * * Determine quantization index code book and its type * / / * Select quantization index code book * / int sel = s - > quant_index_huffman[k][abits] ; / * * Extract bits from the bit stream * / if ( ! abits ) { rscale[l] = 0 ; memset ( block + 8 * l , 0 , 8 * sizeof ( block[0] ) ) ; } else { / * Deal with transients * / int sfi = s - > transition_mode[k][l] & & subsubframe > = s - > transition_mode[k][l] ; rscale[l] = quant_step_size * s - > scale_factor[k][l][sfi] * s - > scalefactor_adj[k][sel] ; if ( abits > = 11 || ! dca_smpl_bitalloc[abits] . vlc[sel] . table ) { if ( abits < = 7 ) { / * Block code * / int block_code1 , block_code2 , size , levels , err ; size = abits_sizes[abits - 1] ; levels = abits_levels[abits - 1] ; block_code1 = get_bits ( & s - > gb , size ) ; block_code2 = get_bits ( & s - > gb , size ) ; err = decode_blockcodes ( block_code1 , block_code2 , levels , block + 8 * l ) ; if ( err ) { av_log ( s - > avctx , AV_LOG_ERROR , ERROR : block code look - up failed\n ) ; return AVERROR_INVALIDDATA ; } } else { / * no coding * / for ( m = 0 ; m < 8 ; m + + ) block[8 * l + m] = get_sbits ( & s - > gb , abits - 3 ) ; } } else { / * Huffman coded * / for ( m = 0 ; m < 8 ; m + + ) block[8 * l + m] = get_bitalloc ( & s - > gb , & dca_smpl_bitalloc[abits] , sel ) ; } } } s - > fmt_conv . int32_to_float_fmul_array8 ( & s - > fmt_conv , subband_samples[k][0] , block , rscale , 8 * s - > vq_start_subband[k] ) ; for ( l = 0 ; l < s - > vq_start_subband[k] ; l + + ) { int m ; / * * Inverse ADPCM if in prediction mode * / if ( s - > prediction_mode[k][l] ) { int n ; if ( s - > predictor_history ) subband_samples[k][l][0] + = ( adpcm_vb[s - > prediction_vq[k][l]][0] * s - > subband_samples_hist[k][l][3] + adpcm_vb[s - > prediction_vq[k][l]][1] * s - > subband_samples_hist[k][l][2] + adpcm_vb[s - > prediction_vq[k][l]][2] * s - > subband_samples_hist[k][l][1] + adpcm_vb[s - > prediction_vq[k][l]][3] * s - > subband_samples_hist[k][l][0] ) * ( 1 . 0f / 8192 ) ; for ( m = 1 ; m < 8 ; m + + ) { float sum = adpcm_vb[s - > prediction_vq[k][l]][0] * subband_samples[k][l][m - 1] ; for ( n = 2 ; n < = 4 ; n + + ) if ( m > = n ) sum + = adpcm_vb[s - > prediction_vq[k][l]][n - 1] * subband_samples[k][l][m - n] ; else if ( s - > predictor_history ) sum + = adpcm_vb[s - > prediction_vq[k][l]][n - 1] * s - > subband_samples_hist[k][l][m - n + 4] ; subband_samples[k][l][m] + = sum * 1 . 0f / 8192 ; } } } / * * Decode VQ encoded high frequencies * / for ( l = s - > vq_start_subband[k] ; l < s - > subband_activity[k] ; l + + ) { / * 1 vector - > 32 samples but we only need the 8 samples * for this subsubframe . * / int hfvq = s - > high_freq_vq[k][l] ; if ( ! s - > debug_flag & 0x01 ) { av_log ( s - > avctx , AV_LOG_DEBUG , Stream with high frequencies VQ coding\n ) ; s - > debug_flag |= 0x01 ; } int8x8_fmul_int32 ( & s - > dcadsp , subband_samples[k][l] , & high_freq_vq[hfvq][subsubframe * 8] , s - > scale_factor[k][l][0] ) ; } } / * Check for DSYNC after subsubframe * / if ( s - > aspf || subsubframe == s - > subsubframes[s - > current_subframe] - 1 ) { if ( 0xFFFF == get_bits ( & s - > gb , 16 ) ) { / * 0xFFFF * / ifdef TRACE av_log ( s - > avctx , AV_LOG_DEBUG , Got subframe DSYNC\n ) ; endif } else { av_log ( s - > avctx , AV_LOG_ERROR , Didn ' t get subframe DSYNC\n ) ; return AVERROR_INVALIDDATA ; } } / * Backup predictor history for adpcm * / for ( k = base_channel ; k < s - > prim_channels ; k + + ) for ( l = 0 ; l < s - > vq_start_subband[k] ; l + + ) AV_COPY128 ( s - > subband_samples_hist[k][l] , & subband_samples[k][l][4] ) ; return 0 ; }",0
"int ff_mpeg_update_thread_context ( AVCodecContext * dst , const AVCodecContext * src ) { int i ; MpegEncContext * s = dst - > priv_data , * s1 = src - > priv_data ; if ( dst == src ) return 0 ; // FIXME can parameters change on I - frames ? // in that case dst may need a reinit if ( ! s - > context_initialized ) { memcpy ( s , s1 , sizeof ( MpegEncContext ) ) ; s - > avctx = dst ; s - > bitstream_buffer = NULL ; s - > bitstream_buffer_size = s - > allocated_bitstream_buffer_size = 0 ; if ( s1 - > context_initialized ) { s - > picture_range_start + = MAX_PICTURE_COUNT ; s - > picture_range_end + = MAX_PICTURE_COUNT ; ff_MPV_common_init ( s ) ; } } if ( s - > height ! = s1 - > height || s - > width ! = s1 - > width || s - > context_reinit ) { int err ; s - > context_reinit = 0 ; s - > height = s1 - > height ; s - > width = s1 - > width ; if ( ( err = ff_MPV_common_frame_size_change ( s ) ) < 0 ) return err ; } s - > avctx - > coded_height = s1 - > avctx - > coded_height ; s - > avctx - > coded_width = s1 - > avctx - > coded_width ; s - > avctx - > width = s1 - > avctx - > width ; s - > avctx - > height = s1 - > avctx - > height ; s - > coded_picture_number = s1 - > coded_picture_number ; s - > picture_number = s1 - > picture_number ; s - > input_picture_number = s1 - > input_picture_number ; memcpy ( s - > picture , s1 - > picture , s1 - > picture_count * sizeof ( Picture ) ) ; memcpy ( & s - > last_picture , & s1 - > last_picture , ( char * ) & s1 - > last_picture_ptr - ( char * ) & s1 - > last_picture ) ; // reset s - > picture[] . f . extended_data to s - > picture[] . f . data for ( i = 0 ; i < s - > picture_count ; i + + ) s - > picture[i] . f . extended_data = s - > picture[i] . f . data ; s - > last_picture_ptr = REBASE_PICTURE ( s1 - > last_picture_ptr , s , s1 ) ; s - > current_picture_ptr = REBASE_PICTURE ( s1 - > current_picture_ptr , s , s1 ) ; s - > next_picture_ptr = REBASE_PICTURE ( s1 - > next_picture_ptr , s , s1 ) ; // Error/bug resilience s - > next_p_frame_damaged = s1 - > next_p_frame_damaged ; s - > workaround_bugs = s1 - > workaround_bugs ; s - > padding_bug_score = s1 - > padding_bug_score ; // MPEG4 timing info memcpy ( & s - > time_increment_bits , & s1 - > time_increment_bits , ( char * ) & s1 - > shape - ( char * ) & s1 - > time_increment_bits ) ; // B - frame info s - > max_b_frames = s1 - > max_b_frames ; s - > low_delay = s1 - > low_delay ; s - > dropable = s1 - > dropable ; // DivX handling ( doesn ' t work ) s - > divx_packed = s1 - > divx_packed ; if ( s1 - > bitstream_buffer ) { if ( s1 - > bitstream_buffer_size + FF_INPUT_BUFFER_PADDING_SIZE > s - > allocated_bitstream_buffer_size ) av_fast_malloc ( & s - > bitstream_buffer , & s - > allocated_bitstream_buffer_size , s1 - > allocated_bitstream_buffer_size ) ; s - > bitstream_buffer_size = s1 - > bitstream_buffer_size ; memcpy ( s - > bitstream_buffer , s1 - > bitstream_buffer , s1 - > bitstream_buffer_size ) ; memset ( s - > bitstream_buffer + s - > bitstream_buffer_size , 0 , FF_INPUT_BUFFER_PADDING_SIZE ) ; } // MPEG2/interlacing info memcpy ( & s - > progressive_sequence , & s1 - > progressive_sequence , ( char * ) & s1 - > rtp_mode - ( char * ) & s1 - > progressive_sequence ) ; if ( ! s1 - > first_field ) { s - > last_pict_type = s1 - > pict_type ; if ( s1 - > current_picture_ptr ) s - > last_lambda_for[s1 - > pict_type] = s1 - > current_picture_ptr - > f . quality ; if ( s1 - > pict_type ! = AV_PICTURE_TYPE_B ) { s - > last_non_b_pict_type = s1 - > pict_type ; } } return 0 ; }",0
static int h261_probe ( AVProbeData * p ) { int code ; const uint8_t * d ; if ( p - > buf_size < 6 ) return 0 ; d = p - > buf ; code = ( d[0] < < 12 ) | ( d[1] < < 4 ) | ( d[2] > > 4 ) ; if ( code == 0x10 ) { return 50 ; } return 0 ; },0
"static int mov_read_wfex ( MOVContext * c , AVIOContext * pb , MOVAtom atom ) { AVStream * st ; if ( c - > fc - > nb_streams < 1 ) return 0 ; st = c - > fc - > streams[c - > fc - > nb_streams - 1] ; ff_get_wav_header ( pb , st - > codec , atom . size ) ; return 0 ; }",0
"static int pcm_bluray_parse_header ( AVCodecContext * avctx , const uint8_t * header ) { static const uint8_t bits_per_samples[4] = { 0 , 16 , 20 , 24 } ; static const uint32_t channel_layouts[16] = { 0 , AV_CH_LAYOUT_MONO , 0 , AV_CH_LAYOUT_STEREO , AV_CH_LAYOUT_SURROUND , AV_CH_LAYOUT_2_1 , AV_CH_LAYOUT_4POINT0 , AV_CH_LAYOUT_2_2 , AV_CH_LAYOUT_5POINT0 , AV_CH_LAYOUT_5POINT1 , AV_CH_LAYOUT_7POINT0 , AV_CH_LAYOUT_7POINT1 , 0 , 0 , 0 , 0 } ; static const uint8_t channels[16] = { 0 , 1 , 0 , 2 , 3 , 3 , 4 , 4 , 5 , 6 , 7 , 8 , 0 , 0 , 0 , 0 } ; uint8_t channel_layout = header[2] > > 4 ; if ( avctx - > debug & FF_DEBUG_PICT_INFO ) av_dlog ( avctx , pcm_bluray_parse_header : header = %02x%02x%02x%02x\n , header[0] , header[1] , header[2] , header[3] ) ; / * get the sample depth and derive the sample format from it * / avctx - > bits_per_coded_sample = bits_per_samples[header[3] > > 6] ; if ( ! avctx - > bits_per_coded_sample ) { av_log ( avctx , AV_LOG_ERROR , unsupported sample depth ( 0 ) \n ) ; return - 1 ; } avctx - > sample_fmt = avctx - > bits_per_coded_sample == 16 ? AV_SAMPLE_FMT_S16 : AV_SAMPLE_FMT_S32 ; if ( avctx - > sample_fmt == AV_SAMPLE_FMT_S32 ) avctx - > bits_per_raw_sample = avctx - > bits_per_coded_sample ; / * get the sample rate . Not all values are known or exist . * / switch ( header[2] & 0x0f ) { case 1 : avctx - > sample_rate = 48000 ; break ; case 4 : avctx - > sample_rate = 96000 ; break ; case 5 : avctx - > sample_rate = 192000 ; break ; default : avctx - > sample_rate = 0 ; av_log ( avctx , AV_LOG_ERROR , unsupported sample rate ( %d ) \n , header[2] & 0x0f ) ; return - 1 ; } / * * get the channel number ( and mapping ) . Not all values are known or exist . * It must be noted that the number of channels in the MPEG stream can * differ from the actual meaningful number , e . g . mono audio still has two * channels , one being empty . * / avctx - > channel_layout = channel_layouts[channel_layout] ; avctx - > channels = channels[channel_layout] ; if ( ! avctx - > channels ) { av_log ( avctx , AV_LOG_ERROR , unsupported channel configuration ( %d ) \n , channel_layout ) ; return - 1 ; } avctx - > bit_rate = avctx - > channels * avctx - > sample_rate * avctx - > bits_per_coded_sample ; if ( avctx - > debug & FF_DEBUG_PICT_INFO ) av_dlog ( avctx , pcm_bluray_parse_header : %d channels , %d bits per sample , %d kHz , %d kbit\n , avctx - > channels , avctx - > bits_per_coded_sample , avctx - > sample_rate , avctx - > bit_rate ) ; return 0 ; }",0
"int ff_dxva2_commit_buffer ( AVCodecContext * avctx , AVDXVAContext * ctx , DECODER_BUFFER_DESC * dsc , unsigned type , const void * data , unsigned size , unsigned mb_count ) { void * dxva_data ; unsigned dxva_size ; int result ; HRESULT hr ; if CONFIG_D3D11VA if ( avctx - > pix_fmt == AV_PIX_FMT_D3D11VA_VLD ) hr = ID3D11VideoContext_GetDecoderBuffer ( D3D11VA_CONTEXT ( ctx ) - > video_context , D3D11VA_CONTEXT ( ctx ) - > decoder , type , & dxva_size , & dxva_data ) ; endif if CONFIG_DXVA2 if ( avctx - > pix_fmt == AV_PIX_FMT_DXVA2_VLD ) hr = IDirectXVideoDecoder_GetBuffer ( DXVA2_CONTEXT ( ctx ) - > decoder , type , & dxva_data , & dxva_size ) ; endif if ( FAILED ( hr ) ) { av_log ( avctx , AV_LOG_ERROR , Failed to get a buffer for %u : 0x%lx\n , type , hr ) ; return - 1 ; } if ( size < = dxva_size ) { memcpy ( dxva_data , data , size ) ; if CONFIG_D3D11VA if ( avctx - > pix_fmt == AV_PIX_FMT_D3D11VA_VLD ) { D3D11_VIDEO_DECODER_BUFFER_DESC * dsc11 = dsc ; memset ( dsc11 , 0 , sizeof ( * dsc11 ) ) ; dsc11 - > BufferType = type ; dsc11 - > DataSize = size ; dsc11 - > NumMBsInBuffer = mb_count ; } endif if CONFIG_DXVA2 if ( avctx - > pix_fmt == AV_PIX_FMT_DXVA2_VLD ) { DXVA2_DecodeBufferDesc * dsc2 = dsc ; memset ( dsc2 , 0 , sizeof ( * dsc2 ) ) ; dsc2 - > CompressedBufferType = type ; dsc2 - > DataSize = size ; dsc2 - > NumMBsInBuffer = mb_count ; } endif result = 0 ; } else { av_log ( avctx , AV_LOG_ERROR , Buffer for type %u was too small\n , type ) ; result = - 1 ; } if CONFIG_D3D11VA if ( avctx - > pix_fmt == AV_PIX_FMT_D3D11VA_VLD ) hr = ID3D11VideoContext_ReleaseDecoderBuffer ( D3D11VA_CONTEXT ( ctx ) - > video_context , D3D11VA_CONTEXT ( ctx ) - > decoder , type ) ; endif if CONFIG_DXVA2 if ( avctx - > pix_fmt == AV_PIX_FMT_DXVA2_VLD ) hr = IDirectXVideoDecoder_ReleaseBuffer ( DXVA2_CONTEXT ( ctx ) - > decoder , type ) ; endif if ( FAILED ( hr ) ) { av_log ( avctx , AV_LOG_ERROR , Failed to release buffer type %u : 0x%lx\n , type , hr ) ; result = - 1 ; } return result ; }",1
"static void new_video_stream ( AVFormatContext * oc , int file_idx ) { AVStream * st ; AVOutputStream * ost ; AVCodecContext * video_enc ; enum CodecID codec_id ; AVCodec * codec= NULL ; st = av_new_stream ( oc , oc - > nb_streams < nb_streamid_map ? streamid_map[oc - > nb_streams] : 0 ) ; if ( ! st ) { fprintf ( stderr , Could not alloc stream\n ) ; ffmpeg_exit ( 1 ) ; } ost = new_output_stream ( oc , file_idx ) ; output_codecs = grow_array ( output_codecs , sizeof ( * output_codecs ) , & nb_output_codecs , nb_output_codecs + 1 ) ; if ( ! video_stream_copy ) { if ( video_codec_name ) { codec_id = find_codec_or_die ( video_codec_name , AVMEDIA_TYPE_VIDEO , 1 , avcodec_opts[AVMEDIA_TYPE_VIDEO] - > strict_std_compliance ) ; codec = avcodec_find_encoder_by_name ( video_codec_name ) ; output_codecs[nb_output_codecs - 1] = codec ; } else { codec_id = av_guess_codec ( oc - > oformat , NULL , oc - > filename , NULL , AVMEDIA_TYPE_VIDEO ) ; codec = avcodec_find_encoder ( codec_id ) ; } } avcodec_get_context_defaults3 ( st - > codec , codec ) ; ost - > bitstream_filters = video_bitstream_filters ; video_bitstream_filters= NULL ; avcodec_thread_init ( st - > codec , thread_count ) ; video_enc = st - > codec ; if ( video_codec_tag ) video_enc - > codec_tag= video_codec_tag ; if ( ( video_global_header & 1 ) || ( video_global_header==0 & & ( oc - > oformat - > flags & AVFMT_GLOBALHEADER ) ) ) { video_enc - > flags |= CODEC_FLAG_GLOBAL_HEADER ; avcodec_opts[AVMEDIA_TYPE_VIDEO] - > flags|= CODEC_FLAG_GLOBAL_HEADER ; } if ( video_global_header & 2 ) { video_enc - > flags2 |= CODEC_FLAG2_LOCAL_HEADER ; avcodec_opts[AVMEDIA_TYPE_VIDEO] - > flags2|= CODEC_FLAG2_LOCAL_HEADER ; } if ( video_stream_copy ) { st - > stream_copy = 1 ; video_enc - > codec_type = AVMEDIA_TYPE_VIDEO ; video_enc - > sample_aspect_ratio = st - > sample_aspect_ratio = av_d2q ( frame_aspect_ratio * frame_height/frame_width , 255 ) ; } else { const char * p ; int i ; AVRational fps= frame_rate . num ? frame_rate : ( AVRational ) { 25 , 1 } ; video_enc - > codec_id = codec_id ; set_context_opts ( video_enc , avcodec_opts[AVMEDIA_TYPE_VIDEO] , AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM , codec ) ; if ( codec & & codec - > supported_framerates & & ! force_fps ) fps = codec - > supported_framerates[av_find_nearest_q_idx ( fps , codec - > supported_framerates ) ] ; video_enc - > time_base . den = fps . num ; video_enc - > time_base . num = fps . den ; video_enc - > width = frame_width ; video_enc - > height = frame_height ; video_enc - > sample_aspect_ratio = av_d2q ( frame_aspect_ratio * video_enc - > height/video_enc - > width , 255 ) ; video_enc - > pix_fmt = frame_pix_fmt ; st - > sample_aspect_ratio = video_enc - > sample_aspect_ratio ; choose_pixel_fmt ( st , codec ) ; if ( intra_only ) video_enc - > gop_size = 0 ; if ( video_qscale || same_quality ) { video_enc - > flags |= CODEC_FLAG_QSCALE ; video_enc - > global_quality= st - > quality = FF_QP2LAMBDA * video_qscale ; } if ( intra_matrix ) video_enc - > intra_matrix = intra_matrix ; if ( inter_matrix ) video_enc - > inter_matrix = inter_matrix ; p= video_rc_override_string ; for ( i=0 ; p ; i + + ) { int start , end , q ; int e=sscanf ( p , %d , %d , %d , & start , & end , & q ) ; if ( e ! =3 ) { fprintf ( stderr , error parsing rc_override\n ) ; ffmpeg_exit ( 1 ) ; } video_enc - > rc_override= av_realloc ( video_enc - > rc_override , sizeof ( RcOverride ) * ( i + 1 ) ) ; video_enc - > rc_override[i] . start_frame= start ; video_enc - > rc_override[i] . end_frame = end ; if ( q > 0 ) { video_enc - > rc_override[i] . qscale= q ; video_enc - > rc_override[i] . quality_factor= 1 . 0 ; } else { video_enc - > rc_override[i] . qscale= 0 ; video_enc - > rc_override[i] . quality_factor= - q/100 . 0 ; } p= strchr ( p , ' / ' ) ; if ( p ) p + + ; } video_enc - > rc_override_count=i ; if ( ! video_enc - > rc_initial_buffer_occupancy ) video_enc - > rc_initial_buffer_occupancy = video_enc - > rc_buffer_size * 3/4 ; video_enc - > me_threshold= me_threshold ; video_enc - > intra_dc_precision= intra_dc_precision - 8 ; if ( do_psnr ) video_enc - > flags|= CODEC_FLAG_PSNR ; / * two pass mode * / if ( do_pass ) { if ( do_pass == 1 ) { video_enc - > flags |= CODEC_FLAG_PASS1 ; } else { video_enc - > flags |= CODEC_FLAG_PASS2 ; } } if ( forced_key_frames ) parse_forced_key_frames ( forced_key_frames , ost , video_enc ) ; } if ( video_language ) { av_metadata_set2 ( & st - > metadata , language , video_language , 0 ) ; av_freep ( & video_language ) ; } / * reset some key parameters * / video_disable = 0 ; av_freep ( & video_codec_name ) ; av_freep ( & forced_key_frames ) ; video_stream_copy = 0 ; frame_pix_fmt = PIX_FMT_NONE ; }",1
"static int alac_decode_frame ( AVCodecContext * avctx , void * outbuffer , int * outputsize , uint8_t * inbuffer , int input_buffer_size ) { ALACContext * alac = avctx - > priv_data ; int channels ; int32_t outputsamples ; / * short - circuit null buffers * / if ( ! inbuffer || ! input_buffer_size ) return input_buffer_size ; / * initialize from the extradata * / if ( ! alac - > context_initialized ) { if ( alac - > avctx - > extradata_size ! = ALAC_EXTRADATA_SIZE ) { av_log ( avctx , AV_LOG_ERROR , alac : expected %d extradata bytes\n , ALAC_EXTRADATA_SIZE ) ; return input_buffer_size ; } alac_set_info ( alac ) ; alac - > context_initialized = 1 ; } outputsamples = alac - > setinfo_max_samples_per_frame ; init_get_bits ( & alac - > gb , inbuffer , input_buffer_size * 8 ) ; channels = get_bits ( & alac - > gb , 3 ) ; * outputsize = outputsamples * alac - > bytespersample ; switch ( channels ) { case 0 : { / * 1 channel * / int hassize ; int isnotcompressed ; int readsamplesize ; int wasted_bytes ; int ricemodifier ; / * 2 result = something to do with output waiting . * perhaps matters if we read > 1 frame in a pass ? * / get_bits ( & alac - > gb , 4 ) ; get_bits ( & alac - > gb , 12 ) ; / * unknown , skip 12 bits * / hassize = get_bits ( & alac - > gb , 1 ) ; / * the output sample size is stored soon * / wasted_bytes = get_bits ( & alac - > gb , 2 ) ; / * unknown ? * / isnotcompressed = get_bits ( & alac - > gb , 1 ) ; / * whether the frame is compressed * / if ( hassize ) { / * now read the number of samples , * as a 32bit integer * / outputsamples = get_bits ( & alac - > gb , 32 ) ; * outputsize = outputsamples * alac - > bytespersample ; } readsamplesize = alac - > setinfo_sample_size - ( wasted_bytes * 8 ) ; if ( ! isnotcompressed ) { / * so it is compressed * / int16_t predictor_coef_table[32] ; int predictor_coef_num ; int prediction_type ; int prediction_quantitization ; int i ; / * FIXME : skip 16 bits , not sure what they are . seem to be used in * two channel case * / get_bits ( & alac - > gb , 8 ) ; get_bits ( & alac - > gb , 8 ) ; prediction_type = get_bits ( & alac - > gb , 4 ) ; prediction_quantitization = get_bits ( & alac - > gb , 4 ) ; ricemodifier = get_bits ( & alac - > gb , 3 ) ; predictor_coef_num = get_bits ( & alac - > gb , 5 ) ; / * read the predictor table * / for ( i = 0 ; i < predictor_coef_num ; i + + ) { predictor_coef_table[i] = ( int16_t ) get_bits ( & alac - > gb , 16 ) ; } if ( wasted_bytes ) { / * these bytes seem to have something to do with * > 2 channel files . * / av_log ( avctx , AV_LOG_ERROR , FIXME : unimplemented , unhandling of wasted_bytes\n ) ; } bastardized_rice_decompress ( alac , alac - > predicterror_buffer_a , outputsamples , readsamplesize , alac - > setinfo_rice_initialhistory , alac - > setinfo_rice_kmodifier , ricemodifier * alac - > setinfo_rice_historymult / 4 , ( 1 < < alac - > setinfo_rice_kmodifier ) - 1 ) ; if ( prediction_type == 0 ) { / * adaptive fir * / predictor_decompress_fir_adapt ( alac - > predicterror_buffer_a , alac - > outputsamples_buffer_a , outputsamples , readsamplesize , predictor_coef_table , predictor_coef_num , prediction_quantitization ) ; } else { av_log ( avctx , AV_LOG_ERROR , FIXME : unhandled prediction type : %i\n , prediction_type ) ; / * i think the only other prediction type ( or perhaps this is just a * boolean ? ) runs adaptive fir twice . . like : * predictor_decompress_fir_adapt ( predictor_error , tempout , . . . ) * predictor_decompress_fir_adapt ( predictor_error , outputsamples . . . ) * little strange . . * / } } else { / * not compressed , easy case * / if ( readsamplesize < = 16 ) { int i ; for ( i = 0 ; i < outputsamples ; i + + ) { int32_t audiobits = get_bits ( & alac - > gb , readsamplesize ) ; audiobits = SIGN_EXTENDED32 ( audiobits , readsamplesize ) ; alac - > outputsamples_buffer_a[i] = audiobits ; } } else { int i ; for ( i = 0 ; i < outputsamples ; i + + ) { int32_t audiobits ; audiobits = get_bits ( & alac - > gb , 16 ) ; / * special case of sign extension . . * as we ' ll be ORing the low 16bits into this * / audiobits = audiobits < < 16 ; audiobits = audiobits > > ( 32 - readsamplesize ) ; audiobits |= get_bits ( & alac - > gb , readsamplesize - 16 ) ; alac - > outputsamples_buffer_a[i] = audiobits ; } } / * wasted_bytes = 0 ; // unused * / } switch ( alac - > setinfo_sample_size ) { case 16 : { int i ; for ( i = 0 ; i < outputsamples ; i + + ) { int16_t sample = alac - > outputsamples_buffer_a[i] ; ( ( int16_t * ) outbuffer ) [i * alac - > numchannels] = sample ; } break ; } case 20 : case 24 : case 32 : av_log ( avctx , AV_LOG_ERROR , FIXME : unimplemented sample size %i\n , alac - > setinfo_sample_size ) ; break ; default : break ; } break ; } case 1 : { / * 2 channels * / int hassize ; int isnotcompressed ; int readsamplesize ; int wasted_bytes ; uint8_t interlacing_shift ; uint8_t interlacing_leftweight ; / * 2 result = something to do with output waiting . * perhaps matters if we read > 1 frame in a pass ? * / get_bits ( & alac - > gb , 4 ) ; get_bits ( & alac - > gb , 12 ) ; / * unknown , skip 12 bits * / hassize = get_bits ( & alac - > gb , 1 ) ; / * the output sample size is stored soon * / wasted_bytes = get_bits ( & alac - > gb , 2 ) ; / * unknown ? * / isnotcompressed = get_bits ( & alac - > gb , 1 ) ; / * whether the frame is compressed * / if ( hassize ) { / * now read the number of samples , * as a 32bit integer * / outputsamples = get_bits ( &",1
"static int add_doubles_metadata ( int count , const char * name , const char * sep , TiffContext * s ) { char * ap ; int i ; double * dp ; if ( bytestream2_get_bytes_left ( & s - > gb ) < count * sizeof ( int64_t ) ) return - 1 ; dp = av_malloc ( count * sizeof ( double ) ) ; if ( ! dp ) return AVERROR ( ENOMEM ) ; for ( i = 0 ; i < count ; i + + ) dp[i] = tget_double ( & s - > gb , s - > le ) ; ap = doubles2str ( dp , count , sep ) ; av_freep ( & dp ) ; if ( ! ap ) return AVERROR ( ENOMEM ) ; av_dict_set ( & s - > picture . metadata , name , ap , AV_DICT_DONT_STRDUP_VAL ) ; return 0 ; }",0
"static int decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; C93DecoderContext * const c93 = avctx - > priv_data ; AVFrame * const newpic = & c93 - > pictures[c93 - > currentpic] ; AVFrame * const oldpic = & c93 - > pictures[c93 - > currentpic 1] ; AVFrame * picture = data ; uint8_t * out ; int stride , i , x , y , bt = 0 ; c93 - > currentpic = 1 ; newpic - > reference = 1 ; newpic - > buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE | FF_BUFFER_HINTS_READABLE ; if ( avctx - > reget_buffer ( avctx , newpic ) ) { av_log ( avctx , AV_LOG_ERROR , reget_buffer ( ) failed\n ) ; return - 1 ; } stride = newpic - > linesize[0] ; if ( buf[0] & C93_FIRST_FRAME ) { newpic - > pict_type = AV_PICTURE_TYPE_I ; newpic - > key_frame = 1 ; } else { newpic - > pict_type = AV_PICTURE_TYPE_P ; newpic - > key_frame = 0 ; } if ( * buf + + & C93_HAS_PALETTE ) { uint32_t * palette = ( uint32_t * ) newpic - > data[1] ; const uint8_t * palbuf = buf + buf_size - 768 - 1 ; for ( i = 0 ; i < 256 ; i + + ) { palette[i] = bytestream_get_be24 ( & palbuf ) ; } } else { if ( oldpic - > data[1] ) memcpy ( newpic - > data[1] , oldpic - > data[1] , 256 * 4 ) ; } for ( y = 0 ; y < HEIGHT ; y + = 8 ) { out = newpic - > data[0] + y * stride ; for ( x = 0 ; x < WIDTH ; x + = 8 ) { uint8_t * copy_from = oldpic - > data[0] ; unsigned int offset , j ; uint8_t cols[4] , grps[4] ; C93BlockType block_type ; if ( ! bt ) bt = * buf + + ; block_type= bt & 0x0F ; switch ( block_type ) { case C93_8X8_FROM_PREV : offset = bytestream_get_le16 ( & buf ) ; if ( copy_block ( avctx , out , copy_from , offset , 8 , stride ) ) return - 1 ; break ; case C93_4X4_FROM_CURR : copy_from = newpic - > data[0] ; case C93_4X4_FROM_PREV : for ( j = 0 ; j < 8 ; j + = 4 ) { for ( i = 0 ; i < 8 ; i + = 4 ) { offset = bytestream_get_le16 ( & buf ) ; if ( copy_block ( avctx , & out[j * stride + i] , copy_from , offset , 4 , stride ) ) return - 1 ; } } break ; case C93_8X8_2COLOR : bytestream_get_buffer ( & buf , cols , 2 ) ; for ( i = 0 ; i < 8 ; i + + ) { draw_n_color ( out + i * stride , stride , 8 , 1 , 1 , cols , NULL , * buf + + ) ; } break ; case C93_4X4_2COLOR : case C93_4X4_4COLOR : case C93_4X4_4COLOR_GRP : for ( j = 0 ; j < 8 ; j + = 4 ) { for ( i = 0 ; i < 8 ; i + = 4 ) { if ( block_type == C93_4X4_2COLOR ) { bytestream_get_buffer ( & buf , cols , 2 ) ; draw_n_color ( out + i + j * stride , stride , 4 , 4 , 1 , cols , NULL , bytestream_get_le16 ( & buf ) ) ; } else if ( block_type == C93_4X4_4COLOR ) { bytestream_get_buffer ( & buf , cols , 4 ) ; draw_n_color ( out + i + j * stride , stride , 4 , 4 , 2 , cols , NULL , bytestream_get_le32 ( & buf ) ) ; } else { bytestream_get_buffer ( & buf , grps , 4 ) ; draw_n_color ( out + i + j * stride , stride , 4 , 4 , 1 , cols , grps , bytestream_get_le16 ( & buf ) ) ; } } } break ; case C93_NOOP : break ; case C93_8X8_INTRA : for ( j = 0 ; j < 8 ; j + + ) bytestream_get_buffer ( & buf , out + j * stride , 8 ) ; break ; default : av_log ( avctx , AV_LOG_ERROR , unexpected type %x at %dx%d\n , block_type , x , y ) ; return - 1 ; } bt > > = 4 ; out + = 8 ; } } * picture = * newpic ; * data_size = sizeof ( AVFrame ) ; return buf_size ; }",1
"static int filter_frame ( AVFilterLink * inlink , AVFilterBufferRef * in ) { HQDN3DContext * hqdn3d = inlink - > dst - > priv ; AVFilterLink * outlink = inlink - > dst - > outputs[0] ; AVFilterBufferRef * out ; int direct , c ; if ( in - > perms & AV_PERM_WRITE ) { direct = 1 ; out = in ; } else { out = ff_get_video_buffer ( outlink , AV_PERM_WRITE , outlink - > w , outlink - > h ) ; if ( ! out ) { avfilter_unref_bufferp ( & in ) ; return AVERROR ( ENOMEM ) ; } avfilter_copy_buffer_ref_props ( out , in ) ; out - > video - > w = outlink - > w ; out - > video - > h = outlink - > h ; } for ( c = 0 ; c < 3 ; c + + ) { denoise ( hqdn3d , in - > data[c] , out - > data[c] , hqdn3d - > line , & hqdn3d - > frame_prev[c] , in - > video - > w > > ( ! ! c * hqdn3d - > hsub ) , in - > video - > h > > ( ! ! c * hqdn3d - > vsub ) , in - > linesize[c] , out - > linesize[c] , hqdn3d - > coefs[c ? 2 : 0] , hqdn3d - > coefs[c ? 3 : 1] ) ; } if ( ! direct ) avfilter_unref_bufferp ( & in ) ; return ff_filter_frame ( outlink , out ) ; }",1
"static int encode_block ( SVQ1EncContext * s , uint8_t * src , uint8_t * ref , uint8_t * decoded , int stride , int level , int threshold , int lambda , int intra ) { int count , y , x , i , j , split , best_mean , best_score , best_count ; int best_vector[6] ; int block_sum[7] = { 0 , 0 , 0 , 0 , 0 , 0 } ; int w = 2 < < ( level + 2 > > 1 ) ; int h = 2 < < ( level + 1 > > 1 ) ; int size = w * h ; int16_t ( * block ) [256] = s - > encoded_block_levels[level] ; const int8_t * codebook_sum , * codebook ; const uint16_t ( * mean_vlc ) [2] ; const uint8_t ( * multistage_vlc ) [2] ; best_score = 0 ; // FIXME : Optimize , this does not need to be done multiple times . if ( intra ) { codebook_sum = svq1_intra_codebook_sum[level] ; codebook = ff_svq1_intra_codebooks[level] ; mean_vlc = ff_svq1_intra_mean_vlc ; multistage_vlc = ff_svq1_intra_multistage_vlc[level] ; for ( y = 0 ; y < h ; y + + ) { for ( x = 0 ; x < w ; x + + ) { int v = src[x + y * stride] ; block[0][x + w * y] = v ; best_score + = v * v ; block_sum[0] + = v ; } } } else { codebook_sum = svq1_inter_codebook_sum[level] ; codebook = ff_svq1_inter_codebooks[level] ; mean_vlc = ff_svq1_inter_mean_vlc + 256 ; multistage_vlc = ff_svq1_inter_multistage_vlc[level] ; for ( y = 0 ; y < h ; y + + ) { for ( x = 0 ; x < w ; x + + ) { int v = src[x + y * stride] - ref[x + y * stride] ; block[0][x + w * y] = v ; best_score + = v * v ; block_sum[0] + = v ; } } } best_count = 0 ; best_score - = ( int ) ( ( unsigned ) block_sum[0] * block_sum[0] > > ( level + 3 ) ) ; best_mean = block_sum[0] + ( size > > 1 ) > > ( level + 3 ) ; if ( level < 4 ) { for ( count = 1 ; count < 7 ; count + + ) { int best_vector_score = INT_MAX ; int best_vector_sum = - 999 , best_vector_mean = - 999 ; const int stage = count - 1 ; const int8_t * vector ; for ( i = 0 ; i < 16 ; i + + ) { int sum = codebook_sum[stage * 16 + i] ; int sqr , diff , score ; vector = codebook + stage * size * 16 + i * size ; sqr = s - > ssd_int8_vs_int16 ( vector , block[stage] , size ) ; diff = block_sum[stage] - sum ; score = sqr - ( diff * ( int64_t ) diff > > ( level + 3 ) ) ; // FIXME : 64bit slooow if ( score < best_vector_score ) { int mean = diff + ( size > > 1 ) > > ( level + 3 ) ; av_assert2 ( mean > - 300 & & mean < 300 ) ; mean = av_clip ( mean , intra ? 0 : - 256 , 255 ) ; best_vector_score = score ; best_vector[stage] = i ; best_vector_sum = sum ; best_vector_mean = mean ; } } av_assert0 ( best_vector_mean ! = - 999 ) ; vector = codebook + stage * size * 16 + best_vector[stage] * size ; for ( j = 0 ; j < size ; j + + ) block[stage + 1][j] = block[stage][j] - vector[j] ; block_sum[stage + 1] = block_sum[stage] - best_vector_sum ; best_vector_score + = lambda * ( + 1 + 4 * count + multistage_vlc[1 + count][1] + mean_vlc[best_vector_mean][1] ) ; if ( best_vector_score < best_score ) { best_score = best_vector_score ; best_count = count ; best_mean = best_vector_mean ; } } } split = 0 ; if ( best_score > threshold & & level ) { int score = 0 ; int offset = level & 1 ? stride * h / 2 : w / 2 ; PutBitContext backup[6] ; for ( i = level - 1 ; i > = 0 ; i - - ) backup[i] = s - > reorder_pb[i] ; score + = encode_block ( s , src , ref , decoded , stride , level - 1 , threshold > > 1 , lambda , intra ) ; score + = encode_block ( s , src + offset , ref + offset , decoded + offset , stride , level - 1 , threshold > > 1 , lambda , intra ) ; score + = lambda ; if ( score < best_score ) { best_score = score ; split = 1 ; } else { for ( i = level - 1 ; i > = 0 ; i - - ) s - > reorder_pb[i] = backup[i] ; } } if ( level > 0 ) put_bits ( & s - > reorder_pb[level] , 1 , split ) ; if ( ! split ) { av_assert1 ( best_mean > = 0 & & best_mean < 256 || ! intra ) ; av_assert1 ( best_mean > = - 256 & & best_mean < 256 ) ; av_assert1 ( best_count > = 0 & & best_count < 7 ) ; av_assert1 ( level < 4 || best_count == 0 ) ; / * output the encoding * / put_bits ( & s - > reorder_pb[level] , multistage_vlc[1 + best_count][1] , multistage_vlc[1 + best_count][0] ) ; put_bits ( & s - > reorder_pb[level] , mean_vlc[best_mean][1] , mean_vlc[best_mean][0] ) ; for ( i = 0 ; i < best_count ; i + + ) { av_assert2 ( best_vector[i] > = 0 & & best_vector[i] < 16 ) ; put_bits ( & s - > reorder_pb[level] , 4 , best_vector[i] ) ; } for ( y = 0 ; y < h ; y + + ) for ( x = 0 ; x < w ; x + + ) decoded[x + y * stride] = src[x + y * stride] - block[best_count][x + w * y] + best_mean ; } return best_score ; }",1
"static inline CopyRet copy_frame ( AVCodecContext * avctx , BC_DTS_PROC_OUT * output , void * data , int * data_size ) { BC_STATUS ret ; BC_DTS_STATUS decoder_status = { 0 , } ; uint8_t trust_interlaced ; uint8_t interlaced ; CHDContext * priv = avctx - > priv_data ; int64_t pkt_pts = AV_NOPTS_VALUE ; uint8_t pic_type = 0 ; uint8_t bottom_field = ( output - > PicInfo . flags & VDEC_FLAG_BOTTOMFIELD ) == VDEC_FLAG_BOTTOMFIELD ; uint8_t bottom_first = ! ! ( output - > PicInfo . flags & VDEC_FLAG_BOTTOM_FIRST ) ; int width = output - > PicInfo . width ; int height = output - > PicInfo . height ; int bwidth ; uint8_t * src = output - > Ybuff ; int sStride ; uint8_t * dst ; int dStride ; if ( output - > PicInfo . timeStamp ! = 0 ) { OpaqueList * node = opaque_list_pop ( priv , output - > PicInfo . timeStamp ) ; if ( node ) { pkt_pts = node - > reordered_opaque ; pic_type = node - > pic_type ; av_free ( node ) ; } else { / * * We will encounter a situation where a timestamp cannot be * popped if a second field is being returned . In this case , * each field has the same timestamp and the first one will * cause it to be popped . To keep subsequent calculations * simple , pic_type should be set a FIELD value - doesn ' t * matter which , but I chose BOTTOM . * / pic_type = PICT_BOTTOM_FIELD ; } av_log ( avctx , AV_LOG_VERBOSE , output \ pts\ : % PRIu64 \n , output - > PicInfo . timeStamp ) ; av_log ( avctx , AV_LOG_VERBOSE , output picture type %d\n , pic_type ) ; } ret = DtsGetDriverStatus ( priv - > dev , & decoder_status ) ; if ( ret ! = BC_STS_SUCCESS ) { av_log ( avctx , AV_LOG_ERROR , CrystalHD : GetDriverStatus failed : %u\n , ret ) ; return RET_ERROR ; } / * * For most content , we can trust the interlaced flag returned * by the hardware , but sometimes we can ' t . These are the * conditions under which we can trust the flag : * * 1 ) It ' s not h . 264 content * 2 ) The UNKNOWN_SRC flag is not set * 3 ) We know we ' re expecting a second field * 4 ) The hardware reports this picture and the next picture * have the same picture number . * * Note that there can still be interlaced content that will * fail this check , if the hardware hasn ' t decoded the next * picture or if there is a corruption in the stream . ( In either * case a 0 will be returned for the next picture number ) * / trust_interlaced = avctx - > codec - > id ! = CODEC_ID_H264 || ! ( output - > PicInfo . flags & VDEC_FLAG_UNKNOWN_SRC ) || priv - > need_second_field || ( decoder_status . picNumFlags & 0x40000000 ) == output - > PicInfo . picture_number ; / * * If we got a false negative for trust_interlaced on the first field , * we will realise our mistake here when we see that the picture number is that * of the previous picture . We cannot recover the frame and should discard the * second field to keep the correct number of output frames . * / if ( output - > PicInfo . picture_number == priv - > last_picture & & ! priv - > need_second_field ) { av_log ( avctx , AV_LOG_WARNING , Incorrectly guessed progressive frame . Discarding second field\n ) ; / * Returning without providing a picture . * / return RET_OK ; } interlaced = ( output - > PicInfo . flags & VDEC_FLAG_INTERLACED_SRC ) & & trust_interlaced ; if ( ! trust_interlaced & & ( decoder_status . picNumFlags & 0x40000000 ) == 0 ) { av_log ( avctx , AV_LOG_VERBOSE , Next picture number unknown . Assuming progressive frame . \n ) ; } av_log ( avctx , AV_LOG_VERBOSE , Interlaced state : %d | trust_interlaced %d\n , interlaced , trust_interlaced ) ; if ( priv - > pic . data[0] & & ! priv - > need_second_field ) avctx - > release_buffer ( avctx , & priv - > pic ) ; priv - > need_second_field = interlaced & & ! priv - > need_second_field ; priv - > pic . buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE ; if ( ! priv - > pic . data[0] ) { if ( avctx - > get_buffer ( avctx , & priv - > pic ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed\n ) ; return RET_ERROR ; } } bwidth = av_image_get_linesize ( avctx - > pix_fmt , width , 0 ) ; if ( priv - > is_70012 ) { int pStride ; if ( width < = 720 ) pStride = 720 ; else if ( width < = 1280 ) pStride = 1280 ; else pStride = 1920 ; sStride = av_image_get_linesize ( avctx - > pix_fmt , pStride , 0 ) ; } else { sStride = bwidth ; } dStride = priv - > pic . linesize[0] ; dst = priv - > pic . data[0] ; av_log ( priv - > avctx , AV_LOG_VERBOSE , CrystalHD : Copying out frame\n ) ; if ( interlaced ) { int dY = 0 ; int sY = 0 ; height /= 2 ; if ( bottom_field ) { av_log ( priv - > avctx , AV_LOG_VERBOSE , Interlaced : bottom field\n ) ; dY = 1 ; } else { av_log ( priv - > avctx , AV_LOG_VERBOSE , Interlaced : top field\n ) ; dY = 0 ; } for ( sY = 0 ; sY < height ; dY + + , sY + + ) { memcpy ( & ( dst[dY * dStride] ) , & ( src[sY * sStride] ) , bwidth ) ; dY + + ; } } else { av_image_copy_plane ( dst , dStride , src , sStride , bwidth , height ) ; } priv - > pic . interlaced_frame = interlaced ; if ( interlaced ) priv - > pic . top_field_first = ! bottom_first ; priv - > pic . pkt_pts = pkt_pts ; if ( ! priv - > need_second_field ) { * data_size = sizeof ( AVFrame ) ; * ( AVFrame * ) data = priv - > pic ; } / * * Two types of PAFF content have been observed . One form causes the * hardware to return a field pair and the other individual fields , * even though the input is always individual fields . We must skip * copying on the next decode ( ) call to maintain pipeline length in * the first case . * / if ( ! interlaced & & ( output - > PicInfo .",0
"static inline void RENAME ( hyscale_fast ) ( SwsContext * c , int16_t * dst , int dstWidth , const uint8_t * src , int srcW , int xInc ) { if ARCH_X86 if COMPILE_TEMPLATE_MMX2 int32_t * filterPos = c - > hLumFilterPos ; int16_t * filter = c - > hLumFilter ; int canMMX2BeUsed = c - > canMMX2BeUsed ; void * mmx2FilterCode= c - > lumMmx2FilterCode ; int i ; if defined ( PIC ) DECLARE_ALIGNED ( 8 , uint64_t , ebxsave ) ; endif if ( canMMX2BeUsed ) { __asm__ volatile ( if defined ( PIC ) mov %% REG_b , %5 \n\t endif pxor %%mm7 , %%mm7 \n\t mov %0 , %% REG_c \n\t mov %1 , %% REG_D \n\t mov %2 , %% REG_d \n\t mov %3 , %% REG_b \n\t xor %% REG_a , %% REG_a \n\t // i PREFETCH ( %% REG_c ) \n\t PREFETCH 32 ( %% REG_c ) \n\t PREFETCH 64 ( %% REG_c ) \n\t if ARCH_X86_64 define CALL_MMX2_FILTER_CODE \ movl ( %% REG_b ) , %%esi \n\t \ call * %4 \n\t \ movl ( %% REG_b , %% REG_a ) , %%esi \n\t \ add %% REG_S , %% REG_c \n\t \ add %% REG_a , %% REG_D \n\t \ xor %% REG_a , %% REG_a \n\t \ else define CALL_MMX2_FILTER_CODE \ movl ( %% REG_b ) , %%esi \n\t \ call * %4 \n\t \ addl ( %% REG_b , %% REG_a ) , %% REG_c \n\t \ add %% REG_a , %% REG_D \n\t \ xor %% REG_a , %% REG_a \n\t \ endif / * ARCH_X86_64 * / CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE if defined ( PIC ) mov %5 , %% REG_b \n\t endif : : m ( src ) , m ( dst ) , m ( filter ) , m ( filterPos ) , m ( mmx2FilterCode ) if defined ( PIC ) , m ( ebxsave ) endif : % REG_a , % REG_c , % REG_d , % REG_S , % REG_D if ! defined ( PIC ) , % REG_b endif ) ; for ( i=dstWidth - 1 ; ( i * xInc ) > > 16 > =srcW - 1 ; i - - ) dst[i] = src[srcW - 1] * 128 ; } else { endif / * COMPILE_TEMPLATE_MMX2 * / x86_reg dstWidth_reg = dstWidth ; x86_reg xInc_shr16 = xInc > > 16 ; uint16_t xInc_mask = xInc & 0xffff ; //NO MMX just normal asm . . . __asm__ volatile ( xor %% REG_a , %% REG_a \n\t // i xor %% REG_d , %% REG_d \n\t // xx xorl %%ecx , %%ecx \n\t // xalpha ASMALIGN ( 4 ) 1 : \n\t movzbl ( %0 , %% REG_d ) , %%edi \n\t //src[xx] movzbl 1 ( %0 , %% REG_d ) , %%esi \n\t //src[xx + 1] FAST_BILINEAR_X86 movw %%si , ( %% REG_D , %% REG_a , 2 ) \n\t addw %4 , %%cx \n\t //xalpha + = xInc & 0xFFFF adc %3 , %% REG_d \n\t //xx + = xInc > > 16 + carry movzbl ( %0 , %% REG_d ) , %%edi \n\t //src[xx] movzbl 1 ( %0 , %% REG_d ) , %%esi \n\t //src[xx + 1] FAST_BILINEAR_X86 movw %%si , 2 ( %% REG_D , %% REG_a , 2 ) \n\t addw %4 , %%cx \n\t //xalpha + = xInc & 0xFFFF adc %3 , %% REG_d \n\t //xx + = xInc > > 16 + carry add 2 , %% REG_a \n\t cmp %2 , %% REG_a \n\t jb 1b \n\t : : r ( src ) , m ( dst ) , m ( dstWidth_reg ) , m ( xInc_shr16 ) , m ( xInc_mask ) : % REG_a , % REG_d , %ecx , % REG_D , %esi ) ; if COMPILE_TEMPLATE_MMX2 } //if MMX2 can ' t be used endif else int i ; unsigned int xpos=0 ; for ( i=0 ; i < dstWidth ; i + + ) { register unsigned int xx=xpos > > 16 ; register unsigned int xalpha= ( xpos & 0xFFFF ) > > 9 ; dst[i]= ( src[xx] < < 7 ) + ( src[xx + 1] - src[xx] ) * xalpha ; xpos + =xInc ; } endif / * ARCH_X86 * / }",1
"static int decrypt_init ( AVFormatContext * s , ID3v2ExtraMeta * em , uint8_t * header ) { OMAContext * oc = s - > priv_data ; ID3v2ExtraMetaGEOB * geob = NULL ; uint8_t * gdata ; oc - > encrypted = 1 ; av_log ( s , AV_LOG_INFO , File is encrypted\n ) ; / * find GEOB metadata * / while ( em ) { if ( ! strcmp ( em - > tag , GEOB ) & & ( geob = em - > data ) & & ( ! strcmp ( geob - > description , OMG_LSI ) || ! strcmp ( geob - > description , OMG_BKLSI ) ) ) { break ; } em = em - > next ; } if ( ! em ) { av_log ( s , AV_LOG_ERROR , No encryption header found\n ) ; return AVERROR_INVALIDDATA ; } if ( geob - > datasize < 64 ) { av_log ( s , AV_LOG_ERROR , Invalid GEOB data size : %u\n , geob - > datasize ) ; return AVERROR_INVALIDDATA ; } gdata = geob - > data ; if ( AV_RB16 ( gdata ) ! = 1 ) av_log ( s , AV_LOG_WARNING , Unknown version in encryption header\n ) ; oc - > k_size = AV_RB16 ( & gdata[2] ) ; oc - > e_size = AV_RB16 ( & gdata[4] ) ; oc - > i_size = AV_RB16 ( & gdata[6] ) ; oc - > s_size = AV_RB16 ( & gdata[8] ) ; if ( memcmp ( & gdata[OMA_ENC_HEADER_SIZE] , KEYRING , 12 ) ) { av_log ( s , AV_LOG_ERROR , Invalid encryption header\n ) ; return AVERROR_INVALIDDATA ; } oc - > rid = AV_RB32 ( & gdata[OMA_ENC_HEADER_SIZE + 28] ) ; av_log ( s , AV_LOG_DEBUG , RID : % . 8x\n , oc - > rid ) ; memcpy ( oc - > iv , & header[0x58] , 8 ) ; hex_log ( s , AV_LOG_DEBUG , IV , oc - > iv , 8 ) ; hex_log ( s , AV_LOG_DEBUG , CBC - MAC , & gdata[OMA_ENC_HEADER_SIZE + oc - > k_size + oc - > e_size + oc - > i_size] , 8 ) ; if ( s - > keylen > 0 ) { kset ( s , s - > key , s - > key , s - > keylen ) ; } if ( ! memcmp ( oc - > r_val , ( const uint8_t[8] ) { 0 } , 8 ) || rprobe ( s , gdata , oc - > r_val ) < 0 & & nprobe ( s , gdata , geob - > datasize , oc - > n_val ) < 0 ) { int i ; for ( i = 0 ; i < FF_ARRAY_ELEMS ( leaf_table ) ; i + = 2 ) { uint8_t buf[16] ; AV_WL64 ( buf , leaf_table[i] ) ; AV_WL64 ( & buf[8] , leaf_table[i + 1] ) ; kset ( s , buf , buf , 16 ) ; if ( ! rprobe ( s , gdata , oc - > r_val ) || ! nprobe ( s , gdata , geob - > datasize , oc - > n_val ) ) break ; } if ( i > = sizeof ( leaf_table ) ) { av_log ( s , AV_LOG_ERROR , Invalid key\n ) ; return AVERROR_INVALIDDATA ; } } / * e_val * / av_des_init ( & oc - > av_des , oc - > m_val , 64 , 0 ) ; av_des_crypt ( & oc - > av_des , oc - > e_val , & gdata[OMA_ENC_HEADER_SIZE + 40] , 1 , NULL , 0 ) ; hex_log ( s , AV_LOG_DEBUG , EK , oc - > e_val , 8 ) ; / * init e_val * / av_des_init ( & oc - > av_des , oc - > e_val , 64 , 1 ) ; return 0 ; }",1
"static int tta_read_header ( AVFormatContext * s , AVFormatParameters * ap ) { TTAContext * c = s - > priv_data ; AVStream * st ; int i , channels , bps , samplerate , datalen , framelen , start ; start = url_ftell ( & s - > pb ) ; if ( get_le32 ( & s - > pb ) ! = ff_get_fourcc ( TTA1 ) ) return - 1 ; // not tta file url_fskip ( & s - > pb , 2 ) ; // FIXME : flags channels = get_le16 ( & s - > pb ) ; bps = get_le16 ( & s - > pb ) ; samplerate = get_le32 ( & s - > pb ) ; datalen = get_le32 ( & s - > pb ) ; url_fskip ( & s - > pb , 4 ) ; // header crc framelen = 1 . 04489795918367346939 * samplerate ; c - > totalframes = datalen / framelen + ( ( datalen % framelen ) ? 1 : 0 ) ; c - > currentframe = 0 ; c - > seektable = av_mallocz ( sizeof ( uint32_t ) * c - > totalframes ) ; if ( ! c - > seektable ) return AVERROR_NOMEM ; for ( i = 0 ; i < c - > totalframes ; i + + ) c - > seektable[i] = get_le32 ( & s - > pb ) ; url_fskip ( & s - > pb , 4 ) ; // seektable crc st = av_new_stream ( s , 0 ) ; // av_set_pts_info ( st , 32 , 1 , 1000 ) ; if ( ! st ) return AVERROR_NOMEM ; st - > codec - > codec_type = CODEC_TYPE_AUDIO ; st - > codec - > codec_id = CODEC_ID_TTA ; st - > codec - > channels = channels ; st - > codec - > sample_rate = samplerate ; st - > codec - > bits_per_sample = bps ; st - > codec - > extradata_size = url_ftell ( & s - > pb ) - start ; if ( st - > codec - > extradata_size + FF_INPUT_BUFFER_PADDING_SIZE < = ( unsigned ) st - > codec - > extradata_size ) { //this check is redundant as get_buffer should fail av_log ( s , AV_LOG_ERROR , extradata_size too large\n ) ; st - > codec - > extradata = av_mallocz ( st - > codec - > extradata_size + FF_INPUT_BUFFER_PADDING_SIZE ) ; url_fseek ( & s - > pb , start , SEEK_SET ) ; // or SEEK_CUR and - size ? : ) get_buffer ( & s - > pb , st - > codec - > extradata , st - > codec - > extradata_size ) ; return 0 ;",1
"static av_cold int fft_init ( AVCodecContext * avctx , AC3MDCTContext * mdct , int ln ) { int i , n , n2 ; float alpha ; n = 1 < < ln ; n2 = n > > 1 ; FF_ALLOC_OR_GOTO ( avctx , mdct - > costab , n2 * sizeof ( * mdct - > costab ) , fft_alloc_fail ) ; FF_ALLOC_OR_GOTO ( avctx , mdct - > sintab , n2 * sizeof ( * mdct - > sintab ) , fft_alloc_fail ) ; for ( i = 0 ; i < n2 ; i + + ) { alpha = 2 . 0 * M_PI * i / n ; mdct - > costab[i] = FIX15 ( cos ( alpha ) ) ; mdct - > sintab[i] = FIX15 ( sin ( alpha ) ) ; } return 0 ; fft_alloc_fail : mdct_end ( mdct ) ; return AVERROR ( ENOMEM ) ; }",0
void in_asm_used_var_warning_killer ( ) { volatile int i= yCoeff + vrCoeff + ubCoeff + vgCoeff + ugCoeff + bF8 + bFC + w400 + w80 + w10 + bm00001111 + bm00000111 + bm11111000 + b16Mask + g16Mask + r16Mask + b15Mask + g15Mask + r15Mask + temp0 + asm_yalpha1 + asm_uvalpha1 + M24A + M24B + M24C + w02 + funnyYCode[0] + funnyUVCode[0] + b5Dither + g5Dither + r5Dither + g6Dither + dither4[0] + dither8[0] ; if ( i ) i=0 ; },1
"static void vc1_inv_trans_4x8_dc_c ( uint8_t * dest , int linesize , DCTELEM * block ) { int i ; int dc = block[0] ; const uint8_t * cm ; dc = ( 17 * dc + 4 ) > > 3 ; dc = ( 12 * dc + 64 ) > > 7 ; cm = ff_cropTbl + MAX_NEG_CROP + dc ; for ( i = 0 ; i < 8 ; i + + ) { dest[0] = cm[dest[0]] ; dest[1] = cm[dest[1]] ; dest[2] = cm[dest[2]] ; dest[3] = cm[dest[3]] ; dest + = linesize ; } }",1
"static int qsv_decode ( AVCodecContext * avctx , QSVContext * q , AVFrame * frame , int * got_frame , AVPacket * avpkt ) { QSVFrame * out_frame ; mfxFrameSurface1 * insurf ; mfxFrameSurface1 * outsurf ; mfxSyncPoint * sync ; mfxBitstream bs = { { { 0 } } } ; int ret ; if ( avpkt - > size ) { bs . Data = avpkt - > data ; bs . DataLength = avpkt - > size ; bs . MaxLength = bs . DataLength ; bs . TimeStamp = avpkt - > pts ; } sync = av_mallocz ( sizeof ( * sync ) ) ; if ( ! sync ) { av_freep ( & sync ) ; return AVERROR ( ENOMEM ) ; } do { ret = get_surface ( avctx , q , & insurf ) ; if ( ret < 0 ) return ret ; ret = MFXVideoDECODE_DecodeFrameAsync ( q - > session , avpkt - > size ? & bs : NULL , insurf , & outsurf , sync ) ; if ( ret == MFX_WRN_DEVICE_BUSY ) av_usleep ( 500 ) ; } while ( ret == MFX_WRN_DEVICE_BUSY || ret == MFX_ERR_MORE_SURFACE ) ; if ( ret ! = MFX_ERR_NONE & & ret ! = MFX_ERR_MORE_DATA & & ret ! = MFX_WRN_VIDEO_PARAM_CHANGED & & ret ! = MFX_ERR_MORE_SURFACE ) { av_log ( avctx , AV_LOG_ERROR , Error during QSV decoding . \n ) ; av_freep ( & sync ) ; return ff_qsv_error ( ret ) ; } / * make sure we do not enter an infinite loop if the SDK * did not consume any data and did not return anything * / if ( ! * sync & & ! bs . DataOffset ) { av_log ( avctx , AV_LOG_WARNING , A decode call did not consume any data\n ) ; bs . DataOffset = avpkt - > size ; } if ( * sync ) { QSVFrame * out_frame = find_frame ( q , outsurf ) ; if ( ! out_frame ) { av_log ( avctx , AV_LOG_ERROR , The returned surface does not correspond to any frame\n ) ; av_freep ( & sync ) ; return AVERROR_BUG ; } out_frame - > queued = 1 ; av_fifo_generic_write ( q - > async_fifo , & out_frame , sizeof ( out_frame ) , NULL ) ; av_fifo_generic_write ( q - > async_fifo , & sync , sizeof ( sync ) , NULL ) ; } else { av_freep ( & sync ) ; } if ( ! av_fifo_space ( q - > async_fifo ) || ( ! avpkt - > size & & av_fifo_size ( q - > async_fifo ) ) ) { AVFrame * src_frame ; av_fifo_generic_read ( q - > async_fifo , & out_frame , sizeof ( out_frame ) , NULL ) ; av_fifo_generic_read ( q - > async_fifo , & sync , sizeof ( sync ) , NULL ) ; out_frame - > queued = 0 ; do { ret = MFXVideoCORE_SyncOperation ( q - > session , * sync , 1000 ) ; } while ( ret == MFX_WRN_IN_EXECUTION ) ; av_freep ( & sync ) ; src_frame = out_frame - > frame ; ret = av_frame_ref ( frame , src_frame ) ; if ( ret < 0 ) return ret ; outsurf = out_frame - > surface ; if FF_API_PKT_PTS FF_DISABLE_DEPRECATION_WARNINGS frame - > pkt_pts = outsurf - > Data . TimeStamp ; FF_ENABLE_DEPRECATION_WARNINGS endif frame - > pts = outsurf - > Data . TimeStamp ; frame - > repeat_pict = outsurf - > Info . PicStruct & MFX_PICSTRUCT_FRAME_TRIPLING ? 4 : outsurf - > Info . PicStruct & MFX_PICSTRUCT_FRAME_DOUBLING ? 2 : outsurf - > Info . PicStruct & MFX_PICSTRUCT_FIELD_REPEATED ? 1 : 0 ; frame - > top_field_first = outsurf - > Info . PicStruct & MFX_PICSTRUCT_FIELD_TFF ; frame - > interlaced_frame = ! ( outsurf - > Info . PicStruct & MFX_PICSTRUCT_PROGRESSIVE ) ; * got_frame = 1 ; } return bs . DataOffset ; }",1
"static int cmp ( const void * a , const void * b ) { const double va = * ( const double * ) a , vb = * ( const double * ) b ; return va < vb ? - 1 : ( va > vb ? 1 : 0 ) ; }",1
"static void read_len_table ( uint8_t * dst , GetBitContext * gb ) { int i , val , repeat ; for ( i=0 ; i < 256 ; ) { repeat= get_bits ( gb , 3 ) ; val = get_bits ( gb , 5 ) ; if ( repeat==0 ) repeat= get_bits ( gb , 8 ) ; //printf ( %d %d\n , val , repeat ) ; while ( repeat - - ) dst[i + + ] = val ; } }",1
"static int dca_parse ( AVCodecParserContext * s , AVCodecContext * avctx , const uint8_t * * poutbuf , int * poutbuf_size , const uint8_t * buf , int buf_size ) { DCAParseContext * pc1 = s - > priv_data ; ParseContext * pc = & pc1 - > pc ; int next , duration , sample_rate ; if ( s - > flags & PARSER_FLAG_COMPLETE_FRAMES ) { next = buf_size ; } else { next = dca_find_frame_end ( pc1 , buf , buf_size ) ; if ( ff_combine_frame ( pc , next , & buf , & buf_size ) < 0 ) { * poutbuf = NULL ; * poutbuf_size = 0 ; return buf_size ; } } / * read the duration and sample rate from the frame header * / if ( ! dca_parse_params ( buf , buf_size , & duration , & sample_rate , & pc1 - > framesize ) ) { s - > duration = duration ; avctx - > sample_rate = sample_rate ; } else s - > duration = 0 ; * poutbuf = buf ; * poutbuf_size = buf_size ; return next ; }",1
"static int smacker_read_packet ( AVFormatContext * s , AVPacket * pkt ) { SmackerContext * smk = s - > priv_data ; int flags ; int ret ; int i ; int frame_size = 0 ; int palchange = 0 ; if ( s - > pb - > eof_reached || smk - > cur_frame > = smk - > frames ) return AVERROR_EOF ; / * if we demuxed all streams , pass another frame * / if ( smk - > curstream < 0 ) { avio_seek ( s - > pb , smk - > nextpos , 0 ) ; frame_size = smk - > frm_size[smk - > cur_frame] & ( 3 ) ; flags = smk - > frm_flags[smk - > cur_frame] ; / * handle palette change event * / if ( flags & SMACKER_PAL ) { int size , sz , t , off , j , pos ; uint8_t * pal = smk - > pal ; uint8_t oldpal[768] ; memcpy ( oldpal , pal , 768 ) ; size = avio_r8 ( s - > pb ) ; size = size * 4 - 1 ; frame_size - = size ; frame_size - - ; sz = 0 ; pos = avio_tell ( s - > pb ) + size ; while ( sz < 256 ) { t = avio_r8 ( s - > pb ) ; if ( t & 0x80 ) { / * skip palette entries * / sz + = ( t & 0x7F ) + 1 ; pal + = ( ( t & 0x7F ) + 1 ) * 3 ; } else if ( t & 0x40 ) { / * copy with offset * / off = avio_r8 ( s - > pb ) ; j = ( t & 0x3F ) + 1 ; if ( off + j > 0x100 ) { av_log ( s , AV_LOG_ERROR , Invalid palette update , offset=%d length=%d extends beyond palette size\n , off , j ) ; return AVERROR_INVALIDDATA ; } off * = 3 ; while ( j - - & & sz < 256 ) { * pal + + = oldpal[off + 0] ; * pal + + = oldpal[off + 1] ; * pal + + = oldpal[off + 2] ; sz + + ; off + = 3 ; } } else { / * new entries * / * pal + + = smk_pal[t] ; * pal + + = smk_pal[avio_r8 ( s - > pb ) & 0x3F] ; * pal + + = smk_pal[avio_r8 ( s - > pb ) & 0x3F] ; sz + + ; } } avio_seek ( s - > pb , pos , 0 ) ; palchange |= 1 ; } flags > > = 1 ; smk - > curstream = - 1 ; / * if audio chunks are present , put them to stack and retrieve later * / for ( i = 0 ; i < 7 ; i + + ) { if ( flags & 1 ) { int size ; uint8_t * tmpbuf ; size = avio_rl32 ( s - > pb ) - 4 ; frame_size - = size ; frame_size - = 4 ; smk - > curstream + + ; tmpbuf = av_realloc ( smk - > bufs[smk - > curstream] , size ) ; if ( ! tmpbuf ) return AVERROR ( ENOMEM ) ; smk - > bufs[smk - > curstream] = tmpbuf ; smk - > buf_sizes[smk - > curstream] = size ; ret = avio_read ( s - > pb , smk - > bufs[smk - > curstream] , size ) ; if ( ret ! = size ) return AVERROR ( EIO ) ; smk - > stream_id[smk - > curstream] = smk - > indexes[i] ; } flags > > = 1 ; } if ( frame_size < 0 ) return AVERROR_INVALIDDATA ; if ( av_new_packet ( pkt , frame_size + 769 ) ) return AVERROR ( ENOMEM ) ; if ( smk - > frm_size[smk - > cur_frame] & 1 ) palchange |= 2 ; pkt - > data[0] = palchange ; memcpy ( pkt - > data + 1 , smk - > pal , 768 ) ; ret = avio_read ( s - > pb , pkt - > data + 769 , frame_size ) ; if ( ret ! = frame_size ) return AVERROR ( EIO ) ; pkt - > stream_index = smk - > videoindex ; pkt - > pts = smk - > cur_frame ; pkt - > size = ret + 769 ; smk - > cur_frame + + ; smk - > nextpos = avio_tell ( s - > pb ) ; } else { if ( av_new_packet ( pkt , smk - > buf_sizes[smk - > curstream] ) ) return AVERROR ( ENOMEM ) ; memcpy ( pkt - > data , smk - > bufs[smk - > curstream] , smk - > buf_sizes[smk - > curstream] ) ; pkt - > size = smk - > buf_sizes[smk - > curstream] ; pkt - > stream_index = smk - > stream_id[smk - > curstream] ; pkt - > pts = smk - > aud_pts[smk - > curstream] ; smk - > aud_pts[smk - > curstream] + = AV_RL32 ( pkt - > data ) ; smk - > curstream - - ; } return 0 ; }",0
"static int decode_header ( EXRContext * s ) { int magic_number , version , i , flags , sar = 0 ; int layer_match = 0 ; s - > current_channel_offset = 0 ; s - > xmin = 0 ; s - > xmax = 0 ; s - > ymin = 0 ; s - > ymax = 0 ; s - > xdelta = 0 ; s - > ydelta = 0 ; s - > channel_offsets[0] = - 1 ; s - > channel_offsets[1] = - 1 ; s - > channel_offsets[2] = - 1 ; s - > channel_offsets[3] = - 1 ; s - > pixel_type = EXR_UNKNOWN ; s - > compression = EXR_UNKN ; s - > nb_channels = 0 ; s - > w = 0 ; s - > h = 0 ; s - > tile_attr . xSize = - 1 ; s - > tile_attr . ySize = - 1 ; s - > is_tile = 0 ; s - > is_luma = 0 ; if ( bytestream2_get_bytes_left ( & s - > gb ) < 10 ) { av_log ( s - > avctx , AV_LOG_ERROR , Header too short to parse . \n ) ; return AVERROR_INVALIDDATA ; } magic_number = bytestream2_get_le32 ( & s - > gb ) ; if ( magic_number ! = 20000630 ) { / * As per documentation of OpenEXR , it is supposed to be * int 20000630 little - endian * / av_log ( s - > avctx , AV_LOG_ERROR , Wrong magic number %d . \n , magic_number ) ; return AVERROR_INVALIDDATA ; } version = bytestream2_get_byte ( & s - > gb ) ; if ( version ! = 2 ) { avpriv_report_missing_feature ( s - > avctx , Version %d , version ) ; return AVERROR_PATCHWELCOME ; } flags = bytestream2_get_le24 ( & s - > gb ) ; if ( flags == 0x00 ) s - > is_tile = 0 ; else if ( flags & 0x02 ) s - > is_tile = 1 ; else { avpriv_report_missing_feature ( s - > avctx , flags %d , flags ) ; return AVERROR_PATCHWELCOME ; } // Parse the header while ( bytestream2_get_bytes_left ( & s - > gb ) > 0 & & * s - > gb . buffer ) { int var_size ; if ( ( var_size = check_header_variable ( s , channels , chlist , 38 ) ) > = 0 ) { GetByteContext ch_gb ; if ( ! var_size ) return AVERROR_INVALIDDATA ; bytestream2_init ( & ch_gb , s - > gb . buffer , var_size ) ; while ( bytestream2_get_bytes_left ( & ch_gb ) > = 19 ) { EXRChannel * channel ; enum ExrPixelType current_pixel_type ; int channel_index = - 1 ; int xsub , ysub ; if ( strcmp ( s - > layer , ) ! = 0 ) { if ( strncmp ( ch_gb . buffer , s - > layer , strlen ( s - > layer ) ) == 0 ) { layer_match = 1 ; av_log ( s - > avctx , AV_LOG_INFO , Channel match layer : %s . \n , ch_gb . buffer ) ; ch_gb . buffer + = strlen ( s - > layer ) ; if ( * ch_gb . buffer == ' . ' ) ch_gb . buffer + + ; / * skip dot if not given * / } else { av_log ( s - > avctx , AV_LOG_INFO , Channel doesn ' t match layer : %s . \n , ch_gb . buffer ) ; } } else { layer_match = 1 ; } if ( layer_match ) { / * only search channel if the layer match is valid * / if ( ! strcmp ( ch_gb . buffer , R ) || ! strcmp ( ch_gb . buffer , X ) || ! strcmp ( ch_gb . buffer , U ) ) { channel_index = 0 ; s - > is_luma = 0 ; } else if ( ! strcmp ( ch_gb . buffer , G ) || ! strcmp ( ch_gb . buffer , V ) ) { channel_index = 1 ; s - > is_luma = 0 ; } else if ( ! strcmp ( ch_gb . buffer , Y ) ) { channel_index = 1 ; s - > is_luma = 1 ; } else if ( ! strcmp ( ch_gb . buffer , B ) || ! strcmp ( ch_gb . buffer , Z ) || ! strcmp ( ch_gb . buffer , W ) ) { channel_index = 2 ; s - > is_luma = 0 ; } else if ( ! strcmp ( ch_gb . buffer , A ) ) { channel_index = 3 ; } else { av_log ( s - > avctx , AV_LOG_WARNING , Unsupported channel % . 256s . \n , ch_gb . buffer ) ; } } / * skip until you get a 0 * / while ( bytestream2_get_bytes_left ( & ch_gb ) > 0 & & bytestream2_get_byte ( & ch_gb ) ) continue ; if ( bytestream2_get_bytes_left ( & ch_gb ) < 4 ) { av_log ( s - > avctx , AV_LOG_ERROR , Incomplete header . \n ) ; return AVERROR_INVALIDDATA ; } current_pixel_type = bytestream2_get_le32 ( & ch_gb ) ; if ( current_pixel_type > = EXR_UNKNOWN ) { avpriv_report_missing_feature ( s - > avctx , Pixel type %d , current_pixel_type ) ; return AVERROR_PATCHWELCOME ; } bytestream2_skip ( & ch_gb , 4 ) ; xsub = bytestream2_get_le32 ( & ch_gb ) ; ysub = bytestream2_get_le32 ( & ch_gb ) ; if ( xsub ! = 1 || ysub ! = 1 ) { avpriv_report_missing_feature ( s - > avctx , Subsampling %dx%d , xsub , ysub ) ; return AVERROR_PATCHWELCOME ; } if ( s - > channel_offsets[channel_index] == - 1 ) { / * channel have not been previously assign * / if ( channel_index > = 0 ) { if ( s - > pixel_type ! = EXR_UNKNOWN & & s - > pixel_type ! = current_pixel_type ) { av_log ( s - > avctx , AV_LOG_ERROR , RGB channels not of the same depth . \n ) ; return AVERROR_INVALIDDATA ; } s - > pixel_type = current_pixel_type ; s - > channel_offsets[channel_index] = s - > current_channel_offset ; } } s - > channels = av_realloc ( s - > channels , + + s - > nb_channels * sizeof ( EXRChannel ) ) ; if ( ! s - > channels ) return AVERROR ( ENOMEM ) ; channel = & s - > channels[s - > nb_channels - 1] ; channel - > pixel_type = current_pixel_type ; channel - > xsub = xsub ; channel - > ysub = ysub ; s - > current_channel_offset + = 1 < < current_pixel_type ; } / * Check if all channels are set with an offset or if the channels * are causing an overflow * / if ( ! s - > is_luma ) { / * if we expected to have at",1
"static void encode_block ( NellyMoserEncodeContext * s , unsigned char * output , int output_size ) { PutBitContext pb ; int i , j , band , block , best_idx , power_idx = 0 ; float power_val , coeff , coeff_sum ; float pows[NELLY_FILL_LEN] ; int bits[NELLY_BUF_LEN] , idx_table[NELLY_BANDS] ; float cand[NELLY_BANDS] ; apply_mdct ( s ) ; init_put_bits ( & pb , output , output_size * 8 ) ; i = 0 ; for ( band = 0 ; band < NELLY_BANDS ; band + + ) { coeff_sum = 0 ; for ( j = 0 ; j < ff_nelly_band_sizes_table[band] ; i + + , j + + ) { coeff_sum + = s - > mdct_out[i ] * s - > mdct_out[i ] + s - > mdct_out[i + NELLY_BUF_LEN] * s - > mdct_out[i + NELLY_BUF_LEN] ; } cand[band] = log ( FFMAX ( 1 . 0 , coeff_sum / ( ff_nelly_band_sizes_table[band] < < 7 ) ) ) * 1024 . 0 / M_LN2 ; } if ( s - > avctx - > trellis ) { get_exponent_dynamic ( s , cand , idx_table ) ; } else { get_exponent_greedy ( s , cand , idx_table ) ; } i = 0 ; for ( band = 0 ; band < NELLY_BANDS ; band + + ) { if ( band ) { power_idx + = ff_nelly_delta_table[idx_table[band]] ; put_bits ( & pb , 5 , idx_table[band] ) ; } else { power_idx = ff_nelly_init_table[idx_table[0]] ; put_bits ( & pb , 6 , idx_table[0] ) ; } power_val = pow_table[power_idx & 0x7FF] / ( 1 < < ( ( power_idx > > 11 ) + POW_TABLE_OFFSET ) ) ; for ( j = 0 ; j < ff_nelly_band_sizes_table[band] ; i + + , j + + ) { s - > mdct_out[i] * = power_val ; s - > mdct_out[i + NELLY_BUF_LEN] * = power_val ; pows[i] = power_idx ; } } ff_nelly_get_sample_bits ( pows , bits ) ; for ( block = 0 ; block < 2 ; block + + ) { for ( i = 0 ; i < NELLY_FILL_LEN ; i + + ) { if ( bits[i] > 0 ) { const float * table = ff_nelly_dequantization_table + ( 1 < < bits[i] ) - 1 ; coeff = s - > mdct_out[block * NELLY_BUF_LEN + i] ; best_idx = quant_lut[av_clip ( coeff * quant_lut_mul[bits[i]] + quant_lut_add[bits[i]] , quant_lut_offset[bits[i]] , quant_lut_offset[bits[i] + 1] - 1 ) ] ; if ( fabs ( coeff - table[best_idx] ) > fabs ( coeff - table[best_idx + 1] ) ) best_idx + + ; put_bits ( & pb , bits[i] , best_idx ) ; } } if ( ! block ) put_bits ( & pb , NELLY_HEADER_BITS + NELLY_DETAIL_BITS - put_bits_count ( & pb ) , 0 ) ; } flush_put_bits ( & pb ) ; memset ( put_bits_ptr ( & pb ) , 0 , output + output_size - put_bits_ptr ( & pb ) ) ; }",1
"static void dnxhd_decode_dct_block_10 ( const DNXHDContext * ctx , RowContext * row , int n ) { dnxhd_decode_dct_block ( ctx , row , n , 6 , 8 , 4 ) ; }",1
"static void opt_qsquish ( const char * arg ) { video_qsquish = atof ( arg ) ; if ( video_qsquish < 0 . 0 || video_qsquish > 99 . 0 ) { fprintf ( stderr , qsquish must be > = 0 . 0 and < = 99 . 0\n ) ; exit ( 1 ) ; } }",0
"static int create_vorbis_context ( vorbis_enc_context * venc , AVCodecContext * avctx ) { vorbis_enc_floor * fc ; vorbis_enc_residue * rc ; vorbis_enc_mapping * mc ; int i , book , ret ; venc - > channels = avctx - > channels ; venc - > sample_rate = avctx - > sample_rate ; venc - > log2_blocksize[0] = venc - > log2_blocksize[1] = 11 ; venc - > ncodebooks = FF_ARRAY_ELEMS ( cvectors ) ; venc - > codebooks = av_malloc ( sizeof ( vorbis_enc_codebook ) * venc - > ncodebooks ) ; if ( ! venc - > codebooks ) return AVERROR ( ENOMEM ) ; // codebook 0 . . 14 - floor1 book , values 0 . . 255 // codebook 15 residue masterbook // codebook 16 . . 29 residue for ( book = 0 ; book < venc - > ncodebooks ; book + + ) { vorbis_enc_codebook * cb = & venc - > codebooks[book] ; int vals ; cb - > ndimensions = cvectors[book] . dim ; cb - > nentries = cvectors[book] . real_len ; cb - > min = cvectors[book] . min ; cb - > delta = cvectors[book] . delta ; cb - > lookup = cvectors[book] . lookup ; cb - > seq_p = 0 ; cb - > lens = av_malloc_array ( cb - > nentries , sizeof ( uint8_t ) ) ; cb - > codewords = av_malloc_array ( cb - > nentries , sizeof ( uint32_t ) ) ; if ( ! cb - > lens || ! cb - > codewords ) return AVERROR ( ENOMEM ) ; memcpy ( cb - > lens , cvectors[book] . clens , cvectors[book] . len ) ; memset ( cb - > lens + cvectors[book] . len , 0 , cb - > nentries - cvectors[book] . len ) ; if ( cb - > lookup ) { vals = cb_lookup_vals ( cb - > lookup , cb - > ndimensions , cb - > nentries ) ; cb - > quantlist = av_malloc_array ( vals , sizeof ( int ) ) ; if ( ! cb - > quantlist ) return AVERROR ( ENOMEM ) ; for ( i = 0 ; i < vals ; i + + ) cb - > quantlist[i] = cvectors[book] . quant[i] ; } else { cb - > quantlist = NULL ; } if ( ( ret = ready_codebook ( cb ) ) < 0 ) return ret ; } venc - > nfloors = 1 ; venc - > floors = av_malloc ( sizeof ( vorbis_enc_floor ) * venc - > nfloors ) ; if ( ! venc - > floors ) return AVERROR ( ENOMEM ) ; // just 1 floor fc = & venc - > floors[0] ; fc - > partitions = NUM_FLOOR_PARTITIONS ; fc - > partition_to_class = av_malloc ( sizeof ( int ) * fc - > partitions ) ; if ( ! fc - > partition_to_class ) return AVERROR ( ENOMEM ) ; fc - > nclasses = 0 ; for ( i = 0 ; i < fc - > partitions ; i + + ) { static const int a[] = { 0 , 1 , 2 , 2 , 3 , 3 , 4 , 4 } ; fc - > partition_to_class[i] = a[i] ; fc - > nclasses = FFMAX ( fc - > nclasses , fc - > partition_to_class[i] ) ; } fc - > nclasses + + ; fc - > classes = av_malloc_array ( fc - > nclasses , sizeof ( vorbis_enc_floor_class ) ) ; if ( ! fc - > classes ) return AVERROR ( ENOMEM ) ; for ( i = 0 ; i < fc - > nclasses ; i + + ) { vorbis_enc_floor_class * c = & fc - > classes[i] ; int j , books ; c - > dim = floor_classes[i] . dim ; c - > subclass = floor_classes[i] . subclass ; c - > masterbook = floor_classes[i] . masterbook ; books = ( 1 < < c - > subclass ) ; c - > books = av_malloc_array ( books , sizeof ( int ) ) ; if ( ! c - > books ) return AVERROR ( ENOMEM ) ; for ( j = 0 ; j < books ; j + + ) c - > books[j] = floor_classes[i] . nbooks[j] ; } fc - > multiplier = 2 ; fc - > rangebits = venc - > log2_blocksize[0] - 1 ; fc - > values = 2 ; for ( i = 0 ; i < fc - > partitions ; i + + ) fc - > values + = fc - > classes[fc - > partition_to_class[i]] . dim ; fc - > list = av_malloc_array ( fc - > values , sizeof ( vorbis_floor1_entry ) ) ; if ( ! fc - > list ) return AVERROR ( ENOMEM ) ; fc - > list[0] . x = 0 ; fc - > list[1] . x = 1 < < fc - > rangebits ; for ( i = 2 ; i < fc - > values ; i + + ) { static const int a[] = { 93 , 23 , 372 , 6 , 46 , 186 , 750 , 14 , 33 , 65 , 130 , 260 , 556 , 3 , 10 , 18 , 28 , 39 , 55 , 79 , 111 , 158 , 220 , 312 , 464 , 650 , 850 } ; fc - > list[i] . x = a[i - 2] ; } if ( ff_vorbis_ready_floor1_list ( avctx , fc - > list , fc - > values ) ) return AVERROR_BUG ; venc - > nresidues = 1 ; venc - > residues = av_malloc ( sizeof ( vorbis_enc_residue ) * venc - > nresidues ) ; if ( ! venc - > residues ) return AVERROR ( ENOMEM ) ; // single residue rc = & venc - > residues[0] ; rc - > type = 2 ; rc - > begin = 0 ; rc - > end = 1600 ; rc - > partition_size = 32 ; rc - > classifications = 10 ; rc - > classbook = 15 ; rc - > books = av_malloc ( sizeof ( * rc - > books ) * rc - > classifications ) ; if ( ! rc - > books ) return AVERROR ( ENOMEM ) ; { static const int8_t a[10][8] = { { - 1 , - 1 , - 1 , - 1 , - 1 , - 1 , - 1 , - 1 , } , { - 1 , - 1 , 16 , - 1 , - 1 , - 1 , - 1 , - 1 , } , { - 1 , - 1 , 17 , - 1 , - 1 , - 1 , - 1 , - 1 , } , { - 1 , - 1 , 18 , - 1 , -",0
"static void mpeg_decode_picture_coding_extension ( Mpeg1Context * s1 ) { MpegEncContext * s= & s1 - > mpeg_enc_ctx ; s - > full_pel[0] = s - > full_pel[1] = 0 ; s - > mpeg_f_code[0][0] = get_bits ( & s - > gb , 4 ) ; s - > mpeg_f_code[0][1] = get_bits ( & s - > gb , 4 ) ; s - > mpeg_f_code[1][0] = get_bits ( & s - > gb , 4 ) ; s - > mpeg_f_code[1][1] = get_bits ( & s - > gb , 4 ) ; if ( ! s - > pict_type & & s1 - > mpeg_enc_ctx_allocated ) { av_log ( s - > avctx , AV_LOG_ERROR , Missing picture start code , guessing missing values\n ) ; if ( s - > mpeg_f_code[1][0] == 15 & & s - > mpeg_f_code[1][1]==15 ) { if ( s - > mpeg_f_code[0][0] == 15 & & s - > mpeg_f_code[0][1] == 15 ) s - > pict_type= FF_I_TYPE ; else s - > pict_type= FF_P_TYPE ; } else s - > pict_type= FF_B_TYPE ; s - > current_picture . pict_type= s - > pict_type ; s - > current_picture . key_frame= s - > pict_type == FF_I_TYPE ; } s - > intra_dc_precision = get_bits ( & s - > gb , 2 ) ; s - > picture_structure = get_bits ( & s - > gb , 2 ) ; s - > top_field_first = get_bits1 ( & s - > gb ) ; s - > frame_pred_frame_dct = get_bits1 ( & s - > gb ) ; s - > concealment_motion_vectors = get_bits1 ( & s - > gb ) ; s - > q_scale_type = get_bits1 ( & s - > gb ) ; s - > intra_vlc_format = get_bits1 ( & s - > gb ) ; s - > alternate_scan = get_bits1 ( & s - > gb ) ; s - > repeat_first_field = get_bits1 ( & s - > gb ) ; s - > chroma_420_type = get_bits1 ( & s - > gb ) ; s - > progressive_frame = get_bits1 ( & s - > gb ) ; if ( s - > progressive_sequence & & ! s - > progressive_frame ) { s - > progressive_frame= 1 ; av_log ( s - > avctx , AV_LOG_ERROR , interlaced frame in progressive sequence , ignoring\n ) ; } if ( s - > picture_structure==0 || ( s - > progressive_frame & & s - > picture_structure ! =PICT_FRAME ) ) { av_log ( s - > avctx , AV_LOG_ERROR , picture_structure %d invalid , ignoring\n , s - > picture_structure ) ; s - > picture_structure= PICT_FRAME ; } if ( s - > progressive_frame & & ! s - > frame_pred_frame_dct ) { av_log ( s - > avctx , AV_LOG_ERROR , invalid frame_pred_frame_dct\n ) ; s - > frame_pred_frame_dct= 1 ; } if ( s - > picture_structure == PICT_FRAME ) { s - > first_field=0 ; s - > v_edge_pos= 16 * s - > mb_height ; } else { s - > first_field = 1 ; s - > v_edge_pos= 8 * s - > mb_height ; memset ( s - > mbskip_table , 0 , s - > mb_stride * s - > mb_height ) ; } if ( s - > alternate_scan ) { ff_init_scantable ( s - > dsp . idct_permutation , & s - > inter_scantable , ff_alternate_vertical_scan ) ; ff_init_scantable ( s - > dsp . idct_permutation , & s - > intra_scantable , ff_alternate_vertical_scan ) ; } else { ff_init_scantable ( s - > dsp . idct_permutation , & s - > inter_scantable , ff_zigzag_direct ) ; ff_init_scantable ( s - > dsp . idct_permutation , & s - > intra_scantable , ff_zigzag_direct ) ; } / * composite display not parsed * / dprintf ( s - > avctx , intra_dc_precision=%d\n , s - > intra_dc_precision ) ; dprintf ( s - > avctx , picture_structure=%d\n , s - > picture_structure ) ; dprintf ( s - > avctx , top field first=%d\n , s - > top_field_first ) ; dprintf ( s - > avctx , repeat first field=%d\n , s - > repeat_first_field ) ; dprintf ( s - > avctx , conceal=%d\n , s - > concealment_motion_vectors ) ; dprintf ( s - > avctx , intra_vlc_format=%d\n , s - > intra_vlc_format ) ; dprintf ( s - > avctx , alternate_scan=%d\n , s - > alternate_scan ) ; dprintf ( s - > avctx , frame_pred_frame_dct=%d\n , s - > frame_pred_frame_dct ) ; dprintf ( s - > avctx , progressive_frame=%d\n , s - > progressive_frame ) ; }",0
"static int mov_write_mdia_tag ( AVIOContext * pb , MOVMuxContext * mov , MOVTrack * track ) { int64_t pos = avio_tell ( pb ) ; avio_wb32 ( pb , 0 ) ; / * size * / ffio_wfourcc ( pb , mdia ) ; mov_write_mdhd_tag ( pb , mov , track ) ; mov_write_hdlr_tag ( pb , track ) ; mov_write_minf_tag ( pb , track ) ; return update_size ( pb , pos ) ; }",1
"int ff_h264_decode_sei ( H264Context * h ) { while ( get_bits_left ( & h - > gb ) > 16 ) { int size , type ; type=0 ; do { if ( get_bits_left ( & h - > gb ) < 8 ) return AVERROR_INVALIDDATA ; type + = show_bits ( & h - > gb , 8 ) ; } while ( get_bits ( & h - > gb , 8 ) == 255 ) ; size=0 ; do { if ( get_bits_left ( & h - > gb ) < 8 ) return AVERROR_INVALIDDATA ; size + = show_bits ( & h - > gb , 8 ) ; } while ( get_bits ( & h - > gb , 8 ) == 255 ) ; if ( h - > avctx - > debug & FF_DEBUG_STARTCODE ) av_log ( h - > avctx , AV_LOG_DEBUG , SEI %d len : %d\n , type , size ) ; switch ( type ) { case SEI_TYPE_PIC_TIMING : // Picture timing SEI if ( decode_picture_timing ( h ) < 0 ) return - 1 ; break ; case SEI_TYPE_USER_DATA_ITU_T_T35 : if ( decode_user_data_itu_t_t35 ( h , size ) < 0 ) return - 1 ; break ; case SEI_TYPE_USER_DATA_UNREGISTERED : if ( decode_unregistered_user_data ( h , size ) < 0 ) return - 1 ; break ; case SEI_TYPE_RECOVERY_POINT : if ( decode_recovery_point ( h ) < 0 ) return - 1 ; break ; case SEI_BUFFERING_PERIOD : if ( decode_buffering_period ( h ) < 0 ) return - 1 ; break ; case SEI_TYPE_FRAME_PACKING : if ( decode_frame_packing ( h , size ) < 0 ) return - 1 ; default : skip_bits ( & h - > gb , 8 * size ) ; } //FIXME check bits here align_get_bits ( & h - > gb ) ; } return 0 ; }",1
"static int parse_fragment ( AVFormatContext * s , const char * filename , int64_t * start_ts , int64_t * duration , int64_t * moof_size , int64_t size ) { AVIOContext * in ; int ret ; uint32_t len ; if ( ( ret = avio_open2 ( & in , filename , AVIO_FLAG_READ , & s - > interrupt_callback , NULL ) ) < 0 ) return ret ; ret = AVERROR ( EIO ) ; * moof_size = avio_rb32 ( in ) ; if ( * moof_size < 8 || * moof_size > size ) goto fail ; if ( avio_rl32 ( in ) ! = MKTAG ( ' m ' , ' o ' , ' o ' , ' f ' ) ) goto fail ; len = avio_rb32 ( in ) ; if ( len > * moof_size ) goto fail ; if ( avio_rl32 ( in ) ! = MKTAG ( ' m ' , ' f ' , ' h ' , ' d ' ) ) goto fail ; avio_seek ( in , len - 8 , SEEK_CUR ) ; avio_rb32 ( in ) ; / * traf size * / if ( avio_rl32 ( in ) ! = MKTAG ( ' t ' , ' r ' , ' a ' , ' f ' ) ) goto fail ; while ( avio_tell ( in ) < * moof_size ) { uint32_t len = avio_rb32 ( in ) ; uint32_t tag = avio_rl32 ( in ) ; int64_t end = avio_tell ( in ) + len - 8 ; if ( len < 8 || len > = * moof_size ) goto fail ; if ( tag == MKTAG ( ' u ' , ' u ' , ' i ' , ' d ' ) ) { const uint8_t tfxd[] = { 0x6d , 0x1d , 0x9b , 0x05 , 0x42 , 0xd5 , 0x44 , 0xe6 , 0x80 , 0xe2 , 0x14 , 0x1d , 0xaf , 0xf7 , 0x57 , 0xb2 } ; uint8_t uuid[16] ; avio_read ( in , uuid , 16 ) ; if ( ! memcmp ( uuid , tfxd , 16 ) & & len > = 8 + 16 + 4 + 16 ) { avio_seek ( in , 4 , SEEK_CUR ) ; * start_ts = avio_rb64 ( in ) ; * duration = avio_rb64 ( in ) ; ret = 0 ; break ; } } avio_seek ( in , end , SEEK_SET ) ; } fail : avio_close ( in ) ; return ret ; }",0
"static int mpeg_decode_postinit ( AVCodecContext * avctx ) { Mpeg1Context * s1 = avctx - > priv_data ; MpegEncContext * s = & s1 - > mpeg_enc_ctx ; uint8_t old_permutation[64] ; int ret ; if ( avctx - > codec_id == AV_CODEC_ID_MPEG1VIDEO ) { // MPEG - 1 aspect avctx - > sample_aspect_ratio = av_d2q ( 1 . 0 / ff_mpeg1_aspect[s - > aspect_ratio_info] , 255 ) ; } else { // MPEG - 2 // MPEG - 2 aspect if ( s - > aspect_ratio_info > 1 ) { AVRational dar = av_mul_q ( av_div_q ( ff_mpeg2_aspect[s - > aspect_ratio_info] , ( AVRational ) { s1 - > pan_scan . width , s1 - > pan_scan . height } ) , ( AVRational ) { s - > width , s - > height } ) ; / * We ignore the spec here and guess a bit as reality does not * match the spec , see for example res_change_ffmpeg_aspect . ts * and sequence - display - aspect . mpg . * issue1613 , 621 , 562 * / if ( ( s1 - > pan_scan . width == 0 ) || ( s1 - > pan_scan . height == 0 ) || ( av_cmp_q ( dar , ( AVRational ) { 4 , 3 } ) & & av_cmp_q ( dar , ( AVRational ) { 16 , 9 } ) ) ) { s - > avctx - > sample_aspect_ratio = av_div_q ( ff_mpeg2_aspect[s - > aspect_ratio_info] , ( AVRational ) { s - > width , s - > height } ) ; } else { s - > avctx - > sample_aspect_ratio = av_div_q ( ff_mpeg2_aspect[s - > aspect_ratio_info] , ( AVRational ) { s1 - > pan_scan . width , s1 - > pan_scan . height } ) ; // issue1613 4/3 16/9 - > 16/9 // res_change_ffmpeg_aspect . ts 4/3 225/44 - > 4/3 // widescreen - issue562 . mpg 4/3 16/9 - > 16/9 // s - > avctx - > sample_aspect_ratio = av_mul_q ( s - > avctx - > sample_aspect_ratio , ( AVRational ) { s - > width , s - > height } ) ; av_dlog ( avctx , A %d/%d\n , ff_mpeg2_aspect[s - > aspect_ratio_info] . num , ff_mpeg2_aspect[s - > aspect_ratio_info] . den ) ; av_dlog ( avctx , B %d/%d\n , s - > avctx - > sample_aspect_ratio . num , s - > avctx - > sample_aspect_ratio . den ) ; } } else { s - > avctx - > sample_aspect_ratio = ff_mpeg2_aspect[s - > aspect_ratio_info] ; } } // MPEG - 2 ff_set_sar ( s - > avctx , s - > avctx - > sample_aspect_ratio ) ; if ( ( s1 - > mpeg_enc_ctx_allocated == 0 ) || avctx - > coded_width ! = s - > width || avctx - > coded_height ! = s - > height || s1 - > save_width ! = s - > width || s1 - > save_height ! = s - > height || s1 - > save_aspect_info ! = s - > aspect_ratio_info || ( s1 - > save_progressive_seq ! = s - > progressive_sequence & & FFALIGN ( s - > height , 16 ) ! = FFALIGN ( s - > height , 32 ) ) || 0 ) { if ( s1 - > mpeg_enc_ctx_allocated ) { ParseContext pc = s - > parse_context ; s - > parse_context . buffer = 0 ; ff_mpv_common_end ( s ) ; s - > parse_context = pc ; s1 - > mpeg_enc_ctx_allocated = 0 ; } ret = ff_set_dimensions ( avctx , s - > width , s - > height ) ; if ( ret < 0 ) return ret ; if ( avctx - > codec_id == AV_CODEC_ID_MPEG2VIDEO & & s - > bit_rate ) { avctx - > rc_max_rate = s - > bit_rate ; } else if ( avctx - > codec_id == AV_CODEC_ID_MPEG1VIDEO & & s - > bit_rate & & ( s - > bit_rate ! = 0x3FFFF * 400 || s - > vbv_delay ! = 0xFFFF ) ) { avctx - > bit_rate = s - > bit_rate ; } s1 - > save_aspect_info = s - > aspect_ratio_info ; s1 - > save_width = s - > width ; s1 - > save_height = s - > height ; s1 - > save_progressive_seq = s - > progressive_sequence ; / * low_delay may be forced , in this case we will have B - frames * that behave like P - frames . * / avctx - > has_b_frames = ! s - > low_delay ; if ( avctx - > codec_id == AV_CODEC_ID_MPEG1VIDEO ) { // MPEG - 1 fps avctx - > framerate = ff_mpeg12_frame_rate_tab[s - > frame_rate_index] ; avctx - > ticks_per_frame = 1 ; } else { // MPEG - 2 // MPEG - 2 fps av_reduce ( & s - > avctx - > framerate . num , & s - > avctx - > framerate . den , ff_mpeg12_frame_rate_tab[s - > frame_rate_index] . num * s1 - > frame_rate_ext . num , ff_mpeg12_frame_rate_tab[s - > frame_rate_index] . den * s1 - > frame_rate_ext . den , 1 < < 30 ) ; avctx - > ticks_per_frame = 2 ; } // MPEG - 2 avctx - > pix_fmt = mpeg_get_pixelformat ( avctx ) ; setup_hwaccel_for_pixfmt ( avctx ) ; / * Quantization matrices may need reordering * if DCT permutation is changed . * / memcpy ( old_permutation , s - > idsp . idct_permutation , 64 * sizeof ( uint8_t ) ) ; ff_mpv_idct_init ( s ) ; if ( ( ret = ff_mpv_common_init ( s ) ) < 0 ) return ret ; quant_matrix_rebuild ( s - > intra_matrix , old_permutation , s - > idsp . idct_permutation ) ; quant_matrix_rebuild ( s - > inter_matrix , old_permutation , s - > idsp . idct_permutation ) ; quant_matrix_rebuild ( s - > chroma_intra_matrix , old_permutation , s - > idsp . idct_permutation ) ; quant_matrix_rebuild ( s - > chroma_inter_matrix , old_permutation , s - > idsp . idct_permutation ) ; s1 - > mpeg_enc_ctx_allocated = 1 ; } return 0 ; }",0
"static int mxf_read_primer_pack ( void * arg , AVIOContext * pb , int tag , int size , UID uid , int64_t klv_offset ) { MXFContext * mxf = arg ; int item_num = avio_rb32 ( pb ) ; int item_len = avio_rb32 ( pb ) ; if ( item_len ! = 18 ) { avpriv_request_sample ( pb , Primer pack item length %d , item_len ) ; return AVERROR_PATCHWELCOME ; } if ( item_num > 65536 ) { av_log ( mxf - > fc , AV_LOG_ERROR , item_num %d is too large\n , item_num ) ; return AVERROR_INVALIDDATA ; } mxf - > local_tags = av_calloc ( item_num , item_len ) ; if ( ! mxf - > local_tags ) return AVERROR ( ENOMEM ) ; mxf - > local_tags_count = item_num ; avio_read ( pb , mxf - > local_tags , item_num * item_len ) ; return 0 ; }",1
"static inline void RENAME ( yuv2bgr24_2 ) ( SwsContext * c , const uint16_t * buf0 , const uint16_t * buf1 , const uint16_t * ubuf0 , const uint16_t * ubuf1 , const uint16_t * vbuf0 , const uint16_t * vbuf1 , const uint16_t * abuf0 , const uint16_t * abuf1 , uint8_t * dest , int dstW , int yalpha , int uvalpha , int y ) { x86_reg uv_off = c - > uv_off < < 1 ; //Note 8280 == DSTW_OFFSET but the preprocessor can ' t handle that there : ( __asm__ volatile ( mov %% REG_b , ESP_OFFSET ( %5 ) \n\t mov %4 , %% REG_b \n\t push %% REG_BP \n\t YSCALEYUV2RGB ( %%REGBP , %5 , %6 ) pxor %%mm7 , %%mm7 \n\t WRITEBGR24 ( %%REGb , 8280 ( %5 ) , %%REGBP ) pop %% REG_BP \n\t mov ESP_OFFSET ( %5 ) , %% REG_b \n\t : : c ( buf0 ) , d ( buf1 ) , S ( ubuf0 ) , D ( ubuf1 ) , m ( dest ) , a ( & c - > redDither ) , m ( uv_off ) ) ; }",1
int avformat_network_init ( void ) { if CONFIG_NETWORK int ret ; ff_network_inited_globally = 1 ; if ( ( ret = ff_network_init ( ) ) < 0 ) return ret ; ff_tls_init ( ) ; endif return 0 ; },1
"static int sab_diamond_search ( MpegEncContext * s , int * best , int dmin , int src_index , int ref_index , int const penalty_factor , int size , int h , int flags ) { MotionEstContext * const c= & s - > me ; me_cmp_func cmpf , chroma_cmpf ; Minima minima[MAX_SAB_SIZE] ; const int minima_count= FFABS ( c - > dia_size ) ; int i , j ; LOAD_COMMON LOAD_COMMON2 int map_generation= c - > map_generation ; cmpf= s - > dsp . me_cmp[size] ; chroma_cmpf= s - > dsp . me_cmp[size + 1] ; for ( j=i=0 ; i < ME_MAP_SIZE ; i + + ) { uint32_t key= map[i] ; key + = ( 1 < < ( ME_MAP_MV_BITS - 1 ) ) + ( 1 < < ( 2 * ME_MAP_MV_BITS - 1 ) ) ; if ( ( key & ( ( - 1 ) < < ( 2 * ME_MAP_MV_BITS ) ) ) ! = map_generation ) continue ; assert ( j < MAX_SAB_SIZE ) ; //max j = number of predictors minima[j] . height= score_map[i] ; minima[j] . x= key & ( ( 1 < < ME_MAP_MV_BITS ) - 1 ) ; key > > =ME_MAP_MV_BITS ; minima[j] . y= key & ( ( 1 < < ME_MAP_MV_BITS ) - 1 ) ; minima[j] . x - = ( 1 < < ( ME_MAP_MV_BITS - 1 ) ) ; minima[j] . y - = ( 1 < < ( ME_MAP_MV_BITS - 1 ) ) ; minima[j] . checked=0 ; if ( minima[j] . x || minima[j] . y ) minima[j] . height + = ( mv_penalty[ ( ( minima[j] . x ) < < shift ) - pred_x] + mv_penalty[ ( ( minima[j] . y ) < < shift ) - pred_y] ) * penalty_factor ; j + + ; } qsort ( minima , j , sizeof ( Minima ) , minima_cmp ) ; for ( ; j < minima_count ; j + + ) { minima[j] . height=256 * 256 * 256 * 64 ; minima[j] . checked=0 ; minima[j] . x= minima[j] . y=0 ; } for ( i=0 ; i < minima_count ; i + + ) { const int x= minima[i] . x ; const int y= minima[i] . y ; int d ; if ( minima[i] . checked ) continue ; if ( x > = xmax || x < = xmin || y > = ymax || y < = ymin ) continue ; SAB_CHECK_MV ( x - 1 , y ) SAB_CHECK_MV ( x + 1 , y ) SAB_CHECK_MV ( x , y - 1 ) SAB_CHECK_MV ( x , y + 1 ) minima[i] . checked= 1 ; } best[0]= minima[0] . x ; best[1]= minima[0] . y ; dmin= minima[0] . height ; if ( best[0] < xmax & & best[0] > xmin & & best[1] < ymax & & best[1] > ymin ) { int d ; //ensure that the refernece samples for hpel refinement are in the map CHECK_MV ( best[0] - 1 , best[1] ) CHECK_MV ( best[0] + 1 , best[1] ) CHECK_MV ( best[0] , best[1] - 1 ) CHECK_MV ( best[0] , best[1] + 1 ) } return dmin ; }",1
"static int tiff_decode_tag ( TiffContext * s , const uint8_t * start , const uint8_t * buf , const uint8_t * end_buf ) { unsigned tag , type , count , off , value = 0 ; int i ; uint32_t * pal ; const uint8_t * rp , * gp , * bp ; if ( end_buf - buf < 12 ) return AVERROR_INVALIDDATA ; tag = tget_short ( & buf , s - > le ) ; type = tget_short ( & buf , s - > le ) ; count = tget_long ( & buf , s - > le ) ; off = tget_long ( & buf , s - > le ) ; if ( type == 0 || type > = FF_ARRAY_ELEMS ( type_sizes ) ) { av_log ( s - > avctx , AV_LOG_DEBUG , Unknown tiff type ( %u ) encountered\n , type ) ; return 0 ; } if ( count == 1 ) { switch ( type ) { case TIFF_BYTE : case TIFF_SHORT : buf - = 4 ; value = tget ( & buf , type , s - > le ) ; buf = NULL ; break ; case TIFF_LONG : value = off ; buf = NULL ; break ; case TIFF_STRING : if ( count < = 4 ) { buf - = 4 ; break ; } default : value = UINT_MAX ; buf = start + off ; } } else { if ( count < = 4 & & type_sizes[type] * count < = 4 ) buf - = 4 ; else buf = start + off ; } if ( buf & & ( buf < start || buf > end_buf ) ) { av_log ( s - > avctx , AV_LOG_ERROR , Tag referencing position outside the image\n ) ; return AVERROR_INVALIDDATA ; } switch ( tag ) { case TIFF_WIDTH : s - > width = value ; break ; case TIFF_HEIGHT : s - > height = value ; break ; case TIFF_BPP : s - > bppcount = count ; if ( count > 4 ) { av_log ( s - > avctx , AV_LOG_ERROR , This format is not supported ( bpp=%d , %d components ) \n , s - > bpp , count ) ; return AVERROR_INVALIDDATA ; } if ( count == 1 ) s - > bpp = value ; else { switch ( type ) { case TIFF_BYTE : s - > bpp = ( off & 0xFF ) + ( ( off > > 8 ) & 0xFF ) + ( ( off > > 16 ) & 0xFF ) + ( ( off > > 24 ) & 0xFF ) ; break ; case TIFF_SHORT : case TIFF_LONG : s - > bpp = 0 ; for ( i = 0 ; i < count & & buf < end_buf ; i + + ) s - > bpp + = tget ( & buf , type , s - > le ) ; break ; default : s - > bpp = - 1 ; } } break ; case TIFF_SAMPLES_PER_PIXEL : if ( count ! = 1 ) { av_log ( s - > avctx , AV_LOG_ERROR , Samples per pixel requires a single value , many provided\n ) ; return AVERROR_INVALIDDATA ; } if ( s - > bppcount == 1 ) s - > bpp * = value ; s - > bppcount = value ; break ; case TIFF_COMPR : s - > compr = value ; s - > predictor = 0 ; switch ( s - > compr ) { case TIFF_RAW : case TIFF_PACKBITS : case TIFF_LZW : case TIFF_CCITT_RLE : break ; case TIFF_G3 : case TIFF_G4 : s - > fax_opts = 0 ; break ; case TIFF_DEFLATE : case TIFF_ADOBE_DEFLATE : if CONFIG_ZLIB break ; else av_log ( s - > avctx , AV_LOG_ERROR , Deflate : ZLib not compiled in\n ) ; return AVERROR ( ENOSYS ) ; endif case TIFF_JPEG : case TIFF_NEWJPEG : avpriv_report_missing_feature ( s - > avctx , JPEG compression ) ; return AVERROR_PATCHWELCOME ; default : av_log ( s - > avctx , AV_LOG_ERROR , Unknown compression method %i\n , s - > compr ) ; return AVERROR_INVALIDDATA ; } break ; case TIFF_ROWSPERSTRIP : if ( type == TIFF_LONG & & value == UINT_MAX ) value = s - > avctx - > height ; if ( value < 1 ) { av_log ( s - > avctx , AV_LOG_ERROR , Incorrect value of rows per strip\n ) ; return AVERROR_INVALIDDATA ; } s - > rps = value ; break ; case TIFF_STRIP_OFFS : if ( count == 1 ) { s - > stripdata = NULL ; s - > stripoff = value ; } else s - > stripdata = start + off ; s - > strips = count ; if ( s - > strips == 1 ) s - > rps = s - > height ; s - > sot = type ; if ( s - > stripdata > end_buf ) { av_log ( s - > avctx , AV_LOG_ERROR , Tag referencing position outside the image\n ) ; return AVERROR_INVALIDDATA ; } break ; case TIFF_STRIP_SIZE : if ( count == 1 ) { s - > stripsizes = NULL ; s - > stripsize = value ; s - > strips = 1 ; } else { s - > stripsizes = start + off ; } s - > strips = count ; s - > sstype = type ; if ( s - > stripsizes > end_buf ) { av_log ( s - > avctx , AV_LOG_ERROR , Tag referencing position outside the image\n ) ; return AVERROR_INVALIDDATA ; } break ; case TIFF_PREDICTOR : s - > predictor = value ; break ; case TIFF_INVERT : switch ( value ) { case 0 : s - > invert = 1 ; break ; case 1 : s - > invert = 0 ; break ; case 2 : case 3 : break ; default : av_log ( s - > avctx , AV_LOG_ERROR , Color mode %d is not supported\n , value ) ; return AVERROR_INVALIDDATA ; } break ; case TIFF_FILL_ORDER : if ( value < 1 || value > 2 ) { av_log ( s - > avctx , AV_LOG_ERROR , Unknown FillOrder value %d , trying default one\n , value ) ; value = 1 ; } s - > fill_order = value - 1 ; break ; case TIFF_PAL : pal = ( uint32_t * ) s - > palette ; off = type_sizes[type] ; if ( count / 3 > 256 || end_buf - buf < count / 3 * off * 3 ) return AVERROR_INVALIDDATA ; rp = buf ; gp = buf + count / 3 * off ; bp = buf + count / 3 * off * 2 ; off = ( type_sizes[type] - 1 ) < < 3 ; for ( i = 0 ; i < count /",1
"static int read_packet ( AVFormatContext * s , AVPacket * pkt ) { MmDemuxContext * mm = s - > priv_data ; AVIOContext * pb = s - > pb ; unsigned char preamble[MM_PREAMBLE_SIZE] ; unsigned int type , length ; while ( 1 ) { if ( avio_read ( pb , preamble , MM_PREAMBLE_SIZE ) ! = MM_PREAMBLE_SIZE ) { return AVERROR ( EIO ) ; } type = AV_RL16 ( & preamble[0] ) ; length = AV_RL16 ( & preamble[2] ) ; switch ( type ) { case MM_TYPE_PALETTE : case MM_TYPE_INTER : case MM_TYPE_INTRA : case MM_TYPE_INTRA_HH : case MM_TYPE_INTER_HH : case MM_TYPE_INTRA_HHV : case MM_TYPE_INTER_HHV : / * output preamble + data * / if ( av_new_packet ( pkt , length + MM_PREAMBLE_SIZE ) ) return AVERROR ( ENOMEM ) ; memcpy ( pkt - > data , preamble , MM_PREAMBLE_SIZE ) ; if ( avio_read ( pb , pkt - > data + MM_PREAMBLE_SIZE , length ) ! = length ) return AVERROR ( EIO ) ; pkt - > size = length + MM_PREAMBLE_SIZE ; pkt - > stream_index = 0 ; pkt - > pts = mm - > video_pts ; if ( type ! =MM_TYPE_PALETTE ) mm - > video_pts + + ; return 0 ; case MM_TYPE_AUDIO : if ( av_get_packet ( s - > pb , pkt , length ) < 0 ) return AVERROR ( ENOMEM ) ; pkt - > size = length ; pkt - > stream_index = 1 ; pkt - > pts = mm - > audio_pts + + ; return 0 ; default : av_log ( s , AV_LOG_INFO , unknown chunk type 0x%x\n , type ) ; avio_skip ( pb , length ) ; } } }",0
"void ff_ac3_bit_alloc_calc_mask ( AC3BitAllocParameters * s , int16_t * band_psd , int start , int end , int fast_gain , int is_lfe , int dba_mode , int dba_nsegs , uint8_t * dba_offsets , uint8_t * dba_lengths , uint8_t * dba_values , int16_t * mask ) { int16_t excite[50] ; / * excitation * / int bin , k ; int bndstrt , bndend , begin , end1 , tmp ; int lowcomp , fastleak , slowleak ; / * excitation function * / bndstrt = bin_to_band_tab[start] ; bndend = bin_to_band_tab[end - 1] + 1 ; if ( bndstrt == 0 ) { lowcomp = 0 ; lowcomp = calc_lowcomp1 ( lowcomp , band_psd[0] , band_psd[1] , 384 ) ; excite[0] = band_psd[0] - fast_gain - lowcomp ; lowcomp = calc_lowcomp1 ( lowcomp , band_psd[1] , band_psd[2] , 384 ) ; excite[1] = band_psd[1] - fast_gain - lowcomp ; begin = 7 ; for ( bin = 2 ; bin < 7 ; bin + + ) { if ( ! ( is_lfe & & bin == 6 ) ) lowcomp = calc_lowcomp1 ( lowcomp , band_psd[bin] , band_psd[bin + 1] , 384 ) ; fastleak = band_psd[bin] - fast_gain ; slowleak = band_psd[bin] - s - > slow_gain ; excite[bin] = fastleak - lowcomp ; if ( ! ( is_lfe & & bin == 6 ) ) { if ( band_psd[bin] < = band_psd[bin + 1] ) { begin = bin + 1 ; break ; } } } end1=bndend ; if ( end1 > 22 ) end1=22 ; for ( bin = begin ; bin < end1 ; bin + + ) { if ( ! ( is_lfe & & bin == 6 ) ) lowcomp = calc_lowcomp ( lowcomp , band_psd[bin] , band_psd[bin + 1] , bin ) ; fastleak = FFMAX ( fastleak - s - > fast_decay , band_psd[bin] - fast_gain ) ; slowleak = FFMAX ( slowleak - s - > slow_decay , band_psd[bin] - s - > slow_gain ) ; excite[bin] = FFMAX ( fastleak - lowcomp , slowleak ) ; } begin = 22 ; } else { / * coupling channel * / begin = bndstrt ; fastleak = ( s - > cpl_fast_leak < < 8 ) + 768 ; slowleak = ( s - > cpl_slow_leak < < 8 ) + 768 ; } for ( bin = begin ; bin < bndend ; bin + + ) { fastleak = FFMAX ( fastleak - s - > fast_decay , band_psd[bin] - fast_gain ) ; slowleak = FFMAX ( slowleak - s - > slow_decay , band_psd[bin] - s - > slow_gain ) ; excite[bin] = FFMAX ( fastleak , slowleak ) ; } / * compute masking curve * / for ( bin = bndstrt ; bin < bndend ; bin + + ) { tmp = s - > db_per_bit - band_psd[bin] ; if ( tmp > 0 ) { excite[bin] + = tmp > > 2 ; } mask[bin] = FFMAX ( ff_ac3_hearing_threshold_tab[bin > > s - > sr_shift][s - > sr_code] , excite[bin] ) ; } / * delta bit allocation * / if ( dba_mode == DBA_REUSE || dba_mode == DBA_NEW ) { int band , seg , delta ; band = 0 ; for ( seg = 0 ; seg < FFMIN ( 8 , dba_nsegs ) ; seg + + ) { band = FFMIN ( 49 , band + dba_offsets[seg] ) ; if ( dba_values[seg] > = 4 ) { delta = ( dba_values[seg] - 3 ) < < 7 ; } else { delta = ( dba_values[seg] - 4 ) < < 7 ; } for ( k = 0 ; k < dba_lengths[seg] ; k + + ) { mask[band] + = delta ; band + + ; } } } }",0
"static mfxIMPL choose_implementation ( const InputStream * ist ) { static const struct { const char * name ; mfxIMPL impl ; } impl_map[] = { { auto , MFX_IMPL_AUTO } , { sw , MFX_IMPL_SOFTWARE } , { hw , MFX_IMPL_HARDWARE } , { auto_any , MFX_IMPL_AUTO_ANY } , { hw_any , MFX_IMPL_HARDWARE_ANY } , { hw2 , MFX_IMPL_HARDWARE2 } , { hw3 , MFX_IMPL_HARDWARE3 } , { hw4 , MFX_IMPL_HARDWARE4 } , } ; mfxIMPL impl = MFX_IMPL_AUTO_ANY ; int i ; if ( ist - > hwaccel_device ) { for ( i = 0 ; i < FF_ARRAY_ELEMS ( impl_map ) ; i + + ) if ( ! strcmp ( ist - > hwaccel_device , impl_map[i] . name ) ) { impl = impl_map[i] . impl ; break ; } if ( i == FF_ARRAY_ELEMS ( impl_map ) ) impl = strtol ( ist - > hwaccel_device , NULL , 0 ) ; } return impl ; }",0
"static inline void RENAME ( rgb16to15 ) ( const uint8_t * src , uint8_t * dst , long src_size ) { register const uint8_t * s=src ; register uint8_t * d=dst ; register const uint8_t * end ; const uint8_t * mm_end ; end = s + src_size ; if COMPILE_TEMPLATE_MMX __asm__ volatile ( PREFETCH %0 : : m ( * s ) ) ; __asm__ volatile ( movq %0 , %%mm7 : : m ( mask15rg ) ) ; __asm__ volatile ( movq %0 , %%mm6 : : m ( mask15b ) ) ; mm_end = end - 15 ; while ( s < mm_end ) { __asm__ volatile ( PREFETCH 32%1 \n\t movq %1 , %%mm0 \n\t movq 8%1 , %%mm2 \n\t movq %%mm0 , %%mm1 \n\t movq %%mm2 , %%mm3 \n\t psrlq 1 , %%mm0 \n\t psrlq 1 , %%mm2 \n\t pand %%mm7 , %%mm0 \n\t pand %%mm7 , %%mm2 \n\t pand %%mm6 , %%mm1 \n\t pand %%mm6 , %%mm3 \n\t por %%mm1 , %%mm0 \n\t por %%mm3 , %%mm2 \n\t MOVNTQ %%mm0 , %0 \n\t MOVNTQ %%mm2 , 8%0 : =m ( * d ) : m ( * s ) ) ; d + =16 ; s + =16 ; } __asm__ volatile ( SFENCE : : : memory ) ; __asm__ volatile ( EMMS : : : memory ) ; endif mm_end = end - 3 ; while ( s < mm_end ) { register uint32_t x= * ( ( const uint32_t * ) s ) ; * ( ( uint32_t * ) d ) = ( ( x > > 1 ) & 0x7FE07FE0 ) | ( x & 0x001F001F ) ; s + =4 ; d + =4 ; } if ( s < end ) { register uint16_t x= * ( ( const uint16_t * ) s ) ; * ( ( uint16_t * ) d ) = ( ( x > > 1 ) & 0x7FE0 ) | ( x & 0x001F ) ; } }",0
"static void hscroll ( AVCodecContext * avctx ) { AnsiContext * s = avctx - > priv_data ; int i ; if ( s - > y < avctx - > height - s - > font_height ) { s - > y + = s - > font_height ; return ; } i = 0 ; for ( ; i < avctx - > height - s - > font_height ; i + + ) memcpy ( s - > frame - > data[0] + i * s - > frame - > linesize[0] , s - > frame - > data[0] + ( i + s - > font_height ) * s - > frame - > linesize[0] , avctx - > width ) ; for ( ; i < avctx - > height ; i + + ) memset ( s - > frame - > data[0] + i * s - > frame - > linesize[0] , DEFAULT_BG_COLOR , avctx - > width ) ; }",0
"static int vaapi_encode_issue ( AVCodecContext * avctx , VAAPIEncodePicture * pic ) { VAAPIEncodeContext * ctx = avctx - > priv_data ; VAAPIEncodeSlice * slice ; VAStatus vas ; int err , i ; char data[MAX_PARAM_BUFFER_SIZE] ; size_t bit_len ; av_log ( avctx , AV_LOG_DEBUG , Issuing encode for pic % PRId64 /% PRId64 as type %s . \n , pic - > display_order , pic - > encode_order , picture_type_name[pic - > type] ) ; if ( pic - > nb_refs == 0 ) { av_log ( avctx , AV_LOG_DEBUG , No reference pictures . \n ) ; } else { av_log ( avctx , AV_LOG_DEBUG , Refers to : ) ; for ( i = 0 ; i < pic - > nb_refs ; i + + ) { av_log ( avctx , AV_LOG_DEBUG , % PRId64 /% PRId64 , pic - > refs[i] - > display_order , pic - > refs[i] - > encode_order ) ; } av_log ( avctx , AV_LOG_DEBUG , . \n ) ; } av_assert0 ( pic - > input_available & & ! pic - > encode_issued ) ; for ( i = 0 ; i < pic - > nb_refs ; i + + ) { av_assert0 ( pic - > refs[i] ) ; // If we are serialised then the references must have already // completed . If not , they must have been issued but need not // have completed yet . if ( ctx - > issue_mode == ISSUE_MODE_SERIALISE_EVERYTHING ) av_assert0 ( pic - > refs[i] - > encode_complete ) ; else av_assert0 ( pic - > refs[i] - > encode_issued ) ; } av_log ( avctx , AV_LOG_DEBUG , Input surface is % x . \n , pic - > input_surface ) ; pic - > recon_image = av_frame_alloc ( ) ; if ( ! pic - > recon_image ) { err = AVERROR ( ENOMEM ) ; goto fail ; } err = av_hwframe_get_buffer ( ctx - > recon_frames_ref , pic - > recon_image , 0 ) ; if ( err < 0 ) { err = AVERROR ( ENOMEM ) ; goto fail ; } pic - > recon_surface = ( VASurfaceID ) ( uintptr_t ) pic - > recon_image - > data[3] ; av_log ( avctx , AV_LOG_DEBUG , Recon surface is % x . \n , pic - > recon_surface ) ; pic - > output_buffer_ref = av_buffer_pool_get ( ctx - > output_buffer_pool ) ; if ( ! pic - > output_buffer_ref ) { err = AVERROR ( ENOMEM ) ; goto fail ; } pic - > output_buffer = ( VABufferID ) ( uintptr_t ) pic - > output_buffer_ref - > data ; av_log ( avctx , AV_LOG_DEBUG , Output buffer is % x . \n , pic - > output_buffer ) ; if ( ctx - > codec - > picture_params_size > 0 ) { pic - > codec_picture_params = av_malloc ( ctx - > codec - > picture_params_size ) ; if ( ! pic - > codec_picture_params ) goto fail ; memcpy ( pic - > codec_picture_params , ctx - > codec_picture_params , ctx - > codec - > picture_params_size ) ; } else { av_assert0 ( ! ctx - > codec_picture_params ) ; } pic - > nb_param_buffers = 0 ; if ( pic - > encode_order == 0 ) { // Global parameter buffers are set on the first picture only . for ( i = 0 ; i < ctx - > nb_global_params ; i + + ) { err = vaapi_encode_make_param_buffer ( avctx , pic , VAEncMiscParameterBufferType , ( char * ) ctx - > global_params[i] , ctx - > global_params_size[i] ) ; if ( err < 0 ) goto fail ; } } if ( pic - > type == PICTURE_TYPE_IDR & & ctx - > codec - > init_sequence_params ) { err = vaapi_encode_make_param_buffer ( avctx , pic , VAEncSequenceParameterBufferType , ctx - > codec_sequence_params , ctx - > codec - > sequence_params_size ) ; if ( err < 0 ) goto fail ; } if ( ctx - > codec - > init_picture_params ) { err = ctx - > codec - > init_picture_params ( avctx , pic ) ; if ( err < 0 ) { av_log ( avctx , AV_LOG_ERROR , Failed to initialise picture parameters : %d . \n , err ) ; goto fail ; } err = vaapi_encode_make_param_buffer ( avctx , pic , VAEncPictureParameterBufferType , pic - > codec_picture_params , ctx - > codec - > picture_params_size ) ; if ( err < 0 ) goto fail ; } if ( pic - > type == PICTURE_TYPE_IDR ) { if ( ctx - > codec - > write_sequence_header ) { bit_len = 8 * sizeof ( data ) ; err = ctx - > codec - > write_sequence_header ( avctx , data , & bit_len ) ; if ( err < 0 ) { av_log ( avctx , AV_LOG_ERROR , Failed to write per - sequence header : %d . \n , err ) ; goto fail ; } err = vaapi_encode_make_packed_header ( avctx , pic , ctx - > codec - > sequence_header_type , data , bit_len ) ; if ( err < 0 ) goto fail ; } } if ( ctx - > codec - > write_picture_header ) { bit_len = 8 * sizeof ( data ) ; err = ctx - > codec - > write_picture_header ( avctx , pic , data , & bit_len ) ; if ( err < 0 ) { av_log ( avctx , AV_LOG_ERROR , Failed to write per - picture header : %d . \n , err ) ; goto fail ; } err = vaapi_encode_make_packed_header ( avctx , pic , ctx - > codec - > picture_header_type , data , bit_len ) ; if ( err < 0 ) goto fail ; } if ( ctx - > codec - > write_extra_buffer ) { for ( i = 0 ; ; i + + ) { size_t len = sizeof ( data ) ; int type ; err = ctx - > codec - > write_extra_buffer ( avctx , pic , i , & type , data , & len ) ; if ( err == AVERROR_EOF ) break ; if ( err < 0 ) { av_log ( avctx , AV_LOG_ERROR , Failed to write extra buffer %d : %d . \n , i , err ) ; goto fail ; } err = vaapi_encode_make_param_buffer ( avctx , pic , type , data , len ) ; if ( err < 0 ) goto fail ; } } if ( ctx - > codec - > write_extra_header ) { for ( i = 0 ; ; i + + ) { int type ; bit_len = 8 * sizeof ( data ) ; err = ctx - > codec - > write_extra_header ( avctx , pic , i , & type , data , & bit_len ) ; if ( err == AVERROR_EOF ) break ; if ( err < 0 ) { av_log ( avctx , AV_LOG_ERROR , Failed to write extra header %d : %d",0
"static void avc_luma_hv_qrt_8w_msa ( const uint8_t * src_x , const uint8_t * src_y , int32_t src_stride , uint8_t * dst , int32_t dst_stride , int32_t height ) { uint32_t loop_cnt ; v16i8 src_hz0 , src_hz1 , src_hz2 , src_hz3 ; v16i8 src_vt0 , src_vt1 , src_vt2 , src_vt3 , src_vt4 ; v16i8 src_vt5 , src_vt6 , src_vt7 , src_vt8 ; v16i8 mask0 , mask1 , mask2 ; v8i16 hz_out0 , hz_out1 , hz_out2 , hz_out3 ; v8i16 vert_out0 , vert_out1 , vert_out2 , vert_out3 ; v8i16 out0 , out1 , out2 , out3 ; v16u8 tmp0 , tmp1 ; LD_SB3 ( & luma_mask_arr[0] , 16 , mask0 , mask1 , mask2 ) ; LD_SB5 ( src_y , src_stride , src_vt0 , src_vt1 , src_vt2 , src_vt3 , src_vt4 ) ; src_y + = ( 5 * src_stride ) ; src_vt0 = ( v16i8 ) __msa_insve_d ( ( v2i64 ) src_vt0 , 1 , ( v2i64 ) src_vt1 ) ; src_vt1 = ( v16i8 ) __msa_insve_d ( ( v2i64 ) src_vt1 , 1 , ( v2i64 ) src_vt2 ) ; src_vt2 = ( v16i8 ) __msa_insve_d ( ( v2i64 ) src_vt2 , 1 , ( v2i64 ) src_vt3 ) ; src_vt3 = ( v16i8 ) __msa_insve_d ( ( v2i64 ) src_vt3 , 1 , ( v2i64 ) src_vt4 ) ; XORI_B4_128_SB ( src_vt0 , src_vt1 , src_vt2 , src_vt3 ) ; for ( loop_cnt = ( height > > 2 ) ; loop_cnt - - ; ) { LD_SB4 ( src_x , src_stride , src_hz0 , src_hz1 , src_hz2 , src_hz3 ) ; XORI_B4_128_SB ( src_hz0 , src_hz1 , src_hz2 , src_hz3 ) ; src_x + = ( 4 * src_stride ) ; hz_out0 = AVC_HORZ_FILTER_SH ( src_hz0 , src_hz0 , mask0 , mask1 , mask2 ) ; hz_out1 = AVC_HORZ_FILTER_SH ( src_hz1 , src_hz1 , mask0 , mask1 , mask2 ) ; hz_out2 = AVC_HORZ_FILTER_SH ( src_hz2 , src_hz2 , mask0 , mask1 , mask2 ) ; hz_out3 = AVC_HORZ_FILTER_SH ( src_hz3 , src_hz3 , mask0 , mask1 , mask2 ) ; SRARI_H4_SH ( hz_out0 , hz_out1 , hz_out2 , hz_out3 , 5 ) ; SAT_SH4_SH ( hz_out0 , hz_out1 , hz_out2 , hz_out3 , 7 ) ; LD_SB4 ( src_y , src_stride , src_vt5 , src_vt6 , src_vt7 , src_vt8 ) ; src_y + = ( 4 * src_stride ) ; src_vt4 = ( v16i8 ) __msa_insve_d ( ( v2i64 ) src_vt4 , 1 , ( v2i64 ) src_vt5 ) ; src_vt5 = ( v16i8 ) __msa_insve_d ( ( v2i64 ) src_vt5 , 1 , ( v2i64 ) src_vt6 ) ; src_vt6 = ( v16i8 ) __msa_insve_d ( ( v2i64 ) src_vt6 , 1 , ( v2i64 ) src_vt7 ) ; src_vt7 = ( v16i8 ) __msa_insve_d ( ( v2i64 ) src_vt7 , 1 , ( v2i64 ) src_vt8 ) ; XORI_B4_128_SB ( src_vt4 , src_vt5 , src_vt6 , src_vt7 ) ; / * filter calc * / AVC_CALC_DPADD_B_6PIX_2COEFF_SH ( src_vt0 , src_vt1 , src_vt2 , src_vt3 , src_vt4 , src_vt5 , vert_out0 , vert_out1 ) ; AVC_CALC_DPADD_B_6PIX_2COEFF_SH ( src_vt2 , src_vt3 , src_vt4 , src_vt5 , src_vt6 , src_vt7 , vert_out2 , vert_out3 ) ; SRARI_H4_SH ( vert_out0 , vert_out1 , vert_out2 , vert_out3 , 5 ) ; SAT_SH4_SH ( vert_out0 , vert_out1 , vert_out2 , vert_out3 , 7 ) ; out0 = __msa_srari_h ( ( hz_out0 + vert_out0 ) , 1 ) ; out1 = __msa_srari_h ( ( hz_out1 + vert_out1 ) , 1 ) ; out2 = __msa_srari_h ( ( hz_out2 + vert_out2 ) , 1 ) ; out3 = __msa_srari_h ( ( hz_out3 + vert_out3 ) , 1 ) ; SAT_SH4_SH ( out0 , out1 , out2 , out3 , 7 ) ; tmp0 = PCKEV_XORI128_UB ( out0 , out1 ) ; tmp1 = PCKEV_XORI128_UB ( out2 , out3 ) ; ST8x4_UB ( tmp0 , tmp1 , dst , dst_stride ) ; dst + = ( 4 * dst_stride ) ; src_vt3 = src_vt7 ; src_vt1 = src_vt5 ; src_vt5 = src_vt4 ; src_vt4 = src_vt8 ; src_vt2 = src_vt6 ; src_vt0 = src_vt5 ; } }",0
"int av_packet_split_side_data ( AVPacket * pkt ) { if ( ! pkt - > side_data_elems & & pkt - > size > 12 & & AV_RB64 ( pkt - > data + pkt - > size - 8 ) == FF_MERGE_MARKER ) { int i ; unsigned int size , orig_pktsize = pkt - > size ; uint8_t * p ; p = pkt - > data + pkt - > size - 8 - 5 ; for ( i=1 ; ; i + + ) { size = AV_RB32 ( p ) ; if ( size > INT_MAX || p - pkt - > data < size ) return 0 ; if ( p[4] & 128 ) break ; p - = size + 5 ; } pkt - > side_data = av_malloc ( i * sizeof ( * pkt - > side_data ) ) ; if ( ! pkt - > side_data ) return AVERROR ( ENOMEM ) ; p= pkt - > data + pkt - > size - 8 - 5 ; for ( i=0 ; ; i + + ) { size= AV_RB32 ( p ) ; av_assert0 ( size < =INT_MAX & & p - pkt - > data > = size ) ; pkt - > side_data[i] . data = av_malloc ( size + FF_INPUT_BUFFER_PADDING_SIZE ) ; pkt - > side_data[i] . size = size ; pkt - > side_data[i] . type = p[4] & 127 ; if ( ! pkt - > side_data[i] . data ) return AVERROR ( ENOMEM ) ; memcpy ( pkt - > side_data[i] . data , p - size , size ) ; pkt - > size - = size + 5 ; if ( p[4] & 128 ) break ; p - = size + 5 ; } pkt - > size - = 8 ; / * FFMIN ( ) prevents overflow in case the packet wasn ' t allocated with * proper padding . * If the side data is smaller than the buffer padding size , the * remaining bytes should have already been filled with zeros by the * original packet allocation anyway . * / memset ( pkt - > data + pkt - > size , 0 , FFMIN ( orig_pktsize - pkt - > size , FF_INPUT_BUFFER_PADDING_SIZE ) ) ; pkt - > side_data_elems = i + 1 ; return 1 ; } return 0 ; }",0
"static int aasc_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; AascContext * s = avctx - > priv_data ; int compr , i , stride ; s - > frame . reference = 3 ; s - > frame . buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE ; if ( avctx - > reget_buffer ( avctx , & s - > frame ) ) { av_log ( avctx , AV_LOG_ERROR , reget_buffer ( ) failed\n ) ; return - 1 ; } compr = AV_RL32 ( buf ) ; buf + = 4 ; buf_size - = 4 ; switch ( avctx - > codec_tag ) { case MKTAG ( ' A ' , ' A ' , ' S ' , ' 4 ' ) : bytestream2_init ( & s - > gb , buf - 4 , buf_size + 4 ) ; ff_msrle_decode ( avctx , ( AVPicture * ) & s - > frame , 8 , & s - > gb ) ; break ; case MKTAG ( ' A ' , ' A ' , ' S ' , ' C ' ) : switch ( compr ) { case 0 : stride = ( avctx - > width * 3 + 3 ) & 3 ; for ( i = avctx - > height - 1 ; i > = 0 ; i - - ) { if ( avctx - > width * 3 > buf_size ) { av_log ( avctx , AV_LOG_ERROR , Next line is beyond buffer bounds\n ) ; break ; } memcpy ( s - > frame . data[0] + i * s - > frame . linesize[0] , buf , avctx - > width * 3 ) ; buf + = stride ; buf_size - = stride ; } break ; case 1 : bytestream2_init ( & s - > gb , buf , buf_size ) ; ff_msrle_decode ( avctx , ( AVPicture * ) & s - > frame , 8 , & s - > gb ) ; break ; default : av_log ( avctx , AV_LOG_ERROR , Unknown compression type %d\n , compr ) ; return - 1 ; } break ; default : av_log ( avctx , AV_LOG_ERROR , Unknown FourCC : %X\n , avctx - > codec_tag ) ; return - 1 ; } * data_size = sizeof ( AVFrame ) ; * ( AVFrame * ) data = s - > frame ; / * report that the buffer was completely consumed * / return buf_size ; }",0
"static int dxva_get_decoder_guid ( AVCodecContext * avctx , void * service , void * surface_format , unsigned guid_count , const GUID * guid_list , GUID * decoder_guid ) { FFDXVASharedContext * sctx = DXVA_SHARED_CONTEXT ( avctx ) ; unsigned i , j ; * decoder_guid = ff_GUID_NULL ; for ( i = 0 ; dxva_modes[i] . guid ; i + + ) { const dxva_mode * mode = & dxva_modes[i] ; int validate ; if ( mode - > codec ! = avctx - > codec_id ) continue ; for ( j = 0 ; j < guid_count ; j + + ) { if ( IsEqualGUID ( mode - > guid , & guid_list[j] ) ) break ; } if ( j == guid_count ) continue ; if CONFIG_D3D11VA if ( sctx - > pix_fmt == AV_PIX_FMT_D3D11 ) validate = d3d11va_validate_output ( service , * mode - > guid , surface_format ) ; endif if CONFIG_DXVA2 if ( sctx - > pix_fmt == AV_PIX_FMT_DXVA2_VLD ) validate = dxva2_validate_output ( service , * mode - > guid , surface_format ) ; endif if ( validate ) { * decoder_guid = * mode - > guid ; break ; } } if ( IsEqualGUID ( decoder_guid , & ff_GUID_NULL ) ) { av_log ( avctx , AV_LOG_VERBOSE , No decoder device for codec found\n ) ; return AVERROR ( EINVAL ) ; } if ( IsEqualGUID ( decoder_guid , & ff_DXVADDI_Intel_ModeH264_E ) ) sctx - > workaround |= FF_DXVA2_WORKAROUND_INTEL_CLEARVIDEO ; return 0 ; }",0
"static int decode_vol_header ( Mpeg4DecContext * ctx , GetBitContext * gb ) { MpegEncContext * s = & ctx - > m ; int width , height , vo_ver_id ; / * vol header * / skip_bits ( gb , 1 ) ; / * random access * / s - > vo_type = get_bits ( gb , 8 ) ; if ( get_bits1 ( gb ) ! = 0 ) { / * is_ol_id * / vo_ver_id = get_bits ( gb , 4 ) ; / * vo_ver_id * / skip_bits ( gb , 3 ) ; / * vo_priority * / } else { vo_ver_id = 1 ; } s - > aspect_ratio_info = get_bits ( gb , 4 ) ; if ( s - > aspect_ratio_info == FF_ASPECT_EXTENDED ) { s - > avctx - > sample_aspect_ratio . num = get_bits ( gb , 8 ) ; // par_width s - > avctx - > sample_aspect_ratio . den = get_bits ( gb , 8 ) ; // par_height } else { s - > avctx - > sample_aspect_ratio = ff_h263_pixel_aspect[s - > aspect_ratio_info] ; } if ( ( ctx - > vol_control_parameters = get_bits1 ( gb ) ) ) { / * vol control parameter * / int chroma_format = get_bits ( gb , 2 ) ; if ( chroma_format ! = CHROMA_420 ) av_log ( s - > avctx , AV_LOG_ERROR , illegal chroma format\n ) ; s - > low_delay = get_bits1 ( gb ) ; if ( get_bits1 ( gb ) ) { / * vbv parameters * / get_bits ( gb , 15 ) ; / * first_half_bitrate * / skip_bits1 ( gb ) ; / * marker * / get_bits ( gb , 15 ) ; / * latter_half_bitrate * / skip_bits1 ( gb ) ; / * marker * / get_bits ( gb , 15 ) ; / * first_half_vbv_buffer_size * / skip_bits1 ( gb ) ; / * marker * / get_bits ( gb , 3 ) ; / * latter_half_vbv_buffer_size * / get_bits ( gb , 11 ) ; / * first_half_vbv_occupancy * / skip_bits1 ( gb ) ; / * marker * / get_bits ( gb , 15 ) ; / * latter_half_vbv_occupancy * / skip_bits1 ( gb ) ; / * marker * / } } else { / * is setting low delay flag only once the smartest thing to do ? * low delay detection won ' t be overridden . * / if ( s - > picture_number == 0 ) s - > low_delay = 0 ; } ctx - > shape = get_bits ( gb , 2 ) ; / * vol shape * / if ( ctx - > shape ! = RECT_SHAPE ) av_log ( s - > avctx , AV_LOG_ERROR , only rectangular vol supported\n ) ; if ( ctx - > shape == GRAY_SHAPE & & vo_ver_id ! = 1 ) { av_log ( s - > avctx , AV_LOG_ERROR , Gray shape not supported\n ) ; skip_bits ( gb , 4 ) ; / * video_object_layer_shape_extension * / } check_marker ( gb , before time_increment_resolution ) ; s - > avctx - > framerate . num = get_bits ( gb , 16 ) ; if ( ! s - > avctx - > framerate . num ) { av_log ( s - > avctx , AV_LOG_ERROR , framerate==0\n ) ; return AVERROR_INVALIDDATA ; } ctx - > time_increment_bits = av_log2 ( s - > avctx - > framerate . num - 1 ) + 1 ; if ( ctx - > time_increment_bits < 1 ) ctx - > time_increment_bits = 1 ; check_marker ( gb , before fixed_vop_rate ) ; if ( get_bits1 ( gb ) ! = 0 ) / * fixed_vop_rate * / s - > avctx - > framerate . den = get_bits ( gb , ctx - > time_increment_bits ) ; else s - > avctx - > framerate . den = 1 ; s - > avctx - > time_base = av_inv_q ( av_mul_q ( s - > avctx - > framerate , ( AVRational ) { s - > avctx - > ticks_per_frame , 1 } ) ) ; ctx - > t_frame = 0 ; if ( ctx - > shape ! = BIN_ONLY_SHAPE ) { if ( ctx - > shape == RECT_SHAPE ) { check_marker ( gb , before width ) ; width = get_bits ( gb , 13 ) ; check_marker ( gb , before height ) ; height = get_bits ( gb , 13 ) ; check_marker ( gb , after height ) ; if ( width & & height & & / * they should be non zero but who knows * / ! ( s - > width & & s - > codec_tag == AV_RL32 ( MP4S ) ) ) { if ( s - > width & & s - > height & & ( s - > width ! = width || s - > height ! = height ) ) s - > context_reinit = 1 ; s - > width = width ; s - > height = height ; } } s - > progressive_sequence = s - > progressive_frame = get_bits1 ( gb ) 1 ; s - > interlaced_dct = 0 ; if ( ! get_bits1 ( gb ) & & ( s - > avctx - > debug & FF_DEBUG_PICT_INFO ) ) av_log ( s - > avctx , AV_LOG_INFO , / * OBMC Disable * / MPEG4 OBMC not supported ( very likely buggy encoder ) \n ) ; if ( vo_ver_id == 1 ) ctx - > vol_sprite_usage = get_bits1 ( gb ) ; / * vol_sprite_usage * / else ctx - > vol_sprite_usage = get_bits ( gb , 2 ) ; / * vol_sprite_usage * / if ( ctx - > vol_sprite_usage == STATIC_SPRITE ) av_log ( s - > avctx , AV_LOG_ERROR , Static Sprites not supported\n ) ; if ( ctx - > vol_sprite_usage == STATIC_SPRITE || ctx - > vol_sprite_usage == GMC_SPRITE ) { if ( ctx - > vol_sprite_usage == STATIC_SPRITE ) { skip_bits ( gb , 13 ) ; // sprite_width skip_bits1 ( gb ) ; / * marker * / skip_bits ( gb , 13 ) ; // sprite_height skip_bits1 ( gb ) ; / * marker * / skip_bits ( gb , 13 ) ; // sprite_left skip_bits1 ( gb ) ; / * marker * / skip_bits ( gb , 13 ) ; // sprite_top skip_bits1 ( gb ) ; / * marker * / } ctx - > num_sprite_warping_points = get_bits ( gb , 6 ) ; if ( ctx - > num_sprite_warping_points > 3 ) { av_log ( s - > avctx , AV_LOG_ERROR , %d sprite_warping_points\n , ctx - > num_sprite_warping_points ) ; ctx - > num_sprite_warping_points = 0 ; return AVERROR_INVALIDDATA ; } s - > sprite_warping_accuracy = get_bits ( gb , 2 ) ; ctx - > sprite_brightness_change = get_bits1 ( gb ) ; if ( ctx - > vol_sprite_usage == STATIC_SPRITE ) skip_bits1 ( gb ) ; //",0
"static int mmap_read_frame ( AVFormatContext * ctx , AVPacket * pkt ) { struct video_data * s = ctx - > priv_data ; struct v4l2_buffer buf = { . type = V4L2_BUF_TYPE_VIDEO_CAPTURE , . memory = V4L2_MEMORY_MMAP } ; struct pollfd p = { . fd = s - > fd , . events = POLLIN } ; int res ; res = poll ( & p , 1 , s - > timeout ) ; if ( res < 0 ) return AVERROR ( errno ) ; if ( ! ( p . revents & ( POLLIN | POLLERR | POLLHUP ) ) ) return AVERROR ( EAGAIN ) ; / * FIXME : Some special treatment might be needed in case of loss of signal . . . * / while ( ( res = ioctl ( s - > fd , VIDIOC_DQBUF , & buf ) ) < 0 & & ( errno == EINTR ) ) ; if ( res < 0 ) { if ( errno == EAGAIN ) { pkt - > size = 0 ; return AVERROR ( EAGAIN ) ; } av_log ( ctx , AV_LOG_ERROR , ioctl ( VIDIOC_DQBUF ) : %s\n , strerror ( errno ) ) ; return AVERROR ( errno ) ; } if ( buf . index > = s - > buffers ) { av_log ( ctx , AV_LOG_ERROR , Invalid buffer index received . \n ) ; return AVERROR ( EINVAL ) ; } avpriv_atomic_int_add_and_fetch ( & s - > buffers_queued , - 1 ) ; // always keep at least one buffer queued av_assert0 ( avpriv_atomic_int_get ( & s - > buffers_queued ) > = 1 ) ; if ( s - > frame_size > 0 & & buf . bytesused ! = s - > frame_size ) { av_log ( ctx , AV_LOG_ERROR , The v4l2 frame is %d bytes , but %d bytes are expected\n , buf . bytesused , s - > frame_size ) ; return AVERROR_INVALIDDATA ; } / * Image is at s - > buff_start[buf . index] * / if ( avpriv_atomic_int_get ( & s - > buffers_queued ) == FFMAX ( s - > buffers / 8 , 1 ) ) { / * when we start getting low on queued buffers , fall back on copying data * / res = av_new_packet ( pkt , buf . bytesused ) ; if ( res < 0 ) { av_log ( ctx , AV_LOG_ERROR , Error allocating a packet . \n ) ; return res ; } memcpy ( pkt - > data , s - > buf_start[buf . index] , buf . bytesused ) ; res = ioctl ( s - > fd , VIDIOC_QBUF , & buf ) ; if ( res < 0 ) { av_log ( ctx , AV_LOG_ERROR , ioctl ( VIDIOC_QBUF ) \n ) ; av_free_packet ( pkt ) ; return AVERROR ( errno ) ; } avpriv_atomic_int_add_and_fetch ( & s - > buffers_queued , 1 ) ; } else { struct buff_data * buf_descriptor ; pkt - > data = s - > buf_start[buf . index] ; pkt - > size = buf . bytesused ; if FF_API_DESTRUCT_PACKET FF_DISABLE_DEPRECATION_WARNINGS pkt - > destruct = dummy_release_buffer ; FF_ENABLE_DEPRECATION_WARNINGS endif buf_descriptor = av_malloc ( sizeof ( struct buff_data ) ) ; if ( buf_descriptor == NULL ) { / * Something went wrong . . . Since av_malloc ( ) failed , we cannot even * allocate a buffer for memcpying into it * / av_log ( ctx , AV_LOG_ERROR , Failed to allocate a buffer descriptor\n ) ; res = ioctl ( s - > fd , VIDIOC_QBUF , & buf ) ; return AVERROR ( ENOMEM ) ; } buf_descriptor - > fd = s - > fd ; buf_descriptor - > index = buf . index ; buf_descriptor - > s = s ; pkt - > buf = av_buffer_create ( pkt - > data , pkt - > size , mmap_release_buffer , buf_descriptor , 0 ) ; if ( ! pkt - > buf ) { av_freep ( & buf_descriptor ) ; return AVERROR ( ENOMEM ) ; } } pkt - > pts = buf . timestamp . tv_sec * INT64_C ( 1000000 ) + buf . timestamp . tv_usec ; return s - > buf_len[buf . index] ; }",0
"static int aac_encode_frame ( AVCodecContext * avctx , uint8_t * frame , int buf_size , void * data ) { AACEncContext * s = avctx - > priv_data ; int16_t * samples = s - > samples , * samples2 , * la ; ChannelElement * cpe ; int i , j , chans , tag , start_ch ; const uint8_t * chan_map = aac_chan_configs[avctx - > channels - 1] ; int chan_el_counter[4] ; FFPsyWindowInfo windows[avctx - > channels] ; if ( s - > last_frame ) return 0 ; if ( data ) { if ( ! s - > psypp ) { memcpy ( s - > samples + 1024 * avctx - > channels , data , 1024 * avctx - > channels * sizeof ( s - > samples[0] ) ) ; } else { start_ch = 0 ; samples2 = s - > samples + 1024 * avctx - > channels ; for ( i = 0 ; i < chan_map[0] ; i + + ) { tag = chan_map[i + 1] ; chans = tag == TYPE_CPE ? 2 : 1 ; ff_psy_preprocess ( s - > psypp , ( uint16_t * ) data + start_ch , samples2 + start_ch , start_ch , chans ) ; start_ch + = chans ; } } } if ( ! avctx - > frame_number ) { memcpy ( s - > samples , s - > samples + 1024 * avctx - > channels , 1024 * avctx - > channels * sizeof ( s - > samples[0] ) ) ; return 0 ; } start_ch = 0 ; for ( i = 0 ; i < chan_map[0] ; i + + ) { FFPsyWindowInfo * wi = windows + start_ch ; tag = chan_map[i + 1] ; chans = tag == TYPE_CPE ? 2 : 1 ; cpe = & s - > cpe[i] ; samples2 = samples + start_ch ; la = samples2 + 1024 * avctx - > channels + start_ch ; if ( ! data ) la = NULL ; for ( j = 0 ; j < chans ; j + + ) { IndividualChannelStream * ics = & cpe - > ch[j] . ics ; int k ; wi[j] = ff_psy_suggest_window ( & s - > psy , samples2 , la , start_ch + j , ics - > window_sequence[0] ) ; ics - > window_sequence[1] = ics - > window_sequence[0] ; ics - > window_sequence[0] = wi[j] . window_type[0] ; ics - > use_kb_window[1] = ics - > use_kb_window[0] ; ics - > use_kb_window[0] = wi[j] . window_shape ; ics - > num_windows = wi[j] . num_windows ; ics - > swb_sizes = s - > psy . bands [ics - > num_windows == 8] ; ics - > num_swb = s - > psy . num_bands[ics - > num_windows == 8] ; for ( k = 0 ; k < ics - > num_windows ; k + + ) ics - > group_len[k] = wi[j] . grouping[k] ; s - > cur_channel = start_ch + j ; apply_window_and_mdct ( avctx , s , & cpe - > ch[j] , samples2 , j ) ; } start_ch + = chans ; } init_put_bits ( & s - > pb , frame , buf_size * 8 ) ; if ( ( avctx - > frame_number & 0xFF ) ==1 & & ! ( avctx - > flags & CODEC_FLAG_BITEXACT ) ) put_bitstream_info ( avctx , s , LIBAVCODEC_IDENT ) ; start_ch = 0 ; memset ( chan_el_counter , 0 , sizeof ( chan_el_counter ) ) ; for ( i = 0 ; i < chan_map[0] ; i + + ) { FFPsyWindowInfo * wi = windows + start_ch ; tag = chan_map[i + 1] ; chans = tag == TYPE_CPE ? 2 : 1 ; cpe = & s - > cpe[i] ; for ( j = 0 ; j < chans ; j + + ) { s - > coder - > search_for_quantizers ( avctx , s , & cpe - > ch[j] , s - > lambda ) ; } cpe - > common_window = 0 ; if ( chans > 1 & & wi[0] . window_type[0] == wi[1] . window_type[0] & & wi[0] . window_shape == wi[1] . window_shape ) { cpe - > common_window = 1 ; for ( j = 0 ; j < wi[0] . num_windows ; j + + ) { if ( wi[0] . grouping[j] ! = wi[1] . grouping[j] ) { cpe - > common_window = 0 ; break ; } } } if ( cpe - > common_window & & s - > coder - > search_for_ms ) s - > coder - > search_for_ms ( s , cpe , s - > lambda ) ; adjust_frame_information ( s , cpe , chans ) ; put_bits ( & s - > pb , 3 , tag ) ; put_bits ( & s - > pb , 4 , chan_el_counter[tag] + + ) ; if ( chans == 2 ) { put_bits ( & s - > pb , 1 , cpe - > common_window ) ; if ( cpe - > common_window ) { put_ics_info ( s , & cpe - > ch[0] . ics ) ; encode_ms_info ( & s - > pb , cpe ) ; } } for ( j = 0 ; j < chans ; j + + ) { s - > cur_channel = start_ch + j ; ff_psy_set_band_info ( & s - > psy , s - > cur_channel , cpe - > ch[j] . coeffs , & wi[j] ) ; encode_individual_channel ( avctx , s , & cpe - > ch[j] , cpe - > common_window ) ; } start_ch + = chans ; } put_bits ( & s - > pb , 3 , TYPE_END ) ; flush_put_bits ( & s - > pb ) ; avctx - > frame_bits = put_bits_count ( & s - > pb ) ; // rate control stuff if ( ! ( avctx - > flags & CODEC_FLAG_QSCALE ) ) { float ratio = avctx - > bit_rate * 1024 . 0f / avctx - > sample_rate / avctx - > frame_bits ; s - > lambda * = ratio ; s - > lambda = fminf ( s - > lambda , 65536 . f ) ; } if ( avctx - > frame_bits > 6144 * avctx - > channels ) av_log ( avctx , AV_LOG_ERROR , input buffer violation %d > %d . \n , avctx - > frame_bits , 6144 * avctx - > channels ) ; if ( ! data ) s - > last_frame = 1 ; memcpy ( s - > samples , s - > samples + 1024 * avctx - > channels , 1024 * avctx - > channels * sizeof ( s - > samples[0] ) ) ; return put_bits_count ( & s - > pb ) > > 3 ; }",1
"static int vc1_decode_intra_block ( VC1Context * v , DCTELEM block[64] , int n , int coded , int mquant , int codingset ) { GetBitContext * gb = & v - > s . gb ; MpegEncContext * s = & v - > s ; int dc_pred_dir = 0 ; / * Direction of the DC prediction used * / int run_diff , i ; int16_t * dc_val ; int16_t * ac_val , * ac_val2 ; int dcdiff ; int mb_pos = s - > mb_x + s - > mb_y * s - > mb_stride ; int a_avail , c_avail ; / * XXX : Guard against dumb values of mquant * / mquant = ( mquant < 1 ) ? 0 : ( ( mquant > 31 ) ? 31 : mquant ) ; / * Set DC scale - y and c use the same * / s - > y_dc_scale = s - > y_dc_scale_table[mquant] ; s - > c_dc_scale = s - > c_dc_scale_table[mquant] ; / * check if prediction blocks A and C are available * / a_avail = c_avail = 0 ; if ( ( n == 2 || n == 3 ) || ( s - > mb_y & & IS_INTRA ( s - > current_picture . mb_type[mb_pos - s - > mb_stride] ) ) ) a_avail = 1 ; if ( ( n == 1 || n == 3 ) || ( s - > mb_x & & IS_INTRA ( s - > current_picture . mb_type[mb_pos - 1] ) ) ) c_avail = 1 ; / * Get DC differential * / if ( n < 4 ) { dcdiff = get_vlc2 ( & s - > gb , ff_msmp4_dc_luma_vlc[s - > dc_table_index] . table , DC_VLC_BITS , 3 ) ; } else { dcdiff = get_vlc2 ( & s - > gb , ff_msmp4_dc_chroma_vlc[s - > dc_table_index] . table , DC_VLC_BITS , 3 ) ; } if ( dcdiff < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , Illegal DC VLC\n ) ; return - 1 ; } if ( dcdiff ) { if ( dcdiff == 119 / * ESC index value * / ) { / * TODO : Optimize * / if ( mquant == 1 ) dcdiff = get_bits ( gb , 10 ) ; else if ( mquant == 2 ) dcdiff = get_bits ( gb , 9 ) ; else dcdiff = get_bits ( gb , 8 ) ; } else { if ( mquant == 1 ) dcdiff = ( dcdiff < < 2 ) + get_bits ( gb , 2 ) - 3 ; else if ( mquant == 2 ) dcdiff = ( dcdiff < < 1 ) + get_bits ( gb , 1 ) - 1 ; } if ( get_bits ( gb , 1 ) ) dcdiff = - dcdiff ; } / * Prediction * / dcdiff + = vc1_pred_dc ( & v - > s , v - > overlap , mquant , n , a_avail , c_avail , & dc_val , & dc_pred_dir ) ; * dc_val = dcdiff ; / * Store the quantized DC coeff , used for prediction * / if ( n < 4 ) { block[0] = dcdiff * s - > y_dc_scale ; } else { block[0] = dcdiff * s - > c_dc_scale ; } / * Skip ? * / run_diff = 0 ; i = 0 ; if ( ! coded ) { goto not_coded ; } //AC Decoding i = 1 ; { int last = 0 , skip , value ; const int8_t * zz_table ; int scale ; int k ; scale = mquant * 2 + v - > halfpq ; zz_table = vc1_simple_progressive_8x8_zz ; ac_val = s - > ac_val[0][0] + s - > block_index[n] * 16 ; ac_val2 = ac_val ; if ( dc_pred_dir ) //left ac_val - = 16 ; else //top ac_val - = 16 * s - > block_wrap[n] ; while ( ! last ) { vc1_decode_ac_coeff ( v , & last , & skip , & value , codingset ) ; i + = skip ; if ( i > 63 ) break ; block[zz_table[i + + ]] = value ; } / * apply AC prediction if needed * / if ( s - > ac_pred ) { / * scale predictors if needed * / int mb_pos2 , q1 , q2 ; mb_pos2 = mb_pos - dc_pred_dir - ( 1 - dc_pred_dir ) * s - > mb_stride ; q1 = s - > current_picture . qscale_table[mb_pos] ; q2 = s - > current_picture . qscale_table[mb_pos2] ; if ( ! c_avail ) { memset ( ac_val , 0 , 8 * sizeof ( ac_val[0] ) ) ; dc_pred_dir = 0 ; } if ( ! a_avail ) { memset ( ac_val + 8 , 0 , 8 * sizeof ( ac_val[0] ) ) ; dc_pred_dir = 1 ; } if ( ! q1 & & q1 & & q2 & & q1 ! = q2 ) { q1 = q1 * 2 - 1 ; q2 = q2 * 2 - 1 ; if ( dc_pred_dir ) { //left for ( k = 1 ; k < 8 ; k + + ) block[k < < 3] + = ( ac_val[k] * q2 * vc1_dqscale[q1 - 1] + 0x20000 ) > > 18 ; } else { //top for ( k = 1 ; k < 8 ; k + + ) block[k] + = ( ac_val[k + 8] * q2 * vc1_dqscale[q1 - 1] + 0x20000 ) > > 18 ; } } else { if ( dc_pred_dir ) { //left for ( k = 1 ; k < 8 ; k + + ) block[k < < 3] + = ac_val[k] ; } else { //top for ( k = 1 ; k < 8 ; k + + ) block[k] + = ac_val[k + 8] ; } } } / * save AC coeffs for further prediction * / for ( k = 1 ; k < 8 ; k + + ) { ac_val2[k] = block[k < < 3] ; ac_val2[k + 8] = block[k] ; } / * scale AC coeffs * / for ( k = 1 ; k < 64 ; k + + ) if ( block[k] ) { block[k] * = scale ; if ( ! v - > pquantizer ) block[k] + = ( block[k] < 0 ) ? - mquant : mquant ; } if ( s - > ac_pred ) i = 63 ; } not_coded : if ( ! coded ) { int k , scale ; ac_val = s - > ac_val[0][0] + s - > block_index[n] * 16 ; ac_val2 = ac_val ; if ( ! c_avail ) { memset ( ac_val , 0 , 8 * sizeof ( ac_val[0] ) ) ; dc_pred_dir = 0 ; } if ( ! a_avail ) { memset ( ac_val + 8 , 0 , 8 * sizeof ( ac_val[0] ) ) ; dc_pred_dir = 1 ; }",0
"static int vp3_decode_end ( AVCodecContext * avctx ) { Vp3DecodeContext * s = avctx - > priv_data ; av_free ( s - > all_fragments ) ; av_free ( s - > coded_fragment_list ) ; av_free ( s - > superblock_fragments ) ; av_free ( s - > superblock_macroblocks ) ; av_free ( s - > macroblock_fragments ) ; av_free ( s - > macroblock_coded ) ; / * release all frames * / avctx - > release_buffer ( avctx , & s - > golden_frame ) ; avctx - > release_buffer ( avctx , & s - > last_frame ) ; avctx - > release_buffer ( avctx , & s - > current_frame ) ; return 0 ; }",0
"SchroFrame * ff_create_schro_frame ( AVCodecContext * avccontext , SchroFrameFormat schro_frame_fmt ) { AVPicture * p_pic ; SchroFrame * p_frame ; int y_width , uv_width ; int y_height , uv_height ; int i ; y_width = avccontext - > width ; y_height = avccontext - > height ; uv_width = y_width > > ( SCHRO_FRAME_FORMAT_H_SHIFT ( schro_frame_fmt ) ) ; uv_height = y_height > > ( SCHRO_FRAME_FORMAT_V_SHIFT ( schro_frame_fmt ) ) ; p_pic = av_mallocz ( sizeof ( AVPicture ) ) ; avpicture_alloc ( p_pic , avccontext - > pix_fmt , y_width , y_height ) ; p_frame = schro_frame_new ( ) ; p_frame - > format = schro_frame_fmt ; p_frame - > width = y_width ; p_frame - > height = y_height ; schro_frame_set_free_callback ( p_frame , free_schro_frame , ( void * ) p_pic ) ; for ( i = 0 ; i < 3 ; + + i ) { p_frame - > components[i] . width = i ? uv_width : y_width ; p_frame - > components[i] . stride = p_pic - > linesize[i] ; p_frame - > components[i] . height = i ? uv_height : y_height ; p_frame - > components[i] . length = p_frame - > components[i] . stride * p_frame - > components[i] . height ; p_frame - > components[i] . data = p_pic - > data[i] ; if ( i ) { p_frame - > components[i] . v_shift = SCHRO_FRAME_FORMAT_V_SHIFT ( p_frame - > format ) ; p_frame - > components[i] . h_shift = SCHRO_FRAME_FORMAT_H_SHIFT ( p_frame - > format ) ; } } return p_frame ; }",1
"static int ffm_seek ( AVFormatContext * s , int stream_index , int64_t wanted_pts , int flags ) { FFMContext * ffm = s - > priv_data ; int64_t pos_min , pos_max , pos ; int64_t pts_min , pts_max , pts ; double pos1 ; av_dlog ( s , wanted_pts=%0 . 6f\n , wanted_pts / 1000000 . 0 ) ; / * find the position using linear interpolation ( better than dichotomy in typical cases ) * / if ( ffm - > write_index & & ffm - > write_index < ffm - > file_size ) { if ( get_dts ( s , FFM_PACKET_SIZE ) < wanted_pts ) { pos_min = FFM_PACKET_SIZE ; pos_max = ffm - > write_index - FFM_PACKET_SIZE ; } else { pos_min = ffm - > write_index ; pos_max = ffm - > file_size - FFM_PACKET_SIZE ; } } else { pos_min = FFM_PACKET_SIZE ; pos_max = ffm - > file_size - FFM_PACKET_SIZE ; } while ( pos_min < = pos_max ) { pts_min = get_dts ( s , pos_min ) ; pts_max = get_dts ( s , pos_max ) ; if ( pts_min > wanted_pts || pts_max < = wanted_pts ) { pos = pts_min > wanted_pts ? pos_min : pos_max ; goto found ; } / * linear interpolation * / pos1 = ( double ) ( pos_max - pos_min ) * ( double ) ( wanted_pts - pts_min ) / ( double ) ( pts_max - pts_min ) ; pos = ( ( ( int64_t ) pos1 ) / FFM_PACKET_SIZE ) * FFM_PACKET_SIZE ; if ( pos < = pos_min ) pos = pos_min ; else if ( pos > = pos_max ) pos = pos_max ; pts = get_dts ( s , pos ) ; / * check if we are lucky * / if ( pts == wanted_pts ) { goto found ; } else if ( pts > wanted_pts ) { pos_max = pos - FFM_PACKET_SIZE ; } else { pos_min = pos + FFM_PACKET_SIZE ; } } pos = ( flags & AVSEEK_FLAG_BACKWARD ) ? pos_min : pos_max ; found : if ( ffm_seek1 ( s , pos ) < 0 ) return - 1 ; / * reset read state * / ffm - > read_state = READ_HEADER ; ffm - > packet_ptr = ffm - > packet ; ffm - > packet_end = ffm - > packet ; ffm - > first_packet = 1 ; return 0 ; }",0
"static inline void RENAME ( rgb16tobgr24 ) ( const uint8_t * src , uint8_t * dst , int src_size ) { const uint16_t * end ; const uint16_t * mm_end ; uint8_t * d = ( uint8_t * ) dst ; const uint16_t * s = ( const uint16_t * ) src ; end = s + src_size/2 ; __asm__ volatile ( PREFETCH %0 : : m ( * s ) : memory ) ; mm_end = end - 7 ; while ( s < mm_end ) { __asm__ volatile ( PREFETCH 32%1 \n\t movq %1 , %%mm0 \n\t movq %1 , %%mm1 \n\t movq %1 , %%mm2 \n\t pand %2 , %%mm0 \n\t pand %3 , %%mm1 \n\t pand %4 , %%mm2 \n\t psllq 3 , %%mm0 \n\t psrlq 3 , %%mm1 \n\t psrlq 8 , %%mm2 \n\t movq %%mm0 , %%mm3 \n\t movq %%mm1 , %%mm4 \n\t movq %%mm2 , %%mm5 \n\t punpcklwd %5 , %%mm0 \n\t punpcklwd %5 , %%mm1 \n\t punpcklwd %5 , %%mm2 \n\t punpckhwd %5 , %%mm3 \n\t punpckhwd %5 , %%mm4 \n\t punpckhwd %5 , %%mm5 \n\t psllq 8 , %%mm1 \n\t psllq 16 , %%mm2 \n\t por %%mm1 , %%mm0 \n\t por %%mm2 , %%mm0 \n\t psllq 8 , %%mm4 \n\t psllq 16 , %%mm5 \n\t por %%mm4 , %%mm3 \n\t por %%mm5 , %%mm3 \n\t movq %%mm0 , %%mm6 \n\t movq %%mm3 , %%mm7 \n\t movq 8%1 , %%mm0 \n\t movq 8%1 , %%mm1 \n\t movq 8%1 , %%mm2 \n\t pand %2 , %%mm0 \n\t pand %3 , %%mm1 \n\t pand %4 , %%mm2 \n\t psllq 3 , %%mm0 \n\t psrlq 3 , %%mm1 \n\t psrlq 8 , %%mm2 \n\t movq %%mm0 , %%mm3 \n\t movq %%mm1 , %%mm4 \n\t movq %%mm2 , %%mm5 \n\t punpcklwd %5 , %%mm0 \n\t punpcklwd %5 , %%mm1 \n\t punpcklwd %5 , %%mm2 \n\t punpckhwd %5 , %%mm3 \n\t punpckhwd %5 , %%mm4 \n\t punpckhwd %5 , %%mm5 \n\t psllq 8 , %%mm1 \n\t psllq 16 , %%mm2 \n\t por %%mm1 , %%mm0 \n\t por %%mm2 , %%mm0 \n\t psllq 8 , %%mm4 \n\t psllq 16 , %%mm5 \n\t por %%mm4 , %%mm3 \n\t por %%mm5 , %%mm3 \n\t : =m ( * d ) : m ( * s ) , m ( mask16b ) , m ( mask16g ) , m ( mask16r ) , m ( mmx_null ) : memory ) ; / * borrowed 32 to 24 * / __asm__ volatile ( movq %%mm0 , %%mm4 \n\t movq %%mm3 , %%mm5 \n\t movq %%mm6 , %%mm0 \n\t movq %%mm7 , %%mm1 \n\t movq %%mm4 , %%mm6 \n\t movq %%mm5 , %%mm7 \n\t movq %%mm0 , %%mm2 \n\t movq %%mm1 , %%mm3 \n\t STORE_BGR24_MMX : =m ( * d ) : m ( * s ) : memory ) ; d + = 24 ; s + = 8 ; } __asm__ volatile ( SFENCE : : : memory ) ; __asm__ volatile ( EMMS : : : memory ) ; while ( s < end ) { register uint16_t bgr ; bgr = * s + + ; * d + + = ( bgr & 0x1F ) < < 3 ; * d + + = ( bgr & 0x7E0 ) > > 3 ; * d + + = ( bgr & 0xF800 ) > > 8 ; } }",1
"int ff_h264_field_end ( H264Context * h , int in_setup ) { AVCodecContext * const avctx = h - > avctx ; int err = 0 ; h - > mb_y = 0 ; if ( CONFIG_H264_VDPAU_DECODER & & h - > avctx - > codec - > capabilities & CODEC_CAP_HWACCEL_VDPAU ) ff_vdpau_h264_set_reference_frames ( h ) ; if ( in_setup || ! ( avctx - > active_thread_type & FF_THREAD_FRAME ) ) { if ( ! h - > droppable ) { err = ff_h264_execute_ref_pic_marking ( h , h - > mmco , h - > mmco_index ) ; h - > prev_poc_msb = h - > poc_msb ; h - > prev_poc_lsb = h - > poc_lsb ; } h - > prev_frame_num_offset = h - > frame_num_offset ; h - > prev_frame_num = h - > frame_num ; h - > outputed_poc = h - > next_outputed_poc ; } if ( avctx - > hwaccel ) { if ( avctx - > hwaccel - > end_frame ( avctx ) < 0 ) av_log ( avctx , AV_LOG_ERROR , hardware accelerator failed to decode picture\n ) ; } if ( CONFIG_H264_VDPAU_DECODER & & h - > avctx - > codec - > capabilities & CODEC_CAP_HWACCEL_VDPAU ) ff_vdpau_h264_picture_complete ( h ) ; if CONFIG_ERROR_RESILIENCE / * * FIXME : Error handling code does not seem to support interlaced * when slices span multiple rows * The ff_er_add_slice calls don ' t work right for bottom * fields ; they cause massive erroneous error concealing * Error marking covers both fields ( top and bottom ) . * This causes a mismatched s - > error_count * and a bad error table . Further , the error count goes to * INT_MAX when called for bottom field , because mb_y is * past end by one ( callers fault ) and resync_mb_y ! = 0 * causes problems for the first MB line , too . * / if ( ! FIELD_PICTURE ( h ) & & h - > current_slice & & ! h - > sps . new ) { ff_h264_set_erpic ( & h - > er . cur_pic , h - > cur_pic_ptr ) ; ff_er_frame_end ( & h - > er ) ; } endif / * CONFIG_ERROR_RESILIENCE * / if ( ! in_setup & & ! h - > droppable ) ff_thread_report_progress ( & h - > cur_pic_ptr - > tf , INT_MAX , h - > picture_structure == PICT_BOTTOM_FIELD ) ; emms_c ( ) ; h - > current_slice = 0 ; return err ; }",1
"double av_int2dbl ( int64_t v ) { if ( v + v > 0xFFEULL < < 52 ) return NAN ; return ldexp ( ( ( v & ( ( 1LL < < 52 ) - 1 ) ) + ( 1LL < < 52 ) ) * ( v > > 63|1 ) , ( v > > 52 & 0x7FF ) - 1075 ) ; }",1
"static inline int mxf_read_utf16_string ( AVIOContext * pb , int size , char * * str , int be ) { int ret ; size_t buf_size ; if ( size < 0 ) return AVERROR ( EINVAL ) ; buf_size = size + size / 2 + 1 ; * str = av_malloc ( buf_size ) ; if ( ! * str ) return AVERROR ( ENOMEM ) ; if ( be ) ret = avio_get_str16be ( pb , size , * str , buf_size ) ; else ret = avio_get_str16le ( pb , size , * str , buf_size ) ; if ( ret < 0 ) { av_freep ( str ) ; return ret ; } return ret ; }",1
"static void synth_block_fcb_acb ( WMAVoiceContext * s , GetBitContext * gb , int block_idx , int size , int block_pitch_sh2 , const struct frame_type_desc * frame_desc , float * excitation ) { static const float gain_coeff[6] = { 0 . 8169 , - 0 . 06545 , 0 . 1726 , 0 . 0185 , - 0 . 0359 , 0 . 0458 } ; float pulses[MAX_FRAMESIZE / 2] , pred_err , acb_gain , fcb_gain ; int n , idx , gain_weight ; AMRFixed fcb ; assert ( size < = MAX_FRAMESIZE / 2 ) ; memset ( pulses , 0 , sizeof ( * pulses ) * size ) ; fcb . pitch_lag = block_pitch_sh2 > > 2 ; fcb . pitch_fac = 1 . 0 ; fcb . no_repeat_mask = 0 ; fcb . n = 0 ; / * For the other frame types , this is where we apply the innovation * ( fixed ) codebook pulses of the speech signal . * / if ( frame_desc - > fcb_type == FCB_TYPE_AW_PULSES ) { aw_pulse_set1 ( s , gb , block_idx , & fcb ) ; aw_pulse_set2 ( s , gb , block_idx , & fcb ) ; } else / * FCB_TYPE_EXC_PULSES * / { int offset_nbits = 5 - frame_desc - > log_n_blocks ; fcb . no_repeat_mask = - 1 ; / * similar to ff_decode_10_pulses_35bits ( ) , but with single pulses * ( instead of double ) for a subset of pulses * / for ( n = 0 ; n < 5 ; n + + ) { float sign ; int pos1 , pos2 ; sign = get_bits1 ( gb ) ? 1 . 0 : - 1 . 0 ; pos1 = get_bits ( gb , offset_nbits ) ; fcb . x[fcb . n] = n + 5 * pos1 ; fcb . y[fcb . n + + ] = sign ; if ( n < frame_desc - > dbl_pulses ) { pos2 = get_bits ( gb , offset_nbits ) ; fcb . x[fcb . n] = n + 5 * pos2 ; fcb . y[fcb . n + + ] = ( pos1 < pos2 ) ? - sign : sign ; } } } ff_set_fixed_vector ( pulses , & fcb , 1 . 0 , size ) ; / * Calculate gain for adaptive & fixed codebook signal . * see ff_amr_set_fixed_gain ( ) . * / idx = get_bits ( gb , 7 ) ; fcb_gain = expf ( avpriv_scalarproduct_float_c ( s - > gain_pred_err , gain_coeff , 6 ) - 5 . 2409161640 + wmavoice_gain_codebook_fcb[idx] ) ; acb_gain = wmavoice_gain_codebook_acb[idx] ; pred_err = av_clipf ( wmavoice_gain_codebook_fcb[idx] , - 2 . 9957322736 / * log ( 0 . 05 ) * / , 1 . 6094379124 / * log ( 5 . 0 ) * / ) ; gain_weight = 8 > > frame_desc - > log_n_blocks ; memmove ( & s - > gain_pred_err[gain_weight] , s - > gain_pred_err , sizeof ( * s - > gain_pred_err ) * ( 6 - gain_weight ) ) ; for ( n = 0 ; n < gain_weight ; n + + ) s - > gain_pred_err[n] = pred_err ; / * Calculation of adaptive codebook * / if ( frame_desc - > acb_type == ACB_TYPE_ASYMMETRIC ) { int len ; for ( n = 0 ; n < size ; n + = len ) { int next_idx_sh16 ; int abs_idx = block_idx * size + n ; int pitch_sh16 = ( s - > last_pitch_val < < 16 ) + s - > pitch_diff_sh16 * abs_idx ; int pitch = ( pitch_sh16 + 0x6FFF ) > > 16 ; int idx_sh16 = ( ( pitch < < 16 ) - pitch_sh16 ) * 8 + 0x58000 ; idx = idx_sh16 > > 16 ; if ( s - > pitch_diff_sh16 ) { if ( s - > pitch_diff_sh16 > 0 ) { next_idx_sh16 = ( idx_sh16 ) & 0xFFFF ; } else next_idx_sh16 = ( idx_sh16 + 0x10000 ) & 0xFFFF ; len = av_clip ( ( idx_sh16 - next_idx_sh16 ) / s - > pitch_diff_sh16 / 8 , 1 , size - n ) ; } else len = size ; ff_acelp_interpolatef ( & excitation[n] , & excitation[n - pitch] , wmavoice_ipol1_coeffs , 17 , idx , 9 , len ) ; } } else / * ACB_TYPE_HAMMING * / { int block_pitch = block_pitch_sh2 > > 2 ; idx = block_pitch_sh2 & 3 ; if ( idx ) { ff_acelp_interpolatef ( excitation , & excitation[ - block_pitch] , wmavoice_ipol2_coeffs , 4 , idx , 8 , size ) ; } else av_memcpy_backptr ( ( uint8_t * ) excitation , sizeof ( float ) * block_pitch , sizeof ( float ) * size ) ; } / * Interpolate ACB/FCB and use as excitation signal * / ff_weighted_vector_sumf ( excitation , excitation , pulses , acb_gain , fcb_gain , size ) ; }",1
"void url_split ( char * proto , int proto_size , char * hostname , int hostname_size , int * port_ptr , char * path , int path_size , const char * url ) { const char * p ; char * q ; int port ; port = - 1 ; p = url ; q = proto ; while ( * p ! = ' : ' & & * p ! = ' \0 ' ) { if ( ( q - proto ) < proto_size - 1 ) * q + + = * p ; p + + ; } if ( proto_size > 0 ) * q = ' \0 ' ; if ( * p == ' \0 ' ) { if ( proto_size > 0 ) proto[0] = ' \0 ' ; if ( hostname_size > 0 ) hostname[0] = ' \0 ' ; p = url ; } else { p + + ; if ( * p == ' / ' ) p + + ; if ( * p == ' / ' ) p + + ; q = hostname ; while ( * p ! = ' : ' & & * p ! = ' / ' & & * p ! = ' ? ' & & * p ! = ' \0 ' ) { if ( ( q - hostname ) < hostname_size - 1 ) * q + + = * p ; p + + ; } if ( hostname_size > 0 ) * q = ' \0 ' ; if ( * p == ' : ' ) { p + + ; port = strtoul ( p , ( char * * ) & p , 10 ) ; } } if ( port_ptr ) * port_ptr = port ; pstrcpy ( path , path_size , p ) ; }",0
"static unsigned long iv_decode_frame ( Indeo3DecodeContext * s , const uint8_t * buf , int buf_size ) { unsigned int image_width , image_height , chroma_width , chroma_height ; unsigned long flags , cb_offset , data_size , y_offset , v_offset , u_offset , mc_vector_count ; const uint8_t * hdr_pos , * buf_pos ; buf_pos = buf ; buf_pos + = 18 ; / * skip OS header ( 16 bytes ) and version number * / flags = bytestream_get_le16 ( & buf_pos ) ; data_size = bytestream_get_le32 ( & buf_pos ) ; cb_offset = * buf_pos + + ; buf_pos + = 3 ; / * skip reserved byte and checksum * / image_height = bytestream_get_le16 ( & buf_pos ) ; image_width = bytestream_get_le16 ( & buf_pos ) ; if ( avcodec_check_dimensions ( NULL , image_width , image_height ) ) return - 1 ; chroma_height = ( ( image_height > > 2 ) + 3 ) & 0x7ffc ; chroma_width = ( ( image_width > > 2 ) + 3 ) & 0x7ffc ; y_offset = bytestream_get_le32 ( & buf_pos ) ; v_offset = bytestream_get_le32 ( & buf_pos ) ; u_offset = bytestream_get_le32 ( & buf_pos ) ; buf_pos + = 4 ; / * reserved * / hdr_pos = buf_pos ; if ( data_size == 0x80 ) return 4 ; if ( flags & 0x200 ) { s - > cur_frame = s - > iv_frame + 1 ; s - > ref_frame = s - > iv_frame ; } else { s - > cur_frame = s - > iv_frame ; s - > ref_frame = s - > iv_frame + 1 ; } buf_pos = buf + 16 + y_offset ; mc_vector_count = bytestream_get_le32 ( & buf_pos ) ; iv_Decode_Chunk ( s , s - > cur_frame - > Ybuf , s - > ref_frame - > Ybuf , image_width , image_height , buf_pos + mc_vector_count * 2 , cb_offset , hdr_pos , buf_pos , FFMIN ( image_width , 160 ) ) ; if ( ! ( s - > avctx - > flags & CODEC_FLAG_GRAY ) ) { buf_pos = buf + 16 + v_offset ; mc_vector_count = bytestream_get_le32 ( & buf_pos ) ; iv_Decode_Chunk ( s , s - > cur_frame - > Vbuf , s - > ref_frame - > Vbuf , chroma_width , chroma_height , buf_pos + mc_vector_count * 2 , cb_offset , hdr_pos , buf_pos , FFMIN ( chroma_width , 40 ) ) ; buf_pos = buf + 16 + u_offset ; mc_vector_count = bytestream_get_le32 ( & buf_pos ) ; iv_Decode_Chunk ( s , s - > cur_frame - > Ubuf , s - > ref_frame - > Ubuf , chroma_width , chroma_height , buf_pos + mc_vector_count * 2 , cb_offset , hdr_pos , buf_pos , FFMIN ( chroma_width , 40 ) ) ; } return 8 ; }",0
"static void rtsp_send_cmd_async ( AVFormatContext * s , const char * cmd , RTSPMessageHeader * reply , unsigned char * * content_ptr ) { RTSPState * rt = s - > priv_data ; char buf[4096] , buf1[1024] ; rt - > seq + + ; av_strlcpy ( buf , cmd , sizeof ( buf ) ) ; snprintf ( buf1 , sizeof ( buf1 ) , CSeq : %d\r\n , rt - > seq ) ; av_strlcat ( buf , buf1 , sizeof ( buf ) ) ; if ( rt - > session_id[0] ! = ' \0 ' & & ! strstr ( cmd , \nIf - Match : ) ) { snprintf ( buf1 , sizeof ( buf1 ) , Session : %s\r\n , rt - > session_id ) ; av_strlcat ( buf , buf1 , sizeof ( buf ) ) ; } if ( rt - > auth_b64 ) av_strlcatf ( buf , sizeof ( buf ) , Authorization : Basic %s\r\n , rt - > auth_b64 ) ; av_strlcat ( buf , \r\n , sizeof ( buf ) ) ; dprintf ( s , Sending : \n%s - - \n , buf ) ; url_write ( rt - > rtsp_hd , buf , strlen ( buf ) ) ; rt - > last_cmd_time = av_gettime ( ) ; }",0
"static void apply_channel_coupling ( AC3EncodeContext * s ) { LOCAL_ALIGNED_16 ( CoefType , cpl_coords , [AC3_MAX_BLOCKS] , [AC3_MAX_CHANNELS][16] ) ; if CONFIG_AC3ENC_FLOAT LOCAL_ALIGNED_16 ( int32_t , fixed_cpl_coords , [AC3_MAX_BLOCKS] , [AC3_MAX_CHANNELS][16] ) ; else int32_t ( * fixed_cpl_coords ) [AC3_MAX_CHANNELS][16] = cpl_coords ; endif int blk , ch , bnd , i , j ; CoefSumType energy[AC3_MAX_BLOCKS][AC3_MAX_CHANNELS][16] = { { { 0 } } } ; int cpl_start , num_cpl_coefs ; memset ( cpl_coords , 0 , AC3_MAX_BLOCKS * sizeof ( * cpl_coords ) ) ; if CONFIG_AC3ENC_FLOAT memset ( fixed_cpl_coords , 0 , AC3_MAX_BLOCKS * sizeof ( * cpl_coords ) ) ; endif / * align start to 16 - byte boundary . align length to multiple of 32 . note : coupling start bin % 4 will always be 1 * / cpl_start = s - > start_freq[CPL_CH] - 1 ; num_cpl_coefs = FFALIGN ( s - > num_cpl_subbands * 12 + 1 , 32 ) ; cpl_start = FFMIN ( 256 , cpl_start + num_cpl_coefs ) - num_cpl_coefs ; / * calculate coupling channel from fbw channels * / for ( blk = 0 ; blk < s - > num_blocks ; blk + + ) { AC3Block * block = & s - > blocks[blk] ; CoefType * cpl_coef = & block - > mdct_coef[CPL_CH][cpl_start] ; if ( ! block - > cpl_in_use ) continue ; memset ( cpl_coef , 0 , num_cpl_coefs * sizeof ( * cpl_coef ) ) ; for ( ch = 1 ; ch < = s - > fbw_channels ; ch + + ) { CoefType * ch_coef = & block - > mdct_coef[ch][cpl_start] ; if ( ! block - > channel_in_cpl[ch] ) continue ; for ( i = 0 ; i < num_cpl_coefs ; i + + ) cpl_coef[i] + = ch_coef[i] ; } / * coefficients must be clipped in order to be encoded * / clip_coefficients ( & s - > dsp , cpl_coef , num_cpl_coefs ) ; } / * calculate energy in each band in coupling channel and each fbw channel * / / * TODO : possibly use SIMD to speed up energy calculation * / bnd = 0 ; i = s - > start_freq[CPL_CH] ; while ( i < s - > cpl_end_freq ) { int band_size = s - > cpl_band_sizes[bnd] ; for ( ch = CPL_CH ; ch < = s - > fbw_channels ; ch + + ) { for ( blk = 0 ; blk < s - > num_blocks ; blk + + ) { AC3Block * block = & s - > blocks[blk] ; if ( ! block - > cpl_in_use || ( ch > CPL_CH & & ! block - > channel_in_cpl[ch] ) ) continue ; for ( j = 0 ; j < band_size ; j + + ) { CoefType v = block - > mdct_coef[ch][i + j] ; MAC_COEF ( energy[blk][ch][bnd] , v , v ) ; } } } i + = band_size ; bnd + + ; } / * calculate coupling coordinates for all blocks for all channels * / for ( blk = 0 ; blk < s - > num_blocks ; blk + + ) { AC3Block * block = & s - > blocks[blk] ; if ( ! block - > cpl_in_use ) continue ; for ( ch = 1 ; ch < = s - > fbw_channels ; ch + + ) { if ( ! block - > channel_in_cpl[ch] ) continue ; for ( bnd = 0 ; bnd < s - > num_cpl_bands ; bnd + + ) { cpl_coords[blk][ch][bnd] = calc_cpl_coord ( energy[blk][ch][bnd] , energy[blk][CPL_CH][bnd] ) ; } } } / * determine which blocks to send new coupling coordinates for * / for ( blk = 0 ; blk < s - > num_blocks ; blk + + ) { AC3Block * block = & s - > blocks[blk] ; AC3Block * block0 = blk ? & s - > blocks[blk - 1] : NULL ; memset ( block - > new_cpl_coords , 0 , sizeof ( block - > new_cpl_coords ) ) ; if ( block - > cpl_in_use ) { / * send new coordinates if this is the first block , if previous * block did not use coupling but this block does , the channels * using coupling has changed from the previous block , or the * coordinate difference from the last block for any channel is * greater than a threshold value . * / if ( blk == 0 || ! block0 - > cpl_in_use ) { for ( ch = 1 ; ch < = s - > fbw_channels ; ch + + ) block - > new_cpl_coords[ch] = 1 ; } else { for ( ch = 1 ; ch < = s - > fbw_channels ; ch + + ) { if ( ! block - > channel_in_cpl[ch] ) continue ; if ( ! block0 - > channel_in_cpl[ch] ) { block - > new_cpl_coords[ch] = 1 ; } else { CoefSumType coord_diff = 0 ; for ( bnd = 0 ; bnd < s - > num_cpl_bands ; bnd + + ) { coord_diff + = FFABS ( cpl_coords[blk - 1][ch][bnd] - cpl_coords[blk ][ch][bnd] ) ; } coord_diff /= s - > num_cpl_bands ; if ( coord_diff > NEW_CPL_COORD_THRESHOLD ) block - > new_cpl_coords[ch] = 1 ; } } } } } / * calculate final coupling coordinates , taking into account reusing of coordinates in successive blocks * / for ( bnd = 0 ; bnd < s - > num_cpl_bands ; bnd + + ) { blk = 0 ; while ( blk < s - > num_blocks ) { int av_uninit ( blk1 ) ; AC3Block * block = & s - > blocks[blk] ; if ( ! block - > cpl_in_use ) { blk + + ; continue ; } for ( ch = 1 ; ch < = s - > fbw_channels ; ch + + ) { CoefSumType energy_ch , energy_cpl ; if ( ! block - > channel_in_cpl[ch] ) continue ; energy_cpl = energy[blk][CPL_CH][bnd] ; energy_ch = energy[blk][ch][bnd] ; blk1 = blk + 1 ; while ( ! s - > blocks[blk1] . new_cpl_coords[ch] & & blk1 < s - > num_blocks ) { if ( s - > blocks[blk1] . cpl_in_use ) { energy_cpl + = energy[blk1][CPL_CH][bnd] ; energy_ch + = energy[blk1][ch][bnd] ; } blk1 + + ; } cpl_coords[blk][ch][bnd] = calc_cpl_coord ( energy_ch , energy_cpl ) ; } blk = blk1 ; } } / * calculate exponents/mantissas for coupling coordinates * / for ( blk = 0 ; blk < s - > num_blocks ; blk + + ) { AC3Block * block = & s - > blocks[blk] ; if ( ! block - > cpl_in_use ) continue ; if CONFIG_AC3ENC_FLOAT s - > ac3dsp . float_to_fixed24 ( fixed_cpl_coords[blk][1] , cpl_coords[blk][1] , s - > fbw_channels * 16 ) ; endif s - > ac3dsp . extract_exponents ( block - > cpl_coord_exp[1] , fixed_cpl_coords[blk][1] , s - > fbw_channels * 16 ) ; for ( ch = 1 ; ch <",1
"static int get_high_utility_cell ( elbg_data * elbg ) { int i=0 ; / * Using linear search , do binary if it ever turns to be speed critical * / int r = av_lfg_get ( elbg - > rand_state ) %elbg - > utility_inc[elbg - > numCB - 1] + 1 ; while ( elbg - > utility_inc[i] < r ) i + + ; av_assert2 ( elbg - > cells[i] ) ; return i ; }",1
"static void ff_jref_idct1_put ( uint8_t * dest , int line_size , DCTELEM * block ) { uint8_t * cm = ff_cropTbl + MAX_NEG_CROP ; dest[0] = cm[ ( block[0] + 4 ) > > 3] ; }",1
static av_cold int v410_encode_close ( AVCodecContext * avctx ) { av_freep ( & avctx - > coded_frame ) ; return 0 ; },0
"static int vp3_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , uint8_t * buf , int buf_size ) { Vp3DecodeContext * s = avctx - > priv_data ; GetBitContext gb ; static int counter = 0 ; init_get_bits ( & gb , buf , buf_size * 8 ) ; if ( s - > theora & & get_bits1 ( & gb ) ) { int ptype = get_bits ( & gb , 7 ) ; skip_bits ( & gb , 6 * 8 ) ; / * theora * / switch ( ptype ) { case 1 : theora_decode_comments ( avctx , gb ) ; break ; case 2 : theora_decode_tables ( avctx , gb ) ; init_dequantizer ( s ) ; break ; default : av_log ( avctx , AV_LOG_ERROR , Unknown Theora config packet : %d\n , ptype ) ; } return buf_size ; } s - > keyframe = ! get_bits1 ( & gb ) ; if ( ! s - > theora ) skip_bits ( & gb , 1 ) ; s - > last_quality_index = s - > quality_index ; s - > quality_index = get_bits ( & gb , 6 ) ; if ( s - > theora > = 0x030200 ) skip_bits1 ( & gb ) ; if ( s - > avctx - > debug & FF_DEBUG_PICT_INFO ) av_log ( s - > avctx , AV_LOG_INFO , VP3 %sframe %d : Q index = %d\n , s - > keyframe ? key : , counter , s - > quality_index ) ; counter + + ; if ( s - > quality_index ! = s - > last_quality_index ) init_dequantizer ( s ) ; if ( s - > keyframe ) { if ( ! s - > theora ) { skip_bits ( & gb , 4 ) ; / * width code * / skip_bits ( & gb , 4 ) ; / * height code * / if ( s - > version ) { s - > version = get_bits ( & gb , 5 ) ; if ( counter == 1 ) av_log ( s - > avctx , AV_LOG_DEBUG , VP version : %d\n , s - > version ) ; } } if ( s - > version || s - > theora ) { if ( get_bits1 ( & gb ) ) av_log ( s - > avctx , AV_LOG_ERROR , Warning , unsupported keyframe coding type ? ! \n ) ; skip_bits ( & gb , 2 ) ; / * reserved ? * / } if ( s - > last_frame . data[0] == s - > golden_frame . data[0] ) { if ( s - > golden_frame . data[0] ) avctx - > release_buffer ( avctx , & s - > golden_frame ) ; s - > last_frame= s - > golden_frame ; / * ensure that we catch any access to this released frame * / } else { if ( s - > golden_frame . data[0] ) avctx - > release_buffer ( avctx , & s - > golden_frame ) ; if ( s - > last_frame . data[0] ) avctx - > release_buffer ( avctx , & s - > last_frame ) ; } s - > golden_frame . reference = 3 ; if ( avctx - > get_buffer ( avctx , & s - > golden_frame ) < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , vp3 : get_buffer ( ) failed\n ) ; return - 1 ; } / * golden frame is also the current frame * / memcpy ( & s - > current_frame , & s - > golden_frame , sizeof ( AVFrame ) ) ; / * time to figure out pixel addresses ? * / if ( ! s - > pixel_addresses_inited ) { if ( ! s - > flipped_image ) vp3_calculate_pixel_addresses ( s ) ; else theora_calculate_pixel_addresses ( s ) ; } } else { / * allocate a new current frame * / s - > current_frame . reference = 3 ; if ( avctx - > get_buffer ( avctx , & s - > current_frame ) < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , vp3 : get_buffer ( ) failed\n ) ; return - 1 ; } } s - > current_frame . qscale_table= s - > qscale_table ; //FIXME allocate individual tables per AVFrame s - > current_frame . qstride= 0 ; init_frame ( s , & gb ) ; if KEYFRAMES_ONLY if ( ! s - > keyframe ) { memcpy ( s - > current_frame . data[0] , s - > golden_frame . data[0] , s - > current_frame . linesize[0] * s - > height ) ; memcpy ( s - > current_frame . data[1] , s - > golden_frame . data[1] , s - > current_frame . linesize[1] * s - > height / 2 ) ; memcpy ( s - > current_frame . data[2] , s - > golden_frame . data[2] , s - > current_frame . linesize[2] * s - > height / 2 ) ; } else { endif if ( unpack_superblocks ( s , & gb ) || unpack_modes ( s , & gb ) || unpack_vectors ( s , & gb ) || unpack_dct_coeffs ( s , & gb ) ) { av_log ( s - > avctx , AV_LOG_ERROR , vp3 : could not decode frame\n ) ; return - 1 ; } reverse_dc_prediction ( s , 0 , s - > fragment_width , s - > fragment_height ) ; render_fragments ( s , 0 , s - > width , s - > height , 0 ) ; // apply_loop_filter ( s ) ; if ( ( avctx - > flags & CODEC_FLAG_GRAY ) == 0 ) { reverse_dc_prediction ( s , s - > u_fragment_start , s - > fragment_width / 2 , s - > fragment_height / 2 ) ; reverse_dc_prediction ( s , s - > v_fragment_start , s - > fragment_width / 2 , s - > fragment_height / 2 ) ; render_fragments ( s , s - > u_fragment_start , s - > width / 2 , s - > height / 2 , 1 ) ; render_fragments ( s , s - > v_fragment_start , s - > width / 2 , s - > height / 2 , 2 ) ; } else { memset ( s - > current_frame . data[1] , 0x80 , s - > width * s - > height / 4 ) ; memset ( s - > current_frame . data[2] , 0x80 , s - > width * s - > height / 4 ) ; } if KEYFRAMES_ONLY } endif * data_size=sizeof ( AVFrame ) ; * ( AVFrame * ) data= s - > current_frame ; / * release the last frame , if it is allocated and if it is not the * golden frame * / if ( ( s - > last_frame . data[0] ) & & ( s - > last_frame . data[0]",0
"static int au_read_header ( AVFormatContext * s ) { int size ; unsigned int tag ; AVIOContext * pb = s - > pb ; unsigned int id , channels , rate ; enum AVCodecID codec ; AVStream * st ; / * check . snd header * / tag = avio_rl32 ( pb ) ; if ( tag ! = MKTAG ( ' . ' , ' s ' , ' n ' , ' d ' ) ) return - 1 ; size = avio_rb32 ( pb ) ; / * header size * / avio_rb32 ( pb ) ; / * data size * / id = avio_rb32 ( pb ) ; rate = avio_rb32 ( pb ) ; channels = avio_rb32 ( pb ) ; codec = ff_codec_get_id ( codec_au_tags , id ) ; if ( ! av_get_bits_per_sample ( codec ) ) { av_log_ask_for_sample ( s , could not determine bits per sample\n ) ; return AVERROR_PATCHWELCOME ; } if ( channels == 0 || channels > 64 ) { av_log ( s , AV_LOG_ERROR , Invalid number of channels %d\n , channels ) ; return AVERROR_INVALIDDATA ; } if ( size > = 24 ) { / * skip unused data * / avio_skip ( pb , size - 24 ) ; } / * now we are ready : build format streams * / st = avformat_new_stream ( s , NULL ) ; if ( ! st ) return - 1 ; st - > codec - > codec_type = AVMEDIA_TYPE_AUDIO ; st - > codec - > codec_tag = id ; st - > codec - > codec_id = codec ; st - > codec - > channels = channels ; st - > codec - > sample_rate = rate ; avpriv_set_pts_info ( st , 64 , 1 , rate ) ; return 0 ; }",0
"static av_always_inline void encode_mb_internal ( MpegEncContext * s , int motion_x , int motion_y , int mb_block_height , int mb_block_count ) { int16_t weight[8][64] ; DCTELEM orig[8][64] ; const int mb_x= s - > mb_x ; const int mb_y= s - > mb_y ; int i ; int skip_dct[8] ; int dct_offset = s - > linesize * 8 ; //default for progressive frames uint8_t * ptr_y , * ptr_cb , * ptr_cr ; int wrap_y , wrap_c ; for ( i=0 ; i < mb_block_count ; i + + ) skip_dct[i]=s - > skipdct ; if ( s - > adaptive_quant ) { const int last_qp= s - > qscale ; const int mb_xy= mb_x + mb_y * s - > mb_stride ; s - > lambda= s - > lambda_table[mb_xy] ; update_qscale ( s ) ; if ( ! ( s - > flags & CODEC_FLAG_QP_RD ) ) { s - > qscale= s - > current_picture_ptr - > qscale_table[mb_xy] ; s - > dquant= s - > qscale - last_qp ; if ( s - > out_format==FMT_H263 ) { s - > dquant= av_clip ( s - > dquant , - 2 , 2 ) ; if ( s - > codec_id==CODEC_ID_MPEG4 ) { if ( ! s - > mb_intra ) { if ( s - > pict_type == FF_B_TYPE ) { if ( s - > dquant & 1 || s - > mv_dir & MV_DIRECT ) s - > dquant= 0 ; } if ( s - > mv_type==MV_TYPE_8X8 ) s - > dquant=0 ; } } } } ff_set_qscale ( s , last_qp + s - > dquant ) ; } else if ( s - > flags & CODEC_FLAG_QP_RD ) ff_set_qscale ( s , s - > qscale + s - > dquant ) ; wrap_y = s - > linesize ; wrap_c = s - > uvlinesize ; ptr_y = s - > new_picture . data[0] + ( mb_y * 16 * wrap_y ) + mb_x * 16 ; ptr_cb = s - > new_picture . data[1] + ( mb_y * mb_block_height * wrap_c ) + mb_x * 8 ; ptr_cr = s - > new_picture . data[2] + ( mb_y * mb_block_height * wrap_c ) + mb_x * 8 ; if ( mb_x * 16 + 16 > s - > width || mb_y * 16 + 16 > s - > height ) { uint8_t * ebuf= s - > edge_emu_buffer + 32 ; ff_emulated_edge_mc ( ebuf , ptr_y , wrap_y , 16 , 16 , mb_x * 16 , mb_y * 16 , s - > width , s - > height ) ; ptr_y= ebuf ; ff_emulated_edge_mc ( ebuf + 18 * wrap_y , ptr_cb , wrap_c , 8 , mb_block_height , mb_x * 8 , mb_y * 8 , s - > width > > 1 , s - > height > > 1 ) ; ptr_cb= ebuf + 18 * wrap_y ; ff_emulated_edge_mc ( ebuf + 18 * wrap_y + 8 , ptr_cr , wrap_c , 8 , mb_block_height , mb_x * 8 , mb_y * 8 , s - > width > > 1 , s - > height > > 1 ) ; ptr_cr= ebuf + 18 * wrap_y + 8 ; } if ( s - > mb_intra ) { if ( s - > flags & CODEC_FLAG_INTERLACED_DCT ) { int progressive_score , interlaced_score ; s - > interlaced_dct=0 ; progressive_score= s - > dsp . ildct_cmp[4] ( s , ptr_y , NULL , wrap_y , 8 ) + s - > dsp . ildct_cmp[4] ( s , ptr_y + wrap_y * 8 , NULL , wrap_y , 8 ) - 400 ; if ( progressive_score > 0 ) { interlaced_score = s - > dsp . ildct_cmp[4] ( s , ptr_y , NULL , wrap_y * 2 , 8 ) + s - > dsp . ildct_cmp[4] ( s , ptr_y + wrap_y , NULL , wrap_y * 2 , 8 ) ; if ( progressive_score > interlaced_score ) { s - > interlaced_dct=1 ; dct_offset= wrap_y ; wrap_y < < =1 ; if ( s - > chroma_format == CHROMA_422 ) wrap_c < < =1 ; } } } s - > dsp . get_pixels ( s - > block[0] , ptr_y , wrap_y ) ; s - > dsp . get_pixels ( s - > block[1] , ptr_y + 8 , wrap_y ) ; s - > dsp . get_pixels ( s - > block[2] , ptr_y + dct_offset , wrap_y ) ; s - > dsp . get_pixels ( s - > block[3] , ptr_y + dct_offset + 8 , wrap_y ) ; if ( s - > flags & CODEC_FLAG_GRAY ) { skip_dct[4]= 1 ; skip_dct[5]= 1 ; } else { s - > dsp . get_pixels ( s - > block[4] , ptr_cb , wrap_c ) ; s - > dsp . get_pixels ( s - > block[5] , ptr_cr , wrap_c ) ; if ( ! s - > chroma_y_shift ) { / * 422 * / s - > dsp . get_pixels ( s - > block[6] , ptr_cb + ( dct_offset > > 1 ) , wrap_c ) ; s - > dsp . get_pixels ( s - > block[7] , ptr_cr + ( dct_offset > > 1 ) , wrap_c ) ; } } } else { op_pixels_func ( * op_pix ) [4] ; qpel_mc_func ( * op_qpix ) [16] ; uint8_t * dest_y , * dest_cb , * dest_cr ; dest_y = s - > dest[0] ; dest_cb = s - > dest[1] ; dest_cr = s - > dest[2] ; if ( ( ! s - > no_rounding ) || s - > pict_type==FF_B_TYPE ) { op_pix = s - > dsp . put_pixels_tab ; op_qpix= s - > dsp . put_qpel_pixels_tab ; } else { op_pix = s - > dsp . put_no_rnd_pixels_tab ; op_qpix= s - > dsp . put_no_rnd_qpel_pixels_tab ; } if ( s - > mv_dir & MV_DIR_FORWARD ) { MPV_motion ( s , dest_y , dest_cb , dest_cr , 0 , s - > last_picture . data , op_pix , op_qpix ) ; op_pix = s - > dsp . avg_pixels_tab ; op_qpix= s - > dsp . avg_qpel_pixels_tab ; } if ( s - > mv_dir & MV_DIR_BACKWARD ) { MPV_motion ( s , dest_y , dest_cb , dest_cr , 1 , s - > next_picture . data , op_pix , op_qpix ) ; } if ( s - > flags & CODEC_FLAG_INTERLACED_DCT ) { int progressive_score , interlaced_score ; s - > interlaced_dct=0 ; progressive_score= s - > dsp . ildct_cmp[0] ( s , dest_y , ptr_y , wrap_y , 8 ) + s - > dsp . ildct_cmp[0] ( s , dest_y + wrap_y * 8 , ptr_y + wrap_y * 8 , wrap_y , 8 ) - 400 ; if ( s - > avctx - > ildct_cmp == FF_CMP_VSSE ) progressive_score - = 400 ; if ( progressive_score > 0 ) { interlaced_score = s - > dsp . ildct_cmp[0] ( s , dest_y , ptr_y , wrap_y * 2",0
"static int sbr_hf_calc_npatches ( AACContext * ac , SpectralBandReplication * sbr ) { int i , k , sb = 0 ; int msb = sbr - > k[0] ; int usb = sbr - > kx[1] ; int goal_sb = ( ( 1000 < < 11 ) + ( sbr - > sample_rate > > 1 ) ) / sbr - > sample_rate ; sbr - > num_patches = 0 ; if ( goal_sb < sbr - > kx[1] + sbr - > m[1] ) { for ( k = 0 ; sbr - > f_master[k] < goal_sb ; k + + ) ; } else k = sbr - > n_master ; do { int odd = 0 ; for ( i = k ; i == k || sb > ( sbr - > k[0] - 1 + msb - odd ) ; i - - ) { sb = sbr - > f_master[i] ; odd = ( sb + sbr - > k[0] ) & 1 ; } sbr - > patch_num_subbands[sbr - > num_patches] = FFMAX ( sb - usb , 0 ) ; sbr - > patch_start_subband[sbr - > num_patches] = sbr - > k[0] - odd - sbr - > patch_num_subbands[sbr - > num_patches] ; if ( sbr - > patch_num_subbands[sbr - > num_patches] > 0 ) { usb = sb ; msb = sb ; sbr - > num_patches + + ; } else msb = sbr - > kx[1] ; if ( sbr - > f_master[k] - sb < 3 ) k = sbr - > n_master ; } while ( sb ! = sbr - > kx[1] + sbr - > m[1] ) ; if ( sbr - > patch_num_subbands[sbr - > num_patches - 1] < 3 & & sbr - > num_patches > 1 ) sbr - > num_patches - - ; // Requirements ( 14496 - 3 sp04 p205 ) sets the maximum number of patches to 5 // However the Coding Technologies decoder check uses 6 patches if ( sbr - > num_patches > 6 ) { av_log ( ac - > avccontext , AV_LOG_ERROR , Too many patches : %d\n , sbr - > num_patches ) ; return - 1 ; } return 0 ; }",1
"void av_log_format_line ( void * ptr , int level , const char * fmt , va_list vl , char * line , int line_size , int * print_prefix ) { char part[3][512] ; format_line ( ptr , level , fmt , vl , part , sizeof ( part[0] ) , print_prefix , NULL ) ; snprintf ( line , line_size , %s%s%s , part[0] , part[1] , part[2] ) ; }",1
"static inline void RENAME ( rgb32tobgr15 ) ( const uint8_t * src , uint8_t * dst , long src_size ) { const uint8_t * s = src ; const uint8_t * end ; ifdef HAVE_MMX const uint8_t * mm_end ; endif uint16_t * d = ( uint16_t * ) dst ; end = s + src_size ; ifdef HAVE_MMX __asm __volatile ( PREFETCH %0 : : m ( * src ) : memory ) ; __asm __volatile ( movq %0 , %%mm7\n\t movq %1 , %%mm6\n\t : : m ( red_15mask ) , m ( green_15mask ) ) ; mm_end = end - 15 ; while ( s < mm_end ) { __asm __volatile ( PREFETCH 32%1\n\t movd %1 , %%mm0\n\t movd 4%1 , %%mm3\n\t punpckldq 8%1 , %%mm0\n\t punpckldq 12%1 , %%mm3\n\t movq %%mm0 , %%mm1\n\t movq %%mm0 , %%mm2\n\t movq %%mm3 , %%mm4\n\t movq %%mm3 , %%mm5\n\t psllq 7 , %%mm0\n\t psllq 7 , %%mm3\n\t pand %%mm7 , %%mm0\n\t pand %%mm7 , %%mm3\n\t psrlq 6 , %%mm1\n\t psrlq 6 , %%mm4\n\t pand %%mm6 , %%mm1\n\t pand %%mm6 , %%mm4\n\t psrlq 19 , %%mm2\n\t psrlq 19 , %%mm5\n\t pand %2 , %%mm2\n\t pand %2 , %%mm5\n\t por %%mm1 , %%mm0\n\t por %%mm4 , %%mm3\n\t por %%mm2 , %%mm0\n\t por %%mm5 , %%mm3\n\t psllq 16 , %%mm3\n\t por %%mm3 , %%mm0\n\t MOVNTQ %%mm0 , %0\n\t : =m ( * d ) : m ( * s ) , m ( blue_15mask ) : memory ) ; d + = 4 ; s + = 16 ; } __asm __volatile ( SFENCE : : : memory ) ; __asm __volatile ( EMMS : : : memory ) ; endif while ( s < end ) { register int rgb = * ( uint32_t * ) s ; s + = 4 ; * d + + = ( ( rgb & 0xF8 ) < < 7 ) + ( ( rgb & 0xF800 ) > > 6 ) + ( ( rgb & 0xF80000 ) > > 19 ) ; } }",1
"static int http_receive_data ( HTTPContext * c ) { HTTPContext * c1 ; if ( c - > buffer_end > c - > buffer_ptr ) { int len ; len = recv ( c - > fd , c - > buffer_ptr , c - > buffer_end - c - > buffer_ptr , 0 ) ; if ( len < 0 ) { if ( ff_neterrno ( ) ! = FF_NETERROR ( EAGAIN ) & & ff_neterrno ( ) ! = FF_NETERROR ( EINTR ) ) / * error : close connection * / goto fail ; } else if ( len == 0 ) / * end of connection : close it * / goto fail ; else { c - > buffer_ptr + = len ; c - > data_count + = len ; update_datarate ( & c - > datarate , c - > data_count ) ; } } if ( c - > buffer_ptr - c - > buffer > = 2 & & c - > data_count > FFM_PACKET_SIZE ) { if ( c - > buffer[0] ! = ' f ' || c - > buffer[1] ! = ' m ' ) { http_log ( Feed stream has become desynchronized - - disconnecting\n ) ; goto fail ; } } if ( c - > buffer_ptr > = c - > buffer_end ) { FFStream * feed = c - > stream ; / * a packet has been received : write it in the store , except if header * / if ( c - > data_count > FFM_PACKET_SIZE ) { // printf ( writing pos=0x% PRIx64 size=0x% PRIx64 \n , feed - > feed_write_index , feed - > feed_size ) ; / * XXX : use llseek or url_seek * / lseek ( c - > feed_fd , feed - > feed_write_index , SEEK_SET ) ; if ( write ( c - > feed_fd , c - > buffer , FFM_PACKET_SIZE ) < 0 ) { http_log ( Error writing to feed file : %s\n , strerror ( errno ) ) ; goto fail ; } feed - > feed_write_index + = FFM_PACKET_SIZE ; / * update file size * / if ( feed - > feed_write_index > c - > stream - > feed_size ) feed - > feed_size = feed - > feed_write_index ; / * handle wrap around if max file size reached * / if ( c - > stream - > feed_max_size & & feed - > feed_write_index > = c - > stream - > feed_max_size ) feed - > feed_write_index = FFM_PACKET_SIZE ; / * write index * / ffm_write_write_index ( c - > feed_fd , feed - > feed_write_index ) ; / * wake up any waiting connections * / for ( c1 = first_http_ctx ; c1 ! = NULL ; c1 = c1 - > next ) { if ( c1 - > state == HTTPSTATE_WAIT_FEED & & c1 - > stream - > feed == c - > stream - > feed ) c1 - > state = HTTPSTATE_SEND_DATA ; } } else { / * We have a header in our hands that contains useful data * / AVFormatContext * s = NULL ; ByteIOContext * pb ; AVInputFormat * fmt_in ; int i ; url_open_buf ( & pb , c - > buffer , c - > buffer_end - c - > buffer , URL_RDONLY ) ; pb - > is_streamed = 1 ; / * use feed output format name to find corresponding input format * / fmt_in = av_find_input_format ( feed - > fmt - > name ) ; if ( ! fmt_in ) goto fail ; av_open_input_stream ( & s , pb , c - > stream - > feed_filename , fmt_in , NULL ) ; / * Now we have the actual streams * / if ( s - > nb_streams ! = feed - > nb_streams ) { av_close_input_stream ( s ) ; av_free ( pb ) ; goto fail ; } for ( i = 0 ; i < s - > nb_streams ; i + + ) memcpy ( feed - > streams[i] - > codec , s - > streams[i] - > codec , sizeof ( AVCodecContext ) ) ; av_close_input_stream ( s ) ; av_free ( pb ) ; } c - > buffer_ptr = c - > buffer ; } return 0 ; fail : c - > stream - > feed_opened = 0 ; close ( c - > feed_fd ) ; / * wake up any waiting connections to stop waiting for feed * / for ( c1 = first_http_ctx ; c1 ! = NULL ; c1 = c1 - > next ) { if ( c1 - > state == HTTPSTATE_WAIT_FEED & & c1 - > stream - > feed == c - > stream - > feed ) c1 - > state = HTTPSTATE_SEND_DATA_TRAILER ; } return - 1 ; }",0
"static void av_always_inline filter_mb_edgech ( uint8_t * pix , int stride , const int16_t bS[4] , unsigned int qp , H264Context * h , int intra ) { const int qp_bd_offset = 6 * ( h - > sps . bit_depth_luma - 8 ) ; const unsigned int index_a = qp - qp_bd_offset + h - > slice_alpha_c0_offset ; const int alpha = alpha_table[index_a] ; const int beta = beta_table[qp - qp_bd_offset + h - > slice_beta_offset] ; if ( alpha ==0 || beta == 0 ) return ; if ( bS[0] < 4 || ! intra ) { int8_t tc[4] ; tc[0] = tc0_table[index_a][bS[0]] + 1 ; tc[1] = tc0_table[index_a][bS[1]] + 1 ; tc[2] = tc0_table[index_a][bS[2]] + 1 ; tc[3] = tc0_table[index_a][bS[3]] + 1 ; h - > h264dsp . h264_v_loop_filter_chroma ( pix , stride , alpha , beta , tc ) ; } else { h - > h264dsp . h264_v_loop_filter_chroma_intra ( pix , stride , alpha , beta ) ; } }",0
"static int http_start_receive_data ( HTTPContext * c ) { int fd ; if ( c - > stream - > feed_opened ) return - 1 ; / * Don ' t permit writing to this one * / if ( c - > stream - > readonly ) return - 1 ; / * open feed * / fd = open ( c - > stream - > feed_filename , O_RDWR ) ; if ( fd < 0 ) { http_log ( Error opening feeder file : %s\n , strerror ( errno ) ) ; return - 1 ; } c - > feed_fd = fd ; if ( c - > stream - > truncate ) { / * truncate feed file * / ffm_write_write_index ( c - > feed_fd , FFM_PACKET_SIZE ) ; ftruncate ( c - > feed_fd , FFM_PACKET_SIZE ) ; http_log ( Truncating feed file ' %s ' \n , c - > stream - > feed_filename ) ; } else { if ( ( c - > stream - > feed_write_index = ffm_read_write_index ( fd ) ) < 0 ) { http_log ( Error reading write index from feed file : %s\n , strerror ( errno ) ) ; return - 1 ; } } c - > stream - > feed_write_index = FFMAX ( ffm_read_write_index ( fd ) , FFM_PACKET_SIZE ) ; c - > stream - > feed_size = lseek ( fd , 0 , SEEK_END ) ; lseek ( fd , 0 , SEEK_SET ) ; / * init buffer input * / c - > buffer_ptr = c - > buffer ; c - > buffer_end = c - > buffer + FFM_PACKET_SIZE ; c - > stream - > feed_opened = 1 ; c - > chunked_encoding = ! ! av_stristr ( c - > buffer , Transfer - Encoding : chunked ) ; return 0 ; }",0
"static int init_filter_param ( AVFilterContext * ctx , FilterParam * fp , const char * effect_type , int width ) { int z ; const char * effect = fp - > amount == 0 ? none : fp - > amount < 0 ? blur : sharpen ; if ( ! ( fp - > msize_x & fp - > msize_y & 1 ) ) { av_log ( ctx , AV_LOG_ERROR , Invalid even size for %s matrix size %dx%d\n , effect_type , fp - > msize_x , fp - > msize_y ) ; return AVERROR ( EINVAL ) ; } av_log ( ctx , AV_LOG_VERBOSE , effect : %s type : %s msize_x : %d msize_y : %d amount : %0 . 2f\n , effect , effect_type , fp - > msize_x , fp - > msize_y , fp - > amount / 65535 . 0 ) ; for ( z = 0 ; z < 2 * fp - > steps_y ; z + + ) fp - > sc[z] = av_malloc ( sizeof ( * ( fp - > sc[z] ) ) * ( width + 2 * fp - > steps_x ) ) ; return 0 ; }",0
"static void do_video_out ( AVFormatContext * s , AVOutputStream * ost , AVInputStream * ist , AVFrame * in_picture , int * frame_size ) { int nb_frames , i , ret ; AVFrame * final_picture , * formatted_picture , * resampling_dst , * padding_src ; AVFrame picture_crop_temp , picture_pad_temp ; AVCodecContext * enc , * dec ; avcodec_get_frame_defaults ( & picture_crop_temp ) ; avcodec_get_frame_defaults ( & picture_pad_temp ) ; enc = ost - > st - > codec ; dec = ist - > st - > codec ; / * by default , we output a single frame * / nb_frames = 1 ; * frame_size = 0 ; if ( video_sync_method > 0 || ( video_sync_method & & av_q2d ( enc - > time_base ) > 0 . 001 ) ) { double vdelta ; vdelta = get_sync_ipts ( ost ) / av_q2d ( enc - > time_base ) - ost - > sync_opts ; //FIXME set to 0 . 5 after we fix some dts/pts bugs like in avidec . c if ( vdelta < - 1 . 1 ) nb_frames = 0 ; else if ( video_sync_method == 2 ) ost - > sync_opts= lrintf ( get_sync_ipts ( ost ) / av_q2d ( enc - > time_base ) ) ; else if ( vdelta > 1 . 1 ) nb_frames = lrintf ( vdelta ) ; //fprintf ( stderr , vdelta : %f , ost - > sync_opts : % PRId64 , ost - > sync_ipts : %f nb_frames : %d\n , vdelta , ost - > sync_opts , ost - > sync_ipts , nb_frames ) ; if ( nb_frames == 0 ) { + + nb_frames_drop ; if ( verbose > 2 ) fprintf ( stderr , * * * drop ! \n ) ; } else if ( nb_frames > 1 ) { nb_frames_dup + = nb_frames ; if ( verbose > 2 ) fprintf ( stderr , * * * %d dup ! \n , nb_frames - 1 ) ; } } else ost - > sync_opts= lrintf ( get_sync_ipts ( ost ) / av_q2d ( enc - > time_base ) ) ; nb_frames= FFMIN ( nb_frames , max_frames[CODEC_TYPE_VIDEO] - ost - > frame_number ) ; if ( nb_frames < = 0 ) return ; if ( ost - > video_crop ) { if ( av_picture_crop ( ( AVPicture * ) & picture_crop_temp , ( AVPicture * ) in_picture , dec - > pix_fmt , ost - > topBand , ost - > leftBand ) < 0 ) { av_log ( NULL , AV_LOG_ERROR , error cropping picture\n ) ; if ( exit_on_error ) av_exit ( 1 ) ; return ; } formatted_picture = & picture_crop_temp ; } else { formatted_picture = in_picture ; } final_picture = formatted_picture ; padding_src = formatted_picture ; resampling_dst = & ost - > pict_tmp ; if ( ost - > video_pad ) { final_picture = & ost - > pict_tmp ; if ( ost - > video_resample ) { if ( av_picture_crop ( ( AVPicture * ) & picture_pad_temp , ( AVPicture * ) final_picture , enc - > pix_fmt , ost - > padtop , ost - > padleft ) < 0 ) { av_log ( NULL , AV_LOG_ERROR , error padding picture\n ) ; if ( exit_on_error ) av_exit ( 1 ) ; return ; } resampling_dst = & picture_pad_temp ; } } if ( ost - > video_resample ) { padding_src = NULL ; final_picture = & ost - > pict_tmp ; sws_scale ( ost - > img_resample_ctx , formatted_picture - > data , formatted_picture - > linesize , 0 , ost - > resample_height , resampling_dst - > data , resampling_dst - > linesize ) ; } if ( ost - > video_pad ) { av_picture_pad ( ( AVPicture * ) final_picture , ( AVPicture * ) padding_src , enc - > height , enc - > width , enc - > pix_fmt , ost - > padtop , ost - > padbottom , ost - > padleft , ost - > padright , padcolor ) ; } / * duplicates frame if needed * / for ( i=0 ; i < nb_frames ; i + + ) { AVPacket pkt ; av_init_packet ( & pkt ) ; pkt . stream_index= ost - > index ; if ( s - > oformat - > flags & AVFMT_RAWPICTURE ) { / * raw pictures are written as AVPicture structure to avoid any copies . We support temorarily the older method . * / AVFrame * old_frame = enc - > coded_frame ; enc - > coded_frame = dec - > coded_frame ; //FIXME/XXX remove this hack pkt . data= ( uint8_t * ) final_picture ; pkt . size= sizeof ( AVPicture ) ; pkt . pts= av_rescale_q ( ost - > sync_opts , enc - > time_base , ost - > st - > time_base ) ; pkt . flags |= PKT_FLAG_KEY ; write_frame ( s , & pkt , ost - > st - > codec , bitstream_filters[ost - > file_index][pkt . stream_index] ) ; enc - > coded_frame = old_frame ; } else { AVFrame big_picture ; big_picture= * final_picture ; / * better than nothing : use input picture interlaced settings * / big_picture . interlaced_frame = in_picture - > interlaced_frame ; if ( avctx_opts[CODEC_TYPE_VIDEO] - > flags & ( CODEC_FLAG_INTERLACED_DCT|CODEC_FLAG_INTERLACED_ME ) ) { if ( top_field_first == - 1 ) big_picture . top_field_first = in_picture - > top_field_first ; else big_picture . top_field_first = top_field_first ; } / * handles sameq here . This is not correct because it may not be a global option * / if ( same_quality ) { big_picture . quality = ist - > st - > quality ; } else big_picture . quality = ost - > st - > quality ; if ( ! me_threshold ) big_picture . pict_type = 0 ; // big_picture . pts = AV_NOPTS_VALUE ; big_picture . pts= ost - > sync_opts ; // big_picture . pts= av_rescale ( ost - > sync_opts , AV_TIME_BASE * ( int64_t ) enc - > time_base . num , enc - > time_base . den ) ; //av_log ( NULL , AV_LOG_DEBUG , % PRId64 - > encoder\n , ost - > sync_opts ) ; ret = avcodec_encode_video ( enc , bit_buffer , bit_buffer_size , & big_picture ) ; if ( ret == - 1 ) { fprintf ( stderr , Video encoding failed\n ) ; av_exit ( 1 ) ; } //enc - > frame_number = enc - > real_pict_num ; if ( ret > 0 ) { pkt . data= bit_buffer ; pkt . size= ret ; if ( enc - > coded_frame - > pts ! = AV_NOPTS_VALUE ) pkt . pts= av_rescale_q ( enc - > coded_frame - > pts , enc - > time_base , ost - > st - > time_base ) ; / * av_log ( NULL , AV_LOG_DEBUG , encoder - > % PRId64 /% PRId64 \n , pkt . pts ! = AV_NOPTS_VALUE ? av_rescale ( pkt . pts , enc - > time_base . den , AV_TIME_BASE * ( int64_t ) enc",0
"static int process_ea_header ( AVFormatContext * s ) { uint32_t blockid , size = 0 ; EaDemuxContext * ea = s - > priv_data ; ByteIOContext * pb = & s - > pb ; blockid = get_le32 ( pb ) ; if ( blockid == MVhd_TAG ) { size = get_le32 ( pb ) ; process_video_header_vp6 ( s ) ; url_fskip ( pb , size - 32 ) ; blockid = get_le32 ( pb ) ; } if ( blockid ! = SCHl_TAG ) return 0 ; size + = get_le32 ( pb ) ; blockid = get_le32 ( pb ) ; if ( blockid == GSTR_TAG ) { url_fskip ( pb , 4 ) ; } else if ( blockid ! = PT00_TAG ) { av_log ( s , AV_LOG_ERROR , unknown SCHl headerid\n ) ; return 0 ; } process_audio_header_elements ( s ) ; / * skip to the start of the data * / url_fseek ( pb , size , SEEK_SET ) ; return 1 ; }",0
"static void check_external_clock_sync ( VideoState * is , double pts ) { if ( fabs ( get_external_clock ( is ) - pts ) > AV_NOSYNC_THRESHOLD ) { update_external_clock_pts ( is , pts ) ; } }",0
"static int mov_read_stsd ( MOVContext * c , ByteIOContext * pb , MOV_atom_t atom ) { AVStream * st = c - > fc - > streams[c - > fc - > nb_streams - 1] ; MOVStreamContext * sc = ( MOVStreamContext * ) st - > priv_data ; int entries , frames_per_sample ; uint32_t format ; print_atom ( stsd , atom ) ; get_byte ( pb ) ; / * version * / get_byte ( pb ) ; get_byte ( pb ) ; get_byte ( pb ) ; / * flags * / entries = get_be32 ( pb ) ; while ( entries - - ) { enum CodecID id ; int size = get_be32 ( pb ) ; / * size * / format = get_le32 ( pb ) ; / * data format * / get_be32 ( pb ) ; / * reserved * / get_be16 ( pb ) ; / * reserved * / get_be16 ( pb ) ; / * index * / / * for MPEG4 : set codec type by looking for it * / id = codec_get_id ( mov_video_tags , format ) ; if ( id > = 0 ) { AVCodec * codec ; codec = avcodec_find_decoder ( id ) ; if ( codec ) st - > codec . codec_type = codec - > type ; } ifdef DEBUG printf ( size=%d 4CC= %c%c%c%c codec_type=%d\n , size , ( format > > 0 ) & 0xff , ( format > > 8 ) & 0xff , ( format > > 16 ) & 0xff , ( format > > 24 ) & 0xff , st - > codec . codec_type ) ; endif st - > codec . codec_tag = format ; if ( st - > codec . codec_type==CODEC_TYPE_VIDEO ) { MOV_atom_t a = { 0 , 0 , 0 } ; st - > codec . codec_id = id ; get_be16 ( pb ) ; / * version * / get_be16 ( pb ) ; / * revision level * / get_be32 ( pb ) ; / * vendor * / get_be32 ( pb ) ; / * temporal quality * / get_be32 ( pb ) ; / * spacial quality * / st - > codec . width = get_be16 ( pb ) ; / * width * / st - > codec . height = get_be16 ( pb ) ; / * height * / if 1 if ( st - > codec . codec_id == CODEC_ID_MPEG4 ) { / * in some MPEG4 the width/height are not correct , so we ignore this info * / st - > codec . width = 0 ; st - > codec . height = 0 ; } endif get_be32 ( pb ) ; / * horiz resolution * / get_be32 ( pb ) ; / * vert resolution * / get_be32 ( pb ) ; / * data size , always 0 * / frames_per_sample = get_be16 ( pb ) ; / * frames per samples * / ifdef DEBUG printf ( frames/samples = %d\n , frames_per_sample ) ; endif get_buffer ( pb , ( uint8_t * ) st - > codec . codec_name , 32 ) ; / * codec name * / st - > codec . bits_per_sample = get_be16 ( pb ) ; / * depth * / st - > codec . color_table_id = get_be16 ( pb ) ; / * colortable id * / st - > codec . frame_rate = 25 ; st - > codec . frame_rate_base = 1 ; size - = ( 16 + 8 * 4 + 2 + 32 + 2 * 2 ) ; if 0 while ( size > = 8 ) { MOV_atom_t a ; int64_t start_pos ; a . size = get_be32 ( pb ) ; a . type = get_le32 ( pb ) ; size - = 8 ; ifdef DEBUG printf ( VIDEO : atom_type=%c%c%c%c atom . size=%Ld size_left=%d\n , ( a . type > > 0 ) & 0xff , ( a . type > > 8 ) & 0xff , ( a . type > > 16 ) & 0xff , ( a . type > > 24 ) & 0xff , a . size , size ) ; endif start_pos = url_ftell ( pb ) ; switch ( a . type ) { case MKTAG ( ' e ' , ' s ' , ' d ' , ' s ' ) : { int tag , len ; / * Well , broken but suffisant for some MP4 streams * / get_be32 ( pb ) ; / * version + flags * / len = mov_mp4_read_descr ( pb , & tag ) ; if ( tag == 0x03 ) { / * MP4ESDescrTag * / get_be16 ( pb ) ; / * ID * / get_byte ( pb ) ; / * priority * / len = mov_mp4_read_descr ( pb , & tag ) ; if ( tag ! = 0x04 ) goto fail ; / * MP4DecConfigDescrTag * / get_byte ( pb ) ; / * objectTypeId * / get_be32 ( pb ) ; / * streamType + buffer size * / get_be32 ( pb ) ; / * max bit rate * / get_be32 ( pb ) ; / * avg bit rate * / len = mp4_read_descr ( pb , & tag ) ; if ( tag ! = 0x05 ) goto fail ; / * MP4DecSpecificDescrTag * / ifdef DEBUG printf ( Specific MPEG4 header len=%d\n , len ) ; endif sc - > header_data = av_mallocz ( len ) ; if ( sc - > header_data ) { get_buffer ( pb , sc - > header_data , len ) ; sc - > header_len = len ; } } / * in any case , skip garbage * / } break ; default : break ; } fail : printf ( ATOMENEWSIZE %Ld %d\n , atom . size , url_ftell ( pb ) - start_pos ) ; if ( atom . size > 8 ) { url_fskip ( pb , ( atom . size - 8 ) - ( ( url_ftell ( pb ) - start_pos ) ) ) ; size - = atom . size - 8 ; } } if ( size > 0 ) { / * unknown extension * / url_fskip ( pb , size ) ; } else a . size = size ; mov_read_default ( c , pb , a ) ; endif } else { get_be16 ( pb ) ; / * version * / get_be16 ( pb ) ; / * revision level * / get_be32 ( pb ) ; / * vendor * / st - > codec . channels = get_be16 ( pb ) ; / * channel count * / st - > codec . bits_per_sample = get_be16 ( pb ) ; / * sample size * / st - > codec . codec_id = codec_get_id ( mov_audio_tags , format ) ; / * handle specific s8 codec * / get_be16 ( pb ) ; / * compression id =",1
"int av_packet_add_side_data ( AVPacket * pkt , enum AVPacketSideDataType type , uint8_t * data , size_t size ) { int elems = pkt - > side_data_elems ; if ( ( unsigned ) elems + 1 > INT_MAX / sizeof ( * pkt - > side_data ) ) return AVERROR ( ERANGE ) ; pkt - > side_data = av_realloc ( pkt - > side_data , ( elems + 1 ) * sizeof ( * pkt - > side_data ) ) ; if ( ! pkt - > side_data ) return AVERROR ( ENOMEM ) ; pkt - > side_data[elems] . data = data ; pkt - > side_data[elems] . size = size ; pkt - > side_data[elems] . type = type ; pkt - > side_data_elems + + ; return 0 ; }",1
"static int get_siz ( J2kDecoderContext * s ) { int i , ret ; if ( s - > buf_end - s - > buf < 36 ) bytestream_get_be16 ( & s - > buf ) ; // Rsiz ( skipped ) s - > width = bytestream_get_be32 ( & s - > buf ) ; // width s - > height = bytestream_get_be32 ( & s - > buf ) ; // height s - > image_offset_x = bytestream_get_be32 ( & s - > buf ) ; // X0Siz s - > image_offset_y = bytestream_get_be32 ( & s - > buf ) ; // Y0Siz s - > tile_width = bytestream_get_be32 ( & s - > buf ) ; // XTSiz s - > tile_height = bytestream_get_be32 ( & s - > buf ) ; // YTSiz s - > tile_offset_x = bytestream_get_be32 ( & s - > buf ) ; // XT0Siz s - > tile_offset_y = bytestream_get_be32 ( & s - > buf ) ; // YT0Siz s - > ncomponents = bytestream_get_be16 ( & s - > buf ) ; // CSiz if ( s - > buf_end - s - > buf < 2 * s - > ncomponents ) for ( i = 0 ; i < s - > ncomponents ; i + + ) { // Ssiz_i XRsiz_i , YRsiz_i uint8_t x = bytestream_get_byte ( & s - > buf ) ; s - > cbps[i] = ( x & 0x7f ) + 1 ; s - > precision = FFMAX ( s - > cbps[i] , s - > precision ) ; s - > sgnd[i] = ! ! ( x & 0x80 ) ; s - > cdx[i] = bytestream_get_byte ( & s - > buf ) ; s - > cdy[i] = bytestream_get_byte ( & s - > buf ) ; } s - > numXtiles = ff_j2k_ceildiv ( s - > width - s - > tile_offset_x , s - > tile_width ) ; s - > numYtiles = ff_j2k_ceildiv ( s - > height - s - > tile_offset_y , s - > tile_height ) ; s - > tile = av_mallocz ( s - > numXtiles * s - > numYtiles * sizeof ( J2kTile ) ) ; if ( ! s - > tile ) return AVERROR ( ENOMEM ) ; for ( i = 0 ; i < s - > numXtiles * s - > numYtiles ; i + + ) { J2kTile * tile = s - > tile + i ; tile - > comp = av_mallocz ( s - > ncomponents * sizeof ( J2kComponent ) ) ; if ( ! tile - > comp ) return AVERROR ( ENOMEM ) ; } s - > avctx - > width = s - > width - s - > image_offset_x ; s - > avctx - > height = s - > height - s - > image_offset_y ; switch ( s - > ncomponents ) { case 1 : if ( s - > precision > 8 ) { s - > avctx - > pix_fmt = PIX_FMT_GRAY16 ; } else s - > avctx - > pix_fmt = PIX_FMT_GRAY8 ; break ; case 3 : if ( s - > precision > 8 ) { s - > avctx - > pix_fmt = PIX_FMT_RGB48 ; } else s - > avctx - > pix_fmt = PIX_FMT_RGB24 ; break ; case 4 : s - > avctx - > pix_fmt = PIX_FMT_BGRA ; break ; } if ( s - > picture . data[0] ) s - > avctx - > release_buffer ( s - > avctx , & s - > picture ) ; if ( ( ret = s - > avctx - > get_buffer ( s - > avctx , & s - > picture ) ) < 0 ) return ret ; s - > picture . pict_type = FF_I_TYPE ; s - > picture . key_frame = 1 ; return 0 ; }",1
"static int decode_ref_pic_marking ( H264Context * h , GetBitContext * gb ) { MpegEncContext * const s = & h - > s ; int i ; if ( h - > nal_unit_type == NAL_IDR_SLICE ) { //FIXME fields s - > broken_link= get_bits1 ( gb ) - 1 ; h - > mmco[0] . long_arg= get_bits1 ( gb ) - 1 ; // current_long_term_idx if ( h - > mmco[0] . long_arg == - 1 ) else { h - > mmco[0] . opcode= MMCO_LONG ; h - > mmco_index= 1 ; } } else { if ( get_bits1 ( gb ) ) { // adaptive_ref_pic_marking_mode_flag for ( i= 0 ; i < MAX_MMCO_COUNT ; i + + ) { MMCOOpcode opcode= get_ue_golomb ( gb ) ; h - > mmco[i] . opcode= opcode ; if ( opcode==MMCO_SHORT2UNUSED || opcode==MMCO_SHORT2LONG ) { h - > mmco[i] . short_pic_num= ( h - > curr_pic_num - get_ue_golomb ( gb ) - 1 ) & ( h - > max_pic_num - 1 ) ; / * if ( h - > mmco[i] . short_pic_num > = h - > short_ref_count || h - > short_ref[ h - > mmco[i] . short_pic_num ] == NULL ) { av_log ( s - > avctx , AV_LOG_ERROR , illegal short ref in memory management control operation %d\n , mmco ) ; return - 1 ; } * / } if ( opcode==MMCO_SHORT2LONG || opcode==MMCO_LONG2UNUSED || opcode==MMCO_LONG || opcode==MMCO_SET_MAX_LONG ) { unsigned int long_arg= get_ue_golomb ( gb ) ; if ( long_arg > = 32 || ( long_arg > = 16 & & ! ( opcode == MMCO_LONG2UNUSED & & FIELD_PICTURE ) ) ) { av_log ( h - > s . avctx , AV_LOG_ERROR , illegal long ref in memory management control operation %d\n , opcode ) ; return - 1 ; } h - > mmco[i] . long_arg= long_arg ; } if ( opcode > ( unsigned ) MMCO_LONG ) { av_log ( h - > s . avctx , AV_LOG_ERROR , illegal memory management control operation %d\n , opcode ) ; return - 1 ; } if ( opcode == MMCO_END ) break ; } h - > mmco_index= i ; } else { assert ( h - > long_ref_count + h - > short_ref_count < = h - > sps . ref_frame_count ) ; if ( h - > short_ref_count & & h - > long_ref_count + h - > short_ref_count == h - > sps . ref_frame_count & & ! ( FIELD_PICTURE & & ! s - > first_field & & s - > current_picture_ptr - > reference ) ) { h - > mmco[0] . opcode= MMCO_SHORT2UNUSED ; h - > mmco[0] . short_pic_num= h - > short_ref[ h - > short_ref_count - 1 ] - > frame_num ; h - > mmco_index= 1 ; if ( FIELD_PICTURE ) { h - > mmco[0] . short_pic_num * = 2 ; h - > mmco[1] . opcode= MMCO_SHORT2UNUSED ; h - > mmco[1] . short_pic_num= h - > mmco[0] . short_pic_num + 1 ; h - > mmco_index= 2 ; } } else } } return 0 ; }",1
"static int decode_main_header ( NUTContext * nut ) { AVFormatContext * s= nut - > avf ; ByteIOContext * bc = & s - > pb ; uint64_t tmp , end ; unsigned int stream_count ; int i , j , tmp_stream , tmp_mul , tmp_pts , tmp_size , count , tmp_res ; end= get_packetheader ( nut , bc , 1 ) ; end + = url_ftell ( bc ) - 4 ; GET_V ( tmp , tmp > =2 & & tmp < = 3 ) GET_V ( stream_count , tmp > 0 & & tmp < =MAX_STREAMS ) nut - > max_distance = get_v ( bc ) ; if ( nut - > max_distance > 65536 ) { av_log ( s , AV_LOG_DEBUG , max_distance %d\n , nut - > max_distance ) ; nut - > max_distance= 65536 ; } GET_V ( nut - > time_base_count , tmp > 0 & & tmp < INT_MAX / sizeof ( AVRational ) ) nut - > time_base= av_malloc ( nut - > time_base_count * sizeof ( AVRational ) ) ; for ( i=0 ; i < nut - > time_base_count ; i + + ) { GET_V ( nut - > time_base[i] . num , tmp > 0 & & tmp < ( 1ULL < < 31 ) ) GET_V ( nut - > time_base[i] . den , tmp > 0 & & tmp < ( 1ULL < < 31 ) ) if ( ff_gcd ( nut - > time_base[i] . num , nut - > time_base[i] . den ) ! = 1 ) { av_log ( s , AV_LOG_ERROR , time base invalid\n ) ; return - 1 ; } } tmp_pts=0 ; tmp_mul=1 ; tmp_stream=0 ; for ( i=0 ; i < 256 ; ) { int tmp_flags = get_v ( bc ) ; int tmp_fields= get_v ( bc ) ; if ( tmp_fields > 0 ) tmp_pts = get_s ( bc ) ; if ( tmp_fields > 1 ) tmp_mul = get_v ( bc ) ; if ( tmp_fields > 2 ) tmp_stream= get_v ( bc ) ; if ( tmp_fields > 3 ) tmp_size = get_v ( bc ) ; else tmp_size = 0 ; if ( tmp_fields > 4 ) tmp_res = get_v ( bc ) ; else tmp_res = 0 ; if ( tmp_fields > 5 ) count = get_v ( bc ) ; else count = tmp_mul - tmp_size ; while ( tmp_fields - - > 6 ) get_v ( bc ) ; if ( count == 0 || i + count > 256 ) { av_log ( s , AV_LOG_ERROR , illegal count %d at %d\n , count , i ) ; return - 1 ; } if ( tmp_stream > = stream_count ) { av_log ( s , AV_LOG_ERROR , illegal stream number\n ) ; return - 1 ; } for ( j=0 ; j < count ; j + + , i + + ) { if ( i == ' N ' ) { nut - > frame_code[i] . flags= FLAG_INVALID ; j - - ; continue ; } nut - > frame_code[i] . flags = tmp_flags ; nut - > frame_code[i] . pts_delta = tmp_pts ; nut - > frame_code[i] . stream_id = tmp_stream ; nut - > frame_code[i] . size_mul = tmp_mul ; nut - > frame_code[i] . size_lsb = tmp_size + j ; nut - > frame_code[i] . reserved_count = tmp_res ; } } assert ( nut - > frame_code[ ' N ' ] . flags == FLAG_INVALID ) ; if ( skip_reserved ( bc , end ) || check_checksum ( bc ) ) { av_log ( s , AV_LOG_ERROR , Main header checksum mismatch\n ) ; return - 1 ; } nut - > stream = av_mallocz ( sizeof ( StreamContext ) * stream_count ) ; for ( i=0 ; i < stream_count ; i + + ) { av_new_stream ( s , i ) ; } return 0 ; }",1
"static void enqueue_packet ( RTPDemuxContext * s , uint8_t * buf , int len ) { uint16_t seq = AV_RB16 ( buf + 2 ) ; RTPPacket * * cur = & s - > queue , * packet ; / * Find the correct place in the queue to insert the packet * / while ( * cur ) { int16_t diff = seq - ( * cur ) - > seq ; if ( diff < 0 ) break ; cur = & ( * cur ) - > next ; } packet = av_mallocz ( sizeof ( * packet ) ) ; if ( ! packet ) return ; packet - > recvtime = av_gettime_relative ( ) ; packet - > seq = seq ; packet - > len = len ; packet - > buf = buf ; packet - > next = * cur ; * cur = packet ; s - > queue_len + + ; }",1
"int ff_rv34_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , const uint8_t * buf , int buf_size ) { RV34DecContext * r = avctx - > priv_data ; MpegEncContext * s = & r - > s ; AVFrame * pict = data ; SliceInfo si ; int i ; int slice_count ; const uint8_t * slices_hdr = NULL ; int last = 0 ; / * no supplementary picture * / if ( buf_size == 0 ) { / * special case for last picture * / if ( s - > low_delay==0 & & s - > next_picture_ptr ) { * pict= * ( AVFrame * ) s - > next_picture_ptr ; s - > next_picture_ptr= NULL ; * data_size = sizeof ( AVFrame ) ; } return 0 ; } if ( ! avctx - > slice_count ) { slice_count = ( * buf + + ) + 1 ; slices_hdr = buf + 4 ; buf + = 8 * slice_count ; } else slice_count = avctx - > slice_count ; for ( i=0 ; i < slice_count ; i + + ) { int offset= get_slice_offset ( avctx , slices_hdr , i ) ; int size ; if ( i + 1 == slice_count ) size= buf_size - offset ; else size= get_slice_offset ( avctx , slices_hdr , i + 1 ) - offset ; if ( offset > buf_size ) { av_log ( avctx , AV_LOG_ERROR , Slice offset is greater than frame size\n ) ; break ; } r - > si . end = s - > mb_width * s - > mb_height ; if ( i + 1 < slice_count ) { init_get_bits ( & s - > gb , buf + get_slice_offset ( avctx , slices_hdr , i + 1 ) , ( buf_size - get_slice_offset ( avctx , slices_hdr , i + 1 ) ) * 8 ) ; if ( r - > parse_slice_header ( r , & r - > s . gb , & si ) < 0 ) { if ( i + 2 < slice_count ) size = get_slice_offset ( avctx , slices_hdr , i + 2 ) - offset ; else size = buf_size - offset ; } else r - > si . end = si . start ; } if ( ! i & & si . type == FF_B_TYPE & & ( ! s - > last_picture_ptr || ! s - > last_picture_ptr - > data[0] ) ) return - 1 ; last = rv34_decode_slice ( r , r - > si . end , buf + offset , size ) ; s - > mb_num_left = r - > s . mb_x + r - > s . mb_y * r - > s . mb_width - r - > si . start ; if ( last ) break ; } if ( last ) { if ( r - > loop_filter ) r - > loop_filter ( r , s - > mb_height - 1 ) ; ff_er_frame_end ( s ) ; MPV_frame_end ( s ) ; if ( s - > pict_type == FF_B_TYPE || s - > low_delay ) { * pict= * ( AVFrame * ) s - > current_picture_ptr ; } else if ( s - > last_picture_ptr ! = NULL ) { * pict= * ( AVFrame * ) s - > last_picture_ptr ; } if ( s - > last_picture_ptr || s - > low_delay ) { * data_size = sizeof ( AVFrame ) ; ff_print_debug_info ( s , pict ) ; } s - > current_picture_ptr= NULL ; //so we can detect if frame_end wasnt called ( find some nicer solution . . . ) } return buf_size ; }",0
"static av_cold int mss2_decode_init ( AVCodecContext * avctx ) { MSS2Context * const ctx = avctx - > priv_data ; MSS12Context * c = & ctx - > c ; int ret ; c - > avctx = avctx ; avctx - > coded_frame = & ctx - > pic ; if ( ret = ff_mss12_decode_init ( c , 1 , & ctx - > sc[0] , & ctx - > sc[1] ) ) return ret ; c - > pal_stride = c - > mask_stride ; c - > pal_pic = av_malloc ( c - > pal_stride * avctx - > height ) ; c - > last_pal_pic = av_malloc ( c - > pal_stride * avctx - > height ) ; if ( ! c - > pal_pic || ! c - > last_pal_pic ) { mss2_decode_end ( avctx ) ; return AVERROR ( ENOMEM ) ; } if ( ret = wmv9_init ( avctx ) ) { mss2_decode_end ( avctx ) ; return ret ; } ff_mss2dsp_init ( & ctx - > dsp ) ; avctx - > pix_fmt = c - > free_colours == 127 ? AV_PIX_FMT_RGB555 : AV_PIX_FMT_RGB24 ; return 0 ; }",1
"static void build_file_streams ( void ) { FFStream * stream , * stream_next ; AVFormatContext * infile ; int i ; / * gather all streams * / for ( stream = first_stream ; stream ! = NULL ; stream = stream_next ) { stream_next = stream - > next ; if ( stream - > stream_type == STREAM_TYPE_LIVE & & ! stream - > feed ) { / * the stream comes from a file * / / * try to open the file * / / * open stream * / stream - > ap_in = av_mallocz ( sizeof ( AVFormatParameters ) ) ; if ( ! strcmp ( stream - > fmt - > name , rtp ) ) { / * specific case : if transport stream output to RTP , we use a raw transport stream reader * / stream - > ap_in - > mpeg2ts_raw = 1 ; stream - > ap_in - > mpeg2ts_compute_pcr = 1 ; } if ( av_open_input_file ( & infile , stream - > feed_filename , stream - > ifmt , 0 , stream - > ap_in ) < 0 ) { http_log ( %s not found , stream - > feed_filename ) ; / * remove stream ( no need to spend more time on it ) * / fail : remove_stream ( stream ) ; } else { / * find all the AVStreams inside and reference them in ' stream ' * / if ( av_find_stream_info ( infile ) < 0 ) { http_log ( Could not find codec parameters from ' %s ' , stream - > feed_filename ) ; av_close_input_file ( infile ) ; goto fail ; } extract_mpeg4_header ( infile ) ; for ( i=0 ; i < infile - > nb_streams ; i + + ) add_av_stream1 ( stream , infile - > streams[i] - > codec ) ; av_close_input_file ( infile ) ; } } } }",1
"static void xan_unpack ( unsigned char * dest , unsigned char * src ) { unsigned char opcode ; int size ; int offset ; int byte1 , byte2 , byte3 ; for ( ; ; ) { opcode = * src + + ; if ( ( opcode & 0x80 ) == 0 ) { offset = * src + + ; size = opcode & 3 ; bytecopy ( dest , src , size ) ; dest + = size ; src + = size ; size = ( ( opcode & 0x1c ) > > 2 ) + 3 ; bytecopy ( dest , dest - ( ( ( opcode & 0x60 ) < < 3 ) + offset + 1 ) , size ) ; dest + = size ; } else if ( ( opcode & 0x40 ) == 0 ) { byte1 = * src + + ; byte2 = * src + + ; size = byte1 > > 6 ; bytecopy ( dest , src , size ) ; dest + = size ; src + = size ; size = ( opcode & 0x3f ) + 4 ; bytecopy ( dest , dest - ( ( ( byte1 & 0x3f ) < < 8 ) + byte2 + 1 ) , size ) ; dest + = size ; } else if ( ( opcode & 0x20 ) == 0 ) { byte1 = * src + + ; byte2 = * src + + ; byte3 = * src + + ; size = opcode & 3 ; bytecopy ( dest , src , size ) ; dest + = size ; src + = size ; size = byte3 + 5 + ( ( opcode & 0xc ) < < 6 ) ; bytecopy ( dest , dest - ( ( ( ( opcode & 0x10 ) > > 4 ) < < 0x10 ) + 1 + ( byte1 < < 8 ) + byte2 ) , size ) ; dest + = size ; } else { size = ( ( opcode & 0x1f ) < < 2 ) + 4 ; if ( size > 0x70 ) break ; bytecopy ( dest , src , size ) ; dest + = size ; src + = size ; } } size = opcode & 3 ; bytecopy ( dest , src , size ) ; dest + = size ; src + = size ; }",0
"static av_cold int dcadec_init ( AVCodecContext * avctx ) { DCAContext * s = avctx - > priv_data ; s - > avctx = avctx ; s - > core . avctx = avctx ; s - > exss . avctx = avctx ; s - > xll . avctx = avctx ; s - > lbr . avctx = avctx ; ff_dca_init_vlcs ( ) ; if ( ff_dca_core_init ( & s - > core ) < 0 ) return AVERROR ( ENOMEM ) ; if ( ff_dca_lbr_init ( & s - > lbr ) < 0 ) return AVERROR ( ENOMEM ) ; ff_dcadsp_init ( & s - > dcadsp ) ; s - > core . dcadsp = & s - > dcadsp ; s - > xll . dcadsp = & s - > dcadsp ; s - > lbr . dcadsp = & s - > dcadsp ; s - > crctab = av_crc_get_table ( AV_CRC_16_CCITT ) ; switch ( avctx - > request_channel_layout & AV_CH_LAYOUT_NATIVE ) { case 0 : s - > request_channel_layout = 0 ; break ; case AV_CH_LAYOUT_STEREO : case AV_CH_LAYOUT_STEREO_DOWNMIX : s - > request_channel_layout = DCA_SPEAKER_LAYOUT_STEREO ; break ; case AV_CH_LAYOUT_5POINT0 : s - > request_channel_layout = DCA_SPEAKER_LAYOUT_5POINT0 ; break ; case AV_CH_LAYOUT_5POINT1 : s - > request_channel_layout = DCA_SPEAKER_LAYOUT_5POINT1 ; break ; default : av_log ( avctx , AV_LOG_WARNING , Invalid request_channel_layout\n ) ; break ; } avctx - > sample_fmt = AV_SAMPLE_FMT_S32P ; avctx - > bits_per_raw_sample = 24 ; return 0 ; }",0
"static void vc1_decode_b_mb_intfi ( VC1Context * v ) { MpegEncContext * s = & v - > s ; GetBitContext * gb = & s - > gb ; int i , j ; int mb_pos = s - > mb_x + s - > mb_y * s - > mb_stride ; int cbp = 0 ; / * cbp decoding stuff * / int mqdiff , mquant ; / * MB quantization * / int ttmb = v - > ttfrm ; / * MB Transform type * / int mb_has_coeffs = 0 ; / * last_flag * / int val ; / * temp value * / int first_block = 1 ; int dst_idx , off ; int fwd ; int dmv_x[2] , dmv_y[2] , pred_flag[2] ; int bmvtype = BMV_TYPE_BACKWARD ; int idx_mbmode , interpmvp ; mquant = v - > pq ; / * Lossy initialization * / s - > mb_intra = 0 ; idx_mbmode = get_vlc2 ( gb , v - > mbmode_vlc - > table , VC1_IF_MBMODE_VLC_BITS , 2 ) ; if ( idx_mbmode < = 1 ) { // intra MB s - > mb_intra = v - > is_intra[s - > mb_x] = 1 ; s - > current_picture . f . motion_val[1][s - > block_index[0]][0] = 0 ; s - > current_picture . f . motion_val[1][s - > block_index[0]][1] = 0 ; s - > current_picture . f . mb_type[mb_pos + v - > mb_off] = MB_TYPE_INTRA ; GET_MQUANT ( ) ; s - > current_picture . f . qscale_table[mb_pos] = mquant ; / * Set DC scale - y and c use the same ( not sure if necessary here ) * / s - > y_dc_scale = s - > y_dc_scale_table[mquant] ; s - > c_dc_scale = s - > c_dc_scale_table[mquant] ; v - > s . ac_pred = v - > acpred_plane[mb_pos] = get_bits1 ( gb ) ; mb_has_coeffs = idx_mbmode & 1 ; if ( mb_has_coeffs ) cbp = 1 + get_vlc2 ( & v - > s . gb , v - > cbpcy_vlc - > table , VC1_ICBPCY_VLC_BITS , 2 ) ; dst_idx = 0 ; for ( i = 0 ; i < 6 ; i + + ) { s - > dc_val[0][s - > block_index[i]] = 0 ; dst_idx + = i > > 2 ; val = ( ( cbp > > ( 5 - i ) ) & 1 ) ; v - > mb_type[0][s - > block_index[i]] = s - > mb_intra ; v - > a_avail = v - > c_avail = 0 ; if ( i == 2 || i == 3 || ! s - > first_slice_line ) v - > a_avail = v - > mb_type[0][s - > block_index[i] - s - > block_wrap[i]] ; if ( i == 1 || i == 3 || s - > mb_x ) v - > c_avail = v - > mb_type[0][s - > block_index[i] - 1] ; vc1_decode_intra_block ( v , s - > block[i] , i , val , mquant , ( i & 4 ) ? v - > codingset2 : v - > codingset ) ; if ( ( i > 3 ) & & ( s - > flags & CODEC_FLAG_GRAY ) ) continue ; v - > vc1dsp . vc1_inv_trans_8x8 ( s - > block[i] ) ; if ( v - > rangeredfrm ) for ( j = 0 ; j < 64 ; j + + ) s - > block[i][j] < < = 1 ; off = ( i & 4 ) ? 0 : ( ( i & 1 ) * 8 + ( i & 2 ) * 4 * s - > linesize ) ; off + = v - > second_field ? ( ( i & 4 ) ? s - > current_picture_ptr - > f . linesize[1] : s - > current_picture_ptr - > f . linesize[0] ) : 0 ; s - > dsp . put_signed_pixels_clamped ( s - > block[i] , s - > dest[dst_idx] + off , ( i & 4 ) ? s - > uvlinesize : s - > linesize ) ; // TODO : yet to perform loop filter } } else { s - > mb_intra = v - > is_intra[s - > mb_x] = 0 ; s - > current_picture . f . mb_type[mb_pos + v - > mb_off] = MB_TYPE_16x16 ; for ( i = 0 ; i < 6 ; i + + ) v - > mb_type[0][s - > block_index[i]] = 0 ; if ( v - > fmb_is_raw ) fwd = v - > forward_mb_plane[mb_pos] = get_bits1 ( gb ) ; else fwd = v - > forward_mb_plane[mb_pos] ; if ( idx_mbmode < = 5 ) { // 1 - MV dmv_x[0] = dmv_x[1] = dmv_y[0] = dmv_y[1] = 0 ; pred_flag[0] = pred_flag[1] = 0 ; if ( fwd ) bmvtype = BMV_TYPE_FORWARD ; else { bmvtype = decode012 ( gb ) ; switch ( bmvtype ) { case 0 : bmvtype = BMV_TYPE_BACKWARD ; break ; case 1 : bmvtype = BMV_TYPE_DIRECT ; break ; case 2 : bmvtype = BMV_TYPE_INTERPOLATED ; interpmvp = get_bits1 ( gb ) ; } } v - > bmvtype = bmvtype ; if ( bmvtype ! = BMV_TYPE_DIRECT & & idx_mbmode & 1 ) { get_mvdata_interlaced ( v , & dmv_x[bmvtype == BMV_TYPE_BACKWARD] , & dmv_y[bmvtype == BMV_TYPE_BACKWARD] , & pred_flag[bmvtype == BMV_TYPE_BACKWARD] ) ; } if ( bmvtype == BMV_TYPE_INTERPOLATED & & interpmvp ) { get_mvdata_interlaced ( v , & dmv_x[1] , & dmv_y[1] , & pred_flag[1] ) ; } if ( bmvtype == BMV_TYPE_DIRECT ) { dmv_x[0] = dmv_y[0] = pred_flag[0] = 0 ; dmv_x[1] = dmv_y[1] = pred_flag[0] = 0 ; } vc1_pred_b_mv_intfi ( v , 0 , dmv_x , dmv_y , 1 , pred_flag ) ; vc1_b_mc ( v , dmv_x , dmv_y , ( bmvtype == BMV_TYPE_DIRECT ) , bmvtype ) ; mb_has_coeffs = ! ( idx_mbmode & 2 ) ; } else { // 4 - MV if ( fwd ) bmvtype = BMV_TYPE_FORWARD ; v - > bmvtype = bmvtype ; v - > fourmvbp = get_vlc2 ( gb , v - > fourmvbp_vlc - > table , VC1_4MV_BLOCK_PATTERN_VLC_BITS , 1 ) ; for ( i = 0 ; i < 6 ; i + + ) { if ( i < 4 ) { dmv_x[0] = dmv_y[0] = pred_flag[0] = 0 ; dmv_x[1] = dmv_y[1] = pred_flag[1] = 0 ; val = ( ( v - > fourmvbp > > ( 3 - i ) ) & 1 ) ; if ( val ) { get_mvdata_interlaced ( v , & dmv_x[bmvtype == BMV_TYPE_BACKWARD] , & dmv_y[bmvtype == BMV_TYPE_BACKWARD] , & pred_flag[bmvtype == BMV_TYPE_BACKWARD] ) ; } vc1_pred_b_mv_intfi ( v , i , dmv_x , dmv_y , 0 , pred_flag ) ; vc1_mc_4mv_luma ( v , i , bmvtype == BMV_TYPE_BACKWARD ) ; } else if ( i == 4 ) vc1_mc_4mv_chroma ( v , bmvtype == BMV_TYPE_BACKWARD ) ; } mb_has_coeffs = idx_mbmode & 1 ; } if ( mb_has_coeffs ) cbp = 1 + get_vlc2",0
"static int hls_window ( AVFormatContext * s , int last ) { HLSContext * hls = s - > priv_data ; ListEntry * en ; int64_t target_duration = 0 ; int ret = 0 ; AVIOContext * out = NULL ; char temp_filename[1024] ; int64_t sequence = FFMAX ( hls - > start_sequence , hls - > sequence - hls - > size ) ; snprintf ( temp_filename , sizeof ( temp_filename ) , %s . tmp , s - > filename ) ; if ( ( ret = avio_open2 ( & out , temp_filename , AVIO_FLAG_WRITE , & s - > interrupt_callback , NULL ) ) < 0 ) goto fail ; for ( en = hls - > list ; en ; en = en - > next ) { if ( target_duration < en - > duration ) target_duration = en - > duration ; } avio_printf ( out , EXTM3U\n ) ; avio_printf ( out , EXT - X - VERSION : %d\n , hls - > version ) ; if ( hls - > allowcache == 0 || hls - > allowcache == 1 ) { avio_printf ( out , EXT - X - ALLOW - CACHE : %s\n , hls - > allowcache == 0 ? NO : YES ) ; } avio_printf ( out , EXT - X - TARGETDURATION : % PRId64 \n , av_rescale_rnd ( target_duration , 1 , AV_TIME_BASE , AV_ROUND_UP ) ) ; avio_printf ( out , EXT - X - MEDIA - SEQUENCE : % PRId64 \n , sequence ) ; av_log ( s , AV_LOG_VERBOSE , EXT - X - MEDIA - SEQUENCE : % PRId64 \n , sequence ) ; for ( en = hls - > list ; en ; en = en - > next ) { if ( hls - > version > 2 ) avio_printf ( out , EXTINF : %f\n , ( double ) en - > duration / AV_TIME_BASE ) ; else avio_printf ( out , EXTINF : % PRId64 , \n , av_rescale ( en - > duration , 1 , AV_TIME_BASE ) ) ; if ( hls - > baseurl ) avio_printf ( out , %s , hls - > baseurl ) ; avio_printf ( out , %s\n , en - > name ) ; } if ( last ) avio_printf ( out , EXT - X - ENDLIST\n ) ; fail : avio_closep ( & out ) ; if ( ret > = 0 ) ff_rename ( temp_filename , s - > filename ) ; return ret ; }",0
"static av_cold int imc_decode_init ( AVCodecContext * avctx ) { int i , j , ret ; IMCContext * q = avctx - > priv_data ; double r1 , r2 ; if ( ( avctx - > codec_id == AV_CODEC_ID_IMC & & avctx - > channels ! = 1 ) || ( avctx - > codec_id == AV_CODEC_ID_IAC & & avctx - > channels > 2 ) ) { av_log_ask_for_sample ( avctx , Number of channels is not supported\n ) ; return AVERROR_PATCHWELCOME ; } for ( j = 0 ; j < avctx - > channels ; j + + ) { q - > chctx[j] . decoder_reset = 1 ; for ( i = 0 ; i < BANDS ; i + + ) q - > chctx[j] . old_floor[i] = 1 . 0 ; for ( i = 0 ; i < COEFFS / 2 ; i + + ) q - > chctx[j] . last_fft_im[i] = 0 ; } / * Build mdct window , a simple sine window normalized with sqrt ( 2 ) * / ff_sine_window_init ( q - > mdct_sine_window , COEFFS ) ; for ( i = 0 ; i < COEFFS ; i + + ) q - > mdct_sine_window[i] * = sqrt ( 2 . 0 ) ; for ( i = 0 ; i < COEFFS / 2 ; i + + ) { q - > post_cos[i] = ( 1 . 0f / 32768 ) * cos ( i / 256 . 0 * M_PI ) ; q - > post_sin[i] = ( 1 . 0f / 32768 ) * sin ( i / 256 . 0 * M_PI ) ; r1 = sin ( ( i * 4 . 0 + 1 . 0 ) / 1024 . 0 * M_PI ) ; r2 = cos ( ( i * 4 . 0 + 1 . 0 ) / 1024 . 0 * M_PI ) ; if ( i & 0x1 ) { q - > pre_coef1[i] = ( r1 + r2 ) * sqrt ( 2 . 0 ) ; q - > pre_coef2[i] = - ( r1 - r2 ) * sqrt ( 2 . 0 ) ; } else { q - > pre_coef1[i] = - ( r1 + r2 ) * sqrt ( 2 . 0 ) ; q - > pre_coef2[i] = ( r1 - r2 ) * sqrt ( 2 . 0 ) ; } } / * Generate a square root table * / for ( i = 0 ; i < 30 ; i + + ) q - > sqrt_tab[i] = sqrt ( i ) ; / * initialize the VLC tables * / for ( i = 0 ; i < 4 ; i + + ) { for ( j = 0 ; j < 4 ; j + + ) { huffman_vlc[i][j] . table = & vlc_tables[vlc_offsets[i * 4 + j]] ; huffman_vlc[i][j] . table_allocated = vlc_offsets[i * 4 + j + 1] - vlc_offsets[i * 4 + j] ; init_vlc ( & huffman_vlc[i][j] , 9 , imc_huffman_sizes[i] , imc_huffman_lens[i][j] , 1 , 1 , imc_huffman_bits[i][j] , 2 , 2 , INIT_VLC_USE_NEW_STATIC ) ; } } if ( avctx - > codec_id == AV_CODEC_ID_IAC ) { iac_generate_tabs ( q , avctx - > sample_rate ) ; } else { memcpy ( q - > cyclTab , cyclTab , sizeof ( cyclTab ) ) ; memcpy ( q - > cyclTab2 , cyclTab2 , sizeof ( cyclTab2 ) ) ; memcpy ( q - > weights1 , imc_weights1 , sizeof ( imc_weights1 ) ) ; memcpy ( q - > weights2 , imc_weights2 , sizeof ( imc_weights2 ) ) ; } if ( ( ret = ff_fft_init ( & q - > fft , 7 , 1 ) ) ) { av_log ( avctx , AV_LOG_INFO , FFT init failed\n ) ; return ret ; } ff_dsputil_init ( & q - > dsp , avctx ) ; avctx - > sample_fmt = AV_SAMPLE_FMT_FLTP ; avctx - > channel_layout = avctx - > channels == 1 ? AV_CH_LAYOUT_MONO : AV_CH_LAYOUT_STEREO ; avcodec_get_frame_defaults ( & q - > frame ) ; avctx - > coded_frame = & q - > frame ; return 0 ; }",0
"static int vorbis_parse_setup_hdr_mappings ( vorbis_context * vc ) { GetBitContext * gb= & vc - > gb ; uint_fast8_t i , j ; vc - > mapping_count=get_bits ( gb , 6 ) + 1 ; vc - > mappings= ( vorbis_mapping * ) av_mallocz ( vc - > mapping_count * sizeof ( vorbis_mapping ) ) ; AV_DEBUG ( There are %d mappings . \n , vc - > mapping_count ) ; for ( i=0 ; i < vc - > mapping_count ; + + i ) { vorbis_mapping * mapping_setup= & vc - > mappings[i] ; if ( get_bits ( gb , 16 ) ) { av_log ( vc - > avccontext , AV_LOG_ERROR , Other mappings than type 0 are not compliant with the Vorbis I specification . \n ) ; return 1 ; } if ( get_bits1 ( gb ) ) { mapping_setup - > submaps=get_bits ( gb , 4 ) + 1 ; } else { mapping_setup - > submaps=1 ; } if ( get_bits1 ( gb ) ) { mapping_setup - > coupling_steps=get_bits ( gb , 8 ) + 1 ; mapping_setup - > magnitude= ( uint_fast8_t * ) av_mallocz ( mapping_setup - > coupling_steps * sizeof ( uint_fast8_t ) ) ; mapping_setup - > angle= ( uint_fast8_t * ) av_mallocz ( mapping_setup - > coupling_steps * sizeof ( uint_fast8_t ) ) ; for ( j=0 ; j < mapping_setup - > coupling_steps ; + + j ) { mapping_setup - > magnitude[j]=get_bits ( gb , ilog ( vc - > audio_channels - 1 ) ) ; mapping_setup - > angle[j]=get_bits ( gb , ilog ( vc - > audio_channels - 1 ) ) ; // FIXME : sanity checks } } else { mapping_setup - > coupling_steps=0 ; } AV_DEBUG ( %d mapping coupling steps : %d \n , i , mapping_setup - > coupling_steps ) ; if ( get_bits ( gb , 2 ) ) { av_log ( vc - > avccontext , AV_LOG_ERROR , %d . mapping setup data invalid . \n , i ) ; return 1 ; // following spec . } if ( mapping_setup - > submaps > 1 ) { mapping_setup - > mux= ( uint_fast8_t * ) av_mallocz ( vc - > audio_channels * sizeof ( uint_fast8_t ) ) ; for ( j=0 ; j < vc - > audio_channels ; + + j ) { mapping_setup - > mux[j]=get_bits ( gb , 4 ) ; } } for ( j=0 ; j < mapping_setup - > submaps ; + + j ) { skip_bits ( gb , 8 ) ; // FIXME check ? mapping_setup - > submap_floor[j]=get_bits ( gb , 8 ) ; mapping_setup - > submap_residue[j]=get_bits ( gb , 8 ) ; AV_DEBUG ( %d mapping %d submap : floor %d , residue %d \n , i , j , mapping_setup - > submap_floor[j] , mapping_setup - > submap_residue[j] ) ; } } return 0 ; }",0
"static int http_prepare_data ( HTTPContext * c , long cur_time ) { int i ; switch ( c - > state ) { case HTTPSTATE_SEND_DATA_HEADER : memset ( & c - > fmt_ctx , 0 , sizeof ( c - > fmt_ctx ) ) ; pstrcpy ( c - > fmt_ctx . author , sizeof ( c - > fmt_ctx . author ) , c - > stream - > author ) ; pstrcpy ( c - > fmt_ctx . comment , sizeof ( c - > fmt_ctx . comment ) , c - > stream - > comment ) ; pstrcpy ( c - > fmt_ctx . copyright , sizeof ( c - > fmt_ctx . copyright ) , c - > stream - > copyright ) ; pstrcpy ( c - > fmt_ctx . title , sizeof ( c - > fmt_ctx . title ) , c - > stream - > title ) ; if ( c - > stream - > feed ) { / * open output stream by using specified codecs * / c - > fmt_ctx . oformat = c - > stream - > fmt ; c - > fmt_ctx . nb_streams = c - > stream - > nb_streams ; for ( i=0 ; i < c - > fmt_ctx . nb_streams ; i + + ) { AVStream * st ; st = av_mallocz ( sizeof ( AVStream ) ) ; c - > fmt_ctx . streams[i] = st ; if ( c - > stream - > feed == c - > stream ) memcpy ( st , c - > stream - > streams[i] , sizeof ( AVStream ) ) ; else memcpy ( st , c - > stream - > feed - > streams[c - > stream - > feed_streams[i]] , sizeof ( AVStream ) ) ; st - > codec . frame_number = 0 ; / * XXX : should be done in AVStream , not in codec * / } c - > got_key_frame = 0 ; } else { / * open output stream by using codecs in specified file * / c - > fmt_ctx . oformat = c - > stream - > fmt ; c - > fmt_ctx . nb_streams = c - > fmt_in - > nb_streams ; for ( i=0 ; i < c - > fmt_ctx . nb_streams ; i + + ) { AVStream * st ; st = av_mallocz ( sizeof ( AVStream ) ) ; c - > fmt_ctx . streams[i] = st ; memcpy ( st , c - > fmt_in - > streams[i] , sizeof ( AVStream ) ) ; st - > codec . frame_number = 0 ; / * XXX : should be done in AVStream , not in codec * / } c - > got_key_frame = 0 ; } init_put_byte ( & c - > fmt_ctx . pb , c - > pbuffer , c - > pbuffer_size , 1 , c , NULL , http_write_packet , NULL ) ; c - > fmt_ctx . pb . is_streamed = 1 ; / * prepare header * / av_write_header ( & c - > fmt_ctx ) ; c - > state = HTTPSTATE_SEND_DATA ; c - > last_packet_sent = 0 ; break ; case HTTPSTATE_SEND_DATA : / * find a new packet * / if 0 fifo_total_size = http_fifo_write_count - c - > last_http_fifo_write_count ; if ( fifo_total_size > = ( ( 3 * FIFO_MAX_SIZE ) / 4 ) ) { / * overflow : resync . We suppose that wptr is at this point a pointer to a valid packet * / c - > rptr = http_fifo . wptr ; c - > got_key_frame = 0 ; } start_rptr = c - > rptr ; if ( fifo_read ( & http_fifo , ( UINT8 * ) & hdr , sizeof ( hdr ) , & c - > rptr ) < 0 ) return 0 ; payload_size = ntohs ( hdr . payload_size ) ; payload = av_malloc ( payload_size ) ; if ( fifo_read ( & http_fifo , payload , payload_size , & c - > rptr ) < 0 ) { / * cannot read all the payload * / av_free ( payload ) ; c - > rptr = start_rptr ; return 0 ; } c - > last_http_fifo_write_count = http_fifo_write_count - fifo_size ( & http_fifo , c - > rptr ) ; if ( c - > stream - > stream_type ! = STREAM_TYPE_MASTER ) { / * test if the packet can be handled by this format * / ret = 0 ; for ( i=0 ; i < c - > fmt_ctx . nb_streams ; i + + ) { AVStream * st = c - > fmt_ctx . streams[i] ; if ( test_header ( & hdr , & st - > codec ) ) { / * only begin sending when got a key frame * / if ( st - > codec . key_frame ) c - > got_key_frame |= 1 < < i ; if ( c - > got_key_frame & ( 1 < < i ) ) { ret = c - > fmt_ctx . format - > write_packet ( & c - > fmt_ctx , i , payload , payload_size ) ; } break ; } } if ( ret ) { / * must send trailer now * / c - > state = HTTPSTATE_SEND_DATA_TRAILER ; } } else { / * master case : send everything * / char * q ; q = c - > buffer ; memcpy ( q , & hdr , sizeof ( hdr ) ) ; q + = sizeof ( hdr ) ; memcpy ( q , payload , payload_size ) ; q + = payload_size ; c - > buffer_ptr = c - > buffer ; c - > buffer_end = q ; } av_free ( payload ) ; endif { AVPacket pkt ; / * read a packet from the input stream * / if ( c - > stream - > feed ) { ffm_set_write_index ( c - > fmt_in , c - > stream - > feed - > feed_write_index , c - > stream - > feed - > feed_size ) ; } if ( c - > stream - > max_time & & c - > stream - > max_time + c - > start_time - cur_time < 0 ) { / * We have timed out * / c - > state = HTTPSTATE_SEND_DATA_TRAILER ; } else if ( av_read_packet ( c - > fmt_in , & pkt ) < 0 ) { if ( c - > stream - > feed & & c - > stream - > feed - > feed_opened ) { / * if coming from feed , it means we reached the end of the ffm file , so must wait for more data * / c - > state = HTTPSTATE_WAIT_FEED ; return 1 ; / * state changed * / } else { / * must send trailer now because eof or",1
"static int decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * pkt ) { BinkContext * const c = avctx - > priv_data ; GetBitContext gb ; int blk ; int i , j , plane , plane_idx , bx , by ; uint8_t * dst , * prev , * ref , * ref_start , * ref_end ; int v , col[2] ; const uint8_t * scan ; int xoff , yoff ; DECLARE_ALIGNED_16 ( DCTELEM , block[64] ) ; DECLARE_ALIGNED_16 ( uint8_t , ublock[64] ) ; int coordmap[64] ; if ( c - > pic . data[0] ) avctx - > release_buffer ( avctx , & c - > pic ) ; if ( avctx - > get_buffer ( avctx , & c - > pic ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed\n ) ; return - 1 ; } init_get_bits ( & gb , pkt - > data , pkt - > size * 8 ) ; if ( c - > version > = ' i ' ) skip_bits_long ( & gb , 32 ) ; for ( plane = 0 ; plane < 3 ; plane + + ) { const int stride = c - > pic . linesize[plane] ; int bw = plane ? ( avctx - > width + 15 ) > > 4 : ( avctx - > width + 7 ) > > 3 ; int bh = plane ? ( avctx - > height + 15 ) > > 4 : ( avctx - > height + 7 ) > > 3 ; int width = avctx - > width > > ! ! plane ; init_lengths ( c , FFMAX ( width , 8 ) , bw ) ; for ( i = 0 ; i < BINK_NB_SRC ; i + + ) read_bundle ( & gb , c , i ) ; plane_idx = ( ! plane || ! c - > swap_planes ) ? plane : ( plane 3 ) ; ref_start = c - > last . data[plane_idx] ; ref_end = c - > last . data[plane_idx] + ( bw - 1 + c - > last . linesize[plane_idx] * ( bh - 1 ) ) * 8 ; for ( i = 0 ; i < 64 ; i + + ) coordmap[i] = ( i & 7 ) + ( i > > 3 ) * stride ; for ( by = 0 ; by < bh ; by + + ) { if ( read_block_types ( avctx , & gb , & c - > bundle[BINK_SRC_BLOCK_TYPES] ) < 0 ) return - 1 ; if ( read_block_types ( avctx , & gb , & c - > bundle[BINK_SRC_SUB_BLOCK_TYPES] ) < 0 ) return - 1 ; if ( read_colors ( & gb , & c - > bundle[BINK_SRC_COLORS] , c ) < 0 ) return - 1 ; if ( read_patterns ( avctx , & gb , & c - > bundle[BINK_SRC_PATTERN] ) < 0 ) return - 1 ; if ( read_motion_values ( avctx , & gb , & c - > bundle[BINK_SRC_X_OFF] ) < 0 ) return - 1 ; if ( read_motion_values ( avctx , & gb , & c - > bundle[BINK_SRC_Y_OFF] ) < 0 ) return - 1 ; if ( read_dcs ( avctx , & gb , & c - > bundle[BINK_SRC_INTRA_DC] , DC_START_BITS , 0 ) < 0 ) return - 1 ; if ( read_dcs ( avctx , & gb , & c - > bundle[BINK_SRC_INTER_DC] , DC_START_BITS , 1 ) < 0 ) return - 1 ; if ( read_runs ( avctx , & gb , & c - > bundle[BINK_SRC_RUN] ) < 0 ) return - 1 ; if ( by == bh ) break ; dst = c - > pic . data[plane_idx] + 8 * by * stride ; prev = c - > last . data[plane_idx] + 8 * by * stride ; for ( bx = 0 ; bx < bw ; bx + + , dst + = 8 , prev + = 8 ) { blk = get_value ( c , BINK_SRC_BLOCK_TYPES ) ; // 16x16 block type on odd line means part of the already decoded block , so skip it if ( ( by & 1 ) & & blk == SCALED_BLOCK ) { bx + + ; dst + = 8 ; prev + = 8 ; continue ; } switch ( blk ) { case SKIP_BLOCK : c - > dsp . put_pixels_tab[1][0] ( dst , prev , stride , 8 ) ; break ; case SCALED_BLOCK : blk = get_value ( c , BINK_SRC_SUB_BLOCK_TYPES ) ; switch ( blk ) { case RUN_BLOCK : scan = bink_patterns[get_bits ( & gb , 4 ) ] ; i = 0 ; do { int run = get_value ( c , BINK_SRC_RUN ) + 1 ; i + = run ; if ( i > 64 ) { av_log ( avctx , AV_LOG_ERROR , Run went out of bounds\n ) ; return - 1 ; } if ( get_bits1 ( & gb ) ) { v = get_value ( c , BINK_SRC_COLORS ) ; for ( j = 0 ; j < run ; j + + ) ublock[ * scan + + ] = v ; } else { for ( j = 0 ; j < run ; j + + ) ublock[ * scan + + ] = get_value ( c , BINK_SRC_COLORS ) ; } } while ( i < 63 ) ; if ( i == 63 ) ublock[ * scan + + ] = get_value ( c , BINK_SRC_COLORS ) ; break ; case INTRA_BLOCK : c - > dsp . clear_block ( block ) ; block[0] = get_value ( c , BINK_SRC_INTRA_DC ) ; read_dct_coeffs ( & gb , block , c - > scantable . permutated , 1 ) ; c - > dsp . idct ( block ) ; c - > dsp . put_pixels_nonclamped ( block , ublock , 8 ) ; break ; case FILL_BLOCK : v = get_value ( c , BINK_SRC_COLORS ) ; c - > dsp . fill_block_tab[0] ( dst , v , stride , 16 ) ; break ; case PATTERN_BLOCK : for ( i = 0 ; i < 2 ; i + + ) col[i] = get_value ( c , BINK_SRC_COLORS ) ; for ( j = 0 ; j < 8 ; j + + ) { v = get_value ( c , BINK_SRC_PATTERN ) ; for ( i = 0 ; i < 8 ; i + + , v > > = 1 ) ublock[i + j * 8] = col[v & 1] ; } break ; case RAW_BLOCK : for ( j = 0 ; j < 8 ; j + + ) for ( i = 0 ; i < 8 ; i + + ) ublock[i + j * 8] = get_value ( c , BINK_SRC_COLORS ) ; break ; default : av_log ( avctx ,",1
"static int png_write_row ( PNGContext * s , const uint8_t * data , int size ) { int ret ; s - > zstream . avail_in = size ; s - > zstream . next_in = ( uint8_t * ) data ; while ( s - > zstream . avail_in > 0 ) { ret = deflate ( & s - > zstream , Z_NO_FLUSH ) ; if ( ret ! = Z_OK ) return - 1 ; if ( s - > zstream . avail_out == 0 ) { png_write_chunk ( & s - > bytestream , MKTAG ( ' I ' , ' D ' , ' A ' , ' T ' ) , s - > buf , IOBUF_SIZE ) ; s - > zstream . avail_out = IOBUF_SIZE ; s - > zstream . next_out = s - > buf ; } } return 0 ; }",1
"AVBufferRef * av_buffer_pool_get ( AVBufferPool * pool ) { AVBufferRef * ret ; BufferPoolEntry * buf ; / * check whether the pool is empty * / buf = get_pool ( pool ) ; if ( ! buf ) return pool_alloc_buffer ( pool ) ; / * keep the first entry , return the rest of the list to the pool * / add_to_pool ( buf - > next ) ; buf - > next = NULL ; ret = av_buffer_create ( buf - > data , pool - > size , pool_release_buffer , buf , 0 ) ; if ( ! ret ) { add_to_pool ( buf ) ; return NULL ; } avpriv_atomic_int_add_and_fetch ( & pool - > refcount , 1 ) ; return ret ; }",1
"static void FUNCC ( pred4x4_127_dc ) ( uint8_t * _src , const uint8_t * topright , int _stride ) { pixel * src = ( pixel * ) _src ; int stride = _stride/sizeof ( pixel ) ; ( ( pixel4 * ) ( src + 0 * stride ) ) [0]= ( ( pixel4 * ) ( src + 1 * stride ) ) [0]= ( ( pixel4 * ) ( src + 2 * stride ) ) [0]= ( ( pixel4 * ) ( src + 3 * stride ) ) [0]= PIXEL_SPLAT_X4 ( ( 1 < < ( BIT_DEPTH - 1 ) ) - 1 ) ; }",1
"av_cold int ff_vaapi_encode_close ( AVCodecContext * avctx ) { VAAPIEncodeContext * ctx = avctx - > priv_data ; VAAPIEncodePicture * pic , * next ; for ( pic = ctx - > pic_start ; pic ; pic = next ) { next = pic - > next ; vaapi_encode_free ( avctx , pic ) ; } if ( ctx - > va_context ! = VA_INVALID_ID ) vaDestroyContext ( ctx - > hwctx - > display , ctx - > va_context ) ; if ( ctx - > va_config ! = VA_INVALID_ID ) vaDestroyConfig ( ctx - > hwctx - > display , ctx - > va_config ) ; if ( ctx - > codec - > close ) ctx - > codec - > close ( avctx ) ; av_freep ( & ctx - > codec_sequence_params ) ; av_freep ( & ctx - > codec_picture_params ) ; av_buffer_unref ( & ctx - > recon_frames_ref ) ; av_buffer_unref ( & ctx - > input_frames_ref ) ; av_buffer_unref ( & ctx - > device_ref ) ; av_freep ( & ctx - > priv_data ) ; return 0 ; }",1
"static void vp6_parse_coeff_models ( VP56Context * s ) { VP56RangeCoder * c = & s - > c ; VP56Model * model = s - > modelp ; int def_prob[11] ; int node , cg , ctx , pos ; int ct ; / * code type * / int pt ; / * plane type ( 0 for Y , 1 for U or V ) * / memset ( def_prob , 0x80 , sizeof ( def_prob ) ) ; for ( pt=0 ; pt < 2 ; pt + + ) for ( node=0 ; node < 11 ; node + + ) if ( vp56_rac_get_prob ( c , vp6_dccv_pct[pt][node] ) ) { def_prob[node] = vp56_rac_gets_nn ( c , 7 ) ; model - > coeff_dccv[pt][node] = def_prob[node] ; } else if ( s - > framep[VP56_FRAME_CURRENT] - > key_frame ) { model - > coeff_dccv[pt][node] = def_prob[node] ; } if ( vp56_rac_get ( c ) ) { for ( pos=1 ; pos < 64 ; pos + + ) if ( vp56_rac_get_prob ( c , vp6_coeff_reorder_pct[pos] ) ) model - > coeff_reorder[pos] = vp56_rac_gets ( c , 4 ) ; vp6_coeff_order_table_init ( s ) ; } for ( cg=0 ; cg < 2 ; cg + + ) for ( node=0 ; node < 14 ; node + + ) if ( vp56_rac_get_prob ( c , vp6_runv_pct[cg][node] ) ) model - > coeff_runv[cg][node] = vp56_rac_gets_nn ( c , 7 ) ; for ( ct=0 ; ct < 3 ; ct + + ) for ( pt=0 ; pt < 2 ; pt + + ) for ( cg=0 ; cg < 6 ; cg + + ) for ( node=0 ; node < 11 ; node + + ) if ( vp56_rac_get_prob ( c , vp6_ract_pct[ct][pt][cg][node] ) ) { def_prob[node] = vp56_rac_gets_nn ( c , 7 ) ; model - > coeff_ract[pt][ct][cg][node] = def_prob[node] ; } else if ( s - > framep[VP56_FRAME_CURRENT] - > key_frame ) { model - > coeff_ract[pt][ct][cg][node] = def_prob[node] ; } if ( s - > use_huffman ) { for ( pt=0 ; pt < 2 ; pt + + ) { vp6_build_huff_tree ( s , model - > coeff_dccv[pt] , vp6_huff_coeff_map , 12 , & s - > dccv_vlc[pt] ) ; vp6_build_huff_tree ( s , model - > coeff_runv[pt] , vp6_huff_run_map , 9 , & s - > runv_vlc[pt] ) ; for ( ct=0 ; ct < 3 ; ct + + ) for ( cg = 0 ; cg < 6 ; cg + + ) vp6_build_huff_tree ( s , model - > coeff_ract[pt][ct][cg] , vp6_huff_coeff_map , 12 , & s - > ract_vlc[pt][ct][cg] ) ; } memset ( s - > nb_null , 0 , sizeof ( s - > nb_null ) ) ; } else { / * coeff_dcct is a linear combination of coeff_dccv * / for ( pt=0 ; pt < 2 ; pt + + ) for ( ctx=0 ; ctx < 3 ; ctx + + ) for ( node=0 ; node < 5 ; node + + ) model - > coeff_dcct[pt][ctx][node] = av_clip ( ( ( model - > coeff_dccv[pt][node] * vp6_dccv_lc[ctx][node][0] + 128 ) > > 8 ) + vp6_dccv_lc[ctx][node][1] , 1 , 255 ) ; } }",0
"static int trim_filter_frame ( AVFilterLink * inlink , AVFrame * frame ) { AVFilterContext * ctx = inlink - > dst ; TrimContext * s = ctx - > priv ; int drop ; / * drop everything if EOF has already been returned * / if ( s - > eof ) { av_frame_free ( & frame ) ; return 0 ; } if ( s - > start_frame > = 0 || s - > start_pts ! = AV_NOPTS_VALUE ) { drop = 1 ; if ( s - > start_frame > = 0 & & s - > nb_frames > = s - > start_frame ) drop = 0 ; if ( s - > start_pts ! = AV_NOPTS_VALUE & & frame - > pts ! = AV_NOPTS_VALUE & & frame - > pts > = s - > start_pts ) drop = 0 ; if ( drop ) goto drop ; } if ( s - > first_pts == AV_NOPTS_VALUE & & frame - > pts ! = AV_NOPTS_VALUE ) s - > first_pts = frame - > pts ; if ( s - > end_frame ! = INT64_MAX || s - > end_pts ! = AV_NOPTS_VALUE || s - > duration_tb ) { drop = 1 ; if ( s - > end_frame ! = INT64_MAX & & s - > nb_frames < s - > end_frame ) drop = 0 ; if ( s - > end_pts ! = AV_NOPTS_VALUE & & frame - > pts ! = AV_NOPTS_VALUE & & frame - > pts < s - > end_pts ) drop = 0 ; if ( s - > duration_tb & & frame - > pts ! = AV_NOPTS_VALUE & & frame - > pts - s - > first_pts < s - > duration_tb ) drop = 0 ; if ( drop ) { s - > eof = 1 ; goto drop ; } } s - > nb_frames + + ; s - > got_output = 1 ; return ff_filter_frame ( ctx - > outputs[0] , frame ) ; drop : s - > nb_frames + + ; av_frame_free ( & frame ) ; return 0 ; }",0
"static void RENAME ( yuv2rgb32_2 ) ( SwsContext * c , const uint16_t * buf0 , const uint16_t * buf1 , const uint16_t * ubuf0 , const uint16_t * ubuf1 , const uint16_t * vbuf0 , const uint16_t * vbuf1 , const uint16_t * abuf0 , const uint16_t * abuf1 , uint8_t * dest , int dstW , int yalpha , int uvalpha , int y ) { if ( CONFIG_SWSCALE_ALPHA & & c - > alpPixBuf ) { if ARCH_X86_64 __asm__ volatile ( YSCALEYUV2RGB ( %%r8 , %5 ) YSCALEYUV2RGB_YA ( %%r8 , %5 , %6 , %7 ) psraw 3 , %%mm1 \n\t / * abuf0[eax] - abuf1[eax] > > 7 * / psraw 3 , %%mm7 \n\t / * abuf0[eax] - abuf1[eax] > > 7 * / packuswb %%mm7 , %%mm1 \n\t WRITEBGR32 ( %4 , 8280 ( %5 ) , %%r8 , %%mm2 , %%mm4 , %%mm5 , %%mm1 , %%mm0 , %%mm7 , %%mm3 , %%mm6 ) : : c ( buf0 ) , d ( buf1 ) , S ( ubuf0 ) , D ( ubuf1 ) , r ( dest ) , a ( & c - > redDither ) , r ( abuf0 ) , r ( abuf1 ) : %r8 ) ; else * ( const uint16_t * * ) ( & c - > u_temp ) =abuf0 ; * ( const uint16_t * * ) ( & c - > v_temp ) =abuf1 ; __asm__ volatile ( mov %% REG_b , ESP_OFFSET ( %5 ) \n\t mov %4 , %% REG_b \n\t push %% REG_BP \n\t YSCALEYUV2RGB ( %%REGBP , %5 ) push %0 \n\t push %1 \n\t mov U_TEMP ( %5 ) , %0 \n\t mov V_TEMP ( %5 ) , %1 \n\t YSCALEYUV2RGB_YA ( %%REGBP , %5 , %0 , %1 ) psraw 3 , %%mm1 \n\t / * abuf0[eax] - abuf1[eax] > > 7 * / psraw 3 , %%mm7 \n\t / * abuf0[eax] - abuf1[eax] > > 7 * / packuswb %%mm7 , %%mm1 \n\t pop %1 \n\t pop %0 \n\t WRITEBGR32 ( %%REGb , 8280 ( %5 ) , %%REGBP , %%mm2 , %%mm4 , %%mm5 , %%mm1 , %%mm0 , %%mm7 , %%mm3 , %%mm6 ) pop %% REG_BP \n\t mov ESP_OFFSET ( %5 ) , %% REG_b \n\t : : c ( buf0 ) , d ( buf1 ) , S ( ubuf0 ) , D ( ubuf1 ) , m ( dest ) , a ( & c - > redDither ) ) ; endif } else { __asm__ volatile ( mov %% REG_b , ESP_OFFSET ( %5 ) \n\t mov %4 , %% REG_b \n\t push %% REG_BP \n\t YSCALEYUV2RGB ( %%REGBP , %5 ) pcmpeqd %%mm7 , %%mm7 \n\t WRITEBGR32 ( %%REGb , 8280 ( %5 ) , %%REGBP , %%mm2 , %%mm4 , %%mm5 , %%mm7 , %%mm0 , %%mm1 , %%mm3 , %%mm6 ) pop %% REG_BP \n\t mov ESP_OFFSET ( %5 ) , %% REG_b \n\t : : c ( buf0 ) , d ( buf1 ) , S ( ubuf0 ) , D ( ubuf1 ) , m ( dest ) , a ( & c - > redDither ) ) ; } }",0
"static int read_line ( AVIOContext * pb , char * line , int bufsize ) { int i ; for ( i = 0 ; i < bufsize - 1 ; i + + ) { int b = avio_r8 ( pb ) ; if ( b == 0 ) break ; if ( b == ' \n ' ) { line[i] = ' \0 ' ; return 0 ; } line[i] = b ; } line[i] = ' \0 ' ; return - 1 ; }",0
"static int tiff_decode_tag ( TiffContext * s ) { unsigned tag , type , count , off , value = 0 ; int i , j , k , pos , start ; int ret ; uint32_t * pal ; double * dp ; tag = tget_short ( & s - > gb , s - > le ) ; type = tget_short ( & s - > gb , s - > le ) ; count = tget_long ( & s - > gb , s - > le ) ; off = tget_long ( & s - > gb , s - > le ) ; start = bytestream2_tell ( & s - > gb ) ; if ( type == 0 || type > = FF_ARRAY_ELEMS ( type_sizes ) ) { av_log ( s - > avctx , AV_LOG_DEBUG , Unknown tiff type ( %u ) encountered\n , type ) ; return 0 ; } if ( count == 1 ) { switch ( type ) { case TIFF_BYTE : case TIFF_SHORT : bytestream2_seek ( & s - > gb , - 4 , SEEK_CUR ) ; value = tget ( & s - > gb , type , s - > le ) ; break ; case TIFF_LONG : value = off ; break ; case TIFF_STRING : if ( count < = 4 ) { bytestream2_seek ( & s - > gb , - 4 , SEEK_CUR ) ; break ; } default : value = UINT_MAX ; bytestream2_seek ( & s - > gb , off , SEEK_SET ) ; } } else { if ( count < = 4 & & type_sizes[type] * count < = 4 ) { bytestream2_seek ( & s - > gb , - 4 , SEEK_CUR ) ; } else { bytestream2_seek ( & s - > gb , off , SEEK_SET ) ; } } switch ( tag ) { case TIFF_WIDTH : s - > width = value ; break ; case TIFF_HEIGHT : s - > height = value ; break ; case TIFF_BPP : s - > bppcount = count ; if ( count > 4 ) { av_log ( s - > avctx , AV_LOG_ERROR , This format is not supported ( bpp=%d , %d components ) \n , s - > bpp , count ) ; return AVERROR_INVALIDDATA ; } if ( count == 1 ) s - > bpp = value ; else { switch ( type ) { case TIFF_BYTE : s - > bpp = ( off & 0xFF ) + ( ( off > > 8 ) & 0xFF ) + ( ( off > > 16 ) & 0xFF ) + ( ( off > > 24 ) & 0xFF ) ; break ; case TIFF_SHORT : case TIFF_LONG : s - > bpp = 0 ; if ( bytestream2_get_bytes_left ( & s - > gb ) < type_sizes[type] * count ) return AVERROR_INVALIDDATA ; for ( i = 0 ; i < count ; i + + ) s - > bpp + = tget ( & s - > gb , type , s - > le ) ; break ; default : s - > bpp = - 1 ; } } break ; case TIFF_SAMPLES_PER_PIXEL : if ( count ! = 1 ) { av_log ( s - > avctx , AV_LOG_ERROR , Samples per pixel requires a single value , many provided\n ) ; return AVERROR_INVALIDDATA ; } if ( s - > bppcount == 1 ) s - > bpp * = value ; s - > bppcount = value ; break ; case TIFF_COMPR : s - > compr = value ; s - > predictor = 0 ; switch ( s - > compr ) { case TIFF_RAW : case TIFF_PACKBITS : case TIFF_LZW : case TIFF_CCITT_RLE : break ; case TIFF_G3 : case TIFF_G4 : s - > fax_opts = 0 ; break ; case TIFF_DEFLATE : case TIFF_ADOBE_DEFLATE : if CONFIG_ZLIB break ; else av_log ( s - > avctx , AV_LOG_ERROR , Deflate : ZLib not compiled in\n ) ; return AVERROR ( ENOSYS ) ; endif case TIFF_JPEG : case TIFF_NEWJPEG : av_log ( s - > avctx , AV_LOG_ERROR , JPEG compression is not supported\n ) ; return AVERROR_PATCHWELCOME ; default : av_log ( s - > avctx , AV_LOG_ERROR , Unknown compression method %i\n , s - > compr ) ; return AVERROR_INVALIDDATA ; } break ; case TIFF_ROWSPERSTRIP : if ( type == TIFF_LONG & & value == UINT_MAX ) value = s - > height ; if ( value < 1 ) { av_log ( s - > avctx , AV_LOG_ERROR , Incorrect value of rows per strip\n ) ; return AVERROR_INVALIDDATA ; } s - > rps = value ; break ; case TIFF_STRIP_OFFS : if ( count == 1 ) { s - > strippos = 0 ; s - > stripoff = value ; } else s - > strippos = off ; s - > strips = count ; if ( s - > strips == 1 ) s - > rps = s - > height ; s - > sot = type ; if ( s - > strippos > bytestream2_size ( & s - > gb ) ) { av_log ( s - > avctx , AV_LOG_ERROR , Tag referencing position outside the image\n ) ; return AVERROR_INVALIDDATA ; } break ; case TIFF_STRIP_SIZE : if ( count == 1 ) { s - > stripsizesoff = 0 ; s - > stripsize = value ; s - > strips = 1 ; } else { s - > stripsizesoff = off ; } s - > strips = count ; s - > sstype = type ; if ( s - > stripsizesoff > bytestream2_size ( & s - > gb ) ) { av_log ( s - > avctx , AV_LOG_ERROR , Tag referencing position outside the image\n ) ; return AVERROR_INVALIDDATA ; } break ; case TIFF_TILE_BYTE_COUNTS : case TIFF_TILE_LENGTH : case TIFF_TILE_OFFSETS : case TIFF_TILE_WIDTH : av_log ( s - > avctx , AV_LOG_ERROR , Tiled images are not supported\n ) ; return AVERROR_PATCHWELCOME ; break ; case TIFF_PREDICTOR : s - > predictor = value ; break ; case TIFF_INVERT : switch ( value ) { case 0 : s - > invert = 1 ; break ; case 1 : s - > invert = 0 ; break ; case 2 : case 3 : break ; default : av_log ( s - > avctx , AV_LOG_ERROR , Color mode %d is not supported\n , value ) ; return AVERROR_INVALIDDATA ; } break ; case TIFF_FILL_ORDER : if ( value < 1 || value > 2 ) { av_log ( s - > avctx , AV_LOG_ERROR , Unknown FillOrder value %d , trying default one\n , value ) ; value = 1 ; } s - > fill_order = value - 1 ; break ; case TIFF_PAL : pal = ( uint32_t * ) s - > palette ; off = type_sizes[type] ; if ( count / 3",0
"void av_log_default_callback ( void * avcl , int level , const char * fmt , va_list vl ) { static int print_prefix = 1 ; static int count ; static char prev[1024] ; char line[1024] ; static int is_atty ; AVClass * avc = avcl ? * ( AVClass * * ) avcl : NULL ; int tint = av_clip ( level > > 8 , 0 , 256 ) ; level & = 0xff ; if ( level > av_log_level ) return ; line[0] = 0 ; if ( print_prefix & & avc ) { if ( avc - > parent_log_context_offset ) { AVClass * * parent = * ( AVClass * * * ) ( ( ( uint8_t * ) avcl ) + avc - > parent_log_context_offset ) ; if ( parent & & * parent ) { snprintf ( line , sizeof ( line ) , [%s %p] , ( * parent ) - > item_name ( parent ) , parent ) ; } } snprintf ( line + strlen ( line ) , sizeof ( line ) - strlen ( line ) , [%s %p] , avc - > item_name ( avcl ) , avcl ) ; } vsnprintf ( line + strlen ( line ) , sizeof ( line ) - strlen ( line ) , fmt , vl ) ; print_prefix = strlen ( line ) & & line[strlen ( line ) - 1] == ' \n ' ; if HAVE_ISATTY if ( ! is_atty ) is_atty = isatty ( 2 ) ? 1 : - 1 ; endif if ( print_prefix & & ( flags & AV_LOG_SKIP_REPEATED ) & & ! strncmp ( line , prev , sizeof line ) ) { count + + ; if ( is_atty == 1 ) fprintf ( stderr , Last message repeated %d times\r , count ) ; return ; } if ( count > 0 ) { fprintf ( stderr , Last message repeated %d times\n , count ) ; count = 0 ; } colored_fputs ( av_clip ( level > > 3 , 0 , 6 ) , tint , line ) ; av_strlcpy ( prev , line , sizeof line ) ; }",1
"static int scale_vector ( int16_t * dst , const int16_t * vector , int length ) { int bits , max = 0 ; int i ; for ( i = 0 ; i < length ; i + + ) max |= FFABS ( vector[i] ) ; bits = normalize_bits ( max , 15 ) ; if ( bits == 15 ) for ( i = 0 ; i < length ; i + + ) dst[i] = vector[i] * 0x7fff > > 3 ; else for ( i = 0 ; i < length ; i + + ) dst[i] = vector[i] < < bits > > 3 ; return bits - 3 ; }",1
"av_cold void ff_hpeldsp_vp3_init_x86 ( HpelDSPContext * c , int cpu_flags , int flags ) { if ( EXTERNAL_AMD3DNOW ( cpu_flags ) ) { if ( flags & AV_CODEC_FLAG_BITEXACT ) { c - > put_no_rnd_pixels_tab[1][1] = ff_put_no_rnd_pixels8_x2_exact_3dnow ; c - > put_no_rnd_pixels_tab[1][2] = ff_put_no_rnd_pixels8_y2_exact_3dnow ; } } if ( EXTERNAL_MMXEXT ( cpu_flags ) ) { if ( flags & AV_CODEC_FLAG_BITEXACT ) { c - > put_no_rnd_pixels_tab[1][1] = ff_put_no_rnd_pixels8_x2_exact_mmxext ; c - > put_no_rnd_pixels_tab[1][2] = ff_put_no_rnd_pixels8_y2_exact_mmxext ; } } }",0
"static int expand ( AVFilterContext * ctx , double * pz , int nb , double * coeffs ) { int i ; coeffs[0] = 1 . 0 ; coeffs[1] = 0 . 0 ; for ( i = 0 ; i < nb ; i + + ) { coeffs[2 * ( i + 1 ) ] = 0 . 0 ; coeffs[2 * ( i + 1 ) + 1] = 0 . 0 ; } for ( i = 0 ; i < nb ; i + + ) multiply ( pz[2 * i] , pz[2 * i + 1] , nb , coeffs ) ; for ( i = 0 ; i < nb + 1 ; i + + ) { if ( fabs ( coeffs[2 * i + 1] ) > DBL_EPSILON ) { av_log ( ctx , AV_LOG_ERROR , coeff : %lf of z %d is not real ; poles/zeros are not complex conjugates . \n , coeffs[2 * i + i] , i ) ; return AVERROR ( EINVAL ) ; } } return 0 ; }",0
"static int64_t ffm_seek1 ( AVFormatContext * s , int64_t pos1 ) { FFMContext * ffm = s - > priv_data ; AVIOContext * pb = s - > pb ; int64_t pos ; pos = FFMIN ( pos1 , ffm - > file_size - FFM_PACKET_SIZE ) ; pos = FFMAX ( pos , FFM_PACKET_SIZE ) ; av_dlog ( s , seek to % PRIx64 - > % PRIx64 \n , pos1 , pos ) ; return avio_seek ( pb , pos , SEEK_SET ) ; }",0
"static int raw_read_header ( AVFormatContext * s , AVFormatParameters * ap ) { AVStream * st ; int id ; st = av_new_stream ( s , 0 ) ; if ( ! st ) return AVERROR_NOMEM ; if ( ap ) { id = s - > iformat - > value ; if ( id == CODEC_ID_RAWVIDEO ) { st - > codec - > codec_type = CODEC_TYPE_VIDEO ; } else { st - > codec - > codec_type = CODEC_TYPE_AUDIO ; } st - > codec - > codec_id = id ; switch ( st - > codec - > codec_type ) { case CODEC_TYPE_AUDIO : st - > codec - > sample_rate = ap - > sample_rate ; st - > codec - > channels = ap - > channels ; av_set_pts_info ( st , 64 , 1 , st - > codec - > sample_rate ) ; break ; case CODEC_TYPE_VIDEO : av_set_pts_info ( st , 64 , ap - > time_base . num , ap - > time_base . den ) ; st - > codec - > width = ap - > width ; st - > codec - > height = ap - > height ; st - > codec - > pix_fmt = ap - > pix_fmt ; if ( st - > codec - > pix_fmt == PIX_FMT_NONE ) st - > codec - > pix_fmt= PIX_FMT_YUV420P ; break ; default : return - 1 ; } } else { return - 1 ; } return 0 ; }",0
static av_cold int twin_decode_close ( AVCodecContext * avctx ) { TwinContext * tctx = avctx - > priv_data ; int i ; for ( i = 0 ; i < 3 ; i + + ) { ff_mdct_end ( & tctx - > mdct_ctx[i] ) ; av_free ( tctx - > cos_tabs[i] ) ; } av_free ( tctx - > curr_frame ) ; av_free ( tctx - > spectrum ) ; av_free ( tctx - > prev_frame ) ; av_free ( tctx - > tmp_buf ) ; return 0 ; },1
"void prepare_grab ( void ) { int has_video , has_audio , i , j ; AVFormatContext * oc ; AVFormatContext * ic ; AVFormatParameters ap1 , * ap = & ap1 ; / * see if audio/video inputs are needed * / has_video = 0 ; has_audio = 0 ; memset ( ap , 0 , sizeof ( * ap ) ) ; for ( j=0 ; j < nb_output_files ; j + + ) { oc = output_files[j] ; for ( i=0 ; i < oc - > nb_streams ; i + + ) { AVCodecContext * enc = & oc - > streams[i] - > codec ; switch ( enc - > codec_type ) { case CODEC_TYPE_AUDIO : if ( enc - > sample_rate > ap - > sample_rate ) ap - > sample_rate = enc - > sample_rate ; if ( enc - > channels > ap - > channels ) ap - > channels = enc - > channels ; has_audio = 1 ; break ; case CODEC_TYPE_VIDEO : if ( enc - > width > ap - > width ) ap - > width = enc - > width ; if ( enc - > height > ap - > height ) ap - > height = enc - > height ; if ( enc - > frame_rate > ap - > frame_rate ) ap - > frame_rate = enc - > frame_rate ; has_video = 1 ; break ; default : abort ( ) ; } } } if ( has_video == 0 & & has_audio == 0 ) { fprintf ( stderr , Output file must have at least one audio or video stream\n ) ; exit ( 1 ) ; } if ( has_video ) { AVInputFormat * fmt1 ; fmt1 = av_find_input_format ( video_grab_device ) ; if ( av_open_input_file ( & ic , , fmt1 , 0 , ap ) < 0 ) { fprintf ( stderr , Could not find video grab device\n ) ; exit ( 1 ) ; } / * by now video grab has one stream * / ic - > streams[0] - > r_frame_rate = ap - > frame_rate ; input_files[nb_input_files] = ic ; dump_format ( ic , nb_input_files , v4l_device , 0 ) ; nb_input_files + + ; } if ( has_audio ) { AVInputFormat * fmt1 ; fmt1 = av_find_input_format ( audio_device ) ; if ( av_open_input_file ( & ic , , fmt1 , 0 , ap ) < 0 ) { fprintf ( stderr , Could not find audio grab device\n ) ; exit ( 1 ) ; } input_files[nb_input_files] = ic ; dump_format ( ic , nb_input_files , audio_device , 0 ) ; nb_input_files + + ; } }",0
"static void ipvideo_decode_opcodes ( IpvideoContext * s ) { int x , y ; unsigned char opcode ; int ret ; static int frame = 0 ; GetBitContext gb ; debug_interplay ( - - - - - - - - - - - - - - - - - - frame %d\n , frame ) ; frame + + ; / * this is PAL8 , so make the palette available * / memcpy ( s - > current_frame . data[1] , s - > avctx - > palctrl - > palette , PALETTE_COUNT * 4 ) ; s - > stride = s - > current_frame . linesize[0] ; s - > stream_ptr = s - > buf + 14 ; / * data starts 14 bytes in * / s - > stream_end = s - > buf + s - > size ; s - > line_inc = s - > stride - 8 ; s - > upper_motion_limit_offset = ( s - > avctx - > height - 8 ) * s - > stride + s - > avctx - > width - 8 ; init_get_bits ( & gb , s - > decoding_map , s - > decoding_map_size * 8 ) ; for ( y = 0 ; y < ( s - > stride * s - > avctx - > height ) ; y + = s - > stride * 8 ) { for ( x = y ; x < y + s - > avctx - > width ; x + = 8 ) { opcode = get_bits ( & gb , 4 ) ; debug_interplay ( block ( %3d , %3d ) : encoding 0x%X , data ptr %p\n , x - y , y / s - > stride , opcode , s - > stream_ptr ) ; s - > pixel_ptr = s - > current_frame . data[0] + x ; ret = ipvideo_decode_block[opcode] ( s ) ; if ( ret ! = 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , Interplay video : decode problem on frame %d , block ( %d , %d ) \n , frame , x - y , y / s - > stride ) ; return ; } } } if ( s - > stream_end - s - > stream_ptr > 1 ) { av_log ( s - > avctx , AV_LOG_ERROR , Interplay video : decode finished with %td bytes left over\n , s - > stream_end - s - > stream_ptr ) ; } }",0
"static int asf_read_seek ( AVFormatContext * s , int stream_index , int64_t pts , int flags ) { ASFContext * asf = s - > priv_data ; AVStream * st = s - > streams[stream_index] ; int64_t pos ; int index ; if ( s - > packet_size < = 0 ) return - 1 ; / * Try using the protocol ' s read_seek if available * / if ( s - > pb ) { int ret = avio_seek_time ( s - > pb , stream_index , pts , flags ) ; if ( ret > = 0 ) asf_reset_header ( s ) ; if ( ret ! = AVERROR ( ENOSYS ) ) return ret ; } if ( ! asf - > index_read ) asf_build_simple_index ( s , stream_index ) ; if ( ( asf - > index_read & & st - > index_entries ) ) { index = av_index_search_timestamp ( st , pts , flags ) ; if ( index > = 0 ) { / * find the position * / pos = st - > index_entries[index] . pos ; / * do the seek * / av_log ( s , AV_LOG_DEBUG , SEEKTO : % PRId64 \n , pos ) ; avio_seek ( s - > pb , pos , SEEK_SET ) ; asf_reset_header ( s ) ; return 0 ; } } / * no index or seeking by index failed * / if ( ff_seek_frame_binary ( s , stream_index , pts , flags ) < 0 ) return - 1 ; asf_reset_header ( s ) ; return 0 ; }",1
"void ff_mpeg_unref_picture ( MpegEncContext * s , Picture * pic ) { int off = offsetof ( Picture , mb_mean ) + sizeof ( pic - > mb_mean ) ; pic - > tf . f = & pic - > f ; / * WM Image / Screen codecs allocate internal buffers with different * dimensions / colorspaces ; ignore user - defined callbacks for these . * / if ( s - > codec_id ! = AV_CODEC_ID_WMV3IMAGE & & s - > codec_id ! = AV_CODEC_ID_VC1IMAGE & & s - > codec_id ! = AV_CODEC_ID_MSS2 ) ff_thread_release_buffer ( s - > avctx , & pic - > tf ) ; else av_frame_unref ( & pic - > f ) ; av_buffer_unref ( & pic - > hwaccel_priv_buf ) ; if ( pic - > needs_realloc ) ff_free_picture_tables ( pic ) ; memset ( ( uint8_t * ) pic + off , 0 , sizeof ( * pic ) - off ) ; }",1
"static int shorten_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame_ptr , AVPacket * avpkt ) { AVFrame * frame = data ; const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; ShortenContext * s = avctx - > priv_data ; int i , input_buf_size = 0 ; int ret ; / * allocate internal bitstream buffer * / if ( s - > max_framesize == 0 ) { void * tmp_ptr ; s - > max_framesize = 8192 ; // should hopefully be enough for the first header tmp_ptr = av_fast_realloc ( s - > bitstream , & s - > allocated_bitstream_size , s - > max_framesize + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! tmp_ptr ) { av_log ( avctx , AV_LOG_ERROR , error allocating bitstream buffer\n ) ; return AVERROR ( ENOMEM ) ; } s - > bitstream = tmp_ptr ; } / * append current packet data to bitstream buffer * / if ( 1 & & s - > max_framesize ) { //FIXME truncated buf_size = FFMIN ( buf_size , s - > max_framesize - s - > bitstream_size ) ; input_buf_size = buf_size ; if ( s - > bitstream_index + s - > bitstream_size + buf_size > s - > allocated_bitstream_size ) { memmove ( s - > bitstream , & s - > bitstream[s - > bitstream_index] , s - > bitstream_size ) ; s - > bitstream_index = 0 ; } if ( buf ) memcpy ( & s - > bitstream[s - > bitstream_index + s - > bitstream_size] , buf , buf_size ) ; buf = & s - > bitstream[s - > bitstream_index] ; buf_size + = s - > bitstream_size ; s - > bitstream_size = buf_size ; / * do not decode until buffer has at least max_framesize bytes or * the end of the file has been reached * / if ( buf_size < s - > max_framesize & & avpkt - > data ) { * got_frame_ptr = 0 ; return input_buf_size ; } } / * init and position bitstream reader * / init_get_bits ( & s - > gb , buf , buf_size * 8 ) ; skip_bits ( & s - > gb , s - > bitindex ) ; / * process header or next subblock * / if ( ! s - > got_header ) { if ( ( ret = read_header ( s ) ) < 0 ) return ret ; * got_frame_ptr = 0 ; goto finish_frame ; } / * if quit command was read previously , don ' t decode anything * / if ( s - > got_quit_command ) { * got_frame_ptr = 0 ; return avpkt - > size ; } s - > cur_chan = 0 ; while ( s - > cur_chan < s - > channels ) { unsigned cmd ; int len ; if ( get_bits_left ( & s - > gb ) < 3 + FNSIZE ) { * got_frame_ptr = 0 ; break ; } cmd = get_ur_golomb_shorten ( & s - > gb , FNSIZE ) ; if ( cmd > FN_VERBATIM ) { av_log ( avctx , AV_LOG_ERROR , unknown shorten function %d\n , cmd ) ; * got_frame_ptr = 0 ; break ; } if ( ! is_audio_command[cmd] ) { / * process non - audio command * / switch ( cmd ) { case FN_VERBATIM : len = get_ur_golomb_shorten ( & s - > gb , VERBATIM_CKSIZE_SIZE ) ; while ( len - - ) get_ur_golomb_shorten ( & s - > gb , VERBATIM_BYTE_SIZE ) ; break ; case FN_BITSHIFT : s - > bitshift = get_ur_golomb_shorten ( & s - > gb , BITSHIFTSIZE ) ; break ; case FN_BLOCKSIZE : { unsigned blocksize = get_uint ( s , av_log2 ( s - > blocksize ) ) ; if ( blocksize > s - > blocksize ) { av_log ( avctx , AV_LOG_ERROR , Increasing block size is not supported\n ) ; return AVERROR_PATCHWELCOME ; } if ( ! blocksize || blocksize > MAX_BLOCKSIZE ) { av_log ( avctx , AV_LOG_ERROR , invalid or unsupported block size : %d\n , blocksize ) ; return AVERROR ( EINVAL ) ; } s - > blocksize = blocksize ; break ; } case FN_QUIT : s - > got_quit_command = 1 ; break ; } if ( cmd == FN_BLOCKSIZE || cmd == FN_QUIT ) { * got_frame_ptr = 0 ; break ; } } else { / * process audio command * / int residual_size = 0 ; int channel = s - > cur_chan ; int32_t coffset ; / * get Rice code for residual decoding * / if ( cmd ! = FN_ZERO ) { residual_size = get_ur_golomb_shorten ( & s - > gb , ENERGYSIZE ) ; / * This is a hack as version 0 differed in the definition * of get_sr_golomb_shorten ( ) . * / if ( s - > version == 0 ) residual_size - - ; } / * calculate sample offset using means from previous blocks * / if ( s - > nmean == 0 ) coffset = s - > offset[channel][0] ; else { int32_t sum = ( s - > version < 2 ) ? 0 : s - > nmean / 2 ; for ( i = 0 ; i < s - > nmean ; i + + ) sum + = s - > offset[channel][i] ; coffset = sum / s - > nmean ; if ( s - > version > = 2 ) coffset = s - > bitshift == 0 ? coffset : coffset > > s - > bitshift - 1 > > 1 ; } / * decode samples for this channel * / if ( cmd == FN_ZERO ) { for ( i = 0 ; i < s - > blocksize ; i + + ) s - > decoded[channel][i] = 0 ; } else { if ( ( ret = decode_subframe_lpc ( s , cmd , channel , residual_size , coffset ) ) < 0 ) return ret ; } / * update means with info from the current block * / if ( s - > nmean > 0 ) { int32_t sum = ( s - > version < 2 ) ? 0 : s - > blocksize / 2 ; for ( i = 0 ; i < s - > blocksize ; i + + ) sum + = s - > decoded[channel][i] ; for ( i = 1 ; i < s - > nmean ; i + + ) s - > offset[channel][i - 1] = s - > offset[channel][i] ; if ( s - > version < 2 ) s - > offset[channel][s - > nmean - 1] = sum / s - > blocksize ; else s - > offset[channel][s - > nmean - 1] = ( sum / s - > blocksize ) < < s - > bitshift ; } / * copy wrap samples for use",1
"int64_t ff_lsb2full ( StreamContext * stream , int64_t lsb ) { int64_t mask = ( 1 < < stream - > msb_pts_shift ) - 1 ; int64_t delta= stream - > last_pts - mask/2 ; return ( ( lsb - delta ) & mask ) + delta ; }",1
"int ff_audio_rechunk_interleave ( AVFormatContext * s , AVPacket * out , AVPacket * pkt , int flush , int ( * get_packet ) ( AVFormatContext * , AVPacket * , AVPacket * , int ) , int ( * compare_ts ) ( AVFormatContext * , AVPacket * , AVPacket * ) ) { int i ; if ( pkt ) { AVStream * st = s - > streams[pkt - > stream_index] ; AudioInterleaveContext * aic = st - > priv_data ; if ( st - > codec - > codec_type == AVMEDIA_TYPE_AUDIO ) { unsigned new_size = av_fifo_size ( aic - > fifo ) + pkt - > size ; if ( new_size > aic - > fifo_size ) { if ( av_fifo_realloc2 ( aic - > fifo , new_size ) < 0 ) return - 1 ; aic - > fifo_size = new_size ; } av_fifo_generic_write ( aic - > fifo , pkt - > data , pkt - > size , NULL ) ; } else { // rewrite pts and dts to be decoded time line position pkt - > pts = pkt - > dts = aic - > dts ; aic - > dts + = pkt - > duration ; ff_interleave_add_packet ( s , pkt , compare_ts ) ; } pkt = NULL ; } for ( i = 0 ; i < s - > nb_streams ; i + + ) { AVStream * st = s - > streams[i] ; if ( st - > codec - > codec_type == AVMEDIA_TYPE_AUDIO ) { AVPacket new_pkt ; while ( interleave_new_audio_packet ( s , & new_pkt , i , flush ) ) ff_interleave_add_packet ( s , & new_pkt , compare_ts ) ; } } return get_packet ( s , out , NULL , flush ) ; }",0
static av_cold int init_decoder ( AVCodecContext * avctx ) { avctx - > pix_fmt = PIX_FMT_PAL8 ; return 0 ; },0
"static void opt_output_file ( const char * filename ) { AVFormatContext * oc ; int err , use_video , use_audio , use_subtitle ; int input_has_video , input_has_audio , input_has_subtitle ; AVFormatParameters params , * ap = & params ; AVOutputFormat * file_oformat ; if ( ! strcmp ( filename , - ) ) filename = pipe : ; oc = avformat_alloc_context ( ) ; if ( ! oc ) { print_error ( filename , AVERROR ( ENOMEM ) ) ; ffmpeg_exit ( 1 ) ; } if ( last_asked_format ) { file_oformat = av_guess_format ( last_asked_format , NULL , NULL ) ; if ( ! file_oformat ) { fprintf ( stderr , Requested output format ' %s ' is not a suitable output format\n , last_asked_format ) ; ffmpeg_exit ( 1 ) ; } last_asked_format = NULL ; } else { file_oformat = av_guess_format ( NULL , filename , NULL ) ; if ( ! file_oformat ) { fprintf ( stderr , Unable to find a suitable output format for ' %s ' \n , filename ) ; ffmpeg_exit ( 1 ) ; } } oc - > oformat = file_oformat ; av_strlcpy ( oc - > filename , filename , sizeof ( oc - > filename ) ) ; if ( ! strcmp ( file_oformat - > name , ffm ) & & av_strstart ( filename , http : , NULL ) ) { / * special case for files sent to ffserver : we get the stream parameters from ffserver * / int err = read_ffserver_streams ( oc , filename ) ; if ( err < 0 ) { print_error ( filename , err ) ; ffmpeg_exit ( 1 ) ; } } else { use_video = file_oformat - > video_codec ! = CODEC_ID_NONE || video_stream_copy || video_codec_name ; use_audio = file_oformat - > audio_codec ! = CODEC_ID_NONE || audio_stream_copy || audio_codec_name ; use_subtitle = file_oformat - > subtitle_codec ! = CODEC_ID_NONE || subtitle_stream_copy || subtitle_codec_name ; / * disable if no corresponding type found and at least one input file * / if ( nb_input_files > 0 ) { check_audio_video_sub_inputs ( & input_has_video , & input_has_audio , & input_has_subtitle ) ; if ( ! input_has_video ) use_video = 0 ; if ( ! input_has_audio ) use_audio = 0 ; if ( ! input_has_subtitle ) use_subtitle = 0 ; } / * manual disable * / if ( audio_disable ) use_audio = 0 ; if ( video_disable ) use_video = 0 ; if ( subtitle_disable ) use_subtitle = 0 ; if ( use_video ) new_video_stream ( oc , nb_output_files ) ; if ( use_audio ) new_audio_stream ( oc , nb_output_files ) ; if ( use_subtitle ) new_subtitle_stream ( oc , nb_output_files ) ; oc - > timestamp = recording_timestamp ; av_metadata_copy ( & oc - > metadata , metadata , 0 ) ; av_metadata_free ( & metadata ) ; } output_files[nb_output_files + + ] = oc ; / * check filename in case of an image number is expected * / if ( oc - > oformat - > flags & AVFMT_NEEDNUMBER ) { if ( ! av_filename_number_test ( oc - > filename ) ) { print_error ( oc - > filename , AVERROR_NUMEXPECTED ) ; ffmpeg_exit ( 1 ) ; } } if ( ! ( oc - > oformat - > flags & AVFMT_NOFILE ) ) { / * test if it already exists to avoid loosing precious files * / if ( ! file_overwrite & & ( strchr ( filename , ' : ' ) == NULL || filename[1] == ' : ' || av_strstart ( filename , file : , NULL ) ) ) { if ( url_exist ( filename ) ) { if ( ! using_stdin ) { fprintf ( stderr , File ' %s ' already exists . Overwrite ? [y/N] , filename ) ; fflush ( stderr ) ; if ( ! read_yesno ( ) ) { fprintf ( stderr , Not overwriting - exiting\n ) ; ffmpeg_exit ( 1 ) ; } } else { fprintf ( stderr , File ' %s ' already exists . Exiting . \n , filename ) ; ffmpeg_exit ( 1 ) ; } } } / * open the file * / if ( ( err = avio_open ( & oc - > pb , filename , AVIO_FLAG_WRITE ) ) < 0 ) { print_error ( filename , err ) ; ffmpeg_exit ( 1 ) ; } } memset ( ap , 0 , sizeof ( * ap ) ) ; if ( av_set_parameters ( oc , ap ) < 0 ) { fprintf ( stderr , %s : Invalid encoding parameters\n , oc - > filename ) ; ffmpeg_exit ( 1 ) ; } oc - > preload= ( int ) ( mux_preload * AV_TIME_BASE ) ; oc - > max_delay= ( int ) ( mux_max_delay * AV_TIME_BASE ) ; oc - > loop_output = loop_output ; oc - > flags |= AVFMT_FLAG_NONBLOCK ; set_context_opts ( oc , avformat_opts , AV_OPT_FLAG_ENCODING_PARAM , NULL ) ; av_freep ( & forced_key_frames ) ; }",0
"static int smc_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; SmcContext * s = avctx - > priv_data ; const uint8_t * pal = av_packet_get_side_data ( avpkt , AV_PKT_DATA_PALETTE , NULL ) ; int ret ; bytestream2_init ( & s - > gb , buf , buf_size ) ; if ( ( ret = ff_reget_buffer ( avctx , s - > frame ) ) < 0 ) return ret ; if ( pal ) { s - > frame - > palette_has_changed = 1 ; memcpy ( s - > pal , pal , AVPALETTE_SIZE ) ; } smc_decode_stream ( s ) ; * got_frame = 1 ; if ( ( ret = av_frame_ref ( data , s - > frame ) ) < 0 ) return ret ; / * always report that the buffer was completely consumed * / return buf_size ; }",0
"static inline void apply_8x8 ( MpegEncContext * s , uint8_t * dest_y , uint8_t * dest_cb , uint8_t * dest_cr , int dir , uint8_t * * ref_picture , qpel_mc_func ( * qpix_op ) [16] , op_pixels_func ( * pix_op ) [4] ) { int dxy , mx , my , src_x , src_y ; int i ; int mb_x = s - > mb_x ; int mb_y = s - > mb_y ; uint8_t * ptr , * dest ; mx = 0 ; my = 0 ; if ( s - > quarter_sample ) { for ( i = 0 ; i < 4 ; i + + ) { int motion_x = s - > mv[dir][i][0] ; int motion_y = s - > mv[dir][i][1] ; dxy = ( ( motion_y & 3 ) < < 2 ) | ( motion_x & 3 ) ; src_x = mb_x * 16 + ( motion_x > > 2 ) + ( i & 1 ) * 8 ; src_y = mb_y * 16 + ( motion_y > > 2 ) + ( i > > 1 ) * 8 ; / * WARNING : do no forget half pels * / src_x = av_clip ( src_x , - 16 , s - > width ) ; if ( src_x == s - > width ) dxy & = 3 ; src_y = av_clip ( src_y , - 16 , s - > height ) ; if ( src_y == s - > height ) dxy & = 12 ; ptr = ref_picture[0] + ( src_y * s - > linesize ) + ( src_x ) ; if ( ( unsigned ) src_x > FFMAX ( s - > h_edge_pos - ( motion_x & 3 ) - 8 , 0 ) || ( unsigned ) src_y > FFMAX ( s - > v_edge_pos - ( motion_y & 3 ) - 8 , 0 ) ) { s - > vdsp . emulated_edge_mc ( s - > edge_emu_buffer , ptr , s - > linesize , s - > linesize , 9 , 9 , src_x , src_y , s - > h_edge_pos , s - > v_edge_pos ) ; ptr = s - > edge_emu_buffer ; } dest = dest_y + ( ( i & 1 ) * 8 ) + ( i > > 1 ) * 8 * s - > linesize ; qpix_op[1][dxy] ( dest , ptr , s - > linesize ) ; mx + = s - > mv[dir][i][0] / 2 ; my + = s - > mv[dir][i][1] / 2 ; } } else { for ( i = 0 ; i < 4 ; i + + ) { hpel_motion ( s , dest_y + ( ( i & 1 ) * 8 ) + ( i > > 1 ) * 8 * s - > linesize , ref_picture[0] , mb_x * 16 + ( i & 1 ) * 8 , mb_y * 16 + ( i > > 1 ) * 8 , pix_op[1] , s - > mv[dir][i][0] , s - > mv[dir][i][1] ) ; mx + = s - > mv[dir][i][0] ; my + = s - > mv[dir][i][1] ; } } if ( ! CONFIG_GRAY || ! ( s - > flags & CODEC_FLAG_GRAY ) ) chroma_4mv_motion ( s , dest_cb , dest_cr , ref_picture , pix_op[1] , mx , my ) ; }",0
"void mpeg_motion_internal ( MpegEncContext * s , uint8_t * dest_y , uint8_t * dest_cb , uint8_t * dest_cr , int field_based , int bottom_field , int field_select , uint8_t * * ref_picture , op_pixels_func ( * pix_op ) [4] , int motion_x , int motion_y , int h , int is_mpeg12 , int mb_y ) { uint8_t * ptr_y , * ptr_cb , * ptr_cr ; int dxy , uvdxy , mx , my , src_x , src_y , uvsrc_x , uvsrc_y , v_edge_pos ; ptrdiff_t uvlinesize , linesize ; if 0 if ( s - > quarter_sample ) { motion_x > > = 1 ; motion_y > > = 1 ; } endif v_edge_pos = s - > v_edge_pos > > field_based ; linesize = s - > current_picture . f - > linesize[0] < < field_based ; uvlinesize = s - > current_picture . f - > linesize[1] < < field_based ; dxy = ( ( motion_y & 1 ) < < 1 ) | ( motion_x & 1 ) ; src_x = s - > mb_x * 16 + ( motion_x > > 1 ) ; src_y = ( mb_y < < ( 4 - field_based ) ) + ( motion_y > > 1 ) ; if ( ! is_mpeg12 & & s - > out_format == FMT_H263 ) { if ( ( s - > workaround_bugs & FF_BUG_HPEL_CHROMA ) & & field_based ) { mx = ( motion_x > > 1 ) | ( motion_x & 1 ) ; my = motion_y > > 1 ; uvdxy = ( ( my & 1 ) < < 1 ) | ( mx & 1 ) ; uvsrc_x = s - > mb_x * 8 + ( mx > > 1 ) ; uvsrc_y = ( mb_y < < ( 3 - field_based ) ) + ( my > > 1 ) ; } else { uvdxy = dxy | ( motion_y & 2 ) | ( ( motion_x & 2 ) > > 1 ) ; uvsrc_x = src_x > > 1 ; uvsrc_y = src_y > > 1 ; } // Even chroma mv ' s are full pel in H261 } else if ( ! is_mpeg12 & & s - > out_format == FMT_H261 ) { mx = motion_x / 4 ; my = motion_y / 4 ; uvdxy = 0 ; uvsrc_x = s - > mb_x * 8 + mx ; uvsrc_y = mb_y * 8 + my ; } else { if ( s - > chroma_y_shift ) { mx = motion_x / 2 ; my = motion_y / 2 ; uvdxy = ( ( my & 1 ) < < 1 ) | ( mx & 1 ) ; uvsrc_x = s - > mb_x * 8 + ( mx > > 1 ) ; uvsrc_y = ( mb_y < < ( 3 - field_based ) ) + ( my > > 1 ) ; } else { if ( s - > chroma_x_shift ) { // Chroma422 mx = motion_x / 2 ; uvdxy = ( ( motion_y & 1 ) < < 1 ) | ( mx & 1 ) ; uvsrc_x = s - > mb_x * 8 + ( mx > > 1 ) ; uvsrc_y = src_y ; } else { // Chroma444 uvdxy = dxy ; uvsrc_x = src_x ; uvsrc_y = src_y ; } } } ptr_y = ref_picture[0] + src_y * linesize + src_x ; ptr_cb = ref_picture[1] + uvsrc_y * uvlinesize + uvsrc_x ; ptr_cr = ref_picture[2] + uvsrc_y * uvlinesize + uvsrc_x ; if ( ( unsigned ) src_x > FFMAX ( s - > h_edge_pos - ( motion_x & 1 ) - 16 , 0 ) || ( unsigned ) src_y > FFMAX ( v_edge_pos - ( motion_y & 1 ) - h , 0 ) ) { if ( is_mpeg12 || s - > codec_id == AV_CODEC_ID_MPEG2VIDEO || s - > codec_id == AV_CODEC_ID_MPEG1VIDEO ) { av_log ( s - > avctx , AV_LOG_DEBUG , MPEG motion vector out of boundary ( %d %d ) \n , src_x , src_y ) ; return ; } s - > vdsp . emulated_edge_mc ( s - > sc . edge_emu_buffer , ptr_y , s - > linesize , s - > linesize , 17 , 17 + field_based , src_x , src_y < < field_based , s - > h_edge_pos , s - > v_edge_pos ) ; ptr_y = s - > sc . edge_emu_buffer ; if ( ! CONFIG_GRAY || ! ( s - > avctx - > flags & AV_CODEC_FLAG_GRAY ) ) { uint8_t * uvbuf = s - > sc . edge_emu_buffer + 18 * s - > linesize ; s - > vdsp . emulated_edge_mc ( uvbuf , ptr_cb , s - > uvlinesize , s - > uvlinesize , 9 , 9 + field_based , uvsrc_x , uvsrc_y < < field_based , s - > h_edge_pos > > 1 , s - > v_edge_pos > > 1 ) ; s - > vdsp . emulated_edge_mc ( uvbuf + 16 , ptr_cr , s - > uvlinesize , s - > uvlinesize , 9 , 9 + field_based , uvsrc_x , uvsrc_y < < field_based , s - > h_edge_pos > > 1 , s - > v_edge_pos > > 1 ) ; ptr_cb = uvbuf ; ptr_cr = uvbuf + 16 ; } } / * FIXME use this for field pix too instead of the obnoxious hack which * changes picture . data * / if ( bottom_field ) { dest_y + = s - > linesize ; dest_cb + = s - > uvlinesize ; dest_cr + = s - > uvlinesize ; } if ( field_select ) { ptr_y + = s - > linesize ; ptr_cb + = s - > uvlinesize ; ptr_cr + = s - > uvlinesize ; } pix_op[0][dxy] ( dest_y , ptr_y , linesize , h ) ; if ( ! CONFIG_GRAY || ! ( s - > avctx - > flags & AV_CODEC_FLAG_GRAY ) ) { pix_op[s - > chroma_x_shift][uvdxy] ( dest_cb , ptr_cb , uvlinesize , h > > s - > chroma_y_shift ) ; pix_op[s - > chroma_x_shift][uvdxy] ( dest_cr , ptr_cr , uvlinesize , h > > s - > chroma_y_shift ) ; } if ( ! is_mpeg12 & & ( CONFIG_H261_ENCODER || CONFIG_H261_DECODER ) & & s - > out_format == FMT_H261 ) { ff_h261_loop_filter ( s ) ; } }",0
"static void parse_palette_segment ( AVCodecContext * avctx , const uint8_t * buf , int buf_size ) { PGSSubContext * ctx = avctx - > priv_data ; const uint8_t * buf_end = buf + buf_size ; const uint8_t * cm = ff_crop_tab + MAX_NEG_CROP ; int color_id ; int y , cb , cr , alpha ; int r , g , b , r_add , g_add , b_add ; / * Skip two null bytes * / buf + = 2 ; while ( buf < buf_end ) { color_id = bytestream_get_byte ( & buf ) ; y = bytestream_get_byte ( & buf ) ; cr = bytestream_get_byte ( & buf ) ; cb = bytestream_get_byte ( & buf ) ; alpha = bytestream_get_byte ( & buf ) ; YUV_TO_RGB1 ( cb , cr ) ; YUV_TO_RGB2 ( r , g , b , y ) ; av_dlog ( avctx , Color %d : = ( %d , %d , %d , %d ) \n , color_id , r , g , b , alpha ) ; / * Store color in palette * / ctx - > clut[color_id] = RGBA ( r , g , b , alpha ) ; } }",0
"static int transcode ( OutputFile * output_files , int nb_output_files , InputFile * input_files , int nb_input_files ) { int ret , i ; AVFormatContext * is , * os ; OutputStream * ost ; InputStream * ist ; uint8_t * no_packet ; int no_packet_count = 0 ; int64_t timer_start ; int key ; if ( ! ( no_packet = av_mallocz ( nb_input_files ) ) ) exit_program ( 1 ) ; ret = transcode_init ( output_files , nb_output_files , input_files , nb_input_files ) ; if ( ret < 0 ) goto fail ; if ( ! using_stdin ) { av_log ( NULL , AV_LOG_INFO , Press [q] to stop , [ ? ] for help\n ) ; } timer_start = av_gettime ( ) ; for ( ; received_sigterm == 0 ; ) { int file_index , ist_index ; AVPacket pkt ; int64_t ipts_min ; double opts_min ; int64_t cur_time= av_gettime ( ) ; ipts_min = INT64_MAX ; opts_min = 1e100 ; / * if ' q ' pressed , exits * / if ( ! using_stdin ) { static int64_t last_time ; if ( received_nb_signals ) break ; / * read_key ( ) returns 0 on EOF * / if ( cur_time - last_time > = 100000 & & ! run_as_daemon ) { key = read_key ( ) ; last_time = cur_time ; } else key = - 1 ; if ( key == ' q ' ) break ; if ( key == ' + ' ) av_log_set_level ( av_log_get_level ( ) + 10 ) ; if ( key == ' - ' ) av_log_set_level ( av_log_get_level ( ) - 10 ) ; if ( key == ' s ' ) qp_hist = 1 ; if ( key == ' h ' ) { if ( do_hex_dump ) { do_hex_dump = do_pkt_dump = 0 ; } else if ( do_pkt_dump ) { do_hex_dump = 1 ; } else do_pkt_dump = 1 ; av_log_set_level ( AV_LOG_DEBUG ) ; } if CONFIG_AVFILTER if ( key == ' c ' || key == ' C ' ) { char buf[4096] , target[64] , command[256] , arg[256] = { 0 } ; double time ; int k , n = 0 ; fprintf ( stderr , \nEnter command : < target > < time > < command > [ < argument > ]\n ) ; i = 0 ; while ( ( k = read_key ( ) ) ! = ' \n ' & & k ! = ' \r ' & & i < sizeof ( buf ) - 1 ) if ( k > 0 ) buf[i + + ] = k ; buf[i] = 0 ; if ( k > 0 & & ( n = sscanf ( buf , %63[ ] %lf %255[ ] %255[ \n] , target , & time , command , arg ) ) > = 3 ) { av_log ( NULL , AV_LOG_DEBUG , Processing command target : %s time : %f command : %s arg : %s , target , time , command , arg ) ; for ( i = 0 ; i < nb_output_streams ; i + + ) { ost = & output_streams[i] ; if ( ost - > graph ) { if ( time < 0 ) { ret = avfilter_graph_send_command ( ost - > graph , target , command , arg , buf , sizeof ( buf ) , key == ' c ' ? AVFILTER_CMD_FLAG_ONE : 0 ) ; fprintf ( stderr , Command reply for stream %d : ret : %d res : %s\n , i , ret , buf ) ; } else { ret = avfilter_graph_queue_command ( ost - > graph , target , command , arg , 0 , time ) ; } } } } else { av_log ( NULL , AV_LOG_ERROR , Parse error , at least 3 arguments were expected , only %d given in string ' %s ' \n , n , buf ) ; } } endif if ( key == ' d ' || key == ' D ' ) { int debug=0 ; if ( key == ' D ' ) { debug = input_streams[0] . st - > codec - > debug < < 1 ; if ( ! debug ) debug = 1 ; while ( debug & ( FF_DEBUG_DCT_COEFF|FF_DEBUG_VIS_QP|FF_DEBUG_VIS_MB_TYPE ) ) //unsupported , would just crash debug + = debug ; } else if ( scanf ( %d , & debug ) ! =1 ) fprintf ( stderr , error parsing debug value\n ) ; for ( i=0 ; i < nb_input_streams ; i + + ) { input_streams[i] . st - > codec - > debug = debug ; } for ( i=0 ; i < nb_output_streams ; i + + ) { ost = & output_streams[i] ; ost - > st - > codec - > debug = debug ; } if ( debug ) av_log_set_level ( AV_LOG_DEBUG ) ; fprintf ( stderr , debug=%d\n , debug ) ; } if ( key == ' ? ' ) { fprintf ( stderr , key function\n ? show this help\n + increase verbosity\n - decrease verbosity\n c Send command to filtergraph\n D cycle through available debug modes\n h dump packets/hex press to cycle through the 3 states\n q quit\n s Show QP histogram\n ) ; } } / * select the stream that we must read now by looking at the smallest output pts * / file_index = - 1 ; for ( i = 0 ; i < nb_output_streams ; i + + ) { OutputFile * of ; int64_t ipts ; double opts ; ost = & output_streams[i] ; of = & output_files[ost - > file_index] ; os = output_files[ost - > file_index] . ctx ; ist = & input_streams[ost - > source_index] ; if ( ost - > is_past_recording_time || no_packet[ist - > file_index] || ( os - > pb & & avio_tell ( os - > pb ) > = of - > limit_filesize ) ) continue ; opts = ost - > st - > pts . val * av_q2d ( ost - > st - > time_base ) ; ipts = ist - > pts ; if ( ! input_files[ist - > file_index] . eof_reached ) { if ( ipts < ipts_min ) { ipts_min = ipts ; if ( input_sync ) file_index = ist - > file_index ; } if ( opts < opts_min ) { opts_min = opts ; if ( ! input_sync ) file_index = ist - > file_index ; } } if ( ost - > frame_number > = ost - > max_frames ) { int j ; for ( j = 0 ; j < of - > ctx - > nb_streams ; j + + ) output_streams[of - > ost_index + j] . is_past_recording_time = 1 ; continue ; } } / * if none , if is finished * / if ( file_index < 0 ) { if ( no_packet_count ) { no_packet_count = 0 ; memset ( no_packet , 0 , nb_input_files ) ; usleep ( 10000 ) ; continue ; } break ; } / * read a",0
"void * av_realloc ( void * ptr , size_t size ) { if CONFIG_MEMALIGN_HACK int diff ; endif / * let ' s disallow possible ambiguous cases * / if ( size > ( MAX_MALLOC_SIZE - 16 ) ) return NULL ; if CONFIG_MEMALIGN_HACK //FIXME this isn ' t aligned correctly , though it probably isn ' t needed if ( ! ptr ) return av_malloc ( size ) ; diff= ( ( char * ) ptr ) [ - 1] ; return ( char * ) realloc ( ( char * ) ptr - diff , size + diff ) + diff ; else return realloc ( ptr , size + ! size ) ; endif }",0
"static void handle_char ( CCaptionSubContext * ctx , char hi , char lo , int64_t pts ) { struct Screen * screen = get_writing_screen ( ctx ) ; char * row = screen - > characters[ctx - > cursor_row] ; int ret ; SET_FLAG ( screen - > row_used , ctx - > cursor_row ) ; ret = write_char ( ctx , row , ctx - > cursor_column , hi ) ; if ( ret == 0 ) ctx - > cursor_column + + ; if ( lo ) { ret = write_char ( ctx , row , ctx - > cursor_column , lo ) ; if ( ret == 0 ) ctx - > cursor_column + + ; } write_char ( ctx , row , ctx - > cursor_column , 0 ) ; / * reset prev command since character can repeat * / ctx - > prev_cmd[0] = 0 ; ctx - > prev_cmd[1] = 0 ; if ( lo ) av_dlog ( ctx , ( %c , %c ) \n , hi , lo ) ; else av_dlog ( ctx , ( %c ) \n , hi ) ; }",0
static av_cold int raw_close_decoder ( AVCodecContext * avctx ) { RawVideoContext * context = avctx - > priv_data ; av_freep ( & context - > buffer ) ; return 0 ; },0
"static int mc_subpel ( DiracContext * s , DiracBlock * block , const uint8_t * src[5] , int x , int y , int ref , int plane ) { Plane * p = & s - > plane[plane] ; uint8_t * * ref_hpel = s - > ref_pics[ref] - > hpel[plane] ; int motion_x = block - > u . mv[ref][0] ; int motion_y = block - > u . mv[ref][1] ; int mx , my , i , epel , nplanes = 0 ; if ( plane ) { motion_x > > = s - > chroma_x_shift ; motion_y > > = s - > chroma_y_shift ; } mx = motion_x & ( - 1 < < s - > mv_precision ) ; my = motion_y & ( - 1 < < s - > mv_precision ) ; motion_x > > = s - > mv_precision ; motion_y > > = s - > mv_precision ; / * normalize subpel coordinates to epel * / / * TODO : template this function ? * / mx < < = 3 - s - > mv_precision ; my < < = 3 - s - > mv_precision ; x + = motion_x ; y + = motion_y ; epel = ( mx|my ) & 1 ; / * hpel position * / if ( ! ( ( mx|my ) & 3 ) ) { nplanes = 1 ; src[0] = ref_hpel[ ( my > > 1 ) + ( mx > > 2 ) ] + y * p - > stride + x ; } else { / * qpel or epel * / nplanes = 4 ; for ( i = 0 ; i < 4 ; i + + ) src[i] = ref_hpel[i] + y * p - > stride + x ; / * if we ' re interpolating in the right/bottom halves , adjust the planes as needed we increment x/y because the edge changes for half of the pixels * / if ( mx > 4 ) { src[0] + = 1 ; src[2] + = 1 ; x + + ; } if ( my > 4 ) { src[0] + = p - > stride ; src[1] + = p - > stride ; y + + ; } / * hpel planes are : [0] : F [1] : H [2] : V [3] : C * / if ( ! epel ) { / * check if we really only need 2 planes since either mx or my is a hpel position . ( epel weights of 0 handle this there ) * / if ( ! ( mx & 3 ) ) { / * mx == 0 : average [0] and [2] mx == 4 : average [1] and [3] * / src[ ! mx] = src[2 + ! ! mx] ; nplanes = 2 ; } else if ( ! ( my & 3 ) ) { src[0] = src[ ( my > > 1 ) ] ; src[1] = src[ ( my > > 1 ) + 1] ; nplanes = 2 ; } } else { / * adjust the ordering if needed so the weights work * / if ( mx > 4 ) { FFSWAP ( const uint8_t * , src[0] , src[1] ) ; FFSWAP ( const uint8_t * , src[2] , src[3] ) ; } if ( my > 4 ) { FFSWAP ( const uint8_t * , src[0] , src[2] ) ; FFSWAP ( const uint8_t * , src[1] , src[3] ) ; } src[4] = epel_weights[my & 3][mx & 3] ; } } / * fixme : v/h _edge_pos * / if ( x + p - > xblen > p - > width + EDGE_WIDTH/2 || y + p - > yblen > p - > height + EDGE_WIDTH/2 || x < 0 || y < 0 ) { for ( i = 0 ; i < nplanes ; i + + ) { ff_emulated_edge_mc ( s - > edge_emu_buffer[i] , src[i] , p - > stride , p - > stride , p - > xblen , p - > yblen , x , y , p - > width + EDGE_WIDTH/2 , p - > height + EDGE_WIDTH/2 ) ; src[i] = s - > edge_emu_buffer[i] ; } } return ( nplanes > > 1 ) + epel ; }",1
"static int decode_block_progressive ( MJpegDecodeContext * s , int16_t * block , uint8_t * last_nnz , int ac_index , int16_t * quant_matrix , int ss , int se , int Al , int * EOBRUN ) { int code , i , j , level , val , run ; if ( * EOBRUN ) { ( * EOBRUN ) - - ; return 0 ; } { OPEN_READER ( re , & s - > gb ) ; for ( i = ss ; ; i + + ) { UPDATE_CACHE ( re , & s - > gb ) ; GET_VLC ( code , re , & s - > gb , s - > vlcs[2][ac_index] . table , 9 , 2 ) ; run = ( ( unsigned ) code ) > > 4 ; code & = 0xF ; if ( code ) { i + = run ; if ( code > MIN_CACHE_BITS - 16 ) UPDATE_CACHE ( re , & s - > gb ) ; { int cache = GET_CACHE ( re , & s - > gb ) ; int sign = ( cache ) > > 31 ; level = ( NEG_USR32 ( sign cache , code ) sign ) - sign ; } LAST_SKIP_BITS ( re , & s - > gb , code ) ; if ( i > = se ) { if ( i == se ) { j = s - > scantable . permutated[se] ; block[j] = level * quant_matrix[j] < < Al ; break ; } av_log ( s - > avctx , AV_LOG_ERROR , error count : %d\n , i ) ; return AVERROR_INVALIDDATA ; } j = s - > scantable . permutated[i] ; block[j] = level * quant_matrix[j] < < Al ; } else { if ( run == 0xF ) { // ZRL - skip 15 coefficients i + = 15 ; if ( i > = se ) { av_log ( s - > avctx , AV_LOG_ERROR , ZRL overflow : %d\n , i ) ; return AVERROR_INVALIDDATA ; } } else { val = ( 1 < < run ) ; if ( run ) { UPDATE_CACHE ( re , & s - > gb ) ; val + = NEG_USR32 ( GET_CACHE ( re , & s - > gb ) , run ) ; LAST_SKIP_BITS ( re , & s - > gb , run ) ; } * EOBRUN = val - 1 ; break ; } } } CLOSE_READER ( re , & s - > gb ) ; } if ( i > * last_nnz ) * last_nnz = i ; return 0 ; }",1
"void rgb32tobgr24 ( const uint8_t * src , uint8_t * dst , long src_size ) { long i ; long num_pixels = src_size > > 2 ; for ( i=0 ; i < num_pixels ; i + + ) { ifdef WORDS_BIGENDIAN / * RGB32 ( = A , B , G , R ) - > BGR24 ( = B , G , R ) * / dst[3 * i + 0] = src[4 * i + 1] ; dst[3 * i + 1] = src[4 * i + 2] ; dst[3 * i + 2] = src[4 * i + 3] ; else dst[3 * i + 0] = src[4 * i + 2] ; dst[3 * i + 1] = src[4 * i + 1] ; dst[3 * i + 2] = src[4 * i + 0] ; endif } }",1
"static int initFilter ( int16_t * * outFilter , int16_t * * filterPos , int * outFilterSize , int xInc , int srcW , int dstW , int filterAlign , int one , int flags , int cpu_flags , SwsVector * srcFilter , SwsVector * dstFilter , double param[2] , int is_horizontal ) { int i ; int filterSize ; int filter2Size ; int minFilterSize ; int64_t * filter=NULL ; int64_t * filter2=NULL ; const int64_t fone= 1LL < < 54 ; int ret= - 1 ; emms_c ( ) ; //FIXME this should not be required but it IS ( even for non - MMX versions ) // NOTE : the + 3 is for the MMX ( + 1 ) /SSE ( + 3 ) scaler which reads over the end FF_ALLOC_OR_GOTO ( NULL , * filterPos , ( dstW + 3 ) * sizeof ( int16_t ) , fail ) ; if ( FFABS ( xInc - 0x10000 ) < 10 ) { // unscaled int i ; filterSize= 1 ; FF_ALLOCZ_OR_GOTO ( NULL , filter , dstW * sizeof ( * filter ) * filterSize , fail ) ; for ( i=0 ; i < dstW ; i + + ) { filter[i * filterSize]= fone ; ( * filterPos ) [i]=i ; } } else if ( flags & SWS_POINT ) { // lame looking point sampling mode int i ; int xDstInSrc ; filterSize= 1 ; FF_ALLOC_OR_GOTO ( NULL , filter , dstW * sizeof ( * filter ) * filterSize , fail ) ; xDstInSrc= xInc/2 - 0x8000 ; for ( i=0 ; i < dstW ; i + + ) { int xx= ( xDstInSrc - ( ( filterSize - 1 ) < < 15 ) + ( 1 < < 15 ) ) > > 16 ; ( * filterPos ) [i]= xx ; filter[i]= fone ; xDstInSrc + = xInc ; } } else if ( ( xInc < = ( 1 < < 16 ) & & ( flags & SWS_AREA ) ) || ( flags & SWS_FAST_BILINEAR ) ) { // bilinear upscale int i ; int xDstInSrc ; filterSize= 2 ; FF_ALLOC_OR_GOTO ( NULL , filter , dstW * sizeof ( * filter ) * filterSize , fail ) ; xDstInSrc= xInc/2 - 0x8000 ; for ( i=0 ; i < dstW ; i + + ) { int xx= ( xDstInSrc - ( ( filterSize - 1 ) < < 15 ) + ( 1 < < 15 ) ) > > 16 ; int j ; ( * filterPos ) [i]= xx ; //bilinear upscale / linear interpolate / area averaging for ( j=0 ; j < filterSize ; j + + ) { int64_t coeff= fone - FFABS ( ( xx < < 16 ) - xDstInSrc ) * ( fone > > 16 ) ; if ( coeff < 0 ) coeff=0 ; filter[i * filterSize + j]= coeff ; xx + + ; } xDstInSrc + = xInc ; } } else { int xDstInSrc ; int sizeFactor ; if ( flags & SWS_BICUBIC ) sizeFactor= 4 ; else if ( flags & SWS_X ) sizeFactor= 8 ; else if ( flags & SWS_AREA ) sizeFactor= 1 ; //downscale only , for upscale it is bilinear else if ( flags & SWS_GAUSS ) sizeFactor= 8 ; // infinite ; ) else if ( flags & SWS_LANCZOS ) sizeFactor= param[0] ! = SWS_PARAM_DEFAULT ? ceil ( 2 * param[0] ) : 6 ; else if ( flags & SWS_SINC ) sizeFactor= 20 ; // infinite ; ) else if ( flags & SWS_SPLINE ) sizeFactor= 20 ; // infinite ; ) else if ( flags & SWS_BILINEAR ) sizeFactor= 2 ; else { sizeFactor= 0 ; //GCC warning killer assert ( 0 ) ; } if ( xInc < = 1 < < 16 ) filterSize= 1 + sizeFactor ; // upscale else filterSize= 1 + ( sizeFactor * srcW + dstW - 1 ) / dstW ; if ( filterSize > srcW - 2 ) filterSize=srcW - 2 ; FF_ALLOC_OR_GOTO ( NULL , filter , dstW * sizeof ( * filter ) * filterSize , fail ) ; xDstInSrc= xInc - 0x10000 ; for ( i=0 ; i < dstW ; i + + ) { int xx= ( xDstInSrc - ( ( filterSize - 2 ) < < 16 ) ) / ( 1 < < 17 ) ; int j ; ( * filterPos ) [i]= xx ; for ( j=0 ; j < filterSize ; j + + ) { int64_t d= ( ( int64_t ) FFABS ( ( xx < < 17 ) - xDstInSrc ) ) < < 13 ; double floatd ; int64_t coeff ; if ( xInc > 1 < < 16 ) d= d * dstW/srcW ; floatd= d * ( 1 . 0/ ( 1 < < 30 ) ) ; if ( flags & SWS_BICUBIC ) { int64_t B= ( param[0] ! = SWS_PARAM_DEFAULT ? param[0] : 0 ) * ( 1 < < 24 ) ; int64_t C= ( param[1] ! = SWS_PARAM_DEFAULT ? param[1] : 0 . 6 ) * ( 1 < < 24 ) ; if ( d > = 1LL < < 31 ) { coeff = 0 . 0 ; } else { int64_t dd = ( d * d ) > > 30 ; int64_t ddd = ( dd * d ) > > 30 ; if ( d < 1LL < < 30 ) coeff = ( 12 * ( 1 < < 24 ) - 9 * B - 6 * C ) * ddd + ( - 18 * ( 1 < < 24 ) + 12 * B + 6 * C ) * dd + ( 6 * ( 1 < < 24 ) - 2 * B ) * ( 1 < < 30 ) ; else coeff = ( - B - 6 * C ) * ddd + ( 6 * B + 30 * C ) * dd + ( - 12 * B - 48 * C ) * d + ( 8 * B + 24 * C ) * ( 1 < < 30 ) ; } coeff * = fone > > ( 30 + 24 ) ; } / * else if ( flags & SWS_X ) { double p= param ? param * 0 . 01 : 0 . 3 ; coeff = d ? sin ( d * M_PI ) / ( d * M_PI ) : 1 . 0 ; coeff * = pow ( 2 . 0 , - p * d * d ) ; } * / else if ( flags & SWS_X ) { double A= param[0] ! = SWS_PARAM_DEFAULT ? param[0] : 1 . 0 ; double c ; if ( floatd < 1 . 0 ) c = cos ( floatd * M_PI ) ; else c= - 1 . 0 ; if ( c < 0 . 0 ) c= - pow ( - c , A ) ; else c=",1
"void FUNCC ( ff_h264_idct_add ) ( uint8_t * _dst , DCTELEM * _block , int stride ) { int i ; INIT_CLIP pixel * dst = ( pixel * ) _dst ; dctcoef * block = ( dctcoef * ) _block ; stride /= sizeof ( pixel ) ; block[0] + = 1 < < 5 ; for ( i=0 ; i < 4 ; i + + ) { const int z0= block[i + 4 * 0] + block[i + 4 * 2] ; const int z1= block[i + 4 * 0] - block[i + 4 * 2] ; const int z2= ( block[i + 4 * 1] > > 1 ) - block[i + 4 * 3] ; const int z3= block[i + 4 * 1] + ( block[i + 4 * 3] > > 1 ) ; block[i + 4 * 0]= z0 + z3 ; block[i + 4 * 1]= z1 + z2 ; block[i + 4 * 2]= z1 - z2 ; block[i + 4 * 3]= z0 - z3 ; } for ( i=0 ; i < 4 ; i + + ) { const int z0= block[0 + 4 * i] + block[2 + 4 * i] ; const int z1= block[0 + 4 * i] - block[2 + 4 * i] ; const int z2= ( block[1 + 4 * i] > > 1 ) - block[3 + 4 * i] ; const int z3= block[1 + 4 * i] + ( block[3 + 4 * i] > > 1 ) ; dst[i + 0 * stride]= CLIP ( dst[i + 0 * stride] + ( ( z0 + z3 ) > > 6 ) ) ; dst[i + 1 * stride]= CLIP ( dst[i + 1 * stride] + ( ( z1 + z2 ) > > 6 ) ) ; dst[i + 2 * stride]= CLIP ( dst[i + 2 * stride] + ( ( z1 - z2 ) > > 6 ) ) ; dst[i + 3 * stride]= CLIP ( dst[i + 3 * stride] + ( ( z0 - z3 ) > > 6 ) ) ; } }",1
"static int select_input_picture ( MpegEncContext * s ) { int i , ret ; for ( i = 1 ; i < MAX_PICTURE_COUNT ; i + + ) s - > reordered_input_picture[i - 1] = s - > reordered_input_picture[i] ; s - > reordered_input_picture[MAX_PICTURE_COUNT - 1] = NULL ; / * set next picture type & ordering * / if ( ! s - > reordered_input_picture[0] & & s - > input_picture[0] ) { if ( / * s - > picture_in_gop_number > = s - > gop_size || * / ! s - > next_picture_ptr || s - > intra_only ) { s - > reordered_input_picture[0] = s - > input_picture[0] ; s - > reordered_input_picture[0] - > f - > pict_type = AV_PICTURE_TYPE_I ; s - > reordered_input_picture[0] - > f - > coded_picture_number = s - > coded_picture_number + + ; } else { int b_frames ; if ( s - > avctx - > frame_skip_threshold || s - > avctx - > frame_skip_factor ) { if ( s - > picture_in_gop_number < s - > gop_size & & skip_check ( s , s - > input_picture[0] , s - > next_picture_ptr ) ) { // FIXME check that te gop check above is + - 1 correct av_frame_unref ( s - > input_picture[0] - > f ) ; emms_c ( ) ; ff_vbv_update ( s , 0 ) ; goto no_output_pic ; } } if ( s - > avctx - > flags & AV_CODEC_FLAG_PASS2 ) { for ( i = 0 ; i < s - > max_b_frames + 1 ; i + + ) { int pict_num = s - > input_picture[0] - > f - > display_picture_number + i ; if ( pict_num > = s - > rc_context . num_entries ) break ; if ( ! s - > input_picture[i] ) { s - > rc_context . entry[pict_num - 1] . new_pict_type = AV_PICTURE_TYPE_P ; break ; } s - > input_picture[i] - > f - > pict_type = s - > rc_context . entry[pict_num] . new_pict_type ; } } if ( s - > avctx - > b_frame_strategy == 0 ) { b_frames = s - > max_b_frames ; while ( b_frames & & ! s - > input_picture[b_frames] ) b_frames - - ; } else if ( s - > avctx - > b_frame_strategy == 1 ) { for ( i = 1 ; i < s - > max_b_frames + 1 ; i + + ) { if ( s - > input_picture[i] & & s - > input_picture[i] - > b_frame_score == 0 ) { s - > input_picture[i] - > b_frame_score = get_intra_count ( s , s - > input_picture[i ] - > f - > data[0] , s - > input_picture[i - 1] - > f - > data[0] , s - > linesize ) + 1 ; } } for ( i = 0 ; i < s - > max_b_frames + 1 ; i + + ) { if ( ! s - > input_picture[i] || s - > input_picture[i] - > b_frame_score - 1 > s - > mb_num / s - > avctx - > b_sensitivity ) break ; } b_frames = FFMAX ( 0 , i - 1 ) ; / * reset scores * / for ( i = 0 ; i < b_frames + 1 ; i + + ) { s - > input_picture[i] - > b_frame_score = 0 ; } } else if ( s - > avctx - > b_frame_strategy == 2 ) { b_frames = estimate_best_b_count ( s ) ; } else { av_log ( s - > avctx , AV_LOG_ERROR , illegal b frame strategy\n ) ; b_frames = 0 ; } emms_c ( ) ; for ( i = b_frames - 1 ; i > = 0 ; i - - ) { int type = s - > input_picture[i] - > f - > pict_type ; if ( type & & type ! = AV_PICTURE_TYPE_B ) b_frames = i ; } if ( s - > input_picture[b_frames] - > f - > pict_type == AV_PICTURE_TYPE_B & & b_frames == s - > max_b_frames ) { av_log ( s - > avctx , AV_LOG_ERROR , warning , too many b frames in a row\n ) ; } if ( s - > picture_in_gop_number + b_frames > = s - > gop_size ) { if ( ( s - > mpv_flags & FF_MPV_FLAG_STRICT_GOP ) & & s - > gop_size > s - > picture_in_gop_number ) { b_frames = s - > gop_size - s - > picture_in_gop_number - 1 ; } else { if ( s - > avctx - > flags & AV_CODEC_FLAG_CLOSED_GOP ) b_frames = 0 ; s - > input_picture[b_frames] - > f - > pict_type = AV_PICTURE_TYPE_I ; } } if ( ( s - > avctx - > flags & AV_CODEC_FLAG_CLOSED_GOP ) & & b_frames & & s - > input_picture[b_frames] - > f - > pict_type == AV_PICTURE_TYPE_I ) b_frames - - ; s - > reordered_input_picture[0] = s - > input_picture[b_frames] ; if ( s - > reordered_input_picture[0] - > f - > pict_type ! = AV_PICTURE_TYPE_I ) s - > reordered_input_picture[0] - > f - > pict_type = AV_PICTURE_TYPE_P ; s - > reordered_input_picture[0] - > f - > coded_picture_number = s - > coded_picture_number + + ; for ( i = 0 ; i < b_frames ; i + + ) { s - > reordered_input_picture[i + 1] = s - > input_picture[i] ; s - > reordered_input_picture[i + 1] - > f - > pict_type = AV_PICTURE_TYPE_B ; s - > reordered_input_picture[i + 1] - > f - > coded_picture_number = s - > coded_picture_number + + ; } } } no_output_pic : ff_mpeg_unref_picture ( s - > avctx , & s - > new_picture ) ; if ( s - > reordered_input_picture[0] ) { s - > reordered_input_picture[0] - > reference = s - > reordered_input_picture[0] - > f - > pict_type ! = AV_PICTURE_TYPE_B ? 3 : 0 ; if ( ( ret = ff_mpeg_ref_picture ( s - > avctx , & s - > new_picture , s - > reordered_input_picture[0] ) ) ) return ret ; if ( s - > reordered_input_picture[0] - > shared || s - > avctx - > rc_buffer_size ) { // input is a shared pix , so we can ' t modifiy it - > alloc a new // one & ensure that the shared one is reuseable Picture * pic ; int i = ff_find_unused_picture ( s - > avctx , s - > picture , 0 ) ; if ( i < 0 ) return i ; pic = & s - > picture[i] ; pic - > reference = s - > reordered_input_picture[0] - > reference ; if ( alloc_picture ( s , pic , 0 ) < 0 ) { return - 1 ; } ret = av_frame_copy_props ( pic - > f , s - > reordered_input_picture[0] - > f ) ; if ( ret < 0 ) return ret ; / * mark us unused / free shared",0
"static int h264_slice_header_init ( H264Context * h ) { int nb_slices = ( HAVE_THREADS & & h - > avctx - > active_thread_type & FF_THREAD_SLICE ) ? h - > avctx - > thread_count : 1 ; int i , ret ; ff_set_sar ( h - > avctx , h - > sps . sar ) ; av_pix_fmt_get_chroma_sub_sample ( h - > avctx - > pix_fmt , & h - > chroma_x_shift , & h - > chroma_y_shift ) ; if ( h - > sps . timing_info_present_flag ) { int64_t den = h - > sps . time_scale ; if ( h - > x264_build < 44U ) den * = 2 ; av_reduce ( & h - > avctx - > framerate . den , & h - > avctx - > framerate . num , h - > sps . num_units_in_tick , den , 1 < < 30 ) ; } ff_h264_free_tables ( h ) ; h - > first_field = 0 ; h - > prev_interlaced_frame = 1 ; init_scan_tables ( h ) ; ret = ff_h264_alloc_tables ( h ) ; if ( ret < 0 ) { av_log ( h - > avctx , AV_LOG_ERROR , Could not allocate memory\n ) ; return ret ; } if ( h - > sps . bit_depth_luma < 8 || h - > sps . bit_depth_luma > 10 ) { av_log ( h - > avctx , AV_LOG_ERROR , Unsupported bit depth %d\n , h - > sps . bit_depth_luma ) ; return AVERROR_INVALIDDATA ; } h - > avctx - > bits_per_raw_sample = h - > sps . bit_depth_luma ; h - > pixel_shift = h - > sps . bit_depth_luma > 8 ; h - > chroma_format_idc = h - > sps . chroma_format_idc ; h - > bit_depth_luma = h - > sps . bit_depth_luma ; ff_h264dsp_init ( & h - > h264dsp , h - > sps . bit_depth_luma , h - > sps . chroma_format_idc ) ; ff_h264chroma_init ( & h - > h264chroma , h - > sps . bit_depth_chroma ) ; ff_h264qpel_init ( & h - > h264qpel , h - > sps . bit_depth_luma ) ; ff_h264_pred_init ( & h - > hpc , h - > avctx - > codec_id , h - > sps . bit_depth_luma , h - > sps . chroma_format_idc ) ; ff_videodsp_init ( & h - > vdsp , h - > sps . bit_depth_luma ) ; if ( nb_slices > H264_MAX_THREADS || ( nb_slices > h - > mb_height & & h - > mb_height ) ) { int max_slices ; if ( h - > mb_height ) max_slices = FFMIN ( H264_MAX_THREADS , h - > mb_height ) ; else max_slices = H264_MAX_THREADS ; av_log ( h - > avctx , AV_LOG_WARNING , too many threads/slices %d , reducing to %d\n , nb_slices , max_slices ) ; nb_slices = max_slices ; } h - > slice_context_count = nb_slices ; if ( ! HAVE_THREADS || ! ( h - > avctx - > active_thread_type & FF_THREAD_SLICE ) ) { ret = ff_h264_slice_context_init ( h , & h - > slice_ctx[0] ) ; if ( ret < 0 ) { av_log ( h - > avctx , AV_LOG_ERROR , context_init ( ) failed . \n ) ; return ret ; } } else { for ( i = 0 ; i < h - > slice_context_count ; i + + ) { H264SliceContext * sl = & h - > slice_ctx[i] ; sl - > h264 = h ; sl - > intra4x4_pred_mode = h - > intra4x4_pred_mode + i * 8 * 2 * h - > mb_stride ; sl - > mvd_table[0] = h - > mvd_table[0] + i * 8 * 2 * h - > mb_stride ; sl - > mvd_table[1] = h - > mvd_table[1] + i * 8 * 2 * h - > mb_stride ; if ( ( ret = ff_h264_slice_context_init ( h , sl ) ) < 0 ) { av_log ( h - > avctx , AV_LOG_ERROR , context_init ( ) failed . \n ) ; return ret ; } } } h - > context_initialized = 1 ; return 0 ; }",0
"int ff_mpv_frame_start ( MpegEncContext * s , AVCodecContext * avctx ) { int i , ret ; Picture * pic ; s - > mb_skipped = 0 ; / * mark & release old frames * / if ( s - > pict_type ! = AV_PICTURE_TYPE_B & & s - > last_picture_ptr & & s - > last_picture_ptr ! = s - > next_picture_ptr & & s - > last_picture_ptr - > f - > buf[0] ) { ff_mpeg_unref_picture ( s - > avctx , s - > last_picture_ptr ) ; } / * release forgotten pictures * / / * if ( MPEG - 124 / H . 263 ) * / for ( i = 0 ; i < MAX_PICTURE_COUNT ; i + + ) { if ( & s - > picture[i] ! = s - > last_picture_ptr & & & s - > picture[i] ! = s - > next_picture_ptr & & s - > picture[i] . reference & & ! s - > picture[i] . needs_realloc ) { ff_mpeg_unref_picture ( s - > avctx , & s - > picture[i] ) ; } } ff_mpeg_unref_picture ( s - > avctx , & s - > current_picture ) ; / * release non reference frames * / for ( i = 0 ; i < MAX_PICTURE_COUNT ; i + + ) { if ( ! s - > picture[i] . reference ) ff_mpeg_unref_picture ( s - > avctx , & s - > picture[i] ) ; } if ( s - > current_picture_ptr & & ! s - > current_picture_ptr - > f - > buf[0] ) { // we already have a unused image // ( maybe it was set before reading the header ) pic = s - > current_picture_ptr ; } else { i = ff_find_unused_picture ( s - > avctx , s - > picture , 0 ) ; if ( i < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , no frame buffer available\n ) ; return i ; } pic = & s - > picture[i] ; } pic - > reference = 0 ; if ( ! s - > droppable ) { if ( s - > pict_type ! = AV_PICTURE_TYPE_B ) pic - > reference = 3 ; } pic - > f - > coded_picture_number = s - > coded_picture_number + + ; if ( alloc_picture ( s , pic , 0 ) < 0 ) return - 1 ; s - > current_picture_ptr = pic ; // FIXME use only the vars from current_pic s - > current_picture_ptr - > f - > top_field_first = s - > top_field_first ; if ( s - > codec_id == AV_CODEC_ID_MPEG1VIDEO || s - > codec_id == AV_CODEC_ID_MPEG2VIDEO ) { if ( s - > picture_structure ! = PICT_FRAME ) s - > current_picture_ptr - > f - > top_field_first = ( s - > picture_structure == PICT_TOP_FIELD ) == s - > first_field ; } s - > current_picture_ptr - > f - > interlaced_frame = ! s - > progressive_frame & & ! s - > progressive_sequence ; s - > current_picture_ptr - > field_picture = s - > picture_structure ! = PICT_FRAME ; s - > current_picture_ptr - > f - > pict_type = s - > pict_type ; // if ( s - > avctx - > flags & & AV_CODEC_FLAG_QSCALE ) // s - > current_picture_ptr - > quality = s - > new_picture_ptr - > quality ; s - > current_picture_ptr - > f - > key_frame = s - > pict_type == AV_PICTURE_TYPE_I ; if ( ( ret = ff_mpeg_ref_picture ( s - > avctx , & s - > current_picture , s - > current_picture_ptr ) ) < 0 ) return ret ; if ( s - > pict_type ! = AV_PICTURE_TYPE_B ) { s - > last_picture_ptr = s - > next_picture_ptr ; if ( ! s - > droppable ) s - > next_picture_ptr = s - > current_picture_ptr ; } ff_dlog ( s - > avctx , L%p N%p C%p L%p N%p C%p type : %d drop : %d\n , s - > last_picture_ptr , s - > next_picture_ptr , s - > current_picture_ptr , s - > last_picture_ptr ? s - > last_picture_ptr - > f - > data[0] : NULL , s - > next_picture_ptr ? s - > next_picture_ptr - > f - > data[0] : NULL , s - > current_picture_ptr ? s - > current_picture_ptr - > f - > data[0] : NULL , s - > pict_type , s - > droppable ) ; if ( ( ! s - > last_picture_ptr || ! s - > last_picture_ptr - > f - > buf[0] ) & & ( s - > pict_type ! = AV_PICTURE_TYPE_I || s - > picture_structure ! = PICT_FRAME ) ) { int h_chroma_shift , v_chroma_shift ; av_pix_fmt_get_chroma_sub_sample ( s - > avctx - > pix_fmt , & h_chroma_shift , & v_chroma_shift ) ; if ( s - > pict_type ! = AV_PICTURE_TYPE_I ) av_log ( avctx , AV_LOG_ERROR , warning : first frame is no keyframe\n ) ; else if ( s - > picture_structure ! = PICT_FRAME ) av_log ( avctx , AV_LOG_INFO , allocate dummy last picture for field based first keyframe\n ) ; / * Allocate a dummy frame * / i = ff_find_unused_picture ( s - > avctx , s - > picture , 0 ) ; if ( i < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , no frame buffer available\n ) ; return i ; } s - > last_picture_ptr = & s - > picture[i] ; s - > last_picture_ptr - > reference = 3 ; s - > last_picture_ptr - > f - > pict_type = AV_PICTURE_TYPE_I ; if ( alloc_picture ( s , s - > last_picture_ptr , 0 ) < 0 ) { s - > last_picture_ptr = NULL ; return - 1 ; } memset ( s - > last_picture_ptr - > f - > data[0] , 0 , avctx - > height * s - > last_picture_ptr - > f - > linesize[0] ) ; memset ( s - > last_picture_ptr - > f - > data[1] , 0x80 , ( avctx - > height > > v_chroma_shift ) * s - > last_picture_ptr - > f - > linesize[1] ) ; memset ( s - > last_picture_ptr - > f - > data[2] , 0x80 , ( avctx - > height > > v_chroma_shift ) * s - > last_picture_ptr - > f - > linesize[2] ) ; ff_thread_report_progress ( & s - > last_picture_ptr - > tf , INT_MAX , 0 ) ; ff_thread_report_progress ( & s - > last_picture_ptr - > tf , INT_MAX , 1 ) ; } if ( ( ! s - > next_picture_ptr || ! s - > next_picture_ptr - > f - > buf[0] ) & & s - > pict_type == AV_PICTURE_TYPE_B ) { / * Allocate a dummy frame * / i = ff_find_unused_picture ( s - > avctx , s - > picture ,",0
"static inline void h264_loop_filter_luma_mmx2 ( uint8_t * pix , int stride , int alpha1 , int beta1 , int8_t * tc0 ) { DECLARE_ALIGNED_8 ( uint64_t , tmp0[2] ) ; __asm__ volatile ( movq ( %1 , %3 ) , %%mm0 \n\t //p1 movq ( %1 , %3 , 2 ) , %%mm1 \n\t //p0 movq ( %2 ) , %%mm2 \n\t //q0 movq ( %2 , %3 ) , %%mm3 \n\t //q1 H264_DEBLOCK_MASK ( %6 , %7 ) movd %5 , %%mm4 \n\t punpcklbw %%mm4 , %%mm4 \n\t punpcklwd %%mm4 , %%mm4 \n\t pcmpeqb %%mm3 , %%mm3 \n\t movq %%mm4 , %%mm6 \n\t pcmpgtb %%mm3 , %%mm4 \n\t movq %%mm6 , 8 + %0 \n\t pand %%mm4 , %%mm7 \n\t movq %%mm7 , %0 \n\t / * filter p1 * / movq ( %1 ) , %%mm3 \n\t //p2 DIFF_GT2_MMX ( %%mm1 , %%mm3 , %%mm5 , %%mm6 , %%mm4 ) // |p2 - p0| > beta - 1 pand %%mm7 , %%mm6 \n\t // mask & |p2 - p0| < beta pand 8 + %0 , %%mm7 \n\t // mask & tc0 movq %%mm7 , %%mm4 \n\t psubb %%mm6 , %%mm7 \n\t pand %%mm4 , %%mm6 \n\t // mask & |p2 - p0| < beta & tc0 H264_DEBLOCK_Q1 ( %%mm0 , %%mm3 , ( %1 ) , ( %1 , %3 ) , %%mm6 , %%mm4 ) / * filter q1 * / movq ( %2 , %3 , 2 ) , %%mm4 \n\t //q2 DIFF_GT2_MMX ( %%mm2 , %%mm4 , %%mm5 , %%mm6 , %%mm3 ) // |q2 - q0| > beta - 1 pand %0 , %%mm6 \n\t movq 8 + %0 , %%mm5 \n\t // can be merged with the and below but is slower then pand %%mm6 , %%mm5 \n\t psubb %%mm6 , %%mm7 \n\t movq ( %2 , %3 ) , %%mm3 \n\t H264_DEBLOCK_Q1 ( %%mm3 , %%mm4 , ( %2 , %3 , 2 ) , ( %2 , %3 ) , %%mm5 , %%mm6 ) / * filter p0 , q0 * / H264_DEBLOCK_P0_Q0 ( %8 , unused ) movq %%mm1 , ( %1 , %3 , 2 ) \n\t movq %%mm2 , ( %2 ) \n\t : =m ( * tmp0 ) : r ( pix - 3 * stride ) , r ( pix ) , r ( ( x86_reg ) stride ) , m ( * tmp0 / * unused * / ) , m ( * ( uint32_t * ) tc0 ) , m ( alpha1 ) , m ( beta1 ) , m ( ff_bone ) ) ; }",0
"int ff_init_me ( MpegEncContext * s ) { MotionEstContext * const c= & s - > me ; int cache_size= FFMIN ( ME_MAP_SIZE > > ME_MAP_SHIFT , 1 < < ME_MAP_SHIFT ) ; int dia_size= FFMAX ( FFABS ( s - > avctx - > dia_size ) & 255 , FFABS ( s - > avctx - > pre_dia_size ) & 255 ) ; if ( FFMIN ( s - > avctx - > dia_size , s - > avctx - > pre_dia_size ) < - ME_MAP_SIZE ) { av_log ( s - > avctx , AV_LOG_ERROR , ME_MAP size is too small for SAB diamond\n ) ; return - 1 ; } //special case of snow is needed because snow uses its own iterative ME code if ( s - > me_method ! =ME_ZERO & & s - > me_method ! =ME_EPZS & & s - > me_method ! =ME_X1 & & s - > avctx - > codec_id ! = AV_CODEC_ID_SNOW ) { av_log ( s - > avctx , AV_LOG_ERROR , me_method is only allowed to be set to zero and epzs ; for hex , umh , full and others see dia_size\n ) ; return - 1 ; } c - > avctx= s - > avctx ; if ( cache_size < 2 * dia_size & & ! c - > stride ) { av_log ( s - > avctx , AV_LOG_INFO , ME_MAP size may be a little small for the selected diamond size\n ) ; } ff_set_cmp ( & s - > dsp , s - > dsp . me_pre_cmp , c - > avctx - > me_pre_cmp ) ; ff_set_cmp ( & s - > dsp , s - > dsp . me_cmp , c - > avctx - > me_cmp ) ; ff_set_cmp ( & s - > dsp , s - > dsp . me_sub_cmp , c - > avctx - > me_sub_cmp ) ; ff_set_cmp ( & s - > dsp , s - > dsp . mb_cmp , c - > avctx - > mb_cmp ) ; c - > flags = get_flags ( c , 0 , c - > avctx - > me_cmp & FF_CMP_CHROMA ) ; c - > sub_flags= get_flags ( c , 0 , c - > avctx - > me_sub_cmp & FF_CMP_CHROMA ) ; c - > mb_flags = get_flags ( c , 0 , c - > avctx - > mb_cmp & FF_CMP_CHROMA ) ; / * FIXME s - > no_rounding b_type * / if ( s - > flags & CODEC_FLAG_QPEL ) { c - > sub_motion_search= qpel_motion_search ; c - > qpel_avg= s - > dsp . avg_qpel_pixels_tab ; if ( s - > no_rounding ) c - > qpel_put= s - > dsp . put_no_rnd_qpel_pixels_tab ; else c - > qpel_put= s - > dsp . put_qpel_pixels_tab ; } else { if ( c - > avctx - > me_sub_cmp & FF_CMP_CHROMA ) c - > sub_motion_search= hpel_motion_search ; else if ( c - > avctx - > me_sub_cmp == FF_CMP_SAD & & c - > avctx - > me_cmp == FF_CMP_SAD & & c - > avctx - > mb_cmp == FF_CMP_SAD ) c - > sub_motion_search= sad_hpel_motion_search ; // 2050 vs . 2450 cycles else c - > sub_motion_search= hpel_motion_search ; } c - > hpel_avg= s - > dsp . avg_pixels_tab ; if ( s - > no_rounding ) c - > hpel_put= s - > dsp . put_no_rnd_pixels_tab ; else c - > hpel_put= s - > dsp . put_pixels_tab ; if ( s - > linesize ) { c - > stride = s - > linesize ; c - > uvstride= s - > uvlinesize ; } else { c - > stride = 16 * s - > mb_width + 32 ; c - > uvstride= 8 * s - > mb_width + 16 ; } / * 8x8 fullpel search would need a 4x4 chroma compare , which we do * not have yet , and even if we had , the motion estimation code * does not expect it . * / if ( s - > codec_id ! = AV_CODEC_ID_SNOW ) { if ( ( c - > avctx - > me_cmp & FF_CMP_CHROMA ) / * & & ! s - > dsp . me_cmp[2] * / ) { s - > dsp . me_cmp[2]= zero_cmp ; } if ( ( c - > avctx - > me_sub_cmp & FF_CMP_CHROMA ) & & ! s - > dsp . me_sub_cmp[2] ) { s - > dsp . me_sub_cmp[2]= zero_cmp ; } c - > hpel_put[2][0]= c - > hpel_put[2][1]= c - > hpel_put[2][2]= c - > hpel_put[2][3]= zero_hpel ; } if ( s - > codec_id == AV_CODEC_ID_H261 ) { c - > sub_motion_search= no_sub_motion_search ; } return 0 ; }",0
"static int filter_frame ( AVFilterLink * inlink , AVFrame * buf ) { AVFilterContext * ctx = inlink - > dst ; AVFilterLink * outlink = ctx - > outputs[0] ; DeflickerContext * s = ctx - > priv ; AVDictionary * * metadata ; AVFrame * out , * in ; float f ; int y ; if ( s - > q . available < s - > size & & ! s - > eof ) { s - > luminance[s - > available] = s - > calc_avgy ( ctx , buf ) ; ff_bufqueue_add ( ctx , & s - > q , buf ) ; s - > available + + ; return 0 ; } in = ff_bufqueue_peek ( & s - > q , 0 ) ; out = ff_get_video_buffer ( outlink , outlink - > w , outlink - > h ) ; if ( ! out ) { av_frame_free ( & buf ) ; return AVERROR ( ENOMEM ) ; } s - > get_factor ( ctx , & f ) ; s - > deflicker ( ctx , in - > data[0] , in - > linesize[0] , out - > data[0] , out - > linesize[0] , outlink - > w , outlink - > h , f ) ; for ( y = 1 ; y < s - > nb_planes ; y + + ) { av_image_copy_plane ( out - > data[y] , out - > linesize[y] , in - > data[y] , in - > linesize[y] , s - > planewidth[y] * ( 1 + ( s - > depth > 8 ) ) , s - > planeheight[y] ) ; } av_frame_copy_props ( out , in ) ; metadata = & out - > metadata ; if ( metadata ) { uint8_t value[128] ; snprintf ( value , sizeof ( value ) , %f , s - > luminance[0] ) ; av_dict_set ( metadata , lavfi . deflicker . luminance , value , 0 ) ; snprintf ( value , sizeof ( value ) , %f , s - > luminance[0] * f ) ; av_dict_set ( metadata , lavfi . deflicker . new_luminance , value , 0 ) ; snprintf ( value , sizeof ( value ) , %f , f - 1 . 0f ) ; av_dict_set ( metadata , lavfi . deflicker . relative_change , value , 0 ) ; } in = ff_bufqueue_get ( & s - > q ) ; av_frame_free ( & in ) ; memmove ( & s - > luminance[0] , & s - > luminance[1] , sizeof ( * s - > luminance ) * ( s - > size - 1 ) ) ; s - > luminance[s - > available - 1] = s - > calc_avgy ( ctx , buf ) ; ff_bufqueue_add ( ctx , & s - > q , buf ) ; return ff_filter_frame ( outlink , out ) ; }",0
"static inline int msmpeg4_decode_block ( MpegEncContext * s , DCTELEM * block , int n , int coded ) { int level , i , last , run , run_diff ; int dc_pred_dir ; RLTable * rl ; RL_VLC_ELEM * rl_vlc ; const UINT8 * scan_table ; int qmul , qadd ; if ( s - > mb_intra ) { qmul=1 ; qadd=0 ; / * DC coef * / set_stat ( ST_DC ) ; level = msmpeg4_decode_dc ( s , n , & dc_pred_dir ) ; ifdef PRINT_MB { static int c ; if ( n==0 ) c=0 ; if ( n==4 ) printf ( %X , c ) ; c + = c + dc_pred_dir ; } endif if ( level < 0 ) { fprintf ( stderr , dc overflow - block : %d qscale : %d//\n , n , s - > qscale ) ; if ( s - > inter_intra_pred ) level=0 ; else return - 1 ; } if ( n < 4 ) { rl = & rl_table[s - > rl_table_index] ; if ( level > 256 * s - > y_dc_scale ) { fprintf ( stderr , dc overflow + L qscale : %d//\n , s - > qscale ) ; if ( ! s - > inter_intra_pred ) return - 1 ; } } else { rl = & rl_table[3 + s - > rl_chroma_table_index] ; if ( level > 256 * s - > c_dc_scale ) { fprintf ( stderr , dc overflow + C qscale : %d//\n , s - > qscale ) ; if ( ! s - > inter_intra_pred ) return - 1 ; } } block[0] = level ; run_diff = 0 ; i = 0 ; if ( ! coded ) { goto not_coded ; } if ( s - > ac_pred ) { if ( dc_pred_dir == 0 ) scan_table = s - > intra_v_scantable ; / * left * / else scan_table = s - > intra_h_scantable ; / * top * / } else { scan_table = s - > intra_scantable ; } set_stat ( ST_INTRA_AC ) ; rl_vlc= rl - > rl_vlc[0] ; } else { qmul = s - > qscale < < 1 ; qadd = ( s - > qscale - 1 ) | 1 ; i = - 1 ; rl = & rl_table[3 + s - > rl_table_index] ; if ( s - > msmpeg4_version==2 ) run_diff = 0 ; else run_diff = 1 ; if ( ! coded ) { s - > block_last_index[n] = i ; return 0 ; } scan_table = s - > inter_scantable ; set_stat ( ST_INTER_AC ) ; rl_vlc= rl - > rl_vlc[s - > qscale] ; } { OPEN_READER ( re , & s - > gb ) ; for ( ; ; ) { UPDATE_CACHE ( re , & s - > gb ) ; GET_RL_VLC ( level , run , re , & s - > gb , rl_vlc , TEX_VLC_BITS , 2 ) ; if ( level==0 ) { int cache ; cache= GET_CACHE ( re , & s - > gb ) ; / * escape * / if ( s - > msmpeg4_version==1 || ( cache & 0x80000000 ) ==0 ) { if ( s - > msmpeg4_version==1 || ( cache & 0x40000000 ) ==0 ) { / * third escape * / if ( s - > msmpeg4_version ! =1 ) LAST_SKIP_BITS ( re , & s - > gb , 2 ) ; UPDATE_CACHE ( re , & s - > gb ) ; if ( s - > msmpeg4_version < =3 ) { last= SHOW_UBITS ( re , & s - > gb , 1 ) ; SKIP_CACHE ( re , & s - > gb , 1 ) ; run= SHOW_UBITS ( re , & s - > gb , 6 ) ; SKIP_CACHE ( re , & s - > gb , 6 ) ; level= SHOW_SBITS ( re , & s - > gb , 8 ) ; LAST_SKIP_CACHE ( re , & s - > gb , 8 ) ; SKIP_COUNTER ( re , & s - > gb , 1 + 6 + 8 ) ; } else { int sign ; last= SHOW_UBITS ( re , & s - > gb , 1 ) ; SKIP_BITS ( re , & s - > gb , 1 ) ; if ( ! s - > esc3_level_length ) { int ll ; //printf ( ESC - 3 %X at %d %d\n , show_bits ( & s - > gb , 24 ) , s - > mb_x , s - > mb_y ) ; if ( s - > qscale < 8 ) { ll= SHOW_UBITS ( re , & s - > gb , 3 ) ; SKIP_BITS ( re , & s - > gb , 3 ) ; if ( ll==0 ) { if ( SHOW_UBITS ( re , & s - > gb , 1 ) ) printf ( cool a new vlc code , contact the ffmpeg developers and upload the file\n ) ; SKIP_BITS ( re , & s - > gb , 1 ) ; ll=8 ; } } else { ll=2 ; while ( ll < 8 & & SHOW_UBITS ( re , & s - > gb , 1 ) ==0 ) { ll + + ; SKIP_BITS ( re , & s - > gb , 1 ) ; } if ( ll < 8 ) SKIP_BITS ( re , & s - > gb , 1 ) ; } s - > esc3_level_length= ll ; s - > esc3_run_length= SHOW_UBITS ( re , & s - > gb , 2 ) + 3 ; SKIP_BITS ( re , & s - > gb , 2 ) ; //printf ( level length : %d , run length : %d\n , ll , s - > esc3_run_length ) ; UPDATE_CACHE ( re , & s - > gb ) ; } run= SHOW_UBITS ( re , & s - > gb , s - > esc3_run_length ) ; SKIP_BITS ( re , & s - > gb , s - > esc3_run_length ) ; sign= SHOW_UBITS ( re , & s - > gb , 1 ) ; SKIP_BITS ( re , & s - > gb , 1 ) ; level= SHOW_UBITS ( re , & s - > gb , s - > esc3_level_length ) ; SKIP_BITS ( re , & s - > gb , s - > esc3_level_length ) ; if ( sign ) level= - level ; } //printf ( level : %d , run : %d at %d %d\n , level , run , s - > mb_x , s - > mb_y ) ; if 0 // waste of time / this will detect very few errors { const int abs_level= ABS ( level ) ; const int run1= run - rl - > max_run[last][abs_level] - run_diff ; if ( abs_level < =MAX_LEVEL & & run < =MAX_RUN ) { if ( abs_level < = rl - > max_level[last][run] ) {",1
"static int oma_read_packet ( AVFormatContext * s , AVPacket * pkt ) { OMAContext * oc = s - > priv_data ; AVStream * st = s - > streams[0] ; int packet_size = st - > codec - > block_align ; int byte_rate = st - > codec - > bit_rate > > 3 ; int64_t pos = avio_tell ( s - > pb ) ; int ret = av_get_packet ( s - > pb , pkt , packet_size ) ; if ( ret < packet_size ) pkt - > flags |= AV_PKT_FLAG_CORRUPT ; if ( ret < 0 ) return ret ; if ( ! ret ) return AVERROR_EOF ; pkt - > stream_index = 0 ; if ( pos > 0 ) { pkt - > pts = pkt - > dts = av_rescale ( pos , st - > time_base . den , byte_rate * ( int64_t ) st - > time_base . num ) ; } if ( oc - > encrypted ) { / * previous unencrypted block saved in IV for * the next packet ( CBC mode ) * / if ( ret == packet_size ) av_des_crypt ( & oc - > av_des , pkt - > data , pkt - > data , ( packet_size > > 3 ) , oc - > iv , 1 ) ; else memset ( oc - > iv , 0 , 8 ) ; } return ret ; }",1
"void av_opt_set_defaults2 ( void * s , int mask , int flags ) { endif const AVOption * opt = NULL ; while ( ( opt = av_opt_next ( s , opt ) ) ! = NULL ) { if FF_API_OLD_AVOPTIONS if ( ( opt - > flags & mask ) ! = flags ) continue ; endif switch ( opt - > type ) { case AV_OPT_TYPE_CONST : / * Nothing to be done here * / break ; case AV_OPT_TYPE_FLAGS : case AV_OPT_TYPE_INT : case AV_OPT_TYPE_INT64 : av_opt_set_int ( s , opt - > name , opt - > default_val . i64 , 0 ) ; break ; case AV_OPT_TYPE_DOUBLE : case AV_OPT_TYPE_FLOAT : { double val ; val = opt - > default_val . dbl ; av_opt_set_double ( s , opt - > name , val , 0 ) ; } break ; case AV_OPT_TYPE_RATIONAL : { AVRational val ; val = av_d2q ( opt - > default_val . dbl , INT_MAX ) ; av_opt_set_q ( s , opt - > name , val , 0 ) ; } break ; case AV_OPT_TYPE_STRING : case AV_OPT_TYPE_IMAGE_SIZE : case AV_OPT_TYPE_PIXEL_FMT : case AV_OPT_TYPE_SAMPLE_FMT : av_opt_set ( s , opt - > name , opt - > default_val . str , 0 ) ; break ; case AV_OPT_TYPE_BINARY : / * Cannot set default for binary * / break ; default : av_log ( s , AV_LOG_DEBUG , AVOption type %d of option %s not implemented yet\n , opt - > type , opt - > name ) ; } } }",0
"static int RENAME ( resample_common ) ( ResampleContext * c , void * dest , const void * source , int n , int update_ctx ) { DELEM * dst = dest ; const DELEM * src = source ; int dst_index ; int index= c - > index ; int frac= c - > frac ; int sample_index = 0 ; while ( index > = c - > phase_count ) { sample_index + + ; index - = c - > phase_count ; } for ( dst_index = 0 ; dst_index < n ; dst_index + + ) { FELEM * filter = ( ( FELEM * ) c - > filter_bank ) + c - > filter_alloc * index ; FELEM2 val= FOFFSET ; int i ; for ( i = 0 ; i < c - > filter_length ; i + + ) { val + = src[sample_index + i] * ( FELEM2 ) filter[i] ; } OUT ( dst[dst_index] , val ) ; frac + = c - > dst_incr_mod ; index + = c - > dst_incr_div ; if ( frac > = c - > src_incr ) { frac - = c - > src_incr ; index + + ; } while ( index > = c - > phase_count ) { sample_index + + ; index - = c - > phase_count ; } } if ( update_ctx ) { c - > frac= frac ; c - > index= index ; } return sample_index ; }",1
"static int channelmap_filter_samples ( AVFilterLink * inlink , AVFilterBufferRef * buf ) { AVFilterContext * ctx = inlink - > dst ; AVFilterLink * outlink = ctx - > outputs[0] ; const ChannelMapContext * s = ctx - > priv ; const int nch_in = av_get_channel_layout_nb_channels ( inlink - > channel_layout ) ; const int nch_out = s - > nch ; int ch ; uint8_t * source_planes[MAX_CH] ; memcpy ( source_planes , buf - > extended_data , nch_in * sizeof ( source_planes[0] ) ) ; if ( nch_out > nch_in ) { if ( nch_out > FF_ARRAY_ELEMS ( buf - > data ) ) { uint8_t * * new_extended_data = av_mallocz ( nch_out * sizeof ( * buf - > extended_data ) ) ; if ( ! new_extended_data ) { avfilter_unref_buffer ( buf ) ; return AVERROR ( ENOMEM ) ; } if ( buf - > extended_data == buf - > data ) { buf - > extended_data = new_extended_data ; } else { buf - > extended_data = new_extended_data ; av_free ( buf - > extended_data ) ; } } else if ( buf - > extended_data ! = buf - > data ) { av_free ( buf - > extended_data ) ; buf - > extended_data = buf - > data ; } } for ( ch = 0 ; ch < nch_out ; ch + + ) { buf - > extended_data[s - > map[ch] . out_channel_idx] = source_planes[s - > map[ch] . in_channel_idx] ; } if ( buf - > data ! = buf - > extended_data ) memcpy ( buf - > data , buf - > extended_data , FFMIN ( FF_ARRAY_ELEMS ( buf - > data ) , nch_out ) * sizeof ( buf - > data[0] ) ) ; return ff_filter_samples ( outlink , buf ) ; }",1
"static int encode_thread ( AVCodecContext * c , void * arg ) { MpegEncContext * s= * ( void * * ) arg ; int mb_x , mb_y , pdif = 0 ; int chr_h= 16 > > s - > chroma_y_shift ; int i , j ; MpegEncContext best_s , backup_s ; uint8_t bit_buf[2][MAX_MB_BYTES] ; uint8_t bit_buf2[2][MAX_MB_BYTES] ; uint8_t bit_buf_tex[2][MAX_MB_BYTES] ; PutBitContext pb[2] , pb2[2] , tex_pb[2] ; //printf ( %d - > %d\n , s - > resync_mb_y , s - > end_mb_y ) ; ff_check_alignment ( ) ; for ( i=0 ; i < 2 ; i + + ) { init_put_bits ( & pb [i] , bit_buf [i] , MAX_MB_BYTES ) ; init_put_bits ( & pb2 [i] , bit_buf2 [i] , MAX_MB_BYTES ) ; init_put_bits ( & tex_pb[i] , bit_buf_tex[i] , MAX_MB_BYTES ) ; } s - > last_bits= put_bits_count ( & s - > pb ) ; s - > mv_bits=0 ; s - > misc_bits=0 ; s - > i_tex_bits=0 ; s - > p_tex_bits=0 ; s - > i_count=0 ; s - > f_count=0 ; s - > b_count=0 ; s - > skip_count=0 ; for ( i=0 ; i < 3 ; i + + ) { / * init last dc values * / / * note : quant matrix value ( 8 ) is implied here * / s - > last_dc[i] = 128 < < s - > intra_dc_precision ; s - > current_picture . error[i] = 0 ; } s - > mb_skip_run = 0 ; memset ( s - > last_mv , 0 , sizeof ( s - > last_mv ) ) ; s - > last_mv_dir = 0 ; switch ( s - > codec_id ) { case CODEC_ID_H263 : case CODEC_ID_H263P : case CODEC_ID_FLV1 : if ( CONFIG_H263_ENCODER || CONFIG_FLV_ENCODER ) s - > gob_index = ff_h263_get_gob_height ( s ) ; break ; case CODEC_ID_MPEG4 : if ( CONFIG_MPEG4_ENCODER & & s - > partitioned_frame ) ff_mpeg4_init_partitions ( s ) ; break ; } s - > resync_mb_x=0 ; s - > resync_mb_y=0 ; s - > first_slice_line = 1 ; s - > ptr_lastgob = s - > pb . buf ; for ( mb_y= s - > start_mb_y ; mb_y < s - > end_mb_y ; mb_y + + ) { // printf ( row %d at %X\n , s - > mb_y , ( int ) s ) ; s - > mb_x=0 ; s - > mb_y= mb_y ; ff_set_qscale ( s , s - > qscale ) ; ff_init_block_index ( s ) ; for ( mb_x=0 ; mb_x < s - > mb_width ; mb_x + + ) { int xy= mb_y * s - > mb_stride + mb_x ; // removed const , H261 needs to adjust this int mb_type= s - > mb_type[xy] ; // int d ; int dmin= INT_MAX ; int dir ; if ( s - > pb . buf_end - s - > pb . buf - ( put_bits_count ( & s - > pb ) > > 3 ) < MAX_MB_BYTES ) { av_log ( s - > avctx , AV_LOG_ERROR , encoded frame too large\n ) ; return - 1 ; } if ( s - > data_partitioning ) { if ( s - > pb2 . buf_end - s - > pb2 . buf - ( put_bits_count ( & s - > pb2 ) > > 3 ) < MAX_MB_BYTES || s - > tex_pb . buf_end - s - > tex_pb . buf - ( put_bits_count ( & s - > tex_pb ) > > 3 ) < MAX_MB_BYTES ) { av_log ( s - > avctx , AV_LOG_ERROR , encoded frame too large\n ) ; return - 1 ; } } s - > mb_x = mb_x ; s - > mb_y = mb_y ; // moved into loop , can get changed by H . 261 ff_update_block_index ( s ) ; if ( CONFIG_H261_ENCODER & & s - > codec_id == CODEC_ID_H261 ) { ff_h261_reorder_mb_index ( s ) ; xy= s - > mb_y * s - > mb_stride + s - > mb_x ; mb_type= s - > mb_type[xy] ; } / * write gob / video packet header * / if ( s - > rtp_mode ) { int current_packet_size , is_gob_start ; current_packet_size= ( ( put_bits_count ( & s - > pb ) + 7 ) > > 3 ) - ( s - > ptr_lastgob - s - > pb . buf ) ; is_gob_start= s - > avctx - > rtp_payload_size & & current_packet_size > = s - > avctx - > rtp_payload_size & & mb_y + mb_x > 0 ; if ( s - > start_mb_y == mb_y & & mb_y > 0 & & mb_x==0 ) is_gob_start=1 ; switch ( s - > codec_id ) { case CODEC_ID_H263 : case CODEC_ID_H263P : if ( ! s - > h263_slice_structured ) if ( s - > mb_x || s - > mb_y%s - > gob_index ) is_gob_start=0 ; break ; case CODEC_ID_MPEG2VIDEO : if ( s - > mb_x==0 & & s - > mb_y ! =0 ) is_gob_start=1 ; case CODEC_ID_MPEG1VIDEO : if ( s - > mb_skip_run ) is_gob_start=0 ; break ; } if ( is_gob_start ) { if ( s - > start_mb_y ! = mb_y || mb_x ! =0 ) { write_slice_end ( s ) ; if ( CONFIG_MPEG4_ENCODER & & s - > codec_id==CODEC_ID_MPEG4 & & s - > partitioned_frame ) { ff_mpeg4_init_partitions ( s ) ; } } assert ( ( put_bits_count ( & s - > pb ) & 7 ) == 0 ) ; current_packet_size= put_bits_ptr ( & s - > pb ) - s - > ptr_lastgob ; if ( s - > avctx - > error_rate & & s - > resync_mb_x + s - > resync_mb_y > 0 ) { int r= put_bits_count ( & s - > pb ) /8 + s - > picture_number + 16 + s - > mb_x + s - > mb_y ; int d= 100 / s - > avctx - > error_rate ; if ( r % d == 0 ) { current_packet_size=0 ; ifndef ALT_BITSTREAM_WRITER s - > pb . buf_ptr= s - > ptr_lastgob ; endif assert ( put_bits_ptr ( & s - > pb ) == s - > ptr_lastgob ) ; } } if ( s - > avctx - > rtp_callback ) { int number_mb = ( mb_y - s - > resync_mb_y ) * s - > mb_width + mb_x - s - > resync_mb_x ; s - > avctx - > rtp_callback ( s - > avctx , s - > ptr_lastgob , current_packet_size , number_mb ) ; } switch ( s - > codec_id ) { case CODEC_ID_MPEG4 : if ( CONFIG_MPEG4_ENCODER ) { ff_mpeg4_encode_video_packet_header ( s ) ; ff_mpeg4_clean_buffers ( s ) ; } break ; case CODEC_ID_MPEG1VIDEO : case CODEC_ID_MPEG2VIDEO : if ( CONFIG_MPEG1VIDEO_ENCODER || CONFIG_MPEG2VIDEO_ENCODER ) { ff_mpeg1_encode_slice_header ( s ) ; ff_mpeg1_clean_buffers ( s ) ; } break ; case CODEC_ID_H263 : case CODEC_ID_H263P : if ( CONFIG_H263_ENCODER ) h263_encode_gob_header (",0
"static void new_audio_stream ( AVFormatContext * oc , int file_idx ) { AVStream * st ; OutputStream * ost ; AVCodec * codec= NULL ; AVCodecContext * audio_enc ; enum CodecID codec_id = CODEC_ID_NONE ; if ( ! audio_stream_copy ) { if ( audio_codec_name ) { codec_id = find_codec_or_die ( audio_codec_name , AVMEDIA_TYPE_AUDIO , 1 , avcodec_opts[AVMEDIA_TYPE_AUDIO] - > strict_std_compliance ) ; codec = avcodec_find_encoder_by_name ( audio_codec_name ) ; } else { codec_id = av_guess_codec ( oc - > oformat , NULL , oc - > filename , NULL , AVMEDIA_TYPE_AUDIO ) ; codec = avcodec_find_encoder ( codec_id ) ; } } ost = new_output_stream ( oc , file_idx , codec ) ; st = ost - > st ; ost - > bitstream_filters = audio_bitstream_filters ; audio_bitstream_filters= NULL ; st - > codec - > thread_count= thread_count ; audio_enc = st - > codec ; audio_enc - > codec_type = AVMEDIA_TYPE_AUDIO ; if ( audio_codec_tag ) audio_enc - > codec_tag= audio_codec_tag ; if ( oc - > oformat - > flags & AVFMT_GLOBALHEADER ) { audio_enc - > flags |= CODEC_FLAG_GLOBAL_HEADER ; } if ( audio_stream_copy ) { st - > stream_copy = 1 ; } else { audio_enc - > codec_id = codec_id ; set_context_opts ( audio_enc , avcodec_opts[AVMEDIA_TYPE_AUDIO] , AV_OPT_FLAG_AUDIO_PARAM | AV_OPT_FLAG_ENCODING_PARAM , codec ) ; if ( audio_qscale > QSCALE_NONE ) { audio_enc - > flags |= CODEC_FLAG_QSCALE ; audio_enc - > global_quality = FF_QP2LAMBDA * audio_qscale ; } if ( audio_channels ) audio_enc - > channels = audio_channels ; if ( audio_sample_fmt ! = AV_SAMPLE_FMT_NONE ) audio_enc - > sample_fmt = audio_sample_fmt ; if ( audio_sample_rate ) audio_enc - > sample_rate = audio_sample_rate ; } if ( audio_language ) { av_dict_set ( & st - > metadata , language , audio_language , 0 ) ; av_freep ( & audio_language ) ; } / * reset some key parameters * / audio_disable = 0 ; av_freep ( & audio_codec_name ) ; audio_stream_copy = 0 ; }",0
"inline static void RENAME ( hcscale ) ( uint16_t * dst , long dstWidth , uint8_t * src1 , uint8_t * src2 , int srcW , int xInc , int flags , int canMMX2BeUsed , int16_t * hChrFilter , int16_t * hChrFilterPos , int hChrFilterSize , void * funnyUVCode , int srcFormat , uint8_t * formatConvBuffer , int16_t * mmx2Filter , int32_t * mmx2FilterPos ) { if ( srcFormat==IMGFMT_YUY2 ) { RENAME ( yuy2ToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( srcFormat==IMGFMT_UYVY ) { RENAME ( uyvyToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( srcFormat==IMGFMT_BGR32 ) { RENAME ( bgr32ToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( srcFormat==IMGFMT_BGR24 ) { RENAME ( bgr24ToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( srcFormat==IMGFMT_BGR16 ) { RENAME ( bgr16ToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( srcFormat==IMGFMT_BGR15 ) { RENAME ( bgr15ToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( srcFormat==IMGFMT_RGB32 ) { RENAME ( rgb32ToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( srcFormat==IMGFMT_RGB24 ) { RENAME ( rgb24ToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( isGray ( srcFormat ) ) { return ; } ifdef HAVE_MMX // use the new MMX scaler if the mmx2 can ' t be used ( its faster than the x86asm one ) if ( ! ( flags & SWS_FAST_BILINEAR ) || ( ! canMMX2BeUsed ) ) else if ( ! ( flags & SWS_FAST_BILINEAR ) ) endif { RENAME ( hScale ) ( dst , dstWidth , src1 , srcW , xInc , hChrFilter , hChrFilterPos , hChrFilterSize ) ; RENAME ( hScale ) ( dst + 2048 , dstWidth , src2 , srcW , xInc , hChrFilter , hChrFilterPos , hChrFilterSize ) ; } else // Fast Bilinear upscale / crap downscale { if defined ( ARCH_X86 ) || defined ( ARCH_X86_64 ) ifdef HAVE_MMX2 int i ; if ( canMMX2BeUsed ) { asm volatile ( pxor %%mm7 , %%mm7 \n\t mov %0 , %% REG_c \n\t mov %1 , %% REG_D \n\t mov %2 , %% REG_d \n\t mov %3 , %% REG_b \n\t xor %% REG_a , %% REG_a \n\t // i PREFETCH ( %% REG_c ) \n\t PREFETCH 32 ( %% REG_c ) \n\t PREFETCH 64 ( %% REG_c ) \n\t ifdef ARCH_X86_64 define FUNNY_UV_CODE \ movl ( %% REG_b ) , %%esi \n\t \ call * %4 \n\t \ movl ( %% REG_b , %% REG_a ) , %%esi\n\t \ add %% REG_S , %% REG_c \n\t \ add %% REG_a , %% REG_D \n\t \ xor %% REG_a , %% REG_a \n\t \ else define FUNNY_UV_CODE \ movl ( %% REG_b ) , %%esi \n\t \ call * %4 \n\t \ addl ( %% REG_b , %% REG_a ) , %% REG_c \n\t \ add %% REG_a , %% REG_D \n\t \ xor %% REG_a , %% REG_a \n\t \ endif FUNNY_UV_CODE FUNNY_UV_CODE FUNNY_UV_CODE FUNNY_UV_CODE xor %% REG_a , %% REG_a \n\t // i mov %5 , %% REG_c \n\t // src mov %1 , %% REG_D \n\t // buf1 add 4096 , %% REG_D \n\t PREFETCH ( %% REG_c ) \n\t PREFETCH 32 ( %% REG_c ) \n\t PREFETCH 64 ( %% REG_c ) \n\t FUNNY_UV_CODE FUNNY_UV_CODE FUNNY_UV_CODE FUNNY_UV_CODE : : m ( src1 ) , m ( dst ) , m ( mmx2Filter ) , m ( mmx2FilterPos ) , m ( funnyUVCode ) , m ( src2 ) : % REG_a , % REG_b , % REG_c , % REG_d , % REG_S , % REG_D ) ; for ( i=dstWidth - 1 ; ( i * xInc ) > > 16 > =srcW - 1 ; i - - ) { // printf ( %d %d %d\n , dstWidth , i , srcW ) ; dst[i] = src1[srcW - 1] * 128 ; dst[i + 2048] = src2[srcW - 1] * 128 ; } } else { endif long xInc_shr16 = ( long ) ( xInc > > 16 ) ; uint16_t xInc_mask = xInc & 0xffff ; asm volatile ( xor %% REG_a , %% REG_a \n\t // i xor %% REG_b , %% REG_b \n\t // xx xorl %%ecx , %%ecx \n\t // 2 * xalpha ASMALIGN16 1 : \n\t mov %0 , %% REG_S \n\t movzbl ( %% REG_S , %% REG_b ) , %%edi \n\t //src[xx] movzbl 1 ( %% REG_S , %% REG_b ) , %%esi \n\t //src[xx + 1] subl %%edi , %%esi \n\t //src[xx + 1] - src[xx] imull %%ecx , %%esi \n\t // ( src[xx + 1] - src[xx] ) * 2 * xalpha shll 16 , %%edi \n\t addl %%edi , %%esi \n\t //src[xx + 1] * 2 * xalpha + src[xx] * ( 1 - 2 * xalpha ) mov %1 , %% REG_D \n\t shrl 9 , %%esi \n\t movw %%si , ( %% REG_D , %% REG_a , 2 ) \n\t movzbl ( %5 , %% REG_b ) , %%edi \n\t //src[xx] movzbl 1 ( %5 , %% REG_b ) , %%esi \n\t //src[xx + 1] subl %%edi , %%esi \n\t //src[xx + 1] - src[xx] imull %%ecx , %%esi \n\t // ( src[xx + 1] - src[xx] ) * 2 * xalpha shll 16 , %%edi \n\t addl %%edi , %%esi \n\t //src[xx + 1] * 2 * xalpha + src[xx] * ( 1 - 2 * xalpha ) mov %1 , %% REG_D \n\t shrl 9 , %%esi \n\t movw %%si , 4096 ( %% REG_D , %% REG_a , 2 ) \n\t addw %4 , %%cx \n\t //2 * xalpha + = xInc & 0xFF adc %3 , %% REG_b \n\t //xx + = xInc > > 8 + carry add 1 , %% REG_a \n\t cmp %2 , %% REG_a \n\t jb 1b \n\t / * GCC - 3 . 3 makes MPlayer crash on IA - 32 machines when using g operand here , which is needed to support GCC - 4 . 0 * / if defined ( ARCH_X86_64 ) & & ( ( __GNUC__ > 3 ) || ( __GNUC__ == 3 & & __GNUC_MINOR__ > = 4 ) ) : : m ( src1 ) , m ( dst ) , g ( ( long ) dstWidth ) , m ( xInc_shr16 ) , m ( xInc_mask",0
"int attribute_align_arg avcodec_decode_audio3 ( AVCodecContext * avctx , int16_t * samples , int * frame_size_ptr , AVPacket * avpkt ) { AVFrame frame = { 0 } ; int ret , got_frame = 0 ; if ( avctx - > get_buffer ! = avcodec_default_get_buffer ) { av_log ( avctx , AV_LOG_ERROR , Custom get_buffer ( ) for use with avcodec_decode_audio3 ( ) detected . Overriding with avcodec_default_get_buffer\n ) ; av_log ( avctx , AV_LOG_ERROR , Please port your application to avcodec_decode_audio4 ( ) \n ) ; avctx - > get_buffer = avcodec_default_get_buffer ; } ret = avcodec_decode_audio4 ( avctx , & frame , & got_frame , avpkt ) ; if ( ret > = 0 & & got_frame ) { int ch , plane_size ; int planar = av_sample_fmt_is_planar ( avctx - > sample_fmt ) ; int data_size = av_samples_get_buffer_size ( & plane_size , avctx - > channels , frame . nb_samples , avctx - > sample_fmt , 1 ) ; if ( * frame_size_ptr < data_size ) { av_log ( avctx , AV_LOG_ERROR , output buffer size is too small for the current frame ( %d < %d ) \n , * frame_size_ptr , data_size ) ; return AVERROR ( EINVAL ) ; } memcpy ( samples , frame . extended_data[0] , plane_size ) ; if ( planar & & avctx - > channels > 1 ) { uint8_t * out = ( ( uint8_t * ) samples ) + plane_size ; for ( ch = 1 ; ch < avctx - > channels ; ch + + ) { memcpy ( out , frame . extended_data[ch] , plane_size ) ; out + = plane_size ; } } * frame_size_ptr = data_size ; } else { * frame_size_ptr = 0 ; } return ret ; }",1
"static int ape_read_header ( AVFormatContext * s ) { AVIOContext * pb = s - > pb ; APEContext * ape = s - > priv_data ; AVStream * st ; uint32_t tag ; int i ; int total_blocks , final_size = 0 ; int64_t pts , file_size ; / * Skip any leading junk such as id3v2 tags * / ape - > junklength = avio_tell ( pb ) ; tag = avio_rl32 ( pb ) ; if ( tag ! = MKTAG ( ' M ' , ' A ' , ' C ' , ' ' ) ) return AVERROR_INVALIDDATA ; ape - > fileversion = avio_rl16 ( pb ) ; if ( ape - > fileversion < APE_MIN_VERSION || ape - > fileversion > APE_MAX_VERSION ) { av_log ( s , AV_LOG_ERROR , Unsupported file version - %d . %02d\n , ape - > fileversion / 1000 , ( ape - > fileversion % 1000 ) / 10 ) ; return AVERROR_PATCHWELCOME ; } if ( ape - > fileversion > = 3980 ) { ape - > padding1 = avio_rl16 ( pb ) ; ape - > descriptorlength = avio_rl32 ( pb ) ; ape - > headerlength = avio_rl32 ( pb ) ; ape - > seektablelength = avio_rl32 ( pb ) ; ape - > wavheaderlength = avio_rl32 ( pb ) ; ape - > audiodatalength = avio_rl32 ( pb ) ; ape - > audiodatalength_high = avio_rl32 ( pb ) ; ape - > wavtaillength = avio_rl32 ( pb ) ; avio_read ( pb , ape - > md5 , 16 ) ; / * Skip any unknown bytes at the end of the descriptor . This is for future compatibility * / if ( ape - > descriptorlength > 52 ) avio_skip ( pb , ape - > descriptorlength - 52 ) ; / * Read header data * / ape - > compressiontype = avio_rl16 ( pb ) ; ape - > formatflags = avio_rl16 ( pb ) ; ape - > blocksperframe = avio_rl32 ( pb ) ; ape - > finalframeblocks = avio_rl32 ( pb ) ; ape - > totalframes = avio_rl32 ( pb ) ; ape - > bps = avio_rl16 ( pb ) ; ape - > channels = avio_rl16 ( pb ) ; ape - > samplerate = avio_rl32 ( pb ) ; } else { ape - > descriptorlength = 0 ; ape - > headerlength = 32 ; ape - > compressiontype = avio_rl16 ( pb ) ; ape - > formatflags = avio_rl16 ( pb ) ; ape - > channels = avio_rl16 ( pb ) ; ape - > samplerate = avio_rl32 ( pb ) ; ape - > wavheaderlength = avio_rl32 ( pb ) ; ape - > wavtaillength = avio_rl32 ( pb ) ; ape - > totalframes = avio_rl32 ( pb ) ; ape - > finalframeblocks = avio_rl32 ( pb ) ; if ( ape - > formatflags & MAC_FORMAT_FLAG_HAS_PEAK_LEVEL ) { avio_skip ( pb , 4 ) ; / * Skip the peak level * / ape - > headerlength + = 4 ; } if ( ape - > formatflags & MAC_FORMAT_FLAG_HAS_SEEK_ELEMENTS ) { ape - > seektablelength = avio_rl32 ( pb ) ; ape - > headerlength + = 4 ; ape - > seektablelength * = sizeof ( int32_t ) ; } else ape - > seektablelength = ape - > totalframes * sizeof ( int32_t ) ; if ( ape - > formatflags & MAC_FORMAT_FLAG_8_BIT ) ape - > bps = 8 ; else if ( ape - > formatflags & MAC_FORMAT_FLAG_24_BIT ) ape - > bps = 24 ; else ape - > bps = 16 ; if ( ape - > fileversion > = 3950 ) ape - > blocksperframe = 73728 * 4 ; else if ( ape - > fileversion > = 3900 || ( ape - > fileversion > = 3800 & & ape - > compressiontype > = 4000 ) ) ape - > blocksperframe = 73728 ; else ape - > blocksperframe = 9216 ; / * Skip any stored wav header * / if ( ! ( ape - > formatflags & MAC_FORMAT_FLAG_CREATE_WAV_HEADER ) ) avio_skip ( pb , ape - > wavheaderlength ) ; } if ( ! ape - > totalframes ) { av_log ( s , AV_LOG_ERROR , No frames in the file ! \n ) ; return AVERROR ( EINVAL ) ; } if ( ape - > totalframes > UINT_MAX / sizeof ( APEFrame ) ) { av_log ( s , AV_LOG_ERROR , Too many frames : % PRIu32 \n , ape - > totalframes ) ; return AVERROR_INVALIDDATA ; } if ( ape - > seektablelength / sizeof ( * ape - > seektable ) < ape - > totalframes ) { av_log ( s , AV_LOG_ERROR , Number of seek entries is less than number of frames : %zu vs . % PRIu32 \n , ape - > seektablelength / sizeof ( * ape - > seektable ) , ape - > totalframes ) ; return AVERROR_INVALIDDATA ; } ape - > frames = av_malloc ( ape - > totalframes * sizeof ( APEFrame ) ) ; if ( ! ape - > frames ) return AVERROR ( ENOMEM ) ; ape - > firstframe = ape - > junklength + ape - > descriptorlength + ape - > headerlength + ape - > seektablelength + ape - > wavheaderlength ; if ( ape - > fileversion < 3810 ) ape - > firstframe + = ape - > totalframes ; ape - > currentframe = 0 ; ape - > totalsamples = ape - > finalframeblocks ; if ( ape - > totalframes > 1 ) ape - > totalsamples + = ape - > blocksperframe * ( ape - > totalframes - 1 ) ; if ( ape - > seektablelength > 0 ) { ape - > seektable = av_malloc ( ape - > seektablelength ) ; if ( ! ape - > seektable ) return AVERROR ( ENOMEM ) ; for ( i = 0 ; i < ape - > seektablelength / sizeof ( uint32_t ) & & ! pb - > eof_reached ; i + + ) ape - > seektable[i] = avio_rl32 ( pb ) ; if ( ape - > fileversion < 3810 ) { ape - > bittable = av_malloc ( ape - > totalframes ) ; if ( ! ape - > bittable ) return AVERROR ( ENOMEM ) ; for ( i = 0 ; i < ape - > totalframes & & ! pb - > eof_reached ; i + + ) ape - > bittable[i] = avio_r8 ( pb ) ; } } ape - > frames[0] . pos = ape - > firstframe ; ape - > frames[0] . nblocks = ape - > blocksperframe ; ape - > frames[0] . skip = 0 ; for ( i = 1 ; i < ape - > totalframes ; i + + ) { ape - > frames[i] . pos = ape -",1
"int ff_vdpau_common_init ( AVCodecContext * avctx , VdpDecoderProfile profile , int level ) { VDPAUHWContext * hwctx = avctx - > hwaccel_context ; VDPAUContext * vdctx = avctx - > internal - > hwaccel_priv_data ; VdpVideoSurfaceQueryCapabilities * surface_query_caps ; VdpDecoderQueryCapabilities * decoder_query_caps ; VdpDecoderCreate * create ; void * func ; VdpStatus status ; VdpBool supported ; uint32_t max_level , max_mb , max_width , max_height ; VdpChromaType type ; uint32_t width ; uint32_t height ; vdctx - > width = UINT32_MAX ; vdctx - > height = UINT32_MAX ; if ( av_vdpau_get_surface_parameters ( avctx , & type , & width , & height ) ) return AVERROR ( ENOSYS ) ; if ( hwctx ) { hwctx - > reset = 0 ; if ( hwctx - > context . decoder ! = VDP_INVALID_HANDLE ) { vdctx - > decoder = hwctx - > context . decoder ; vdctx - > render = hwctx - > context . render ; vdctx - > device = VDP_INVALID_HANDLE ; return 0 ; / * Decoder created by user * / } vdctx - > device = hwctx - > device ; vdctx - > get_proc_address = hwctx - > get_proc_address ; if ( hwctx - > flags & AV_HWACCEL_FLAG_IGNORE_LEVEL ) level = 0 ; if ( ! ( hwctx - > flags & AV_HWACCEL_FLAG_ALLOW_HIGH_DEPTH ) & & type ! = VDP_CHROMA_TYPE_420 ) return AVERROR ( ENOSYS ) ; } else { AVHWFramesContext * frames_ctx = NULL ; AVVDPAUDeviceContext * dev_ctx ; // We assume the hw_frames_ctx always survives until ff_vdpau_common_uninit // is called . This holds true as the user is not allowed to touch // hw_device_ctx , or hw_frames_ctx after get_format ( and ff_get_format // itself also uninits before unreffing hw_frames_ctx ) . if ( avctx - > hw_frames_ctx ) { frames_ctx = ( AVHWFramesContext * ) avctx - > hw_frames_ctx - > data ; } else if ( avctx - > hw_device_ctx ) { int ret ; avctx - > hw_frames_ctx = av_hwframe_ctx_alloc ( avctx - > hw_device_ctx ) ; if ( ! avctx - > hw_frames_ctx ) return AVERROR ( ENOMEM ) ; frames_ctx = ( AVHWFramesContext * ) avctx - > hw_frames_ctx - > data ; frames_ctx - > format = AV_PIX_FMT_VDPAU ; frames_ctx - > sw_format = avctx - > sw_pix_fmt ; frames_ctx - > width = avctx - > coded_width ; frames_ctx - > height = avctx - > coded_height ; ret = av_hwframe_ctx_init ( avctx - > hw_frames_ctx ) ; if ( ret < 0 ) { av_buffer_unref ( & avctx - > hw_frames_ctx ) ; return ret ; } } if ( ! frames_ctx ) { av_log ( avctx , AV_LOG_ERROR , A hardware frames context is required for VDPAU decoding . \n ) ; return AVERROR ( EINVAL ) ; } dev_ctx = frames_ctx - > device_ctx - > hwctx ; vdctx - > device = dev_ctx - > device ; vdctx - > get_proc_address = dev_ctx - > get_proc_address ; if ( avctx - > hwaccel_flags & AV_HWACCEL_FLAG_IGNORE_LEVEL ) level = 0 ; } if ( level < 0 ) return AVERROR ( ENOTSUP ) ; status = vdctx - > get_proc_address ( vdctx - > device , VDP_FUNC_ID_GET_INFORMATION_STRING , & func ) ; if ( status ! = VDP_STATUS_OK ) return vdpau_error ( status ) ; else info = func ; status = info ( & info_string ) ; if ( status ! = VDP_STATUS_OK ) return vdpau_error ( status ) ; if ( avctx - > codec_id == AV_CODEC_ID_HEVC & & strncmp ( info_string , NVIDIA , 7 ) == 0 & & ! ( avctx - > hwaccel_flags & AV_HWACCEL_FLAG_ALLOW_PROFILE_MISMATCH ) ) { av_log ( avctx , AV_LOG_VERBOSE , HEVC with NVIDIA VDPAU drivers is buggy , skipping . \n ) ; return AVERROR ( ENOTSUP ) ; } status = vdctx - > get_proc_address ( vdctx - > device , VDP_FUNC_ID_VIDEO_SURFACE_QUERY_CAPABILITIES , & func ) ; if ( status ! = VDP_STATUS_OK ) return vdpau_error ( status ) ; else surface_query_caps = func ; status = surface_query_caps ( vdctx - > device , type , & supported , & max_width , & max_height ) ; if ( status ! = VDP_STATUS_OK ) return vdpau_error ( status ) ; if ( supported ! = VDP_TRUE || max_width < width || max_height < height ) return AVERROR ( ENOTSUP ) ; status = vdctx - > get_proc_address ( vdctx - > device , VDP_FUNC_ID_DECODER_QUERY_CAPABILITIES , & func ) ; if ( status ! = VDP_STATUS_OK ) return vdpau_error ( status ) ; else decoder_query_caps = func ; status = decoder_query_caps ( vdctx - > device , profile , & supported , & max_level , & max_mb , & max_width , & max_height ) ; ifdef VDP_DECODER_PROFILE_H264_CONSTRAINED_BASELINE if ( ( status ! = VDP_STATUS_OK || supported ! = VDP_TRUE ) & & profile == VDP_DECODER_PROFILE_H264_CONSTRAINED_BASELINE ) { profile = VDP_DECODER_PROFILE_H264_MAIN ; status = decoder_query_caps ( vdctx - > device , profile , & supported , & max_level , & max_mb , & max_width , & max_height ) ; } endif if ( status ! = VDP_STATUS_OK ) return vdpau_error ( status ) ; if ( supported ! = VDP_TRUE || max_level < level || max_width < width || max_height < height ) return AVERROR ( ENOTSUP ) ; status = vdctx - > get_proc_address ( vdctx - > device , VDP_FUNC_ID_DECODER_CREATE , & func ) ; if ( status ! = VDP_STATUS_OK ) return vdpau_error ( status ) ; else create = func ; status = vdctx - > get_proc_address ( vdctx - > device , VDP_FUNC_ID_DECODER_RENDER , & func ) ; if ( status ! = VDP_STATUS_OK ) return vdpau_error ( status ) ; else vdctx - > render = func ; status = create ( vdctx - > device , profile , width , height , avctx - > refs , & vdctx - > decoder ) ; if ( status == VDP_STATUS_OK ) { vdctx - > width = avctx - > coded_width ; vdctx - > height = avctx - > coded_height ; } return vdpau_error ( status ) ; }",1
"static void dequantization_int_97 ( int x , int y , Jpeg2000Cblk * cblk , Jpeg2000Component * comp , Jpeg2000T1Context * t1 , Jpeg2000Band * band ) { int i , j ; int w = cblk - > coord[0][1] - cblk - > coord[0][0] ; for ( j = 0 ; j < ( cblk - > coord[1][1] - cblk - > coord[1][0] ) ; + + j ) { int32_t * datap = & comp - > i_data[ ( comp - > coord[0][1] - comp - > coord[0][0] ) * ( y + j ) + x] ; int * src = t1 - > data[j] ; for ( i = 0 ; i < w ; + + i ) datap[i] = ( src[i] * band - > i_stepsize + ( 1 < < 14 ) ) > > 15 ; } }",1
"static int idcin_probe ( AVProbeData * p ) { unsigned int number , sample_rate ; / * * This is what you could call a probabilistic file check : id CIN * files don ' t have a definite file signature . In lieu of such a marker , * perform sanity checks on the 5 32 - bit header fields : * width , height : greater than 0 , less than or equal to 1024 * audio sample rate : greater than or equal to 8000 , less than or * equal to 48000 , or 0 for no audio * audio sample width ( bytes/sample ) : 0 for no audio , or 1 or 2 * audio channels : 0 for no audio , or 1 or 2 * / / * check we have enough data to do all checks , otherwise the 0 - padding may cause a wrong recognition * / if ( p - > buf_size < 20 ) return 0 ; / * check the video width * / number = AV_RL32 ( & p - > buf[0] ) ; if ( ( number == 0 ) || ( number > 1024 ) ) return 0 ; / * check the video height * / number = AV_RL32 ( & p - > buf[4] ) ; if ( ( number == 0 ) || ( number > 1024 ) ) return 0 ; / * check the audio sample rate * / sample_rate = AV_RL32 ( & p - > buf[8] ) ; if ( sample_rate & & ( sample_rate < 8000 || sample_rate > 48000 ) ) return 0 ; / * check the audio bytes/sample * / number = AV_RL32 ( & p - > buf[12] ) ; if ( number > 2 || sample_rate & & ! number ) return 0 ; / * check the audio channels * / number = AV_RL32 ( & p - > buf[16] ) ; if ( number > 2 || sample_rate & & ! number ) return 0 ; / * return half certainty since this check is a bit sketchy * / return AVPROBE_SCORE_EXTENSION ; }",1
"yuv2rgb_full_1_c_template ( SwsContext * c , const int16_t * buf0 , const int16_t * ubuf[2] , const int16_t * vbuf[2] , const int16_t * abuf0 , uint8_t * dest , int dstW , int uvalpha , int y , enum AVPixelFormat target , int hasAlpha ) { const int16_t * ubuf0 = ubuf[0] , * vbuf0 = vbuf[0] ; int i ; int step = ( target == AV_PIX_FMT_RGB24 || target == AV_PIX_FMT_BGR24 ) ? 3 : 4 ; int err[4] = { 0 } ; if ( target == AV_PIX_FMT_BGR4_BYTE || target == AV_PIX_FMT_RGB4_BYTE || target == AV_PIX_FMT_BGR8 || target == AV_PIX_FMT_RGB8 ) step = 1 ; if ( uvalpha < 2048 ) { int A = 0 ; //init to silence warning for ( i = 0 ; i < dstW ; i + + ) { int Y = buf0[i] < < 2 ; int U = ( ubuf0[i] - ( 128 < < 7 ) ) < < 2 ; int V = ( vbuf0[i] - ( 128 < < 7 ) ) < < 2 ; if ( hasAlpha ) { A = ( abuf0[i] + 64 ) > > 7 ; if ( A & 0x100 ) A = av_clip_uint8 ( A ) ; } yuv2rgb_write_full ( c , dest , i , Y , A , U , V , y , target , hasAlpha , err ) ; dest + = step ; } } else { const int16_t * ubuf1 = ubuf[1] , * vbuf1 = vbuf[1] ; int A = 0 ; //init to silence warning for ( i = 0 ; i < dstW ; i + + ) { int Y = buf0[i] < < 2 ; int U = ( ubuf0[i] + ubuf1[i] - ( 128 < < 8 ) ) < < 1 ; int V = ( vbuf0[i] + vbuf1[i] - ( 128 < < 8 ) ) < < 1 ; if ( hasAlpha ) { A = ( abuf0[i] + 64 ) > > 7 ; if ( A & 0x100 ) A = av_clip_uint8 ( A ) ; } yuv2rgb_write_full ( c , dest , i , Y , A , U , V , y , target , hasAlpha , err ) ; dest + = step ; } } c - > dither_error[0][i] = err[0] ; c - > dither_error[1][i] = err[1] ; c - > dither_error[2][i] = err[2] ; }",0
"static inline int hpel_motion ( MpegEncContext * s , uint8_t * dest , uint8_t * src , int src_x , int src_y , op_pixels_func * pix_op , int motion_x , int motion_y ) { int dxy = 0 ; int emu = 0 ; src_x + = motion_x > > 1 ; src_y + = motion_y > > 1 ; / * WARNING : do no forget half pels * / src_x = av_clip ( src_x , - 16 , s - > width ) ; // FIXME unneeded for emu ? if ( src_x ! = s - > width ) dxy |= motion_x & 1 ; src_y = av_clip ( src_y , - 16 , s - > height ) ; if ( src_y ! = s - > height ) dxy |= ( motion_y & 1 ) < < 1 ; src + = src_y * s - > linesize + src_x ; if ( ( unsigned ) src_x > FFMAX ( s - > h_edge_pos - ( motion_x & 1 ) - 8 , 0 ) || ( unsigned ) src_y > FFMAX ( s - > v_edge_pos - ( motion_y & 1 ) - 8 , 0 ) ) { s - > vdsp . emulated_edge_mc ( s - > edge_emu_buffer , src , s - > linesize , s - > linesize , 9 , 9 , src_x , src_y , s - > h_edge_pos , s - > v_edge_pos ) ; src = s - > edge_emu_buffer ; emu = 1 ; } pix_op[dxy] ( dest , src , s - > linesize , 8 ) ; return emu ; }",0
static inline void downmix_dualmono_to_mono ( float * samples ) { int i ; for ( i = 0 ; i < 256 ; i + + ) { samples[i] + = samples[i + 256] ; samples[i + 256] = 0 ; } },0
static int film_read_close ( AVFormatContext * s ) { FilmDemuxContext * film = s - > priv_data ; av_free ( film - > sample_table ) ; av_free ( film - > stereo_buffer ) ; return 0 ; },1
"void Process ( void * ctx , AVPicture * picture , enum PixelFormat pix_fmt , int width , int height , int64_t pts ) { int err = 0 ; ContextInfo * ci = ( ContextInfo * ) ctx ; AVPicture picture1 ; AVPicture picture2 ; AVPicture * pict = picture ; int out_width ; int out_height ; int i ; uint8_t * ptr = NULL ; FILE * in = rwpipe_reader ( ci - > rw ) ; FILE * out = rwpipe_writer ( ci - > rw ) ; / * Check that we have a pipe to talk to . * / if ( in == NULL || out == NULL ) err = 1 ; / * Convert to RGB24 if necessary * / if ( ! err & & pix_fmt ! = PIX_FMT_RGB24 ) { int size = avpicture_get_size ( PIX_FMT_RGB24 , width , height ) ; if ( size ! = ci - > size1 ) { av_free ( ci - > buf1 ) ; ci - > buf1 = av_malloc ( size ) ; ci - > size1 = size ; err = ci - > buf1 == NULL ; } if ( ! err ) { avpicture_fill ( & picture1 , ci - > buf1 , PIX_FMT_RGB24 , width , height ) ; // if we already got a SWS context , let ' s realloc if is not re - useable ci - > toRGB_convert_ctx = sws_getCachedContext ( ci - > toRGB_convert_ctx , width , height , pix_fmt , width , height , PIX_FMT_RGB24 , sws_flags , NULL , NULL , NULL ) ; if ( ci - > toRGB_convert_ctx == NULL ) { av_log ( NULL , AV_LOG_ERROR , Cannot initialize the toRGB conversion context\n ) ; return ; } // img_convert parameters are 2 first destination , then 4 source // sws_scale parameters are context , 4 first source , then 2 destination sws_scale ( ci - > toRGB_convert_ctx , picture - > data , picture - > linesize , 0 , height , picture1 . data , picture1 . linesize ) ; pict = & picture1 ; } } / * Write out the PPM * / if ( ! err ) { ptr = pict - > data[ 0 ] ; fprintf ( out , P6\n%d %d\n255\n , width , height ) ; for ( i = 0 ; ! err & & i < height ; i + + ) { err = ! fwrite ( ptr , width * 3 , 1 , out ) ; ptr + = pict - > linesize[ 0 ] ; } if ( ! err ) err = fflush ( out ) ; } / * Read the PPM returned . * / if ( ! err & & ! rwpipe_read_ppm_header ( ci - > rw , & out_width , & out_height ) ) { int size = avpicture_get_size ( PIX_FMT_RGB24 , out_width , out_height ) ; if ( size ! = ci - > size2 ) { av_free ( ci - > buf2 ) ; ci - > buf2 = av_malloc ( size ) ; ci - > size2 = size ; err = ci - > buf2 == NULL ; } if ( ! err ) { avpicture_fill ( & picture2 , ci - > buf2 , PIX_FMT_RGB24 , out_width , out_height ) ; ptr = picture2 . data[ 0 ] ; for ( i = 0 ; ! err & & i < out_height ; i + + ) { err = ! fread ( ptr , out_width * 3 , 1 , in ) ; ptr + = picture2 . linesize[ 0 ] ; } } } / * Convert the returned PPM back to the input format * / if ( ! err ) { / * The out_width/out_height returned from the PPM * filter won ' t necessarily be the same as width and height * but it will be scaled anyway to width/height . * / av_log ( NULL , AV_LOG_DEBUG , PPM vhook : Input dimensions : %d x %d Output dimensions : %d x %d\n , width , height , out_width , out_height ) ; ci - > fromRGB_convert_ctx = sws_getCachedContext ( ci - > fromRGB_convert_ctx , out_width , out_height , PIX_FMT_RGB24 , width , height , pix_fmt , sws_flags , NULL , NULL , NULL ) ; if ( ci - > fromRGB_convert_ctx == NULL ) { av_log ( NULL , AV_LOG_ERROR , Cannot initialize the fromRGB conversion context\n ) ; return ; } // img_convert parameters are 2 first destination , then 4 source // sws_scale parameters are context , 4 first source , then 2 destination sws_scale ( ci - > fromRGB_convert_ctx , picture2 . data , picture2 . linesize , 0 , out_height , picture - > data , picture - > linesize ) ; } }",1
"static av_cold int libschroedinger_decode_init ( AVCodecContext * avctx ) { SchroDecoderParams * p_schro_params = avctx - > priv_data ; / * First of all , initialize our supporting libraries . * / schro_init ( ) ; schro_debug_set_level ( avctx - > debug ) ; p_schro_params - > decoder = schro_decoder_new ( ) ; schro_decoder_set_skip_ratio ( p_schro_params - > decoder , 1 ) ; if ( ! p_schro_params - > decoder ) return - 1 ; / * Initialize the decoded frame queue . * / ff_schro_queue_init ( & p_schro_params - > dec_frame_queue ) ; return 0 ; }",1
"static void update_stream_timings ( AVFormatContext * ic ) { int64_t start_time , start_time1 , start_time_text , end_time , end_time1 ; int64_t duration , duration1 , filesize ; int i ; AVStream * st ; AVProgram * p ; start_time = INT64_MAX ; start_time_text = INT64_MAX ; end_time = INT64_MIN ; duration = INT64_MIN ; for ( i = 0 ; i < ic - > nb_streams ; i + + ) { st = ic - > streams[i] ; if ( st - > start_time ! = AV_NOPTS_VALUE & & st - > time_base . den ) { start_time1= av_rescale_q ( st - > start_time , st - > time_base , AV_TIME_BASE_Q ) ; if ( st - > codec - > codec_type == AVMEDIA_TYPE_SUBTITLE || st - > codec - > codec_type == AVMEDIA_TYPE_DATA ) { if ( start_time1 < start_time_text ) start_time_text = start_time1 ; } else start_time = FFMIN ( start_time , start_time1 ) ; end_time1 = AV_NOPTS_VALUE ; if ( st - > duration ! = AV_NOPTS_VALUE ) { end_time1 = start_time1 + av_rescale_q ( st - > duration , st - > time_base , AV_TIME_BASE_Q ) ; end_time = FFMAX ( end_time , end_time1 ) ; } for ( p = NULL ; ( p = av_find_program_from_stream ( ic , p , i ) ) ; ) { if ( p - > start_time == AV_NOPTS_VALUE || p - > start_time > start_time1 ) p - > start_time = start_time1 ; if ( p - > end_time < end_time1 ) p - > end_time = end_time1 ; } } if ( st - > duration ! = AV_NOPTS_VALUE ) { duration1 = av_rescale_q ( st - > duration , st - > time_base , AV_TIME_BASE_Q ) ; duration = FFMAX ( duration , duration1 ) ; } } if ( start_time == INT64_MAX || ( start_time > start_time_text & & start_time - start_time_text < AV_TIME_BASE ) ) start_time = start_time_text ; else if ( start_time > start_time_text ) av_log ( ic , AV_LOG_VERBOSE , Ignoring outlier non primary stream starttime %f\n , start_time_text / ( float ) AV_TIME_BASE ) ; if ( start_time ! = INT64_MAX ) { ic - > start_time = start_time ; if ( end_time ! = INT64_MIN ) { if ( ic - > nb_programs ) { for ( i=0 ; i < ic - > nb_programs ; i + + ) { p = ic - > programs[i] ; if ( p - > start_time ! = AV_NOPTS_VALUE & & p - > end_time > p - > start_time ) duration = FFMAX ( duration , p - > end_time - p - > start_time ) ; } } else duration = FFMAX ( duration , end_time - start_time ) ; } } if ( duration ! = INT64_MIN & & duration > 0 & & ic - > duration == AV_NOPTS_VALUE ) { ic - > duration = duration ; } if ( ic - > pb & & ( filesize = avio_size ( ic - > pb ) ) > 0 & & ic - > duration ! = AV_NOPTS_VALUE ) { / * compute the bitrate * / ic - > bit_rate = ( double ) filesize * 8 . 0 * AV_TIME_BASE / ( double ) ic - > duration ; } }",1
"static int decode_frame_header ( VP8Context * s , const uint8_t * buf , int buf_size ) { VP56RangeCoder * c = & s - > c ; int header_size , hscale , vscale , i , j , k , l , m , ret ; int width = s - > avctx - > width ; int height = s - > avctx - > height ; s - > keyframe = ! ( buf[0] & 1 ) ; s - > profile = ( buf[0] > > 1 ) & 7 ; s - > invisible = ! ( buf[0] & 0x10 ) ; header_size = AV_RL24 ( buf ) > > 5 ; buf + = 3 ; buf_size - = 3 ; if ( s - > profile > 3 ) av_log ( s - > avctx , AV_LOG_WARNING , Unknown profile %d\n , s - > profile ) ; if ( ! s - > profile ) memcpy ( s - > put_pixels_tab , s - > vp8dsp . put_vp8_epel_pixels_tab , sizeof ( s - > put_pixels_tab ) ) ; else // profile 1 - 3 use bilinear , 4 + aren ' t defined so whatever memcpy ( s - > put_pixels_tab , s - > vp8dsp . put_vp8_bilinear_pixels_tab , sizeof ( s - > put_pixels_tab ) ) ; if ( header_size > buf_size - 7 * s - > keyframe ) { av_log ( s - > avctx , AV_LOG_ERROR , Header size larger than data provided\n ) ; return AVERROR_INVALIDDATA ; } if ( s - > keyframe ) { if ( AV_RL24 ( buf ) ! = 0x2a019d ) { av_log ( s - > avctx , AV_LOG_ERROR , Invalid start code 0x%x\n , AV_RL24 ( buf ) ) ; return AVERROR_INVALIDDATA ; } width = AV_RL16 ( buf + 3 ) & 0x3fff ; height = AV_RL16 ( buf + 5 ) & 0x3fff ; hscale = buf[4] > > 6 ; vscale = buf[6] > > 6 ; buf + = 7 ; buf_size - = 7 ; if ( hscale || vscale ) av_log_missing_feature ( s - > avctx , Upscaling , 1 ) ; s - > update_golden = s - > update_altref = VP56_FRAME_CURRENT ; for ( i = 0 ; i < 4 ; i + + ) for ( j = 0 ; j < 16 ; j + + ) memcpy ( s - > prob - > token[i][j] , vp8_token_default_probs[i][vp8_coeff_band[j]] , sizeof ( s - > prob - > token[i][j] ) ) ; memcpy ( s - > prob - > pred16x16 , vp8_pred16x16_prob_inter , sizeof ( s - > prob - > pred16x16 ) ) ; memcpy ( s - > prob - > pred8x8c , vp8_pred8x8c_prob_inter , sizeof ( s - > prob - > pred8x8c ) ) ; memcpy ( s - > prob - > mvc , vp8_mv_default_prob , sizeof ( s - > prob - > mvc ) ) ; memset ( & s - > segmentation , 0 , sizeof ( s - > segmentation ) ) ; } if ( ! s - > macroblocks_base || / * first frame * / width ! = s - > avctx - > width || height ! = s - > avctx - > height ) { if ( ( ret = update_dimensions ( s , width , height ) ) < 0 ) return ret ; } ff_vp56_init_range_decoder ( c , buf , header_size ) ; buf + = header_size ; buf_size - = header_size ; if ( s - > keyframe ) { if ( vp8_rac_get ( c ) ) av_log ( s - > avctx , AV_LOG_WARNING , Unspecified colorspace\n ) ; vp8_rac_get ( c ) ; // whether we can skip clamping in dsp functions } if ( ( s - > segmentation . enabled = vp8_rac_get ( c ) ) ) parse_segment_info ( s ) ; else s - > segmentation . update_map = 0 ; // FIXME : move this to some init function ? s - > filter . simple = vp8_rac_get ( c ) ; s - > filter . level = vp8_rac_get_uint ( c , 6 ) ; s - > filter . sharpness = vp8_rac_get_uint ( c , 3 ) ; if ( ( s - > lf_delta . enabled = vp8_rac_get ( c ) ) ) if ( vp8_rac_get ( c ) ) update_lf_deltas ( s ) ; if ( setup_partitions ( s , buf , buf_size ) ) { av_log ( s - > avctx , AV_LOG_ERROR , Invalid partitions\n ) ; return AVERROR_INVALIDDATA ; } get_quants ( s ) ; if ( ! s - > keyframe ) { update_refs ( s ) ; s - > sign_bias[VP56_FRAME_GOLDEN] = vp8_rac_get ( c ) ; s - > sign_bias[VP56_FRAME_GOLDEN2 / * altref * / ] = vp8_rac_get ( c ) ; } // if we aren ' t saving this frame ' s probabilities for future frames , // make a copy of the current probabilities if ( ! ( s - > update_probabilities = vp8_rac_get ( c ) ) ) s - > prob[1] = s - > prob[0] ; s - > update_last = s - > keyframe || vp8_rac_get ( c ) ; for ( i = 0 ; i < 4 ; i + + ) for ( j = 0 ; j < 8 ; j + + ) for ( k = 0 ; k < 3 ; k + + ) for ( l = 0 ; l < NUM_DCT_TOKENS - 1 ; l + + ) if ( vp56_rac_get_prob_branchy ( c , vp8_token_update_probs[i][j][k][l] ) ) { int prob = vp8_rac_get_uint ( c , 8 ) ; for ( m = 0 ; vp8_coeff_band_indexes[j][m] > = 0 ; m + + ) s - > prob - > token[i][vp8_coeff_band_indexes[j][m]][k][l] = prob ; } if ( ( s - > mbskip_enabled = vp8_rac_get ( c ) ) ) s - > prob - > mbskip = vp8_rac_get_uint ( c , 8 ) ; if ( ! s - > keyframe ) { s - > prob - > intra = vp8_rac_get_uint ( c , 8 ) ; s - > prob - > last = vp8_rac_get_uint ( c , 8 ) ; s - > prob - > golden = vp8_rac_get_uint ( c , 8 ) ; if ( vp8_rac_get ( c ) ) for ( i = 0 ; i < 4 ; i + + ) s - > prob - > pred16x16[i] = vp8_rac_get_uint ( c , 8 ) ; if ( vp8_rac_get ( c ) ) for ( i = 0 ; i < 3 ; i + + ) s - > prob - > pred8x8c[i] = vp8_rac_get_uint ( c , 8 ) ; // 17 . 2 MV probability update for ( i = 0 ; i < 2 ; i + + ) for ( j = 0 ; j < 19 ; j + + ) if ( vp56_rac_get_prob_branchy ( c , vp8_mv_update_prob[i][j] ) ) s - > prob - >",1
"static unsigned long iv_decode_frame ( Indeo3DecodeContext * s , unsigned char * buf , int buf_size ) { unsigned int hdr_width , hdr_height , chroma_width , chroma_height ; unsigned long fflags1 , fflags2 , fflags3 , offs1 , offs2 , offs3 , offs ; unsigned char * hdr_pos , * buf_pos ; buf_pos = buf ; buf_pos + = 18 ; fflags1 = le2me_16 ( * ( uint16_t * ) buf_pos ) ; buf_pos + = 2 ; fflags3 = le2me_32 ( * ( uint32_t * ) buf_pos ) ; buf_pos + = 4 ; fflags2 = * buf_pos + + ; buf_pos + = 3 ; hdr_height = le2me_16 ( * ( uint16_t * ) buf_pos ) ; buf_pos + = 2 ; hdr_width = le2me_16 ( * ( uint16_t * ) buf_pos ) ; buf_pos + = 2 ; chroma_height = ( ( hdr_height > > 2 ) + 3 ) & 0x7ffc ; chroma_width = ( ( hdr_width > > 2 ) + 3 ) & 0x7ffc ; offs1 = le2me_32 ( * ( uint32_t * ) buf_pos ) ; buf_pos + = 4 ; offs2 = le2me_32 ( * ( uint32_t * ) buf_pos ) ; buf_pos + = 4 ; offs3 = le2me_32 ( * ( uint32_t * ) buf_pos ) ; buf_pos + = 8 ; hdr_pos = buf_pos ; if ( fflags3 == 0x80 ) return 4 ; if ( fflags1 & 0x200 ) { s - > cur_frame = s - > iv_frame + 1 ; s - > ref_frame = s - > iv_frame ; } else { s - > cur_frame = s - > iv_frame ; s - > ref_frame = s - > iv_frame + 1 ; } buf_pos = buf + 16 + offs1 ; offs = le2me_32 ( * ( uint32_t * ) buf_pos ) ; buf_pos + = 4 ; iv_Decode_Chunk ( s , s - > cur_frame - > Ybuf , s - > ref_frame - > Ybuf , hdr_width , hdr_height , buf_pos + offs * 2 , fflags2 , hdr_pos , buf_pos , min ( hdr_width , 160 ) ) ; if ( ! ( s - > avctx - > flags & CODEC_FLAG_GRAY ) ) { buf_pos = buf + 16 + offs2 ; offs = le2me_32 ( * ( uint32_t * ) buf_pos ) ; buf_pos + = 4 ; iv_Decode_Chunk ( s , s - > cur_frame - > Vbuf , s - > ref_frame - > Vbuf , chroma_width , chroma_height , buf_pos + offs * 2 , fflags2 , hdr_pos , buf_pos , min ( chroma_width , 40 ) ) ; buf_pos = buf + 16 + offs3 ; offs = le2me_32 ( * ( uint32_t * ) buf_pos ) ; buf_pos + = 4 ; iv_Decode_Chunk ( s , s - > cur_frame - > Ubuf , s - > ref_frame - > Ubuf , chroma_width , chroma_height , buf_pos + offs * 2 , fflags2 , hdr_pos , buf_pos , min ( chroma_width , 40 ) ) ; } return 8 ; }",1
"static int imc_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame_ptr , AVPacket * avpkt ) { AVFrame * frame = data ; const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; int ret , i ; IMCContext * q = avctx - > priv_data ; LOCAL_ALIGNED_16 ( uint16_t , buf16 , [IMC_BLOCK_SIZE / 2] ) ; if ( buf_size < IMC_BLOCK_SIZE * avctx - > channels ) { av_log ( avctx , AV_LOG_ERROR , frame too small ! \n ) ; return AVERROR_INVALIDDATA ; } / * get output buffer * / frame - > nb_samples = COEFFS ; if ( ( ret = ff_get_buffer ( avctx , frame , 0 ) ) < 0 ) return ret ; for ( i = 0 ; i < avctx - > channels ; i + + ) { q - > out_samples = ( float * ) frame - > extended_data[i] ; q - > bdsp . bswap16_buf ( buf16 , ( const uint16_t * ) buf , IMC_BLOCK_SIZE / 2 ) ; init_get_bits ( & q - > gb , ( const uint8_t * ) buf16 , IMC_BLOCK_SIZE * 8 ) ; buf + = IMC_BLOCK_SIZE ; if ( ( ret = imc_decode_block ( avctx , q , i ) ) < 0 ) return ret ; } if ( avctx - > channels == 2 ) { q - > fdsp . butterflies_float ( ( float * ) frame - > extended_data[0] , ( float * ) frame - > extended_data[1] , COEFFS ) ; } * got_frame_ptr = 1 ; return IMC_BLOCK_SIZE * avctx - > channels ; }",1
"int init_vlc ( VLC * vlc , int nb_bits , int nb_codes , const void * bits , int bits_wrap , int bits_size , const void * codes , int codes_wrap , int codes_size ) { vlc - > bits = nb_bits ; vlc - > table = NULL ; vlc - > table_allocated = 0 ; vlc - > table_size = 0 ; ifdef DEBUG_VLC printf ( build table nb_codes=%d\n , nb_codes ) ; endif if ( build_table ( vlc , nb_bits , nb_codes , bits , bits_wrap , bits_size , codes , codes_wrap , codes_size , 0 , 0 ) < 0 ) { av_free ( vlc - > table ) ; return - 1 ; } return 0 ; }",1
"static void filter ( AVFilterContext * ctx ) { IDETContext * idet = ctx - > priv ; int y , i ; int64_t alpha[2]= { 0 } ; int64_t delta=0 ; Type type , best_type ; int match = 0 ; for ( i = 0 ; i < idet - > csp - > nb_components ; i + + ) { int w = idet - > cur - > video - > w ; int h = idet - > cur - > video - > h ; int refs = idet - > cur - > linesize[i] ; if ( i & & i < 3 ) { w > > = idet - > csp - > log2_chroma_w ; h > > = idet - > csp - > log2_chroma_h ; } for ( y = 2 ; y < h - 2 ; y + + ) { uint8_t * prev = & idet - > prev - > data[i][y * refs] ; uint8_t * cur = & idet - > cur - > data[i][y * refs] ; uint8_t * next = & idet - > next - > data[i][y * refs] ; alpha[ y & 1] + = idet - > filter_line ( cur - refs , prev , cur + refs , w ) ; alpha[ ( y 1 ) & 1] + = idet - > filter_line ( cur - refs , next , cur + refs , w ) ; delta + = idet - > filter_line ( cur - refs , cur , cur + refs , w ) ; } } if ( alpha[0] / ( float ) alpha[1] > idet - > interlace_threshold ) { type = TFF ; } else if ( alpha[1] / ( float ) alpha[0] > idet - > interlace_threshold ) { type = BFF ; } else if ( alpha[1] / ( float ) delta > idet - > progressive_threshold ) { type = PROGRSSIVE ; } else { type = UNDETERMINED ; } memmove ( idet - > history + 1 , idet - > history , HIST_SIZE - 1 ) ; idet - > history[0] = type ; best_type = UNDETERMINED ; for ( i=0 ; i < HIST_SIZE ; i + + ) { if ( idet - > history[i] ! = UNDETERMINED ) { if ( best_type == UNDETERMINED ) best_type = idet - > history[i] ; if ( idet - > history[i] == best_type ) { match + + ; } else { match=0 ; break ; } } } if ( idet - > last_type == UNDETERMINED ) { if ( match ) idet - > last_type = best_type ; } else { if ( match > 2 ) idet - > last_type = best_type ; } if ( idet - > last_type == TFF ) { idet - > cur - > video - > top_field_first = 1 ; idet - > cur - > video - > interlaced = 1 ; } else if ( idet - > last_type == BFF ) { idet - > cur - > video - > top_field_first = 0 ; idet - > cur - > video - > interlaced = 1 ; } else if ( idet - > last_type == PROGRSSIVE ) { idet - > cur - > video - > interlaced = 0 ; } idet - > prestat [ type] + + ; idet - > poststat[idet - > last_type] + + ; av_log ( ctx , AV_LOG_DEBUG , Single frame : %s , Multi frame : %s\n , type2str ( type ) , type2str ( idet - > last_type ) ) ; }",1
"static float get_band_cost_UPAIR12_mips ( struct AACEncContext * s , PutBitContext * pb , const float * in , const float * scaled , int size , int scale_idx , int cb , const float lambda , const float uplim , int * bits ) { const float Q34 = ff_aac_pow34sf_tab[POW_SF2_ZERO - scale_idx + SCALE_ONE_POS - SCALE_DIV_512] ; const float IQ = ff_aac_pow2sf_tab [POW_SF2_ZERO + scale_idx - SCALE_ONE_POS + SCALE_DIV_512] ; int i ; float cost = 0 ; int qc1 , qc2 , qc3 , qc4 ; int curbits = 0 ; uint8_t * p_bits = ( uint8_t * ) ff_aac_spectral_bits[cb - 1] ; float * p_codes = ( float * ) ff_aac_codebook_vectors[cb - 1] ; for ( i = 0 ; i < size ; i + = 4 ) { const float * vec , * vec2 ; int curidx , curidx2 ; int sign1 , count1 , sign2 , count2 ; int * in_int = ( int * ) & in[i] ; float * in_pos = ( float * ) & in[i] ; float di0 , di1 , di2 , di3 ; int t0 , t1 , t2 , t3 , t4 ; qc1 = scaled[i ] * Q34 + ROUND_STANDARD ; qc2 = scaled[i + 1] * Q34 + ROUND_STANDARD ; qc3 = scaled[i + 2] * Q34 + ROUND_STANDARD ; qc4 = scaled[i + 3] * Q34 + ROUND_STANDARD ; __asm__ volatile ( . set push \n\t . set noreorder \n\t ori %[t4] , zero , 12 \n\t ori %[sign1] , zero , 0 \n\t ori %[sign2] , zero , 0 \n\t slt %[t0] , %[t4] , %[qc1] \n\t slt %[t1] , %[t4] , %[qc2] \n\t slt %[t2] , %[t4] , %[qc3] \n\t slt %[t3] , %[t4] , %[qc4] \n\t movn %[qc1] , %[t4] , %[t0] \n\t movn %[qc2] , %[t4] , %[t1] \n\t movn %[qc3] , %[t4] , %[t2] \n\t movn %[qc4] , %[t4] , %[t3] \n\t lw %[t0] , 0 ( %[in_int] ) \n\t lw %[t1] , 4 ( %[in_int] ) \n\t lw %[t2] , 8 ( %[in_int] ) \n\t lw %[t3] , 12 ( %[in_int] ) \n\t slt %[t0] , %[t0] , zero \n\t movn %[sign1] , %[t0] , %[qc1] \n\t slt %[t2] , %[t2] , zero \n\t movn %[sign2] , %[t2] , %[qc3] \n\t slt %[t1] , %[t1] , zero \n\t sll %[t0] , %[sign1] , 1 \n\t or %[t0] , %[t0] , %[t1] \n\t movn %[sign1] , %[t0] , %[qc2] \n\t slt %[t3] , %[t3] , zero \n\t sll %[t0] , %[sign2] , 1 \n\t or %[t0] , %[t0] , %[t3] \n\t movn %[sign2] , %[t0] , %[qc4] \n\t slt %[count1] , zero , %[qc1] \n\t slt %[t1] , zero , %[qc2] \n\t slt %[count2] , zero , %[qc3] \n\t slt %[t2] , zero , %[qc4] \n\t addu %[count1] , %[count1] , %[t1] \n\t addu %[count2] , %[count2] , %[t2] \n\t . set pop \n\t : [qc1] + r ( qc1 ) , [qc2] + r ( qc2 ) , [qc3] + r ( qc3 ) , [qc4] + r ( qc4 ) , [sign1] = & r ( sign1 ) , [count1] = & r ( count1 ) , [sign2] = & r ( sign2 ) , [count2] = & r ( count2 ) , [t0] = & r ( t0 ) , [t1] = & r ( t1 ) , [t2] = & r ( t2 ) , [t3] = & r ( t3 ) , [t4] = & r ( t4 ) : [in_int] r ( in_int ) : memory ) ; curidx = 13 * qc1 ; curidx + = qc2 ; curidx2 = 13 * qc3 ; curidx2 + = qc4 ; curbits + = p_bits[curidx] ; curbits + = p_bits[curidx2] ; curbits + = upair12_sign_bits[curidx] ; curbits + = upair12_sign_bits[curidx2] ; vec = & p_codes[curidx * 2] ; vec2 = & p_codes[curidx2 * 2] ; __asm__ volatile ( . set push \n\t . set noreorder \n\t lwc1 %[di0] , 0 ( %[in_pos] ) \n\t lwc1 %[di1] , 4 ( %[in_pos] ) \n\t lwc1 %[di2] , 8 ( %[in_pos] ) \n\t lwc1 %[di3] , 12 ( %[in_pos] ) \n\t abs . s %[di0] , %[di0] \n\t abs . s %[di1] , %[di1] \n\t abs . s %[di2] , %[di2] \n\t abs . s %[di3] , %[di3] \n\t lwc1 f0 , 0 ( %[vec] ) \n\t lwc1 f1 , 4 ( %[vec] ) \n\t lwc1 f2 , 0 ( %[vec2] ) \n\t lwc1 f3 , 4 ( %[vec2] ) \n\t nmsub . s %[di0] , %[di0] , f0 , %[IQ] \n\t nmsub . s %[di1] , %[di1] , f1 , %[IQ] \n\t nmsub . s %[di2] , %[di2] , f2 , %[IQ] \n\t nmsub . s %[di3] , %[di3] , f3 , %[IQ] \n\t . set pop \n\t : [di0] = & f ( di0 ) , [di1] = & f ( di1 ) , [di2] = & f ( di2 ) , [di3] = & f ( di3 ) : [in_pos] r ( in_pos ) , [vec] r ( vec ) , [vec2] r ( vec2 ) , [IQ] f ( IQ ) : f0 , f1 , f2 , f3 , memory ) ; cost + = di0 * di0 + di1 * di1 + di2 * di2 + di3 * di3 ; } if ( bits ) * bits = curbits ; return cost * lambda + curbits ; }",1
"static int libopenjpeg_copy_unpacked16 ( AVCodecContext * avctx , const AVFrame * frame , opj_image_t * image ) { int compno ; int x ; int y ; int width ; int height ; int * image_line ; int frame_index ; const int numcomps = image - > numcomps ; uint16_t * frame_ptr ; for ( compno = 0 ; compno < numcomps ; + + compno ) { if ( image - > comps[compno] . w > frame - > linesize[compno] ) { av_log ( avctx , AV_LOG_ERROR , Error : frame ' s linesize is too small for the image\n ) ; return 0 ; } } for ( compno = 0 ; compno < numcomps ; + + compno ) { width = avctx - > width / image - > comps[compno] . dx ; height = avctx - > height / image - > comps[compno] . dy ; frame_ptr = ( uint16_t * ) frame - > data[compno] ; for ( y = 0 ; y < height ; + + y ) { image_line = image - > comps[compno] . data + y * image - > comps[compno] . w ; frame_index = y * ( frame - > linesize[compno] / 2 ) ; for ( x = 0 ; x < width ; + + x ) image_line[x] = frame_ptr[frame_index + + ] ; for ( ; x < image - > comps[compno] . w ; + + x ) { image_line[x] = image_line[x - 1] ; } } for ( ; y < image - > comps[compno] . h ; + + y ) { image_line = image - > comps[compno] . data + y * image - > comps[compno] . w ; for ( x = 0 ; x < image - > comps[compno] . w ; + + x ) { image_line[x] = image_line[x - image - > comps[compno] . w] ; } } } return 1 ; }",1
"inline static void RENAME ( hcscale ) ( uint16_t * dst , int dstWidth , uint8_t * src1 , uint8_t * src2 , int srcW , int xInc , int flags , int canMMX2BeUsed , int16_t * hChrFilter , int16_t * hChrFilterPos , int hChrFilterSize , void * funnyUVCode , int srcFormat , uint8_t * formatConvBuffer , int16_t * mmx2Filter , int32_t * mmx2FilterPos ) { if ( srcFormat==IMGFMT_YUY2 ) { RENAME ( yuy2ToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( srcFormat==IMGFMT_UYVY ) { RENAME ( uyvyToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( srcFormat==IMGFMT_BGR32 ) { RENAME ( bgr32ToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( srcFormat==IMGFMT_BGR24 ) { RENAME ( bgr24ToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( srcFormat==IMGFMT_BGR16 ) { RENAME ( bgr16ToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( srcFormat==IMGFMT_BGR15 ) { RENAME ( bgr15ToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( srcFormat==IMGFMT_RGB32 ) { RENAME ( rgb32ToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( srcFormat==IMGFMT_RGB24 ) { RENAME ( rgb24ToUV ) ( formatConvBuffer , formatConvBuffer + 2048 , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + 2048 ; } else if ( isGray ( srcFormat ) ) { return ; } ifdef HAVE_MMX // use the new MMX scaler if the mmx2 can ' t be used ( its faster than the x86asm one ) if ( ! ( flags & SWS_FAST_BILINEAR ) || ( ! canMMX2BeUsed ) ) else if ( ! ( flags & SWS_FAST_BILINEAR ) ) endif { RENAME ( hScale ) ( dst , dstWidth , src1 , srcW , xInc , hChrFilter , hChrFilterPos , hChrFilterSize ) ; RENAME ( hScale ) ( dst + 2048 , dstWidth , src2 , srcW , xInc , hChrFilter , hChrFilterPos , hChrFilterSize ) ; } else // Fast Bilinear upscale / crap downscale { if defined ( ARCH_X86 ) || defined ( ARCH_X86_64 ) ifdef HAVE_MMX2 int i ; if ( canMMX2BeUsed ) { asm volatile ( pxor %%mm7 , %%mm7 \n\t mov %0 , %% REG_c \n\t mov %1 , %% REG_D \n\t mov %2 , %% REG_d \n\t mov %3 , %% REG_b \n\t xor %% REG_a , %% REG_a \n\t // i PREFETCH ( %% REG_c ) \n\t PREFETCH 32 ( %% REG_c ) \n\t PREFETCH 64 ( %% REG_c ) \n\t ifdef ARCH_X86_64 define FUNNY_UV_CODE \ movl ( %% REG_b ) , %%esi \n\t \ call * %4 \n\t \ movl ( %% REG_b , %% REG_a ) , %%esi\n\t \ add %% REG_S , %% REG_c \n\t \ add %% REG_a , %% REG_D \n\t \ xor %% REG_a , %% REG_a \n\t \ else define FUNNY_UV_CODE \ movl ( %% REG_b ) , %%esi \n\t \ call * %4 \n\t \ addl ( %% REG_b , %% REG_a ) , %% REG_c \n\t \ add %% REG_a , %% REG_D \n\t \ xor %% REG_a , %% REG_a \n\t \ endif FUNNY_UV_CODE FUNNY_UV_CODE FUNNY_UV_CODE FUNNY_UV_CODE xor %% REG_a , %% REG_a \n\t // i mov %5 , %% REG_c \n\t // src mov %1 , %% REG_D \n\t // buf1 add 4096 , %% REG_D \n\t PREFETCH ( %% REG_c ) \n\t PREFETCH 32 ( %% REG_c ) \n\t PREFETCH 64 ( %% REG_c ) \n\t FUNNY_UV_CODE FUNNY_UV_CODE FUNNY_UV_CODE FUNNY_UV_CODE : : m ( src1 ) , m ( dst ) , m ( mmx2Filter ) , m ( mmx2FilterPos ) , m ( funnyUVCode ) , m ( src2 ) : % REG_a , % REG_b , % REG_c , % REG_d , % REG_S , % REG_D ) ; for ( i=dstWidth - 1 ; ( i * xInc ) > > 16 > =srcW - 1 ; i - - ) { // printf ( %d %d %d\n , dstWidth , i , srcW ) ; dst[i] = src1[srcW - 1] * 128 ; dst[i + 2048] = src2[srcW - 1] * 128 ; } } else { endif long xInc_shr16 = ( long ) ( xInc > > 16 ) ; int xInc_mask = xInc & 0xffff ; asm volatile ( xor %% REG_a , %% REG_a \n\t // i xor %% REG_b , %% REG_b \n\t // xx xorl %%ecx , %%ecx \n\t // 2 * xalpha . balign 16 \n\t 1 : \n\t mov %0 , %% REG_S \n\t movzbl ( %% REG_S , %% REG_b ) , %%edi \n\t //src[xx] movzbl 1 ( %% REG_S , %% REG_b ) , %%esi \n\t //src[xx + 1] subl %%edi , %%esi \n\t //src[xx + 1] - src[xx] imull %%ecx , %%esi \n\t // ( src[xx + 1] - src[xx] ) * 2 * xalpha shll 16 , %%edi \n\t addl %%edi , %%esi \n\t //src[xx + 1] * 2 * xalpha + src[xx] * ( 1 - 2 * xalpha ) mov %1 , %% REG_D \n\t shrl 9 , %%esi \n\t movw %%si , ( %% REG_D , %% REG_a , 2 ) \n\t movzbl ( %5 , %% REG_b ) , %%edi \n\t //src[xx] movzbl 1 ( %5 , %% REG_b ) , %%esi \n\t //src[xx + 1] subl %%edi , %%esi \n\t //src[xx + 1] - src[xx] imull %%ecx , %%esi \n\t // ( src[xx + 1] - src[xx] ) * 2 * xalpha shll 16 , %%edi \n\t addl %%edi , %%esi \n\t //src[xx + 1] * 2 * xalpha + src[xx] * ( 1 - 2 * xalpha ) mov %1 , %% REG_D \n\t shrl 9 , %%esi \n\t movw %%si , 4096 ( %% REG_D , %% REG_a , 2 ) \n\t addw %4 , %%cx \n\t //2 * xalpha + = xInc & 0xFF adc %3 , %% REG_b \n\t //xx + = xInc > > 8 + carry add 1 , %% REG_a \n\t cmp %2 , %% REG_a \n\t jb 1b \n\t / * GCC - 3 . 3 makes MPlayer crash on IA - 32 machines when using g operand here , which is needed to support GCC - 4 . 0 * / if defined ( ARCH_X86_64 ) & & ( ( __GNUC__ > 3 ) || ( __GNUC__ == 3 & & __GNUC_MINOR__ > = 4 ) ) : : m ( src1 ) , m ( dst ) , g ( ( long ) dstWidth ) , m ( xInc_shr16 ) ,",1
"static int tak_read_header ( AVFormatContext * s ) { TAKDemuxContext * tc = s - > priv_data ; AVIOContext * pb = s - > pb ; GetBitContext gb ; AVStream * st ; uint8_t * buffer = NULL ; int ret ; st = avformat_new_stream ( s , 0 ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; st - > codec - > codec_type = AVMEDIA_TYPE_AUDIO ; st - > codec - > codec_id = AV_CODEC_ID_TAK ; st - > need_parsing = AVSTREAM_PARSE_FULL_RAW ; tc - > mlast_frame = 0 ; if ( avio_rl32 ( pb ) ! = MKTAG ( ' t ' , ' B ' , ' a ' , ' K ' ) ) { avio_seek ( pb , - 4 , SEEK_CUR ) ; return 0 ; } while ( ! url_feof ( pb ) ) { enum TAKMetaDataType type ; int size ; type = avio_r8 ( pb ) & 0x7f ; size = avio_rl24 ( pb ) ; switch ( type ) { case TAK_METADATA_STREAMINFO : case TAK_METADATA_LAST_FRAME : case TAK_METADATA_ENCODER : if ( size < = 3 ) return AVERROR_INVALIDDATA ; buffer = av_malloc ( size - 3 + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! buffer ) return AVERROR ( ENOMEM ) ; ffio_init_checksum ( pb , tak_check_crc , 0xCE04B7U ) ; if ( avio_read ( pb , buffer , size - 3 ) ! = size - 3 ) { av_freep ( & buffer ) ; return AVERROR ( EIO ) ; } if ( ffio_get_checksum ( s - > pb ) ! = avio_rb24 ( pb ) ) { av_log ( s , AV_LOG_ERROR , %d metadata block CRC error . \n , type ) ; if ( s - > error_recognition & AV_EF_EXPLODE ) { av_freep ( & buffer ) ; return AVERROR_INVALIDDATA ; } } init_get_bits8 ( & gb , buffer , size - 3 ) ; break ; case TAK_METADATA_MD5 : { uint8_t md5[16] ; int i ; if ( size ! = 19 ) return AVERROR_INVALIDDATA ; ffio_init_checksum ( pb , tak_check_crc , 0xCE04B7U ) ; avio_read ( pb , md5 , 16 ) ; if ( ffio_get_checksum ( s - > pb ) ! = avio_rb24 ( pb ) ) { av_log ( s , AV_LOG_ERROR , MD5 metadata block CRC error . \n ) ; if ( s - > error_recognition & AV_EF_EXPLODE ) return AVERROR_INVALIDDATA ; } av_log ( s , AV_LOG_VERBOSE , MD5= ) ; for ( i = 0 ; i < 16 ; i + + ) av_log ( s , AV_LOG_VERBOSE , %02x , md5[i] ) ; av_log ( s , AV_LOG_VERBOSE , \n ) ; break ; } case TAK_METADATA_END : { int64_t curpos = avio_tell ( pb ) ; if ( pb - > seekable ) { ff_ape_parse_tag ( s ) ; avio_seek ( pb , curpos , SEEK_SET ) ; } tc - > data_end + = curpos ; return 0 ; } default : ret = avio_skip ( pb , size ) ; if ( ret < 0 ) return ret ; } if ( type == TAK_METADATA_STREAMINFO ) { TAKStreamInfo ti ; avpriv_tak_parse_streaminfo ( & gb , & ti ) ; if ( ti . samples > 0 ) st - > duration = ti . samples ; st - > codec - > bits_per_coded_sample = ti . bps ; if ( ti . ch_layout ) st - > codec - > channel_layout = ti . ch_layout ; st - > codec - > sample_rate = ti . sample_rate ; st - > codec - > channels = ti . channels ; st - > start_time = 0 ; avpriv_set_pts_info ( st , 64 , 1 , st - > codec - > sample_rate ) ; st - > codec - > extradata = buffer ; st - > codec - > extradata_size = size - 3 ; buffer = NULL ; } else if ( type == TAK_METADATA_LAST_FRAME ) { if ( size ! = 11 ) return AVERROR_INVALIDDATA ; tc - > mlast_frame = 1 ; tc - > data_end = get_bits64 ( & gb , TAK_LAST_FRAME_POS_BITS ) + get_bits ( & gb , TAK_LAST_FRAME_SIZE_BITS ) ; av_freep ( & buffer ) ; } else if ( type == TAK_METADATA_ENCODER ) { av_log ( s , AV_LOG_VERBOSE , encoder version : %0X\n , get_bits_long ( & gb , TAK_ENCODER_VERSION_BITS ) ) ; av_freep ( & buffer ) ; } } return AVERROR_EOF ; }",1
"static int decode_subframe_fixed ( FLACContext * s , int channel , int pred_order ) { int i ; av_log ( s - > avctx , AV_LOG_DEBUG , SUBFRAME FIXED\n ) ; / * warm up samples * / av_log ( s - > avctx , AV_LOG_DEBUG , warm up samples : %d\n , pred_order ) ; for ( i = 0 ; i < pred_order ; i + + ) { s - > decoded[channel][i] = get_sbits ( & s - > gb , s - > curr_bps ) ; // av_log ( s - > avctx , AV_LOG_DEBUG , %d : %d\n , i , s - > decoded[channel][i] ) ; } if ( decode_residuals ( s , channel , pred_order ) < 0 ) return - 1 ; switch ( pred_order ) { case 0 : break ; case 1 : for ( i = pred_order ; i < s - > blocksize ; i + + ) s - > decoded[channel][i] + = s - > decoded[channel][i - 1] ; break ; case 2 : for ( i = pred_order ; i < s - > blocksize ; i + + ) s - > decoded[channel][i] + = 2 * s - > decoded[channel][i - 1] - s - > decoded[channel][i - 2] ; break ; case 3 : for ( i = pred_order ; i < s - > blocksize ; i + + ) s - > decoded[channel][i] + = 3 * s - > decoded[channel][i - 1] - 3 * s - > decoded[channel][i - 2] + s - > decoded[channel][i - 3] ; break ; case 4 : for ( i = pred_order ; i < s - > blocksize ; i + + ) s - > decoded[channel][i] + = 4 * s - > decoded[channel][i - 1] - 6 * s - > decoded[channel][i - 2] + 4 * s - > decoded[channel][i - 3] - s - > decoded[channel][i - 4] ; break ; default : av_log ( s - > avctx , AV_LOG_ERROR , illegal pred order %d\n , pred_order ) ; return - 1 ; } return 0 ; }",0
"static int v4l2_set_parameters ( AVFormatContext * s1 , AVFormatParameters * ap ) { struct video_data * s = s1 - > priv_data ; struct v4l2_input input ; struct v4l2_standard standard ; struct v4l2_streamparm streamparm = { 0 } ; struct v4l2_fract * tpf = & streamparm . parm . capture . timeperframe ; int i , ret ; AVRational framerate_q ; streamparm . type = V4L2_BUF_TYPE_VIDEO_CAPTURE ; if ( s - > framerate & & ( ret = av_parse_video_rate ( & framerate_q , s - > framerate ) ) < 0 ) { av_log ( s1 , AV_LOG_ERROR , Could not parse framerate ' %s ' . \n , s - > framerate ) ; return ret ; } / * set tv video input * / memset ( & input , 0 , sizeof ( input ) ) ; input . index = s - > channel ; if ( ioctl ( s - > fd , VIDIOC_ENUMINPUT , & input ) < 0 ) { av_log ( s1 , AV_LOG_ERROR , The V4L2 driver ioctl enum input failed : \n ) ; return AVERROR ( EIO ) ; } av_log ( s1 , AV_LOG_DEBUG , The V4L2 driver set input_id : %d , input : %s\n , s - > channel , input . name ) ; if ( ioctl ( s - > fd , VIDIOC_S_INPUT , & input . index ) < 0 ) { av_log ( s1 , AV_LOG_ERROR , The V4L2 driver ioctl set input ( %d ) failed\n , s - > channel ) ; return AVERROR ( EIO ) ; } if ( s - > standard ) { av_log ( s1 , AV_LOG_DEBUG , The V4L2 driver set standard : %s\n , s - > standard ) ; / * set tv standard * / memset ( & standard , 0 , sizeof ( standard ) ) ; for ( i=0 ; ; i + + ) { standard . index = i ; if ( ioctl ( s - > fd , VIDIOC_ENUMSTD , & standard ) < 0 ) { av_log ( s1 , AV_LOG_ERROR , The V4L2 driver ioctl set standard ( %s ) failed\n , s - > standard ) ; return AVERROR ( EIO ) ; } if ( ! av_strcasecmp ( standard . name , s - > standard ) ) { break ; } } av_log ( s1 , AV_LOG_DEBUG , The V4L2 driver set standard : %s , id : % PRIu64 \n , s - > standard , ( uint64_t ) standard . id ) ; if ( ioctl ( s - > fd , VIDIOC_S_STD , & standard . id ) < 0 ) { av_log ( s1 , AV_LOG_ERROR , The V4L2 driver ioctl set standard ( %s ) failed\n , s - > standard ) ; return AVERROR ( EIO ) ; } } if ( framerate_q . num & & framerate_q . den ) { av_log ( s1 , AV_LOG_DEBUG , Setting time per frame to %d/%d\n , framerate_q . den , framerate_q . num ) ; tpf - > numerator = framerate_q . den ; tpf - > denominator = framerate_q . num ; if ( ioctl ( s - > fd , VIDIOC_S_PARM , & streamparm ) ! = 0 ) { av_log ( s1 , AV_LOG_ERROR , ioctl set time per frame ( %d/%d ) failed\n , framerate_q . den , framerate_q . num ) ; return AVERROR ( EIO ) ; } if ( framerate_q . num ! = tpf - > denominator || framerate_q . den ! = tpf - > numerator ) { av_log ( s1 , AV_LOG_INFO , The driver changed the time per frame from %d/%d to %d/%d\n , framerate_q . den , framerate_q . num , tpf - > numerator , tpf - > denominator ) ; } } else { if ( ioctl ( s - > fd , VIDIOC_G_PARM , & streamparm ) ! = 0 ) { av_log ( s1 , AV_LOG_ERROR , ioctl ( VIDIOC_G_PARM ) : %s\n , strerror ( errno ) ) ; return AVERROR ( errno ) ; } } s1 - > streams[0] - > codec - > time_base . den = tpf - > denominator ; s1 - > streams[0] - > codec - > time_base . num = tpf - > numerator ; s - > timeout = 100 + av_rescale_q ( 1 , s1 - > streams[0] - > codec - > time_base , ( AVRational ) { 1 , 1000 } ) ; return 0 ; }",0
"static int aac_encode_frame ( AVCodecContext * avctx , AVPacket * avpkt , const AVFrame * frame , int * got_packet_ptr ) { AACEncContext * s = avctx - > priv_data ; float * * samples = s - > planar_samples , * samples2 , * la , * overlap ; ChannelElement * cpe ; SingleChannelElement * sce ; IndividualChannelStream * ics ; int i , its , ch , w , chans , tag , start_ch , ret , frame_bits ; int target_bits , rate_bits , too_many_bits , too_few_bits ; int ms_mode = 0 , is_mode = 0 , tns_mode = 0 , pred_mode = 0 ; int chan_el_counter[4] ; FFPsyWindowInfo windows[AAC_MAX_CHANNELS] ; if ( s - > last_frame == 2 ) return 0 ; / * add current frame to queue * / if ( frame ) { if ( ( ret = ff_af_queue_add ( & s - > afq , frame ) ) < 0 ) return ret ; } copy_input_samples ( s , frame ) ; if ( s - > psypp ) ff_psy_preprocess ( s - > psypp , s - > planar_samples , s - > channels ) ; if ( ! avctx - > frame_number ) return 0 ; start_ch = 0 ; for ( i = 0 ; i < s - > chan_map[0] ; i + + ) { FFPsyWindowInfo * wi = windows + start_ch ; tag = s - > chan_map[i + 1] ; chans = tag == TYPE_CPE ? 2 : 1 ; cpe = & s - > cpe[i] ; for ( ch = 0 ; ch < chans ; ch + + ) { float clip_avoidance_factor ; sce = & cpe - > ch[ch] ; ics = & sce - > ics ; s - > cur_channel = start_ch + ch ; overlap = & samples[s - > cur_channel][0] ; samples2 = overlap + 1024 ; la = samples2 + ( 448 + 64 ) ; if ( ! frame ) la = NULL ; if ( tag == TYPE_LFE ) { wi[ch] . window_type[0] = ONLY_LONG_SEQUENCE ; wi[ch] . window_shape = 0 ; wi[ch] . num_windows = 1 ; wi[ch] . grouping[0] = 1 ; / * Only the lowest 12 coefficients are used in a LFE channel . * The expression below results in only the bottom 8 coefficients * being used for 11 . 025kHz to 16kHz sample rates . * / ics - > num_swb = s - > samplerate_index > = 8 ? 1 : 3 ; } else { wi[ch] = s - > psy . model - > window ( & s - > psy , samples2 , la , s - > cur_channel , ics - > window_sequence[0] ) ; } ics - > window_sequence[1] = ics - > window_sequence[0] ; ics - > window_sequence[0] = wi[ch] . window_type[0] ; ics - > use_kb_window[1] = ics - > use_kb_window[0] ; ics - > use_kb_window[0] = wi[ch] . window_shape ; ics - > num_windows = wi[ch] . num_windows ; ics - > swb_sizes = s - > psy . bands [ics - > num_windows == 8] ; ics - > num_swb = tag == TYPE_LFE ? ics - > num_swb : s - > psy . num_bands[ics - > num_windows == 8] ; ics - > max_sfb = FFMIN ( ics - > max_sfb , ics - > num_swb ) ; ics - > swb_offset = wi[ch] . window_type[0] == EIGHT_SHORT_SEQUENCE ? ff_swb_offset_128 [s - > samplerate_index] : ff_swb_offset_1024[s - > samplerate_index] ; ics - > tns_max_bands = wi[ch] . window_type[0] == EIGHT_SHORT_SEQUENCE ? ff_tns_max_bands_128 [s - > samplerate_index] : ff_tns_max_bands_1024[s - > samplerate_index] ; clip_avoidance_factor = 0 . 0f ; for ( w = 0 ; w < ics - > num_windows ; w + + ) ics - > group_len[w] = wi[ch] . grouping[w] ; for ( w = 0 ; w < ics - > num_windows ; w + + ) { if ( wi[ch] . clipping[w] > CLIP_AVOIDANCE_FACTOR ) { ics - > window_clipping[w] = 1 ; clip_avoidance_factor = FFMAX ( clip_avoidance_factor , wi[ch] . clipping[w] ) ; } else { ics - > window_clipping[w] = 0 ; } } if ( clip_avoidance_factor > CLIP_AVOIDANCE_FACTOR ) { ics - > clip_avoidance_factor = CLIP_AVOIDANCE_FACTOR / clip_avoidance_factor ; } else { ics - > clip_avoidance_factor = 1 . 0f ; } apply_window_and_mdct ( s , sce , overlap ) ; if ( s - > options . ltp & & s - > coder - > update_ltp ) { s - > coder - > update_ltp ( s , sce ) ; apply_window[sce - > ics . window_sequence[0]] ( s - > fdsp , sce , & sce - > ltp_state[0] ) ; s - > mdct1024 . mdct_calc ( & s - > mdct1024 , sce - > lcoeffs , sce - > ret_buf ) ; } if ( isnan ( cpe - > ch - > coeffs[0] ) ) { av_log ( avctx , AV_LOG_ERROR , Input contains NaN\n ) ; return AVERROR ( EINVAL ) ; } avoid_clipping ( s , sce ) ; } start_ch + = chans ; } if ( ( ret = ff_alloc_packet2 ( avctx , avpkt , 8192 * s - > channels , 0 ) ) < 0 ) return ret ; frame_bits = its = 0 ; do { init_put_bits ( & s - > pb , avpkt - > data , avpkt - > size ) ; if ( ( avctx - > frame_number & 0xFF ) ==1 & & ! ( avctx - > flags & AV_CODEC_FLAG_BITEXACT ) ) put_bitstream_info ( s , LIBAVCODEC_IDENT ) ; start_ch = 0 ; target_bits = 0 ; memset ( chan_el_counter , 0 , sizeof ( chan_el_counter ) ) ; for ( i = 0 ; i < s - > chan_map[0] ; i + + ) { FFPsyWindowInfo * wi = windows + start_ch ; const float * coeffs[2] ; tag = s - > chan_map[i + 1] ; chans = tag == TYPE_CPE ? 2 : 1 ; cpe = & s - > cpe[i] ; cpe - > common_window = 0 ; memset ( cpe - > is_mask , 0 , sizeof ( cpe - > is_mask ) ) ; memset ( cpe - > ms_mask , 0 , sizeof ( cpe - > ms_mask ) ) ; put_bits ( & s - > pb , 3 , tag ) ; put_bits ( & s - > pb , 4 , chan_el_counter[tag] + + ) ; for ( ch = 0 ; ch < chans ; ch + + ) { sce = & cpe - > ch[ch] ; coeffs[ch] = sce - > coeffs ; sce - > ics . predictor_present = 0 ; sce - > ics . ltp . present = 0 ; memset ( sce - > ics . ltp . used , 0 , sizeof ( sce - > ics . ltp . used ) ) ; memset ( sce - > ics . prediction_used , 0 , sizeof ( sce - > ics . prediction_used ) ) ; memset ( &",0
"static AVFilterContext * parse_filter ( const char * * buf , AVFilterGraph * graph , int index , AVClass * log_ctx ) { char * opts = NULL ; char * name = consume_string ( buf ) ; if ( * * buf == ' = ' ) { ( * buf ) + + ; opts = consume_string ( buf ) ; } return create_filter ( graph , index , name , opts , log_ctx ) ; }",1
static AVCodec * AVCodecInitialize ( enum AVCodecID codec_id ) { AVCodec * res ; avcodec_register_all ( ) ; av_log_set_level ( AV_LOG_PANIC ) ; res = avcodec_find_decoder ( codec_id ) ; if ( ! res ) error ( Failed to find decoder ) ; return res ; },1
"static int mpegts_read_packet ( AVFormatContext * s , AVPacket * pkt ) { MpegTSContext * ts = s - > priv_data ; if ( ! ts - > mpeg2ts_raw ) { ts - > pkt = pkt ; return handle_packets ( ts , 0 ) ; } else { return mpegts_raw_read_packet ( s , pkt ) ; } }",0
"static int start_frame ( AVFilterLink * link , AVFilterBufferRef * picref ) { AVFilterContext * ctx = link - > dst ; YADIFContext * yadif = ctx - > priv ; if ( yadif - > frame_pending ) return_frame ( ctx , 1 ) ; if ( yadif - > prev ) avfilter_unref_buffer ( yadif - > prev ) ; yadif - > prev = yadif - > cur ; yadif - > cur = yadif - > next ; yadif - > next = picref ; if ( ! yadif - > cur ) return 0 ; if ( yadif - > auto_enable & & ! yadif - > cur - > video - > interlaced ) { yadif - > out = avfilter_ref_buffer ( yadif - > cur , AV_PERM_READ ) ; avfilter_unref_bufferp ( & yadif - > prev ) ; if ( yadif - > out - > pts ! = AV_NOPTS_VALUE ) yadif - > out - > pts * = 2 ; return ff_start_frame ( ctx - > outputs[0] , yadif - > out ) ; } if ( ! yadif - > prev ) yadif - > prev = avfilter_ref_buffer ( yadif - > cur , AV_PERM_READ ) ; yadif - > out = ff_get_video_buffer ( ctx - > outputs[0] , AV_PERM_WRITE | AV_PERM_PRESERVE | AV_PERM_REUSE , link - > w , link - > h ) ; avfilter_copy_buffer_ref_props ( yadif - > out , yadif - > cur ) ; yadif - > out - > video - > interlaced = 0 ; if ( yadif - > out - > pts ! = AV_NOPTS_VALUE ) yadif - > out - > pts * = 2 ; return ff_start_frame ( ctx - > outputs[0] , yadif - > out ) ; }",0
"static void truncpasses ( Jpeg2000EncoderContext * s , Jpeg2000Tile * tile ) { int precno , compno , reslevelno , bandno , cblkno , lev ; Jpeg2000CodingStyle * codsty = & s - > codsty ; for ( compno = 0 ; compno < s - > ncomponents ; compno + + ) { Jpeg2000Component * comp = tile - > comp + compno ; for ( reslevelno = 0 , lev = codsty - > nreslevels - 1 ; reslevelno < codsty - > nreslevels ; reslevelno + + , lev - - ) { Jpeg2000ResLevel * reslevel = comp - > reslevel + reslevelno ; for ( precno = 0 ; precno < reslevel - > num_precincts_x * reslevel - > num_precincts_y ; precno + + ) { for ( bandno = 0 ; bandno < reslevel - > nbands ; bandno + + ) { int bandpos = bandno + ( reslevelno > 0 ) ; Jpeg2000Band * band = reslevel - > band + bandno ; Jpeg2000Prec * prec = band - > prec + precno ; for ( cblkno = 0 ; cblkno < prec - > nb_codeblocks_height * prec - > nb_codeblocks_width ; cblkno + + ) { Jpeg2000Cblk * cblk = prec - > cblk + cblkno ; cblk - > ninclpasses = getcut ( cblk , s - > lambda , ( int64_t ) dwt_norms[codsty - > transform][bandpos][lev] * ( int64_t ) band - > i_stepsize > > 16 ) ; } } } } } }",0
"static int init_tile ( Jpeg2000DecoderContext * s , int tileno ) { int compno ; int tilex = tileno % s - > numXtiles ; int tiley = tileno / s - > numXtiles ; Jpeg2000Tile * tile = s - > tile + tileno ; if ( ! tile - > comp ) return AVERROR ( ENOMEM ) ; tile - > coord[0][0] = av_clip ( tilex * s - > tile_width + s - > tile_offset_x , s - > image_offset_x , s - > width ) ; tile - > coord[0][1] = av_clip ( ( tilex + 1 ) * s - > tile_width + s - > tile_offset_x , s - > image_offset_x , s - > width ) ; tile - > coord[1][0] = av_clip ( tiley * s - > tile_height + s - > tile_offset_y , s - > image_offset_y , s - > height ) ; tile - > coord[1][1] = av_clip ( ( tiley + 1 ) * s - > tile_height + s - > tile_offset_y , s - > image_offset_y , s - > height ) ; for ( compno = 0 ; compno < s - > ncomponents ; compno + + ) { Jpeg2000Component * comp = tile - > comp + compno ; Jpeg2000CodingStyle * codsty = tile - > codsty + compno ; Jpeg2000QuantStyle * qntsty = tile - > qntsty + compno ; int ret ; // global bandno comp - > coord_o[0][0] = tile - > coord[0][0] ; comp - > coord_o[0][1] = tile - > coord[0][1] ; comp - > coord_o[1][0] = tile - > coord[1][0] ; comp - > coord_o[1][1] = tile - > coord[1][1] ; if ( compno ) { comp - > coord_o[0][0] /= s - > cdx[compno] ; comp - > coord_o[0][1] /= s - > cdx[compno] ; comp - > coord_o[1][0] /= s - > cdy[compno] ; comp - > coord_o[1][1] /= s - > cdy[compno] ; } comp - > coord[0][0] = ff_jpeg2000_ceildivpow2 ( comp - > coord_o[0][0] , s - > reduction_factor ) ; comp - > coord[0][1] = ff_jpeg2000_ceildivpow2 ( comp - > coord_o[0][1] , s - > reduction_factor ) ; comp - > coord[1][0] = ff_jpeg2000_ceildivpow2 ( comp - > coord_o[1][0] , s - > reduction_factor ) ; comp - > coord[1][1] = ff_jpeg2000_ceildivpow2 ( comp - > coord_o[1][1] , s - > reduction_factor ) ; if ( ret = ff_jpeg2000_init_component ( comp , codsty , qntsty , s - > cbps[compno] , s - > cdx[compno] , s - > cdy[compno] , s - > avctx ) ) return ret ; } return 0 ; }",1
"static int srt_write_packet ( AVFormatContext * avf , AVPacket * pkt ) { SRTContext * srt = avf - > priv_data ; int write_ts = avf - > streams[0] - > codec - > codec_id ! = AV_CODEC_ID_SRT ; srt - > index + + ; if ( write_ts ) { int64_t s = pkt - > pts , e , d = pkt - > duration ; if ( d < = 0 ) / * For backward compatibility , fallback to convergence_duration . * / d = pkt - > convergence_duration ; if ( s == AV_NOPTS_VALUE || d < 0 ) { av_log ( avf , AV_LOG_ERROR , Insufficient timestamps . \n ) ; return AVERROR ( EINVAL ) ; } e = s + d ; avio_printf ( avf - > pb , %d\n%02d : %02d : %02d , %03d - - > %02d : %02d : %02d , %03d\n , srt - > index , ( int ) ( s / 3600000 ) , ( int ) ( s / 60000 ) % 60 , ( int ) ( s / 1000 ) % 60 , ( int ) ( s % 1000 ) , ( int ) ( e / 3600000 ) , ( int ) ( e / 60000 ) % 60 , ( int ) ( e / 1000 ) % 60 , ( int ) ( e % 1000 ) ) ; } avio_write ( avf - > pb , pkt - > data , pkt - > size ) ; if ( write_ts ) avio_write ( avf - > pb , \n\n , 2 ) ; avio_flush ( avf - > pb ) ; return 0 ; }",1
"static void av_always_inline filter_mb_edgeh ( uint8_t * pix , int stride , const int16_t bS[4] , unsigned int qp , H264Context * h , int intra ) { const int qp_bd_offset = 6 * ( h - > sps . bit_depth_luma - 8 ) ; const unsigned int index_a = qp - qp_bd_offset + h - > slice_alpha_c0_offset ; const int alpha = alpha_table[index_a] ; const int beta = beta_table[qp - qp_bd_offset + h - > slice_beta_offset] ; if ( alpha ==0 || beta == 0 ) return ; if ( bS[0] < 4 || ! intra ) { int8_t tc[4] ; tc[0] = tc0_table[index_a][bS[0]] ; tc[1] = tc0_table[index_a][bS[1]] ; tc[2] = tc0_table[index_a][bS[2]] ; tc[3] = tc0_table[index_a][bS[3]] ; h - > h264dsp . h264_v_loop_filter_luma ( pix , stride , alpha , beta , tc ) ; } else { h - > h264dsp . h264_v_loop_filter_luma_intra ( pix , stride , alpha , beta ) ; } }",0
"static int flac_encode_frame ( AVCodecContext * avctx , AVPacket * avpkt , const AVFrame * frame , int * got_packet_ptr ) { FlacEncodeContext * s ; int frame_bytes , out_bytes , ret ; s = avctx - > priv_data ; / * when the last block is reached , update the header in extradata * / if ( ! frame ) { s - > max_framesize = s - > max_encoded_framesize ; av_md5_final ( s - > md5ctx , s - > md5sum ) ; write_streaminfo ( s , avctx - > extradata ) ; return 0 ; } / * change max_framesize for small final frame * / if ( frame - > nb_samples < s - > frame . blocksize ) { s - > max_framesize = ff_flac_get_max_frame_size ( frame - > nb_samples , s - > channels , avctx - > bits_per_raw_sample ) ; } init_frame ( s , frame - > nb_samples ) ; copy_samples ( s , frame - > data[0] ) ; channel_decorrelation ( s ) ; remove_wasted_bits ( s ) ; frame_bytes = encode_frame ( s ) ; / * fallback to verbatim mode if the compressed frame is larger than it would be if encoded uncompressed . * / if ( frame_bytes < 0 || frame_bytes > s - > max_framesize ) { s - > frame . verbatim_only = 1 ; frame_bytes = encode_frame ( s ) ; if ( frame_bytes < 0 ) { av_log ( avctx , AV_LOG_ERROR , Bad frame count\n ) ; return frame_bytes ; } } if ( ( ret = ff_alloc_packet2 ( avctx , avpkt , frame_bytes ) ) ) return ret ; out_bytes = write_frame ( s , avpkt ) ; s - > frame_count + + ; s - > sample_count + = frame - > nb_samples ; if ( ( ret = update_md5_sum ( s , frame - > data[0] ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , Error updating MD5 checksum\n ) ; return ret ; } if ( out_bytes > s - > max_encoded_framesize ) s - > max_encoded_framesize = out_bytes ; if ( out_bytes < s - > min_framesize ) s - > min_framesize = out_bytes ; avpkt - > pts = frame - > pts ; avpkt - > duration = ff_samples_to_time_base ( avctx , frame - > nb_samples ) ; avpkt - > size = out_bytes ; * got_packet_ptr = 1 ; return 0 ; }",0
"static int decode_vol_header ( MpegEncContext * s , GetBitContext * gb ) { int width , height , vo_ver_id ; / * vol header * / skip_bits ( gb , 1 ) ; / * random access * / s - > vo_type= get_bits ( gb , 8 ) ; if ( get_bits1 ( gb ) ! = 0 ) { / * is_ol_id * / vo_ver_id = get_bits ( gb , 4 ) ; / * vo_ver_id * / skip_bits ( gb , 3 ) ; / * vo_priority * / } else { vo_ver_id = 1 ; } //printf ( vo type : %d\n , s - > vo_type ) ; s - > aspect_ratio_info= get_bits ( gb , 4 ) ; if ( s - > aspect_ratio_info == FF_ASPECT_EXTENDED ) { s - > aspected_width = get_bits ( gb , 8 ) ; // par_width s - > aspected_height = get_bits ( gb , 8 ) ; // par_height } else { s - > aspected_width = pixel_aspect[s - > aspect_ratio_info][0] ; s - > aspected_height= pixel_aspect[s - > aspect_ratio_info][1] ; } if ( ( s - > vol_control_parameters=get_bits1 ( gb ) ) ) { / * vol control parameter * / int chroma_format= get_bits ( gb , 2 ) ; if ( chroma_format ! =1 ) { printf ( illegal chroma format\n ) ; } s - > low_delay= get_bits1 ( gb ) ; if ( get_bits1 ( gb ) ) { / * vbv parameters * / get_bits ( gb , 15 ) ; / * first_half_bitrate * / skip_bits1 ( gb ) ; / * marker * / get_bits ( gb , 15 ) ; / * latter_half_bitrate * / skip_bits1 ( gb ) ; / * marker * / get_bits ( gb , 15 ) ; / * first_half_vbv_buffer_size * / skip_bits1 ( gb ) ; / * marker * / get_bits ( gb , 3 ) ; / * latter_half_vbv_buffer_size * / get_bits ( gb , 11 ) ; / * first_half_vbv_occupancy * / skip_bits1 ( gb ) ; / * marker * / get_bits ( gb , 15 ) ; / * latter_half_vbv_occupancy * / skip_bits1 ( gb ) ; / * marker * / } } else { // set low delay flag only once so the smart ? low delay detection wont be overriden if ( s - > picture_number==0 ) s - > low_delay=0 ; } s - > shape = get_bits ( gb , 2 ) ; / * vol shape * / if ( s - > shape ! = RECT_SHAPE ) printf ( only rectangular vol supported\n ) ; if ( s - > shape == GRAY_SHAPE & & vo_ver_id ! = 1 ) { printf ( Gray shape not supported\n ) ; skip_bits ( gb , 4 ) ; //video_object_layer_shape_extension } skip_bits1 ( gb ) ; / * marker * / s - > time_increment_resolution = get_bits ( gb , 16 ) ; s - > time_increment_bits = av_log2 ( s - > time_increment_resolution - 1 ) + 1 ; if ( s - > time_increment_bits < 1 ) s - > time_increment_bits = 1 ; skip_bits1 ( gb ) ; / * marker * / if ( get_bits1 ( gb ) ! = 0 ) { / * fixed_vop_rate * / skip_bits ( gb , s - > time_increment_bits ) ; } if ( s - > shape ! = BIN_ONLY_SHAPE ) { if ( s - > shape == RECT_SHAPE ) { skip_bits1 ( gb ) ; / * marker * / width = get_bits ( gb , 13 ) ; skip_bits1 ( gb ) ; / * marker * / height = get_bits ( gb , 13 ) ; skip_bits1 ( gb ) ; / * marker * / if ( width & & height ) { / * they should be non zero but who knows . . . * / s - > width = width ; s - > height = height ; // printf ( width/height : %d %d\n , width , height ) ; } } s - > progressive_sequence= get_bits1 ( gb ) 1 ; if ( ! get_bits1 ( gb ) ) printf ( OBMC not supported ( very likely buggy encoder ) \n ) ; / * OBMC Disable * / if ( vo_ver_id == 1 ) { s - > vol_sprite_usage = get_bits1 ( gb ) ; / * vol_sprite_usage * / } else { s - > vol_sprite_usage = get_bits ( gb , 2 ) ; / * vol_sprite_usage * / } if ( s - > vol_sprite_usage==STATIC_SPRITE ) printf ( Static Sprites not supported\n ) ; if ( s - > vol_sprite_usage==STATIC_SPRITE || s - > vol_sprite_usage==GMC_SPRITE ) { if ( s - > vol_sprite_usage==STATIC_SPRITE ) { s - > sprite_width = get_bits ( gb , 13 ) ; skip_bits1 ( gb ) ; / * marker * / s - > sprite_height= get_bits ( gb , 13 ) ; skip_bits1 ( gb ) ; / * marker * / s - > sprite_left = get_bits ( gb , 13 ) ; skip_bits1 ( gb ) ; / * marker * / s - > sprite_top = get_bits ( gb , 13 ) ; skip_bits1 ( gb ) ; / * marker * / } s - > num_sprite_warping_points= get_bits ( gb , 6 ) ; s - > sprite_warping_accuracy = get_bits ( gb , 2 ) ; s - > sprite_brightness_change= get_bits1 ( gb ) ; if ( s - > vol_sprite_usage==STATIC_SPRITE ) s - > low_latency_sprite= get_bits1 ( gb ) ; } // FIXME sadct disable bit if verid ! =1 & & shape not rect if ( get_bits1 ( gb ) == 1 ) { / * not_8_bit * / s - > quant_precision = get_bits ( gb , 4 ) ; / * quant_precision * / if ( get_bits ( gb , 4 ) ! =8 ) printf ( N - bit not supported\n ) ; / * bits_per_pixel * / if ( s - > quant_precision ! =5 ) printf ( quant precission %d\n , s - > quant_precision ) ; } else { s - > quant_precision = 5 ; } // FIXME a bunch of grayscale shape things if ( ( s - > mpeg_quant=get_bits1 ( gb ) ) ) { / * vol_quant_type * / int i , v ; / * load default matrixes * / for ( i=0 ; i < 64 ; i + + ) { int j= s - > dsp . idct_permutation[i] ; v= ff_mpeg4_default_intra_matrix[i] ; s - > intra_matrix[j]= v ; s - > chroma_intra_matrix[j]= v ; v= ff_mpeg4_default_non_intra_matrix[i] ; s - > inter_matrix[j]= v ; s - > chroma_inter_matrix[j]= v ; } / * load custom intra matrix * / if ( get_bits1 ( gb ) ) { int last=0 ; for ( i=0 ; i < 64 ; i + + ) { int j ; v= get_bits ( gb , 8 ) ; if ( v==0 ) break ; last= v ; j= s - > dsp . idct_permutation[ ff_zigzag_direct[i] ] ;",0
"void ff_vp3_v_loop_filter_mmx ( uint8_t * src , int stride , int * bounding_values ) { __asm__ volatile ( movq %0 , %%mm6 \n\t movq %1 , %%mm4 \n\t movq %2 , %%mm2 \n\t movq %3 , %%mm1 \n\t VP3_LOOP_FILTER ( %4 ) movq %%mm4 , %1 \n\t movq %%mm3 , %2 \n\t : + m ( * ( uint64_t * ) ( src - 2 * stride ) ) , + m ( * ( uint64_t * ) ( src - 1 * stride ) ) , + m ( * ( uint64_t * ) ( src + 0 * stride ) ) , + m ( * ( uint64_t * ) ( src + 1 * stride ) ) : m ( * ( uint64_t * ) ( bounding_values + 129 ) ) ) ; }",0
"void ff_init_me ( MpegEncContext * s ) { MotionEstContext * const c= & s - > me ; c - > avctx= s - > avctx ; ff_set_cmp ( & s - > dsp , s - > dsp . me_pre_cmp , c - > avctx - > me_pre_cmp ) ; ff_set_cmp ( & s - > dsp , s - > dsp . me_cmp , c - > avctx - > me_cmp ) ; ff_set_cmp ( & s - > dsp , s - > dsp . me_sub_cmp , c - > avctx - > me_sub_cmp ) ; ff_set_cmp ( & s - > dsp , s - > dsp . mb_cmp , c - > avctx - > mb_cmp ) ; c - > flags = get_flags ( c , 0 , c - > avctx - > me_cmp & FF_CMP_CHROMA ) ; c - > sub_flags= get_flags ( c , 0 , c - > avctx - > me_sub_cmp & FF_CMP_CHROMA ) ; c - > mb_flags = get_flags ( c , 0 , c - > avctx - > mb_cmp & FF_CMP_CHROMA ) ; / * FIXME s - > no_rounding b_type * / if ( s - > flags & CODEC_FLAG_QPEL ) { c - > sub_motion_search= qpel_motion_search ; c - > qpel_avg= s - > dsp . avg_qpel_pixels_tab ; if ( s - > no_rounding ) c - > qpel_put= s - > dsp . put_no_rnd_qpel_pixels_tab ; else c - > qpel_put= s - > dsp . put_qpel_pixels_tab ; } else { if ( c - > avctx - > me_sub_cmp & FF_CMP_CHROMA ) c - > sub_motion_search= hpel_motion_search ; else if ( c - > avctx - > me_sub_cmp == FF_CMP_SAD & & c - > avctx - > me_cmp == FF_CMP_SAD & & c - > avctx - > mb_cmp == FF_CMP_SAD ) c - > sub_motion_search= sad_hpel_motion_search ; // 2050 vs . 2450 cycles else c - > sub_motion_search= hpel_motion_search ; } c - > hpel_avg= s - > dsp . avg_pixels_tab ; if ( s - > no_rounding ) c - > hpel_put= s - > dsp . put_no_rnd_pixels_tab ; else c - > hpel_put= s - > dsp . put_pixels_tab ; if ( s - > linesize ) { c - > stride = s - > linesize ; c - > uvstride= s - > uvlinesize ; } else { c - > stride = 16 * s - > mb_width + 32 ; c - > uvstride= 8 * s - > mb_width + 16 ; } // 8x8 fullpel search would need a 4x4 chroma compare , which we dont have yet , and even if we had the motion estimation code doesnt expect it if ( ( c - > avctx - > me_cmp & FF_CMP_CHROMA ) & & ! s - > dsp . me_cmp[2] ) { s - > dsp . me_cmp[2]= zero_cmp ; } if ( ( c - > avctx - > me_sub_cmp & FF_CMP_CHROMA ) & & ! s - > dsp . me_sub_cmp[2] ) { s - > dsp . me_sub_cmp[2]= zero_cmp ; } c - > hpel_put[2][0]= c - > hpel_put[2][1]= c - > hpel_put[2][2]= c - > hpel_put[2][3]= zero_hpel ; c - > temp= c - > scratchpad ; }",0
"static int decode ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; const uint8_t * buf_end ; uint8_t segment_type ; int segment_length ; int i , ret ; av_dlog ( avctx , PGS sub packet : \n ) ; for ( i = 0 ; i < buf_size ; i + + ) { av_dlog ( avctx , %02x , buf[i] ) ; if ( i % 16 == 15 ) av_dlog ( avctx , \n ) ; } if ( i & 15 ) av_dlog ( avctx , \n ) ; * data_size = 0 ; / * Ensure that we have received at a least a segment code and segment length * / if ( buf_size < 3 ) return - 1 ; buf_end = buf + buf_size ; / * Step through buffer to identify segments * / while ( buf < buf_end ) { segment_type = bytestream_get_byte ( & buf ) ; segment_length = bytestream_get_be16 ( & buf ) ; av_dlog ( avctx , Segment Length %d , Segment Type %x\n , segment_length , segment_type ) ; if ( segment_type ! = DISPLAY_SEGMENT & & segment_length > buf_end - buf ) break ; switch ( segment_type ) { case PALETTE_SEGMENT : parse_palette_segment ( avctx , buf , segment_length ) ; break ; case PICTURE_SEGMENT : parse_picture_segment ( avctx , buf , segment_length ) ; break ; case PRESENTATION_SEGMENT : ret = parse_presentation_segment ( avctx , buf , segment_length , avpkt - > pts ) ; if ( ret < 0 ) return ret ; break ; case WINDOW_SEGMENT : / * * Window Segment Structure ( No new information provided ) : * 2 bytes : Unknown , * 2 bytes : X position of subtitle , * 2 bytes : Y position of subtitle , * 2 bytes : Width of subtitle , * 2 bytes : Height of subtitle . * / break ; case DISPLAY_SEGMENT : * data_size = display_end_segment ( avctx , data , buf , segment_length ) ; break ; default : av_log ( avctx , AV_LOG_ERROR , Unknown subtitle segment type 0x%x , length %d\n , segment_type , segment_length ) ; break ; } buf + = segment_length ; } return buf_size ; }",0
"static int mov_finalize_stsd_codec ( MOVContext * c , AVIOContext * pb , AVStream * st , MOVStreamContext * sc ) { if ( st - > codec - > codec_type == AVMEDIA_TYPE_AUDIO & & ! st - > codec - > sample_rate & & sc - > time_scale > 1 ) st - > codec - > sample_rate = sc - > time_scale ; / * special codec parameters handling * / switch ( st - > codec - > codec_id ) { if CONFIG_DV_DEMUXER case AV_CODEC_ID_DVAUDIO : c - > dv_fctx = avformat_alloc_context ( ) ; if ( ! c - > dv_fctx ) { av_log ( c - > fc , AV_LOG_ERROR , dv demux context alloc error\n ) ; return AVERROR ( ENOMEM ) ; } c - > dv_demux = avpriv_dv_init_demux ( c - > dv_fctx ) ; if ( ! c - > dv_demux ) { av_log ( c - > fc , AV_LOG_ERROR , dv demux context init error\n ) ; return AVERROR ( ENOMEM ) ; } sc - > dv_audio_container = 1 ; st - > codec - > codec_id = AV_CODEC_ID_PCM_S16LE ; break ; endif / * no ifdef since parameters are always those * / case AV_CODEC_ID_QCELP : st - > codec - > channels = 1 ; // force sample rate for qcelp when not stored in mov if ( st - > codec - > codec_tag ! = MKTAG ( ' Q ' , ' c ' , ' l ' , ' p ' ) ) st - > codec - > sample_rate = 8000 ; break ; case AV_CODEC_ID_AMR_NB : st - > codec - > channels = 1 ; / * force sample rate for amr , stsd in 3gp does not store sample rate * / st - > codec - > sample_rate = 8000 ; break ; case AV_CODEC_ID_AMR_WB : st - > codec - > channels = 1 ; st - > codec - > sample_rate = 16000 ; break ; case AV_CODEC_ID_MP2 : case AV_CODEC_ID_MP3 : / * force type after stsd for m1a hdlr * / st - > codec - > codec_type = AVMEDIA_TYPE_AUDIO ; st - > need_parsing = AVSTREAM_PARSE_FULL ; break ; case AV_CODEC_ID_GSM : case AV_CODEC_ID_ADPCM_MS : case AV_CODEC_ID_ADPCM_IMA_WAV : case AV_CODEC_ID_ILBC : st - > codec - > block_align = sc - > bytes_per_frame ; break ; case AV_CODEC_ID_ALAC : if ( st - > codec - > extradata_size == 36 ) { st - > codec - > channels = AV_RB8 ( st - > codec - > extradata + 21 ) ; st - > codec - > sample_rate = AV_RB32 ( st - > codec - > extradata + 32 ) ; } break ; case AV_CODEC_ID_VC1 : st - > need_parsing = AVSTREAM_PARSE_FULL ; break ; default : break ; } return 0 ; }",0
"static int decode_pic_hdr ( IVI45DecContext * ctx , AVCodecContext * avctx ) { int pic_size_indx , i , p ; IVIPicConfig pic_conf ; if ( get_bits ( & ctx - > gb , 18 ) ! = 0x3FFF8 ) { av_log ( avctx , AV_LOG_ERROR , Invalid picture start code ! \n ) ; return AVERROR_INVALIDDATA ; } ctx - > prev_frame_type = ctx - > frame_type ; ctx - > frame_type = get_bits ( & ctx - > gb , 3 ) ; if ( ctx - > frame_type == 7 ) { av_log ( avctx , AV_LOG_ERROR , Invalid frame type : %d\n , ctx - > frame_type ) ; return AVERROR_INVALIDDATA ; } if IVI4_STREAM_ANALYSER if ( ctx - > frame_type == FRAMETYPE_BIDIR ) ctx - > has_b_frames = 1 ; endif ctx - > transp_status = get_bits1 ( & ctx - > gb ) ; if IVI4_STREAM_ANALYSER if ( ctx - > transp_status ) { ctx - > has_transp = 1 ; } endif / * unknown bit : Mac decoder ignores this bit , XANIM returns error * / if ( get_bits1 ( & ctx - > gb ) ) { av_log ( avctx , AV_LOG_ERROR , Sync bit is set ! \n ) ; return AVERROR_INVALIDDATA ; } ctx - > data_size = get_bits1 ( & ctx - > gb ) ? get_bits ( & ctx - > gb , 24 ) : 0 ; / * null frames don ' t contain anything else so we just return * / if ( ctx - > frame_type > = FRAMETYPE_NULL_FIRST ) { av_dlog ( avctx , Null frame encountered ! \n ) ; return 0 ; } / * Check key lock status . If enabled - ignore lock word . * / / * Usually we have to prompt the user for the password , but * / / * we don ' t do that because Indeo 4 videos can be decoded anyway * / if ( get_bits1 ( & ctx - > gb ) ) { skip_bits_long ( & ctx - > gb , 32 ) ; av_dlog ( avctx , Password - protected clip ! \n ) ; } pic_size_indx = get_bits ( & ctx - > gb , 3 ) ; if ( pic_size_indx == IVI4_PIC_SIZE_ESC ) { pic_conf . pic_height = get_bits ( & ctx - > gb , 16 ) ; pic_conf . pic_width = get_bits ( & ctx - > gb , 16 ) ; } else { pic_conf . pic_height = ivi4_common_pic_sizes[pic_size_indx * 2 + 1] ; pic_conf . pic_width = ivi4_common_pic_sizes[pic_size_indx * 2 ] ; } / * Decode tile dimensions . * / if ( get_bits1 ( & ctx - > gb ) ) { pic_conf . tile_height = scale_tile_size ( pic_conf . pic_height , get_bits ( & ctx - > gb , 4 ) ) ; pic_conf . tile_width = scale_tile_size ( pic_conf . pic_width , get_bits ( & ctx - > gb , 4 ) ) ; if IVI4_STREAM_ANALYSER ctx - > uses_tiling = 1 ; endif } else { pic_conf . tile_height = pic_conf . pic_height ; pic_conf . tile_width = pic_conf . pic_width ; } / * Decode chroma subsampling . We support only 4 : 4 aka YVU9 . * / if ( get_bits ( & ctx - > gb , 2 ) ) { av_log ( avctx , AV_LOG_ERROR , Only YVU9 picture format is supported ! \n ) ; return AVERROR_INVALIDDATA ; } pic_conf . chroma_height = ( pic_conf . pic_height + 3 ) > > 2 ; pic_conf . chroma_width = ( pic_conf . pic_width + 3 ) > > 2 ; / * decode subdivision of the planes * / pic_conf . luma_bands = decode_plane_subdivision ( & ctx - > gb ) ; if ( pic_conf . luma_bands ) pic_conf . chroma_bands = decode_plane_subdivision ( & ctx - > gb ) ; ctx - > is_scalable = pic_conf . luma_bands ! = 1 || pic_conf . chroma_bands ! = 1 ; if ( ctx - > is_scalable & & ( pic_conf . luma_bands ! = 4 || pic_conf . chroma_bands ! = 1 ) ) { av_log ( avctx , AV_LOG_ERROR , Scalability : unsupported subdivision ! Luma bands : %d , chroma bands : %d\n , pic_conf . luma_bands , pic_conf . chroma_bands ) ; return AVERROR_INVALIDDATA ; } / * check if picture layout was changed and reallocate buffers * / if ( ivi_pic_config_cmp ( & pic_conf , & ctx - > pic_conf ) ) { if ( ff_ivi_init_planes ( ctx - > planes , & pic_conf ) ) { av_log ( avctx , AV_LOG_ERROR , Couldn ' t reallocate color planes ! \n ) ; return AVERROR ( ENOMEM ) ; } ctx - > pic_conf = pic_conf ; / * set default macroblock/block dimensions * / for ( p = 0 ; p < = 2 ; p + + ) { for ( i = 0 ; i < ( ! p ? pic_conf . luma_bands : pic_conf . chroma_bands ) ; i + + ) { ctx - > planes[p] . bands[i] . mb_size = ! p ? ( ! ctx - > is_scalable ? 16 : 8 ) : 4 ; ctx - > planes[p] . bands[i] . blk_size = ! p ? 8 : 4 ; } } if ( ff_ivi_init_tiles ( ctx - > planes , ctx - > pic_conf . tile_width , ctx - > pic_conf . tile_height ) ) { av_log ( avctx , AV_LOG_ERROR , Couldn ' t reallocate internal structures ! \n ) ; return AVERROR ( ENOMEM ) ; } } ctx - > frame_num = get_bits1 ( & ctx - > gb ) ? get_bits ( & ctx - > gb , 20 ) : 0 ; / * skip decTimeEst field if present * / if ( get_bits1 ( & ctx - > gb ) ) skip_bits ( & ctx - > gb , 8 ) ; / * decode macroblock and block huffman codebooks * / if ( ff_ivi_dec_huff_desc ( & ctx - > gb , get_bits1 ( & ctx - > gb ) , IVI_MB_HUFF , & ctx - > mb_vlc , avctx ) || ff_ivi_dec_huff_desc ( & ctx - > gb , get_bits1 ( & ctx - > gb ) , IVI_BLK_HUFF , & ctx - > blk_vlc , avctx ) ) return AVERROR_INVALIDDATA ; ctx - > rvmap_sel = get_bits1 ( & ctx - > gb ) ? get_bits ( & ctx - > gb , 3 ) : 8 ; ctx - > in_imf = get_bits1 ( & ctx - > gb ) ; ctx - > in_q = get_bits1 ( & ctx - > gb ) ; ctx - > pic_glob_quant = get_bits ( & ctx - > gb , 5 ) ; / * TODO : ignore this parameter if unused * / ctx - > unknown1 = get_bits1 ( & ctx - > gb ) ? get_bits ( & ctx - > gb , 3 ) : 0 ; ctx - > checksum = get_bits1 ( & ctx - >",1
"void ff_vp3_idct_add_altivec ( uint8_t * dst , int stride , DCTELEM block[64] ) { LOAD_ZERO ; vec_u8 t , vdst ; vec_s16 vdst_16 ; vec_u8 vdst_mask = vec_mergeh ( vec_splat_u8 ( - 1 ) , vec_lvsl ( 0 , dst ) ) ; IDCT_START IDCT_1D ( NOP , NOP ) TRANSPOSE8 ( b0 , b1 , b2 , b3 , b4 , b5 , b6 , b7 ) ; IDCT_1D ( ADD8 , SHIFT4 ) define ADD ( a ) \ vdst = vec_ld ( 0 , dst ) ; \ vdst_16 = ( vec_s16 ) vec_perm ( vdst , zero_u8v , vdst_mask ) ; \ vdst_16 = vec_adds ( a , vdst_16 ) ; \ t = vec_packsu ( vdst_16 , vdst_16 ) ; \ vec_ste ( ( vec_u32 ) t , 0 , ( unsigned int * ) dst ) ; \ vec_ste ( ( vec_u32 ) t , 4 , ( unsigned int * ) dst ) ; ADD ( b0 ) dst + = stride ; ADD ( b1 ) dst + = stride ; ADD ( b2 ) dst + = stride ; ADD ( b3 ) dst + = stride ; ADD ( b4 ) dst + = stride ; ADD ( b5 ) dst + = stride ; ADD ( b6 ) dst + = stride ; ADD ( b7 ) }",0
"static int asf_read_replicated_data ( AVFormatContext * s , ASFPacket * asf_pkt ) { ASFContext * asf = s - > priv_data ; AVIOContext * pb = s - > pb ; int ret ; if ( ! asf_pkt - > data_size ) { asf_pkt - > data_size = asf_pkt - > size_left = avio_rl32 ( pb ) ; // read media object size if ( asf_pkt - > data_size < = 0 ) return AVERROR_INVALIDDATA ; if ( ( ret = av_new_packet ( & asf_pkt - > avpkt , asf_pkt - > data_size ) ) < 0 ) return ret ; } else avio_skip ( pb , 4 ) ; // reading of media object size is already done asf_pkt - > dts = avio_rl32 ( pb ) ; // read presentation time if ( asf - > rep_data_len & & ( asf - > rep_data_len > = 8 ) ) avio_skip ( pb , asf - > rep_data_len - 8 ) ; // skip replicated data return 0 ; }",1
"static void calc_thr_3gpp ( const FFPsyWindowInfo * wi , const int num_bands , AacPsyChannel * pch , const uint8_t * band_sizes , const float * coefs ) { int i , w , g ; int start = 0 ; for ( w = 0 ; w < wi - > num_windows * 16 ; w + = 16 ) { for ( g = 0 ; g < num_bands ; g + + ) { AacPsyBand * band = & pch - > band[w + g] ; float form_factor = 0 . 0f ; float Temp ; band - > energy = 0 . 0f ; for ( i = 0 ; i < band_sizes[g] ; i + + ) { band - > energy + = coefs[start + i] * coefs[start + i] ; form_factor + = sqrtf ( fabs ( coefs[start + i] ) ) ; } Temp = band - > energy > 0 ? sqrtf ( ( float ) band_sizes[g] / band - > energy ) : 0 ; band - > thr = band - > energy * 0 . 001258925f ; band - > nz_lines = form_factor * sqrtf ( Temp ) ; start + = band_sizes[g] ; } } }",1
"static int flac_encode_frame ( AVCodecContext * avctx , uint8_t * frame , int buf_size , void * data ) { FlacEncodeContext * s ; const int16_t * samples = data ; int frame_bytes , out_bytes ; s = avctx - > priv_data ; / * when the last block is reached , update the header in extradata * / if ( ! data ) { s - > max_framesize = s - > max_encoded_framesize ; av_md5_final ( s - > md5ctx , s - > md5sum ) ; write_streaminfo ( s , avctx - > extradata ) ; return 0 ; } / * change max_framesize for small final frame * / if ( avctx - > frame_size < s - > frame . blocksize ) { s - > max_framesize = ff_flac_get_max_frame_size ( avctx - > frame_size , s - > channels , 16 ) ; } init_frame ( s ) ; copy_samples ( s , samples ) ; channel_decorrelation ( s ) ; frame_bytes = encode_frame ( s ) ; if ( buf_size < frame_bytes ) { av_log ( avctx , AV_LOG_ERROR , output buffer too small\n ) ; return 0 ; } out_bytes = write_frame ( s , frame , buf_size ) ; / * fallback to verbatim mode if the compressed frame is larger than it would be if encoded uncompressed . * / if ( out_bytes > s - > max_framesize ) { s - > frame . verbatim_only = 1 ; frame_bytes = encode_frame ( s ) ; if ( buf_size < frame_bytes ) { av_log ( avctx , AV_LOG_ERROR , output buffer too small\n ) ; return 0 ; } out_bytes = write_frame ( s , frame , buf_size ) ; } s - > frame_count + + ; avctx - > coded_frame - > pts = s - > sample_count ; s - > sample_count + = avctx - > frame_size ; update_md5_sum ( s , samples ) ; if ( out_bytes > s - > max_encoded_framesize ) s - > max_encoded_framesize = out_bytes ; if ( out_bytes < s - > min_framesize ) s - > min_framesize = out_bytes ; return out_bytes ; }",0
"static int dnxhd_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; DNXHDContext * ctx = avctx - > priv_data ; ThreadFrame frame = { . f = data } ; AVFrame * picture = data ; int first_field = 1 ; int ret , i ; ff_dlog ( avctx , frame size %d\n , buf_size ) ; decode_coding_unit : if ( ( ret = dnxhd_decode_header ( ctx , picture , buf , buf_size , first_field ) ) < 0 ) return ret ; if ( ( avctx - > width || avctx - > height ) & & ( ctx - > width ! = avctx - > width || ctx - > height ! = avctx - > height ) ) { av_log ( avctx , AV_LOG_WARNING , frame size changed : %dx%d - > %dx%d\n , avctx - > width , avctx - > height , ctx - > width , ctx - > height ) ; first_field = 1 ; } if ( avctx - > pix_fmt ! = AV_PIX_FMT_NONE & & avctx - > pix_fmt ! = ctx - > pix_fmt ) { av_log ( avctx , AV_LOG_WARNING , pix_fmt changed : %s - > %s\n , av_get_pix_fmt_name ( avctx - > pix_fmt ) , av_get_pix_fmt_name ( ctx - > pix_fmt ) ) ; first_field = 1 ; } avctx - > pix_fmt = ctx - > pix_fmt ; ret = ff_set_dimensions ( avctx , ctx - > width , ctx - > height ) ; if ( ret < 0 ) return ret ; if ( first_field ) { if ( ( ret = ff_thread_get_buffer ( avctx , & frame , 0 ) ) < 0 ) return ret ; picture - > pict_type = AV_PICTURE_TYPE_I ; picture - > key_frame = 1 ; } ctx - > buf_size = buf_size - 0x280 ; ctx - > buf = buf + 0x280 ; avctx - > execute2 ( avctx , dnxhd_decode_row , picture , NULL , ctx - > mb_height ) ; if ( first_field & & picture - > interlaced_frame ) { buf + = ctx - > cid_table - > coding_unit_size ; buf_size - = ctx - > cid_table - > coding_unit_size ; first_field = 0 ; goto decode_coding_unit ; } ret = 0 ; for ( i = 0 ; i < avctx - > thread_count ; i + + ) { ret + = ctx - > rows[i] . errors ; ctx - > rows[i] . errors = 0 ; } if ( ret ) { av_log ( ctx - > avctx , AV_LOG_ERROR , %d lines with errors\n , ret ) ; return AVERROR_INVALIDDATA ; } * got_frame = 1 ; return avpkt - > size ; }",0
"static void encode_gray_bitstream ( HYuvContext * s , int count ) { int i ; count/=2 ; if ( s - > flags & CODEC_FLAG_PASS1 ) { for ( i=0 ; i < count ; i + + ) { s - > stats[0][ s - > temp[0][2 * i ] ] + + ; s - > stats[0][ s - > temp[0][2 * i + 1] ] + + ; } } else if ( s - > context ) { for ( i=0 ; i < count ; i + + ) { s - > stats[0][ s - > temp[0][2 * i ] ] + + ; put_bits ( & s - > pb , s - > len[0][ s - > temp[0][2 * i ] ] , s - > bits[0][ s - > temp[0][2 * i ] ] ) ; s - > stats[0][ s - > temp[0][2 * i + 1] ] + + ; put_bits ( & s - > pb , s - > len[0][ s - > temp[0][2 * i + 1] ] , s - > bits[0][ s - > temp[0][2 * i + 1] ] ) ; } } else { for ( i=0 ; i < count ; i + + ) { put_bits ( & s - > pb , s - > len[0][ s - > temp[0][2 * i ] ] , s - > bits[0][ s - > temp[0][2 * i ] ] ) ; put_bits ( & s - > pb , s - > len[0][ s - > temp[0][2 * i + 1] ] , s - > bits[0][ s - > temp[0][2 * i + 1] ] ) ; } } }",1
"static int dca_exss_parse_asset_header ( DCAContext * s ) { int header_pos = get_bits_count ( & s - > gb ) ; int header_size ; int channels ; int embedded_stereo = 0 ; int embedded_6ch = 0 ; int drc_code_present ; int extensions_mask ; int i , j ; if ( get_bits_left ( & s - > gb ) < 16 ) return - 1 ; / * We will parse just enough to get to the extensions bitmask with which * we can set the profile value . * / header_size = get_bits ( & s - > gb , 9 ) + 1 ; skip_bits ( & s - > gb , 3 ) ; // asset index if ( s - > static_fields ) { if ( get_bits1 ( & s - > gb ) ) skip_bits ( & s - > gb , 4 ) ; // asset type descriptor if ( get_bits1 ( & s - > gb ) ) skip_bits_long ( & s - > gb , 24 ) ; // language descriptor if ( get_bits1 ( & s - > gb ) ) { / * How can one fit 1024 bytes of text here if the maximum value * for the asset header size field above was 512 bytes ? * / int text_length = get_bits ( & s - > gb , 10 ) + 1 ; if ( get_bits_left ( & s - > gb ) < text_length * 8 ) return - 1 ; skip_bits_long ( & s - > gb , text_length * 8 ) ; // info text } skip_bits ( & s - > gb , 5 ) ; // bit resolution - 1 skip_bits ( & s - > gb , 4 ) ; // max sample rate code channels = get_bits ( & s - > gb , 8 ) + 1 ; if ( get_bits1 ( & s - > gb ) ) { // 1 - to - 1 channels to speakers int spkr_remap_sets ; int spkr_mask_size = 16 ; int num_spkrs[7] ; if ( channels > 2 ) embedded_stereo = get_bits1 ( & s - > gb ) ; if ( channels > 6 ) embedded_6ch = get_bits1 ( & s - > gb ) ; if ( get_bits1 ( & s - > gb ) ) { spkr_mask_size = ( get_bits ( & s - > gb , 2 ) + 1 ) < < 2 ; skip_bits ( & s - > gb , spkr_mask_size ) ; // spkr activity mask } spkr_remap_sets = get_bits ( & s - > gb , 3 ) ; for ( i = 0 ; i < spkr_remap_sets ; i + + ) { / * std layout mask for each remap set * / num_spkrs[i] = dca_exss_mask2count ( get_bits ( & s - > gb , spkr_mask_size ) ) ; } for ( i = 0 ; i < spkr_remap_sets ; i + + ) { int num_dec_ch_remaps = get_bits ( & s - > gb , 5 ) + 1 ; if ( get_bits_left ( & s - > gb ) < 0 ) return - 1 ; for ( j = 0 ; j < num_spkrs[i] ; j + + ) { int remap_dec_ch_mask = get_bits_long ( & s - > gb , num_dec_ch_remaps ) ; int num_dec_ch = av_popcount ( remap_dec_ch_mask ) ; skip_bits_long ( & s - > gb , num_dec_ch * 5 ) ; // remap codes } } } else { skip_bits ( & s - > gb , 3 ) ; // representation type } } drc_code_present = get_bits1 ( & s - > gb ) ; if ( drc_code_present ) get_bits ( & s - > gb , 8 ) ; // drc code if ( get_bits1 ( & s - > gb ) ) skip_bits ( & s - > gb , 5 ) ; // dialog normalization code if ( drc_code_present & & embedded_stereo ) get_bits ( & s - > gb , 8 ) ; // drc stereo code if ( s - > mix_metadata & & get_bits1 ( & s - > gb ) ) { skip_bits ( & s - > gb , 1 ) ; // external mix skip_bits ( & s - > gb , 6 ) ; // post mix gain code if ( get_bits ( & s - > gb , 2 ) ! = 3 ) // mixer drc code skip_bits ( & s - > gb , 3 ) ; // drc limit else skip_bits ( & s - > gb , 8 ) ; // custom drc code if ( get_bits1 ( & s - > gb ) ) // channel specific scaling for ( i = 0 ; i < s - > num_mix_configs ; i + + ) skip_bits_long ( & s - > gb , s - > mix_config_num_ch[i] * 6 ) ; // scale codes else skip_bits_long ( & s - > gb , s - > num_mix_configs * 6 ) ; // scale codes for ( i = 0 ; i < s - > num_mix_configs ; i + + ) { if ( get_bits_left ( & s - > gb ) < 0 ) return - 1 ; dca_exss_skip_mix_coeffs ( & s - > gb , channels , s - > mix_config_num_ch[i] ) ; if ( embedded_6ch ) dca_exss_skip_mix_coeffs ( & s - > gb , 6 , s - > mix_config_num_ch[i] ) ; if ( embedded_stereo ) dca_exss_skip_mix_coeffs ( & s - > gb , 2 , s - > mix_config_num_ch[i] ) ; } } switch ( get_bits ( & s - > gb , 2 ) ) { case 0 : extensions_mask = get_bits ( & s - > gb , 12 ) ; break ; case 1 : extensions_mask = DCA_EXT_EXSS_XLL ; break ; case 2 : extensions_mask = DCA_EXT_EXSS_LBR ; break ; case 3 : extensions_mask = 0 ; / * aux coding * / break ; } / * not parsed further , we were only interested in the extensions mask * / if ( get_bits_left ( & s - > gb ) < 0 ) return - 1 ; if ( get_bits_count ( & s - > gb ) - header_pos > header_size * 8 ) { av_log ( s - > avctx , AV_LOG_WARNING , Asset header size mismatch . \n ) ; return - 1 ; } skip_bits_long ( & s - > gb , header_pos + header_size * 8 - get_bits_count ( & s - > gb ) ) ; if ( extensions_mask & DCA_EXT_EXSS_XLL ) s - > profile = FF_PROFILE_DTS_HD_MA ; else if ( extensions_mask & ( DCA_EXT_EXSS_XBR | DCA_EXT_EXSS_X96 | DCA_EXT_EXSS_XXCH ) ) s - > profile = FF_PROFILE_DTS_HD_HRA ; if ( ! ( extensions_mask & DCA_EXT_CORE ) ) av_log ( s - > avctx , AV_LOG_WARNING , DTS core detection mismatch . \n ) ; if ( ( extensions_mask & DCA_CORE_EXTS ) ! = s - > core_ext_mask ) av_log ( s - > avctx , AV_LOG_WARNING , DTS extensions detection mismatch ( %d",1
"void ff_aac_search_for_ltp ( AACEncContext * s , SingleChannelElement * sce , int common_window ) { int w , g , w2 , i , start = 0 , count = 0 ; int saved_bits = - ( 15 + FFMIN ( sce - > ics . max_sfb , MAX_LTP_LONG_SFB ) ) ; float * C34 = & s - > scoefs[128 * 0] , * PCD = & s - > scoefs[128 * 1] ; float * PCD34 = & s - > scoefs[128 * 2] ; const int max_ltp = FFMIN ( sce - > ics . max_sfb , MAX_LTP_LONG_SFB ) ; if ( sce - > ics . window_sequence[0] == EIGHT_SHORT_SEQUENCE ) { if ( sce - > ics . ltp . lag ) { memset ( & sce - > lcoeffs[0] , 0 . 0f , 3072 * sizeof ( sce - > lcoeffs[0] ) ) ; memset ( & sce - > ics . ltp , 0 , sizeof ( LongTermPrediction ) ) ; } return ; } if ( ! sce - > ics . ltp . lag ) return ; for ( w = 0 ; w < sce - > ics . num_windows ; w + = sce - > ics . group_len[w] ) { start = 0 ; for ( g = 0 ; g < sce - > ics . num_swb ; g + + ) { int bits1 = 0 , bits2 = 0 ; float dist1 = 0 . 0f , dist2 = 0 . 0f ; if ( w * 16 + g > max_ltp ) { start + = sce - > ics . swb_sizes[g] ; continue ; } for ( w2 = 0 ; w2 < sce - > ics . group_len[w] ; w2 + + ) { int bits_tmp1 , bits_tmp2 ; FFPsyBand * band = & s - > psy . ch[s - > cur_channel] . psy_bands[ ( w + w2 ) * 16 + g] ; for ( i = 0 ; i < sce - > ics . swb_sizes[g] ; i + + ) PCD[i] = sce - > coeffs[start + ( w + w2 ) * 128 + i] - sce - > lcoeffs[start + ( w + w2 ) * 128 + i] ; abs_pow34_v ( C34 , & sce - > coeffs[start + ( w + w2 ) * 128] , sce - > ics . swb_sizes[g] ) ; abs_pow34_v ( PCD34 , PCD , sce - > ics . swb_sizes[g] ) ; dist1 + = quantize_band_cost ( s , & sce - > coeffs[start + ( w + w2 ) * 128] , C34 , sce - > ics . swb_sizes[g] , sce - > sf_idx[ ( w + w2 ) * 16 + g] , sce - > band_type[ ( w + w2 ) * 16 + g] , s - > lambda/band - > threshold , INFINITY , & bits_tmp1 , NULL , 0 ) ; dist2 + = quantize_band_cost ( s , PCD , PCD34 , sce - > ics . swb_sizes[g] , sce - > sf_idx[ ( w + w2 ) * 16 + g] , sce - > band_type[ ( w + w2 ) * 16 + g] , s - > lambda/band - > threshold , INFINITY , & bits_tmp2 , NULL , 0 ) ; bits1 + = bits_tmp1 ; bits2 + = bits_tmp2 ; } if ( dist2 < dist1 & & bits2 < bits1 ) { for ( w2 = 0 ; w2 < sce - > ics . group_len[w] ; w2 + + ) for ( i = 0 ; i < sce - > ics . swb_sizes[g] ; i + + ) sce - > coeffs[start + ( w + w2 ) * 128 + i] - = sce - > lcoeffs[start + ( w + w2 ) * 128 + i] ; sce - > ics . ltp . used[w * 16 + g] = 1 ; saved_bits + = bits1 - bits2 ; count + + ; } start + = sce - > ics . swb_sizes[g] ; } } sce - > ics . ltp . present = ! ! count & & ( saved_bits > = 0 ) ; sce - > ics . predictor_present = ! ! sce - > ics . ltp . present ; / * Reset any marked sfbs * / if ( ! sce - > ics . ltp . present & & ! ! count ) { for ( w = 0 ; w < sce - > ics . num_windows ; w + = sce - > ics . group_len[w] ) { start = 0 ; for ( g = 0 ; g < sce - > ics . num_swb ; g + + ) { if ( sce - > ics . ltp . used[w * 16 + g] ) { for ( w2 = 0 ; w2 < sce - > ics . group_len[w] ; w2 + + ) { for ( i = 0 ; i < sce - > ics . swb_sizes[g] ; i + + ) { sce - > coeffs[start + ( w + w2 ) * 128 + i] + = sce - > lcoeffs[start + ( w + w2 ) * 128 + i] ; } } } start + = sce - > ics . swb_sizes[g] ; } } } }",1
"static int parse_vtrk ( AVFormatContext * s , FourxmDemuxContext * fourxm , uint8_t * buf , int size , int left ) { AVStream * st ; / * check that there is enough data * / if ( size ! = vtrk_SIZE || left < size + 8 ) { return AVERROR_INVALIDDATA ; } / * allocate a new AVStream * / st = avformat_new_stream ( s , NULL ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; avpriv_set_pts_info ( st , 60 , 1 , fourxm - > fps ) ; fourxm - > video_stream_index = st - > index ; st - > codec - > codec_type = AVMEDIA_TYPE_VIDEO ; st - > codec - > codec_id = AV_CODEC_ID_4XM ; st - > codec - > extradata_size = 4 ; st - > codec - > extradata = av_malloc ( 4 ) ; AV_WL32 ( st - > codec - > extradata , AV_RL32 ( buf + 16 ) ) ; st - > codec - > width = AV_RL32 ( buf + 36 ) ; st - > codec - > height = AV_RL32 ( buf + 40 ) ; return 0 ; }",1
"static void draw_digit ( int digit , uint8_t * dst , unsigned dst_linesize , unsigned segment_width ) { define TOP_HBAR 1 define MID_HBAR 2 define BOT_HBAR 4 define LEFT_TOP_VBAR 8 define LEFT_BOT_VBAR 16 define RIGHT_TOP_VBAR 32 define RIGHT_BOT_VBAR 64 struct { int x , y , w , h ; } segments[] = { { 1 , 0 , 5 , 1 } , / * TOP_HBAR * / { 1 , 6 , 5 , 1 } , / * MID_HBAR * / { 1 , 12 , 5 , 1 } , / * BOT_HBAR * / { 0 , 1 , 1 , 5 } , / * LEFT_TOP_VBAR * / { 0 , 7 , 1 , 5 } , / * LEFT_BOT_VBAR * / { 6 , 1 , 1 , 5 } , / * RIGHT_TOP_VBAR * / { 6 , 7 , 1 , 5 } / * RIGHT_BOT_VBAR * / } ; static const unsigned char masks[10] = { / * 0 * / TOP_HBAR |BOT_HBAR|LEFT_TOP_VBAR|LEFT_BOT_VBAR|RIGHT_TOP_VBAR|RIGHT_BOT_VBAR , / * 1 * / RIGHT_TOP_VBAR|RIGHT_BOT_VBAR , / * 2 * / TOP_HBAR|MID_HBAR|BOT_HBAR|LEFT_BOT_VBAR |RIGHT_TOP_VBAR , / * 3 * / TOP_HBAR|MID_HBAR|BOT_HBAR |RIGHT_TOP_VBAR|RIGHT_BOT_VBAR , / * 4 * / MID_HBAR |LEFT_TOP_VBAR |RIGHT_TOP_VBAR|RIGHT_BOT_VBAR , / * 5 * / TOP_HBAR|BOT_HBAR|MID_HBAR|LEFT_TOP_VBAR |RIGHT_BOT_VBAR , / * 6 * / TOP_HBAR|BOT_HBAR|MID_HBAR|LEFT_TOP_VBAR|LEFT_BOT_VBAR |RIGHT_BOT_VBAR , / * 7 * / TOP_HBAR |RIGHT_TOP_VBAR|RIGHT_BOT_VBAR , / * 8 * / TOP_HBAR|BOT_HBAR|MID_HBAR|LEFT_TOP_VBAR|LEFT_BOT_VBAR|RIGHT_TOP_VBAR|RIGHT_BOT_VBAR , / * 9 * / TOP_HBAR|BOT_HBAR|MID_HBAR|LEFT_TOP_VBAR |RIGHT_TOP_VBAR|RIGHT_BOT_VBAR , } ; unsigned mask = masks[digit] ; int i ; draw_rectangle ( 0 , dst , dst_linesize , segment_width , 0 , 0 , 8 , 13 ) ; for ( i = 0 ; i < FF_ARRAY_ELEMS ( segments ) ; i + + ) if ( mask & ( 1 < < i ) ) draw_rectangle ( 255 , dst , dst_linesize , segment_width , segments[i] . x , segments[i] . y , segments[i] . w , segments[i] . h ) ; }",1
"static int query_formats ( AVFilterGraph * graph , AVClass * log_ctx ) { int i , j , ret ; int scaler_count = 0 , resampler_count = 0 ; int count_queried = 0 , count_merged = 0 , count_already_merged = 0 , count_delayed = 0 ; for ( i = 0 ; i < graph - > nb_filters ; i + + ) { AVFilterContext * f = graph - > filters[i] ; if ( formats_declared ( f ) ) continue ; if ( f - > filter - > query_formats ) ret = filter_query_formats ( f ) ; else ret = ff_default_query_formats ( f ) ; if ( ret < 0 & & ret ! = AVERROR ( EAGAIN ) ) return ret ; / * note : EAGAIN could indicate a partial success , not counted yet * / count_queried + = ret > = 0 ; } / * go through and merge as many format lists as possible * / for ( i = 0 ; i < graph - > nb_filters ; i + + ) { AVFilterContext * filter = graph - > filters[i] ; for ( j = 0 ; j < filter - > nb_inputs ; j + + ) { AVFilterLink * link = filter - > inputs[j] ; int convert_needed = 0 ; if ( ! link ) continue ; define MERGE_DISPATCH ( field , statement ) \ if ( ! ( link - > in_ field & & link - > out_ field ) ) { \ count_delayed + + ; \ } else if ( link - > in_ field == link - > out_ field ) { \ count_already_merged + + ; \ } else { \ count_merged + + ; \ statement \ } MERGE_DISPATCH ( formats , if ( ! ff_merge_formats ( link - > in_formats , link - > out_formats , link - > type ) ) convert_needed = 1 ; ) if ( link - > type == AVMEDIA_TYPE_AUDIO ) { MERGE_DISPATCH ( channel_layouts , if ( ! ff_merge_channel_layouts ( link - > in_channel_layouts , link - > out_channel_layouts ) ) convert_needed = 1 ; ) MERGE_DISPATCH ( samplerates , if ( ! ff_merge_samplerates ( link - > in_samplerates , link - > out_samplerates ) ) convert_needed = 1 ; ) } undef MERGE_DISPATCH if ( convert_needed ) { AVFilterContext * convert ; AVFilter * filter ; AVFilterLink * inlink , * outlink ; char scale_args[256] ; char inst_name[30] ; / * couldn ' t merge format lists . auto - insert conversion filter * / switch ( link - > type ) { case AVMEDIA_TYPE_VIDEO : if ( ! ( filter = avfilter_get_by_name ( scale ) ) ) { av_log ( log_ctx , AV_LOG_ERROR , ' scale ' filter not present , cannot convert pixel formats . \n ) ; return AVERROR ( EINVAL ) ; } snprintf ( inst_name , sizeof ( inst_name ) , auto - inserted scaler %d , scaler_count + + ) ; av_strlcpy ( scale_args , 0 : 0 , sizeof ( scale_args ) ) ; if ( graph - > scale_sws_opts ) { av_strlcat ( scale_args , : , sizeof ( scale_args ) ) ; av_strlcat ( scale_args , graph - > scale_sws_opts , sizeof ( scale_args ) ) ; } if ( ( ret = avfilter_graph_create_filter ( & convert , filter , inst_name , scale_args , NULL , graph ) ) < 0 ) return ret ; break ; case AVMEDIA_TYPE_AUDIO : if ( ! ( filter = avfilter_get_by_name ( aresample ) ) ) { av_log ( log_ctx , AV_LOG_ERROR , ' aresample ' filter not present , cannot convert audio formats . \n ) ; return AVERROR ( EINVAL ) ; } snprintf ( inst_name , sizeof ( inst_name ) , auto - inserted resampler %d , resampler_count + + ) ; scale_args[0] = ' \0 ' ; if ( graph - > aresample_swr_opts ) snprintf ( scale_args , sizeof ( scale_args ) , %s , graph - > aresample_swr_opts ) ; if ( ( ret = avfilter_graph_create_filter ( & convert , filter , inst_name , graph - > aresample_swr_opts , NULL , graph ) ) < 0 ) return ret ; break ; default : return AVERROR ( EINVAL ) ; } if ( ( ret = avfilter_insert_filter ( link , convert , 0 , 0 ) ) < 0 ) return ret ; filter_query_formats ( convert ) ; inlink = convert - > inputs[0] ; outlink = convert - > outputs[0] ; if ( ! ff_merge_formats ( inlink - > in_formats , inlink - > out_formats , inlink - > type ) || ! ff_merge_formats ( outlink - > in_formats , outlink - > out_formats , outlink - > type ) ) ret |= AVERROR ( ENOSYS ) ; if ( inlink - > type == AVMEDIA_TYPE_AUDIO & & ( ! ff_merge_samplerates ( inlink - > in_samplerates , inlink - > out_samplerates ) || ! ff_merge_channel_layouts ( inlink - > in_channel_layouts , inlink - > out_channel_layouts ) ) ) ret |= AVERROR ( ENOSYS ) ; if ( outlink - > type == AVMEDIA_TYPE_AUDIO & & ( ! ff_merge_samplerates ( outlink - > in_samplerates , outlink - > out_samplerates ) || ! ff_merge_channel_layouts ( outlink - > in_channel_layouts , outlink - > out_channel_layouts ) ) ) ret |= AVERROR ( ENOSYS ) ; if ( ret < 0 ) { av_log ( log_ctx , AV_LOG_ERROR , Impossible to convert between the formats supported by the filter ' %s ' and the filter ' %s ' \n , link - > src - > name , link - > dst - > name ) ; return ret ; } } } } av_log ( graph , AV_LOG_DEBUG , query_formats : %d queried , %d merged , %d already done , %d delayed\n , count_queried , count_merged , count_already_merged , count_delayed ) ; if ( count_delayed ) { AVBPrint bp ; if ( count_queried || count_merged ) return AVERROR ( EAGAIN ) ; av_bprint_init ( & bp , 0 , AV_BPRINT_SIZE_AUTOMATIC ) ; for ( i = 0 ; i < graph - > nb_filters ; i + + ) if ( ! formats_declared ( graph - > filters[i] ) ) av_bprintf ( & bp , %s%s , bp . len ? , : , graph - > filters[i] - > name ) ; av_log ( graph , AV_LOG_ERROR , The following filters could not choose their formats : %s\n Consider inserting the ( a ) format filter near their input or output . \n , bp . str ) ; return AVERROR ( EIO ) ; } return 0 ; }",0
"static inline void mix_2f_1r_to_stereo ( AC3DecodeContext * ctx ) { int i ; float ( * output ) [256] = ctx - > audio_block . block_output ; for ( i = 0 ; i < 256 ; i + + ) { output[1][i] + = output[2][i] ; output[2][i] + = output[3][i] ; } memset ( output[3] , 0 , sizeof ( output[3] ) ) ; }",0
"static int decode_cabac_mb_cbp_chroma ( H264Context * h ) { int ctx ; int cbp_a , cbp_b ; cbp_a = ( h - > left_cbp > > 4 ) & 0x03 ; cbp_b = ( h - > top_cbp > > 4 ) & 0x03 ; ctx = 0 ; if ( cbp_a > 0 ) ctx + + ; if ( cbp_b > 0 ) ctx + = 2 ; if ( get_cabac ( & h - > cabac , & h - > cabac_state[77 + ctx] ) == 0 ) return 0 ; ctx = 4 ; if ( cbp_a == 2 ) ctx + + ; if ( cbp_b == 2 ) ctx + = 2 ; return 1 + get_cabac ( & h - > cabac , & h - > cabac_state[77 + ctx] ) ; }",0
"static int mp3_write_audio_packet ( AVFormatContext * s , AVPacket * pkt ) { MP3Context * mp3 = s - > priv_data ; if ( pkt & & pkt - > data & & pkt - > size > = 4 ) { MPADecodeHeader c ; int av_unused base ; avpriv_mpegaudio_decode_header ( & c , AV_RB32 ( pkt - > data ) ) ; if ( ! mp3 - > initial_bitrate ) mp3 - > initial_bitrate = c . bit_rate ; if ( ( c . bit_rate == 0 ) || ( mp3 - > initial_bitrate ! = c . bit_rate ) ) mp3 - > has_variable_bitrate = 1 ; ifdef FILTER_VBR_HEADERS / * filter out XING and INFO headers . * / base = 4 + xing_offtbl[c . lsf == 1][c . nb_channels == 1] ; if ( base + 4 < = pkt - > size ) { uint32_t v = AV_RB32 ( pkt - > data + base ) ; if ( MKBETAG ( ' X ' , ' i ' , ' n ' , ' g ' ) == v || MKBETAG ( ' I ' , ' n ' , ' f ' , ' o ' ) == v ) return 0 ; } / * filter out VBRI headers . * / base = 4 + 32 ; if ( base + 4 < = pkt - > size & & MKBETAG ( ' V ' , ' B ' , ' R ' , ' I ' ) == AV_RB32 ( pkt - > data + base ) ) return 0 ; endif if ( mp3 - > xing_offset ) mp3_xing_add_frame ( mp3 , pkt ) ; } return ff_raw_write_packet ( s , pkt ) ; }",0
"int has_altivec ( void ) { ifdef __AMIGAOS4__ ULONG result = 0 ; extern struct ExecIFace * IExec ; IExec - > GetCPUInfoTags ( GCIT_VectorUnit , & result , TAG_DONE ) ; if ( result == VECTORTYPE_ALTIVEC ) return 1 ; return 0 ; else / * __AMIGAOS4__ * / ifdef SYS_DARWIN int sels[2] = { CTL_HW , HW_VECTORUNIT } ; int has_vu = 0 ; size_t len = sizeof ( has_vu ) ; int err ; err = sysctl ( sels , 2 , & has_vu , & len , NULL , 0 ) ; if ( err == 0 ) return ( has_vu ! = 0 ) ; else / * SYS_DARWIN * / / * no Darwin , do it the brute - force way * / / * this is borrowed from the libmpeg2 library * / { signal ( SIGILL , sigill_handler ) ; if ( sigsetjmp ( jmpbuf , 1 ) ) { signal ( SIGILL , SIG_DFL ) ; } else { canjump = 1 ; asm volatile ( mtspr 256 , %0\n\t vand %%v0 , %%v0 , %%v0 : : r ( - 1 ) ) ; signal ( SIGILL , SIG_DFL ) ; return 1 ; } } endif / * SYS_DARWIN * / return 0 ; endif / * __AMIGAOS4__ * / }",0
"static int mpeg_field_start ( MpegEncContext * s , const uint8_t * buf , int buf_size ) { AVCodecContext * avctx = s - > avctx ; Mpeg1Context * s1 = ( Mpeg1Context * ) s ; int ret ; if ( s - > picture_structure == PICT_FRAME ) s - > first_field = 0 ; else s - > first_field = 1 ; / * start frame decoding * / if ( s - > first_field || s - > picture_structure == PICT_FRAME ) { AVFrameSideData * pan_scan ; if ( ( ret = ff_mpv_frame_start ( s , avctx ) ) < 0 ) return ret ; ff_mpeg_er_frame_start ( s ) ; / * first check if we must repeat the frame * / s - > current_picture_ptr - > f - > repeat_pict = 0 ; if ( s - > repeat_first_field ) { if ( s - > progressive_sequence ) { if ( s - > top_field_first ) s - > current_picture_ptr - > f - > repeat_pict = 4 ; else s - > current_picture_ptr - > f - > repeat_pict = 2 ; } else if ( s - > progressive_frame ) { s - > current_picture_ptr - > f - > repeat_pict = 1 ; } } pan_scan = av_frame_new_side_data ( s - > current_picture_ptr - > f , AV_FRAME_DATA_PANSCAN , sizeof ( s1 - > pan_scan ) ) ; if ( ! pan_scan ) return AVERROR ( ENOMEM ) ; memcpy ( pan_scan - > data , & s1 - > pan_scan , sizeof ( s1 - > pan_scan ) ) ; if ( s1 - > a53_caption ) { AVFrameSideData * sd = av_frame_new_side_data ( s - > current_picture_ptr - > f , AV_FRAME_DATA_A53_CC , s1 - > a53_caption_size ) ; if ( sd ) memcpy ( sd - > data , s1 - > a53_caption , s1 - > a53_caption_size ) ; av_freep ( & s1 - > a53_caption ) ; } if ( s1 - > has_stereo3d ) { AVStereo3D * stereo = av_stereo3d_create_side_data ( s - > current_picture_ptr - > f ) ; if ( ! stereo ) return AVERROR ( ENOMEM ) ; * stereo = s1 - > stereo3d ; s1 - > has_stereo3d = 0 ; } if ( s1 - > has_afd ) { AVFrameSideData * sd = av_frame_new_side_data ( s - > current_picture_ptr - > f , AV_FRAME_DATA_AFD , 1 ) ; if ( ! sd ) return AVERROR ( ENOMEM ) ; * sd - > data = s1 - > afd ; s1 - > has_afd = 0 ; } if ( HAVE_THREADS & & ( avctx - > active_thread_type & FF_THREAD_FRAME ) ) ff_thread_finish_setup ( avctx ) ; } else { // second field int i ; if ( ! s - > current_picture_ptr ) { av_log ( s - > avctx , AV_LOG_ERROR , first field missing\n ) ; return AVERROR_INVALIDDATA ; } if ( s - > avctx - > hwaccel & & ( s - > avctx - > slice_flags & SLICE_FLAG_ALLOW_FIELD ) ) { if ( s - > avctx - > hwaccel - > end_frame ( s - > avctx ) < 0 ) av_log ( avctx , AV_LOG_ERROR , hardware accelerator failed to decode first field\n ) ; } for ( i = 0 ; i < 4 ; i + + ) { s - > current_picture . f - > data[i] = s - > current_picture_ptr - > f - > data[i] ; if ( s - > picture_structure == PICT_BOTTOM_FIELD ) s - > current_picture . f - > data[i] + = s - > current_picture_ptr - > f - > linesize[i] ; } } if ( avctx - > hwaccel ) { if ( ( ret = avctx - > hwaccel - > start_frame ( avctx , buf , buf_size ) ) < 0 ) return ret ; } if FF_API_XVMC FF_DISABLE_DEPRECATION_WARNINGS // ff_mpv_frame_start will call this function too , // but we need to call it on every field if ( CONFIG_MPEG_XVMC_DECODER & & s - > avctx - > xvmc_acceleration ) if ( ff_xvmc_field_start ( s , avctx ) < 0 ) return - 1 ; FF_ENABLE_DEPRECATION_WARNINGS endif / * FF_API_XVMC * / return 0 ; }",0
"static void mpeg_decode_picture_coding_extension ( MpegEncContext * s ) { s - > full_pel[0] = s - > full_pel[1] = 0 ; s - > mpeg_f_code[0][0] = get_bits ( & s - > gb , 4 ) ; s - > mpeg_f_code[0][1] = get_bits ( & s - > gb , 4 ) ; s - > mpeg_f_code[1][0] = get_bits ( & s - > gb , 4 ) ; s - > mpeg_f_code[1][1] = get_bits ( & s - > gb , 4 ) ; s - > intra_dc_precision = get_bits ( & s - > gb , 2 ) ; s - > picture_structure = get_bits ( & s - > gb , 2 ) ; s - > top_field_first = get_bits1 ( & s - > gb ) ; s - > frame_pred_frame_dct = get_bits1 ( & s - > gb ) ; s - > concealment_motion_vectors = get_bits1 ( & s - > gb ) ; s - > q_scale_type = get_bits1 ( & s - > gb ) ; s - > intra_vlc_format = get_bits1 ( & s - > gb ) ; s - > alternate_scan = get_bits1 ( & s - > gb ) ; s - > repeat_first_field = get_bits1 ( & s - > gb ) ; s - > chroma_420_type = get_bits1 ( & s - > gb ) ; s - > progressive_frame = get_bits1 ( & s - > gb ) ; / * composite display not parsed * / dprintf ( intra_dc_precion=%d\n , s - > intra_dc_precision ) ; dprintf ( picture_structure=%d\n , s - > picture_structure ) ; dprintf ( conceal=%d\n , s - > concealment_motion_vectors ) ; dprintf ( intra_vlc_format=%d\n , s - > intra_vlc_format ) ; dprintf ( alternate_scan=%d\n , s - > alternate_scan ) ; dprintf ( frame_pred_frame_dct=%d\n , s - > frame_pred_frame_dct ) ; }",1
"static int mpegvideo_probe ( AVProbeData * p ) { uint32_t code= - 1 ; int pic=0 , seq=0 , slice=0 , pspack=0 , vpes=0 , apes=0 , res=0 , sicle=0 ; int i ; uint32_t last = 0 ; for ( i=0 ; i < p - > buf_size ; i + + ) { code = ( code < < 8 ) + p - > buf[i] ; if ( ( code & 0xffffff00 ) == 0x100 ) { switch ( code ) { case SEQ_START_CODE : seq + + ; break ; case PICTURE_START_CODE : pic + + ; break ; case PACK_START_CODE : pspack + + ; break ; case 0x1b6 : res + + ; break ; } if ( code > = SLICE_START_CODE & & code < = 0x1af ) { if ( last > = SLICE_START_CODE & & last < = 0x1af ) { if ( code > = last ) slice + + ; else sicle + + ; } else { if ( code == SLICE_START_CODE ) slice + + ; else sicle + + ; } } if ( ( code & 0x1f0 ) == VIDEO_ID ) vpes + + ; else if ( ( code & 0x1e0 ) == AUDIO_ID ) apes + + ; last = code ; } } if ( seq & & seq * 9 < =pic * 10 & & pic * 9 < =slice * 10 & & ! pspack & & ! apes & & ! res & & slice > sicle ) { if ( vpes ) return AVPROBE_SCORE_EXTENSION / 4 ; else return pic > 1 ? AVPROBE_SCORE_EXTENSION + 1 : AVPROBE_SCORE_EXTENSION / 2 ; // + 1 for . mpg } return 0 ; }",1
"static void filter ( MpegAudioContext * s , int ch , short * samples , int incr ) { short * p , * q ; int sum , offset , i , j , norm , n ; short tmp[64] ; int tmp1[32] ; int * out ; // print_pow1 ( samples , 1152 ) ; offset = s - > samples_offset[ch] ; out = & s - > sb_samples[ch][0][0][0] ; for ( j=0 ; j < 36 ; j + + ) { / * 32 samples at once * / for ( i=0 ; i < 32 ; i + + ) { s - > samples_buf[ch][offset + ( 31 - i ) ] = samples[0] ; samples + = incr ; } / * filter * / p = s - > samples_buf[ch] + offset ; q = filter_bank ; / * maxsum = 23169 * / for ( i=0 ; i < 64 ; i + + ) { sum = p[0 * 64] * q[0 * 64] ; sum + = p[1 * 64] * q[1 * 64] ; sum + = p[2 * 64] * q[2 * 64] ; sum + = p[3 * 64] * q[3 * 64] ; sum + = p[4 * 64] * q[4 * 64] ; sum + = p[5 * 64] * q[5 * 64] ; sum + = p[6 * 64] * q[6 * 64] ; sum + = p[7 * 64] * q[7 * 64] ; tmp[i] = sum > > 14 ; p + + ; q + + ; } tmp1[0] = tmp[16] ; for ( i=1 ; i < =16 ; i + + ) tmp1[i] = tmp[i + 16] + tmp[16 - i] ; for ( i=17 ; i < =31 ; i + + ) tmp1[i] = tmp[i + 16] - tmp[80 - i] ; / * integer IDCT 32 with normalization . XXX : There may be some overflow left * / norm = 0 ; for ( i=0 ; i < 32 ; i + + ) { norm |= abs ( tmp1[i] ) ; } n = av_log2 ( norm ) - 12 ; if ( n > 0 ) { for ( i=0 ; i < 32 ; i + + ) tmp1[i] > > = n ; } else { n = 0 ; } idct32 ( out , tmp1 , s - > sblimit , n ) ; / * advance of 32 samples * / offset - = 32 ; out + = 32 ; / * handle the wrap around * / if ( offset < 0 ) { memmove ( s - > samples_buf[ch] + SAMPLES_BUF_SIZE - ( 512 - 32 ) , s - > samples_buf[ch] , ( 512 - 32 ) * 2 ) ; offset = SAMPLES_BUF_SIZE - 512 ; } } s - > samples_offset[ch] = offset ; // print_pow ( s - > sb_samples , 1152 ) ; }",1
"static int get_std_framerate ( int i ) { if ( i < 60 * 12 ) return i * 1001 ; else return ( ( const int[] ) { 24 , 30 , 60 , 12 , 15 , 48 } ) [i - 60 * 12] * 1000 * 12 ; }",0
"void ff_jpeg2000_cleanup ( Jpeg2000Component * comp , Jpeg2000CodingStyle * codsty ) { int reslevelno , bandno , precno ; for ( reslevelno = 0 ; comp - > reslevel & & reslevelno < codsty - > nreslevels ; reslevelno + + ) { Jpeg2000ResLevel * reslevel = comp - > reslevel + reslevelno ; for ( bandno = 0 ; bandno < reslevel - > nbands ; bandno + + ) { Jpeg2000Band * band = reslevel - > band + bandno ; for ( precno = 0 ; precno < reslevel - > num_precincts_x * reslevel - > num_precincts_y ; precno + + ) { Jpeg2000Prec * prec = band - > prec + precno ; av_freep ( & prec - > zerobits ) ; av_freep ( & prec - > cblkincl ) ; av_freep ( & prec - > cblk ) ; } av_freep ( & band - > prec ) ; } av_freep ( & reslevel - > band ) ; } ff_dwt_destroy ( & comp - > dwt ) ; av_freep ( & comp - > reslevel ) ; av_freep ( & comp - > i_data ) ; av_freep ( & comp - > f_data ) ; }",0
"static void filter ( struct vf_priv_s * p , uint8_t * dst[3] , uint8_t * src[3] , int dst_stride[3] , int src_stride[3] , int width , int height ) { int x , y , i ; for ( i=0 ; i < 3 ; i + + ) { p - > frame - > data[i]= src[i] ; p - > frame - > linesize[i]= src_stride[i] ; } p - > avctx_enc - > me_cmp= p - > avctx_enc - > me_sub_cmp= FF_CMP_SAD / * | ( p - > parity ? FF_CMP_ODD : FF_CMP_EVEN ) * / ; p - > frame - > quality= p - > qp * FF_QP2LAMBDA ; avcodec_encode_video ( p - > avctx_enc , p - > outbuf , p - > outbuf_size , p - > frame ) ; p - > frame_dec = p - > avctx_enc - > coded_frame ; for ( i=0 ; i < 3 ; i + + ) { int is_chroma= ! ! i ; int w= width > > is_chroma ; int h= height > > is_chroma ; int fils= p - > frame_dec - > linesize[i] ; int srcs= src_stride[i] ; for ( y=0 ; y < h ; y + + ) { if ( ( y p - > parity ) & 1 ) { for ( x=0 ; x < w ; x + + ) { if ( ( x - 2 ) + ( y - 1 ) * w > =0 & & ( x + 2 ) + ( y + 1 ) * w < w * h ) { //FIXME either alloc larger images or optimize this uint8_t * filp= & p - > frame_dec - > data[i][x + y * fils] ; uint8_t * srcp= & src[i][x + y * srcs] ; int diff0= filp[ - fils] - srcp[ - srcs] ; int diff1= filp[ + fils] - srcp[ + srcs] ; int spatial_score= ABS ( srcp[ - srcs - 1] - srcp[ + srcs - 1] ) + ABS ( srcp[ - srcs ] - srcp[ + srcs ] ) + ABS ( srcp[ - srcs + 1] - srcp[ + srcs + 1] ) - 1 ; int temp= filp[0] ; define CHECK ( j ) \ { int score= ABS ( srcp[ - srcs - 1 + ( j ) ] - srcp[ + srcs - 1 - ( j ) ] ) \ + ABS ( srcp[ - srcs + ( j ) ] - srcp[ + srcs - ( j ) ] ) \ + ABS ( srcp[ - srcs + 1 + ( j ) ] - srcp[ + srcs + 1 - ( j ) ] ) ; \ if ( score < spatial_score ) { \ spatial_score= score ; \ diff0= filp[ - fils + ( j ) ] - srcp[ - srcs + ( j ) ] ; \ diff1= filp[ + fils - ( j ) ] - srcp[ + srcs - ( j ) ] ; CHECK ( - 1 ) CHECK ( - 2 ) } } } } CHECK ( 1 ) CHECK ( 2 ) } } } }",0
"static int apc_read_packet ( AVFormatContext * s , AVPacket * pkt ) { if ( av_get_packet ( s - > pb , pkt , MAX_READ_SIZE ) < = 0 ) return AVERROR ( EIO ) ; pkt - > stream_index = 0 ; return 0 ; }",1
"static int dvbsub_decode ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; DVBSubContext * ctx = avctx - > priv_data ; AVSubtitle * sub = data ; const uint8_t * p , * p_end ; int segment_type ; int page_id ; int segment_length ; int i ; av_dlog ( avctx , DVB sub packet : \n ) ; for ( i=0 ; i < buf_size ; i + + ) { av_dlog ( avctx , %02x , buf[i] ) ; if ( i % 16 == 15 ) av_dlog ( avctx , \n ) ; } if ( i % 16 ) av_dlog ( avctx , \n ) ; if ( buf_size < = 6 || * buf ! = 0x0f ) { av_dlog ( avctx , incomplete or broken packet ) ; return - 1 ; } p = buf ; p_end = buf + buf_size ; while ( p_end - p > = 6 & & * p == 0x0f ) { p + = 1 ; segment_type = * p + + ; page_id = AV_RB16 ( p ) ; p + = 2 ; segment_length = AV_RB16 ( p ) ; p + = 2 ; if ( p_end - p < segment_length ) { av_dlog ( avctx , incomplete or broken packet ) ; return - 1 ; } if ( page_id == ctx - > composition_id || page_id == ctx - > ancillary_id || ctx - > composition_id == - 1 || ctx - > ancillary_id == - 1 ) { switch ( segment_type ) { case DVBSUB_PAGE_SEGMENT : dvbsub_parse_page_segment ( avctx , p , segment_length ) ; break ; case DVBSUB_REGION_SEGMENT : dvbsub_parse_region_segment ( avctx , p , segment_length ) ; break ; case DVBSUB_CLUT_SEGMENT : dvbsub_parse_clut_segment ( avctx , p , segment_length ) ; break ; case DVBSUB_OBJECT_SEGMENT : dvbsub_parse_object_segment ( avctx , p , segment_length ) ; break ; case DVBSUB_DISPLAYDEFINITION_SEGMENT : dvbsub_parse_display_definition_segment ( avctx , p , segment_length ) ; break ; case DVBSUB_DISPLAY_SEGMENT : * data_size = dvbsub_display_end_segment ( avctx , p , segment_length , sub ) ; break ; default : av_dlog ( avctx , Subtitling segment type 0x%x , page id %d , length %d\n , segment_type , page_id , segment_length ) ; break ; } } p + = segment_length ; } return p - buf ; }",0
"static int mov_read_trak ( MOVContext * c , ByteIOContext * pb , MOV_atom_t atom ) { AVStream * st ; MOVStreamContext * sc ; int ret ; st = av_new_stream ( c - > fc , c - > fc - > nb_streams ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; sc = av_mallocz ( sizeof ( MOVStreamContext ) ) ; if ( ! sc ) return AVERROR ( ENOMEM ) ; st - > priv_data = sc ; st - > codec - > codec_type = CODEC_TYPE_DATA ; st - > start_time = 0 ; / * XXX : check * / if ( ( ret = mov_read_default ( c , pb , atom ) ) < 0 ) return ret ; / * sanity checks * / if ( sc - > chunk_count & & ( ! sc - > stts_count || ! sc - > sample_to_chunk_sz || ( ! sc - > sample_size & & ! sc - > sample_count ) ) ) { av_log ( c - > fc , AV_LOG_ERROR , stream %d , missing mandatory atoms , broken header\n , st - > index ) ; sc - > sample_count = 0 ; //ignore track return 0 ; } if ( ! sc - > time_rate ) sc - > time_rate=1 ; if ( ! sc - > time_scale ) sc - > time_scale= c - > time_scale ; av_set_pts_info ( st , 64 , sc - > time_rate , sc - > time_scale ) ; if ( st - > codec - > codec_type == CODEC_TYPE_AUDIO & & ! st - > codec - > frame_size & & sc - > stts_count == 1 ) st - > codec - > frame_size = av_rescale ( sc - > time_rate , st - > codec - > sample_rate , sc - > time_scale ) ; if ( st - > duration ! = AV_NOPTS_VALUE ) { assert ( st - > duration % sc - > time_rate == 0 ) ; st - > duration /= sc - > time_rate ; } sc - > ffindex = st - > index ; mov_build_index ( c , st ) ; if ( sc - > dref_id - 1 < sc - > drefs_count & & sc - > drefs[sc - > dref_id - 1] . path ) { if ( url_fopen ( & sc - > pb , sc - > drefs[sc - > dref_id - 1] . path , URL_RDONLY ) < 0 ) av_log ( c - > fc , AV_LOG_ERROR , stream %d , error opening file %s : %s\n , st - > index , sc - > drefs[sc - > dref_id - 1] . path , strerror ( errno ) ) ; } else sc - > pb = c - > fc - > pb ; switch ( st - > codec - > codec_id ) { ifdef CONFIG_H261_DECODER case CODEC_ID_H261 : endif ifdef CONFIG_H263_DECODER case CODEC_ID_H263 : endif ifdef CONFIG_MPEG4_DECODER case CODEC_ID_MPEG4 : endif st - > codec - > width= 0 ; / * let decoder init width/height * / st - > codec - > height= 0 ; break ; ifdef CONFIG_VORBIS_DECODER case CODEC_ID_VORBIS : endif st - > codec - > sample_rate= 0 ; / * let decoder init parameters properly * / break ; } / * Do not need those anymore . * / av_freep ( & sc - > chunk_offsets ) ; av_freep ( & sc - > sample_to_chunk ) ; av_freep ( & sc - > sample_sizes ) ; av_freep ( & sc - > keyframes ) ; av_freep ( & sc - > stts_data ) ; return 0 ; }",0
"static int sdp_parse ( AVFormatContext * s , const char * content ) { const char * p ; int letter ; / * Some SDP lines , particularly for Realmedia or ASF RTSP streams , * contain long SDP lines containing complete ASF Headers ( several * kB ) or arrays of MDPR ( RM stream descriptor ) headers plus * rulebooks describing their properties . Therefore , the SDP line * buffer is large . * * The Vorbis FMTP line can be up to 16KB - see sdp_parse_fmtp . * / char buf[16384] , * q ; SDPParseState sdp_parse_state , * s1 = & sdp_parse_state ; memset ( s1 , 0 , sizeof ( SDPParseState ) ) ; p = content ; for ( ; ; ) { skip_spaces ( & p ) ; letter = * p ; if ( letter == ' \0 ' ) break ; p + + ; if ( * p ! = ' = ' ) goto next_line ; p + + ; / * get the content * / q = buf ; while ( * p ! = ' \n ' & & * p ! = ' \r ' & & * p ! = ' \0 ' ) { if ( ( q - buf ) < sizeof ( buf ) - 1 ) * q + + = * p ; p + + ; } * q = ' \0 ' ; sdp_parse_line ( s , s1 , letter , buf ) ; next_line : while ( * p ! = ' \n ' & & * p ! = ' \0 ' ) p + + ; if ( * p == ' \n ' ) p + + ; } return 0 ; }",0
"static void flush_change ( H264Context * h ) { h - > outputed_poc = h - > next_outputed_poc = INT_MIN ; h - > prev_interlaced_frame = 1 ; idr ( h ) ; h - > prev_frame_num = - 1 ; if ( h - > s . current_picture_ptr ) h - > s . current_picture_ptr - > f . reference = 0 ; h - > s . first_field = 0 ; memset ( h - > ref_list[0] , 0 , sizeof ( h - > ref_list[0] ) ) ; memset ( h - > ref_list[1] , 0 , sizeof ( h - > ref_list[1] ) ) ; memset ( h - > default_ref_list[0] , 0 , sizeof ( h - > default_ref_list[0] ) ) ; memset ( h - > default_ref_list[1] , 0 , sizeof ( h - > default_ref_list[1] ) ) ; ff_h264_reset_sei ( h ) ; h - > recovery_frame= - 1 ; h - > sync= 0 ; h - > list_count = 0 ; h - > current_slice = 0 ; }",1
"static ResampleContext * resample_init ( ResampleContext * c , int out_rate , int in_rate , int filter_size , int phase_shift , int linear , double cutoff0 , enum AVSampleFormat format , enum SwrFilterType filter_type , int kaiser_beta , double precision , int cheby ) { double cutoff = cutoff0 ? cutoff0 : 0 . 97 ; double factor= FFMIN ( out_rate * cutoff / in_rate , 1 . 0 ) ; int phase_count= 1 < < phase_shift ; if ( ! c || c - > phase_shift ! = phase_shift || c - > linear ! =linear || c - > factor ! = factor || c - > filter_length ! = FFMAX ( ( int ) ceil ( filter_size/factor ) , 1 ) || c - > format ! = format || c - > filter_type ! = filter_type || c - > kaiser_beta ! = kaiser_beta ) { c = av_mallocz ( sizeof ( * c ) ) ; if ( ! c ) return NULL ; c - > format= format ; c - > felem_size= av_get_bytes_per_sample ( c - > format ) ; switch ( c - > format ) { case AV_SAMPLE_FMT_S16P : c - > filter_shift = 15 ; break ; case AV_SAMPLE_FMT_S32P : c - > filter_shift = 30 ; break ; case AV_SAMPLE_FMT_FLTP : case AV_SAMPLE_FMT_DBLP : c - > filter_shift = 0 ; break ; default : av_log ( NULL , AV_LOG_ERROR , Unsupported sample format\n ) ; av_assert0 ( 0 ) ; c - > phase_shift = phase_shift ; c - > phase_mask = phase_count - 1 ; c - > linear = linear ; c - > factor = factor ; c - > filter_length = FFMAX ( ( int ) ceil ( filter_size/factor ) , 1 ) ; c - > filter_alloc = FFALIGN ( c - > filter_length , 8 ) ; c - > filter_bank = av_calloc ( c - > filter_alloc , ( phase_count + 1 ) * c - > felem_size ) ; c - > filter_type = filter_type ; c - > kaiser_beta = kaiser_beta ; if ( ! c - > filter_bank ) if ( build_filter ( c , ( void * ) c - > filter_bank , factor , c - > filter_length , c - > filter_alloc , phase_count , 1 < < c - > filter_shift , filter_type , kaiser_beta ) ) memcpy ( c - > filter_bank + ( c - > filter_alloc * phase_count + 1 ) * c - > felem_size , c - > filter_bank , ( c - > filter_alloc - 1 ) * c - > felem_size ) ; memcpy ( c - > filter_bank + ( c - > filter_alloc * phase_count ) * c - > felem_size , c - > filter_bank + ( c - > filter_alloc - 1 ) * c - > felem_size , c - > felem_size ) ; c - > compensation_distance= 0 ; if ( ! av_reduce ( & c - > src_incr , & c - > dst_incr , out_rate , in_rate * ( int64_t ) phase_count , INT32_MAX/2 ) ) c - > ideal_dst_incr= c - > dst_incr ; c - > index= - phase_count * ( ( c - > filter_length - 1 ) /2 ) ; c - > frac= 0 ; return c ; error : av_freep ( & c - > filter_bank ) ; av_free ( c ) ; return NULL ;",1
"static int decode_packet ( AVCodecContext * avctx , void * data , int * got_frame_ptr , AVPacket * avpkt ) { WmallDecodeCtx * s = avctx - > priv_data ; GetBitContext * gb = & s - > pgb ; const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; int num_bits_prev_frame , packet_sequence_number , spliced_packet ; s - > frame . nb_samples = 0 ; if ( s - > packet_done || s - > packet_loss ) { s - > packet_done = 0 ; / * sanity check for the buffer length * / if ( buf_size < avctx - > block_align ) return 0 ; s - > next_packet_start = buf_size - avctx - > block_align ; buf_size = avctx - > block_align ; s - > buf_bit_size = buf_size < < 3 ; / * parse packet header * / init_get_bits ( gb , buf , s - > buf_bit_size ) ; packet_sequence_number = get_bits ( gb , 4 ) ; skip_bits ( gb , 1 ) ; // Skip seekable_frame_in_packet , currently ununused spliced_packet = get_bits1 ( gb ) ; if ( spliced_packet ) avpriv_request_sample ( avctx , Bitstream splicing ) ; / * get number of bits that need to be added to the previous frame * / num_bits_prev_frame = get_bits ( gb , s - > log2_frame_size ) ; / * check for packet loss * / if ( ! s - > packet_loss & & ( ( s - > packet_sequence_number + 1 ) & 0xF ) ! = packet_sequence_number ) { s - > packet_loss = 1 ; av_log ( avctx , AV_LOG_ERROR , Packet loss detected ! seq %x vs %x\n , s - > packet_sequence_number , packet_sequence_number ) ; } s - > packet_sequence_number = packet_sequence_number ; if ( num_bits_prev_frame > 0 ) { int remaining_packet_bits = s - > buf_bit_size - get_bits_count ( gb ) ; if ( num_bits_prev_frame > = remaining_packet_bits ) { num_bits_prev_frame = remaining_packet_bits ; s - > packet_done = 1 ; } / * Append the previous frame data to the remaining data from the * previous packet to create a full frame . * / save_bits ( s , gb , num_bits_prev_frame , 1 ) ; / * decode the cross packet frame if it is valid * / if ( num_bits_prev_frame < remaining_packet_bits & & ! s - > packet_loss ) decode_frame ( s ) ; } else if ( s - > num_saved_bits - s - > frame_offset ) { av_dlog ( avctx , ignoring %x previously saved bits\n , s - > num_saved_bits - s - > frame_offset ) ; } if ( s - > packet_loss ) { / * Reset number of saved bits so that the decoder does not start * to decode incomplete frames in the s - > len_prefix == 0 case . * / s - > num_saved_bits = 0 ; s - > packet_loss = 0 ; init_put_bits ( & s - > pb , s - > frame_data , MAX_FRAMESIZE ) ; } } else { int frame_size ; s - > buf_bit_size = ( avpkt - > size - s - > next_packet_start ) < < 3 ; init_get_bits ( gb , avpkt - > data , s - > buf_bit_size ) ; skip_bits ( gb , s - > packet_offset ) ; if ( s - > len_prefix & & remaining_bits ( s , gb ) > s - > log2_frame_size & & ( frame_size = show_bits ( gb , s - > log2_frame_size ) ) & & frame_size < = remaining_bits ( s , gb ) ) { save_bits ( s , gb , frame_size , 0 ) ; s - > packet_done = ! decode_frame ( s ) ; } else if ( ! s - > len_prefix & & s - > num_saved_bits > get_bits_count ( & s - > gb ) ) { / * when the frames do not have a length prefix , we don ' t know the * compressed length of the individual frames however , we know what * part of a new packet belongs to the previous frame therefore we * save the incoming packet first , then we append the previous * frame data from the next packet so that we get a buffer that * only contains full frames * / s - > packet_done = ! decode_frame ( s ) ; } else { s - > packet_done = 1 ; } } if ( s - > packet_done & & ! s - > packet_loss & & remaining_bits ( s , gb ) > 0 ) { / * save the rest of the data so that it can be decoded * with the next packet * / save_bits ( s , gb , remaining_bits ( s , gb ) , 0 ) ; } * ( AVFrame * ) data = s - > frame ; * got_frame_ptr = s - > frame . nb_samples > 0 ; s - > packet_offset = get_bits_count ( gb ) & 7 ; return ( s - > packet_loss ) ? AVERROR_INVALIDDATA : get_bits_count ( gb ) > > 3 ; }",1
"static void mpegts_write_pes ( AVFormatContext * s , AVStream * st , const uint8_t * payload , int payload_size , int64_t pts , int64_t dts , int key ) { MpegTSWriteStream * ts_st = st - > priv_data ; MpegTSWrite * ts = s - > priv_data ; uint8_t buf[TS_PACKET_SIZE] ; uint8_t * q ; int val , is_start , len , header_len , write_pcr , is_dvb_subtitle , is_dvb_teletext , flags ; int afc_len , stuffing_len ; int64_t pcr = - 1 ; / * avoid warning * / int64_t delay = av_rescale ( s - > max_delay , 90000 , AV_TIME_BASE ) ; int force_pat = st - > codec - > codec_type == AVMEDIA_TYPE_VIDEO & & key & & ! ts_st - > prev_payload_key ; is_start = 1 ; while ( payload_size > 0 ) { retransmit_si_info ( s , force_pat ) ; force_pat = 0 ; write_pcr = 0 ; if ( ts_st - > pid == ts_st - > service - > pcr_pid ) { if ( ts - > mux_rate > 1 || is_start ) // VBR pcr period is based on frames ts_st - > service - > pcr_packet_count + + ; if ( ts_st - > service - > pcr_packet_count > = ts_st - > service - > pcr_packet_period ) { ts_st - > service - > pcr_packet_count = 0 ; write_pcr = 1 ; if ( ts - > mux_rate > 1 & & dts ! = AV_NOPTS_VALUE & & ( dts - get_pcr ( ts , s - > pb ) /300 ) > delay ) { / * pcr insert gets priority over null packet insert * / if ( write_pcr ) mpegts_insert_pcr_only ( s , st ) ; else mpegts_insert_null_packet ( s ) ; continue ; / * recalculate write_pcr and possibly retransmit si_info * / / * prepare packet header * / q = buf ; * q + + = 0x47 ; val = ( ts_st - > pid > > 8 ) ; if ( is_start ) val |= 0x40 ; * q + + = val ; * q + + = ts_st - > pid ; ts_st - > cc = ( ts_st - > cc + 1 ) & 0xf ; * q + + = 0x10 | ts_st - > cc ; // payload indicator + CC if ( key & & is_start & & pts ! = AV_NOPTS_VALUE ) { // set Random Access for key frames if ( ts_st - > pid == ts_st - > service - > pcr_pid ) write_pcr = 1 ; set_af_flag ( buf , 0x40 ) ; q = get_ts_payload_start ( buf ) ; if ( write_pcr ) { set_af_flag ( buf , 0x10 ) ; q = get_ts_payload_start ( buf ) ; // add 11 , pcr references the last byte of program clock reference base if ( ts - > mux_rate > 1 ) pcr = get_pcr ( ts , s - > pb ) ; else pcr = ( dts - delay ) * 300 ; if ( dts ! = AV_NOPTS_VALUE & & dts < pcr / 300 ) av_log ( s , AV_LOG_WARNING , dts < pcr , TS is invalid\n ) ; extend_af ( buf , write_pcr_bits ( q , pcr ) ) ; q = get_ts_payload_start ( buf ) ; if ( is_start ) { int pes_extension = 0 ; int pes_header_stuffing_bytes = 0 ; / * write PES header * / * q + + = 0x00 ; * q + + = 0x00 ; * q + + = 0x01 ; is_dvb_subtitle = 0 ; is_dvb_teletext = 0 ; if ( st - > codec - > codec_id == AV_CODEC_ID_DIRAC ) { * q + + = 0xfd ; } else * q + + = 0xe0 ; } else if ( st - > codec - > codec_type == AVMEDIA_TYPE_AUDIO & & ( st - > codec - > codec_id == AV_CODEC_ID_MP2 || st - > codec - > codec_id == AV_CODEC_ID_MP3 || st - > codec - > codec_id == AV_CODEC_ID_AAC ) ) { * q + + = 0xc0 ; } else if ( st - > codec - > codec_type == AVMEDIA_TYPE_AUDIO & & st - > codec - > codec_id == AV_CODEC_ID_AC3 & & ts - > m2ts_mode ) { * q + + = 0xfd ; } else { * q + + = 0xbd ; if ( st - > codec - > codec_type == AVMEDIA_TYPE_SUBTITLE ) { if ( st - > codec - > codec_id == AV_CODEC_ID_DVB_SUBTITLE ) { is_dvb_subtitle = 1 ; } else if ( st - > codec - > codec_id == AV_CODEC_ID_DVB_TELETEXT ) { is_dvb_teletext = 1 ; header_len = 0 ; flags = 0 ; if ( pts ! = AV_NOPTS_VALUE ) { header_len + = 5 ; flags |= 0x80 ; if ( dts ! = AV_NOPTS_VALUE & & pts ! = AV_NOPTS_VALUE & & dts ! = pts ) { header_len + = 5 ; flags |= 0x40 ; if ( st - > codec - > codec_type == AVMEDIA_TYPE_VIDEO & & st - > codec - > codec_id == AV_CODEC_ID_DIRAC ) { / * set PES_extension_flag * / pes_extension = 1 ; flags |= 0x01 ; / * * One byte for PES2 extension flag + * one byte for extension length + * one byte for extension id * / header_len + = 3 ; / * for Blu - ray AC3 Audio the PES Extension flag should be as follow * otherwise it will not play sound on blu - ray * / if ( ts - > m2ts_mode & & st - > codec - > codec_type == AVMEDIA_TYPE_AUDIO & & st - > codec - > codec_id == AV_CODEC_ID_AC3 ) { / * set PES_extension_flag * / pes_extension = 1 ; flags |= 0x01 ; header_len + = 3 ; if ( is_dvb_teletext ) { pes_header_stuffing_bytes = 0x24 - header_len ; header_len = 0x24 ; len = payload_size + header_len + 3 ; / * 3 extra bytes should be added to DVB subtitle payload : 0x20 0x00 at the beginning and trailing 0xff * / if ( is_dvb_subtitle ) { len + = 3 ; payload_size + + ; if ( len > 0xffff ) * q + + = len > > 8 ; * q + + = len ; val = 0x80 ; / * data alignment indicator is required for subtitle and data streams * / if ( st - > codec - > codec_type == AVMEDIA_TYPE_SUBTITLE || st - > codec - > codec_type == AVMEDIA_TYPE_DATA ) val |= 0x04 ; * q + + = val ; * q + + = flags ; * q + + = header_len ; if ( pts ! = AV_NOPTS_VALUE ) { write_pts ( q , flags > > 6 , pts ) ; q + = 5 ; if ( dts ! = AV_NOPTS_VALUE & & pts ! = AV_NOPTS_VALUE & & dts ! = pts ) { write_pts ( q , 1 , dts ) ; q + =",1
"static void RENAME ( postProcess ) ( const uint8_t src[] , int srcStride , uint8_t dst[] , int dstStride , int width , int height , const QP_STORE_T QPs[] , int QPStride , int isColor , PPContext * c2 ) { DECLARE_ALIGNED ( 8 , PPContext , c ) = * c2 ; //copy to stack for faster access int x , y ; ifdef TEMPLATE_PP_TIME_MODE const int mode= TEMPLATE_PP_TIME_MODE ; else const int mode= isColor ? c . ppMode . chromMode : c . ppMode . lumMode ; endif int black=0 , white=255 ; // blackest black and whitest white in the picture int QPCorrecture= 256 * 256 ; int copyAhead ; if TEMPLATE_PP_MMX int i ; endif const int qpHShift= isColor ? 4 - c . hChromaSubSample : 4 ; const int qpVShift= isColor ? 4 - c . vChromaSubSample : 4 ; //FIXME remove uint64_t * const yHistogram= c . yHistogram ; uint8_t * const tempSrc= srcStride > 0 ? c . tempSrc : c . tempSrc - 23 * srcStride ; uint8_t * const tempDst= ( dstStride > 0 ? c . tempDst : c . tempDst - 23 * dstStride ) + 32 ; //const int mbWidth= isColor ? ( width + 7 ) > > 3 : ( width + 15 ) > > 4 ; if ( mode & VISUALIZE ) { if ( ! ( mode & ( V_A_DEBLOCK | H_A_DEBLOCK ) ) || TEMPLATE_PP_MMX ) { av_log ( c2 , AV_LOG_WARNING , Visualization is currently only supported with the accurate deblock filter without SIMD\n ) ; } } if TEMPLATE_PP_MMX for ( i=0 ; i < 57 ; i + + ) { int offset= ( ( i * c . ppMode . baseDcDiff ) > > 8 ) + 1 ; int threshold= offset * 2 + 1 ; c . mmxDcOffset[i]= 0x7F - offset ; c . mmxDcThreshold[i]= 0x7F - threshold ; c . mmxDcOffset[i] * = 0x0101010101010101LL ; c . mmxDcThreshold[i] * = 0x0101010101010101LL ; } endif if ( mode & CUBIC_IPOL_DEINT_FILTER ) copyAhead=16 ; else if ( ( mode & LINEAR_BLEND_DEINT_FILTER ) || ( mode & FFMPEG_DEINT_FILTER ) || ( mode & LOWPASS5_DEINT_FILTER ) ) copyAhead=14 ; else if ( ( mode & V_DEBLOCK ) || ( mode & LINEAR_IPOL_DEINT_FILTER ) || ( mode & MEDIAN_DEINT_FILTER ) || ( mode & V_A_DEBLOCK ) ) copyAhead=13 ; else if ( mode & V_X1_FILTER ) copyAhead=11 ; // else if ( mode & V_RK1_FILTER ) copyAhead=10 ; else if ( mode & DERING ) copyAhead=9 ; else copyAhead=8 ; copyAhead - = 8 ; if ( ! isColor ) { uint64_t sum= 0 ; int i ; uint64_t maxClipped ; uint64_t clipped ; double scale ; c . frameNum + + ; // first frame is fscked so we ignore it if ( c . frameNum == 1 ) yHistogram[0]= width * ( uint64_t ) height/64 * 15/256 ; for ( i=0 ; i < 256 ; i + + ) { sum + = yHistogram[i] ; } / * We always get a completely black picture first . * / maxClipped= ( uint64_t ) ( sum * c . ppMode . maxClippedThreshold ) ; clipped= sum ; for ( black=255 ; black > 0 ; black - - ) { if ( clipped < maxClipped ) break ; clipped - = yHistogram[black] ; } clipped= sum ; for ( white=0 ; white < 256 ; white + + ) { if ( clipped < maxClipped ) break ; clipped - = yHistogram[white] ; } scale= ( double ) ( c . ppMode . maxAllowedY - c . ppMode . minAllowedY ) / ( double ) ( white - black ) ; if TEMPLATE_PP_MMXEXT c . packedYScale= ( uint16_t ) ( scale * 256 . 0 + 0 . 5 ) ; c . packedYOffset= ( ( ( black * c . packedYScale ) > > 8 ) - c . ppMode . minAllowedY ) & 0xFFFF ; else c . packedYScale= ( uint16_t ) ( scale * 1024 . 0 + 0 . 5 ) ; c . packedYOffset= ( black - c . ppMode . minAllowedY ) & 0xFFFF ; endif c . packedYOffset|= c . packedYOffset < < 32 ; c . packedYOffset|= c . packedYOffset < < 16 ; c . packedYScale|= c . packedYScale < < 32 ; c . packedYScale|= c . packedYScale < < 16 ; if ( mode & LEVEL_FIX ) QPCorrecture= ( int ) ( scale * 256 * 256 + 0 . 5 ) ; else QPCorrecture= 256 * 256 ; } else { c . packedYScale= 0x0100010001000100LL ; c . packedYOffset= 0 ; QPCorrecture= 256 * 256 ; } / * copy & deinterlace first row of blocks * / y= - BLOCK_SIZE ; { const uint8_t * srcBlock= & ( src[y * srcStride] ) ; uint8_t * dstBlock= tempDst + dstStride ; // From this point on it is guaranteed that we can read and write 16 lines downward // finish 1 block before the next otherwise we might have a problem // with the L1 Cache of the P4 . . . or only a few blocks at a time or something for ( x=0 ; x < width ; x + =BLOCK_SIZE ) { if TEMPLATE_PP_MMXEXT & & HAVE_6REGS / * prefetchnta ( srcBlock + ( ( ( x > > 2 ) & 6 ) + 5 ) * srcStride + 32 ) ; prefetchnta ( srcBlock + ( ( ( x > > 2 ) & 6 ) + 6 ) * srcStride + 32 ) ; prefetcht0 ( dstBlock + ( ( ( x > > 2 ) & 6 ) + 5 ) * dstStride + 32 ) ; prefetcht0 ( dstBlock + ( ( ( x > > 2 ) & 6 ) + 6 ) * dstStride + 32 ) ; * / __asm__ ( mov %4 , %% REG_a \n\t shr 2 , %% REG_a \n\t and 6 , %% REG_a \n\t add %5 , %% REG_a \n\t mov %% REG_a , %% REG_d \n\t imul %1 , %% REG_a \n\t imul %3 , %% REG_d \n\t prefetchnta 32 ( %% REG_a , %0 ) \n\t prefetcht0 32 ( %% REG_d , %2 ) \n\t add %1 , %% REG_a \n\t add %3 , %% REG_d \n\t prefetchnta 32 ( %% REG_a , %0 ) \n\t prefetcht0 32 ( %% REG_d , %2 ) \n\t : : r ( srcBlock ) , r ( ( x86_reg ) srcStride ) , r ( dstBlock ) , r ( ( x86_reg ) dstStride ) , g ( ( x86_reg ) x ) , g ( ( x86_reg ) copyAhead ) : % REG_a , % REG_d ) ; elif TEMPLATE_PP_3DNOW //FIXME check if this is faster on an 3dnow chip or if it is faster without the prefetch or . . . / * prefetch ( srcBlock + ( ( ( x > > 3 ) & 3 ) + 5 ) * srcStride + 32 ) ; prefetch ( srcBlock + ( ( ( x > > 3 )",0
"static char * choose_pix_fmts ( OutputStream * ost ) { if ( ost - > keep_pix_fmt ) { if ( ost - > filter ) avfilter_graph_set_auto_convert ( ost - > filter - > graph - > graph , AVFILTER_AUTO_CONVERT_NONE ) ; if ( ost - > st - > codec - > pix_fmt == PIX_FMT_NONE ) return NULL ; return av_strdup ( av_get_pix_fmt_name ( ost - > st - > codec - > pix_fmt ) ) ; } if ( ost - > st - > codec - > pix_fmt ! = PIX_FMT_NONE ) { return av_strdup ( av_get_pix_fmt_name ( choose_pixel_fmt ( ost - > st , ost - > enc , ost - > st - > codec - > pix_fmt ) ) ) ; } else if ( ost - > enc - > pix_fmts ) { const enum PixelFormat * p ; AVIOContext * s = NULL ; uint8_t * ret ; int len ; if ( avio_open_dyn_buf ( & s ) < 0 ) exit_program ( 1 ) ; p = ost - > enc - > pix_fmts ; if ( ost - > st - > codec - > strict_std_compliance < = FF_COMPLIANCE_UNOFFICIAL ) { if ( ost - > st - > codec - > codec_id == CODEC_ID_MJPEG ) { p = ( const enum PixelFormat[] ) { PIX_FMT_YUVJ420P , PIX_FMT_YUVJ422P , PIX_FMT_YUV420P , PIX_FMT_YUV422P , PIX_FMT_NONE } ; } else if ( ost - > st - > codec - > codec_id == CODEC_ID_LJPEG ) { p = ( const enum PixelFormat[] ) { PIX_FMT_YUVJ420P , PIX_FMT_YUVJ422P , PIX_FMT_YUVJ444P , PIX_FMT_YUV420P , PIX_FMT_YUV422P , PIX_FMT_YUV444P , PIX_FMT_BGRA , PIX_FMT_NONE } ; } } for ( ; * p ! = PIX_FMT_NONE ; p + + ) { const char * name = av_get_pix_fmt_name ( * p ) ; avio_printf ( s , %s : , name ) ; } len = avio_close_dyn_buf ( s , & ret ) ; ret[len - 1] = 0 ; return ret ; } else return NULL ; }",1
"static av_cold int libschroedinger_encode_init ( AVCodecContext * avctx ) { SchroEncoderParams * p_schro_params = avctx - > priv_data ; SchroVideoFormatEnum preset ; / * Initialize the libraries that libschroedinger depends on . * / schro_init ( ) ; / * Create an encoder object . * / p_schro_params - > encoder = schro_encoder_new ( ) ; if ( ! p_schro_params - > encoder ) { av_log ( avctx , AV_LOG_ERROR , Unrecoverable Error : schro_encoder_new failed . ) ; return - 1 ; } / * Initialize the format . * / preset = ff_get_schro_video_format_preset ( avctx ) ; p_schro_params - > format = schro_encoder_get_video_format ( p_schro_params - > encoder ) ; schro_video_format_set_std_video_format ( p_schro_params - > format , preset ) ; p_schro_params - > format - > width = avctx - > width ; p_schro_params - > format - > height = avctx - > height ; if ( set_chroma_format ( avctx ) == - 1 ) return - 1 ; if ( avctx - > color_primaries == AVCOL_PRI_BT709 ) { p_schro_params - > format - > colour_primaries = SCHRO_COLOUR_PRIMARY_HDTV ; } else if ( avctx - > color_primaries == AVCOL_PRI_BT470BG ) { p_schro_params - > format - > colour_primaries = SCHRO_COLOUR_PRIMARY_SDTV_625 ; } else if ( avctx - > color_primaries == AVCOL_PRI_SMPTE170M ) { p_schro_params - > format - > colour_primaries = SCHRO_COLOUR_PRIMARY_SDTV_525 ; } if ( avctx - > colorspace == AVCOL_SPC_BT709 ) { p_schro_params - > format - > colour_matrix = SCHRO_COLOUR_MATRIX_HDTV ; } else if ( avctx - > colorspace == AVCOL_SPC_BT470BG ) { p_schro_params - > format - > colour_matrix = SCHRO_COLOUR_MATRIX_SDTV ; } if ( avctx - > color_trc == AVCOL_TRC_BT709 ) { p_schro_params - > format - > transfer_function = SCHRO_TRANSFER_CHAR_TV_GAMMA ; } if ( ff_get_schro_frame_format ( p_schro_params - > format - > chroma_format , & p_schro_params - > frame_format ) == - 1 ) { av_log ( avctx , AV_LOG_ERROR , This codec currently supports only planar YUV 4 : 2 : 0 , 4 : 2 : 2 and 4 : 4 : 4 formats . \n ) ; return - 1 ; } p_schro_params - > format - > frame_rate_numerator = avctx - > time_base . den ; p_schro_params - > format - > frame_rate_denominator = avctx - > time_base . num ; p_schro_params - > frame_size = avpicture_get_size ( avctx - > pix_fmt , avctx - > width , avctx - > height ) ; avctx - > coded_frame = av_frame_alloc ( ) ; if ( ! avctx - > coded_frame ) return AVERROR ( ENOMEM ) ; if ( ! avctx - > gop_size ) { schro_encoder_setting_set_double ( p_schro_params - > encoder , gop_structure , SCHRO_ENCODER_GOP_INTRA_ONLY ) ; if ( avctx - > coder_type == FF_CODER_TYPE_VLC ) schro_encoder_setting_set_double ( p_schro_params - > encoder , enable_noarith , 1 ) ; } else { schro_encoder_setting_set_double ( p_schro_params - > encoder , au_distance , avctx - > gop_size ) ; avctx - > has_b_frames = 1 ; p_schro_params - > dts = - 1 ; } / * FIXME - Need to handle SCHRO_ENCODER_RATE_CONTROL_LOW_DELAY . * / if ( avctx - > flags & CODEC_FLAG_QSCALE ) { if ( ! avctx - > global_quality ) { / * lossless coding * / schro_encoder_setting_set_double ( p_schro_params - > encoder , rate_control , SCHRO_ENCODER_RATE_CONTROL_LOSSLESS ) ; } else { int quality ; schro_encoder_setting_set_double ( p_schro_params - > encoder , rate_control , SCHRO_ENCODER_RATE_CONTROL_CONSTANT_QUALITY ) ; quality = avctx - > global_quality / FF_QP2LAMBDA ; if ( quality > 10 ) quality = 10 ; schro_encoder_setting_set_double ( p_schro_params - > encoder , quality , quality ) ; } } else { schro_encoder_setting_set_double ( p_schro_params - > encoder , rate_control , SCHRO_ENCODER_RATE_CONTROL_CONSTANT_BITRATE ) ; schro_encoder_setting_set_double ( p_schro_params - > encoder , bitrate , avctx - > bit_rate ) ; } if ( avctx - > flags & CODEC_FLAG_INTERLACED_ME ) / * All material can be coded as interlaced or progressive irrespective of the type of source material . * / schro_encoder_setting_set_double ( p_schro_params - > encoder , interlaced_coding , 1 ) ; schro_encoder_setting_set_double ( p_schro_params - > encoder , open_gop , ! ( avctx - > flags & CODEC_FLAG_CLOSED_GOP ) ) ; / * FIXME : Signal range hardcoded to 8 - bit data until both libschroedinger * and libdirac support other bit - depth data . * / schro_video_format_set_std_signal_range ( p_schro_params - > format , SCHRO_SIGNAL_RANGE_8BIT_VIDEO ) ; / * Set the encoder format . * / schro_encoder_set_video_format ( p_schro_params - > encoder , p_schro_params - > format ) ; / * Set the debug level . * / schro_debug_set_level ( avctx - > debug ) ; schro_encoder_start ( p_schro_params - > encoder ) ; / * Initialize the encoded frame queue . * / ff_schro_queue_init ( & p_schro_params - > enc_frame_queue ) ; return 0 ; }",0
"static int xiph_handle_packet ( AVFormatContext * ctx , PayloadContext * data , AVStream * st , AVPacket * pkt , uint32_t * timestamp , const uint8_t * buf , int len , uint16_t seq , int flags ) { int ident , fragmented , tdt , num_pkts , pkt_len ; if ( ! buf ) { if ( ! data - > split_buf || data - > split_pos + 2 > data - > split_buf_len || data - > split_pkts < = 0 ) { av_log ( ctx , AV_LOG_ERROR , No more data to return\n ) ; return AVERROR_INVALIDDATA ; } pkt_len = AV_RB16 ( data - > split_buf + data - > split_pos ) ; data - > split_pos + = 2 ; if ( data - > split_pos + pkt_len > data - > split_buf_len ) { av_log ( ctx , AV_LOG_ERROR , Not enough data to return\n ) ; return AVERROR_INVALIDDATA ; } if ( av_new_packet ( pkt , pkt_len ) ) { av_log ( ctx , AV_LOG_ERROR , Out of memory . \n ) ; return AVERROR ( ENOMEM ) ; } pkt - > stream_index = st - > index ; memcpy ( pkt - > data , data - > split_buf + data - > split_pos , pkt_len ) ; data - > split_pos + = pkt_len ; data - > split_pkts - - ; return data - > split_pkts > 0 ; } if ( len < 6 || len > INT_MAX/2 ) { av_log ( ctx , AV_LOG_ERROR , Invalid %d byte packet\n , len ) ; return AVERROR_INVALIDDATA ; } // read xiph rtp headers ident = AV_RB24 ( buf ) ; fragmented = buf[3] > > 6 ; tdt = ( buf[3] > > 4 ) & 3 ; num_pkts = buf[3] & 0xf ; pkt_len = AV_RB16 ( buf + 4 ) ; if ( pkt_len > len - 6 ) { av_log ( ctx , AV_LOG_ERROR , Invalid packet length %d in %d byte packet\n , pkt_len , len ) ; return AVERROR_INVALIDDATA ; } if ( ident ! = data - > ident ) { av_log ( ctx , AV_LOG_ERROR , Unimplemented Xiph SDP configuration change detected\n ) ; return AVERROR_PATCHWELCOME ; } if ( tdt ) { av_log ( ctx , AV_LOG_ERROR , Unimplemented RTP Xiph packet settings ( %d , %d , %d ) \n , fragmented , tdt , num_pkts ) ; return AVERROR_PATCHWELCOME ; } buf + = 6 ; // move past header bits len - = 6 ; if ( fragmented == 0 ) { if ( av_new_packet ( pkt , pkt_len ) ) { av_log ( ctx , AV_LOG_ERROR , Out of memory . \n ) ; return AVERROR ( ENOMEM ) ; } pkt - > stream_index = st - > index ; memcpy ( pkt - > data , buf , pkt_len ) ; buf + = pkt_len ; len - = pkt_len ; num_pkts - - ; if ( num_pkts > 0 ) { if ( len > data - > split_buf_size || ! data - > split_buf ) { av_freep ( & data - > split_buf ) ; data - > split_buf_size = 2 * len ; data - > split_buf = av_malloc ( data - > split_buf_size ) ; if ( ! data - > split_buf ) { av_log ( ctx , AV_LOG_ERROR , Out of memory . \n ) ; av_free_packet ( pkt ) ; return AVERROR ( ENOMEM ) ; } } memcpy ( data - > split_buf , buf , len ) ; data - > split_buf_len = len ; data - > split_pos = 0 ; data - > split_pkts = num_pkts ; return 1 ; } return 0 ; } else if ( fragmented == 1 ) { // start of xiph data fragment int res ; // end packet has been lost somewhere , so drop buffered data ffio_free_dyn_buf ( & data - > fragment ) ; if ( ( res = avio_open_dyn_buf ( & data - > fragment ) ) < 0 ) return res ; avio_write ( data - > fragment , buf , pkt_len ) ; data - > timestamp = * timestamp ; } else { av_assert1 ( fragmented < 4 ) ; if ( data - > timestamp ! = * timestamp ) { // skip if fragmented timestamp is incorrect ; // a start packet has been lost somewhere ffio_free_dyn_buf ( & data - > fragment ) ; av_log ( ctx , AV_LOG_ERROR , RTP timestamps don ' t match ! \n ) ; return AVERROR_INVALIDDATA ; } if ( ! data - > fragment ) { av_log ( ctx , AV_LOG_WARNING , Received packet without a start fragment ; dropping . \n ) ; return AVERROR ( EAGAIN ) ; } // copy data to fragment buffer avio_write ( data - > fragment , buf , pkt_len ) ; if ( fragmented == 3 ) { // end of xiph data packet int ret = ff_rtp_finalize_packet ( pkt , & data - > fragment , st - > index ) ; if ( ret < 0 ) { av_log ( ctx , AV_LOG_ERROR , Error occurred when getting fragment buffer . ) ; return ret ; } return 0 ; } } return AVERROR ( EAGAIN ) ; }",0
"static int check_image_pointers ( uint8_t * data[4] , enum AVPixelFormat pix_fmt , const int linesizes[4] ) { const AVPixFmtDescriptor * desc = av_pix_fmt_desc_get ( pix_fmt ) ; int i ; for ( i = 0 ; i < 4 ; i + + ) { int plane = desc - > comp[i] . plane ; if ( ! data[plane] || ! linesizes[plane] ) return 0 ; } return 1 ; }",0
"static void vc1_mc_4mv_luma ( VC1Context * v , int n , int dir ) { MpegEncContext * s = & v - > s ; DSPContext * dsp = & v - > s . dsp ; uint8_t * srcY ; int dxy , mx , my , src_x , src_y ; int off ; int fieldmv = ( v - > fcm == ILACE_FRAME ) ? v - > blk_mv_type[s - > block_index[n]] : 0 ; int v_edge_pos = s - > v_edge_pos > > v - > field_mode ; if ( ! v - > field_mode & & ! v - > s . last_picture . f . data[0] ) return ; mx = s - > mv[dir][n][0] ; my = s - > mv[dir][n][1] ; if ( ! dir ) { if ( v - > field_mode ) { if ( ( v - > cur_field_type ! = v - > ref_field_type[dir] ) & & v - > cur_field_type ) srcY = s - > current_picture . f . data[0] ; else srcY = s - > last_picture . f . data[0] ; } else srcY = s - > last_picture . f . data[0] ; } else srcY = s - > next_picture . f . data[0] ; if ( v - > field_mode ) { if ( v - > cur_field_type ! = v - > ref_field_type[dir] ) my = my - 2 + 4 * v - > cur_field_type ; } if ( s - > pict_type == AV_PICTURE_TYPE_P & & n == 3 & & v - > field_mode ) { int same_count = 0 , opp_count = 0 , k ; int chosen_mv[2][4][2] , f ; int tx , ty ; for ( k = 0 ; k < 4 ; k + + ) { f = v - > mv_f[0][s - > block_index[k] + v - > blocks_off] ; chosen_mv[f][f ? opp_count : same_count][0] = s - > mv[0][k][0] ; chosen_mv[f][f ? opp_count : same_count][1] = s - > mv[0][k][1] ; opp_count + = f ; same_count + = 1 - f ; } f = opp_count > same_count ; switch ( f ? opp_count : same_count ) { case 4 : tx = median4 ( chosen_mv[f][0][0] , chosen_mv[f][1][0] , chosen_mv[f][2][0] , chosen_mv[f][3][0] ) ; ty = median4 ( chosen_mv[f][0][1] , chosen_mv[f][1][1] , chosen_mv[f][2][1] , chosen_mv[f][3][1] ) ; break ; case 3 : tx = mid_pred ( chosen_mv[f][0][0] , chosen_mv[f][1][0] , chosen_mv[f][2][0] ) ; ty = mid_pred ( chosen_mv[f][0][1] , chosen_mv[f][1][1] , chosen_mv[f][2][1] ) ; break ; case 2 : tx = ( chosen_mv[f][0][0] + chosen_mv[f][1][0] ) / 2 ; ty = ( chosen_mv[f][0][1] + chosen_mv[f][1][1] ) / 2 ; break ; } s - > current_picture . f . motion_val[1][s - > block_index[0] + v - > blocks_off][0] = tx ; s - > current_picture . f . motion_val[1][s - > block_index[0] + v - > blocks_off][1] = ty ; for ( k = 0 ; k < 4 ; k + + ) v - > mv_f[1][s - > block_index[k] + v - > blocks_off] = f ; } if ( v - > fcm == ILACE_FRAME ) { // not sure if needed for other types of picture int qx , qy ; int width = s - > avctx - > coded_width ; int height = s - > avctx - > coded_height > > 1 ; qx = ( s - > mb_x * 16 ) + ( mx > > 2 ) ; qy = ( s - > mb_y * 8 ) + ( my > > 3 ) ; if ( qx < - 17 ) mx - = 4 * ( qx + 17 ) ; else if ( qx > width ) mx - = 4 * ( qx - width ) ; if ( qy < - 18 ) my - = 8 * ( qy + 18 ) ; else if ( qy > height + 1 ) my - = 8 * ( qy - height - 1 ) ; } if ( ( v - > fcm == ILACE_FRAME ) & & fieldmv ) off = ( ( n > 1 ) ? s - > linesize : 0 ) + ( n & 1 ) * 8 ; else off = s - > linesize * 4 * ( n & 2 ) + ( n & 1 ) * 8 ; if ( v - > field_mode & & v - > cur_field_type ) off + = s - > current_picture_ptr - > f . linesize[0] ; src_x = s - > mb_x * 16 + ( n & 1 ) * 8 + ( mx > > 2 ) ; if ( ! fieldmv ) src_y = s - > mb_y * 16 + ( n & 2 ) * 4 + ( my > > 2 ) ; else src_y = s - > mb_y * 16 + ( ( n > 1 ) ? 1 : 0 ) + ( my > > 2 ) ; if ( v - > profile ! = PROFILE_ADVANCED ) { src_x = av_clip ( src_x , - 16 , s - > mb_width * 16 ) ; src_y = av_clip ( src_y , - 16 , s - > mb_height * 16 ) ; } else { src_x = av_clip ( src_x , - 17 , s - > avctx - > coded_width ) ; if ( v - > fcm == ILACE_FRAME ) { if ( src_y & 1 ) src_y = av_clip ( src_y , - 17 , s - > avctx - > coded_height + 1 ) ; else src_y = av_clip ( src_y , - 18 , s - > avctx - > coded_height ) ; } else { src_y = av_clip ( src_y , - 18 , s - > avctx - > coded_height + 1 ) ; } } srcY + = src_y * s - > linesize + src_x ; if ( v - > field_mode & & v - > ref_field_type[dir] ) srcY + = s - > current_picture_ptr - > f . linesize[0] ; if ( fieldmv & & ! ( src_y & 1 ) ) v_edge_pos - - ; if ( fieldmv & & ( src_y & 1 ) & & src_y < 4 ) src_y - - ; if ( v - > rangeredfrm || ( v - > mv_mode == MV_PMODE_INTENSITY_COMP ) || s - > h_edge_pos < 13 || v_edge_pos < 23 || ( unsigned ) ( src_x - s - > mspel ) > s - > h_edge_pos - ( mx & 3 ) - 8 - s - > mspel * 2 || ( unsigned ) ( src_y - ( s - > mspel < < fieldmv ) ) > v_edge_pos - ( my & 3 ) - ( ( 8 + s - > mspel * 2 ) < < fieldmv ) ) { srcY - = s - > mspel * ( 1 + ( s - > linesize < < fieldmv ) ) ; / *",0
"static void pool_release_buffer ( void * opaque , uint8_t * data ) { BufferPoolEntry * buf = opaque ; AVBufferPool * pool = buf - > pool ; if ( CONFIG_MEMORY_POISONING ) memset ( buf - > data , 0x2a , pool - > size ) ; add_to_pool ( buf ) ; if ( ! avpriv_atomic_int_add_and_fetch ( & pool - > refcount , - 1 ) ) buffer_pool_free ( pool ) ; }",0
"static void rv34_pred_mv ( RV34DecContext * r , int block_type , int subblock_no , int dmv_no ) { MpegEncContext * s = & r - > s ; int mv_pos = s - > mb_x * 2 + s - > mb_y * 2 * s - > b8_stride ; int A[2] = { 0 } , B[2] , C[2] ; int i , j ; int mx , my ; int avail_index = avail_indexes[subblock_no] ; int c_off = part_sizes_w[block_type] ; mv_pos + = ( subblock_no & 1 ) + ( subblock_no > > 1 ) * s - > b8_stride ; if ( subblock_no == 3 ) c_off = - 1 ; if ( r - > avail_cache[avail_index - 1] ) { A[0] = s - > current_picture_ptr - > f . motion_val[0][mv_pos - 1][0] ; A[1] = s - > current_picture_ptr - > f . motion_val[0][mv_pos - 1][1] ; } if ( r - > avail_cache[avail_index - 4] ) { B[0] = s - > current_picture_ptr - > f . motion_val[0][mv_pos - s - > b8_stride][0] ; B[1] = s - > current_picture_ptr - > f . motion_val[0][mv_pos - s - > b8_stride][1] ; } else { B[0] = A[0] ; B[1] = A[1] ; } if ( ! r - > avail_cache[avail_index - 4 + c_off] ) { if ( r - > avail_cache[avail_index - 4] & & ( r - > avail_cache[avail_index - 1] || r - > rv30 ) ) { C[0] = s - > current_picture_ptr - > f . motion_val[0][mv_pos - s - > b8_stride - 1][0] ; C[1] = s - > current_picture_ptr - > f . motion_val[0][mv_pos - s - > b8_stride - 1][1] ; } else { C[0] = A[0] ; C[1] = A[1] ; } } else { C[0] = s - > current_picture_ptr - > f . motion_val[0][mv_pos - s - > b8_stride + c_off][0] ; C[1] = s - > current_picture_ptr - > f . motion_val[0][mv_pos - s - > b8_stride + c_off][1] ; } mx = mid_pred ( A[0] , B[0] , C[0] ) ; my = mid_pred ( A[1] , B[1] , C[1] ) ; mx + = r - > dmv[dmv_no][0] ; my + = r - > dmv[dmv_no][1] ; for ( j = 0 ; j < part_sizes_h[block_type] ; j + + ) { for ( i = 0 ; i < part_sizes_w[block_type] ; i + + ) { s - > current_picture_ptr - > f . motion_val[0][mv_pos + i + j * s - > b8_stride][0] = mx ; s - > current_picture_ptr - > f . motion_val[0][mv_pos + i + j * s - > b8_stride][1] = my ; } } }",0
