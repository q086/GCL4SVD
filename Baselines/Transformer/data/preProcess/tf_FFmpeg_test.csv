review,sentiment
"static int mp3_seek ( AVFormatContext * s , int stream_index , int64_t timestamp , int flags ) { MP3DecContext * mp3 = s - > priv_data ; AVIndexEntry * ie , ie1 ; AVStream * st = s - > streams[0] ; int64_t ret = av_index_search_timestamp ( st , timestamp , flags ) ; int64_t best_pos ; int fast_seek = ( s - > flags & AVFMT_FLAG_FAST_SEEK ) ? 1 : 0 ; int64_t filesize = mp3 - > header_filesize ; if ( mp3 - > usetoc == 2 ) return - 1 ; // generic index code if ( filesize < = 0 ) { int64_t size = avio_size ( s - > pb ) ; if ( size > 0 & & size > s - > internal - > data_offset ) filesize = size - s - > internal - > data_offset ; } if ( ( mp3 - > is_cbr || fast_seek ) & & ( mp3 - > usetoc == 0 || ! mp3 - > xing_toc ) & & st - > duration > 0 & & filesize > 0 ) { ie = & ie1 ; timestamp = av_clip64 ( timestamp , 0 , st - > duration ) ; ie - > timestamp = timestamp ; ie - > pos = av_rescale ( timestamp , filesize , st - > duration ) + s - > internal - > data_offset ; } else if ( mp3 - > xing_toc ) { if ( ret < 0 ) return ret ; ie = & st - > index_entries[ret] ; } else { return - 1 ; } best_pos = mp3_sync ( s , ie - > pos , flags ) ; if ( best_pos < 0 ) return best_pos ; if ( mp3 - > is_cbr & & ie == & ie1 & & mp3 - > frames ) { int frame_duration = av_rescale ( st - > duration , 1 , mp3 - > frames ) ; ie1 . timestamp = frame_duration * av_rescale ( best_pos - s - > internal - > data_offset , mp3 - > frames , mp3 - > header_filesize ) ; } ff_update_cur_dts ( s , st , ie - > timestamp ) ; return 0 ; }",0
"static inline CopyRet copy_frame ( AVCodecContext * avctx , BC_DTS_PROC_OUT * output , void * data , int * got_frame ) { BC_STATUS ret ; BC_DTS_STATUS decoder_status = { 0 , } ; uint8_t trust_interlaced ; uint8_t interlaced ; CHDContext * priv = avctx - > priv_data ; int64_t pkt_pts = AV_NOPTS_VALUE ; uint8_t pic_type = 0 ; uint8_t bottom_field = ( output - > PicInfo . flags & VDEC_FLAG_BOTTOMFIELD ) == VDEC_FLAG_BOTTOMFIELD ; uint8_t bottom_first = ! ! ( output - > PicInfo . flags & VDEC_FLAG_BOTTOM_FIRST ) ; int width = output - > PicInfo . width ; int height = output - > PicInfo . height ; int bwidth ; uint8_t * src = output - > Ybuff ; int sStride ; uint8_t * dst ; int dStride ; if ( output - > PicInfo . timeStamp ! = 0 ) { OpaqueList * node = opaque_list_pop ( priv , output - > PicInfo . timeStamp ) ; if ( node ) { pkt_pts = node - > reordered_opaque ; pic_type = node - > pic_type ; av_free ( node ) ; } else { / * * We will encounter a situation where a timestamp cannot be * popped if a second field is being returned . In this case , * each field has the same timestamp and the first one will * cause it to be popped . To keep subsequent calculations * simple , pic_type should be set a FIELD value - doesn ' t * matter which , but I chose BOTTOM . * / pic_type = PICT_BOTTOM_FIELD ; } av_log ( avctx , AV_LOG_VERBOSE , output \ pts\ : % PRIu64 \n , output - > PicInfo . timeStamp ) ; av_log ( avctx , AV_LOG_VERBOSE , output picture type %d\n , pic_type ) ; } ret = DtsGetDriverStatus ( priv - > dev , & decoder_status ) ; if ( ret ! = BC_STS_SUCCESS ) { av_log ( avctx , AV_LOG_ERROR , CrystalHD : GetDriverStatus failed : %u\n , ret ) ; return RET_ERROR ; } / * * For most content , we can trust the interlaced flag returned * by the hardware , but sometimes we can ' t . These are the * conditions under which we can trust the flag : * * 1 ) It ' s not h . 264 content * 2 ) The UNKNOWN_SRC flag is not set * 3 ) We know we ' re expecting a second field * 4 ) The hardware reports this picture and the next picture * have the same picture number . * * Note that there can still be interlaced content that will * fail this check , if the hardware hasn ' t decoded the next * picture or if there is a corruption in the stream . ( In either * case a 0 will be returned for the next picture number ) * / trust_interlaced = avctx - > codec - > id ! = AV_CODEC_ID_H264 || ! ( output - > PicInfo . flags & VDEC_FLAG_UNKNOWN_SRC ) || priv - > need_second_field || ( decoder_status . picNumFlags & 0x40000000 ) == output - > PicInfo . picture_number ; / * * If we got a false negative for trust_interlaced on the first field , * we will realise our mistake here when we see that the picture number is that * of the previous picture . We cannot recover the frame and should discard the * second field to keep the correct number of output frames . * / if ( output - > PicInfo . picture_number == priv - > last_picture & & ! priv - > need_second_field ) { av_log ( avctx , AV_LOG_WARNING , Incorrectly guessed progressive frame . Discarding second field\n ) ; / * Returning without providing a picture . * / return RET_OK ; } interlaced = ( output - > PicInfo . flags & VDEC_FLAG_INTERLACED_SRC ) & & trust_interlaced ; if ( ! trust_interlaced & & ( decoder_status . picNumFlags & 0x40000000 ) == 0 ) { av_log ( avctx , AV_LOG_VERBOSE , Next picture number unknown . Assuming progressive frame . \n ) ; } av_log ( avctx , AV_LOG_VERBOSE , Interlaced state : %d | trust_interlaced %d\n , interlaced , trust_interlaced ) ; if ( priv - > pic - > data[0] & & ! priv - > need_second_field ) av_frame_unref ( priv - > pic ) ; priv - > need_second_field = interlaced & & ! priv - > need_second_field ; if ( ! priv - > pic - > data[0] ) { if ( ff_get_buffer ( avctx , priv - > pic , AV_GET_BUFFER_FLAG_REF ) < 0 ) return RET_ERROR ; } bwidth = av_image_get_linesize ( avctx - > pix_fmt , width , 0 ) ; if ( priv - > is_70012 ) { int pStride ; if ( width < = 720 ) pStride = 720 ; else if ( width < = 1280 ) pStride = 1280 ; else pStride = 1920 ; sStride = av_image_get_linesize ( avctx - > pix_fmt , pStride , 0 ) ; } else { sStride = bwidth ; } dStride = priv - > pic - > linesize[0] ; dst = priv - > pic - > data[0] ; av_log ( priv - > avctx , AV_LOG_VERBOSE , CrystalHD : Copying out frame\n ) ; if ( interlaced ) { int dY = 0 ; int sY = 0 ; height /= 2 ; if ( bottom_field ) { av_log ( priv - > avctx , AV_LOG_VERBOSE , Interlaced : bottom field\n ) ; dY = 1 ; } else { av_log ( priv - > avctx , AV_LOG_VERBOSE , Interlaced : top field\n ) ; dY = 0 ; } for ( sY = 0 ; sY < height ; dY + + , sY + + ) { memcpy ( & ( dst[dY * dStride] ) , & ( src[sY * sStride] ) , bwidth ) ; dY + + ; } } else { av_image_copy_plane ( dst , dStride , src , sStride , bwidth , height ) ; } priv - > pic - > interlaced_frame = interlaced ; if ( interlaced ) priv - > pic - > top_field_first = ! bottom_first ; priv - > pic - > pts = pkt_pts ; if FF_API_PKT_PTS FF_DISABLE_DEPRECATION_WARNINGS priv - > pic - > pkt_pts = pkt_pts ; FF_ENABLE_DEPRECATION_WARNINGS endif if ( ! priv - > need_second_field ) { * got_frame = 1 ; if ( ( ret = av_frame_ref ( data , priv - > pic ) ) < 0 ) { return ret ; } } / * * Two types of PAFF content have been observed . One form causes the * hardware to return a field pair and the other individual fields , * even though the input is always individual fields . We must skip * copying on the next decode ( ) call to maintain pipeline length in * the first case . * / if ( ! interlaced & & ( output - > PicInfo . flags & VDEC_FLAG_UNKNOWN_SRC ) &",1
"static av_cold int prores_encode_init ( AVCodecContext * avctx ) { int i ; ProresContext * ctx = avctx - > priv_data ; if ( avctx - > pix_fmt ! = PIX_FMT_YUV422P10LE ) { av_log ( avctx , AV_LOG_ERROR , need YUV422P10\n ) ; return - 1 ; } if ( avctx - > width & 0x1 ) { av_log ( avctx , AV_LOG_ERROR , frame width needs to be multiple of 2\n ) ; return - 1 ; } if ( ( avctx - > height & 0xf ) || ( avctx - > width & 0xf ) ) { ctx - > fill_y = av_malloc ( DEFAULT_SLICE_MB_WIDTH < < 9 ) ; ctx - > fill_u = av_malloc ( DEFAULT_SLICE_MB_WIDTH < < 8 ) ; ctx - > fill_v = av_malloc ( DEFAULT_SLICE_MB_WIDTH < < 8 ) ; } if ( avctx - > profile == FF_PROFILE_UNKNOWN ) { avctx - > profile = FF_PROFILE_PRORES_STANDARD ; av_log ( avctx , AV_LOG_INFO , encoding with ProRes standard ( apcn ) profile\n ) ; } else if ( avctx - > profile < FF_PROFILE_PRORES_PROXY || avctx - > profile > FF_PROFILE_PRORES_HQ ) { av_log ( avctx , AV_LOG_ERROR , unknown profile %d , use [0 - apco , 1 - apcs , 2 - apcn ( default ) , 3 - apch]\n , avctx - > profile ) ; return - 1 ; } avctx - > codec_tag = AV_RL32 ( ( const uint8_t * ) profiles[avctx - > profile] . name ) ; for ( i = 1 ; i < = 16 ; i + + ) { scale_mat ( QMAT_LUMA[avctx - > profile] , ctx - > qmat_luma[i - 1] , i ) ; scale_mat ( QMAT_CHROMA[avctx - > profile] , ctx - > qmat_chroma[i - 1] , i ) ; } avctx - > coded_frame = avcodec_alloc_frame ( ) ; avctx - > coded_frame - > key_frame = 1 ; avctx - > coded_frame - > pict_type = AV_PICTURE_TYPE_I ; return 0 ; }",1
"int estimate_motion ( MpegEncContext * s , int mb_x , int mb_y , int * mx_ptr , int * my_ptr ) { UINT8 * pix , * ppix ; int sum , varc , vard , mx , my , range , dmin , xx , yy ; int xmin , ymin , xmax , ymax ; int rel_xmin , rel_ymin , rel_xmax , rel_ymax ; int pred_x=0 , pred_y=0 ; int P[5][2] ; const int shift= 1 + s - > quarter_sample ; range = 8 * ( 1 < < ( s - > f_code - 1 ) ) ; / * XXX : temporary kludge to avoid overflow for msmpeg4 * / if ( s - > out_format == FMT_H263 & & ! s - > h263_msmpeg4 ) range = range * 2 ; if ( s - > unrestricted_mv ) { xmin = - 16 ; ymin = - 16 ; if ( s - > h263_plus ) range * = 2 ; if ( s - > avctx==NULL || s - > avctx - > codec - > id ! =CODEC_ID_MPEG4 ) { xmax = s - > mb_width * 16 ; ymax = s - > mb_height * 16 ; } else { / * XXX : dunno if this is correct but ffmpeg4 decoder wont like it otherwise ( cuz the drawn edge isnt large enough ) ) * / xmax = s - > width ; ymax = s - > height ; } } else { xmin = 0 ; ymin = 0 ; xmax = s - > mb_width * 16 - 16 ; ymax = s - > mb_height * 16 - 16 ; } switch ( s - > full_search ) { case ME_ZERO : default : no_motion_search ( s , & mx , & my ) ; dmin = 0 ; break ; case ME_FULL : dmin = full_motion_search ( s , & mx , & my , range , xmin , ymin , xmax , ymax ) ; break ; case ME_LOG : dmin = log_motion_search ( s , & mx , & my , range / 2 , xmin , ymin , xmax , ymax ) ; break ; case ME_PHODS : dmin = phods_motion_search ( s , & mx , & my , range / 2 , xmin , ymin , xmax , ymax ) ; break ; case ME_X1 : // just reserving some space for experiments . . . case ME_EPZS : rel_xmin= xmin - s - > mb_x * 16 ; rel_xmax= xmax - s - > mb_x * 16 ; rel_ymin= ymin - s - > mb_y * 16 ; rel_ymax= ymax - s - > mb_y * 16 ; if ( s - > out_format == FMT_H263 ) { static const int off[4]= { 2 , 1 , 1 , - 1 } ; const int mot_stride = s - > block_wrap[0] ; const int mot_xy = s - > block_index[0] ; P[0][0] = s - > motion_val[mot_xy ][0] ; P[0][1] = s - > motion_val[mot_xy ][1] ; P[1][0] = s - > motion_val[mot_xy - 1][0] ; P[1][1] = s - > motion_val[mot_xy - 1][1] ; if ( P[1][0] > ( rel_xmax < < shift ) ) P[1][0]= ( rel_xmax < < shift ) ; / * special case for first line * / if ( ( s - > mb_y == 0 || s - > first_slice_line || s - > first_gob_line ) ) { pred_x = P[1][0] ; pred_y = P[1][1] ; } else { P[2][0] = s - > motion_val[mot_xy - mot_stride ][0] ; P[2][1] = s - > motion_val[mot_xy - mot_stride ][1] ; P[3][0] = s - > motion_val[mot_xy - mot_stride + off[0] ][0] ; P[3][1] = s - > motion_val[mot_xy - mot_stride + off[0] ][1] ; if ( P[2][1] > ( rel_ymax < < shift ) ) P[2][1]= ( rel_ymax < < shift ) ; if ( P[3][0] < ( rel_xmin < < shift ) ) P[3][0]= ( rel_xmin < < shift ) ; if ( P[3][1] > ( rel_ymax < < shift ) ) P[3][1]= ( rel_ymax < < shift ) ; P[4][0]= pred_x = mid_pred ( P[1][0] , P[2][0] , P[3][0] ) ; P[4][1]= pred_y = mid_pred ( P[1][1] , P[2][1] , P[3][1] ) ; } } else { const int xy= s - > mb_y * s - > mb_width + s - > mb_x ; pred_x= s - > last_mv[0][0][0] ; pred_y= s - > last_mv[0][0][1] ; P[0][0]= s - > mv_table[0][xy ] ; P[0][1]= s - > mv_table[1][xy ] ; if ( s - > mb_x == 0 ) { P[1][0]= 0 ; P[1][1]= 0 ; } else { P[1][0]= s - > mv_table[0][xy - 1] ; P[1][1]= s - > mv_table[1][xy - 1] ; if ( P[1][0] > ( rel_xmax < < shift ) ) P[1][0]= ( rel_xmax < < shift ) ; } if ( ! ( s - > mb_y == 0 || s - > first_slice_line || s - > first_gob_line ) ) { P[2][0] = s - > mv_table[0][xy - s - > mb_width] ; P[2][1] = s - > mv_table[1][xy - s - > mb_width] ; P[3][0] = s - > mv_table[0][xy - s - > mb_width + 1] ; P[3][1] = s - > mv_table[1][xy - s - > mb_width + 1] ; if ( P[2][1] > ( rel_ymax < < shift ) ) P[2][1]= ( rel_ymax < < shift ) ; if ( P[3][0] > ( rel_xmax < < shift ) ) P[3][0]= ( rel_xmax < < shift ) ; if ( P[3][0] < ( rel_xmin < < shift ) ) P[3][0]= ( rel_xmin < < shift ) ; if ( P[3][1] > ( rel_ymax < < shift ) ) P[3][1]= ( rel_ymax < < shift ) ; P[4][0]= mid_pred ( P[1][0] , P[2][0] , P[3][0] ) ; P[4][1]= mid_pred ( P[1][1] , P[2][1] , P[3][1] ) ; } } dmin = epzs_motion_search ( s , & mx , & my , P , pred_x , pred_y , rel_xmin , rel_ymin , rel_xmax , rel_ymax ) ; mx + = s - > mb_x * 16 ; my + = s - > mb_y * 16 ; break ; } / * intra / predictive decision * / xx = mb_x * 16 ; yy = mb_y * 16 ; pix = s - > new_picture[0] + ( yy * s - > linesize ) + xx ; / * At this point ( mx , my ) are full - pell and the absolute displacement * / ppix = s - > last_picture[0] + ( my * s - > linesize ) + mx ; sum = pix_sum ( pix , s - > linesize ) ; varc = pix_norm1 ( pix , s - > linesize ) ; vard = pix_norm ( pix , ppix , s - > linesize ) ; vard = vard > > 8 ; sum = sum > > 8 ; varc = ( varc > > 8 ) - ( sum * sum ) ; s - > mb_var[s - > mb_width *",1
"static int get_std_framerate ( int i ) { if ( i < 60 * 12 ) return i * 1001 ; else return ( ( const int[] ) { 24 , 30 , 60 , 12 , 15 } ) [i - 60 * 12] * 1000 * 12 ; }",1
"static void subband_scale ( int * dst , int * src , int scale , int offset , int len ) { int ssign = scale < 0 ? - 1 : 1 ; int s = FFABS ( scale ) ; unsigned int round ; int i , out , c = exp2tab[s & 3] ; s = offset - ( s > > 2 ) ; if ( s > 31 ) { for ( i=0 ; i < len ; i + + ) { dst[i] = 0 ; } } else if ( s > 0 ) { round = 1 < < ( s - 1 ) ; for ( i=0 ; i < len ; i + + ) { out = ( int ) ( ( ( int64_t ) src[i] * c ) > > 32 ) ; dst[i] = ( ( int ) ( out + round ) > > s ) * ssign ; } } else { s = s + 32 ; round = 1U < < ( s - 1 ) ; for ( i=0 ; i < len ; i + + ) { out = ( int ) ( ( int64_t ) ( ( int64_t ) src[i] * c + round ) > > s ) ; dst[i] = out * ssign ; } } }",1
"int ff_h264_decode_mb_cabac ( const H264Context * h , H264SliceContext * sl ) { int mb_xy ; int mb_type , partition_count , cbp = 0 ; int dct8x8_allowed= h - > pps . transform_8x8_mode ; int decode_chroma = h - > sps . chroma_format_idc == 1 || h - > sps . chroma_format_idc == 2 ; const int pixel_shift = h - > pixel_shift ; mb_xy = sl - > mb_xy = sl - > mb_x + sl - > mb_y * h - > mb_stride ; ff_tlog ( h - > avctx , pic : %d mb : %d/%d\n , h - > frame_num , sl - > mb_x , sl - > mb_y ) ; if ( sl - > slice_type_nos ! = AV_PICTURE_TYPE_I ) { int skip ; / * a skipped mb needs the aff flag from the following mb * / if ( FRAME_MBAFF ( h ) & & ( sl - > mb_y & 1 ) == 1 & & sl - > prev_mb_skipped ) skip = sl - > next_mb_skipped ; else skip = decode_cabac_mb_skip ( h , sl , sl - > mb_x , sl - > mb_y ) ; / * read skip flags * / if ( skip ) { if ( FRAME_MBAFF ( h ) & & ( sl - > mb_y & 1 ) == 0 ) { h - > cur_pic . mb_type[mb_xy] = MB_TYPE_SKIP ; sl - > next_mb_skipped = decode_cabac_mb_skip ( h , sl , sl - > mb_x , sl - > mb_y + 1 ) ; if ( ! sl - > next_mb_skipped ) sl - > mb_mbaff = sl - > mb_field_decoding_flag = decode_cabac_field_decoding_flag ( h , sl ) ; } decode_mb_skip ( h , sl ) ; h - > cbp_table[mb_xy] = 0 ; h - > chroma_pred_mode_table[mb_xy] = 0 ; sl - > last_qscale_diff = 0 ; return 0 ; } } if ( FRAME_MBAFF ( h ) ) { if ( ( sl - > mb_y & 1 ) == 0 ) sl - > mb_mbaff = sl - > mb_field_decoding_flag = decode_cabac_field_decoding_flag ( h , sl ) ; } sl - > prev_mb_skipped = 0 ; fill_decode_neighbors ( h , sl , - ( MB_FIELD ( sl ) ) ) ; if ( sl - > slice_type_nos == AV_PICTURE_TYPE_B ) { int ctx = 0 ; av_assert2 ( sl - > slice_type_nos == AV_PICTURE_TYPE_B ) ; if ( ! IS_DIRECT ( sl - > left_type[LTOP] - 1 ) ) ctx + + ; if ( ! IS_DIRECT ( sl - > top_type - 1 ) ) ctx + + ; if ( ! get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[27 + ctx] ) ) { mb_type= 0 ; / * B_Direct_16x16 * / } else if ( ! get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[27 + 3] ) ) { mb_type= 1 + get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[27 + 5] ) ; / * B_L[01]_16x16 * / } else { int bits ; bits = get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[27 + 4] ) < < 3 ; bits + = get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[27 + 5] ) < < 2 ; bits + = get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[27 + 5] ) < < 1 ; bits + = get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[27 + 5] ) ; if ( bits < 8 ) { mb_type= bits + 3 ; / * B_Bi_16x16 through B_L1_L0_16x8 * / } else if ( bits == 13 ) { mb_type = decode_cabac_intra_mb_type ( sl , 32 , 0 ) ; goto decode_intra_mb ; } else if ( bits == 14 ) { mb_type= 11 ; / * B_L1_L0_8x16 * / } else if ( bits == 15 ) { mb_type= 22 ; / * B_8x8 * / } else { bits= ( bits < < 1 ) + get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[27 + 5] ) ; mb_type= bits - 4 ; / * B_L0_Bi_ * through B_Bi_Bi_ * * / } } partition_count= b_mb_type_info[mb_type] . partition_count ; mb_type= b_mb_type_info[mb_type] . type ; } else if ( sl - > slice_type_nos == AV_PICTURE_TYPE_P ) { if ( get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[14] ) == 0 ) { / * P - type * / if ( get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[15] ) == 0 ) { / * P_L0_D16x16 , P_8x8 * / mb_type= 3 * get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[16] ) ; } else { / * P_L0_D8x16 , P_L0_D16x8 * / mb_type= 2 - get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[17] ) ; } partition_count= p_mb_type_info[mb_type] . partition_count ; mb_type= p_mb_type_info[mb_type] . type ; } else { mb_type = decode_cabac_intra_mb_type ( sl , 17 , 0 ) ; goto decode_intra_mb ; } } else { mb_type = decode_cabac_intra_mb_type ( sl , 3 , 1 ) ; if ( sl - > slice_type == AV_PICTURE_TYPE_SI & & mb_type ) mb_type - - ; av_assert2 ( sl - > slice_type_nos == AV_PICTURE_TYPE_I ) ; decode_intra_mb : partition_count = 0 ; cbp= i_mb_type_info[mb_type] . cbp ; sl - > intra16x16_pred_mode = i_mb_type_info[mb_type] . pred_mode ; mb_type= i_mb_type_info[mb_type] . type ; } if ( MB_FIELD ( sl ) ) mb_type |= MB_TYPE_INTERLACED ; h - > slice_table[mb_xy] = sl - > slice_num ; if ( IS_INTRA_PCM ( mb_type ) ) { const int mb_size = ff_h264_mb_sizes[h - > sps . chroma_format_idc] * h - > sps . bit_depth_luma > > 3 ; const uint8_t * ptr ; // We assume these blocks are very rare so we do not optimize it . // FIXME The two following lines get the bitstream position in the cabac // decode , I think it should be done by a function in cabac . h ( or cabac . c ) . ptr= sl - > cabac . bytestream ; if ( sl - > cabac . low & 0x1 ) ptr - - ; if ( CABAC_BITS==16 ) { if ( sl - > cabac . low & 0x1FF ) ptr - - ; } // The pixels are stored in the same order as levels in h - > mb array . if ( ( int ) ( sl - > cabac . bytestream_end - ptr ) < mb_size ) return - 1 ; sl - > intra_pcm_ptr = ptr ; ptr + = mb_size ; ff_init_cabac_decoder ( & sl - > cabac , ptr , sl - > cabac . bytestream_end - ptr ) ; // All blocks are present h - > cbp_table[mb_xy] = 0xf7ef ; h - > chroma_pred_mode_table[mb_xy] = 0 ; // In deblocking , the quantizer is 0 h -",1
"static int swf_write_header ( AVFormatContext * s ) { SWFContext * swf = s - > priv_data ; AVIOContext * pb = s - > pb ; PutBitContext p ; uint8_t buf1[256] ; int i , width , height , rate , rate_base ; int version ; swf - > sound_samples = 0 ; swf - > swf_frame_number = 0 ; swf - > video_frame_number = 0 ; for ( i=0 ; i < s - > nb_streams ; i + + ) { AVCodecContext * enc = s - > streams[i] - > codec ; if ( enc - > codec_type == AVMEDIA_TYPE_AUDIO ) { if ( swf - > audio_enc ) { av_log ( s , AV_LOG_ERROR , SWF muxer only supports 1 audio stream\n ) ; return AVERROR_INVALIDDATA ; if ( enc - > codec_id == AV_CODEC_ID_MP3 ) { if ( ! enc - > frame_size ) { av_log ( s , AV_LOG_ERROR , audio frame size not set\n ) ; return - 1 ; swf - > audio_enc = enc ; swf - > audio_fifo= av_fifo_alloc ( AUDIO_FIFO_SIZE ) ; if ( ! swf - > audio_fifo ) return AVERROR ( ENOMEM ) ; } else { av_log ( s , AV_LOG_ERROR , SWF muxer only supports MP3\n ) ; return - 1 ; } else { if ( swf - > video_enc ) { av_log ( s , AV_LOG_ERROR , SWF muxer only supports 1 video stream\n ) ; return AVERROR_INVALIDDATA ; if ( enc - > codec_id == AV_CODEC_ID_VP6F || enc - > codec_id == AV_CODEC_ID_FLV1 || enc - > codec_id == AV_CODEC_ID_MJPEG ) { swf - > video_st = s - > streams[i] ; swf - > video_enc = enc ; } else { av_log ( s , AV_LOG_ERROR , SWF muxer only supports VP6 , FLV1 and MJPEG\n ) ; return - 1 ; if ( ! swf - > video_enc ) { / * currently , cannot work correctly if audio only * / width = 320 ; height = 200 ; rate = 10 ; rate_base= 1 ; } else { width = swf - > video_enc - > width ; height = swf - > video_enc - > height ; // TODO : should be avg_frame_rate rate = swf - > video_st - > time_base . den ; rate_base = swf - > video_st - > time_base . num ; if ( ! swf - > audio_enc ) swf - > samples_per_frame = ( 44100LL * rate_base ) / rate ; else swf - > samples_per_frame = ( swf - > audio_enc - > sample_rate * rate_base ) / rate ; avio_write ( pb , FWS , 3 ) ; if ( ! strcmp ( avm2 , s - > oformat - > name ) ) version = 9 ; else if ( swf - > video_enc & & swf - > video_enc - > codec_id == AV_CODEC_ID_VP6F ) version = 8 ; / * version 8 and above support VP6 codec * / else if ( swf - > video_enc & & swf - > video_enc - > codec_id == AV_CODEC_ID_FLV1 ) version = 6 ; / * version 6 and above support FLV1 codec * / else version = 4 ; / * version 4 for mpeg audio support * / avio_w8 ( pb , version ) ; avio_wl32 ( pb , DUMMY_FILE_SIZE ) ; / * dummy size ( will be patched if not streamed ) * / put_swf_rect ( pb , 0 , width * 20 , 0 , height * 20 ) ; avio_wl16 ( pb , ( rate * 256 ) / rate_base ) ; / * frame rate * / swf - > duration_pos = avio_tell ( pb ) ; avio_wl16 ( pb , ( uint16_t ) ( DUMMY_DURATION * ( int64_t ) rate / rate_base ) ) ; / * frame count * / / * avm2/swf v9 ( also v8 ? ) files require a file attribute tag * / if ( version == 9 ) { put_swf_tag ( s , TAG_FILEATTRIBUTES ) ; avio_wl32 ( pb , 1 < < 3 ) ; / * set ActionScript v3/AVM2 flag * / put_swf_end_tag ( s ) ; / * define a shape with the jpeg inside * / if ( swf - > video_enc & & swf - > video_enc - > codec_id == AV_CODEC_ID_MJPEG ) { put_swf_tag ( s , TAG_DEFINESHAPE ) ; avio_wl16 ( pb , SHAPE_ID ) ; / * ID of shape * / / * bounding rectangle * / put_swf_rect ( pb , 0 , width , 0 , height ) ; / * style info * / avio_w8 ( pb , 1 ) ; / * one fill style * / avio_w8 ( pb , 0x41 ) ; / * clipped bitmap fill * / avio_wl16 ( pb , BITMAP_ID ) ; / * bitmap ID * / / * position of the bitmap * / put_swf_matrix ( pb , 1 < < FRAC_BITS , 0 , 0 , 1 < < FRAC_BITS , 0 , 0 ) ; avio_w8 ( pb , 0 ) ; / * no line style * / / * shape drawing * / init_put_bits ( & p , buf1 , sizeof ( buf1 ) ) ; put_bits ( & p , 4 , 1 ) ; / * one fill bit * / put_bits ( & p , 4 , 0 ) ; / * zero line bit * / put_bits ( & p , 1 , 0 ) ; / * not an edge * / put_bits ( & p , 5 , FLAG_MOVETO | FLAG_SETFILL0 ) ; put_bits ( & p , 5 , 1 ) ; / * nbits * / put_bits ( & p , 1 , 0 ) ; / * X * / put_bits ( & p , 1 , 0 ) ; / * Y * / put_bits ( & p , 1 , 1 ) ; / * set fill style 1 * / / * draw the rectangle ! * / put_swf_line_edge ( & p , width , 0 ) ; put_swf_line_edge ( & p , 0 , height ) ; put_swf_line_edge ( & p , - width , 0 ) ; put_swf_line_edge ( & p , 0 , - height ) ; / * end of shape * / put_bits ( & p , 1 , 0 ) ; / * not an edge * / put_bits ( & p , 5 , 0 ) ; flush_put_bits ( & p ) ; avio_write ( pb , buf1 , put_bits_ptr ( & p ) - p . buf ) ; put_swf_end_tag ( s ) ; if ( swf - > audio_enc & & swf - > audio_enc - > codec_id == AV_CODEC_ID_MP3 ) { int v = 0 ; / * start sound * / put_swf_tag ( s , TAG_STREAMHEAD2 ) ; switch ( swf - > audio_enc - > sample_rate ) { case 11025 : v |= 1 < < 2 ; break ; case 22050 : v |= 2 < < 2 ; break ; case 44100",1
"static int atrac3_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; ATRAC3Context * q = avctx - > priv_data ; int result = 0 ; const uint8_t * databuf ; float * samples = data ; if ( buf_size < avctx - > block_align ) { av_log ( avctx , AV_LOG_ERROR , Frame too small ( %d bytes ) . Truncated file ? \n , buf_size ) ; * data_size = 0 ; return buf_size ; } / * Check if we need to descramble and what buffer to pass on . * / if ( q - > scrambled_stream ) { decode_bytes ( buf , q - > decoded_bytes_buffer , avctx - > block_align ) ; databuf = q - > decoded_bytes_buffer ; } else { databuf = buf ; } result = decodeFrame ( q , databuf , q - > channels == 2 ? q - > outSamples : & samples ) ; if ( result ! = 0 ) { av_log ( NULL , AV_LOG_ERROR , Frame decoding error ! \n ) ; return - 1 ; } / * interleave * / if ( q - > channels == 2 ) { q - > fmt_conv . float_interleave ( samples , ( const float * * ) q - > outSamples , 1024 , 2 ) ; } * data_size = 1024 * q - > channels * av_get_bytes_per_sample ( avctx - > sample_fmt ) ; return avctx - > block_align ; }",0
static int flic_probe ( AVProbeData * p ) { int magic_number ; if ( p - > buf_size < 6 ) return 0 ; magic_number = AV_RL16 ( & p - > buf[4] ) ; if ( ( magic_number ! = FLIC_FILE_MAGIC_1 ) & & ( magic_number ! = FLIC_FILE_MAGIC_2 ) & & ( magic_number ! = FLIC_FILE_MAGIC_3 ) ) return 0 ; return AVPROBE_SCORE_MAX ; },0
"static void dwt_encode97_int ( DWTContext * s , int * t ) { int lev , w = s - > linelen[s - > ndeclevels - 1][0] ; int * line = s - > i_linebuf ; line + = 5 ; for ( lev = s - > ndeclevels - 1 ; lev > = 0 ; lev - - ) { int lh = s - > linelen[lev][0] , lv = s - > linelen[lev][1] , mh = s - > mod[lev][0] , mv = s - > mod[lev][1] , lp ; int * l ; // VER_SD l = line + mv ; for ( lp = 0 ; lp < lh ; lp + + ) { int i , j = 0 ; for ( i = 0 ; i < lv ; i + + ) l[i] = t[w * i + lp] ; sd_1d97_int ( line , mv , mv + lv ) ; // copy back and deinterleave for ( i = mv ; i < lv ; i + =2 , j + + ) t[w * j + lp] = ( ( l[i] * I_LFTG_X ) + ( 1 < < 16 ) ) > > 17 ; for ( i = 1 - mv ; i < lv ; i + =2 , j + + ) t[w * j + lp] = ( ( l[i] * I_LFTG_K ) + ( 1 < < 16 ) ) > > 17 ; } // HOR_SD l = line + mh ; for ( lp = 0 ; lp < lv ; lp + + ) { int i , j = 0 ; for ( i = 0 ; i < lh ; i + + ) l[i] = t[w * lp + i] ; sd_1d97_int ( line , mh , mh + lh ) ; // copy back and deinterleave for ( i = mh ; i < lh ; i + =2 , j + + ) t[w * lp + j] = ( ( l[i] * I_LFTG_X ) + ( 1 < < 16 ) ) > > 17 ; for ( i = 1 - mh ; i < lh ; i + =2 , j + + ) t[w * lp + j] = ( ( l[i] * I_LFTG_K ) + ( 1 < < 16 ) ) > > 17 ; } } }",1
"static int jp2_find_codestream ( J2kDecoderContext * s ) { uint32_t atom_size ; int found_codestream = 0 , search_range = 10 ; // skip jpeg2k signature atom s - > buf + = 12 ; while ( ! found_codestream & & search_range & & s - > buf_end - s - > buf > = 8 ) { atom_size = AV_RB32 ( s - > buf ) ; if ( AV_RB32 ( s - > buf + 4 ) == JP2_CODESTREAM ) { found_codestream = 1 ; s - > buf + = 8 ; } else { if ( s - > buf_end - s - > buf < atom_size ) return 0 ; s - > buf + = atom_size ; search_range - - ; } } if ( found_codestream ) return 1 ; return 0 ; }",1
"static void decode_postinit ( H264Context * h ) { MpegEncContext * const s = & h - > s ; Picture * out = s - > current_picture_ptr ; Picture * cur = s - > current_picture_ptr ; int i , pics , out_of_order , out_idx ; s - > current_picture_ptr - > qscale_type= FF_QSCALE_TYPE_H264 ; s - > current_picture_ptr - > pict_type= s - > pict_type ; if ( h - > next_output_pic ) return ; if ( cur - > field_poc[0]==INT_MAX || cur - > field_poc[1]==INT_MAX ) { //FIXME this allows the next thread to start once we encounter the first field of a PAFF packet //This works if the next packet contains the second field . It does not work if both fields are //in the same packet . //ff_thread_finish_setup ( s - > avctx ) ; return ; } cur - > interlaced_frame = 0 ; cur - > repeat_pict = 0 ; / * Signal interlacing information externally . * / / * Prioritize picture timing SEI information over used decoding process if it exists . * / if ( h - > sps . pic_struct_present_flag ) { switch ( h - > sei_pic_struct ) { case SEI_PIC_STRUCT_FRAME : break ; case SEI_PIC_STRUCT_TOP_FIELD : case SEI_PIC_STRUCT_BOTTOM_FIELD : cur - > interlaced_frame = 1 ; break ; case SEI_PIC_STRUCT_TOP_BOTTOM : case SEI_PIC_STRUCT_BOTTOM_TOP : if ( FIELD_OR_MBAFF_PICTURE ) cur - > interlaced_frame = 1 ; else // try to flag soft telecine progressive cur - > interlaced_frame = h - > prev_interlaced_frame ; break ; case SEI_PIC_STRUCT_TOP_BOTTOM_TOP : case SEI_PIC_STRUCT_BOTTOM_TOP_BOTTOM : // Signal the possibility of telecined film externally ( pic_struct 5 , 6 ) // From these hints , let the applications decide if they apply deinterlacing . cur - > repeat_pict = 1 ; break ; case SEI_PIC_STRUCT_FRAME_DOUBLING : // Force progressive here , as doubling interlaced frame is a bad idea . cur - > repeat_pict = 2 ; break ; case SEI_PIC_STRUCT_FRAME_TRIPLING : cur - > repeat_pict = 4 ; break ; } if ( ( h - > sei_ct_type & 3 ) & & h - > sei_pic_struct < = SEI_PIC_STRUCT_BOTTOM_TOP ) cur - > interlaced_frame = ( h - > sei_ct_type & ( 1 < < 1 ) ) ! = 0 ; } else { / * Derive interlacing flag from used decoding process . * / cur - > interlaced_frame = FIELD_OR_MBAFF_PICTURE ; } h - > prev_interlaced_frame = cur - > interlaced_frame ; if ( cur - > field_poc[0] ! = cur - > field_poc[1] ) { / * Derive top_field_first from field pocs . * / cur - > top_field_first = cur - > field_poc[0] < cur - > field_poc[1] ; } else { if ( cur - > interlaced_frame || h - > sps . pic_struct_present_flag ) { / * Use picture timing SEI information . Even if it is a information of a past frame , better than nothing . * / if ( h - > sei_pic_struct == SEI_PIC_STRUCT_TOP_BOTTOM || h - > sei_pic_struct == SEI_PIC_STRUCT_TOP_BOTTOM_TOP ) cur - > top_field_first = 1 ; else cur - > top_field_first = 0 ; } else { / * Most likely progressive * / cur - > top_field_first = 0 ; } } //FIXME do something with unavailable reference frames / * Sort B - frames into display order * / if ( h - > sps . bitstream_restriction_flag & & s - > avctx - > has_b_frames < h - > sps . num_reorder_frames ) { s - > avctx - > has_b_frames = h - > sps . num_reorder_frames ; s - > low_delay = 0 ; } if ( s - > avctx - > strict_std_compliance > = FF_COMPLIANCE_STRICT & & ! h - > sps . bitstream_restriction_flag ) { s - > avctx - > has_b_frames= MAX_DELAYED_PIC_COUNT ; s - > low_delay= 0 ; } pics = 0 ; while ( h - > delayed_pic[pics] ) pics + + ; assert ( pics < = MAX_DELAYED_PIC_COUNT ) ; h - > delayed_pic[pics + + ] = cur ; if ( cur - > reference == 0 ) cur - > reference = DELAYED_PIC_REF ; out = h - > delayed_pic[0] ; out_idx = 0 ; for ( i=1 ; h - > delayed_pic[i] & & ! h - > delayed_pic[i] - > key_frame & & ! h - > delayed_pic[i] - > mmco_reset ; i + + ) if ( h - > delayed_pic[i] - > poc < out - > poc ) { out = h - > delayed_pic[i] ; out_idx = i ; } if ( s - > avctx - > has_b_frames == 0 & & ( h - > delayed_pic[0] - > key_frame || h - > delayed_pic[0] - > mmco_reset ) ) h - > next_outputed_poc= INT_MIN ; out_of_order = out - > poc < h - > next_outputed_poc ; if ( h - > sps . bitstream_restriction_flag & & s - > avctx - > has_b_frames > = h - > sps . num_reorder_frames ) { } else if ( ( out_of_order & & pics - 1 == s - > avctx - > has_b_frames & & s - > avctx - > has_b_frames < MAX_DELAYED_PIC_COUNT ) || ( s - > low_delay & & ( ( h - > next_outputed_poc ! = INT_MIN & & out - > poc > h - > next_outputed_poc + 2 ) || cur - > pict_type == AV_PICTURE_TYPE_B ) ) ) { s - > low_delay = 0 ; s - > avctx - > has_b_frames + + ; } if ( out_of_order || pics > s - > avctx - > has_b_frames ) { out - > reference & = DELAYED_PIC_REF ; out - > owner2 = s ; // for frame threading , the owner must be the second field ' s thread // or else the first thread can release the picture and reuse it unsafely for ( i=out_idx ; h - > delayed_pic[i] ; i + + ) h - > delayed_pic[i] = h - > delayed_pic[i + 1] ; } if ( ! out_of_order & & pics > s - > avctx - > has_b_frames ) { h - > next_output_pic = out ; if ( out_idx==0 & & h - > delayed_pic[0] & & ( h - > delayed_pic[0] - > key_frame || h - > delayed_pic[0] - > mmco_reset ) ) { h - > next_outputed_poc = INT_MIN ; } else h - > next_outputed_poc = out - > poc ; } else { av_log ( s - > avctx , AV_LOG_DEBUG , no picture\n ) ; } ff_thread_finish_setup ( s - > avctx ) ; }",1
"static int decode_pic_timing ( HEVCContext * s ) { GetBitContext * gb = & s - > HEVClc - > gb ; HEVCSPS * sps = ( HEVCSPS * ) s - > sps_list[s - > active_seq_parameter_set_id] - > data ; if ( ! sps ) return ( AVERROR ( ENOMEM ) ) ; if ( sps - > vui . frame_field_info_present_flag ) { int pic_struct = get_bits ( gb , 4 ) ; s - > picture_struct = AV_PICTURE_STRUCTURE_UNKNOWN ; if ( pic_struct == 2 ) { av_log ( s - > avctx , AV_LOG_DEBUG , BOTTOM Field\n ) ; s - > picture_struct = AV_PICTURE_STRUCTURE_BOTTOM_FIELD ; } else if ( pic_struct == 1 ) { av_log ( s - > avctx , AV_LOG_DEBUG , TOP Field\n ) ; s - > picture_struct = AV_PICTURE_STRUCTURE_TOP_FIELD ; } get_bits ( gb , 2 ) ; // source_scan_type get_bits ( gb , 1 ) ; // duplicate_flag } return 1 ; }",1
"static void * circular_buffer_task ( void * _URLContext ) { URLContext * h = _URLContext ; UDPContext * s = h - > priv_data ; fd_set rfds ; struct timeval tv ; while ( ! s - > exit_thread ) { int left ; int ret ; int len ; if ( ff_check_interrupt ( & h - > interrupt_callback ) ) { s - > circular_buffer_error = AVERROR ( EINTR ) ; goto end ; } FD_ZERO ( & rfds ) ; FD_SET ( s - > udp_fd , & rfds ) ; tv . tv_sec = 1 ; tv . tv_usec = 0 ; ret = select ( s - > udp_fd + 1 , & rfds , NULL , NULL , & tv ) ; if ( ret < 0 ) { if ( ff_neterrno ( ) == AVERROR ( EINTR ) ) continue ; s - > circular_buffer_error = AVERROR ( EIO ) ; goto end ; } if ( ! ( ret > 0 & & FD_ISSET ( s - > udp_fd , & rfds ) ) ) continue ; / * How much do we have left to the end of the buffer * / / * Whats the minimum we can read so that we dont comletely fill the buffer * / left = av_fifo_space ( s - > fifo ) ; / * No Space left , error , what do we do now * / if ( left < UDP_MAX_PKT_SIZE + 4 ) { av_log ( h , AV_LOG_ERROR , circular_buffer : OVERRUN\n ) ; s - > circular_buffer_error = AVERROR ( EIO ) ; goto end ; } len = recv ( s - > udp_fd , s - > tmp + 4 , sizeof ( s - > tmp ) - 4 , 0 ) ; if ( len < 0 ) { if ( ff_neterrno ( ) ! = AVERROR ( EAGAIN ) & & ff_neterrno ( ) ! = AVERROR ( EINTR ) ) { s - > circular_buffer_error = AVERROR ( EIO ) ; goto end ; } continue ; } AV_WL32 ( s - > tmp , len ) ; pthread_mutex_lock ( & s - > mutex ) ; av_fifo_generic_write ( s - > fifo , s - > tmp , len + 4 , NULL ) ; pthread_cond_signal ( & s - > cond ) ; pthread_mutex_unlock ( & s - > mutex ) ; } end : pthread_mutex_lock ( & s - > mutex ) ; pthread_cond_signal ( & s - > cond ) ; pthread_mutex_unlock ( & s - > mutex ) ; return NULL ; }",1
"static int decode_rle ( uint8_t * bitmap , int linesize , int w , int h , const uint8_t * buf , int start , int buf_size , int is_8bit ) { GetBitContext gb ; int bit_len ; int x , y , len , color ; uint8_t * d ; if ( start > = buf_size ) bit_len = ( buf_size - start ) * 8 ; init_get_bits ( & gb , buf + start , bit_len ) ; x = 0 ; y = 0 ; d = bitmap ; for ( ; ; ) { if ( get_bits_count ( & gb ) > bit_len ) if ( is_8bit ) len = decode_run_8bit ( & gb , & color ) ; else len = decode_run_2bit ( & gb , & color ) ; len = FFMIN ( len , w - x ) ; memset ( d + x , color , len ) ; x + = len ; if ( x > = w ) { y + + ; if ( y > = h ) break ; d + = linesize ; x = 0 ; / * byte align * / align_get_bits ( & gb ) ; } } return 0 ; }",1
"static void decode ( AVCodecContext * dec_ctx , AVFrame * frame , AVPacket * pkt , const char * filename ) { char buf[1024] ; int ret ; ret = avcodec_send_packet ( dec_ctx , pkt ) ; if ( ret < 0 ) { fprintf ( stderr , Error sending a packet for decoding\n ) ; exit ( 1 ) ; } while ( ret > = 0 ) { ret = avcodec_receive_frame ( dec_ctx , frame ) ; if ( ret == AVERROR ( EAGAIN ) || ret == AVERROR_EOF ) return ; else if ( ret < 0 ) { fprintf ( stderr , Error during decoding\n ) ; exit ( 1 ) ; } printf ( saving frame %3d\n , dec_ctx - > frame_number ) ; fflush ( stdout ) ; / * the picture is allocated by the decoder . no need to free it * / snprintf ( buf , sizeof ( buf ) , filename , dec_ctx - > frame_number ) ; pgm_save ( frame - > data[0] , frame - > linesize[0] , frame - > width , frame - > height , buf ) ; } }",1
"static void ripemd128_transform ( uint32_t * state , const uint8_t buffer[64] , int ext ) { uint32_t a , b , c , d , e , f , g , h ; uint32_t block[16] ; int n ; if ( ext ) { a = state[0] ; b = state[1] ; c = state[2] ; d = state[3] ; e = state[4] ; f = state[5] ; g = state[6] ; h = state[7] ; } else { a = e = state[0] ; b = f = state[1] ; c = g = state[2] ; d = h = state[3] ; } for ( n = 0 ; n < 16 ; n + + ) block[n] = AV_RL32 ( buffer + 4 * n ) ; for ( n = 0 ; n < 16 ; ) { ROUND128_0_TO_15 ( a , b , c , d , e , f , g , h ) ; ROUND128_0_TO_15 ( d , a , b , c , h , e , f , g ) ; ROUND128_0_TO_15 ( c , d , a , b , g , h , e , f ) ; ROUND128_0_TO_15 ( b , c , d , a , f , g , h , e ) ; } SWAP ( a , e ) for ( ; n < 32 ; ) { ROUND128_16_TO_31 ( a , b , c , d , e , f , g , h ) ; ROUND128_16_TO_31 ( d , a , b , c , h , e , f , g ) ; ROUND128_16_TO_31 ( c , d , a , b , g , h , e , f ) ; ROUND128_16_TO_31 ( b , c , d , a , f , g , h , e ) ; } SWAP ( b , f ) for ( ; n < 48 ; ) { ROUND128_32_TO_47 ( a , b , c , d , e , f , g , h ) ; ROUND128_32_TO_47 ( d , a , b , c , h , e , f , g ) ; ROUND128_32_TO_47 ( c , d , a , b , g , h , e , f ) ; ROUND128_32_TO_47 ( b , c , d , a , f , g , h , e ) ; } SWAP ( c , g ) for ( ; n < 64 ; ) { ROUND128_48_TO_63 ( a , b , c , d , e , f , g , h ) ; ROUND128_48_TO_63 ( d , a , b , c , h , e , f , g ) ; ROUND128_48_TO_63 ( c , d , a , b , g , h , e , f ) ; ROUND128_48_TO_63 ( b , c , d , a , f , g , h , e ) ; } SWAP ( d , h ) if ( ext ) { state[0] + = a ; state[1] + = b ; state[2] + = c ; state[3] + = d ; state[4] + = e ; state[5] + = f ; state[6] + = g ; state[7] + = h ; } else { h + = c + state[1] ; state[1] = state[2] + d + e ; state[2] = state[3] + a + f ; state[3] = state[0] + b + g ; state[0] = h ; } }",0
"static int mxf_read_seek ( AVFormatContext * s , int stream_index , int64_t sample_time , int flags ) { AVStream * st = s - > streams[stream_index] ; int64_t seconds ; if ( ! s - > bit_rate ) return AVERROR_INVALIDDATA ; if ( sample_time < 0 ) sample_time = 0 ; seconds = av_rescale ( sample_time , st - > time_base . num , st - > time_base . den ) ; avio_seek ( s - > pb , ( s - > bit_rate * seconds ) > > 3 , SEEK_SET ) ; ff_update_cur_dts ( s , st , sample_time ) ; return 0 ; }",1
"static int encode_apng ( AVCodecContext * avctx , AVPacket * pkt , const AVFrame * pict , int * got_packet ) { PNGEncContext * s = avctx - > priv_data ; int ret ; int enc_row_size ; size_t max_packet_size ; APNGFctlChunk fctl_chunk ; if ( pict & & avctx - > codec_id == AV_CODEC_ID_APNG & & s - > color_type == PNG_COLOR_TYPE_PALETTE ) { uint32_t checksum = av_crc ( av_crc_get_table ( AV_CRC_32_IEEE_LE ) , 0U , pict - > data[1] , 256 * sizeof ( uint32_t ) ) ; if ( avctx - > frame_number == 0 ) { s - > palette_checksum = checksum ; } else if ( checksum ! = s - > palette_checksum ) { av_log ( avctx , AV_LOG_ERROR , Input contains more than one unique palette . APNG does not support multiple palettes . \n ) ; return - 1 ; } } enc_row_size = deflateBound ( & s - > zstream , ( avctx - > width * s - > bits_per_pixel + 7 ) > > 3 ) ; max_packet_size = AV_INPUT_BUFFER_MIN_SIZE + // headers avctx - > height * ( enc_row_size + ( 4 + 12 ) * ( ( ( int64_t ) enc_row_size + IOBUF_SIZE - 1 ) / IOBUF_SIZE ) // fdAT * ceil ( enc_row_size / IOBUF_SIZE ) ) ; if ( max_packet_size > INT_MAX ) return AVERROR ( ENOMEM ) ; if ( avctx - > frame_number == 0 ) { s - > bytestream = avctx - > extradata = av_malloc ( FF_MIN_BUFFER_SIZE ) ; if ( ! avctx - > extradata ) return AVERROR ( ENOMEM ) ; ret = encode_headers ( avctx , pict ) ; if ( ret < 0 ) return ret ; avctx - > extradata_size = s - > bytestream - avctx - > extradata ; s - > last_frame_packet = av_malloc ( max_packet_size ) ; if ( ! s - > last_frame_packet ) return AVERROR ( ENOMEM ) ; } else if ( s - > last_frame ) { ret = ff_alloc_packet2 ( avctx , pkt , max_packet_size , 0 ) ; if ( ret < 0 ) return ret ; memcpy ( pkt - > data , s - > last_frame_packet , s - > last_frame_packet_size ) ; pkt - > size = s - > last_frame_packet_size ; pkt - > pts = pkt - > dts = s - > last_frame - > pts ; } if ( pict ) { s - > bytestream_start = s - > bytestream = s - > last_frame_packet ; s - > bytestream_end = s - > bytestream + max_packet_size ; // We ' re encoding the frame first , so we have to do a bit of shuffling around // to have the image data write to the correct place in the buffer fctl_chunk . sequence_number = s - > sequence_number ; + + s - > sequence_number ; s - > bytestream + = 26 + 12 ; ret = apng_encode_frame ( avctx , pict , & fctl_chunk , & s - > last_frame_fctl ) ; if ( ret < 0 ) return ret ; fctl_chunk . delay_num = 0 ; // delay filled in during muxing fctl_chunk . delay_den = 0 ; } else { s - > last_frame_fctl . dispose_op = APNG_DISPOSE_OP_NONE ; } if ( s - > last_frame ) { uint8_t * last_fctl_chunk_start = pkt - > data ; uint8_t buf[26] ; AV_WB32 ( buf + 0 , s - > last_frame_fctl . sequence_number ) ; AV_WB32 ( buf + 4 , s - > last_frame_fctl . width ) ; AV_WB32 ( buf + 8 , s - > last_frame_fctl . height ) ; AV_WB32 ( buf + 12 , s - > last_frame_fctl . x_offset ) ; AV_WB32 ( buf + 16 , s - > last_frame_fctl . y_offset ) ; AV_WB16 ( buf + 20 , s - > last_frame_fctl . delay_num ) ; AV_WB16 ( buf + 22 , s - > last_frame_fctl . delay_den ) ; buf[24] = s - > last_frame_fctl . dispose_op ; buf[25] = s - > last_frame_fctl . blend_op ; png_write_chunk ( & last_fctl_chunk_start , MKTAG ( ' f ' , ' c ' , ' T ' , ' L ' ) , buf , 26 ) ; * got_packet = 1 ; } if ( pict ) { if ( ! s - > last_frame ) { s - > last_frame = av_frame_alloc ( ) ; if ( ! s - > last_frame ) return AVERROR ( ENOMEM ) ; } else if ( s - > last_frame_fctl . dispose_op ! = APNG_DISPOSE_OP_PREVIOUS ) { if ( ! s - > prev_frame ) { s - > prev_frame = av_frame_alloc ( ) ; if ( ! s - > prev_frame ) return AVERROR ( ENOMEM ) ; s - > prev_frame - > format = pict - > format ; s - > prev_frame - > width = pict - > width ; s - > prev_frame - > height = pict - > height ; if ( ( ret = av_frame_get_buffer ( s - > prev_frame , 32 ) ) < 0 ) return ret ; } // Do disposal , but not blending memcpy ( s - > prev_frame - > data[0] , s - > last_frame - > data[0] , s - > last_frame - > linesize[0] * s - > last_frame - > height ) ; if ( s - > last_frame_fctl . dispose_op == APNG_DISPOSE_OP_BACKGROUND ) { uint32_t y ; uint8_t bpp = ( s - > bits_per_pixel + 7 ) > > 3 ; for ( y = s - > last_frame_fctl . y_offset ; y < s - > last_frame_fctl . y_offset + s - > last_frame_fctl . height ; + + y ) { size_t row_start = s - > last_frame - > linesize[0] * y + bpp * s - > last_frame_fctl . x_offset ; memset ( s - > prev_frame - > data[0] + row_start , 0 , bpp * s - > last_frame_fctl . width ) ; } } } av_frame_unref ( s - > last_frame ) ; ret = av_frame_ref ( s - > last_frame , ( AVFrame * ) pict ) ; if ( ret < 0 ) return ret ; s - > last_frame_fctl = fctl_chunk ; s - > last_frame_packet_size = s - > bytestream - s - > bytestream_start ; } else { av_frame_free ( & s - > last_frame ) ; } return 0 ; }",1
"int ff_combine_frame ( ParseContext * pc , int next , const uint8_t * * buf , int * buf_size ) { if ( pc - > overread ) { av_dlog ( NULL , overread %d , state : %X next : %d index : %d o_index : %d\n , pc - > overread , pc - > state , next , pc - > index , pc - > overread_index ) ; av_dlog ( NULL , %X %X %X %X\n , ( * buf ) [0] , ( * buf ) [1] , ( * buf ) [2] , ( * buf ) [3] ) ; } / * Copy overread bytes from last frame into buffer . * / for ( ; pc - > overread > 0 ; pc - > overread - - ) { pc - > buffer[pc - > index + + ]= pc - > buffer[pc - > overread_index + + ] ; } / * flush remaining if EOF * / if ( ! * buf_size & & next == END_NOT_FOUND ) { next= 0 ; } pc - > last_index= pc - > index ; / * copy into buffer end return * / if ( next == END_NOT_FOUND ) { void * new_buffer = av_fast_realloc ( pc - > buffer , & pc - > buffer_size , ( * buf_size ) + pc - > index + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! new_buffer ) return AVERROR ( ENOMEM ) ; pc - > buffer = new_buffer ; memcpy ( & pc - > buffer[pc - > index] , * buf , * buf_size ) ; pc - > index + = * buf_size ; return - 1 ; } * buf_size= pc - > overread_index= pc - > index + next ; / * append to buffer * / if ( pc - > index ) { void * new_buffer = av_fast_realloc ( pc - > buffer , & pc - > buffer_size , next + pc - > index + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! new_buffer ) return AVERROR ( ENOMEM ) ; pc - > buffer = new_buffer ; memcpy ( & pc - > buffer[pc - > index] , * buf , next + FF_INPUT_BUFFER_PADDING_SIZE ) ; pc - > index = 0 ; * buf= pc - > buffer ; } / * store overread bytes * / for ( ; next < 0 ; next + + ) { pc - > state = ( pc - > state < < 8 ) | pc - > buffer[pc - > last_index + next] ; pc - > state64 = ( pc - > state64 < < 8 ) | pc - > buffer[pc - > last_index + next] ; pc - > overread + + ; } if ( pc - > overread ) { av_dlog ( NULL , overread %d , state : %X next : %d index : %d o_index : %d\n , pc - > overread , pc - > state , next , pc - > index , pc - > overread_index ) ; av_dlog ( NULL , %X %X %X %X\n , ( * buf ) [0] , ( * buf ) [1] , ( * buf ) [2] , ( * buf ) [3] ) ; } return 0 ; }",1
"static void qtrle_decode_1bpp ( QtrleContext * s , int stream_ptr , int row_ptr , int lines_to_change ) { int rle_code ; int pixel_ptr = 0 ; int row_inc = s - > frame . linesize[0] ; unsigned char pi0 , pi1 ; / * 2 8 - pixel values * / unsigned char * rgb = s - > frame . data[0] ; int pixel_limit = s - > frame . linesize[0] * s - > avctx - > height ; int skip ; while ( lines_to_change ) { CHECK_STREAM_PTR ( 2 ) ; skip = s - > buf[stream_ptr + + ] ; rle_code = ( signed char ) s - > buf[stream_ptr + + ] ; if ( rle_code == 0 ) break ; if ( skip & 0x80 ) { lines_to_change - - ; row_ptr + = row_inc ; pixel_ptr = row_ptr + 2 * ( skip & 0x7f ) ; } else pixel_ptr + = 2 * skip ; CHECK_PIXEL_PTR ( 0 ) ; / * make sure pixel_ptr is positive * / if ( rle_code < 0 ) { / * decode the run length code * / rle_code = - rle_code ; / * get the next 2 bytes from the stream , treat them as groups * of 8 pixels , and output them rle_code times * / CHECK_STREAM_PTR ( 2 ) ; pi0 = s - > buf[stream_ptr + + ] ; pi1 = s - > buf[stream_ptr + + ] ; CHECK_PIXEL_PTR ( rle_code * 2 ) ; while ( rle_code - - ) { rgb[pixel_ptr + + ] = pi0 ; rgb[pixel_ptr + + ] = pi1 ; } } else { / * copy the same pixel directly to output 2 times * / rle_code * = 2 ; CHECK_STREAM_PTR ( rle_code ) ; CHECK_PIXEL_PTR ( rle_code ) ; while ( rle_code - - ) rgb[pixel_ptr + + ] = s - > buf[stream_ptr + + ] ; } } }",1
"static int libopenjpeg_encode_frame ( AVCodecContext * avctx , AVPacket * pkt , const AVFrame * frame , int * got_packet ) { LibOpenJPEGContext * ctx = avctx - > priv_data ; opj_cinfo_t * compress = ctx - > compress ; opj_image_t * image = ctx - > image ; opj_cio_t * stream = ctx - > stream ; int cpyresult = 0 ; int ret , len ; AVFrame * gbrframe ; switch ( avctx - > pix_fmt ) { case AV_PIX_FMT_RGB24 : case AV_PIX_FMT_RGBA : case AV_PIX_FMT_GRAY8A : cpyresult = libopenjpeg_copy_packed8 ( avctx , frame , image ) ; break ; case AV_PIX_FMT_XYZ12 : cpyresult = libopenjpeg_copy_packed12 ( avctx , frame , image ) ; break ; case AV_PIX_FMT_RGB48 : case AV_PIX_FMT_RGBA64 : cpyresult = libopenjpeg_copy_packed16 ( avctx , frame , image ) ; break ; case AV_PIX_FMT_GBR24P : case AV_PIX_FMT_GBRP9 : case AV_PIX_FMT_GBRP10 : case AV_PIX_FMT_GBRP12 : case AV_PIX_FMT_GBRP14 : case AV_PIX_FMT_GBRP16 : gbrframe = av_frame_alloc ( ) ; if ( ! gbrframe ) return AVERROR ( ENOMEM ) ; av_frame_ref ( gbrframe , frame ) ; gbrframe - > data[0] = frame - > data[2] ; // swap to be rgb gbrframe - > data[1] = frame - > data[0] ; gbrframe - > data[2] = frame - > data[1] ; gbrframe - > linesize[0] = frame - > linesize[2] ; gbrframe - > linesize[1] = frame - > linesize[0] ; gbrframe - > linesize[2] = frame - > linesize[1] ; if ( avctx - > pix_fmt == AV_PIX_FMT_GBR24P ) { cpyresult = libopenjpeg_copy_unpacked8 ( avctx , gbrframe , image ) ; } else { cpyresult = libopenjpeg_copy_unpacked16 ( avctx , gbrframe , image ) ; } av_frame_free ( & gbrframe ) ; break ; case AV_PIX_FMT_GRAY8 : case AV_PIX_FMT_YUV410P : case AV_PIX_FMT_YUV411P : case AV_PIX_FMT_YUV420P : case AV_PIX_FMT_YUV422P : case AV_PIX_FMT_YUV440P : case AV_PIX_FMT_YUV444P : case AV_PIX_FMT_YUVA420P : case AV_PIX_FMT_YUVA422P : case AV_PIX_FMT_YUVA444P : cpyresult = libopenjpeg_copy_unpacked8 ( avctx , frame , image ) ; break ; case AV_PIX_FMT_GRAY16 : case AV_PIX_FMT_YUV420P9 : case AV_PIX_FMT_YUV422P9 : case AV_PIX_FMT_YUV444P9 : case AV_PIX_FMT_YUVA420P9 : case AV_PIX_FMT_YUVA422P9 : case AV_PIX_FMT_YUVA444P9 : case AV_PIX_FMT_YUV444P10 : case AV_PIX_FMT_YUV422P10 : case AV_PIX_FMT_YUV420P10 : case AV_PIX_FMT_YUVA444P10 : case AV_PIX_FMT_YUVA422P10 : case AV_PIX_FMT_YUVA420P10 : case AV_PIX_FMT_YUV420P12 : case AV_PIX_FMT_YUV422P12 : case AV_PIX_FMT_YUV444P12 : case AV_PIX_FMT_YUV420P14 : case AV_PIX_FMT_YUV422P14 : case AV_PIX_FMT_YUV444P14 : case AV_PIX_FMT_YUV444P16 : case AV_PIX_FMT_YUV422P16 : case AV_PIX_FMT_YUV420P16 : case AV_PIX_FMT_YUVA444P16 : case AV_PIX_FMT_YUVA422P16 : case AV_PIX_FMT_YUVA420P16 : cpyresult = libopenjpeg_copy_unpacked16 ( avctx , frame , image ) ; break ; default : av_log ( avctx , AV_LOG_ERROR , The frame ' s pixel format ' %s ' is not supported\n , av_get_pix_fmt_name ( avctx - > pix_fmt ) ) ; return AVERROR ( EINVAL ) ; break ; } if ( ! cpyresult ) { av_log ( avctx , AV_LOG_ERROR , Could not copy the frame data to the internal image buffer\n ) ; return - 1 ; } cio_seek ( stream , 0 ) ; if ( ! opj_encode ( compress , stream , image , NULL ) ) { av_log ( avctx , AV_LOG_ERROR , Error during the opj encode\n ) ; return - 1 ; } len = cio_tell ( stream ) ; if ( ( ret = ff_alloc_packet2 ( avctx , pkt , len ) ) < 0 ) { return ret ; } memcpy ( pkt - > data , stream - > buffer , len ) ; pkt - > flags |= AV_PKT_FLAG_KEY ; * got_packet = 1 ; return 0 ; }",0
"static void format_line ( void * ptr , int level , const char * fmt , va_list vl , AVBPrint part[3] , int * print_prefix , int type[2] ) { AVClass * avc = ptr ? * ( AVClass * * ) ptr : NULL ; av_bprint_init ( part + 0 , 0 , 1 ) ; av_bprint_init ( part + 1 , 0 , 1 ) ; av_bprint_init ( part + 2 , 0 , 65536 ) ; if ( type ) type[0] = type[1] = AV_CLASS_CATEGORY_NA + 16 ; if ( * print_prefix & & avc ) { if ( avc - > parent_log_context_offset ) { AVClass * * parent = * ( AVClass * * * ) ( ( ( uint8_t * ) ptr ) + avc - > parent_log_context_offset ) ; if ( parent & & * parent ) { av_bprintf ( part + 0 , [%s %p] , ( * parent ) - > item_name ( parent ) , parent ) ; if ( type ) type[0] = get_category ( parent ) ; } } av_bprintf ( part + 1 , [%s %p] , avc - > item_name ( ptr ) , ptr ) ; if ( type ) type[1] = get_category ( ptr ) ; } av_vbprintf ( part + 2 , fmt , vl ) ; if ( * part[0] . str || * part[1] . str || * part[2] . str ) { char lastc = part[2] . len ? part[2] . str[part[2] . len - 1] : 0 ; * print_prefix = lastc == ' \n ' || lastc == ' \r ' ; } }",0
"static av_cold int vaapi_encode_mjpeg_init ( AVCodecContext * avctx ) { return ff_vaapi_encode_init ( avctx , & vaapi_encode_type_mjpeg ) ; }",0
static inline int is_yuv_planar ( const PixFmtInfo * ps ) { return ( ps - > color_type == FF_COLOR_YUV || ps - > color_type == FF_COLOR_YUV_JPEG ) & & ps - > pixel_type == FF_PIXEL_PLANAR ; },0
"static int dnxhd_init_vlc ( DNXHDContext * ctx , uint32_t cid ) { if ( cid ! = ctx - > cid ) { int index ; if ( ( index = ff_dnxhd_get_cid_table ( cid ) ) < 0 ) { av_log ( ctx - > avctx , AV_LOG_ERROR , unsupported cid %d\n , cid ) ; return AVERROR ( ENOSYS ) ; } if ( ff_dnxhd_cid_table[index] . bit_depth ! = ctx - > bit_depth ) { av_log ( ctx - > avctx , AV_LOG_ERROR , bit depth mismatches %d %d\n , ff_dnxhd_cid_table[index] . bit_depth , ctx - > bit_depth ) ; return AVERROR_INVALIDDATA ; } ctx - > cid_table = & ff_dnxhd_cid_table[index] ; av_log ( ctx - > avctx , AV_LOG_VERBOSE , Profile cid %d . \n , cid ) ; ff_free_vlc ( & ctx - > ac_vlc ) ; ff_free_vlc ( & ctx - > dc_vlc ) ; ff_free_vlc ( & ctx - > run_vlc ) ; init_vlc ( & ctx - > ac_vlc , DNXHD_VLC_BITS , 257 , ctx - > cid_table - > ac_bits , 1 , 1 , ctx - > cid_table - > ac_codes , 2 , 2 , 0 ) ; init_vlc ( & ctx - > dc_vlc , DNXHD_DC_VLC_BITS , ctx - > bit_depth + 4 , ctx - > cid_table - > dc_bits , 1 , 1 , ctx - > cid_table - > dc_codes , 1 , 1 , 0 ) ; init_vlc ( & ctx - > run_vlc , DNXHD_VLC_BITS , 62 , ctx - > cid_table - > run_bits , 1 , 1 , ctx - > cid_table - > run_codes , 2 , 2 , 0 ) ; ctx - > cid = cid ; } return 0 ; }",0
"int av_opencl_create_kernel ( AVOpenCLKernelEnv * env , const char * kernel_name ) { cl_int status ; int i , ret = 0 ; LOCK_OPENCL ; if ( strlen ( kernel_name ) + 1 > AV_OPENCL_MAX_KERNEL_NAME_SIZE ) { av_log ( & openclutils , AV_LOG_ERROR , Created kernel name %s is too long\n , kernel_name ) ; ret = AVERROR ( EINVAL ) ; goto end ; } if ( ! env - > kernel ) { if ( gpu_env . kernel_count > = MAX_KERNEL_NUM ) { av_log ( & openclutils , AV_LOG_ERROR , Could not create kernel with name ' %s ' , maximum number of kernels %d already reached\n , kernel_name , MAX_KERNEL_NUM ) ; ret = AVERROR ( EINVAL ) ; goto end ; } for ( i = 0 ; i < gpu_env . program_count ; i + + ) { env - > kernel = clCreateKernel ( gpu_env . programs[i] , kernel_name , & status ) ; if ( status == CL_SUCCESS ) break ; } if ( status ! = CL_SUCCESS ) { av_log ( & openclutils , AV_LOG_ERROR , Could not create OpenCL kernel : %s\n , opencl_errstr ( status ) ) ; ret = AVERROR_EXTERNAL ; goto end ; } gpu_env . kernel_count + + ; env - > command_queue = gpu_env . command_queue ; av_strlcpy ( env - > kernel_name , kernel_name , sizeof ( env - > kernel_name ) ) ; } end : UNLOCK_OPENCL ; return ret ; }",0
"static av_cold int a64multi_init_encoder ( AVCodecContext * avctx ) { A64Context * c = avctx - > priv_data ; int a ; av_lfg_init ( & c - > randctx , 1 ) ; if ( avctx - > global_quality < 1 ) { c - > mc_lifetime = 4 ; } else { c - > mc_lifetime = avctx - > global_quality /= FF_QP2LAMBDA ; } av_log ( avctx , AV_LOG_INFO , charset lifetime set to %d frame ( s ) \n , c - > mc_lifetime ) ; / * precalc luma values for later use * / for ( a = 0 ; a < 5 ; a + + ) { c - > mc_luma_vals[a]=a64_palette[mc_colors[a]][0] * 0 . 30 + a64_palette[mc_colors[a]][1] * 0 . 59 + a64_palette[mc_colors[a]][2] * 0 . 11 ; } c - > mc_frame_counter = 0 ; c - > mc_use_5col = avctx - > codec - > id == CODEC_ID_A64_MULTI5 ; c - > mc_meta_charset = av_malloc ( 32000 * c - > mc_lifetime * sizeof ( int ) ) ; c - > mc_best_cb = av_malloc ( CHARSET_CHARS * 32 * sizeof ( int ) ) ; c - > mc_charmap = av_mallocz ( 1000 * c - > mc_lifetime * sizeof ( int ) ) ; c - > mc_colram = av_mallocz ( CHARSET_CHARS * sizeof ( uint8_t ) ) ; c - > mc_charset = av_malloc ( 0x800 * ( INTERLACED + 1 ) * sizeof ( uint8_t ) ) ; / * set up extradata * / avctx - > extradata = av_mallocz ( 8 * 4 + FF_INPUT_BUFFER_PADDING_SIZE ) ; avctx - > extradata_size = 8 * 4 ; AV_WB32 ( avctx - > extradata , c - > mc_lifetime ) ; AV_WB32 ( avctx - > extradata + 16 , INTERLACED ) ; avcodec_get_frame_defaults ( & c - > picture ) ; avctx - > coded_frame = & c - > picture ; avctx - > coded_frame - > pict_type = FF_I_TYPE ; avctx - > coded_frame - > key_frame = 1 ; if ( ! avctx - > codec_tag ) avctx - > codec_tag = AV_RL32 ( a64m ) ; return 0 ; }",0
"static int pulse_write_packet ( AVFormatContext * h , AVPacket * pkt ) { PulseData * s = h - > priv_data ; int size = pkt - > size ; uint8_t * buf = pkt - > data ; int error ; if ( s - > stream_index ! = pkt - > stream_index ) return 0 ; if ( ( error = pa_simple_write ( s - > pa , buf , size , & error ) ) ) { av_log ( s , AV_LOG_ERROR , pa_simple_write failed : %s\n , pa_strerror ( error ) ) ; return AVERROR ( EIO ) ; } return 0 ; }",0
"static void check_default_settings ( AVCodecContext * avctx ) { X264Context * x4 = avctx - > priv_data ; int score = 0 ; score + = x4 - > params . analyse . i_me_range == 0 ; score + = x4 - > params . rc . i_qp_step == 3 ; score + = x4 - > params . i_keyint_max == 12 ; score + = x4 - > params . rc . i_qp_min == 2 ; score + = x4 - > params . rc . i_qp_max == 31 ; score + = x4 - > params . rc . f_qcompress == 0 . 5 ; score + = fabs ( x4 - > params . rc . f_ip_factor - 1 . 25 ) < 0 . 01 ; score + = fabs ( x4 - > params . rc . f_pb_factor - 1 . 25 ) < 0 . 01 ; score + = x4 - > params . analyse . inter == 0 & & x4 - > params . analyse . i_subpel_refine == 8 ; if ( score > = 5 ) { av_log ( avctx , AV_LOG_ERROR , Default settings detected , using medium profile\n ) ; x4 - > preset = av_strdup ( medium ) ; if ( avctx - > bit_rate == 200 * 1000 ) avctx - > crf = 23 ; } }",0
"static inline int decode_picture_parameter_set ( H264Context * h , int bit_length ) { MpegEncContext * const s = & h - > s ; unsigned int tmp , pps_id= get_ue_golomb ( & s - > gb ) ; PPS * pps ; pps = alloc_parameter_set ( h , ( void * * ) h - > pps_buffers , pps_id , MAX_PPS_COUNT , sizeof ( PPS ) , pps ) ; if ( pps == NULL ) return - 1 ; tmp= get_ue_golomb ( & s - > gb ) ; if ( tmp > =MAX_SPS_COUNT || h - > sps_buffers[tmp] == NULL ) { av_log ( h - > s . avctx , AV_LOG_ERROR , sps_id out of range\n ) ; return - 1 ; } pps - > sps_id= tmp ; pps - > cabac= get_bits1 ( & s - > gb ) ; pps - > pic_order_present= get_bits1 ( & s - > gb ) ; pps - > slice_group_count= get_ue_golomb ( & s - > gb ) + 1 ; if ( pps - > slice_group_count > 1 ) { pps - > mb_slice_group_map_type= get_ue_golomb ( & s - > gb ) ; av_log ( h - > s . avctx , AV_LOG_ERROR , FMO not supported\n ) ; switch ( pps - > mb_slice_group_map_type ) { case 0 : if 0 | for ( i = 0 ; i < = num_slice_groups_minus1 ; i + + ) | | | | run_length[ i ] |1 |ue ( v ) | endif break ; case 2 : if 0 | for ( i = 0 ; i < num_slice_groups_minus1 ; i + + ) | | | | { | | | | top_left_mb[ i ] |1 |ue ( v ) | | bottom_right_mb[ i ] |1 |ue ( v ) | | } | | | endif break ; case 3 : case 4 : case 5 : if 0 | slice_group_change_direction_flag |1 |u ( 1 ) | | slice_group_change_rate_minus1 |1 |ue ( v ) | endif break ; case 6 : if 0 | slice_group_id_cnt_minus1 |1 |ue ( v ) | | for ( i = 0 ; i < = slice_group_id_cnt_minus1 ; i + + | | | | ) | | | | slice_group_id[ i ] |1 |u ( v ) | endif break ; } } pps - > ref_count[0]= get_ue_golomb ( & s - > gb ) + 1 ; pps - > ref_count[1]= get_ue_golomb ( & s - > gb ) + 1 ; if ( pps - > ref_count[0] - 1 > 32 - 1 || pps - > ref_count[1] - 1 > 32 - 1 ) { av_log ( h - > s . avctx , AV_LOG_ERROR , reference overflow ( pps ) \n ) ; pps - > ref_count[0]= pps - > ref_count[1]= 1 ; return - 1 ; } pps - > weighted_pred= get_bits1 ( & s - > gb ) ; pps - > weighted_bipred_idc= get_bits ( & s - > gb , 2 ) ; pps - > init_qp= get_se_golomb ( & s - > gb ) + 26 ; pps - > init_qs= get_se_golomb ( & s - > gb ) + 26 ; pps - > chroma_qp_index_offset[0]= get_se_golomb ( & s - > gb ) ; pps - > deblocking_filter_parameters_present= get_bits1 ( & s - > gb ) ; pps - > constrained_intra_pred= get_bits1 ( & s - > gb ) ; pps - > redundant_pic_cnt_present = get_bits1 ( & s - > gb ) ; pps - > transform_8x8_mode= 0 ; h - > dequant_coeff_pps= - 1 ; //contents of sps/pps can change even if id doesn ' t , so reinit memcpy ( pps - > scaling_matrix4 , h - > sps_buffers[pps - > sps_id] - > scaling_matrix4 , sizeof ( pps - > scaling_matrix4 ) ) ; memcpy ( pps - > scaling_matrix8 , h - > sps_buffers[pps - > sps_id] - > scaling_matrix8 , sizeof ( pps - > scaling_matrix8 ) ) ; if ( get_bits_count ( & s - > gb ) < bit_length ) { pps - > transform_8x8_mode= get_bits1 ( & s - > gb ) ; decode_scaling_matrices ( h , h - > sps_buffers[pps - > sps_id] , pps , 0 , pps - > scaling_matrix4 , pps - > scaling_matrix8 ) ; pps - > chroma_qp_index_offset[1]= get_se_golomb ( & s - > gb ) ; //second_chroma_qp_index_offset } else { pps - > chroma_qp_index_offset[1]= pps - > chroma_qp_index_offset[0] ; } build_qp_table ( pps , 0 , pps - > chroma_qp_index_offset[0] ) ; build_qp_table ( pps , 1 , pps - > chroma_qp_index_offset[1] ) ; if ( pps - > chroma_qp_index_offset[0] ! = pps - > chroma_qp_index_offset[1] ) h - > pps . chroma_qp_diff= 1 ; if ( s - > avctx - > debug & FF_DEBUG_PICT_INFO ) { av_log ( h - > s . avctx , AV_LOG_DEBUG , pps : %u sps : %u %s slice_groups : %d ref : %d/%d %s qp : %d/%d/%d/%d %s %s %s %s\n , pps_id , pps - > sps_id , pps - > cabac ? CABAC : CAVLC , pps - > slice_group_count , pps - > ref_count[0] , pps - > ref_count[1] , pps - > weighted_pred ? weighted : , pps - > init_qp , pps - > init_qs , pps - > chroma_qp_index_offset[0] , pps - > chroma_qp_index_offset[1] , pps - > deblocking_filter_parameters_present ? LPAR : , pps - > constrained_intra_pred ? CONSTR : , pps - > redundant_pic_cnt_present ? REDU : , pps - > transform_8x8_mode ? 8x8DCT : ) ; } return 0 ; }",0
"static int xface_encode_frame ( AVCodecContext * avctx , AVPacket * pkt , const AVFrame * frame , int * got_packet ) { XFaceContext * xface = avctx - > priv_data ; ProbRangesQueue pq = { { 0 } , 0 } ; uint8_t bitmap_copy[XFACE_PIXELS] ; BigInt b = { 0 } ; int i , j , k , ret = 0 ; const uint8_t * buf ; uint8_t * p ; char intbuf[XFACE_MAX_DIGITS] ; if ( avctx - > width || avctx - > height ) { if ( avctx - > width ! = XFACE_WIDTH || avctx - > height ! = XFACE_HEIGHT ) { av_log ( avctx , AV_LOG_ERROR , Size value %dx%d not supported , only accepts a size of %dx%d\n , avctx - > width , avctx - > height , XFACE_WIDTH , XFACE_HEIGHT ) ; return AVERROR ( EINVAL ) ; } } avctx - > width = XFACE_WIDTH ; avctx - > height = XFACE_HEIGHT ; / * convert image from MONOWHITE to 1=black 0=white bitmap * / buf = frame - > data[0] ; for ( i = 0 , j = 0 ; i < XFACE_PIXELS ; ) { for ( k = 0 ; k < 8 ; k + + ) xface - > bitmap[i + + ] = ( buf[j] > > ( 7 - k ) ) & 1 ; if ( + + j == XFACE_WIDTH/8 ) { buf + = frame - > linesize[0] ; j = 0 ; } } / * create a copy of bitmap * / memcpy ( bitmap_copy , xface - > bitmap , XFACE_PIXELS ) ; ff_xface_generate_face ( xface - > bitmap , bitmap_copy ) ; encode_block ( xface - > bitmap , 16 , 16 , 0 , & pq ) ; encode_block ( xface - > bitmap + 16 , 16 , 16 , 0 , & pq ) ; encode_block ( xface - > bitmap + 32 , 16 , 16 , 0 , & pq ) ; encode_block ( xface - > bitmap + XFACE_WIDTH * 16 , 16 , 16 , 0 , & pq ) ; encode_block ( xface - > bitmap + XFACE_WIDTH * 16 + 16 , 16 , 16 , 0 , & pq ) ; encode_block ( xface - > bitmap + XFACE_WIDTH * 16 + 32 , 16 , 16 , 0 , & pq ) ; encode_block ( xface - > bitmap + XFACE_WIDTH * 32 , 16 , 16 , 0 , & pq ) ; encode_block ( xface - > bitmap + XFACE_WIDTH * 32 + 16 , 16 , 16 , 0 , & pq ) ; encode_block ( xface - > bitmap + XFACE_WIDTH * 32 + 32 , 16 , 16 , 0 , & pq ) ; while ( pq . prob_ranges_idx > 0 ) push_integer ( & b , pq . prob_ranges[ - - pq . prob_ranges_idx] ) ; / * write the inverted big integer in b to intbuf * / i = 0 ; while ( b . nb_words ) { uint8_t r ; ff_big_div ( & b , XFACE_PRINTS , & r ) ; intbuf[i + + ] = r + XFACE_FIRST_PRINT ; } if ( ( ret = ff_alloc_packet2 ( avctx , pkt , i + 2 ) ) < 0 ) return ret ; / * revert the number , and close the buffer * / p = pkt - > data ; while ( - - i > = 0 ) * ( p + + ) = intbuf[i] ; * ( p + + ) = ' \n ' ; * ( p + + ) = 0 ; pkt - > flags |= AV_PKT_FLAG_KEY ; * got_packet = 1 ; return 0 ; }",0
"yuv2422_1_c_template ( SwsContext * c , const uint16_t * buf0 , const uint16_t * ubuf0 , const uint16_t * ubuf1 , const uint16_t * vbuf0 , const uint16_t * vbuf1 , const uint16_t * abuf0 , uint8_t * dest , int dstW , int uvalpha , enum PixelFormat dstFormat , int flags , int y , enum PixelFormat target ) { int i ; if ( uvalpha < 2048 ) { for ( i = 0 ; i < ( dstW > > 1 ) ; i + + ) { int Y1 = buf0[i * 2] > > 7 ; int Y2 = buf0[i * 2 + 1] > > 7 ; int U = ubuf1[i] > > 7 ; int V = vbuf1[i] > > 7 ; output_pixels ( i * 4 , Y1 , U , Y2 , V ) ; } } else { for ( i = 0 ; i < ( dstW > > 1 ) ; i + + ) { int Y1 = buf0[i * 2] > > 7 ; int Y2 = buf0[i * 2 + 1] > > 7 ; int U = ( ubuf0[i] + ubuf1[i] ) > > 8 ; int V = ( vbuf0[i] + vbuf1[i] ) > > 8 ; output_pixels ( i * 4 , Y1 , U , Y2 , V ) ; } } }",0
"static void encode_signal_range ( VC2EncContext * s ) { int idx ; AVCodecContext * avctx = s - > avctx ; const AVPixFmtDescriptor * fmt = av_pix_fmt_desc_get ( avctx - > pix_fmt ) ; const int depth = fmt - > comp[0] . depth ; if ( depth == 8 & & avctx - > color_range == AVCOL_RANGE_JPEG ) { idx = 1 ; s - > bpp = 1 ; s - > diff_offset = 128 ; } else if ( depth == 8 & & ( avctx - > color_range == AVCOL_RANGE_MPEG || avctx - > color_range == AVCOL_RANGE_UNSPECIFIED ) ) { idx = 2 ; s - > bpp = 1 ; s - > diff_offset = 128 ; } else if ( depth == 10 ) { idx = 3 ; s - > bpp = 2 ; s - > diff_offset = 512 ; } else { idx = 4 ; s - > bpp = 2 ; s - > diff_offset = 2048 ; } put_bits ( & s - > pb , 1 , ! s - > strict_compliance ) ; if ( ! s - > strict_compliance ) put_vc2_ue_uint ( & s - > pb , idx ) ; }",1
"static int webm_dash_manifest_write_header ( AVFormatContext * s ) { int i ; double start = 0 . 0 ; WebMDashMuxContext * w = s - > priv_data ; parse_adaptation_sets ( s ) ; write_header ( s ) ; avio_printf ( s - > pb , < Period id=\ 0\ ) ; avio_printf ( s - > pb , start=\ PT%gS\ , start ) ; if ( ! w - > is_live ) { avio_printf ( s - > pb , duration=\ PT%gS\ , get_duration ( s ) ) ; } avio_printf ( s - > pb , > \n ) ; for ( i = 0 ; i < w - > nb_as ; i + + ) { if ( write_adaptation_set ( s , i ) < 0 ) return - 1 ; } avio_printf ( s - > pb , < /Period > \n ) ; write_footer ( s ) ; return 0 ; }",1
"static av_cold int tta_decode_init ( AVCodecContext * avctx ) { TTAContext * s = avctx - > priv_data ; int i ; s - > avctx = avctx ; // 30bytes includes a seektable with one frame if ( avctx - > extradata_size < 30 ) return - 1 ; init_get_bits ( & s - > gb , avctx - > extradata , avctx - > extradata_size * 8 ) ; if ( show_bits_long ( & s - > gb , 32 ) == AV_RL32 ( TTA1 ) ) { / * signature * / skip_bits ( & s - > gb , 32 ) ; s - > format = get_bits ( & s - > gb , 16 ) ; if ( s - > format > 2 ) { av_log ( s - > avctx , AV_LOG_ERROR , Invalid format\n ) ; return - 1 ; if ( s - > format == FORMAT_ENCRYPTED ) { av_log_missing_feature ( s - > avctx , Encrypted TTA , 0 ) ; return AVERROR ( EINVAL ) ; avctx - > channels = s - > channels = get_bits ( & s - > gb , 16 ) ; avctx - > bits_per_coded_sample = get_bits ( & s - > gb , 16 ) ; s - > bps = ( avctx - > bits_per_coded_sample + 7 ) / 8 ; avctx - > sample_rate = get_bits_long ( & s - > gb , 32 ) ; s - > data_length = get_bits_long ( & s - > gb , 32 ) ; skip_bits ( & s - > gb , 32 ) ; // CRC32 of header switch ( s - > bps ) { case 2 : avctx - > sample_fmt = AV_SAMPLE_FMT_S16 ; avctx - > bits_per_raw_sample = 16 ; break ; case 3 : avctx - > sample_fmt = AV_SAMPLE_FMT_S32 ; avctx - > bits_per_raw_sample = 24 ; break ; default : av_log ( avctx , AV_LOG_ERROR , Invalid/unsupported sample format . \n ) ; // prevent overflow if ( avctx - > sample_rate > 0x7FFFFF ) { av_log ( avctx , AV_LOG_ERROR , sample_rate too large\n ) ; return AVERROR ( EINVAL ) ; s - > frame_length = 256 * avctx - > sample_rate / 245 ; s - > last_frame_length = s - > data_length % s - > frame_length ; s - > total_frames = s - > data_length / s - > frame_length + ( s - > last_frame_length ? 1 : 0 ) ; av_log ( s - > avctx , AV_LOG_DEBUG , format : %d chans : %d bps : %d rate : %d block : %d\n , s - > format , avctx - > channels , avctx - > bits_per_coded_sample , avctx - > sample_rate , avctx - > block_align ) ; av_log ( s - > avctx , AV_LOG_DEBUG , data_length : %d frame_length : %d last : %d total : %d\n , s - > data_length , s - > frame_length , s - > last_frame_length , s - > total_frames ) ; // FIXME : seek table for ( i = 0 ; i < s - > total_frames ; i + + ) skip_bits ( & s - > gb , 32 ) ; skip_bits ( & s - > gb , 32 ) ; // CRC32 of seektable if ( s - > frame_length > = UINT_MAX / ( s - > channels * sizeof ( int32_t ) ) ) { av_log ( avctx , AV_LOG_ERROR , frame_length too large\n ) ; return - 1 ; if ( s - > bps == 2 ) { s - > decode_buffer = av_mallocz ( sizeof ( int32_t ) * s - > frame_length * s - > channels ) ; if ( ! s - > decode_buffer ) return AVERROR ( ENOMEM ) ; s - > ch_ctx = av_malloc ( avctx - > channels * sizeof ( * s - > ch_ctx ) ) ; if ( ! s - > ch_ctx ) { av_freep ( & s - > decode_buffer ) ; return AVERROR ( ENOMEM ) ; } else { av_log ( avctx , AV_LOG_ERROR , Wrong extradata present\n ) ; return - 1 ; avcodec_get_frame_defaults ( & s - > frame ) ; avctx - > coded_frame = & s - > frame ; return 0 ;",1
"static int parse_ffconfig ( const char * filename ) { FILE * f ; char line[1024] ; char cmd[64] ; char arg[1024] ; const char * p ; int val , errors , line_num ; FFStream * * last_stream , * stream , * redirect ; FFStream * * last_feed , * feed , * s ; AVCodecContext audio_enc , video_enc ; enum AVCodecID audio_id , video_id ; f = fopen ( filename , r ) ; if ( ! f ) { perror ( filename ) ; return - 1 ; } errors = 0 ; line_num = 0 ; first_stream = NULL ; last_stream = & first_stream ; first_feed = NULL ; last_feed = & first_feed ; stream = NULL ; feed = NULL ; redirect = NULL ; audio_id = AV_CODEC_ID_NONE ; video_id = AV_CODEC_ID_NONE ; define ERROR ( . . . ) report_config_error ( filename , line_num , & errors , __VA_ARGS__ ) for ( ; ; ) { if ( fgets ( line , sizeof ( line ) , f ) == NULL ) break ; line_num + + ; p = line ; while ( av_isspace ( * p ) ) p + + ; if ( * p == ' \0 ' || * p == ' ' ) continue ; get_arg ( cmd , sizeof ( cmd ) , & p ) ; if ( ! av_strcasecmp ( cmd , Port ) ) { get_arg ( arg , sizeof ( arg ) , & p ) ; val = atoi ( arg ) ; if ( val < 1 || val > 65536 ) { ERROR ( Invalid_port : %s\n , arg ) ; } my_http_addr . sin_port = htons ( val ) ; } else if ( ! av_strcasecmp ( cmd , BindAddress ) ) { get_arg ( arg , sizeof ( arg ) , & p ) ; if ( resolve_host ( & my_http_addr . sin_addr , arg ) ! = 0 ) { ERROR ( %s : %d : Invalid host/IP address : %s\n , arg ) ; } } else if ( ! av_strcasecmp ( cmd , NoDaemon ) ) { // do nothing here , its the default now } else if ( ! av_strcasecmp ( cmd , RTSPPort ) ) { get_arg ( arg , sizeof ( arg ) , & p ) ; val = atoi ( arg ) ; if ( val < 1 || val > 65536 ) { ERROR ( %s : %d : Invalid port : %s\n , arg ) ; } my_rtsp_addr . sin_port = htons ( atoi ( arg ) ) ; } else if ( ! av_strcasecmp ( cmd , RTSPBindAddress ) ) { get_arg ( arg , sizeof ( arg ) , & p ) ; if ( resolve_host ( & my_rtsp_addr . sin_addr , arg ) ! = 0 ) { ERROR ( Invalid host/IP address : %s\n , arg ) ; } } else if ( ! av_strcasecmp ( cmd , MaxHTTPConnections ) ) { get_arg ( arg , sizeof ( arg ) , & p ) ; val = atoi ( arg ) ; if ( val < 1 || val > 65536 ) { ERROR ( Invalid MaxHTTPConnections : %s\n , arg ) ; } nb_max_http_connections = val ; } else if ( ! av_strcasecmp ( cmd , MaxClients ) ) { get_arg ( arg , sizeof ( arg ) , & p ) ; val = atoi ( arg ) ; if ( val < 1 || val > nb_max_http_connections ) { ERROR ( Invalid MaxClients : %s\n , arg ) ; } else { nb_max_connections = val ; } } else if ( ! av_strcasecmp ( cmd , MaxBandwidth ) ) { int64_t llval ; get_arg ( arg , sizeof ( arg ) , & p ) ; llval = strtoll ( arg , NULL , 10 ) ; if ( llval < 10 || llval > 10000000 ) { ERROR ( Invalid MaxBandwidth : %s\n , arg ) ; } else max_bandwidth = llval ; } else if ( ! av_strcasecmp ( cmd , CustomLog ) ) { if ( ! ffserver_debug ) get_arg ( logfilename , sizeof ( logfilename ) , & p ) ; } else if ( ! av_strcasecmp ( cmd , < Feed ) ) { / * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / / * Feed related options * / char * q ; if ( stream || feed ) { ERROR ( Already in a tag\n ) ; } else { feed = av_mallocz ( sizeof ( FFStream ) ) ; get_arg ( feed - > filename , sizeof ( feed - > filename ) , & p ) ; q = strrchr ( feed - > filename , ' > ' ) ; if ( * q ) * q = ' \0 ' ; for ( s = first_feed ; s ; s = s - > next ) { if ( ! strcmp ( feed - > filename , s - > filename ) ) { ERROR ( Feed ' %s ' already registered\n , s - > filename ) ; } } feed - > fmt = av_guess_format ( ffm , NULL , NULL ) ; / * defaut feed file * / snprintf ( feed - > feed_filename , sizeof ( feed - > feed_filename ) , /tmp/%s . ffm , feed - > filename ) ; feed - > feed_max_size = 5 * 1024 * 1024 ; feed - > is_feed = 1 ; feed - > feed = feed ; / * self feeding : - ) * / / * add in stream list * / * last_stream = feed ; last_stream = & feed - > next ; / * add in feed list * / * last_feed = feed ; last_feed = & feed - > next_feed ; } } else if ( ! av_strcasecmp ( cmd , Launch ) ) { if ( feed ) { int i ; feed - > child_argv = av_mallocz ( 64 * sizeof ( char * ) ) ; for ( i = 0 ; i < 62 ; i + + ) { get_arg ( arg , sizeof ( arg ) , & p ) ; if ( ! arg[0] ) break ; feed - > child_argv[i] = av_strdup ( arg ) ; } feed - > child_argv[i] = av_asprintf ( http : //%s : %d/%s , ( my_http_addr . sin_addr . s_addr == INADDR_ANY ) ? 127 . 0 . 0 . 1 : inet_ntoa ( my_http_addr . sin_addr ) , ntohs ( my_http_addr . sin_port ) , feed - > filename ) ; } } else if ( ! av_strcasecmp ( cmd , ReadOnlyFile ) ) { if ( feed ) { get_arg ( feed - > feed_filename , sizeof ( feed - > feed_filename",1
"static void updateMMXDitherTables ( SwsContext * c , int dstY , int lumBufIndex , int chrBufIndex , int lastInLumBuf , int lastInChrBuf ) { const int dstH= c - > dstH ; const int flags= c - > flags ; int16_t * * lumPixBuf= c - > lumPixBuf ; int16_t * * chrUPixBuf= c - > chrUPixBuf ; int16_t * * chrVPixBuf= c - > chrVPixBuf ; int16_t * * alpPixBuf= c - > alpPixBuf ; const int vLumBufSize= c - > vLumBufSize ; const int vChrBufSize= c - > vChrBufSize ; int16_t * vLumFilterPos= c - > vLumFilterPos ; int16_t * vChrFilterPos= c - > vChrFilterPos ; int16_t * vLumFilter= c - > vLumFilter ; int16_t * vChrFilter= c - > vChrFilter ; int32_t * lumMmxFilter= c - > lumMmxFilter ; int32_t * chrMmxFilter= c - > chrMmxFilter ; int32_t av_unused * alpMmxFilter= c - > alpMmxFilter ; const int vLumFilterSize= c - > vLumFilterSize ; const int vChrFilterSize= c - > vChrFilterSize ; const int chrDstY= dstY > > c - > chrDstVSubSample ; const int firstLumSrcY= vLumFilterPos[dstY] ; //First line needed as input const int firstChrSrcY= vChrFilterPos[chrDstY] ; //First line needed as input c - > blueDither= ff_dither8[dstY & 1] ; if ( c - > dstFormat == PIX_FMT_RGB555 || c - > dstFormat == PIX_FMT_BGR555 ) c - > greenDither= ff_dither8[dstY & 1] ; else c - > greenDither= ff_dither4[dstY & 1] ; c - > redDither= ff_dither8[ ( dstY + 1 ) & 1] ; if ( dstY < dstH - 2 ) { const int16_t * * lumSrcPtr= ( const int16_t * * ) lumPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize ; const int16_t * * chrUSrcPtr= ( const int16_t * * ) chrUPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize ; const int16_t * * chrVSrcPtr= ( const int16_t * * ) chrVPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize ; const int16_t * * alpSrcPtr= ( CONFIG_SWSCALE_ALPHA & & alpPixBuf ) ? ( const int16_t * * ) alpPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize : NULL ; int i ; if ( flags & SWS_ACCURATE_RND ) { int s= APCK_SIZE / 8 ; for ( i=0 ; i < vLumFilterSize ; i + =2 ) { * ( const void * * ) & lumMmxFilter[s * i ]= lumSrcPtr[i ] ; * ( const void * * ) & lumMmxFilter[s * i + APCK_PTR2/4 ]= lumSrcPtr[i + ( vLumFilterSize > 1 ) ] ; lumMmxFilter[s * i + APCK_COEF/4 ]= lumMmxFilter[s * i + APCK_COEF/4 + 1]= vLumFilter[dstY * vLumFilterSize + i ] + ( vLumFilterSize > 1 ? vLumFilter[dstY * vLumFilterSize + i + 1] < < 16 : 0 ) ; if ( CONFIG_SWSCALE_ALPHA & & alpPixBuf ) { * ( const void * * ) & alpMmxFilter[s * i ]= alpSrcPtr[i ] ; * ( const void * * ) & alpMmxFilter[s * i + APCK_PTR2/4 ]= alpSrcPtr[i + ( vLumFilterSize > 1 ) ] ; alpMmxFilter[s * i + APCK_COEF/4 ]= alpMmxFilter[s * i + APCK_COEF/4 + 1]= lumMmxFilter[s * i + APCK_COEF/4 ] ; } } for ( i=0 ; i < vChrFilterSize ; i + =2 ) { * ( const void * * ) & chrMmxFilter[s * i ]= chrUSrcPtr[i ] ; * ( const void * * ) & chrMmxFilter[s * i + APCK_PTR2/4 ]= chrUSrcPtr[i + ( vChrFilterSize > 1 ) ] ; chrMmxFilter[s * i + APCK_COEF/4 ]= chrMmxFilter[s * i + APCK_COEF/4 + 1]= vChrFilter[chrDstY * vChrFilterSize + i ] + ( vChrFilterSize > 1 ? vChrFilter[chrDstY * vChrFilterSize + i + 1] < < 16 : 0 ) ; } } else { for ( i=0 ; i < vLumFilterSize ; i + + ) { * ( const void * * ) & lumMmxFilter[4 * i + 0]= lumSrcPtr[i] ; lumMmxFilter[4 * i + 2]= lumMmxFilter[4 * i + 3]= ( ( uint16_t ) vLumFilter[dstY * vLumFilterSize + i] ) * 0x10001 ; if ( CONFIG_SWSCALE_ALPHA & & alpPixBuf ) { * ( const void * * ) & alpMmxFilter[4 * i + 0]= alpSrcPtr[i] ; alpMmxFilter[4 * i + 2]= alpMmxFilter[4 * i + 3]= lumMmxFilter[4 * i + 2] ; } } for ( i=0 ; i < vChrFilterSize ; i + + ) { * ( const void * * ) & chrMmxFilter[4 * i + 0]= chrUSrcPtr[i] ; chrMmxFilter[4 * i + 2]= chrMmxFilter[4 * i + 3]= ( ( uint16_t ) vChrFilter[chrDstY * vChrFilterSize + i] ) * 0x10001 ; } } } }",1
"static inline int decode_alpha_block ( const SHQContext * s , GetBitContext * gb , uint8_t last_alpha[16] , uint8_t * dest , int linesize ) { uint8_t block[128] ; int i = 0 , x , y ; memset ( block , 0 , sizeof ( block ) ) ; { OPEN_READER ( re , gb ) ; for ( ; ; ) { int run , level ; UPDATE_CACHE_LE ( re , gb ) ; GET_VLC ( run , re , gb , ff_dc_alpha_run_vlc_le . table , ALPHA_VLC_BITS , 2 ) ; if ( run == 128 ) break ; i + = run ; if ( i > = 128 ) return AVERROR_INVALIDDATA ; UPDATE_CACHE_LE ( re , gb ) ; GET_VLC ( level , re , gb , ff_dc_alpha_level_vlc_le . table , ALPHA_VLC_BITS , 2 ) ; block[i + + ] = level ; } CLOSE_READER ( re , gb ) ; } for ( y = 0 ; y < 8 ; y + + ) { for ( x = 0 ; x < 16 ; x + + ) { last_alpha[x] - = block[y * 16 + x] ; } memcpy ( dest , last_alpha , 16 ) ; dest + = linesize ; } return 0 ; }",1
"static int dvbsub_read_4bit_string ( uint8_t * destbuf , int dbuf_len , const uint8_t * * srcbuf , int buf_size , int non_mod , uint8_t * map_table ) { GetBitContext gb ; int bits ; int run_length ; int pixels_read = 0 ; init_get_bits ( & gb , * srcbuf , buf_size < < 3 ) ; while ( get_bits_count ( & gb ) < buf_size < < 3 & & pixels_read < dbuf_len ) { bits = get_bits ( & gb , 4 ) ; if ( bits ) { if ( non_mod ! = 1 || bits ! = 1 ) { if ( map_table ) * destbuf + + = map_table[bits] ; else * destbuf + + = bits ; } pixels_read + + ; } else { bits = get_bits1 ( & gb ) ; if ( bits == 0 ) { run_length = get_bits ( & gb , 3 ) ; if ( run_length == 0 ) { ( * srcbuf ) + = ( get_bits_count ( & gb ) + 7 ) > > 3 ; return pixels_read ; } run_length + = 2 ; if ( map_table ) bits = map_table[0] ; else bits = 0 ; while ( run_length - - > 0 & & pixels_read < dbuf_len ) { * destbuf + + = bits ; pixels_read + + ; } } else { bits = get_bits1 ( & gb ) ; if ( bits == 0 ) { run_length = get_bits ( & gb , 2 ) + 4 ; bits = get_bits ( & gb , 4 ) ; if ( non_mod == 1 & & bits == 1 ) pixels_read + = run_length ; else { if ( map_table ) bits = map_table[bits] ; while ( run_length - - > 0 & & pixels_read < dbuf_len ) { * destbuf + + = bits ; pixels_read + + ; } } } else { bits = get_bits ( & gb , 2 ) ; if ( bits == 2 ) { run_length = get_bits ( & gb , 4 ) + 9 ; bits = get_bits ( & gb , 4 ) ; if ( non_mod == 1 & & bits == 1 ) pixels_read + = run_length ; else { if ( map_table ) bits = map_table[bits] ; while ( run_length - - > 0 & & pixels_read < dbuf_len ) { * destbuf + + = bits ; pixels_read + + ; } } } else if ( bits == 3 ) { run_length = get_bits ( & gb , 8 ) + 25 ; bits = get_bits ( & gb , 4 ) ; if ( non_mod == 1 & & bits == 1 ) pixels_read + = run_length ; else { if ( map_table ) bits = map_table[bits] ; while ( run_length - - > 0 & & pixels_read < dbuf_len ) { * destbuf + + = bits ; pixels_read + + ; } } } else if ( bits == 1 ) { pixels_read + = 2 ; if ( map_table ) bits = map_table[0] ; else bits = 0 ; if ( pixels_read < = dbuf_len ) { * destbuf + + = bits ; * destbuf + + = bits ; } } else { if ( map_table ) bits = map_table[0] ; else bits = 0 ; * destbuf + + = bits ; pixels_read + + ; } } } } } if ( get_bits ( & gb , 8 ) ) av_log ( 0 , AV_LOG_ERROR , DVBSub error : line overflow\n ) ; ( * srcbuf ) + = ( get_bits_count ( & gb ) + 7 ) > > 3 ; return pixels_read ; }",0
"static void copy_block ( uint16_t * pdest , uint16_t * psrc , int block_size , int pitch ) { int y ; for ( y = 0 ; y ! = block_size ; y + + , pdest + = pitch , psrc + = pitch ) memcpy ( pdest , psrc , block_size * sizeof ( pdest[0] ) ) ; }",0
"static int ffm2_read_header ( AVFormatContext * s ) { FFMContext * ffm = s - > priv_data ; AVStream * st ; AVIOContext * pb = s - > pb ; AVCodecContext * codec , * dummy_codec = NULL ; AVCodecParameters * codecpar ; const AVCodecDescriptor * codec_desc ; int ret ; int f_main = 0 , f_cprv = - 1 , f_stvi = - 1 , f_stau = - 1 ; AVCodec * enc ; char * buffer ; ffm - > packet_size = avio_rb32 ( pb ) ; if ( ffm - > packet_size ! = FFM_PACKET_SIZE ) { av_log ( s , AV_LOG_ERROR , Invalid packet size %d , expected size was %d\n , ffm - > packet_size , FFM_PACKET_SIZE ) ; ret = AVERROR_INVALIDDATA ; goto fail ; } ffm - > write_index = avio_rb64 ( pb ) ; / * get also filesize * / if ( pb - > seekable ) { ffm - > file_size = avio_size ( pb ) ; if ( ffm - > write_index & & 0 ) adjust_write_index ( s ) ; } else { ffm - > file_size = ( UINT64_C ( 1 ) < < 63 ) - 1 ; } dummy_codec = avcodec_alloc_context3 ( NULL ) ; while ( ! avio_feof ( pb ) ) { unsigned id = avio_rb32 ( pb ) ; unsigned size = avio_rb32 ( pb ) ; int64_t next = avio_tell ( pb ) + size ; char rc_eq_buf[128] ; if ( ! id ) break ; switch ( id ) { case MKBETAG ( ' M ' , ' A ' , ' I ' , ' N ' ) : if ( f_main + + ) { ret = AVERROR ( EINVAL ) ; goto fail ; } avio_rb32 ( pb ) ; / * nb_streams * / avio_rb32 ( pb ) ; / * total bitrate * / break ; case MKBETAG ( ' C ' , ' O ' , ' M ' , ' M ' ) : f_cprv = f_stvi = f_stau = 0 ; st = avformat_new_stream ( s , NULL ) ; if ( ! st ) { ret = AVERROR ( ENOMEM ) ; goto fail ; } avpriv_set_pts_info ( st , 64 , 1 , 1000000 ) ; codec = st - > codec ; codecpar = st - > codecpar ; / * generic info * / codecpar - > codec_id = avio_rb32 ( pb ) ; codec_desc = avcodec_descriptor_get ( codecpar - > codec_id ) ; if ( ! codec_desc ) { av_log ( s , AV_LOG_ERROR , Invalid codec id : %d\n , codecpar - > codec_id ) ; codecpar - > codec_id = AV_CODEC_ID_NONE ; ret = AVERROR_INVALIDDATA ; goto fail ; } codecpar - > codec_type = avio_r8 ( pb ) ; if ( codecpar - > codec_type ! = codec_desc - > type ) { av_log ( s , AV_LOG_ERROR , Codec type mismatch : expected %d , found %d\n , codec_desc - > type , codecpar - > codec_type ) ; codecpar - > codec_id = AV_CODEC_ID_NONE ; codecpar - > codec_type = AVMEDIA_TYPE_UNKNOWN ; ret = AVERROR_INVALIDDATA ; goto fail ; } codecpar - > bit_rate = avio_rb32 ( pb ) ; if ( codecpar - > bit_rate < 0 ) { av_log ( codec , AV_LOG_ERROR , Invalid bit rate % PRId64 \n , codecpar - > bit_rate ) ; ret = AVERROR_INVALIDDATA ; goto fail ; } codec - > flags = avio_rb32 ( pb ) ; codec - > flags2 = avio_rb32 ( pb ) ; codec - > debug = avio_rb32 ( pb ) ; if ( codec - > flags & AV_CODEC_FLAG_GLOBAL_HEADER ) { int size = avio_rb32 ( pb ) ; if ( size < 0 || size > = FF_MAX_EXTRADATA_SIZE ) { av_log ( s , AV_LOG_ERROR , Invalid extradata size %d\n , size ) ; ret = AVERROR_INVALIDDATA ; goto fail ; } codecpar - > extradata = av_mallocz ( size + AV_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! codecpar - > extradata ) return AVERROR ( ENOMEM ) ; codecpar - > extradata_size = size ; avio_read ( pb , codecpar - > extradata , size ) ; } break ; case MKBETAG ( ' S ' , ' T ' , ' V ' , ' I ' ) : if ( f_stvi + + ) { ret = AVERROR ( EINVAL ) ; goto fail ; } codec - > time_base . num = avio_rb32 ( pb ) ; codec - > time_base . den = avio_rb32 ( pb ) ; if ( codec - > time_base . num < = 0 || codec - > time_base . den < = 0 ) { av_log ( s , AV_LOG_ERROR , Invalid time base %d/%d\n , codec - > time_base . num , codec - > time_base . den ) ; ret = AVERROR_INVALIDDATA ; goto fail ; } codecpar - > width = avio_rb16 ( pb ) ; codecpar - > height = avio_rb16 ( pb ) ; ret = av_image_check_size ( codecpar - > width , codecpar - > height , 0 , s ) ; if ( ret < 0 ) goto fail ; avio_rb16 ( pb ) ; // gop_size codecpar - > format = avio_rb32 ( pb ) ; if ( ! av_pix_fmt_desc_get ( codecpar - > format ) ) { av_log ( s , AV_LOG_ERROR , Invalid pix fmt id : %d\n , codecpar - > format ) ; codecpar - > format = AV_PIX_FMT_NONE ; goto fail ; } avio_r8 ( pb ) ; // qmin avio_r8 ( pb ) ; // qmax avio_r8 ( pb ) ; // max_qdiff avio_rb16 ( pb ) ; // qcompress / 10000 . 0 avio_rb16 ( pb ) ; // qblur / 10000 . 0 avio_rb32 ( pb ) ; // bit_rate_tolerance avio_get_str ( pb , INT_MAX , rc_eq_buf , sizeof ( rc_eq_buf ) ) ; avio_rb32 ( pb ) ; // rc_max_rate avio_rb32 ( pb ) ; // rc_min_rate avio_rb32 ( pb ) ; // rc_buffer_size avio_rb64 ( pb ) ; // i_quant_factor avio_rb64 ( pb ) ; // b_quant_factor avio_rb64 ( pb ) ; // i_quant_offset avio_rb64 ( pb ) ; // b_quant_offset avio_rb32 ( pb ) ; // dct_algo avio_rb32 ( pb ) ; // strict_std_compliance avio_rb32 ( pb ) ; // max_b_frames avio_rb32 ( pb ) ; // mpeg_quant avio_rb32 ( pb ) ; // intra_dc_precision avio_rb32 ( pb ) ; // me_method avio_rb32 ( pb ) ; // mb_decision avio_rb32 ( pb ) ; // nsse_weight avio_rb32 ( pb ) ; // frame_skip_cmp avio_rb64 ( pb ) ; // rc_buffer_aggressivity codecpar - > codec_tag = avio_rb32 ( pb ) ; avio_r8 ( pb ) ; // thread_count avio_rb32 ( pb ) ; // coder_type avio_rb32 ( pb ) ; // me_cmp avio_rb32 ( pb ) ; // me_subpel_quality avio_rb32 ( pb ) ; // me_range avio_rb32 ( pb ) ; // keyint_min avio_rb32 ( pb ) ; // scenechange_threshold avio_rb32 ( pb ) ; // b_frame_strategy avio_rb64 ( pb ) ; // qcompress avio_rb64 (",0
"static double get_audio_clock ( VideoState * is ) { double pts ; int hw_buf_size , bytes_per_sec ; pts = is - > audio_clock ; hw_buf_size = audio_write_get_buf_size ( is ) ; bytes_per_sec = 0 ; if ( is - > audio_st ) { bytes_per_sec = is - > audio_st - > codec - > sample_rate * 2 * is - > audio_st - > codec - > channels ; } if ( bytes_per_sec ) pts - = ( double ) hw_buf_size / bytes_per_sec ; return pts ; }",0
"static int mpeg_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; Mpeg1Context * s = avctx - > priv_data ; AVFrame * picture = data ; MpegEncContext * s2 = & s - > mpeg_enc_ctx ; av_dlog ( avctx , fill_buffer\n ) ; if ( buf_size == 0 || ( buf_size == 4 & & AV_RB32 ( buf ) == SEQ_END_CODE ) ) { / * special case for last picture * / if ( s2 - > low_delay == 0 & & s2 - > next_picture_ptr ) { * picture = s2 - > next_picture_ptr - > f ; s2 - > next_picture_ptr = NULL ; * data_size = sizeof ( AVFrame ) ; } return buf_size ; } if ( s2 - > flags & CODEC_FLAG_TRUNCATED ) { int next = ff_mpeg1_find_frame_end ( & s2 - > parse_context , buf , buf_size , NULL ) ; if ( ff_combine_frame ( & s2 - > parse_context , next , ( const uint8_t * * ) & buf , & buf_size ) < 0 ) return buf_size ; } s2 - > codec_tag = avpriv_toupper4 ( avctx - > codec_tag ) ; if ( s - > mpeg_enc_ctx_allocated == 0 & & ( s2 - > codec_tag == AV_RL32 ( VCR2 ) || s2 - > codec_tag == AV_RL32 ( BW10 ) ) ) vcr2_init_sequence ( avctx ) ; s - > slice_count = 0 ; if ( avctx - > extradata & & ! avctx - > frame_number ) { int ret = decode_chunks ( avctx , picture , data_size , avctx - > extradata , avctx - > extradata_size ) ; if ( * data_size ) { av_log ( avctx , AV_LOG_ERROR , picture in extradata\n ) ; * data_size = 0 ; } if ( ret < 0 & & ( avctx - > err_recognition & AV_EF_EXPLODE ) ) return ret ; } return decode_chunks ( avctx , picture , data_size , buf , buf_size ) ; }",0
"uint8_t * ff_stream_new_side_data ( AVStream * st , enum AVPacketSideDataType type , int size ) { AVPacketSideData * sd , * tmp ; int i ; uint8_t * data = av_malloc ( size ) ; if ( ! data ) return NULL ; for ( i = 0 ; i < st - > nb_side_data ; i + + ) { sd = & st - > side_data[i] ; if ( sd - > type == type ) { av_freep ( & sd - > data ) ; sd - > data = data ; sd - > size = size ; return sd - > data ; } } tmp = av_realloc_array ( st - > side_data , st - > nb_side_data + 1 , sizeof ( * tmp ) ) ; if ( ! tmp ) { av_freep ( & data ) ; return NULL ; } st - > side_data = tmp ; st - > nb_side_data + + ; sd = & st - > side_data[st - > nb_side_data - 1] ; sd - > type = type ; sd - > data = data ; sd - > size = size ; return data ; }",0
"static int adts_write_packet ( AVFormatContext * s , AVPacket * pkt ) { ADTSContext * adts = s - > priv_data ; AVIOContext * pb = s - > pb ; uint8_t buf[ADTS_HEADER_SIZE] ; if ( ! pkt - > size ) return 0 ; if ( adts - > write_adts ) { ff_adts_write_frame_header ( adts , buf , pkt - > size , adts - > pce_size ) ; avio_write ( pb , buf , ADTS_HEADER_SIZE ) ; if ( adts - > pce_size ) { avio_write ( pb , adts - > pce_data , adts - > pce_size ) ; adts - > pce_size = 0 ; } } avio_write ( pb , pkt - > data , pkt - > size ) ; avio_flush ( pb ) ; return 0 ; }",0
"static int parse_optional_info ( DCACoreDecoder * s ) { DCAContext * dca = s - > avctx - > priv_data ; int ret = - 1 ; // Time code stamp if ( s - > ts_present ) skip_bits_long ( & s - > gb , 32 ) ; // Auxiliary data if ( s - > aux_present & & ( ret = parse_aux_data ( s ) ) < 0 & & ( s - > avctx - > err_recognition & AV_EF_EXPLODE ) ) return ret ; if ( ret < 0 ) s - > prim_dmix_embedded = 0 ; // Core extensions if ( s - > ext_audio_present & & ! dca - > core_only ) { int sync_pos = FFMIN ( s - > frame_size / 4 , s - > gb . size_in_bits / 32 ) - 1 ; int last_pos = get_bits_count ( & s - > gb ) / 32 ; int size , dist ; // Search for extension sync words aligned on 4 - byte boundary . Search // must be done backwards from the end of core frame to work around // sync word aliasing issues . switch ( s - > ext_audio_type ) { case EXT_AUDIO_XCH : if ( dca - > request_channel_layout ) break ; // The distance between XCH sync word and end of the core frame // must be equal to XCH frame size . Off by one error is allowed for // compatibility with legacy bitstreams . Minimum XCH frame size is // 96 bytes . AMODE and PCHS are further checked to reduce // probability of alias sync detection . for ( ; sync_pos > = last_pos ; sync_pos - - ) { if ( AV_RB32 ( s - > gb . buffer + sync_pos * 4 ) == DCA_SYNCWORD_XCH ) { s - > gb . index = ( sync_pos + 1 ) * 32 ; size = get_bits ( & s - > gb , 10 ) + 1 ; dist = s - > frame_size - sync_pos * 4 ; if ( size > = 96 & & ( size == dist || size - 1 == dist ) & & get_bits ( & s - > gb , 7 ) == 0x08 ) { s - > xch_pos = get_bits_count ( & s - > gb ) ; break ; } } } if ( s - > avctx - > err_recognition & AV_EF_EXPLODE ) { av_log ( s - > avctx , AV_LOG_ERROR , XCH sync word not found\n ) ; return AVERROR_INVALIDDATA ; } break ; case EXT_AUDIO_X96 : // The distance between X96 sync word and end of the core frame // must be equal to X96 frame size . Minimum X96 frame size is 96 // bytes . for ( ; sync_pos > = last_pos ; sync_pos - - ) { if ( AV_RB32 ( s - > gb . buffer + sync_pos * 4 ) == DCA_SYNCWORD_X96 ) { s - > gb . index = ( sync_pos + 1 ) * 32 ; size = get_bits ( & s - > gb , 12 ) + 1 ; dist = s - > frame_size - sync_pos * 4 ; if ( size > = 96 & & size == dist ) { s - > x96_pos = get_bits_count ( & s - > gb ) ; break ; } } } if ( s - > avctx - > err_recognition & AV_EF_EXPLODE ) { av_log ( s - > avctx , AV_LOG_ERROR , X96 sync word not found\n ) ; return AVERROR_INVALIDDATA ; } break ; case EXT_AUDIO_XXCH : if ( dca - > request_channel_layout ) break ; // XXCH frame header CRC must be valid . Minimum XXCH frame header // size is 11 bytes . for ( ; sync_pos > = last_pos ; sync_pos - - ) { if ( AV_RB32 ( s - > gb . buffer + sync_pos * 4 ) == DCA_SYNCWORD_XXCH ) { s - > gb . index = ( sync_pos + 1 ) * 32 ; size = get_bits ( & s - > gb , 6 ) + 1 ; if ( size > = 11 & & ! ff_dca_check_crc ( & s - > gb , ( sync_pos + 1 ) * 32 , sync_pos * 32 + size * 8 ) ) { s - > xxch_pos = sync_pos * 32 ; break ; } } } if ( s - > avctx - > err_recognition & AV_EF_EXPLODE ) { av_log ( s - > avctx , AV_LOG_ERROR , XXCH sync word not found\n ) ; return AVERROR_INVALIDDATA ; } break ; } } return 0 ; }",0
"static void generate_silence ( uint8_t * buf , enum AVSampleFormat sample_fmt , size_t size ) { int fill_char = 0x00 ; if ( sample_fmt == AV_SAMPLE_FMT_U8 ) fill_char = 0x80 ; memset ( buf , fill_char , size ) ; }",1
"void ff_ac3_bit_alloc_calc_psd ( int8_t * exp , int start , int end , int16_t * psd , int16_t * band_psd ) { int bin , j , k , end1 , v ; / * exponent mapping to PSD * / for ( bin=start ; bin < end ; bin + + ) { psd[bin]= ( 3072 - ( exp[bin] < < 7 ) ) ; } / * PSD integration * / j=start ; k=bin_to_band_tab[start] ; do { v = psd[j + + ] ; end1 = FFMIN ( band_start_tab[k + 1] , end ) ; for ( ; j < end1 ; j + + ) { / * logadd * / int adr = FFMIN ( FFABS ( v - psd[j] ) > > 1 , 255 ) ; v = FFMAX ( v , psd[j] ) + ff_ac3_log_add_tab[adr] ; } band_psd[k]=v ; k + + ; } while ( end > band_start_tab[k] ) ; }",0
"static void rv40_h_loop_filter ( uint8_t * src , int stride , int dmode , int lim_q1 , int lim_p1 , int alpha , int beta , int beta2 , int chroma , int edge ) { rv40_adaptive_loop_filter ( src , stride , 1 , dmode , lim_q1 , lim_p1 , alpha , beta , beta2 , chroma , edge ) ; }",0
"static int mono_decode ( COOKContext * q , COOKSubpacket * p , float * mlt_buffer ) { int category_index[128] ; int quant_index_table[102] ; int category[128] ; int ret ; memset ( & category , 0 , sizeof ( category ) ) ; memset ( & category_index , 0 , sizeof ( category_index ) ) ; if ( ( ret = decode_envelope ( q , p , quant_index_table ) ) < 0 ) return ret ; q - > num_vectors = get_bits ( & q - > gb , p - > log2_numvector_size ) ; categorize ( q , p , quant_index_table , category , category_index ) ; expand_category ( q , category , category_index ) ; decode_vectors ( q , p , category , quant_index_table , mlt_buffer ) ; return 0 ; }",0
"static int cuvid_test_dummy_decoder ( AVCodecContext * avctx , const CUVIDPARSERPARAMS * cuparseinfo , int probed_width , int probed_height ) { CuvidContext * ctx = avctx - > priv_data ; CUVIDDECODECREATEINFO cuinfo ; CUvideodecoder cudec = 0 ; int ret = 0 ; memset ( & cuinfo , 0 , sizeof ( cuinfo ) ) ; cuinfo . CodecType = cuparseinfo - > CodecType ; cuinfo . ChromaFormat = cudaVideoChromaFormat_420 ; cuinfo . OutputFormat = cudaVideoSurfaceFormat_NV12 ; cuinfo . ulWidth = probed_width ; cuinfo . ulHeight = probed_height ; cuinfo . ulTargetWidth = cuinfo . ulWidth ; cuinfo . ulTargetHeight = cuinfo . ulHeight ; cuinfo . target_rect . left = 0 ; cuinfo . target_rect . top = 0 ; cuinfo . target_rect . right = cuinfo . ulWidth ; cuinfo . target_rect . bottom = cuinfo . ulHeight ; cuinfo . ulNumDecodeSurfaces = ctx - > nb_surfaces ; cuinfo . ulNumOutputSurfaces = 1 ; cuinfo . ulCreationFlags = cudaVideoCreate_PreferCUVID ; cuinfo . bitDepthMinus8 = 0 ; cuinfo . DeinterlaceMode = cudaVideoDeinterlaceMode_Weave ; ret = CHECK_CU ( ctx - > cvdl - > cuvidCreateDecoder ( & cudec , & cuinfo ) ) ; if ( ret < 0 ) return ret ; ret = CHECK_CU ( ctx - > cvdl - > cuvidDestroyDecoder ( cudec ) ) ; if ( ret < 0 ) return ret ; return 0 ; }",0
"static void mm_decode_inter ( MmContext * s , int half_horiz , int half_vert , const uint8_t * buf , int buf_size ) { const int data_ptr = 2 + AV_RL16 ( & buf[0] ) ; int d , r , y ; d = data_ptr ; r = 2 ; y = 0 ; while ( r < data_ptr ) { int i , j ; int length = buf[r] & 0x7f ; int x = buf[r + 1] + ( ( buf[r] & 0x80 ) < < 1 ) ; r + = 2 ; if ( length==0 ) { y + = x ; continue ; } for ( i=0 ; i < length ; i + + ) { for ( j=0 ; j < 8 ; j + + ) { int replace = ( buf[r + i] > > ( 7 - j ) ) & 1 ; if ( replace ) { int color = buf[d] ; s - > frame . data[0][y * s - > frame . linesize[0] + x] = color ; if ( half_horiz ) s - > frame . data[0][y * s - > frame . linesize[0] + x + 1] = color ; if ( half_vert ) { s - > frame . data[0][ ( y + 1 ) * s - > frame . linesize[0] + x] = color ; if ( half_horiz ) s - > frame . data[0][ ( y + 1 ) * s - > frame . linesize[0] + x + 1] = color ; } d + + ; } x + = half_horiz ? 2 : 1 ; } } r + = length ; y + = half_vert ? 2 : 1 ; } }",0
"static inline void RENAME ( vu9_to_vu12 ) ( const uint8_t * src1 , const uint8_t * src2 , uint8_t * dst1 , uint8_t * dst2 , long width , long height , long srcStride1 , long srcStride2 , long dstStride1 , long dstStride2 ) { x86_reg y ; long x , w , h ; w=width/2 ; h=height/2 ; if COMPILE_TEMPLATE_MMX __asm__ volatile ( PREFETCH %0 \n\t PREFETCH %1 \n\t : : m ( * ( src1 + srcStride1 ) ) , m ( * ( src2 + srcStride2 ) ) : memory ) ; endif for ( y=0 ; y < h ; y + + ) { const uint8_t * s1=src1 + srcStride1 * ( y > > 1 ) ; uint8_t * d=dst1 + dstStride1 * y ; x=0 ; if COMPILE_TEMPLATE_MMX for ( ; x < w - 31 ; x + =32 ) { __asm__ volatile ( PREFETCH 32%1 \n\t movq %1 , %%mm0 \n\t movq 8%1 , %%mm2 \n\t movq 16%1 , %%mm4 \n\t movq 24%1 , %%mm6 \n\t movq %%mm0 , %%mm1 \n\t movq %%mm2 , %%mm3 \n\t movq %%mm4 , %%mm5 \n\t movq %%mm6 , %%mm7 \n\t punpcklbw %%mm0 , %%mm0 \n\t punpckhbw %%mm1 , %%mm1 \n\t punpcklbw %%mm2 , %%mm2 \n\t punpckhbw %%mm3 , %%mm3 \n\t punpcklbw %%mm4 , %%mm4 \n\t punpckhbw %%mm5 , %%mm5 \n\t punpcklbw %%mm6 , %%mm6 \n\t punpckhbw %%mm7 , %%mm7 \n\t MOVNTQ %%mm0 , %0 \n\t MOVNTQ %%mm1 , 8%0 \n\t MOVNTQ %%mm2 , 16%0 \n\t MOVNTQ %%mm3 , 24%0 \n\t MOVNTQ %%mm4 , 32%0 \n\t MOVNTQ %%mm5 , 40%0 \n\t MOVNTQ %%mm6 , 48%0 \n\t MOVNTQ %%mm7 , 56%0 : =m ( d[2 * x] ) : m ( s1[x] ) : memory ) ; } endif for ( ; x < w ; x + + ) d[2 * x]=d[2 * x + 1]=s1[x] ; } for ( y=0 ; y < h ; y + + ) { const uint8_t * s2=src2 + srcStride2 * ( y > > 1 ) ; uint8_t * d=dst2 + dstStride2 * y ; x=0 ; if COMPILE_TEMPLATE_MMX for ( ; x < w - 31 ; x + =32 ) { __asm__ volatile ( PREFETCH 32%1 \n\t movq %1 , %%mm0 \n\t movq 8%1 , %%mm2 \n\t movq 16%1 , %%mm4 \n\t movq 24%1 , %%mm6 \n\t movq %%mm0 , %%mm1 \n\t movq %%mm2 , %%mm3 \n\t movq %%mm4 , %%mm5 \n\t movq %%mm6 , %%mm7 \n\t punpcklbw %%mm0 , %%mm0 \n\t punpckhbw %%mm1 , %%mm1 \n\t punpcklbw %%mm2 , %%mm2 \n\t punpckhbw %%mm3 , %%mm3 \n\t punpcklbw %%mm4 , %%mm4 \n\t punpckhbw %%mm5 , %%mm5 \n\t punpcklbw %%mm6 , %%mm6 \n\t punpckhbw %%mm7 , %%mm7 \n\t MOVNTQ %%mm0 , %0 \n\t MOVNTQ %%mm1 , 8%0 \n\t MOVNTQ %%mm2 , 16%0 \n\t MOVNTQ %%mm3 , 24%0 \n\t MOVNTQ %%mm4 , 32%0 \n\t MOVNTQ %%mm5 , 40%0 \n\t MOVNTQ %%mm6 , 48%0 \n\t MOVNTQ %%mm7 , 56%0 : =m ( d[2 * x] ) : m ( s2[x] ) : memory ) ; } endif for ( ; x < w ; x + + ) d[2 * x]=d[2 * x + 1]=s2[x] ; } if COMPILE_TEMPLATE_MMX __asm__ ( EMMS \n\t SFENCE \n\t : : : memory ) ; endif }",0
"static int analyze_chunk ( AVFormatContext * s , const uint8_t * chunk ) { TYDemuxContext * ty = s - > priv_data ; int num_recs , i ; TyRecHdr * hdrs ; int num_6e0 , num_be0 , num_9c0 , num_3c0 ; / * skip if it ' s a Part header * / if ( AV_RB32 ( & chunk[0] ) == TIVO_PES_FILEID ) return 0 ; / * number of records in chunk ( we ignore high order byte ; * rarely are there > 256 chunks & we don ' t need that many anyway ) * / num_recs = chunk[0] ; if ( num_recs < 5 ) { / * try again with the next chunk . Sometimes there are dead ones * / return 0 ; } chunk + = 4 ; / * skip past rec count & SEQ bytes * / ff_dlog ( s , probe : chunk has %d recs\n , num_recs ) ; hdrs = parse_chunk_headers ( chunk , num_recs ) ; if ( ! hdrs ) return AVERROR ( ENOMEM ) ; / * scan headers . * 1 . check video packets . Presence of 0x6e0 means S1 . * No 6e0 but have be0 means S2 . * 2 . probe for audio 0x9c0 vs 0x3c0 ( AC3 vs Mpeg ) * If AC - 3 , then we have DTivo . * If MPEG , search for PTS offset . This will determine SA vs . DTivo . * / num_6e0 = num_be0 = num_9c0 = num_3c0 = 0 ; for ( i = 0 ; i < num_recs ; i + + ) { switch ( hdrs[i] . subrec_type < < 8 | hdrs[i] . rec_type ) { case 0x6e0 : num_6e0 + + ; case 0xbe0 : num_be0 + + ; case 0x3c0 : num_3c0 + + ; case 0x9c0 : num_9c0 + + ; } } ff_dlog ( s , probe : chunk has %d 0x6e0 recs , %d 0xbe0 recs . \n , num_6e0 , num_be0 ) ; / * set up our variables * / if ( num_6e0 > 0 ) { ff_dlog ( s , detected Series 1 Tivo\n ) ; ty - > tivo_series = TIVO_SERIES1 ; ty - > pes_length = SERIES1_PES_LENGTH ; } else if ( num_be0 > 0 ) { ff_dlog ( s , detected Series 2 Tivo\n ) ; ty - > tivo_series = TIVO_SERIES2 ; ty - > pes_length = SERIES2_PES_LENGTH ; } if ( num_9c0 > 0 ) { ff_dlog ( s , detected AC - 3 Audio ( DTivo ) \n ) ; ty - > audio_type = TIVO_AUDIO_AC3 ; ty - > tivo_type = TIVO_TYPE_DTIVO ; ty - > pts_offset = AC3_PTS_OFFSET ; ty - > pes_length = AC3_PES_LENGTH ; } else if ( num_3c0 > 0 ) { ty - > audio_type = TIVO_AUDIO_MPEG ; ff_dlog ( s , detected MPEG Audio\n ) ; } / * if tivo_type still unknown , we can check PTS location * in MPEG packets to determine tivo_type * / if ( ty - > tivo_type == TIVO_TYPE_UNKNOWN ) { uint32_t data_offset = 16 * num_recs ; for ( i = 0 ; i < num_recs ; i + + ) { if ( ( hdrs[i] . subrec_type < < 0x08 | hdrs[i] . rec_type ) == 0x3c0 & & hdrs[i] . rec_size > 15 ) { / * first make sure we ' re aligned * / int pes_offset = find_es_header ( ty_MPEGAudioPacket , & chunk[data_offset] , 5 ) ; if ( pes_offset > = 0 ) { / * pes found . on SA , PES has hdr data at offset 6 , not PTS . * / if ( ( chunk[data_offset + 6 + pes_offset] & 0x80 ) == 0x80 ) { / * S1SA or S2 ( any ) Mpeg Audio ( PES hdr , not a PTS start ) * / if ( ty - > tivo_series == TIVO_SERIES1 ) ff_dlog ( s , detected Stand - Alone Tivo\n ) ; ty - > tivo_type = TIVO_TYPE_SA ; ty - > pts_offset = SA_PTS_OFFSET ; } else { if ( ty - > tivo_series == TIVO_SERIES1 ) ff_dlog ( s , detected DirecTV Tivo\n ) ; ty - > tivo_type = TIVO_TYPE_DTIVO ; ty - > pts_offset = DTIVO_PTS_OFFSET ; } } } data_offset + = hdrs[i] . rec_size ; } } av_free ( hdrs ) ; return 0 ; }",1
"static int hevc_decode_nal_units ( const uint8_t * buf , int buf_size , HEVCParamSets * ps , int is_nalff , int nal_length_size , void * logctx ) { int i ; int ret = 0 ; H2645Packet pkt = { 0 } ; ret = ff_h2645_packet_split ( & pkt , buf , buf_size , logctx , is_nalff , nal_length_size , AV_CODEC_ID_HEVC , 1 ) ; if ( ret < 0 ) { goto done ; } for ( i = 0 ; i < pkt . nb_nals ; i + + ) { H2645NAL * nal = & pkt . nals[i] ; / * ignore everything except parameter sets and VCL NALUs * / switch ( nal - > type ) { case HEVC_NAL_VPS : ff_hevc_decode_nal_vps ( & nal - > gb , logctx , ps ) ; break ; case HEVC_NAL_SPS : ff_hevc_decode_nal_sps ( & nal - > gb , logctx , ps , 1 ) ; break ; case HEVC_NAL_PPS : ff_hevc_decode_nal_pps ( & nal - > gb , logctx , ps ) ; break ; default : av_log ( logctx , AV_LOG_VERBOSE , Ignoring NAL type %d in extradata\n , nal - > type ) ; break ; } } done : ff_h2645_packet_uninit ( & pkt ) ; return ret ; }",1
"static int load_sofa ( AVFilterContext * ctx , char * filename , int * samplingrate ) { struct SOFAlizerContext * s = ctx - > priv ; / * variables associated with content of SOFA file : * / int ncid , n_dims , n_vars , n_gatts , n_unlim_dim_id , status ; char data_delay_dim_name[NC_MAX_NAME] ; float * sp_a , * sp_e , * sp_r , * data_ir ; char * sofa_conventions ; char dim_name[NC_MAX_NAME] ; / * names of netCDF dimensions * / size_t * dim_length ; / * lengths of netCDF dimensions * / char * text ; unsigned int sample_rate ; int data_delay_dim_id[2] ; int samplingrate_id ; int data_delay_id ; int n_samples ; int m_dim_id = - 1 ; int n_dim_id = - 1 ; int data_ir_id ; size_t att_len ; int m_dim ; int * data_delay ; int sp_id ; int i , ret ; s - > sofa . ncid = 0 ; status = nc_open ( filename , NC_NOWRITE , & ncid ) ; / * open SOFA file read - only * / if ( status ! = NC_NOERR ) { av_log ( ctx , AV_LOG_ERROR , Can ' t find SOFA - file ' %s ' \n , filename ) ; return AVERROR ( EINVAL ) ; } / * get number of dimensions , vars , global attributes and Id of unlimited dimensions : * / nc_inq ( ncid , & n_dims , & n_vars , & n_gatts , & n_unlim_dim_id ) ; / * - - get number of measurements ( M ) and length of one IR ( N ) - - * / dim_length = av_malloc_array ( n_dims , sizeof ( * dim_length ) ) ; if ( ! dim_length ) { nc_close ( ncid ) ; return AVERROR ( ENOMEM ) ; } for ( i = 0 ; i < n_dims ; i + + ) { / * go through all dimensions of file * / nc_inq_dim ( ncid , i , ( char * ) & dim_name , & dim_length[i] ) ; / * get dimensions * / if ( ! strncmp ( M , ( const char * ) & dim_name , 1 ) ) / * get ID of dimension M * / m_dim_id = i ; if ( ! strncmp ( N , ( const char * ) & dim_name , 1 ) ) / * get ID of dimension N * / n_dim_id = i ; } if ( ( m_dim_id == - 1 ) || ( n_dim_id == - 1 ) ) { / * dimension M or N couldn ' t be found * / av_log ( ctx , AV_LOG_ERROR , Can ' t find required dimensions in SOFA file . \n ) ; av_freep ( & dim_length ) ; nc_close ( ncid ) ; return AVERROR ( EINVAL ) ; } n_samples = dim_length[n_dim_id] ; / * get length of one IR * / m_dim = dim_length[m_dim_id] ; / * get number of measurements * / av_freep ( & dim_length ) ; / * - - check file type - - * / / * get length of attritube Conventions * / status = nc_inq_attlen ( ncid , NC_GLOBAL , Conventions , & att_len ) ; if ( status ! = NC_NOERR ) { av_log ( ctx , AV_LOG_ERROR , Can ' t get length of attribute \ Conventions\ . \n ) ; nc_close ( ncid ) ; return AVERROR_INVALIDDATA ; } / * check whether file is SOFA file * / text = av_malloc ( att_len + 1 ) ; if ( ! text ) { nc_close ( ncid ) ; return AVERROR ( ENOMEM ) ; } nc_get_att_text ( ncid , NC_GLOBAL , Conventions , text ) ; * ( text + att_len ) = 0 ; if ( strncmp ( SOFA , text , 4 ) ) { av_log ( ctx , AV_LOG_ERROR , Not a SOFA file ! \n ) ; av_freep ( & text ) ; nc_close ( ncid ) ; return AVERROR ( EINVAL ) ; } av_freep ( & text ) ; status = nc_inq_attlen ( ncid , NC_GLOBAL , License , & att_len ) ; if ( status == NC_NOERR ) { text = av_malloc ( att_len + 1 ) ; if ( text ) { nc_get_att_text ( ncid , NC_GLOBAL , License , text ) ; * ( text + att_len ) = 0 ; av_log ( ctx , AV_LOG_INFO , SOFA file License : %s\n , text ) ; av_freep ( & text ) ; } } status = nc_inq_attlen ( ncid , NC_GLOBAL , SourceDescription , & att_len ) ; if ( status == NC_NOERR ) { text = av_malloc ( att_len + 1 ) ; if ( text ) { nc_get_att_text ( ncid , NC_GLOBAL , SourceDescription , text ) ; * ( text + att_len ) = 0 ; av_log ( ctx , AV_LOG_INFO , SOFA file SourceDescription : %s\n , text ) ; av_freep ( & text ) ; } } status = nc_inq_attlen ( ncid , NC_GLOBAL , Comment , & att_len ) ; if ( status == NC_NOERR ) { text = av_malloc ( att_len + 1 ) ; if ( text ) { nc_get_att_text ( ncid , NC_GLOBAL , Comment , text ) ; * ( text + att_len ) = 0 ; av_log ( ctx , AV_LOG_INFO , SOFA file Comment : %s\n , text ) ; av_freep ( & text ) ; } } status = nc_inq_attlen ( ncid , NC_GLOBAL , SOFAConventions , & att_len ) ; if ( status ! = NC_NOERR ) { av_log ( ctx , AV_LOG_ERROR , Can ' t get length of attribute \ SOFAConventions\ . \n ) ; nc_close ( ncid ) ; return AVERROR_INVALIDDATA ; } sofa_conventions = av_malloc ( att_len + 1 ) ; if ( ! sofa_conventions ) { nc_close ( ncid ) ; return AVERROR ( ENOMEM ) ; } nc_get_att_text ( ncid , NC_GLOBAL , SOFAConventions , sofa_conventions ) ; * ( sofa_conventions + att_len ) = 0 ; if ( strncmp ( SimpleFreeFieldHRIR , sofa_conventions , att_len ) ) { av_log ( ctx , AV_LOG_ERROR , Not a SimpleFreeFieldHRIR file ! \n ) ; av_freep ( & sofa_conventions ) ; nc_close ( ncid ) ; return AVERROR ( EINVAL ) ; } av_freep ( & sofa_conventions ) ; / * - - get sampling rate of HRTFs - - * / / * read ID , then value * / status = nc_inq_varid ( ncid , Data . SamplingRate , & samplingrate_id ) ; status + = nc_get_var_uint ( ncid , samplingrate_id , & sample_rate ) ; if ( status ! = NC_NOERR ) { av_log ( ctx , AV_LOG_ERROR , Couldn ' t read Data . SamplingRate . \n ) ; nc_close ( ncid ) ; return AVERROR ( EINVAL ) ; } * samplingrate = sample_rate ; / * remember sampling rate * / / * - - allocate memory for one value for each measurement position : - - * / sp_a = s - > sofa . sp_a = av_malloc_array ( m_dim",1
"static int rv40_h_loop_filter_strength ( uint8_t * src , int stride , int beta , int beta2 , int edge , int * p1 , int * q1 ) { return rv40_loop_filter_strength ( src , stride , 1 , beta , beta2 , edge , p1 , q1 ) ; }",1
"static int decode_pic ( AVSContext * h ) { MpegEncContext * s = & h - > s ; int skip_count ; enum cavs_mb mb_type ; if ( ! s - > context_initialized ) { s - > avctx - > idct_algo = FF_IDCT_CAVS ; if ( MPV_common_init ( s ) < 0 ) return - 1 ; ff_init_scantable ( s - > dsp . idct_permutation , & h - > scantable , ff_zigzag_direct ) ; } skip_bits ( & s - > gb , 16 ) ; //bbv_dwlay if ( h - > stc == PIC_PB_START_CODE ) { h - > pic_type = get_bits ( & s - > gb , 2 ) + FF_I_TYPE ; if ( h - > pic_type > FF_B_TYPE ) { av_log ( s - > avctx , AV_LOG_ERROR , illegal picture type\n ) ; return - 1 ; } / * make sure we have the reference frames we need * / if ( ! h - > DPB[0] . data[0] || ( ! h - > DPB[1] . data[0] & & h - > pic_type == FF_B_TYPE ) ) return - 1 ; } else { h - > pic_type = FF_I_TYPE ; if ( get_bits1 ( & s - > gb ) ) skip_bits ( & s - > gb , 24 ) ; //time_code } / * release last B frame * / if ( h - > picture . data[0] ) s - > avctx - > release_buffer ( s - > avctx , ( AVFrame * ) & h - > picture ) ; s - > avctx - > get_buffer ( s - > avctx , ( AVFrame * ) & h - > picture ) ; ff_cavs_init_pic ( h ) ; h - > picture . poc = get_bits ( & s - > gb , 8 ) * 2 ; / * get temporal distances and MV scaling factors * / if ( h - > pic_type ! = FF_B_TYPE ) { h - > dist[0] = ( h - > picture . poc - h - > DPB[0] . poc + 512 ) % 512 ; } else { h - > dist[0] = ( h - > DPB[0] . poc - h - > picture . poc + 512 ) % 512 ; } h - > dist[1] = ( h - > picture . poc - h - > DPB[1] . poc + 512 ) % 512 ; h - > scale_den[0] = h - > dist[0] ? 512/h - > dist[0] : 0 ; h - > scale_den[1] = h - > dist[1] ? 512/h - > dist[1] : 0 ; if ( h - > pic_type == FF_B_TYPE ) { h - > sym_factor = h - > dist[0] * h - > scale_den[1] ; } else { h - > direct_den[0] = h - > dist[0] ? 16384/h - > dist[0] : 0 ; h - > direct_den[1] = h - > dist[1] ? 16384/h - > dist[1] : 0 ; } if ( s - > low_delay ) get_ue_golomb ( & s - > gb ) ; //bbv_check_times h - > progressive = get_bits1 ( & s - > gb ) ; h - > pic_structure = 1 ; if ( ! h - > progressive ) h - > pic_structure = get_bits1 ( & s - > gb ) ; if ( ! h - > pic_structure & & h - > stc == PIC_PB_START_CODE ) skip_bits1 ( & s - > gb ) ; //advanced_pred_mode_disable skip_bits1 ( & s - > gb ) ; //top_field_first skip_bits1 ( & s - > gb ) ; //repeat_first_field h - > qp_fixed = get_bits1 ( & s - > gb ) ; h - > qp = get_bits ( & s - > gb , 6 ) ; if ( h - > pic_type == FF_I_TYPE ) { if ( ! h - > progressive & & ! h - > pic_structure ) skip_bits1 ( & s - > gb ) ; //what is this ? skip_bits ( & s - > gb , 4 ) ; //reserved bits } else { if ( ! ( h - > pic_type == FF_B_TYPE & & h - > pic_structure == 1 ) ) h - > ref_flag = get_bits1 ( & s - > gb ) ; skip_bits ( & s - > gb , 4 ) ; //reserved bits h - > skip_mode_flag = get_bits1 ( & s - > gb ) ; } h - > loop_filter_disable = get_bits1 ( & s - > gb ) ; if ( ! h - > loop_filter_disable & & get_bits1 ( & s - > gb ) ) { h - > alpha_offset = get_se_golomb ( & s - > gb ) ; h - > beta_offset = get_se_golomb ( & s - > gb ) ; } else { h - > alpha_offset = h - > beta_offset = 0 ; } if ( h - > pic_type == FF_I_TYPE ) { do { check_for_slice ( h ) ; decode_mb_i ( h , 0 ) ; } while ( ff_cavs_next_mb ( h ) ) ; } else if ( h - > pic_type == FF_P_TYPE ) { do { check_for_slice ( h ) ; if ( h - > skip_mode_flag ) { skip_count = get_ue_golomb ( & s - > gb ) ; while ( skip_count - - ) { decode_mb_p ( h , P_SKIP ) ; if ( ! ff_cavs_next_mb ( h ) ) goto done ; } check_for_slice ( h ) ; mb_type = get_ue_golomb ( & s - > gb ) + P_16X16 ; } else mb_type = get_ue_golomb ( & s - > gb ) + P_SKIP ; if ( mb_type > P_8X8 ) { decode_mb_i ( h , mb_type - P_8X8 - 1 ) ; } else decode_mb_p ( h , mb_type ) ; } while ( ff_cavs_next_mb ( h ) ) ; } else { / * FF_B_TYPE * / do { check_for_slice ( h ) ; if ( h - > skip_mode_flag ) { skip_count = get_ue_golomb ( & s - > gb ) ; while ( skip_count - - ) { decode_mb_b ( h , B_SKIP ) ; if ( ! ff_cavs_next_mb ( h ) ) goto done ; } check_for_slice ( h ) ; mb_type = get_ue_golomb ( & s - > gb ) + B_DIRECT ; } else mb_type = get_ue_golomb ( & s - > gb ) + B_SKIP ; if ( mb_type > B_8X8 ) { decode_mb_i ( h , mb_type - B_8X8 - 1 ) ; } else decode_mb_b ( h , mb_type ) ; } while ( ff_cavs_next_mb ( h ) ) ; } done : if ( h - > pic_type ! = FF_B_TYPE ) { if ( h - > DPB[1] . data[0] ) s - > avctx - > release_buffer ( s - > avctx , ( AVFrame * ) & h - > DPB[1] ) ; h - > DPB[1] = h - > DPB[0] ; h - > DPB[0] = h",0
"static int gxf_interleave_packet ( AVFormatContext * s , AVPacket * out , AVPacket * pkt , int flush ) { GXFContext * gxf = s - > priv_data ; AVPacket new_pkt ; int i ; for ( i = 0 ; i < s - > nb_streams ; i + + ) { if ( s - > streams[i] - > codec - > codec_type == CODEC_TYPE_AUDIO ) { GXFStreamContext * sc = & gxf - > streams[i] ; if ( pkt & & pkt - > stream_index == i ) { av_fifo_write ( & sc - > audio_buffer , pkt - > data , pkt - > size ) ; pkt = NULL ; } if ( flush || av_fifo_size ( & sc - > audio_buffer ) > = GXF_AUDIO_PACKET_SIZE ) { if ( ! pkt & & gxf_new_audio_packet ( gxf , sc , & new_pkt , flush ) > 0 ) { pkt = & new_pkt ; break ; / * add pkt right now into list * / } } } } return av_interleave_packet_per_dts ( s , out , pkt , flush ) ; }",0
"int ff_nvdec_decode_init ( AVCodecContext * avctx ) { NVDECContext * ctx = avctx - > internal - > hwaccel_priv_data ; NVDECFramePool * pool ; AVHWFramesContext * frames_ctx ; const AVPixFmtDescriptor * sw_desc ; CUVIDDECODECREATEINFO params = { 0 } ; int cuvid_codec_type , cuvid_chroma_format ; int ret = 0 ; sw_desc = av_pix_fmt_desc_get ( avctx - > sw_pix_fmt ) ; if ( ! sw_desc ) return AVERROR_BUG ; cuvid_codec_type = map_avcodec_id ( avctx - > codec_id ) ; if ( cuvid_codec_type < 0 ) { av_log ( avctx , AV_LOG_ERROR , Unsupported codec ID\n ) ; return AVERROR_BUG ; } cuvid_chroma_format = map_chroma_format ( avctx - > sw_pix_fmt ) ; if ( cuvid_chroma_format < 0 ) { av_log ( avctx , AV_LOG_ERROR , Unsupported chroma format\n ) ; return AVERROR ( ENOSYS ) ; } if ( ! avctx - > hw_frames_ctx ) { ret = ff_decode_get_hw_frames_ctx ( avctx , AV_HWDEVICE_TYPE_CUDA ) ; if ( ret < 0 ) return ret ; } frames_ctx = ( AVHWFramesContext * ) avctx - > hw_frames_ctx - > data ; params . ulWidth = avctx - > coded_width ; params . ulHeight = avctx - > coded_height ; params . ulTargetWidth = avctx - > coded_width ; params . ulTargetHeight = avctx - > coded_height ; params . bitDepthMinus8 = sw_desc - > comp[0] . depth - 8 ; params . OutputFormat = params . bitDepthMinus8 ? cudaVideoSurfaceFormat_P016 : cudaVideoSurfaceFormat_NV12 ; params . CodecType = cuvid_codec_type ; params . ChromaFormat = cuvid_chroma_format ; params . ulNumDecodeSurfaces = frames_ctx - > initial_pool_size ; params . ulNumOutputSurfaces = 1 ; ret = nvdec_decoder_create ( & ctx - > decoder_ref , frames_ctx - > device_ref , & params , avctx ) ; if ( ret < 0 ) return ret ; pool = av_mallocz ( sizeof ( * pool ) ) ; if ( ! pool ) { ret = AVERROR ( ENOMEM ) ; goto fail ; } pool - > dpb_size = frames_ctx - > initial_pool_size ; ctx - > decoder_pool = av_buffer_pool_init2 ( sizeof ( int ) , pool , nvdec_decoder_frame_alloc , av_free ) ; if ( ! ctx - > decoder_pool ) { ret = AVERROR ( ENOMEM ) ; goto fail ; } return 0 ; fail : ff_nvdec_decode_uninit ( avctx ) ; return ret ; }",0
"static int thp_read_packet ( AVFormatContext * s , AVPacket * pkt ) { ThpDemuxContext * thp = s - > priv_data ; AVIOContext * pb = s - > pb ; unsigned int size ; int ret ; if ( thp - > audiosize == 0 ) { / * Terminate when last frame is reached . * / if ( thp - > frame > = thp - > framecnt ) return AVERROR_EOF ; avio_seek ( pb , thp - > next_frame , SEEK_SET ) ; / * Locate the next frame and read out its size . * / thp - > next_frame + = FFMAX ( thp - > next_framesz , 1 ) ; thp - > next_framesz = avio_rb32 ( pb ) ; avio_rb32 ( pb ) ; / * Previous total size . * / size = avio_rb32 ( pb ) ; / * Total size of this frame . * / / * Store the audiosize so the next time this function is called , the audio can be read . * / if ( thp - > has_audio ) thp - > audiosize = avio_rb32 ( pb ) ; / * Audio size . * / else thp - > frame + + ; ret = av_get_packet ( pb , pkt , size ) ; if ( ret ! = size ) { av_free_packet ( pkt ) ; return AVERROR ( EIO ) ; } pkt - > stream_index = thp - > video_stream_index ; } else { ret = av_get_packet ( pb , pkt , thp - > audiosize ) ; if ( ret ! = thp - > audiosize ) { av_free_packet ( pkt ) ; return AVERROR ( EIO ) ; } pkt - > stream_index = thp - > audio_stream_index ; if ( thp - > audiosize > = 8 ) pkt - > duration = AV_RB32 ( & pkt - > data[4] ) ; thp - > audiosize = 0 ; thp - > frame + + ; } return 0 ; }",1
"static int RENAME ( resample_common ) ( ResampleContext * c , DELEM * dst , const DELEM * src , int n , int update_ctx ) { int dst_index ; int index= c - > index ; int frac= c - > frac ; int sample_index = index > > c - > phase_shift ; index & = c - > phase_mask ; for ( dst_index = 0 ; dst_index < n ; dst_index + + ) { FELEM * filter = ( ( FELEM * ) c - > filter_bank ) + c - > filter_alloc * index ; FELEM2 val=0 ; int i ; for ( i = 0 ; i < c - > filter_length ; i + + ) { val + = src[sample_index + i] * ( FELEM2 ) filter[i] ; } OUT ( dst[dst_index] , val ) ; frac + = c - > dst_incr_mod ; index + = c - > dst_incr_div ; if ( frac > = c - > src_incr ) { frac - = c - > src_incr ; index + + ; } sample_index + = index > > c - > phase_shift ; index & = c - > phase_mask ; } if ( update_ctx ) { c - > frac= frac ; c - > index= index ; } return sample_index ; }",0
"int av_image_fill_pointers ( uint8_t * data[4] , enum PixelFormat pix_fmt , int height , uint8_t * ptr , const int linesizes[4] ) { int i , total_size , size[4] , has_plane[4] ; const AVPixFmtDescriptor * desc = & av_pix_fmt_descriptors[pix_fmt] ; memset ( data , 0 , sizeof ( data[0] ) * 4 ) ; memset ( size , 0 , sizeof ( size ) ) ; memset ( has_plane , 0 , sizeof ( has_plane ) ) ; if ( ( unsigned ) pix_fmt > = PIX_FMT_NB || desc - > flags & PIX_FMT_HWACCEL ) return AVERROR ( EINVAL ) ; data[0] = ptr ; if ( linesizes[0] > ( INT_MAX - 1024 ) / height ) return AVERROR ( EINVAL ) ; size[0] = linesizes[0] * height ; if ( desc - > flags & PIX_FMT_PAL ) { size[0] = ( size[0] + 3 ) & 3 ; data[1] = ptr + size[0] ; / * palette is stored here as 256 32 bits words * / return size[0] + 256 * 4 ; } for ( i = 0 ; i < 4 ; i + + ) has_plane[desc - > comp[i] . plane] = 1 ; total_size = size[0] ; for ( i = 1 ; i < 4 & & has_plane[i] ; i + + ) { int h , s = ( i == 1 || i == 2 ) ? desc - > log2_chroma_h : 0 ; data[i] = data[i - 1] + size[i - 1] ; h = ( height + ( 1 < < s ) - 1 ) > > s ; if ( linesizes[i] > INT_MAX / h ) return AVERROR ( EINVAL ) ; size[i] = h * linesizes[i] ; if ( total_size > INT_MAX - size[i] ) return AVERROR ( EINVAL ) ; total_size + = size[i] ; } return total_size ; }",1
"av_cold int MPV_common_init ( MpegEncContext * s ) { int y_size , c_size , yc_size , i , mb_array_size , mv_table_size , x , y , threads ; if ( s - > codec_id == CODEC_ID_MPEG2VIDEO & & ! s - > progressive_sequence ) s - > mb_height = ( s - > height + 31 ) / 32 * 2 ; else s - > mb_height = ( s - > height + 15 ) / 16 ; if ( s - > avctx - > pix_fmt == PIX_FMT_NONE ) { av_log ( s - > avctx , AV_LOG_ERROR , decoding to PIX_FMT_NONE is not supported . \n ) ; return - 1 ; } if ( s - > avctx - > thread_count > MAX_THREADS || ( s - > avctx - > thread_count > s - > mb_height & & s - > mb_height ) ) { av_log ( s - > avctx , AV_LOG_ERROR , too many threads\n ) ; return - 1 ; } if ( ( s - > width || s - > height ) & & avcodec_check_dimensions ( s - > avctx , s - > width , s - > height ) ) return - 1 ; dsputil_init ( & s - > dsp , s - > avctx ) ; ff_dct_common_init ( s ) ; s - > flags= s - > avctx - > flags ; s - > flags2= s - > avctx - > flags2 ; s - > mb_width = ( s - > width + 15 ) / 16 ; s - > mb_stride = s - > mb_width + 1 ; s - > b8_stride = s - > mb_width * 2 + 1 ; s - > b4_stride = s - > mb_width * 4 + 1 ; mb_array_size= s - > mb_height * s - > mb_stride ; mv_table_size= ( s - > mb_height + 2 ) * s - > mb_stride + 1 ; / * set chroma shifts * / avcodec_get_chroma_sub_sample ( s - > avctx - > pix_fmt , & ( s - > chroma_x_shift ) , & ( s - > chroma_y_shift ) ) ; / * set default edge pos , will be overriden in decode_header if needed * / s - > h_edge_pos= s - > mb_width * 16 ; s - > v_edge_pos= s - > mb_height * 16 ; s - > mb_num = s - > mb_width * s - > mb_height ; s - > block_wrap[0]= s - > block_wrap[1]= s - > block_wrap[2]= s - > block_wrap[3]= s - > b8_stride ; s - > block_wrap[4]= s - > block_wrap[5]= s - > mb_stride ; y_size = s - > b8_stride * ( 2 * s - > mb_height + 1 ) ; c_size = s - > mb_stride * ( s - > mb_height + 1 ) ; yc_size = y_size + 2 * c_size ; / * convert fourcc to upper case * / s - > codec_tag = ff_toupper4 ( s - > avctx - > codec_tag ) ; s - > stream_codec_tag = ff_toupper4 ( s - > avctx - > stream_codec_tag ) ; s - > avctx - > coded_frame= ( AVFrame * ) & s - > current_picture ; FF_ALLOCZ_OR_GOTO ( s - > avctx , s - > mb_index2xy , ( s - > mb_num + 1 ) * sizeof ( int ) , fail ) //error ressilience code looks cleaner with this for ( y=0 ; y < s - > mb_height ; y + + ) { for ( x=0 ; x < s - > mb_width ; x + + ) { s - > mb_index2xy[ x + y * s - > mb_width ] = x + y * s - > mb_stride ; } } s - > mb_index2xy[ s - > mb_height * s - > mb_width ] = ( s - > mb_height - 1 ) * s - > mb_stride + s - > mb_width ; //FIXME really needed ? if ( s - > encoding ) { / * Allocate MV tables * / FF_ALLOCZ_OR_GOTO ( s - > avctx , s - > p_mv_table_base , mv_table_size * 2 * sizeof ( int16_t ) , fail ) FF_ALLOCZ_OR_GOTO ( s - > avctx , s - > b_forw_mv_table_base , mv_table_size * 2 * sizeof ( int16_t ) , fail ) FF_ALLOCZ_OR_GOTO ( s - > avctx , s - > b_back_mv_table_base , mv_table_size * 2 * sizeof ( int16_t ) , fail ) FF_ALLOCZ_OR_GOTO ( s - > avctx , s - > b_bidir_forw_mv_table_base , mv_table_size * 2 * sizeof ( int16_t ) , fail ) FF_ALLOCZ_OR_GOTO ( s - > avctx , s - > b_bidir_back_mv_table_base , mv_table_size * 2 * sizeof ( int16_t ) , fail ) FF_ALLOCZ_OR_GOTO ( s - > avctx , s - > b_direct_mv_table_base , mv_table_size * 2 * sizeof ( int16_t ) , fail ) s - > p_mv_table = s - > p_mv_table_base + s - > mb_stride + 1 ; s - > b_forw_mv_table = s - > b_forw_mv_table_base + s - > mb_stride + 1 ; s - > b_back_mv_table = s - > b_back_mv_table_base + s - > mb_stride + 1 ; s - > b_bidir_forw_mv_table= s - > b_bidir_forw_mv_table_base + s - > mb_stride + 1 ; s - > b_bidir_back_mv_table= s - > b_bidir_back_mv_table_base + s - > mb_stride + 1 ; s - > b_direct_mv_table = s - > b_direct_mv_table_base + s - > mb_stride + 1 ; if ( s - > msmpeg4_version ) { FF_ALLOCZ_OR_GOTO ( s - > avctx , s - > ac_stats , 2 * 2 * ( MAX_LEVEL + 1 ) * ( MAX_RUN + 1 ) * 2 * sizeof ( int ) , fail ) ; } FF_ALLOCZ_OR_GOTO ( s - > avctx , s - > avctx - > stats_out , 256 , fail ) ; / * Allocate MB type table * / FF_ALLOCZ_OR_GOTO ( s - > avctx , s - > mb_type , mb_array_size * sizeof ( uint16_t ) , fail ) //needed for encoding FF_ALLOCZ_OR_GOTO ( s - > avctx , s - > lambda_table , mb_array_size * sizeof ( int ) , fail ) FF_ALLOCZ_OR_GOTO ( s - > avctx , s - > q_intra_matrix , 64 * 32 * sizeof ( int ) , fail ) FF_ALLOCZ_OR_GOTO ( s - > avctx , s - > q_inter_matrix , 64 * 32 * sizeof ( int ) , fail ) FF_ALLOCZ_OR_GOTO ( s - > avctx , s - > q_intra_matrix16 , 64 * 32 * 2 * sizeof ( uint16_t ) , fail ) FF_ALLOCZ_OR_GOTO ( s - > avctx , s - > q_inter_matrix16 , 64 * 32 * 2 * sizeof ( uint16_t ) , fail ) FF_ALLOCZ_OR_GOTO ( s - > avctx , s - > input_picture , MAX_PICTURE_COUNT * sizeof ( Picture * ) , fail ) FF_ALLOCZ_OR_GOTO ( s - > avctx , s - > reordered_input_picture , MAX_PICTURE_COUNT * sizeof ( Picture * ) , fail ) if ( s",1
"static av_cold int aac_decode_init ( AVCodecContext * avctx ) { AACContext * ac = avctx - > priv_data ; int ret ; ac - > avctx = avctx ; ac - > oc[1] . m4ac . sample_rate = avctx - > sample_rate ; aacdec_init ( ac ) ; if USE_FIXED avctx - > sample_fmt = AV_SAMPLE_FMT_S32P ; else avctx - > sample_fmt = AV_SAMPLE_FMT_FLTP ; endif / * USE_FIXED * / if ( avctx - > extradata_size > 0 ) { if ( ( ret = decode_audio_specific_config ( ac , ac - > avctx , & ac - > oc[1] . m4ac , avctx - > extradata , avctx - > extradata_size * 8 , 1 ) ) < 0 ) return ret ; } else { int sr , i ; uint8_t layout_map[MAX_ELEM_ID * 4][3] ; int layout_map_tags ; sr = sample_rate_idx ( avctx - > sample_rate ) ; ac - > oc[1] . m4ac . sampling_index = sr ; ac - > oc[1] . m4ac . channels = avctx - > channels ; ac - > oc[1] . m4ac . sbr = - 1 ; ac - > oc[1] . m4ac . ps = - 1 ; for ( i = 0 ; i < FF_ARRAY_ELEMS ( ff_mpeg4audio_channels ) ; i + + ) if ( ff_mpeg4audio_channels[i] == avctx - > channels ) break ; if ( i == FF_ARRAY_ELEMS ( ff_mpeg4audio_channels ) ) { i = 0 ; } ac - > oc[1] . m4ac . chan_config = i ; if ( ac - > oc[1] . m4ac . chan_config ) { int ret = set_default_channel_config ( avctx , layout_map , & layout_map_tags , ac - > oc[1] . m4ac . chan_config ) ; if ( ! ret ) output_configure ( ac , layout_map , layout_map_tags , OC_GLOBAL_HDR , 0 ) ; else if ( avctx - > err_recognition & AV_EF_EXPLODE ) return AVERROR_INVALIDDATA ; } } if ( avctx - > channels > MAX_CHANNELS ) { av_log ( avctx , AV_LOG_ERROR , Too many channels\n ) ; return AVERROR_INVALIDDATA ; } AAC_INIT_VLC_STATIC ( 0 , 304 ) ; AAC_INIT_VLC_STATIC ( 1 , 270 ) ; AAC_INIT_VLC_STATIC ( 2 , 550 ) ; AAC_INIT_VLC_STATIC ( 3 , 300 ) ; AAC_INIT_VLC_STATIC ( 4 , 328 ) ; AAC_INIT_VLC_STATIC ( 5 , 294 ) ; AAC_INIT_VLC_STATIC ( 6 , 306 ) ; AAC_INIT_VLC_STATIC ( 7 , 268 ) ; AAC_INIT_VLC_STATIC ( 8 , 510 ) ; AAC_INIT_VLC_STATIC ( 9 , 366 ) ; AAC_INIT_VLC_STATIC ( 10 , 462 ) ; AAC_RENAME ( ff_aac_sbr_init ) ( ) ; if USE_FIXED ac - > fdsp = avpriv_alloc_fixed_dsp ( avctx - > flags & AV_CODEC_FLAG_BITEXACT ) ; else ac - > fdsp = avpriv_float_dsp_alloc ( avctx - > flags & AV_CODEC_FLAG_BITEXACT ) ; endif / * USE_FIXED * / if ( ! ac - > fdsp ) { return AVERROR ( ENOMEM ) ; } ac - > random_state = 0x1f2e3d4c ; ff_aac_tableinit ( ) ; INIT_VLC_STATIC ( & vlc_scalefactors , 7 , FF_ARRAY_ELEMS ( ff_aac_scalefactor_code ) , ff_aac_scalefactor_bits , sizeof ( ff_aac_scalefactor_bits[0] ) , sizeof ( ff_aac_scalefactor_bits[0] ) , ff_aac_scalefactor_code , sizeof ( ff_aac_scalefactor_code[0] ) , sizeof ( ff_aac_scalefactor_code[0] ) , 352 ) ; AAC_RENAME_32 ( ff_mdct_init ) ( & ac - > mdct , 11 , 1 , 1 . 0 / RANGE15 ( 1024 . 0 ) ) ; AAC_RENAME_32 ( ff_mdct_init ) ( & ac - > mdct_ld , 10 , 1 , 1 . 0 / RANGE15 ( 512 . 0 ) ) ; AAC_RENAME_32 ( ff_mdct_init ) ( & ac - > mdct_small , 8 , 1 , 1 . 0 / RANGE15 ( 128 . 0 ) ) ; AAC_RENAME_32 ( ff_mdct_init ) ( & ac - > mdct_ltp , 11 , 0 , RANGE15 ( - 2 . 0 ) ) ; if ! USE_FIXED ret = ff_imdct15_init ( & ac - > mdct480 , 5 ) ; if ( ret < 0 ) return ret ; endif // window initialization AAC_RENAME ( ff_kbd_window_init ) ( AAC_RENAME ( ff_aac_kbd_long_1024 ) , 4 . 0 , 1024 ) ; AAC_RENAME ( ff_kbd_window_init ) ( AAC_RENAME ( ff_aac_kbd_short_128 ) , 6 . 0 , 128 ) ; AAC_RENAME ( ff_init_ff_sine_windows ) ( 10 ) ; AAC_RENAME ( ff_init_ff_sine_windows ) ( 9 ) ; AAC_RENAME ( ff_init_ff_sine_windows ) ( 7 ) ; AAC_RENAME ( cbrt_tableinit ) ( ) ; return 0 ; }",1
"static int msf_probe ( AVProbeData * p ) { if ( memcmp ( p - > buf , MSF , 3 ) ) return 0 ; if ( AV_RB32 ( p - > buf + 8 ) < = 0 ) return 0 ; if ( AV_RB32 ( p - > buf + 16 ) < = 0 ) return 0 ; return AVPROBE_SCORE_MAX / 3 * 2 ; }",1
"static inline int writer_print_string ( WriterContext * wctx , const char * key , const char * val , int opt ) { const struct section * section = wctx - > section[wctx - > level] ; int ret = 0 ; if ( opt & & ! ( wctx - > writer - > flags & WRITER_FLAG_DISPLAY_OPTIONAL_FIELDS ) ) return 0 ; if ( section - > show_all_entries || av_dict_get ( section - > entries_to_show , key , NULL , 0 ) ) { wctx - > writer - > print_string ( wctx , key , val ) ; wctx - > nb_item[wctx - > level] + + ; } return ret ; }",0
"static int mpjpeg_read_packet ( AVFormatContext * s , AVPacket * pkt ) { int size ; int ret ; MPJPEGDemuxContext * mpjpeg = s - > priv_data ; if ( mpjpeg - > boundary == NULL ) { mpjpeg - > boundary = av_strdup ( - - ) ; mpjpeg - > searchstr = av_strdup ( \r\n - - ) ; if ( ! mpjpeg - > boundary || ! mpjpeg - > searchstr ) { av_freep ( & mpjpeg - > boundary ) ; av_freep ( & mpjpeg - > searchstr ) ; return AVERROR ( ENOMEM ) ; } mpjpeg - > searchstr_len = strlen ( mpjpeg - > searchstr ) ; } ret = parse_multipart_header ( s - > pb , & size , mpjpeg - > boundary , s ) ; if ( ret < 0 ) return ret ; if ( size > 0 ) { / * size has been provided to us in MIME header * / ret = av_get_packet ( s - > pb , pkt , size ) ; } else { / * no size was given - - we read until the next boundary or end - of - file * / int remaining = 0 , len ; const int read_chunk = 2048 ; av_init_packet ( pkt ) ; pkt - > data = NULL ; pkt - > size = 0 ; pkt - > pos = avio_tell ( s - > pb ) ; / * we may need to return as much as all we ' ve read back to the buffer * / ffio_ensure_seekback ( s - > pb , read_chunk ) ; while ( ( ret = av_append_packet ( s - > pb , pkt , read_chunk - remaining ) ) > = 0 ) { / * scan the new data * / len = ret + remaining ; char * start = pkt - > data + pkt - > size - len ; do { if ( ! memcmp ( start , mpjpeg - > searchstr , mpjpeg - > searchstr_len ) ) { // got the boundary ! rewind the stream avio_seek ( s - > pb , - ( len - 2 ) , SEEK_CUR ) ; pkt - > size - = ( len - 2 ) ; return pkt - > size ; } len - - ; start + + ; } while ( len > = mpjpeg - > searchstr_len ) ; remaining = len ; } / * error or EOF occurred * / if ( ret == AVERROR_EOF ) { ret = pkt - > size > 0 ? pkt - > size : AVERROR_EOF ; } else { av_packet_unref ( pkt ) ; } } return ret ; }",0
"static int mov_read_enda ( MOVContext * c , ByteIOContext * pb , MOVAtom atom ) { AVStream * st = c - > fc - > streams[c - > fc - > nb_streams - 1] ; int little_endian = get_be16 ( pb ) ; dprintf ( c - > fc , enda %d\n , little_endian ) ; if ( little_endian == 1 ) { switch ( st - > codec - > codec_id ) { case CODEC_ID_PCM_S24BE : st - > codec - > codec_id = CODEC_ID_PCM_S24LE ; break ; case CODEC_ID_PCM_S32BE : st - > codec - > codec_id = CODEC_ID_PCM_S32LE ; break ; case CODEC_ID_PCM_F32BE : st - > codec - > codec_id = CODEC_ID_PCM_F32LE ; break ; case CODEC_ID_PCM_F64BE : st - > codec - > codec_id = CODEC_ID_PCM_F64LE ; break ; default : break ; } } return 0 ; }",0
"static inline int decode_scalar ( GetBitContext * gb , int k , int limit , int readsamplesize ) { int x = get_unary_0_9 ( gb ) ; if ( x > 8 ) { / * RICE THRESHOLD * / / * use alternative encoding * / x = get_bits ( gb , readsamplesize ) ; } else { if ( k > = limit ) k = limit ; if ( k ! = 1 ) { int extrabits = show_bits ( gb , k ) ; / * multiply x by 2 k - 1 , as part of their strange algorithm * / x = ( x < < k ) - x ; if ( extrabits > 1 ) { x + = extrabits - 1 ; skip_bits ( gb , k ) ; } else skip_bits ( gb , k - 1 ) ; } } return x ; }",0
"static void opt_b_frames ( const char * arg ) { b_frames = atoi ( arg ) ; if ( b_frames > FF_MAX_B_FRAMES ) { fprintf ( stderr , \nCannot have more than %d B frames , increase FF_MAX_B_FRAMES . \n , FF_MAX_B_FRAMES ) ; exit ( 1 ) ; } else if ( b_frames < 1 ) { fprintf ( stderr , \nNumber of B frames must be higher than 0\n ) ; exit ( 1 ) ; } }",0
"static av_cold int encode_init ( AVCodecContext * avc_context ) { theora_info t_info ; theora_comment t_comment ; ogg_packet o_packet ; unsigned int offset ; TheoraContext * h = avc_context - > priv_data ; / * Set up the theora_info struct * / theora_info_init ( & t_info ) ; t_info . width = FFALIGN ( avc_context - > width , 16 ) ; t_info . height = FFALIGN ( avc_context - > height , 16 ) ; t_info . frame_width = avc_context - > width ; t_info . frame_height = avc_context - > height ; t_info . offset_x = 0 ; t_info . offset_y = avc_context - > height & 0xf ; / * Swap numerator and denominator as time_base in AVCodecContext gives the * time period between frames , but theora_info needs the framerate . * / t_info . fps_numerator = avc_context - > time_base . den ; t_info . fps_denominator = avc_context - > time_base . num ; if ( avc_context - > sample_aspect_ratio . num ! = 0 ) { t_info . aspect_numerator = avc_context - > sample_aspect_ratio . num ; t_info . aspect_denominator = avc_context - > sample_aspect_ratio . den ; } else { t_info . aspect_numerator = 1 ; t_info . aspect_denominator = 1 ; } t_info . colorspace = OC_CS_UNSPECIFIED ; t_info . pixelformat = OC_PF_420 ; t_info . target_bitrate = avc_context - > bit_rate ; t_info . keyframe_frequency = avc_context - > gop_size ; t_info . keyframe_frequency_force = avc_context - > gop_size ; t_info . keyframe_mindistance = avc_context - > keyint_min ; t_info . quality = 0 ; t_info . quick_p = 1 ; t_info . dropframes_p = 0 ; t_info . keyframe_auto_p = 1 ; t_info . keyframe_data_target_bitrate = t_info . target_bitrate * 1 . 5 ; t_info . keyframe_auto_threshold = 80 ; t_info . noise_sensitivity = 1 ; t_info . sharpness = 0 ; / * Now initialise libtheora * / if ( theora_encode_init ( & ( h - > t_state ) , & t_info ) ! = 0 ) { av_log ( avc_context , AV_LOG_ERROR , theora_encode_init failed\n ) ; return - 1 ; } / * Clear up theora_info struct * / theora_info_clear ( & t_info ) ; / * Output first header packet consisting of theora header , comment , and tables . Each one is prefixed with a 16bit size , then they are concatenated together into ffmpeg ' s extradata . * / offset = 0 ; / * Header * / theora_encode_header ( & ( h - > t_state ) , & o_packet ) ; if ( concatenate_packet ( & offset , avc_context , & o_packet ) ! = 0 ) { return - 1 ; } / * Comment * / theora_comment_init ( & t_comment ) ; theora_encode_comment ( & t_comment , & o_packet ) ; if ( concatenate_packet ( & offset , avc_context , & o_packet ) ! = 0 ) { return - 1 ; } / * Tables * / theora_encode_tables ( & ( h - > t_state ) , & o_packet ) ; if ( concatenate_packet ( & offset , avc_context , & o_packet ) ! = 0 ) { return - 1 ; } / * Clear up theora_comment struct * / theora_comment_clear ( & t_comment ) ; / * Set up the output AVFrame * / avc_context - > coded_frame= avcodec_alloc_frame ( ) ; return 0 ; }",1
"static int frame_thread_init ( AVCodecContext * avctx ) { int thread_count = avctx - > thread_count ; AVCodec * codec = avctx - > codec ; AVCodecContext * src = avctx ; FrameThreadContext * fctx ; int i , err = 0 ; if ( thread_count < = 1 ) { avctx - > active_thread_type = 0 ; return 0 ; } avctx - > thread_opaque = fctx = av_mallocz ( sizeof ( FrameThreadContext ) ) ; fctx - > threads = av_mallocz ( sizeof ( PerThreadContext ) * thread_count ) ; pthread_mutex_init ( & fctx - > buffer_mutex , NULL ) ; fctx - > delaying = 1 ; for ( i = 0 ; i < thread_count ; i + + ) { AVCodecContext * copy = av_malloc ( sizeof ( AVCodecContext ) ) ; PerThreadContext * p = & fctx - > threads[i] ; pthread_mutex_init ( & p - > mutex , NULL ) ; pthread_mutex_init ( & p - > progress_mutex , NULL ) ; pthread_cond_init ( & p - > input_cond , NULL ) ; pthread_cond_init ( & p - > progress_cond , NULL ) ; pthread_cond_init ( & p - > output_cond , NULL ) ; p - > parent = fctx ; p - > avctx = copy ; if ( ! copy ) { err = AVERROR ( ENOMEM ) ; goto error ; } * copy = * src ; copy - > thread_opaque = p ; copy - > pkt = & p - > avpkt ; if ( ! i ) { src = copy ; if ( codec - > init ) err = codec - > init ( copy ) ; update_context_from_thread ( avctx , copy , 1 ) ; } else { copy - > priv_data = av_malloc ( codec - > priv_data_size ) ; if ( ! copy - > priv_data ) { err = AVERROR ( ENOMEM ) ; goto error ; } memcpy ( copy - > priv_data , src - > priv_data , codec - > priv_data_size ) ; copy - > internal = av_malloc ( sizeof ( AVCodecInternal ) ) ; if ( ! copy - > internal ) { err = AVERROR ( ENOMEM ) ; goto error ; } * ( copy - > internal ) = * ( src - > internal ) ; copy - > internal - > is_copy = 1 ; if ( codec - > init_thread_copy ) err = codec - > init_thread_copy ( copy ) ; } if ( err ) goto error ; pthread_create ( & p - > thread , NULL , frame_worker_thread , p ) ; } return 0 ; error : frame_thread_free ( avctx , i + 1 ) ; return err ; }",1
"static char * shorts2str ( int16_t * sp , int count , const char * sep ) { int i ; char * ap , * ap0 ; if ( ! sep ) sep = , ; ap = av_malloc ( ( 5 + strlen ( sep ) ) * count ) ; if ( ! ap ) return NULL ; ap0 = ap ; ap[0] = ' \0 ' ; for ( i = 0 ; i < count ; i + + ) { int l = snprintf ( ap , 5 + strlen ( sep ) , %d%s , sp[i] , sep ) ; ap + = l ; } ap0[strlen ( ap0 ) - strlen ( sep ) ] = ' \0 ' ; return ap0 ; }",0
"static int h264_set_parameter_from_sps ( H264Context * h ) { if ( h - > flags & CODEC_FLAG_LOW_DELAY || ( h - > sps . bitstream_restriction_flag & & ! h - > sps . num_reorder_frames ) ) { if ( h - > avctx - > has_b_frames > 1 || h - > delayed_pic[0] ) av_log ( h - > avctx , AV_LOG_WARNING , Delayed frames seen . Reenabling low delay requires a codec flush . \n ) ; else h - > low_delay = 1 ; if ( h - > avctx - > has_b_frames < 2 ) h - > avctx - > has_b_frames = ! h - > low_delay ; if ( h - > avctx - > bits_per_raw_sample ! = h - > sps . bit_depth_luma || h - > cur_chroma_format_idc ! = h - > sps . chroma_format_idc ) { if ( h - > avctx - > codec & & h - > avctx - > codec - > capabilities & CODEC_CAP_HWACCEL_VDPAU & & ( h - > sps . bit_depth_luma ! = 8 || h - > sps . chroma_format_idc > 1 ) ) { av_log ( h - > avctx , AV_LOG_ERROR , VDPAU decoding does not support video colorspace . \n ) ; return AVERROR_INVALIDDATA ; if ( h - > sps . bit_depth_luma > = 8 & & h - > sps . bit_depth_luma < = 10 ) { h - > avctx - > bits_per_raw_sample = h - > sps . bit_depth_luma ; h - > cur_chroma_format_idc = h - > sps . chroma_format_idc ; h - > pixel_shift = h - > sps . bit_depth_luma > 8 ; ff_h264dsp_init ( & h - > h264dsp , h - > sps . bit_depth_luma , h - > sps . chroma_format_idc ) ; ff_h264chroma_init ( & h - > h264chroma , h - > sps . bit_depth_chroma ) ; ff_h264qpel_init ( & h - > h264qpel , h - > sps . bit_depth_luma ) ; ff_h264_pred_init ( & h - > hpc , h - > avctx - > codec_id , h - > sps . bit_depth_luma , h - > sps . chroma_format_idc ) ; h - > dsp . dct_bits = h - > sps . bit_depth_luma > 8 ? 32 : 16 ; ff_dsputil_init ( & h - > dsp , h - > avctx ) ; ff_videodsp_init ( & h - > vdsp , h - > sps . bit_depth_luma ) ; } else { av_log ( h - > avctx , AV_LOG_ERROR , Unsupported bit depth : %d\n , h - > sps . bit_depth_luma ) ; return AVERROR_INVALIDDATA ; return 0 ;",1
"int ff_raw_video_read_header ( AVFormatContext * s ) { AVStream * st ; FFRawVideoDemuxerContext * s1 = s - > priv_data ; AVRational framerate ; int ret = 0 ; st = avformat_new_stream ( s , NULL ) ; if ( ! st ) { ret = AVERROR ( ENOMEM ) ; goto fail ; } st - > codec - > codec_type = AVMEDIA_TYPE_VIDEO ; st - > codec - > codec_id = s - > iformat - > raw_codec_id ; st - > need_parsing = AVSTREAM_PARSE_FULL ; if ( ( ret = av_parse_video_rate ( & framerate , s1 - > framerate ) ) < 0 ) { av_log ( s , AV_LOG_ERROR , Could not parse framerate : %s . \n , s1 - > framerate ) ; goto fail ; } st - > r_frame_rate = st - > avg_frame_rate = framerate ; avpriv_set_pts_info ( st , 64 , framerate . den , framerate . num ) ; fail : return ret ; }",1
"static int mov_read_packet ( AVFormatContext * s , AVPacket * pkt ) { MOVContext * mov = s - > priv_data ; MOVStreamContext * sc ; AVIndexEntry * sample ; AVStream * st = NULL ; int ret ; mov - > fc = s ; retry : sample = mov_find_next_sample ( s , & st ) ; if ( ! sample ) { mov - > found_mdat = 0 ; if ( ! mov - > next_root_atom ) return AVERROR_EOF ; avio_seek ( s - > pb , mov - > next_root_atom , SEEK_SET ) ; mov - > next_root_atom = 0 ; if ( mov_read_default ( mov , s - > pb , ( MOVAtom ) { AV_RL32 ( root ) , INT64_MAX } ) < 0 || url_feof ( s - > pb ) ) return AVERROR_EOF ; av_dlog ( s , read fragments , offset 0x% PRIx64 \n , avio_tell ( s - > pb ) ) ; goto retry ; sc = st - > priv_data ; / * must be done just before reading , to avoid infinite loop on sample * / sc - > current_sample + + ; if ( st - > discard ! = AVDISCARD_ALL ) { if ( avio_seek ( sc - > pb , sample - > pos , SEEK_SET ) ! = sample - > pos ) { av_log ( mov - > fc , AV_LOG_ERROR , stream %d , offset 0x% PRIx64 : partial file\n , sc - > ffindex , sample - > pos ) ; return AVERROR_INVALIDDATA ; ret = av_get_packet ( sc - > pb , pkt , sample - > size ) ; if ( ret < 0 ) return ret ; if ( sc - > has_palette ) { uint8_t * pal ; pal = av_packet_new_side_data ( pkt , AV_PKT_DATA_PALETTE , AVPALETTE_SIZE ) ; if ( ! pal ) { av_log ( mov - > fc , AV_LOG_ERROR , Cannot append palette to packet\n ) ; } else { memcpy ( pal , sc - > palette , AVPALETTE_SIZE ) ; sc - > has_palette = 0 ; if CONFIG_DV_DEMUXER if ( mov - > dv_demux & & sc - > dv_audio_container ) { avpriv_dv_produce_packet ( mov - > dv_demux , pkt , pkt - > data , pkt - > size , pkt - > pos ) ; av_free ( pkt - > data ) ; pkt - > size = 0 ; ret = avpriv_dv_get_packet ( mov - > dv_demux , pkt ) ; if ( ret < 0 ) return ret ; endif pkt - > stream_index = sc - > ffindex ; pkt - > dts = sample - > timestamp ; if ( sc - > ctts_data & & sc - > ctts_index < sc - > ctts_count ) { pkt - > pts = pkt - > dts + sc - > dts_shift + sc - > ctts_data[sc - > ctts_index] . duration ; / * update ctts context * / sc - > ctts_sample + + ; if ( sc - > ctts_index < sc - > ctts_count & & sc - > ctts_data[sc - > ctts_index] . count == sc - > ctts_sample ) { sc - > ctts_index + + ; sc - > ctts_sample = 0 ; if ( sc - > wrong_dts ) pkt - > dts = AV_NOPTS_VALUE ; } else { int64_t next_dts = ( sc - > current_sample < st - > nb_index_entries ) ? st - > index_entries[sc - > current_sample] . timestamp : st - > duration ; pkt - > duration = next_dts - pkt - > dts ; pkt - > pts = pkt - > dts ; if ( st - > discard == AVDISCARD_ALL ) goto retry ; pkt - > flags |= sample - > flags & AVINDEX_KEYFRAME ? AV_PKT_FLAG_KEY : 0 ; pkt - > pos = sample - > pos ; av_dlog ( s , stream %d , pts % PRId64 , dts % PRId64 , pos 0x% PRIx64 , duration %d\n , pkt - > stream_index , pkt - > pts , pkt - > dts , pkt - > pos , pkt - > duration ) ; return 0 ;",1
"static int svq1_motion_inter_4v_block ( DSPContext * dsp , GetBitContext * bitbuf , uint8_t * current , uint8_t * previous , int pitch , svq1_pmv * motion , int x , int y ) { uint8_t * src ; uint8_t * dst ; svq1_pmv mv ; svq1_pmv * pmv[4] ; int i , result ; / * predict and decode motion vector ( 0 ) * / pmv[0] = & motion[0] ; if ( y == 0 ) { pmv[1] = pmv[2] = pmv[0] ; } else { pmv[1] = & motion[ ( x / 8 ) + 2] ; pmv[2] = & motion[ ( x / 8 ) + 4] ; } result = svq1_decode_motion_vector ( bitbuf , & mv , pmv ) ; if ( result ! = 0 ) return result ; / * predict and decode motion vector ( 1 ) * / pmv[0] = & mv ; if ( y == 0 ) { pmv[1] = pmv[2] = pmv[0] ; } else { pmv[1] = & motion[ ( x / 8 ) + 3] ; } result = svq1_decode_motion_vector ( bitbuf , & motion[0] , pmv ) ; if ( result ! = 0 ) return result ; / * predict and decode motion vector ( 2 ) * / pmv[1] = & motion[0] ; pmv[2] = & motion[ ( x / 8 ) + 1] ; result = svq1_decode_motion_vector ( bitbuf , & motion[ ( x / 8 ) + 2] , pmv ) ; if ( result ! = 0 ) return result ; / * predict and decode motion vector ( 3 ) * / pmv[2] = & motion[ ( x / 8 ) + 2] ; pmv[3] = & motion[ ( x / 8 ) + 3] ; result = svq1_decode_motion_vector ( bitbuf , pmv[3] , pmv ) ; if ( result ! = 0 ) return result ; / * form predictions * / for ( i = 0 ; i < 4 ; i + + ) { int mvx = pmv[i] - > x + ( i & 1 ) * 16 ; int mvy = pmv[i] - > y + ( i > > 1 ) * 16 ; // FIXME : clipping or padding ? if ( y + ( mvy > > 1 ) < 0 ) mvy = 0 ; if ( x + ( mvx > > 1 ) < 0 ) mvx = 0 ; src = & previous[ ( x + ( mvx > > 1 ) ) + ( y + ( mvy > > 1 ) ) * pitch] ; dst = current ; dsp - > put_pixels_tab[1][ ( ( mvy & 1 ) < < 1 ) | ( mvx & 1 ) ] ( dst , src , pitch , 8 ) ; / * select next block * / if ( i & 1 ) current + = 8 * ( pitch - 1 ) ; else current + = 8 ; } return 0 ; }",1
"static av_always_inline void idct_mb ( VP8Context * s , uint8_t * dst[3] , VP8Macroblock * mb ) { int x , y , ch ; if ( mb - > mode ! = MODE_I4x4 ) { uint8_t * y_dst = dst[0] ; for ( y = 0 ; y < 4 ; y + + ) { uint32_t nnz4 = AV_RL32 ( s - > non_zero_count_cache[y] ) ; if ( nnz4 ) { if ( nnz4 & 0x01010101 ) { for ( x = 0 ; x < 4 ; x + + ) { if ( ( uint8_t ) nnz4 == 1 ) s - > vp8dsp . vp8_idct_dc_add ( y_dst + 4 * x , s - > block[y][x] , s - > linesize ) ; else if ( ( uint8_t ) nnz4 > 1 ) s - > vp8dsp . vp8_idct_add ( y_dst + 4 * x , s - > block[y][x] , s - > linesize ) ; nnz4 > > = 8 ; if ( ! nnz4 ) break ; } } else { s - > vp8dsp . vp8_idct_dc_add4y ( y_dst , s - > block[y] , s - > linesize ) ; } } y_dst + = 4 * s - > linesize ; } } for ( ch = 0 ; ch < 2 ; ch + + ) { uint32_t nnz4 = AV_RL32 ( s - > non_zero_count_cache[4 + ch] ) ; if ( nnz4 ) { uint8_t * ch_dst = dst[1 + ch] ; if ( nnz4 & 0x01010101 ) { for ( y = 0 ; y < 2 ; y + + ) { for ( x = 0 ; x < 2 ; x + + ) { if ( ( uint8_t ) nnz4 == 1 ) s - > vp8dsp . vp8_idct_dc_add ( ch_dst + 4 * x , s - > block[4 + ch][ ( y < < 1 ) + x] , s - > uvlinesize ) ; else if ( ( uint8_t ) nnz4 > 1 ) s - > vp8dsp . vp8_idct_add ( ch_dst + 4 * x , s - > block[4 + ch][ ( y < < 1 ) + x] , s - > uvlinesize ) ; nnz4 > > = 8 ; if ( ! nnz4 ) break ; } ch_dst + = 4 * s - > uvlinesize ; } } else { s - > vp8dsp . vp8_idct_dc_add4uv ( ch_dst , s - > block[4 + ch] , s - > uvlinesize ) ; } } } }",0
"static av_always_inline float quantize_and_encode_band_cost_template ( struct AACEncContext * s , PutBitContext * pb , const float * in , const float * scaled , int size , int scale_idx , int cb , const float lambda , const float uplim , int * bits , int BT_ZERO , int BT_UNSIGNED , int BT_PAIR , int BT_ESC ) { const int q_idx = POW_SF2_ZERO - scale_idx + SCALE_ONE_POS - SCALE_DIV_512 ; const float Q = ff_aac_pow2sf_tab [q_idx] ; const float Q34 = ff_aac_pow34sf_tab[q_idx] ; const float IQ = ff_aac_pow2sf_tab [POW_SF2_ZERO + scale_idx - SCALE_ONE_POS + SCALE_DIV_512] ; const float CLIPPED_ESCAPE = 165140 . 0f * IQ ; int i , j ; float cost = 0 ; const int dim = BT_PAIR ? 2 : 4 ; int resbits = 0 ; const int range = aac_cb_range[cb] ; const int maxval = aac_cb_maxval[cb] ; int off ; if ( BT_ZERO ) { for ( i = 0 ; i < size ; i + + ) cost + = in[i] * in[i] ; if ( bits ) * bits = 0 ; return cost * lambda ; } if ( ! scaled ) { abs_pow34_v ( s - > scoefs , in , size ) ; scaled = s - > scoefs ; } quantize_bands ( s - > qcoefs , in , scaled , size , Q34 , ! BT_UNSIGNED , maxval ) ; if ( BT_UNSIGNED ) { off = 0 ; } else { off = maxval ; } for ( i = 0 ; i < size ; i + = dim ) { const float * vec ; int * quants = s - > qcoefs + i ; int curidx = 0 ; int curbits ; float rd = 0 . 0f ; for ( j = 0 ; j < dim ; j + + ) { curidx * = range ; curidx + = quants[j] + off ; } curbits = ff_aac_spectral_bits[cb - 1][curidx] ; vec = & ff_aac_codebook_vectors[cb - 1][curidx * dim] ; if ( BT_UNSIGNED ) { for ( j = 0 ; j < dim ; j + + ) { float t = fabsf ( in[i + j] ) ; float di ; if ( BT_ESC & & vec[j] == 64 . 0f ) { //FIXME : slow if ( t > = CLIPPED_ESCAPE ) { di = t - CLIPPED_ESCAPE ; curbits + = 21 ; } else { int c = av_clip_uintp2 ( quant ( t , Q ) , 13 ) ; di = t - c * cbrtf ( c ) * IQ ; curbits + = av_log2 ( c ) * 2 - 4 + 1 ; } } else { di = t - vec[j] * IQ ; } if ( vec[j] ! = 0 . 0f ) curbits + + ; rd + = di * di ; } } else { for ( j = 0 ; j < dim ; j + + ) { float di = in[i + j] - vec[j] * IQ ; rd + = di * di ; } } cost + = rd * lambda + curbits ; resbits + = curbits ; if ( cost > = uplim ) return uplim ; if ( pb ) { put_bits ( pb , ff_aac_spectral_bits[cb - 1][curidx] , ff_aac_spectral_codes[cb - 1][curidx] ) ; if ( BT_UNSIGNED ) for ( j = 0 ; j < dim ; j + + ) if ( ff_aac_codebook_vectors[cb - 1][curidx * dim + j] ! = 0 . 0f ) put_bits ( pb , 1 , in[i + j] < 0 . 0f ) ; if ( BT_ESC ) { for ( j = 0 ; j < 2 ; j + + ) { if ( ff_aac_codebook_vectors[cb - 1][curidx * 2 + j] == 64 . 0f ) { int coef = av_clip_uintp2 ( quant ( fabsf ( in[i + j] ) , Q ) , 13 ) ; int len = av_log2 ( coef ) ; put_bits ( pb , len - 4 + 1 , ( 1 < < ( len - 4 + 1 ) ) - 2 ) ; put_bits ( pb , len , coef & ( ( 1 < < len ) - 1 ) ) ; } } } } } if ( bits ) * bits = resbits ; return cost ; }",1
"static int seek_test ( const char * input_filename , const char * start , const char * end ) { AVCodec * codec = NULL ; AVCodecContext * ctx= NULL ; AVCodecParameters * origin_par = NULL ; AVFrame * fr = NULL ; AVFormatContext * fmt_ctx = NULL ; int video_stream ; int result ; int i , j ; long int start_ts , end_ts ; size_of_array = 0 ; number_of_elements = 0 ; crc_array = pts_array = NULL ; result = avformat_open_input ( & fmt_ctx , input_filename , NULL , NULL ) ; if ( result < 0 ) { av_log ( NULL , AV_LOG_ERROR , Can ' t open file\n ) ; return result ; } result = avformat_find_stream_info ( fmt_ctx , NULL ) ; if ( result < 0 ) { av_log ( NULL , AV_LOG_ERROR , Can ' t get stream info\n ) ; return result ; } start_ts = read_seek_range ( start ) ; end_ts = read_seek_range ( end ) ; if ( ( start_ts < 0 ) || ( end_ts < 0 ) ) return - 1 ; //TODO : add ability to work with audio format video_stream = av_find_best_stream ( fmt_ctx , AVMEDIA_TYPE_VIDEO , - 1 , - 1 , NULL , 0 ) ; if ( video_stream < 0 ) { av_log ( NULL , AV_LOG_ERROR , Can ' t find video stream in input file\n ) ; return - 1 ; } origin_par = fmt_ctx - > streams[video_stream] - > codecpar ; codec = avcodec_find_decoder ( origin_par - > codec_id ) ; if ( ! codec ) { av_log ( NULL , AV_LOG_ERROR , Can ' t find decoder\n ) ; return - 1 ; } ctx = avcodec_alloc_context3 ( codec ) ; if ( ! ctx ) { av_log ( NULL , AV_LOG_ERROR , Can ' t allocate decoder context\n ) ; return AVERROR ( ENOMEM ) ; } result = avcodec_parameters_to_context ( ctx , origin_par ) ; if ( result ) { av_log ( NULL , AV_LOG_ERROR , Can ' t copy decoder context\n ) ; return result ; } result = avcodec_open2 ( ctx , codec , NULL ) ; if ( result < 0 ) { av_log ( ctx , AV_LOG_ERROR , Can ' t open decoder\n ) ; return result ; } fr = av_frame_alloc ( ) ; if ( ! fr ) { av_log ( NULL , AV_LOG_ERROR , Can ' t allocate frame\n ) ; return AVERROR ( ENOMEM ) ; } result = compute_crc_of_packets ( fmt_ctx , video_stream , ctx , fr , i , j , 1 ) ; if ( result ! = 0 ) return - 1 ; for ( i = start_ts ; i < end_ts ; i + = 100 ) { for ( j = i + 100 ; j < end_ts ; j + = 100 ) result = compute_crc_of_packets ( fmt_ctx , video_stream , ctx , fr , i , j , 0 ) ; if ( result ! = 0 ) return - 1 ; } av_freep ( & crc_array ) ; av_freep ( & pts_array ) ; av_frame_free ( & fr ) ; avcodec_close ( ctx ) ; avformat_close_input ( & fmt_ctx ) ; avcodec_free_context ( & ctx ) ; return 0 ; }",1
"static inline void RENAME ( rgb15to16 ) ( const uint8_t * src , uint8_t * dst , int src_size ) { register const uint8_t * s=src ; register uint8_t * d=dst ; register const uint8_t * end ; const uint8_t * mm_end ; end = s + src_size ; __asm__ volatile ( PREFETCH %0 : : m ( * s ) ) ; __asm__ volatile ( movq %0 , %%mm4 : : m ( mask15s ) ) ; mm_end = end - 15 ; while ( s < mm_end ) { __asm__ volatile ( PREFETCH 32%1 \n\t movq %1 , %%mm0 \n\t movq 8%1 , %%mm2 \n\t movq %%mm0 , %%mm1 \n\t movq %%mm2 , %%mm3 \n\t pand %%mm4 , %%mm0 \n\t pand %%mm4 , %%mm2 \n\t paddw %%mm1 , %%mm0 \n\t paddw %%mm3 , %%mm2 \n\t MOVNTQ %%mm0 , %0 \n\t MOVNTQ %%mm2 , 8%0 : =m ( * d ) : m ( * s ) ) ; d + =16 ; s + =16 ; } __asm__ volatile ( SFENCE : : : memory ) ; __asm__ volatile ( EMMS : : : memory ) ; mm_end = end - 3 ; while ( s < mm_end ) { register unsigned x= * ( ( const uint32_t * ) s ) ; * ( ( uint32_t * ) d ) = ( x & 0x7FFF7FFF ) + ( x & 0x7FE07FE0 ) ; d + =4 ; s + =4 ; } if ( s < end ) { register unsigned short x= * ( ( const uint16_t * ) s ) ; * ( ( uint16_t * ) d ) = ( x & 0x7FFF ) + ( x & 0x7FE0 ) ; } }",1
"static inline void RENAME ( rgb15to32 ) ( const uint8_t * src , uint8_t * dst , long src_size ) { const uint16_t * end ; ifdef HAVE_MMX const uint16_t * mm_end ; endif uint8_t * d = ( uint8_t * ) dst ; const uint16_t * s = ( const uint16_t * ) src ; end = s + src_size/2 ; ifdef HAVE_MMX __asm __volatile ( PREFETCH %0 : : m ( * s ) : memory ) ; __asm __volatile ( pxor %%mm7 , %%mm7\n\t : : : memory ) ; mm_end = end - 3 ; while ( s < mm_end ) { __asm __volatile ( PREFETCH 32%1\n\t movq %1 , %%mm0\n\t movq %1 , %%mm1\n\t movq %1 , %%mm2\n\t pand %2 , %%mm0\n\t pand %3 , %%mm1\n\t pand %4 , %%mm2\n\t psllq 3 , %%mm0\n\t psrlq 2 , %%mm1\n\t psrlq 7 , %%mm2\n\t movq %%mm0 , %%mm3\n\t movq %%mm1 , %%mm4\n\t movq %%mm2 , %%mm5\n\t punpcklwd %%mm7 , %%mm0\n\t punpcklwd %%mm7 , %%mm1\n\t punpcklwd %%mm7 , %%mm2\n\t punpckhwd %%mm7 , %%mm3\n\t punpckhwd %%mm7 , %%mm4\n\t punpckhwd %%mm7 , %%mm5\n\t psllq 8 , %%mm1\n\t psllq 16 , %%mm2\n\t por %%mm1 , %%mm0\n\t por %%mm2 , %%mm0\n\t psllq 8 , %%mm4\n\t psllq 16 , %%mm5\n\t por %%mm4 , %%mm3\n\t por %%mm5 , %%mm3\n\t MOVNTQ %%mm0 , %0\n\t MOVNTQ %%mm3 , 8%0\n\t : =m ( * d ) : m ( * s ) , m ( mask15b ) , m ( mask15g ) , m ( mask15r ) : memory ) ; d + = 16 ; s + = 4 ; } __asm __volatile ( SFENCE : : : memory ) ; __asm __volatile ( EMMS : : : memory ) ; endif while ( s < end ) { if 0 //slightly slower on athlon int bgr= * s + + ; * ( ( uint32_t * ) d ) + + = ( ( bgr & 0x1F ) < < 3 ) + ( ( bgr & 0x3E0 ) < < 6 ) + ( ( bgr & 0x7C00 ) < < 9 ) ; else register uint16_t bgr ; bgr = * s + + ; ifdef WORDS_BIGENDIAN * d + + = 0 ; * d + + = ( bgr & 0x7C00 ) > > 7 ; * d + + = ( bgr & 0x3E0 ) > > 2 ; * d + + = ( bgr & 0x1F ) < < 3 ; else * d + + = ( bgr & 0x1F ) < < 3 ; * d + + = ( bgr & 0x3E0 ) > > 2 ; * d + + = ( bgr & 0x7C00 ) > > 7 ; * d + + = 0 ; endif endif } }",1
"int decode_splitmvs ( VP8Context * s , VP56RangeCoder * c , VP8Macroblock * mb , int layout ) { int part_idx ; int n , num ; VP8Macroblock * top_mb ; VP8Macroblock * left_mb = & mb[ - 1] ; const uint8_t * mbsplits_left = vp8_mbsplits[left_mb - > partitioning] ; const uint8_t * mbsplits_top , * mbsplits_cur , * firstidx ; VP56mv * top_mv ; VP56mv * left_mv = left_mb - > bmv ; VP56mv * cur_mv = mb - > bmv ; if ( ! layout ) // layout is inlined , s - > mb_layout is not top_mb = & mb[2] ; else top_mb = & mb[ - s - > mb_width - 1] ; mbsplits_top = vp8_mbsplits[top_mb - > partitioning] ; top_mv = top_mb - > bmv ; if ( vp56_rac_get_prob_branchy ( c , vp8_mbsplit_prob[0] ) ) { if ( vp56_rac_get_prob_branchy ( c , vp8_mbsplit_prob[1] ) ) part_idx = VP8_SPLITMVMODE_16x8 + vp56_rac_get_prob ( c , vp8_mbsplit_prob[2] ) ; else part_idx = VP8_SPLITMVMODE_8x8 ; } else { part_idx = VP8_SPLITMVMODE_4x4 ; } num = vp8_mbsplit_count[part_idx] ; mbsplits_cur = vp8_mbsplits[part_idx] , firstidx = vp8_mbfirstidx[part_idx] ; mb - > partitioning = part_idx ; for ( n = 0 ; n < num ; n + + ) { int k = firstidx[n] ; uint32_t left , above ; const uint8_t * submv_prob ; if ( ! ( k & 3 ) ) left = AV_RN32A ( & left_mv[mbsplits_left[k + 3]] ) ; else left = AV_RN32A ( & cur_mv[mbsplits_cur[k - 1]] ) ; if ( k < = 3 ) above = AV_RN32A ( & top_mv[mbsplits_top[k + 12]] ) ; else above = AV_RN32A ( & cur_mv[mbsplits_cur[k - 4]] ) ; submv_prob = get_submv_prob ( left , above ) ; if ( vp56_rac_get_prob_branchy ( c , submv_prob[0] ) ) { if ( vp56_rac_get_prob_branchy ( c , submv_prob[1] ) ) { if ( vp56_rac_get_prob_branchy ( c , submv_prob[2] ) ) { mb - > bmv[n] . y = mb - > mv . y + read_mv_component ( c , s - > prob - > mvc[0] ) ; mb - > bmv[n] . x = mb - > mv . x + read_mv_component ( c , s - > prob - > mvc[1] ) ; } else { AV_ZERO32 ( & mb - > bmv[n] ) ; } } else { AV_WN32A ( & mb - > bmv[n] , above ) ; } } else { AV_WN32A ( & mb - > bmv[n] , left ) ; } } return num ; }",1
"static inline void FUNC ( idctSparseColPut ) ( pixel * dest , int line_size , DCTELEM * col ) { int a0 , a1 , a2 , a3 , b0 , b1 , b2 , b3 ; INIT_CLIP ; IDCT_COLS ; dest[0] = CLIP ( ( a0 + b0 ) > > COL_SHIFT ) ; dest + = line_size ; dest[0] = CLIP ( ( a1 + b1 ) > > COL_SHIFT ) ; dest + = line_size ; dest[0] = CLIP ( ( a2 + b2 ) > > COL_SHIFT ) ; dest + = line_size ; dest[0] = CLIP ( ( a3 + b3 ) > > COL_SHIFT ) ; dest + = line_size ; dest[0] = CLIP ( ( a3 - b3 ) > > COL_SHIFT ) ; dest + = line_size ; dest[0] = CLIP ( ( a2 - b2 ) > > COL_SHIFT ) ; dest + = line_size ; dest[0] = CLIP ( ( a1 - b1 ) > > COL_SHIFT ) ; dest + = line_size ; dest[0] = CLIP ( ( a0 - b0 ) > > COL_SHIFT ) ; }",1
"static int aasc_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; AascContext * s = avctx - > priv_data ; int compr , i , stride , ret ; if ( buf_size < 4 ) if ( ( ret = ff_reget_buffer ( avctx , s - > frame ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , reget_buffer ( ) failed\n ) ; return ret ; } compr = AV_RL32 ( buf ) ; buf + = 4 ; buf_size - = 4 ; switch ( compr ) { case 0 : stride = ( avctx - > width * 3 + 3 ) & 3 ; for ( i = avctx - > height - 1 ; i > = 0 ; i - - ) { memcpy ( s - > frame - > data[0] + i * s - > frame - > linesize[0] , buf , avctx - > width * 3 ) ; buf + = stride ; } break ; case 1 : bytestream2_init ( & s - > gb , buf , buf_size ) ; ff_msrle_decode ( avctx , ( AVPicture * ) s - > frame , 8 , & s - > gb ) ; break ; default : av_log ( avctx , AV_LOG_ERROR , Unknown compression type %d\n , compr ) ; } * got_frame = 1 ; if ( ( ret = av_frame_ref ( data , s - > frame ) ) < 0 ) return ret ; / * report that the buffer was completely consumed * / return buf_size ; }",1
"int check_codec_match ( AVCodecContext * ccf , AVCodecContext * ccs , int stream ) { int matches = 1 ; define CHECK_CODEC ( x ) ( ccf - > x ! = ccs - > x ) if ( CHECK_CODEC ( codec_id ) || CHECK_CODEC ( codec_type ) ) { http_log ( Codecs do not match for stream %d\n , stream ) ; matches = 0 ; } else if ( CHECK_CODEC ( bit_rate ) || CHECK_CODEC ( flags ) ) { http_log ( Codec bitrates do not match for stream %d\n , stream ) ; matches = 0 ; } else if ( ccf - > codec_type == AVMEDIA_TYPE_VIDEO ) { if ( CHECK_CODEC ( time_base . den ) || CHECK_CODEC ( time_base . num ) || CHECK_CODEC ( width ) || CHECK_CODEC ( height ) ) { http_log ( Codec width , height or framerate do not match for stream %d\n , stream ) ; matches = 0 ; } } else if ( ccf - > codec_type == AVMEDIA_TYPE_AUDIO ) { if ( CHECK_CODEC ( sample_rate ) || CHECK_CODEC ( channels ) || CHECK_CODEC ( frame_size ) ) { http_log ( Codec sample_rate , channels , frame_size do not match for stream %d\n , stream ) ; matches = 0 ; } } else { http_log ( Unknown codec type for stream %d\n , stream ) ; matches = 0 ; } return matches ; }",0
"static int encode_init ( AVCodecContext * avctx ) { WMACodecContext * s = avctx - > priv_data ; int i , flags1 , flags2 ; uint8_t * extradata ; s - > avctx = avctx ; if ( avctx - > channels > MAX_CHANNELS ) { av_log ( avctx , AV_LOG_ERROR , too many channels : got %i , need %i or fewer , avctx - > channels , MAX_CHANNELS ) ; return AVERROR ( EINVAL ) ; } if ( avctx - > sample_rate > 48000 ) { av_log ( avctx , AV_LOG_ERROR , sample rate is too high : %d > 48kHz , avctx - > sample_rate ) ; return AVERROR ( EINVAL ) ; } if ( avctx - > bit_rate < 24 * 1000 ) { av_log ( avctx , AV_LOG_ERROR , bitrate too low : got %i , need 24000 or higher\n , avctx - > bit_rate ) ; return AVERROR ( EINVAL ) ; } / * extract flag infos * / flags1 = 0 ; flags2 = 1 ; if ( avctx - > codec - > id == CODEC_ID_WMAV1 ) { extradata= av_malloc ( 4 ) ; avctx - > extradata_size= 4 ; AV_WL16 ( extradata , flags1 ) ; AV_WL16 ( extradata + 2 , flags2 ) ; } else if ( avctx - > codec - > id == CODEC_ID_WMAV2 ) { extradata= av_mallocz ( 10 ) ; avctx - > extradata_size= 10 ; AV_WL32 ( extradata , flags1 ) ; AV_WL16 ( extradata + 4 , flags2 ) ; } else av_assert0 ( 0 ) ; avctx - > extradata= extradata ; s - > use_exp_vlc = flags2 & 0x0001 ; s - > use_bit_reservoir = flags2 & 0x0002 ; s - > use_variable_block_len = flags2 & 0x0004 ; if ( avctx - > channels == 2 ) s - > ms_stereo = 1 ; ff_wma_init ( avctx , flags2 ) ; / * init MDCT * / for ( i = 0 ; i < s - > nb_block_sizes ; i + + ) ff_mdct_init ( & s - > mdct_ctx[i] , s - > frame_len_bits - i + 1 , 0 , 1 . 0 ) ; s - > block_align = avctx - > bit_rate * ( int64_t ) s - > frame_len / ( avctx - > sample_rate * 8 ) ; s - > block_align = FFMIN ( s - > block_align , MAX_CODED_SUPERFRAME_SIZE ) ; avctx - > block_align = s - > block_align ; avctx - > bit_rate = avctx - > block_align * 8LL * avctx - > sample_rate / s - > frame_len ; //av_log ( NULL , AV_LOG_ERROR , %d %d %d %d\n , s - > block_align , avctx - > bit_rate , s - > frame_len , avctx - > sample_rate ) ; avctx - > frame_size = avctx - > delay = s - > frame_len ; if FF_API_OLD_ENCODE_AUDIO avctx - > coded_frame = & s - > frame ; avcodec_get_frame_defaults ( avctx - > coded_frame ) ; endif return 0 ; }",0
AVFilter * * av_filter_next ( AVFilter * * filter ) { return filter ? + + filter : & registered_avfilters[0] ; },0
"static void get_tag ( AVFormatContext * s , const char * key , int type , int len , int type2_size ) { char * value ; int64_t off = avio_tell ( s - > pb ) ; if ( ( unsigned ) len > = ( UINT_MAX - 1 ) / 2 ) return ; value = av_malloc ( 2 * len + 1 ) ; if ( ! value ) goto finish ; if ( type == 0 ) { // UTF16 - LE avio_get_str16le ( s - > pb , len , value , 2 * len + 1 ) ; } else if ( type == - 1 ) { // ASCII avio_read ( s - > pb , value , len ) ; value[len]=0 ; } else if ( type == 1 ) { // byte array if ( ! strcmp ( key , WM/Picture ) ) { // handle cover art asf_read_picture ( s , len ) ; } else if ( ! strcmp ( key , ID3 ) ) { // handle ID3 tag get_id3_tag ( s , len ) ; } else { av_log ( s , AV_LOG_VERBOSE , Unsupported byte array in tag %s . \n , key ) ; } goto finish ; } else if ( type > 1 & & type < = 5 ) { // boolean or DWORD or QWORD or WORD uint64_t num = get_value ( s - > pb , type , type2_size ) ; snprintf ( value , len , % PRIu64 , num ) ; } else if ( type == 6 ) { // ( don ' t ) handle GUID av_log ( s , AV_LOG_DEBUG , Unsupported GUID value in tag %s . \n , key ) ; goto finish ; } else { av_log ( s , AV_LOG_DEBUG , Unsupported value type %d in tag %s . \n , type , key ) ; goto finish ; } if ( * value ) av_dict_set ( & s - > metadata , key , value , 0 ) ; finish : av_freep ( & value ) ; avio_seek ( s - > pb , off + len , SEEK_SET ) ; }",1
"av_cold int ff_yuv2rgb_c_init_tables ( SwsContext * c , const int inv_table[4] , int fullRange , int brightness , int contrast , int saturation ) { const int isRgb = c - > dstFormat==PIX_FMT_RGB32 || c - > dstFormat==PIX_FMT_RGB32_1 || c - > dstFormat==PIX_FMT_BGR24 || c - > dstFormat==PIX_FMT_RGB565BE || c - > dstFormat==PIX_FMT_RGB565LE || c - > dstFormat==PIX_FMT_RGB555BE || c - > dstFormat==PIX_FMT_RGB555LE || c - > dstFormat==PIX_FMT_RGB444BE || c - > dstFormat==PIX_FMT_RGB444LE || c - > dstFormat==PIX_FMT_RGB8 || c - > dstFormat==PIX_FMT_RGB4 || c - > dstFormat==PIX_FMT_RGB4_BYTE || c - > dstFormat==PIX_FMT_MONOBLACK ; const int isNotNe = c - > dstFormat==PIX_FMT_NE ( RGB565LE , RGB565BE ) || c - > dstFormat==PIX_FMT_NE ( RGB555LE , RGB555BE ) || c - > dstFormat==PIX_FMT_NE ( RGB444LE , RGB444BE ) || c - > dstFormat==PIX_FMT_NE ( BGR565LE , BGR565BE ) || c - > dstFormat==PIX_FMT_NE ( BGR555LE , BGR555BE ) || c - > dstFormat==PIX_FMT_NE ( BGR444LE , BGR444BE ) ; const int bpp = c - > dstFormatBpp ; uint8_t * y_table ; uint16_t * y_table16 ; uint32_t * y_table32 ; int i , base , rbase , gbase , bbase , abase , needAlpha ; const int yoffs = fullRange ? 384 : 326 ; int64_t crv = inv_table[0] ; int64_t cbu = inv_table[1] ; int64_t cgu = - inv_table[2] ; int64_t cgv = - inv_table[3] ; int64_t cy = 1 < < 16 ; int64_t oy = 0 ; int64_t yb = 0 ; if ( ! fullRange ) { cy = ( cy * 255 ) / 219 ; oy = 16 < < 16 ; } else { crv = ( crv * 224 ) / 255 ; cbu = ( cbu * 224 ) / 255 ; cgu = ( cgu * 224 ) / 255 ; cgv = ( cgv * 224 ) / 255 ; } cy = ( cy * contrast ) > > 16 ; crv = ( crv * contrast * saturation ) > > 32 ; cbu = ( cbu * contrast * saturation ) > > 32 ; cgu = ( cgu * contrast * saturation ) > > 32 ; cgv = ( cgv * contrast * saturation ) > > 32 ; oy - = 256 * brightness ; c - > uOffset= 0x0400040004000400LL ; c - > vOffset= 0x0400040004000400LL ; c - > yCoeff= roundToInt16 ( cy * 8192 ) * 0x0001000100010001ULL ; c - > vrCoeff= roundToInt16 ( crv * 8192 ) * 0x0001000100010001ULL ; c - > ubCoeff= roundToInt16 ( cbu * 8192 ) * 0x0001000100010001ULL ; c - > vgCoeff= roundToInt16 ( cgv * 8192 ) * 0x0001000100010001ULL ; c - > ugCoeff= roundToInt16 ( cgu * 8192 ) * 0x0001000100010001ULL ; c - > yOffset= roundToInt16 ( oy * 8 ) * 0x0001000100010001ULL ; c - > yuv2rgb_y_coeff = ( int16_t ) roundToInt16 ( cy < < 13 ) ; c - > yuv2rgb_y_offset = ( int16_t ) roundToInt16 ( oy < < 9 ) ; c - > yuv2rgb_v2r_coeff= ( int16_t ) roundToInt16 ( crv < < 13 ) ; c - > yuv2rgb_v2g_coeff= ( int16_t ) roundToInt16 ( cgv < < 13 ) ; c - > yuv2rgb_u2g_coeff= ( int16_t ) roundToInt16 ( cgu < < 13 ) ; c - > yuv2rgb_u2b_coeff= ( int16_t ) roundToInt16 ( cbu < < 13 ) ; //scale coefficients by cy crv = ( ( crv < < 16 ) + 0x8000 ) / cy ; cbu = ( ( cbu < < 16 ) + 0x8000 ) / cy ; cgu = ( ( cgu < < 16 ) + 0x8000 ) / cy ; cgv = ( ( cgv < < 16 ) + 0x8000 ) / cy ; av_free ( c - > yuvTable ) ; switch ( bpp ) { case 1 : c - > yuvTable = av_malloc ( 1024 ) ; y_table = c - > yuvTable ; yb = - ( 384 < < 16 ) - oy ; for ( i = 0 ; i < 1024 - 110 ; i + + ) { y_table[i + 110] = av_clip_uint8 ( ( yb + 0x8000 ) > > 16 ) > > 7 ; yb + = cy ; } fill_table ( c - > table_gU , 1 , cgu , y_table + yoffs ) ; fill_gv_table ( c - > table_gV , 1 , cgv ) ; break ; case 4 : case 4|128 : rbase = isRgb ? 3 : 0 ; gbase = 1 ; bbase = isRgb ? 0 : 3 ; c - > yuvTable = av_malloc ( 1024 * 3 ) ; y_table = c - > yuvTable ; yb = - ( 384 < < 16 ) - oy ; for ( i = 0 ; i < 1024 - 110 ; i + + ) { int yval = av_clip_uint8 ( ( yb + 0x8000 ) > > 16 ) ; y_table[i + 110 ] = ( yval > > 7 ) < < rbase ; y_table[i + 37 + 1024] = ( ( yval + 43 ) / 85 ) < < gbase ; y_table[i + 110 + 2048] = ( yval > > 7 ) < < bbase ; yb + = cy ; } fill_table ( c - > table_rV , 1 , crv , y_table + yoffs ) ; fill_table ( c - > table_gU , 1 , cgu , y_table + yoffs + 1024 ) ; fill_table ( c - > table_bU , 1 , cbu , y_table + yoffs + 2048 ) ; fill_gv_table ( c - > table_gV , 1 , cgv ) ; break ; case 8 : rbase = isRgb ? 5 : 0 ; gbase = isRgb ? 2 : 3 ; bbase = isRgb ? 0 : 6 ; c - > yuvTable = av_malloc ( 1024 * 3 ) ; y_table = c - > yuvTable ; yb = - ( 384 < < 16 ) - oy ; for ( i = 0 ; i < 1024 - 38 ; i + + ) { int yval = av_clip_uint8 ( ( yb + 0x8000 ) > > 16 ) ; y_table[i + 16 ] = ( ( yval + 18 ) / 36 ) < < rbase ; y_table[i + 16 + 1024] = ( ( yval + 18 ) / 36 ) < < gbase ; y_table[i + 37 + 2048] = ( ( yval + 43 ) / 85 ) < < bbase ; yb + = cy ; } fill_table ( c - > table_rV , 1 , crv , y_table + yoffs ) ; fill_table ( c - > table_gU , 1 , cgu , y_table + yoffs + 1024 ) ; fill_table ( c - > table_bU , 1 , cbu , y_table + yoffs + 2048 ) ; fill_gv_table ( c - > table_gV , 1 , cgv ) ; break ; case 12 : rbase = isRgb ? 8 : 0 ; gbase = 4 ; bbase = isRgb ? 0 : 8 ; c - > yuvTable",1
"static int config_input_ref ( AVFilterLink * inlink ) { const AVPixFmtDescriptor * desc = av_pix_fmt_desc_get ( inlink - > format ) ; AVFilterContext * ctx = inlink - > dst ; PSNRContext * s = ctx - > priv ; unsigned sum ; int j ; s - > nb_components = desc - > nb_components ; if ( ctx - > inputs[0] - > w ! = ctx - > inputs[1] - > w || ctx - > inputs[0] - > h ! = ctx - > inputs[1] - > h ) { av_log ( ctx , AV_LOG_ERROR , Width and height of input videos must be same . \n ) ; return AVERROR ( EINVAL ) ; } if ( ctx - > inputs[0] - > format ! = ctx - > inputs[1] - > format ) { av_log ( ctx , AV_LOG_ERROR , Inputs must be of same pixel format . \n ) ; return AVERROR ( EINVAL ) ; } s - > max[0] = ( 1 < < ( desc - > comp[0] . depth_minus1 + 1 ) ) - 1 ; s - > max[1] = ( 1 < < ( desc - > comp[1] . depth_minus1 + 1 ) ) - 1 ; s - > max[2] = ( 1 < < ( desc - > comp[2] . depth_minus1 + 1 ) ) - 1 ; s - > max[3] = ( 1 < < ( desc - > comp[3] . depth_minus1 + 1 ) ) - 1 ; s - > is_rgb = ff_fill_rgba_map ( s - > rgba_map , inlink - > format ) > = 0 ; s - > comps[0] = s - > is_rgb ? ' r ' : ' y ' ; s - > comps[1] = s - > is_rgb ? ' g ' : ' u ' ; s - > comps[2] = s - > is_rgb ? ' b ' : ' v ' ; s - > comps[3] = ' a ' ; s - > planeheight[1] = s - > planeheight[2] = FF_CEIL_RSHIFT ( inlink - > h , desc - > log2_chroma_h ) ; s - > planeheight[0] = s - > planeheight[3] = inlink - > h ; s - > planewidth[1] = s - > planewidth[2] = FF_CEIL_RSHIFT ( inlink - > w , desc - > log2_chroma_w ) ; s - > planewidth[0] = s - > planewidth[3] = inlink - > w ; sum = 0 ; for ( j = 0 ; j < s - > nb_components ; j + + ) sum + = s - > planeheight[j] * s - > planewidth[j] ; for ( j = 0 ; j < s - > nb_components ; j + + ) { s - > planeweight[j] = ( double ) s - > planeheight[j] * s - > planewidth[j] / sum ; s - > average_max + = s - > max[j] * s - > planeweight[j] ; } s - > compute_mse = desc - > comp[0] . depth_minus1 > 7 ? compute_images_mse_16bit : compute_images_mse ; return 0 ; }",1
"int dv_produce_packet ( DVDemuxContext * c , AVPacket * pkt , uint8_t * buf , int buf_size ) { int size , i ; uint8_t * ppcm[4] = { 0 } ; if ( buf_size < DV_PROFILE_BYTES || ! ( c - > sys = dv_frame_profile ( buf ) ) || buf_size < c - > sys - > frame_size ) { return - 1 ; / * Broken frame , or not enough data * / } / * Queueing audio packet * / / * FIXME : in case of no audio/bad audio we have to do something * / size = dv_extract_audio_info ( c , buf ) ; for ( i = 0 ; i < c - > ach ; i + + ) { c - > audio_pkt[i] . size = size ; c - > audio_pkt[i] . pts = c - > abytes * 30000 * 8 / c - > ast[i] - > codec - > bit_rate ; ppcm[i] = c - > audio_buf[i] ; } dv_extract_audio ( buf , ppcm , c - > sys ) ; c - > abytes + = size ; / * We work with 720p frames split in half , thus even frames have * channels 0 , 1 and odd 2 , 3 . * / if ( c - > sys - > height == 720 ) { if ( buf[1] & 0x0C ) c - > audio_pkt[2] . size = c - > audio_pkt[3] . size = 0 ; else c - > audio_pkt[0] . size = c - > audio_pkt[1] . size = 0 ; } / * Now it ' s time to return video packet * / size = dv_extract_video_info ( c , buf ) ; av_init_packet ( pkt ) ; pkt - > data = buf ; pkt - > size = size ; pkt - > flags |= PKT_FLAG_KEY ; pkt - > stream_index = c - > vst - > id ; pkt - > pts = c - > frames ; c - > frames + + ; return size ; }",1
"int ff_rtmp_packet_create ( RTMPPacket * pkt , int channel_id , RTMPPacketType type , int timestamp , int size ) { pkt - > data = av_malloc ( size ) ; if ( ! pkt - > data ) return AVERROR ( ENOMEM ) ; pkt - > data_size = size ; pkt - > channel_id = channel_id ; pkt - > type = type ; pkt - > timestamp = timestamp ; pkt - > extra = 0 ; pkt - > ts_delta = 0 ; return 0 ;",1
"static int ac3_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; AC3DecodeContext * s = avctx - > priv_data ; int16_t * out_samples = ( int16_t * ) data ; int blk , ch , err ; const uint8_t * channel_map ; const float * output[AC3_MAX_CHANNELS] ; / * initialize the GetBitContext with the start of valid AC - 3 Frame * / if ( s - > input_buffer ) { / * copy input buffer to decoder context to avoid reading past the end of the buffer , which can be caused by a damaged input stream . * / memcpy ( s - > input_buffer , buf , FFMIN ( buf_size , AC3_FRAME_BUFFER_SIZE ) ) ; init_get_bits ( & s - > gbc , s - > input_buffer , buf_size * 8 ) ; } else { init_get_bits ( & s - > gbc , buf , buf_size * 8 ) ; } / * parse the syncinfo * / * data_size = 0 ; err = parse_frame_header ( s ) ; / * check that reported frame size fits in input buffer * / if ( s - > frame_size > buf_size ) { av_log ( avctx , AV_LOG_ERROR , incomplete frame\n ) ; err = AAC_AC3_PARSE_ERROR_FRAME_SIZE ; } / * check for crc mismatch * / if ( err ! = AAC_AC3_PARSE_ERROR_FRAME_SIZE & & avctx - > error_recognition > = FF_ER_CAREFUL ) { if ( av_crc ( av_crc_get_table ( AV_CRC_16_ANSI ) , 0 , & buf[2] , s - > frame_size - 2 ) ) { av_log ( avctx , AV_LOG_ERROR , frame CRC mismatch\n ) ; err = AAC_AC3_PARSE_ERROR_CRC ; } } if ( err & & err ! = AAC_AC3_PARSE_ERROR_CRC ) { switch ( err ) { case AAC_AC3_PARSE_ERROR_SYNC : av_log ( avctx , AV_LOG_ERROR , frame sync error\n ) ; return - 1 ; case AAC_AC3_PARSE_ERROR_BSID : av_log ( avctx , AV_LOG_ERROR , invalid bitstream id\n ) ; break ; case AAC_AC3_PARSE_ERROR_SAMPLE_RATE : av_log ( avctx , AV_LOG_ERROR , invalid sample rate\n ) ; break ; case AAC_AC3_PARSE_ERROR_FRAME_SIZE : av_log ( avctx , AV_LOG_ERROR , invalid frame size\n ) ; break ; case AAC_AC3_PARSE_ERROR_FRAME_TYPE : / * skip frame if CRC is ok . otherwise use error concealment . * / / * TODO : add support for substreams and dependent frames * / if ( s - > frame_type == EAC3_FRAME_TYPE_DEPENDENT || s - > substreamid ) { av_log ( avctx , AV_LOG_ERROR , unsupported frame type : skipping frame\n ) ; return s - > frame_size ; } else { av_log ( avctx , AV_LOG_ERROR , invalid frame type\n ) ; } break ; default : av_log ( avctx , AV_LOG_ERROR , invalid header\n ) ; break ; } } / * if frame is ok , set audio parameters * / if ( ! err ) { avctx - > sample_rate = s - > sample_rate ; avctx - > bit_rate = s - > bit_rate ; / * channel config * / s - > out_channels = s - > channels ; s - > output_mode = s - > channel_mode ; if ( s - > lfe_on ) s - > output_mode |= AC3_OUTPUT_LFEON ; if ( avctx - > request_channels > 0 & & avctx - > request_channels < = 2 & & avctx - > request_channels < s - > channels ) { s - > out_channels = avctx - > request_channels ; s - > output_mode = avctx - > request_channels == 1 ? AC3_CHMODE_MONO : AC3_CHMODE_STEREO ; s - > channel_layout = ff_ac3_channel_layout_tab[s - > output_mode] ; } avctx - > channels = s - > out_channels ; avctx - > channel_layout = s - > channel_layout ; / * set downmixing coefficients if needed * / if ( s - > channels ! = s - > out_channels & & ! ( ( s - > output_mode & AC3_OUTPUT_LFEON ) & & s - > fbw_channels == s - > out_channels ) ) { set_downmix_coeffs ( s ) ; } } else if ( ! s - > out_channels ) { s - > out_channels = avctx - > channels ; if ( s - > out_channels < s - > channels ) s - > output_mode = s - > out_channels == 1 ? AC3_CHMODE_MONO : AC3_CHMODE_STEREO ; } / * decode the audio blocks * / channel_map = ff_ac3_dec_channel_map[s - > output_mode & AC3_OUTPUT_LFEON][s - > lfe_on] ; for ( ch = 0 ; ch < s - > out_channels ; ch + + ) output[ch] = s - > output[channel_map[ch]] ; for ( blk = 0 ; blk < s - > num_blocks ; blk + + ) { if ( ! err & & decode_audio_block ( s , blk ) ) { av_log ( avctx , AV_LOG_ERROR , error decoding the audio block\n ) ; err = 1 ; } s - > dsp . float_to_int16_interleave ( out_samples , output , 256 , s - > out_channels ) ; out_samples + = 256 * s - > out_channels ; } * data_size = s - > num_blocks * 256 * avctx - > channels * sizeof ( int16_t ) ; return s - > frame_size ; }",0
"static inline void RENAME ( yuv2yuvX_ar ) ( SwsContext * c , const int16_t * lumFilter , const int16_t * * lumSrc , int lumFilterSize , const int16_t * chrFilter , const int16_t * * chrUSrc , const int16_t * * chrVSrc , int chrFilterSize , const int16_t * * alpSrc , uint8_t * dest , uint8_t * uDest , uint8_t * vDest , uint8_t * aDest , long dstW , long chrDstW ) { if ( uDest ) { YSCALEYUV2YV12X_ACCURATE ( CHR_MMX_FILTER_OFFSET , uDest , chrDstW , 0 ) YSCALEYUV2YV12X_ACCURATE ( CHR_MMX_FILTER_OFFSET , vDest , chrDstW + c - > uv_off , c - > uv_off ) } if ( CONFIG_SWSCALE_ALPHA & & aDest ) { YSCALEYUV2YV12X_ACCURATE ( ALP_MMX_FILTER_OFFSET , aDest , dstW , 0 ) } YSCALEYUV2YV12X_ACCURATE ( LUM_MMX_FILTER_OFFSET , dest , dstW , 0 ) }",1
"static void FUNCC ( pred8x8l_vertical ) ( uint8_t * _src , int has_topleft , int has_topright , int _stride ) { int y ; pixel * src = ( pixel * ) _src ; int stride = _stride/sizeof ( pixel ) ; PREDICT_8x8_LOAD_TOP ; src[0] = t0 ; src[1] = t1 ; src[2] = t2 ; src[3] = t3 ; src[4] = t4 ; src[5] = t5 ; src[6] = t6 ; src[7] = t7 ; for ( y = 1 ; y < 8 ; y + + ) { ( ( pixel4 * ) ( src + y * stride ) ) [0] = ( ( pixel4 * ) src ) [0] ; ( ( pixel4 * ) ( src + y * stride ) ) [1] = ( ( pixel4 * ) src ) [1] ; } }",1
"static int check_intra_pred_mode ( int mode , int mb_x , int mb_y ) { if ( mode == DC_PRED8x8 ) { if ( ! ( mb_x|mb_y ) ) mode = DC_128_PRED8x8 ; else if ( ! mb_y ) mode = LEFT_DC_PRED8x8 ; else if ( ! mb_x ) mode = TOP_DC_PRED8x8 ; } return mode ; }",0
"static int http_open_cnx ( URLContext * h ) { const char * path , * proxy_path , * lower_proto = tcp , * local_path ; char hostname[1024] , hoststr[1024] , proto[10] ; char auth[1024] , proxyauth[1024] ; char path1[1024] ; char buf[1024] , urlbuf[1024] ; int port , use_proxy , err , location_changed = 0 , redirects = 0 ; HTTPAuthType cur_auth_type , cur_proxy_auth_type ; HTTPContext * s = h - > priv_data ; URLContext * hd = NULL ; proxy_path = getenv ( http_proxy ) ; use_proxy = ( proxy_path ! = NULL ) & & ! getenv ( no_proxy ) & & av_strstart ( proxy_path , http : // , NULL ) ; / * fill the dest addr * / redo : / * needed in any case to build the host string * / av_url_split ( proto , sizeof ( proto ) , auth , sizeof ( auth ) , hostname , sizeof ( hostname ) , & port , path1 , sizeof ( path1 ) , s - > location ) ; ff_url_join ( hoststr , sizeof ( hoststr ) , NULL , NULL , hostname , port , NULL ) ; if ( ! strcmp ( proto , https ) ) { lower_proto = tls ; use_proxy = 0 ; if ( port < 0 ) port = 443 ; } if ( port < 0 ) port = 80 ; if ( path1[0] == ' \0 ' ) path = / ; else path = path1 ; local_path = path ; if ( use_proxy ) { / * Reassemble the request URL without auth string - we don ' t * want to leak the auth to the proxy . * / ff_url_join ( urlbuf , sizeof ( urlbuf ) , proto , NULL , hostname , port , %s , path1 ) ; path = urlbuf ; av_url_split ( NULL , 0 , proxyauth , sizeof ( proxyauth ) , hostname , sizeof ( hostname ) , & port , NULL , 0 , proxy_path ) ; } ff_url_join ( buf , sizeof ( buf ) , lower_proto , NULL , hostname , port , NULL ) ; err = ffurl_open ( & hd , buf , AVIO_FLAG_READ_WRITE , & h - > interrupt_callback , NULL ) ; if ( err < 0 ) goto fail ; s - > hd = hd ; cur_auth_type = s - > auth_state . auth_type ; cur_proxy_auth_type = s - > auth_state . auth_type ; if ( http_connect ( h , path , local_path , hoststr , auth , proxyauth , & location_changed ) < 0 ) goto fail ; if ( s - > http_code == 401 ) { if ( cur_auth_type == HTTP_AUTH_NONE & & s - > auth_state . auth_type ! = HTTP_AUTH_NONE ) { ffurl_close ( hd ) ; goto redo ; } else goto fail ; } if ( s - > http_code == 407 ) { if ( cur_proxy_auth_type == HTTP_AUTH_NONE & & s - > proxy_auth_state . auth_type ! = HTTP_AUTH_NONE ) { ffurl_close ( hd ) ; goto redo ; } else goto fail ; } if ( ( s - > http_code == 301 || s - > http_code == 302 || s - > http_code == 303 || s - > http_code == 307 ) & & location_changed == 1 ) { / * url moved , get next * / ffurl_close ( hd ) ; if ( redirects + + > = MAX_REDIRECTS ) return AVERROR ( EIO ) ; location_changed = 0 ; goto redo ; } return 0 ; fail : if ( hd ) ffurl_close ( hd ) ; s - > hd = NULL ; return AVERROR ( EIO ) ; }",1
"static void vmdaudio_loadsound ( VmdAudioContext * s , unsigned char * data , uint8_t * buf , int silence ) { if ( s - > channels == 2 ) { if ( ( s - > block_align & 0x01 ) == 0 ) { if ( silence ) memset ( data , 0 , s - > block_align * 2 ) ; else vmdaudio_decode_audio ( s , data , buf , 1 ) ; } else { if ( silence ) memset ( data , 0 , s - > block_align * 2 ) ; // else // vmdaudio_decode_audio ( s , data , buf , 1 ) ; } } else { } }",1
"static int xwd_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { AVFrame * p = data ; const uint8_t * buf = avpkt - > data ; int i , ret , buf_size = avpkt - > size ; uint32_t version , header_size , vclass , ncolors ; uint32_t xoffset , be , bpp , lsize , rsize ; uint32_t pixformat , pixdepth , bunit , bitorder , bpad ; uint32_t rgb[3] ; uint8_t * ptr ; GetByteContext gb ; if ( buf_size < XWD_HEADER_SIZE ) return AVERROR_INVALIDDATA ; bytestream2_init ( & gb , buf , buf_size ) ; header_size = bytestream2_get_be32u ( & gb ) ; version = bytestream2_get_be32u ( & gb ) ; if ( version ! = XWD_VERSION ) { av_log ( avctx , AV_LOG_ERROR , unsupported version\n ) ; return AVERROR_INVALIDDATA ; } if ( buf_size < header_size || header_size < XWD_HEADER_SIZE ) { av_log ( avctx , AV_LOG_ERROR , invalid header size\n ) ; return AVERROR_INVALIDDATA ; } pixformat = bytestream2_get_be32u ( & gb ) ; pixdepth = bytestream2_get_be32u ( & gb ) ; avctx - > width = bytestream2_get_be32u ( & gb ) ; avctx - > height = bytestream2_get_be32u ( & gb ) ; xoffset = bytestream2_get_be32u ( & gb ) ; be = bytestream2_get_be32u ( & gb ) ; bunit = bytestream2_get_be32u ( & gb ) ; bitorder = bytestream2_get_be32u ( & gb ) ; bpad = bytestream2_get_be32u ( & gb ) ; bpp = bytestream2_get_be32u ( & gb ) ; lsize = bytestream2_get_be32u ( & gb ) ; vclass = bytestream2_get_be32u ( & gb ) ; rgb[0] = bytestream2_get_be32u ( & gb ) ; rgb[1] = bytestream2_get_be32u ( & gb ) ; rgb[2] = bytestream2_get_be32u ( & gb ) ; bytestream2_skipu ( & gb , 8 ) ; ncolors = bytestream2_get_be32u ( & gb ) ; bytestream2_skipu ( & gb , header_size - ( XWD_HEADER_SIZE - 20 ) ) ; av_log ( avctx , AV_LOG_DEBUG , pixformat % PRIu32 , pixdepth % PRIu32 , bunit % PRIu32 , bitorder % PRIu32 , bpad % PRIu32 \n , pixformat , pixdepth , bunit , bitorder , bpad ) ; av_log ( avctx , AV_LOG_DEBUG , vclass % PRIu32 , ncolors % PRIu32 , bpp % PRIu32 , be % PRIu32 , lsize % PRIu32 , xoffset % PRIu32 \n , vclass , ncolors , bpp , be , lsize , xoffset ) ; av_log ( avctx , AV_LOG_DEBUG , red %0 PRIx32 , green %0 PRIx32 , blue %0 PRIx32 \n , rgb[0] , rgb[1] , rgb[2] ) ; if ( pixformat > XWD_Z_PIXMAP ) { av_log ( avctx , AV_LOG_ERROR , invalid pixmap format\n ) ; return AVERROR_INVALIDDATA ; } if ( pixdepth == 0 || pixdepth > 32 ) { av_log ( avctx , AV_LOG_ERROR , invalid pixmap depth\n ) ; return AVERROR_INVALIDDATA ; } if ( xoffset ) { avpriv_request_sample ( avctx , xoffset % PRIu32 , xoffset ) ; return AVERROR_PATCHWELCOME ; } if ( be > 1 ) { av_log ( avctx , AV_LOG_ERROR , invalid byte order\n ) ; return AVERROR_INVALIDDATA ; } if ( bitorder > 1 ) { av_log ( avctx , AV_LOG_ERROR , invalid bitmap bit order\n ) ; return AVERROR_INVALIDDATA ; } if ( bunit ! = 8 & & bunit ! = 16 & & bunit ! = 32 ) { av_log ( avctx , AV_LOG_ERROR , invalid bitmap unit\n ) ; return AVERROR_INVALIDDATA ; } if ( bpad ! = 8 & & bpad ! = 16 & & bpad ! = 32 ) { av_log ( avctx , AV_LOG_ERROR , invalid bitmap scan - line pad\n ) ; return AVERROR_INVALIDDATA ; } if ( bpp == 0 || bpp > 32 ) { av_log ( avctx , AV_LOG_ERROR , invalid bits per pixel\n ) ; return AVERROR_INVALIDDATA ; } if ( ncolors > 256 ) { av_log ( avctx , AV_LOG_ERROR , invalid number of entries in colormap\n ) ; return AVERROR_INVALIDDATA ; } if ( ( ret = av_image_check_size ( avctx - > width , avctx - > height , 0 , NULL ) ) < 0 ) return ret ; rsize = FFALIGN ( avctx - > width * bpp , bpad ) / 8 ; if ( lsize < rsize ) { av_log ( avctx , AV_LOG_ERROR , invalid bytes per scan - line\n ) ; return AVERROR_INVALIDDATA ; } if ( bytestream2_get_bytes_left ( & gb ) < ncolors * XWD_CMAP_SIZE + ( uint64_t ) avctx - > height * lsize ) { av_log ( avctx , AV_LOG_ERROR , input buffer too small\n ) ; return AVERROR_INVALIDDATA ; } if ( pixformat ! = XWD_Z_PIXMAP ) { avpriv_report_missing_feature ( avctx , Pixmap format % PRIu32 , pixformat ) ; return AVERROR_PATCHWELCOME ; } avctx - > pix_fmt = AV_PIX_FMT_NONE ; switch ( vclass ) { case XWD_STATIC_GRAY : case XWD_GRAY_SCALE : if ( bpp ! = 1 & & bpp ! = 8 ) return AVERROR_INVALIDDATA ; if ( pixdepth == 1 ) { avctx - > pix_fmt = AV_PIX_FMT_MONOWHITE ; } else if ( pixdepth == 8 ) { avctx - > pix_fmt = AV_PIX_FMT_GRAY8 ; } break ; case XWD_STATIC_COLOR : case XWD_PSEUDO_COLOR : if ( bpp == 8 ) avctx - > pix_fmt = AV_PIX_FMT_PAL8 ; break ; case XWD_TRUE_COLOR : case XWD_DIRECT_COLOR : if ( bpp ! = 16 & & bpp ! = 24 & & bpp ! = 32 ) return AVERROR_INVALIDDATA ; if ( bpp == 16 & & pixdepth == 15 ) { if ( rgb[0] == 0x7C00 & & rgb[1] == 0x3E0 & & rgb[2] == 0x1F ) avctx - > pix_fmt = be ? AV_PIX_FMT_RGB555BE : AV_PIX_FMT_RGB555LE ; else if ( rgb[0] == 0x1F & & rgb[1] == 0x3E0 & & rgb[2] == 0x7C00 ) avctx - > pix_fmt = be ? AV_PIX_FMT_BGR555BE : AV_PIX_FMT_BGR555LE ; } else if ( bpp == 16 & & pixdepth == 16 ) { if ( rgb[0] == 0xF800 & & rgb[1] == 0x7E0 & & rgb[2] == 0x1F ) avctx - > pix_fmt = be ? AV_PIX_FMT_RGB565BE : AV_PIX_FMT_RGB565LE ; else if ( rgb[0] == 0x1F & & rgb[1] == 0x7E0 & & rgb[2] == 0xF800 ) avctx - > pix_fmt = be ? AV_PIX_FMT_BGR565BE : AV_PIX_FMT_BGR565LE ; } else if ( bpp == 24 ) { if ( rgb[0] == 0xFF0000 & & rgb[1] == 0xFF00 & & rgb[2] == 0xFF ) avctx - > pix_fmt = be ? AV_PIX_FMT_RGB24 : AV_PIX_FMT_BGR24 ; else if ( rgb[0] == 0xFF & & rgb[1] == 0xFF00 & & rgb[2] == 0xFF0000 ) avctx - > pix_fmt = be ? AV_PIX_FMT_BGR24 : AV_PIX_FMT_RGB24 ; } else if ( bpp == 32 ) { if ( rgb[0] == 0xFF0000 & & rgb[1] == 0xFF00 & & rgb[2] == 0xFF ) avctx - > pix_fmt = be ? AV_PIX_FMT_ARGB : AV_PIX_FMT_BGRA ; else if ( rgb[0] == 0xFF & & rgb[1] == 0xFF00 & & rgb[2] == 0xFF0000 ) avctx - > pix_fmt = be ? AV_PIX_FMT_ABGR : AV_PIX_FMT_RGBA ; } bytestream2_skipu ( & gb , ncolors * XWD_CMAP_SIZE ) ; break ;",1
"static int decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { PicContext * s = avctx - > priv_data ; AVFrame * frame = data ; uint32_t * palette ; int bits_per_plane , bpp , etype , esize , npal , pos_after_pal ; int i , x , y , plane , tmp , ret , val ; bytestream2_init ( & s - > g , avpkt - > data , avpkt - > size ) ; if ( bytestream2_get_bytes_left ( & s - > g ) < 11 ) return AVERROR_INVALIDDATA ; if ( bytestream2_get_le16u ( & s - > g ) ! = 0x1234 ) return AVERROR_INVALIDDATA ; s - > width = bytestream2_get_le16u ( & s - > g ) ; s - > height = bytestream2_get_le16u ( & s - > g ) ; bytestream2_skip ( & s - > g , 4 ) ; tmp = bytestream2_get_byteu ( & s - > g ) ; bits_per_plane = tmp & 0xF ; s - > nb_planes = ( tmp > > 4 ) + 1 ; bpp = bits_per_plane * s - > nb_planes ; if ( bits_per_plane > 8 || bpp < 1 || bpp > 32 ) { avpriv_request_sample ( avctx , Unsupported bit depth ) ; return AVERROR_PATCHWELCOME ; } if ( bytestream2_peek_byte ( & s - > g ) == 0xFF || bpp == 1 || bpp == 4 || bpp == 8 ) { bytestream2_skip ( & s - > g , 2 ) ; etype = bytestream2_get_le16 ( & s - > g ) ; esize = bytestream2_get_le16 ( & s - > g ) ; if ( bytestream2_get_bytes_left ( & s - > g ) < esize ) return AVERROR_INVALIDDATA ; } else { etype = - 1 ; esize = 0 ; } avctx - > pix_fmt = AV_PIX_FMT_PAL8 ; if ( s - > width ! = avctx - > width & & s - > height ! = avctx - > height ) { if ( av_image_check_size ( s - > width , s - > height , 0 , avctx ) < 0 ) return - 1 ; avcodec_set_dimensions ( avctx , s - > width , s - > height ) ; } if ( ( ret = ff_get_buffer ( avctx , frame , 0 ) ) < 0 ) return ret ; memset ( frame - > data[0] , 0 , s - > height * frame - > linesize[0] ) ; frame - > pict_type = AV_PICTURE_TYPE_I ; frame - > palette_has_changed = 1 ; pos_after_pal = bytestream2_tell ( & s - > g ) + esize ; palette = ( uint32_t * ) frame - > data[1] ; if ( etype == 1 & & esize > 1 & & bytestream2_peek_byte ( & s - > g ) < 6 ) { int idx = bytestream2_get_byte ( & s - > g ) ; npal = 4 ; for ( i = 0 ; i < npal ; i + + ) palette[i] = ff_cga_palette[ cga_mode45_index[idx][i] ] ; } else if ( etype == 2 ) { npal = FFMIN ( esize , 16 ) ; for ( i = 0 ; i < npal ; i + + ) { int pal_idx = bytestream2_get_byte ( & s - > g ) ; palette[i] = ff_cga_palette[FFMIN ( pal_idx , 15 ) ] ; } } else if ( etype == 3 ) { npal = FFMIN ( esize , 16 ) ; for ( i = 0 ; i < npal ; i + + ) { int pal_idx = bytestream2_get_byte ( & s - > g ) ; palette[i] = ff_ega_palette[FFMIN ( pal_idx , 63 ) ] ; } } else if ( etype == 4 || etype == 5 ) { npal = FFMIN ( esize / 3 , 256 ) ; for ( i = 0 ; i < npal ; i + + ) { palette[i] = bytestream2_get_be24 ( & s - > g ) < < 2 ; palette[i] |= 0xFFU < < 24 | palette[i] > > 6 & 0x30303 ; } } else { if ( bpp == 1 ) { npal = 2 ; palette[0] = 0xFF000000 ; palette[1] = 0xFFFFFFFF ; } else if ( bpp == 2 ) { npal = 4 ; for ( i = 0 ; i < npal ; i + + ) palette[i] = ff_cga_palette[ cga_mode45_index[0][i] ] ; } else { npal = 16 ; memcpy ( palette , ff_cga_palette , npal * 4 ) ; } } // fill remaining palette entries memset ( palette + npal , 0 , AVPALETTE_SIZE - npal * 4 ) ; // skip remaining palette bytes bytestream2_seek ( & s - > g , pos_after_pal , SEEK_SET ) ; val = 0 ; y = s - > height - 1 ; if ( bytestream2_get_le16 ( & s - > g ) ) { x = 0 ; plane = 0 ; while ( y > = 0 & & bytestream2_get_bytes_left ( & s - > g ) > = 6 ) { int stop_size , marker , t1 , t2 ; t1 = bytestream2_get_bytes_left ( & s - > g ) ; t2 = bytestream2_get_le16 ( & s - > g ) ; stop_size = t1 - FFMIN ( t1 , t2 ) ; // ignore uncompressed block size bytestream2_skip ( & s - > g , 2 ) ; marker = bytestream2_get_byte ( & s - > g ) ; while ( plane < s - > nb_planes & & y > = 0 & & bytestream2_get_bytes_left ( & s - > g ) > stop_size ) { int run = 1 ; val = bytestream2_get_byte ( & s - > g ) ; if ( val == marker ) { run = bytestream2_get_byte ( & s - > g ) ; if ( run == 0 ) run = bytestream2_get_le16 ( & s - > g ) ; val = bytestream2_get_byte ( & s - > g ) ; } if ( ! bytestream2_get_bytes_left ( & s - > g ) ) break ; if ( bits_per_plane == 8 ) { picmemset_8bpp ( s , frame , val , run , & x , & y ) ; if ( y < 0 ) goto finish ; } else { picmemset ( s , frame , val , run , & x , & y , & plane , bits_per_plane ) ; } } } if ( x < avctx - > width & & y > = 0 ) { int run = ( y + 1 ) * avctx - > width - x ; if ( bits_per_plane == 8 ) picmemset_8bpp ( s , frame , val , run , & x , & y ) ; else picmemset ( s , frame , val , run / ( 8 / bits_per_plane ) , & x , & y , & plane , bits_per_plane ) ; } } else { while ( y",1
"static int voc_probe ( AVProbeData * p ) { int version , check ; if ( p - > buf_size < 26 ) return 0 ; if ( memcmp ( p - > buf , voc_magic , sizeof ( voc_magic ) - 1 ) ) return 0 ; version = p - > buf[22] | ( p - > buf[23] < < 8 ) ; check = p - > buf[24] | ( p - > buf[25] < < 8 ) ; if ( version + 0x1234 ! = check ) return 10 ; return AVPROBE_SCORE_MAX ; }",0
"static int filter_frame ( AVFilterLink * inlink , AVFilterBufferRef * cur_buf ) { AlphaExtractContext * extract = inlink - > dst - > priv ; AVFilterLink * outlink = inlink - > dst - > outputs[0] ; AVFilterBufferRef * out_buf = ff_get_video_buffer ( outlink , AV_PERM_WRITE , outlink - > w , outlink - > h ) ; int ret ; if ( ! out_buf ) { ret = AVERROR ( ENOMEM ) ; goto end ; } avfilter_copy_buffer_ref_props ( out_buf , cur_buf ) ; if ( extract - > is_packed_rgb ) { int x , y ; uint8_t * pin , * pout ; for ( y = 0 ; y < out_buf - > video - > h ; y + + ) { pin = cur_buf - > data[0] + y * cur_buf - > linesize[0] + extract - > rgba_map[A] ; pout = out_buf - > data[0] + y * out_buf - > linesize[0] ; for ( x = 0 ; x < out_buf - > video - > w ; x + + ) { * pout = * pin ; pout + = 1 ; pin + = 4 ; } } } else { const int linesize = FFMIN ( out_buf - > linesize[Y] , cur_buf - > linesize[A] ) ; int y ; for ( y = 0 ; y < out_buf - > video - > h ; y + + ) { memcpy ( out_buf - > data[Y] + y * out_buf - > linesize[Y] , cur_buf - > data[A] + y * cur_buf - > linesize[A] , linesize ) ; } } ret = ff_filter_frame ( outlink , out_buf ) ; end : avfilter_unref_buffer ( cur_buf ) ; return ret ; }",1
static av_cold int alac_decode_init ( AVCodecContext * avctx ) { ALACContext * alac = avctx - > priv_data ; alac - > avctx = avctx ; alac - > context_initialized = 0 ; alac - > numchannels = alac - > avctx - > channels ; return 0 ; },1
"static int cinepak_decode_vectors ( CinepakContext * s , cvid_strip * strip , int chunk_id , int size , const uint8_t * data ) { const uint8_t * eod = ( data + size ) ; uint32_t flag , mask ; uint8_t * cb0 , * cb1 , * cb2 , * cb3 ; unsigned int x , y ; char * ip0 , * ip1 , * ip2 , * ip3 ; flag = 0 ; mask = 0 ; for ( y=strip - > y1 ; y < strip - > y2 ; y + =4 ) { / * take care of y dimension not being multiple of 4 , such streams exist * / ip0 = ip1 = ip2 = ip3 = s - > frame - > data[0] + ( s - > palette_video ? strip - > x1 : strip - > x1 * 3 ) + ( y * s - > frame - > linesize[0] ) ; if ( s - > avctx - > height - y > 1 ) { ip1 = ip0 + s - > frame - > linesize[0] ; if ( s - > avctx - > height - y > 2 ) { ip2 = ip1 + s - > frame - > linesize[0] ; if ( s - > avctx - > height - y > 3 ) { ip3 = ip2 + s - > frame - > linesize[0] ; } } } / * to get the correct picture for not - multiple - of - 4 cases let us fill * each block from the bottom up , thus possibly overwriting the top line * more than once but ending with the correct data in place * ( instead of in - loop checking ) * / for ( x=strip - > x1 ; x < strip - > x2 ; x + =4 ) { if ( ( chunk_id & 0x01 ) & & ! ( mask > > = 1 ) ) { if ( ( data + 4 ) > eod ) return AVERROR_INVALIDDATA ; flag = AV_RB32 ( data ) ; data + = 4 ; mask = 0x80000000 ; } if ( ! ( chunk_id & 0x01 ) || ( flag & mask ) ) { if ( ! ( chunk_id & 0x02 ) & & ! ( mask > > = 1 ) ) { if ( ( data + 4 ) > eod ) return AVERROR_INVALIDDATA ; flag = AV_RB32 ( data ) ; data + = 4 ; mask = 0x80000000 ; } if ( ( chunk_id & 0x02 ) || ( flag & mask ) ) { uint8_t * p ; if ( data > = eod ) return AVERROR_INVALIDDATA ; p = strip - > v1_codebook[ * data + + ] ; if ( s - > palette_video ) { ip3[0] = ip3[1] = ip2[0] = ip2[1] = p[6] ; ip3[2] = ip3[3] = ip2[2] = ip2[3] = p[9] ; ip1[0] = ip1[1] = ip0[0] = ip0[1] = p[0] ; ip1[2] = ip1[3] = ip0[2] = ip0[3] = p[3] ; } else { p + = 6 ; memcpy ( ip3 + 0 , p , 3 ) ; memcpy ( ip3 + 3 , p , 3 ) ; memcpy ( ip2 + 0 , p , 3 ) ; memcpy ( ip2 + 3 , p , 3 ) ; p + = 3 ; / * . . . + 9 * / memcpy ( ip3 + 6 , p , 3 ) ; memcpy ( ip3 + 9 , p , 3 ) ; memcpy ( ip2 + 6 , p , 3 ) ; memcpy ( ip2 + 9 , p , 3 ) ; p - = 9 ; / * . . . + 0 * / memcpy ( ip1 + 0 , p , 3 ) ; memcpy ( ip1 + 3 , p , 3 ) ; memcpy ( ip0 + 0 , p , 3 ) ; memcpy ( ip0 + 3 , p , 3 ) ; p + = 3 ; / * . . . + 3 * / memcpy ( ip1 + 6 , p , 3 ) ; memcpy ( ip1 + 9 , p , 3 ) ; memcpy ( ip0 + 6 , p , 3 ) ; memcpy ( ip0 + 9 , p , 3 ) ; } } else if ( flag & mask ) { if ( ( data + 4 ) > eod ) return AVERROR_INVALIDDATA ; cb0 = strip - > v4_codebook[ * data + + ] ; cb1 = strip - > v4_codebook[ * data + + ] ; cb2 = strip - > v4_codebook[ * data + + ] ; cb3 = strip - > v4_codebook[ * data + + ] ; if ( s - > palette_video ) { uint8_t * p ; p = ip3 ; * p + + = cb2[6] ; * p + + = cb2[9] ; * p + + = cb3[6] ; * p = cb3[9] ; p = ip2 ; * p + + = cb2[0] ; * p + + = cb2[3] ; * p + + = cb3[0] ; * p = cb3[3] ; p = ip1 ; * p + + = cb0[6] ; * p + + = cb0[9] ; * p + + = cb1[6] ; * p = cb1[9] ; p = ip0 ; * p + + = cb0[0] ; * p + + = cb0[3] ; * p + + = cb1[0] ; * p = cb1[3] ; } else { memcpy ( ip3 + 0 , cb2 + 6 , 6 ) ; memcpy ( ip3 + 6 , cb3 + 6 , 6 ) ; memcpy ( ip2 + 0 , cb2 + 0 , 6 ) ; memcpy ( ip2 + 6 , cb3 + 0 , 6 ) ; memcpy ( ip1 + 0 , cb0 + 6 , 6 ) ; memcpy ( ip1 + 6 , cb1 + 6 , 6 ) ; memcpy ( ip0 + 0 , cb0 + 0 , 6 ) ; memcpy ( ip0 + 6 , cb1 + 0 , 6 ) ; } } } if ( s - > palette_video ) { ip0 + = 4 ; ip1 + = 4 ; ip2 + = 4 ; ip3 + = 4 ; } else { ip0 + = 12 ; ip1 + = 12 ; ip2 + = 12 ; ip3 + = 12 ; } } } return 0 ; }",1
"AVRational av_d2q ( double d , int max ) { AVRational a ; define LOG2 0 . 69314718055994530941723212145817656807550013436025 int exponent ; int64_t den ; if ( isnan ( d ) ) return ( AVRational ) { 0 , 0 } ; if ( isinf ( d ) ) return ( AVRational ) { d < 0 ? - 1 : 1 , 0 } ; exponent = FFMAX ( ( int ) ( log ( fabs ( d ) + 1e - 20 ) /LOG2 ) , 0 ) ; den = 1LL < < ( 61 - exponent ) ; av_reduce ( & a . num , & a . den , ( int64_t ) ( d * den + 0 . 5 ) , den , max ) ; return a ; }",1
"static void selfTest ( uint8_t * src[3] , int stride[3] , int w , int h ) { enum PixelFormat srcFormat , dstFormat ; int srcW , srcH , dstW , dstH ; int flags ; for ( srcFormat = 0 ; srcFormat < PIX_FMT_NB ; srcFormat + + ) { for ( dstFormat = 0 ; dstFormat < PIX_FMT_NB ; dstFormat + + ) { printf ( %s - > %s\n , sws_format_name ( srcFormat ) , sws_format_name ( dstFormat ) ) ; srcW= w ; srcH= h ; for ( dstW=w - w/3 ; dstW < = 4 * w/3 ; dstW + = w/3 ) { for ( dstH=h - h/3 ; dstH < = 4 * h/3 ; dstH + = h/3 ) { for ( flags=1 ; flags < 33 ; flags * =2 ) { int res ; res = doTest ( src , stride , w , h , srcFormat , dstFormat , srcW , srcH , dstW , dstH , flags ) ; if ( res < 0 ) { dstW = 4 * w / 3 ; dstH = 4 * h / 3 ; flags = 33 ; } } } } } } }",1
"static int dct_max8x8_c ( MpegEncContext * s , uint8_t * src1 , uint8_t * src2 , ptrdiff_t stride , int h ) { LOCAL_ALIGNED_16 ( int16_t , temp , [64] ) ; int sum = 0 , i ; av_assert2 ( h == 8 ) ; s - > pdsp . diff_pixels ( temp , src1 , src2 , stride ) ; s - > fdsp . fdct ( temp ) ; for ( i = 0 ; i < 64 ; i + + ) sum = FFMAX ( sum , FFABS ( temp[i] ) ) ; return sum ; }",1
"static void intra_predict_mad_cow_dc_l00_8x8_msa ( uint8_t * src , int32_t stride ) { uint8_t lp_cnt ; uint32_t src0 = 0 ; uint64_t out0 , out1 ; for ( lp_cnt = 0 ; lp_cnt < 4 ; lp_cnt + + ) { src0 + = src[lp_cnt * stride - 1] ; } src0 = ( src0 + 2 ) > > 2 ; out0 = src0 * 0x0101010101010101 ; out1 = 0x8080808080808080 ; for ( lp_cnt = 4 ; lp_cnt - - ; ) { SD ( out0 , src ) ; SD ( out1 , src + stride * 4 ) ; src + = stride ; } }",0
"static void term_exit ( void ) { ifndef __MINGW32__ tcsetattr ( 0 , TCSANOW , & oldtty ) ; endif }",0
"static void copy_parameter_set ( void * * to , void * * from , int count , int size ) { int i ; for ( i = 0 ; i < count ; i + + ) { if ( to[i] & & ! from[i] ) av_freep ( & to[i] ) ; else if ( from[i] & & ! to[i] ) to[i] = av_malloc ( size ) ; if ( from[i] ) memcpy ( to[i] , from[i] , size ) ; } }",0
av_cold void swri_resample_dsp_x86_init ( ResampleContext * c ) { int av_unused mm_flags = av_get_cpu_flags ( ) ; switch ( c - > format ) { case AV_SAMPLE_FMT_S16P : if ( ARCH_X86_32 & & EXTERNAL_MMXEXT ( mm_flags ) ) { c - > dsp . resample = c - > linear ? ff_resample_linear_int16_mmxext : ff_resample_common_int16_mmxext ; } if ( EXTERNAL_SSE2 ( mm_flags ) ) { c - > dsp . resample = c - > linear ? ff_resample_linear_int16_sse2 : ff_resample_common_int16_sse2 ; } if ( EXTERNAL_XOP ( mm_flags ) ) { c - > dsp . resample = c - > linear ? ff_resample_linear_int16_xop : ff_resample_common_int16_xop ; } break ; case AV_SAMPLE_FMT_FLTP : if ( EXTERNAL_SSE ( mm_flags ) ) { c - > dsp . resample = c - > linear ? ff_resample_linear_float_sse : ff_resample_common_float_sse ; } if ( EXTERNAL_AVX ( mm_flags ) ) { c - > dsp . resample = c - > linear ? ff_resample_linear_float_avx : ff_resample_common_float_avx ; } if ( EXTERNAL_FMA3 ( mm_flags ) ) { c - > dsp . resample = c - > linear ? ff_resample_linear_float_fma3 : ff_resample_common_float_fma3 ; } if ( EXTERNAL_FMA4 ( mm_flags ) ) { c - > dsp . resample = c - > linear ? ff_resample_linear_float_fma4 : ff_resample_common_float_fma4 ; } break ; case AV_SAMPLE_FMT_DBLP : if ( EXTERNAL_SSE2 ( mm_flags ) ) { c - > dsp . resample = c - > linear ? ff_resample_linear_double_sse2 : ff_resample_common_double_sse2 ; } break ; } },0
"alloc_parameter_set ( H264Context * h , void * * vec , const unsigned int id , const unsigned int max , const size_t size , const char * name ) { if ( id > =max ) { av_log ( h - > s . avctx , AV_LOG_ERROR , %s_id ( %d ) out of range\n , name , id ) ; return NULL ; } if ( ! vec[id] ) { vec[id] = av_mallocz ( size ) ; if ( vec[id] == NULL ) av_log ( h - > s . avctx , AV_LOG_ERROR , cannot allocate memory for %s\n , name ) ; } return vec[id] ; }",0
"static int filter_frame ( AVFilterLink * inlink , AVFrame * ref ) { FrameStepContext * framestep = inlink - > dst - > priv ; if ( ! ( framestep - > frame_count + + % framestep - > frame_step ) ) { framestep - > frame_selected = 1 ; return ff_filter_frame ( inlink - > dst - > outputs[0] , ref ) ; } else { framestep - > frame_selected = 0 ; av_frame_free ( & ref ) ; return 0 ; } }",0
"void ff_aac_search_for_is ( AACEncContext * s , AVCodecContext * avctx , ChannelElement * cpe ) { SingleChannelElement * sce0 = & cpe - > ch[0] ; SingleChannelElement * sce1 = & cpe - > ch[1] ; int start = 0 , count = 0 , w , w2 , g , i , prev_sf1 = - 1 ; const float freq_mult = avctx - > sample_rate/ ( 1024 . 0f/sce0 - > ics . num_windows ) /2 . 0f ; uint8_t nextband1[128] ; if ( ! cpe - > common_window ) return ; / * * Scout out next nonzero bands * / ff_init_nextband_map ( sce1 , nextband1 ) ; for ( w = 0 ; w < sce0 - > ics . num_windows ; w + = sce0 - > ics . group_len[w] ) { start = 0 ; for ( g = 0 ; g < sce0 - > ics . num_swb ; g + + ) { if ( start * freq_mult > INT_STEREO_LOW_LIMIT * ( s - > lambda/170 . 0f ) & & cpe - > ch[0] . band_type[w * 16 + g] ! = NOISE_BT & & ! cpe - > ch[0] . zeroes[w * 16 + g] & & cpe - > ch[1] . band_type[w * 16 + g] ! = NOISE_BT & & ! cpe - > ch[1] . zeroes[w * 16 + g] & & ff_sfdelta_can_remove_band ( sce1 , nextband1 , prev_sf1 , w * 16 + g ) ) { float ener0 = 0 . 0f , ener1 = 0 . 0f , ener01 = 0 . 0f , ener01p = 0 . 0f ; struct AACISError ph_err1 , ph_err2 , * best ; if ( sce0 - > band_type[w * 16 + g] == NOISE_BT || sce1 - > band_type[w * 16 + g] == NOISE_BT ) { start + = sce0 - > ics . swb_sizes[g] ; continue ; } for ( w2 = 0 ; w2 < sce0 - > ics . group_len[w] ; w2 + + ) { for ( i = 0 ; i < sce0 - > ics . swb_sizes[g] ; i + + ) { float coef0 = fabsf ( sce0 - > coeffs[start + ( w + w2 ) * 128 + i] ) ; float coef1 = fabsf ( sce1 - > coeffs[start + ( w + w2 ) * 128 + i] ) ; ener0 + = coef0 * coef0 ; ener1 + = coef1 * coef1 ; ener01 + = ( coef0 + coef1 ) * ( coef0 + coef1 ) ; ener01p + = ( coef0 - coef1 ) * ( coef0 - coef1 ) ; } } ph_err1 = ff_aac_is_encoding_err ( s , cpe , start , w , g , ener0 , ener1 , ener01p , 0 , - 1 ) ; ph_err2 = ff_aac_is_encoding_err ( s , cpe , start , w , g , ener0 , ener1 , ener01 , 0 , + 1 ) ; best = ( ph_err1 . pass & & ph_err1 . error < ph_err2 . error ) ? & ph_err1 : & ph_err2 ; if ( best - > pass ) { cpe - > is_mask[w * 16 + g] = 1 ; cpe - > ms_mask[w * 16 + g] = 0 ; cpe - > ch[0] . is_ener[w * 16 + g] = sqrt ( ener0 / best - > ener01 ) ; cpe - > ch[1] . is_ener[w * 16 + g] = ener0/ener1 ; cpe - > ch[1] . band_type[w * 16 + g] = ( best - > phase > 0 ) ? INTENSITY_BT : INTENSITY_BT2 ; count + + ; } } if ( ! sce1 - > zeroes[w * 16 + g] & & sce1 - > band_type[w * 16 + g] < RESERVED_BT ) prev_sf1 = sce1 - > sf_idx[w * 16 + g] ; start + = sce0 - > ics . swb_sizes[g] ; } } cpe - > is_mode = ! ! count ; }",0
"int ff_aac_ac3_parse ( AVCodecParserContext * s1 , AVCodecContext * avctx , const uint8_t * * poutbuf , int * poutbuf_size , const uint8_t * buf , int buf_size ) { AACAC3ParseContext * s = s1 - > priv_data ; const uint8_t * buf_ptr ; int len , sample_rate , bit_rate , channels , samples ; * poutbuf = NULL ; * poutbuf_size = 0 ; buf_ptr = buf ; while ( buf_size > 0 ) { int size_needed= s - > frame_size ? s - > frame_size : s - > header_size ; len = s - > inbuf_ptr - s - > inbuf ; if ( len < size_needed ) { len = FFMIN ( size_needed - len , buf_size ) ; memcpy ( s - > inbuf_ptr , buf_ptr , len ) ; buf_ptr + = len ; s - > inbuf_ptr + = len ; buf_size - = len ; } if ( s - > frame_size == 0 ) { if ( ( s - > inbuf_ptr - s - > inbuf ) == s - > header_size ) { len = s - > sync ( s - > inbuf , & channels , & sample_rate , & bit_rate , & samples ) ; if ( len == 0 ) { / * no sync found : move by one byte ( inefficient , but simple ! ) * / memmove ( s - > inbuf , s - > inbuf + 1 , s - > header_size - 1 ) ; s - > inbuf_ptr - - ; } else { s - > frame_size = len ; / * update codec info * / avctx - > sample_rate = sample_rate ; avctx - > channels = channels ; / * allow downmixing to mono or stereo for AC3 * / if ( avctx - > request_channels > 0 & & avctx - > request_channels < channels & & avctx - > request_channels < = 2 & & avctx - > codec_id == CODEC_ID_AC3 ) { avctx - > channels = avctx - > request_channels ; } avctx - > bit_rate = bit_rate ; avctx - > frame_size = samples ; } } } else { if ( s - > inbuf_ptr - s - > inbuf == s - > frame_size ) { * poutbuf = s - > inbuf ; * poutbuf_size = s - > frame_size ; s - > inbuf_ptr = s - > inbuf ; s - > frame_size = 0 ; break ; } } } return buf_ptr - buf ; }",0
"static int mpegts_read_header ( AVFormatContext * s , AVFormatParameters * ap ) { MpegTSContext * ts = s - > priv_data ; AVIOContext * pb = s - > pb ; uint8_t buf[5 * 1024] ; int len ; int64_t pos ; if FF_API_FORMAT_PARAMETERS if ( ap ) { if ( ap - > mpeg2ts_compute_pcr ) ts - > mpeg2ts_compute_pcr = ap - > mpeg2ts_compute_pcr ; if ( ap - > mpeg2ts_raw ) { av_log ( s , AV_LOG_ERROR , use mpegtsraw_demuxer ! \n ) ; return - 1 ; } } endif / * read the first 1024 bytes to get packet size * / pos = avio_tell ( pb ) ; len = avio_read ( pb , buf , sizeof ( buf ) ) ; if ( len ! = sizeof ( buf ) ) goto fail ; ts - > raw_packet_size = get_packet_size ( buf , sizeof ( buf ) ) ; if ( ts - > raw_packet_size < = 0 ) goto fail ; ts - > stream = s ; ts - > auto_guess = 0 ; if ( s - > iformat == & ff_mpegts_demuxer ) { / * normal demux * / / * first do a scaning to get all the services * / if ( avio_seek ( pb , pos , SEEK_SET ) < 0 ) av_log ( s , AV_LOG_ERROR , Unable to seek back to the start\n ) ; mpegts_open_section_filter ( ts , SDT_PID , sdt_cb , ts , 1 ) ; mpegts_open_section_filter ( ts , PAT_PID , pat_cb , ts , 1 ) ; handle_packets ( ts , s - > probesize / ts - > raw_packet_size ) ; / * if could not find service , enable auto_guess * / ts - > auto_guess = 1 ; av_dlog ( ts - > stream , tuning done\n ) ; s - > ctx_flags |= AVFMTCTX_NOHEADER ; } else { AVStream * st ; int pcr_pid , pid , nb_packets , nb_pcrs , ret , pcr_l ; int64_t pcrs[2] , pcr_h ; int packet_count[2] ; uint8_t packet[TS_PACKET_SIZE] ; / * only read packets * / st = av_new_stream ( s , 0 ) ; if ( ! st ) goto fail ; av_set_pts_info ( st , 60 , 1 , 27000000 ) ; st - > codec - > codec_type = AVMEDIA_TYPE_DATA ; st - > codec - > codec_id = CODEC_ID_MPEG2TS ; / * we iterate until we find two PCRs to estimate the bitrate * / pcr_pid = - 1 ; nb_pcrs = 0 ; nb_packets = 0 ; for ( ; ; ) { ret = read_packet ( s , packet , ts - > raw_packet_size ) ; if ( ret < 0 ) return - 1 ; pid = AV_RB16 ( packet + 1 ) & 0x1fff ; if ( ( pcr_pid == - 1 || pcr_pid == pid ) & & parse_pcr ( & pcr_h , & pcr_l , packet ) == 0 ) { pcr_pid = pid ; packet_count[nb_pcrs] = nb_packets ; pcrs[nb_pcrs] = pcr_h * 300 + pcr_l ; nb_pcrs + + ; if ( nb_pcrs > = 2 ) break ; } nb_packets + + ; } / * NOTE1 : the bitrate is computed without the FEC * / / * NOTE2 : it is only the bitrate of the start of the stream * / ts - > pcr_incr = ( pcrs[1] - pcrs[0] ) / ( packet_count[1] - packet_count[0] ) ; ts - > cur_pcr = pcrs[0] - ts - > pcr_incr * packet_count[0] ; s - > bit_rate = ( TS_PACKET_SIZE * 8 ) * 27e6 / ts - > pcr_incr ; st - > codec - > bit_rate = s - > bit_rate ; st - > start_time = ts - > cur_pcr ; av_dlog ( ts - > stream , start=%0 . 3f pcr=%0 . 3f incr=%d\n , st - > start_time / 1000000 . 0 , pcrs[0] / 27e6 , ts - > pcr_incr ) ; } avio_seek ( pb , pos , SEEK_SET ) ; return 0 ; fail : return - 1 ; }",0
"static int end_frame ( AVFilterLink * inlink ) { AVFilterContext * ctx = inlink - > dst ; FPSContext * s = ctx - > priv ; AVFilterLink * outlink = ctx - > outputs[0] ; AVFilterBufferRef * buf = inlink - > cur_buf ; int64_t delta ; int i , ret ; inlink - > cur_buf = NULL ; s - > frames_in + + ; / * discard frames until we get the first timestamp * / if ( s - > pts == AV_NOPTS_VALUE ) { if ( buf - > pts ! = AV_NOPTS_VALUE ) { write_to_fifo ( s - > fifo , buf ) ; s - > first_pts = s - > pts = buf - > pts ; } else { av_log ( ctx , AV_LOG_WARNING , Discarding initial frame ( s ) with no timestamp . \n ) ; avfilter_unref_buffer ( buf ) ; s - > drop + + ; } return 0 ; } / * now wait for the next timestamp * / if ( buf - > pts == AV_NOPTS_VALUE ) { return write_to_fifo ( s - > fifo , buf ) ; } / * number of output frames * / delta = av_rescale_q ( buf - > pts - s - > pts , inlink - > time_base , outlink - > time_base ) ; if ( delta < 1 ) { / * drop the frame and everything buffered except the first * / AVFilterBufferRef * tmp ; int drop = av_fifo_size ( s - > fifo ) /sizeof ( AVFilterBufferRef * ) ; av_log ( ctx , AV_LOG_DEBUG , Dropping %d frame ( s ) . \n , drop ) ; s - > drop + = drop ; av_fifo_generic_read ( s - > fifo , & tmp , sizeof ( tmp ) , NULL ) ; flush_fifo ( s - > fifo ) ; ret = write_to_fifo ( s - > fifo , tmp ) ; avfilter_unref_buffer ( buf ) ; return ret ; } / * can output > = 1 frames * / for ( i = 0 ; i < delta ; i + + ) { AVFilterBufferRef * buf_out ; av_fifo_generic_read ( s - > fifo , & buf_out , sizeof ( buf_out ) , NULL ) ; / * duplicate the frame if needed * / if ( ! av_fifo_size ( s - > fifo ) & & i < delta - 1 ) { av_log ( ctx , AV_LOG_DEBUG , Duplicating frame . \n ) ; write_to_fifo ( s - > fifo , avfilter_ref_buffer ( buf_out , AV_PERM_READ ) ) ; s - > dup + + ; } buf_out - > pts = av_rescale_q ( s - > first_pts , inlink - > time_base , outlink - > time_base ) + s - > frames_out ; if ( ( ret = ff_start_frame ( outlink , buf_out ) ) < 0 || ( ret = ff_draw_slice ( outlink , 0 , outlink - > h , 1 ) ) < 0 || ( ret = ff_end_frame ( outlink ) ) < 0 ) { avfilter_unref_bufferp ( & buf ) ; return ret ; } s - > frames_out + + ; } flush_fifo ( s - > fifo ) ; ret = write_to_fifo ( s - > fifo , buf ) ; s - > pts = s - > first_pts + av_rescale_q ( s - > frames_out , outlink - > time_base , inlink - > time_base ) ; return ret ; }",0
"static int roq_read_packet ( AVFormatContext * s , AVPacket * pkt ) { RoqDemuxContext * roq = s - > priv_data ; AVIOContext * pb = s - > pb ; int ret = 0 ; unsigned int chunk_size ; unsigned int chunk_type ; unsigned int codebook_size ; unsigned char preamble[RoQ_CHUNK_PREAMBLE_SIZE] ; int packet_read = 0 ; int64_t codebook_offset ; while ( ! packet_read ) { if ( avio_feof ( s - > pb ) ) return AVERROR ( EIO ) ; / * get the next chunk preamble * / if ( ( ret = avio_read ( pb , preamble , RoQ_CHUNK_PREAMBLE_SIZE ) ) ! = RoQ_CHUNK_PREAMBLE_SIZE ) return AVERROR ( EIO ) ; chunk_type = AV_RL16 ( & preamble[0] ) ; chunk_size = AV_RL32 ( & preamble[2] ) ; if ( chunk_size > INT_MAX ) return AVERROR_INVALIDDATA ; chunk_size = ffio_limit ( pb , chunk_size ) ; switch ( chunk_type ) { case RoQ_INFO : if ( roq - > video_stream_index == - 1 ) { AVStream * st = avformat_new_stream ( s , NULL ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; avpriv_set_pts_info ( st , 63 , 1 , roq - > frame_rate ) ; roq - > video_stream_index = st - > index ; st - > codecpar - > codec_type = AVMEDIA_TYPE_VIDEO ; st - > codecpar - > codec_id = AV_CODEC_ID_ROQ ; st - > codecpar - > codec_tag = 0 ; / * no fourcc * / if ( avio_read ( pb , preamble , RoQ_CHUNK_PREAMBLE_SIZE ) ! = RoQ_CHUNK_PREAMBLE_SIZE ) return AVERROR ( EIO ) ; st - > codecpar - > width = roq - > width = AV_RL16 ( preamble ) ; st - > codecpar - > height = roq - > height = AV_RL16 ( preamble + 2 ) ; break ; } / * don ' t care about this chunk anymore * / avio_skip ( pb , RoQ_CHUNK_PREAMBLE_SIZE ) ; break ; case RoQ_QUAD_CODEBOOK : if ( roq - > video_stream_index < 0 ) return AVERROR_INVALIDDATA ; / * packet needs to contain both this codebook and next VQ chunk * / codebook_offset = avio_tell ( pb ) - RoQ_CHUNK_PREAMBLE_SIZE ; codebook_size = chunk_size ; avio_skip ( pb , codebook_size ) ; if ( avio_read ( pb , preamble , RoQ_CHUNK_PREAMBLE_SIZE ) ! = RoQ_CHUNK_PREAMBLE_SIZE ) return AVERROR ( EIO ) ; chunk_size = AV_RL32 ( & preamble[2] ) + RoQ_CHUNK_PREAMBLE_SIZE * 2 + codebook_size ; if ( chunk_size > INT_MAX ) return AVERROR_INVALIDDATA ; / * rewind * / avio_seek ( pb , codebook_offset , SEEK_SET ) ; / * load up the packet * / ret= av_get_packet ( pb , pkt , chunk_size ) ; if ( ret ! = chunk_size ) return AVERROR ( EIO ) ; pkt - > stream_index = roq - > video_stream_index ; pkt - > pts = roq - > video_pts + + ; packet_read = 1 ; break ; case RoQ_SOUND_MONO : case RoQ_SOUND_STEREO : if ( roq - > audio_stream_index == - 1 ) { AVStream * st = avformat_new_stream ( s , NULL ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; avpriv_set_pts_info ( st , 32 , 1 , RoQ_AUDIO_SAMPLE_RATE ) ; roq - > audio_stream_index = st - > index ; st - > codecpar - > codec_type = AVMEDIA_TYPE_AUDIO ; st - > codecpar - > codec_id = AV_CODEC_ID_ROQ_DPCM ; st - > codecpar - > codec_tag = 0 ; / * no tag * / if ( chunk_type == RoQ_SOUND_STEREO ) { st - > codecpar - > channels = 2 ; st - > codecpar - > channel_layout = AV_CH_LAYOUT_STEREO ; } else { st - > codecpar - > channels = 1 ; st - > codecpar - > channel_layout = AV_CH_LAYOUT_MONO ; } roq - > audio_channels = st - > codecpar - > channels ; st - > codecpar - > sample_rate = RoQ_AUDIO_SAMPLE_RATE ; st - > codecpar - > bits_per_coded_sample = 16 ; st - > codecpar - > bit_rate = st - > codecpar - > channels * st - > codecpar - > sample_rate * st - > codecpar - > bits_per_coded_sample ; st - > codecpar - > block_align = st - > codecpar - > channels * st - > codecpar - > bits_per_coded_sample ; } case RoQ_QUAD_VQ : if ( chunk_type == RoQ_QUAD_VQ ) { if ( roq - > video_stream_index < 0 ) return AVERROR_INVALIDDATA ; } / * load up the packet * / if ( av_new_packet ( pkt , chunk_size + RoQ_CHUNK_PREAMBLE_SIZE ) ) return AVERROR ( EIO ) ; / * copy over preamble * / memcpy ( pkt - > data , preamble , RoQ_CHUNK_PREAMBLE_SIZE ) ; if ( chunk_type == RoQ_QUAD_VQ ) { pkt - > stream_index = roq - > video_stream_index ; pkt - > pts = roq - > video_pts + + ; } else { pkt - > stream_index = roq - > audio_stream_index ; pkt - > pts = roq - > audio_frame_count ; roq - > audio_frame_count + = ( chunk_size / roq - > audio_channels ) ; } pkt - > pos= avio_tell ( pb ) ; ret = avio_read ( pb , pkt - > data + RoQ_CHUNK_PREAMBLE_SIZE , chunk_size ) ; if ( ret ! = chunk_size ) ret = AVERROR ( EIO ) ; packet_read = 1 ; break ; default : av_log ( s , AV_LOG_ERROR , unknown RoQ chunk ( %04X ) \n , chunk_type ) ; return AVERROR_INVALIDDATA ; } } return ret ; }",1
"static inline void RENAME ( hScale ) ( int16_t * dst , int dstW , uint8_t * src , int srcW , int xInc , int16_t * filter , int16_t * filterPos , int filterSize ) { ifdef HAVE_MMX assert ( filterSize % 4 == 0 & & filterSize > 0 ) ; if ( filterSize==4 ) // allways true for upscaling , sometimes for down too { long counter= - 2 * dstW ; filter - = counter * 2 ; filterPos - = counter/2 ; dst - = counter/2 ; asm volatile ( pxor %%mm7 , %%mm7 \n\t movq MANGLE ( w02 ) , %%mm6 \n\t push %% REG_BP \n\t // we use 7 regs here . . . mov %% REG_a , %% REG_BP \n\t . balign 16 \n\t 1 : \n\t movzwl ( %2 , %% REG_BP ) , %%eax \n\t movzwl 2 ( %2 , %% REG_BP ) , %%ebx\n\t movq ( %1 , %% REG_BP , 4 ) , %%mm1\n\t movq 8 ( %1 , %% REG_BP , 4 ) , %%mm3\n\t movd ( %3 , %% REG_a ) , %%mm0 \n\t movd ( %3 , %% REG_b ) , %%mm2 \n\t punpcklbw %%mm7 , %%mm0 \n\t punpcklbw %%mm7 , %%mm2 \n\t pmaddwd %%mm1 , %%mm0 \n\t pmaddwd %%mm2 , %%mm3 \n\t psrad 8 , %%mm0 \n\t psrad 8 , %%mm3 \n\t packssdw %%mm3 , %%mm0 \n\t pmaddwd %%mm6 , %%mm0 \n\t packssdw %%mm0 , %%mm0 \n\t movd %%mm0 , ( %4 , %% REG_BP ) \n\t add 4 , %% REG_BP \n\t jnc 1b \n\t pop %% REG_BP \n\t : + a ( counter ) : c ( filter ) , d ( filterPos ) , S ( src ) , D ( dst ) : % REG_b ) ; } else if ( filterSize==8 ) { long counter= - 2 * dstW ; filter - = counter * 4 ; filterPos - = counter/2 ; dst - = counter/2 ; asm volatile ( pxor %%mm7 , %%mm7 \n\t movq MANGLE ( w02 ) , %%mm6 \n\t push %% REG_BP \n\t // we use 7 regs here . . . mov %% REG_a , %% REG_BP \n\t . balign 16 \n\t 1 : \n\t movzwl ( %2 , %% REG_BP ) , %%eax \n\t movzwl 2 ( %2 , %% REG_BP ) , %%ebx\n\t movq ( %1 , %% REG_BP , 8 ) , %%mm1\n\t movq 16 ( %1 , %% REG_BP , 8 ) , %%mm3\n\t movd ( %3 , %% REG_a ) , %%mm0 \n\t movd ( %3 , %% REG_b ) , %%mm2 \n\t punpcklbw %%mm7 , %%mm0 \n\t punpcklbw %%mm7 , %%mm2 \n\t pmaddwd %%mm1 , %%mm0 \n\t pmaddwd %%mm2 , %%mm3 \n\t movq 8 ( %1 , %% REG_BP , 8 ) , %%mm1\n\t movq 24 ( %1 , %% REG_BP , 8 ) , %%mm5\n\t movd 4 ( %3 , %% REG_a ) , %%mm4 \n\t movd 4 ( %3 , %% REG_b ) , %%mm2 \n\t punpcklbw %%mm7 , %%mm4 \n\t punpcklbw %%mm7 , %%mm2 \n\t pmaddwd %%mm1 , %%mm4 \n\t pmaddwd %%mm2 , %%mm5 \n\t paddd %%mm4 , %%mm0 \n\t paddd %%mm5 , %%mm3 \n\t psrad 8 , %%mm0 \n\t psrad 8 , %%mm3 \n\t packssdw %%mm3 , %%mm0 \n\t pmaddwd %%mm6 , %%mm0 \n\t packssdw %%mm0 , %%mm0 \n\t movd %%mm0 , ( %4 , %% REG_BP ) \n\t add 4 , %% REG_BP \n\t jnc 1b \n\t pop %% REG_BP \n\t : + a ( counter ) : c ( filter ) , d ( filterPos ) , S ( src ) , D ( dst ) : % REG_b ) ; } else { uint8_t * offset = src + filterSize ; long counter= - 2 * dstW ; // filter - = counter * filterSize/2 ; filterPos - = counter/2 ; dst - = counter/2 ; asm volatile ( pxor %%mm7 , %%mm7 \n\t movq MANGLE ( w02 ) , %%mm6 \n\t . balign 16 \n\t 1 : \n\t mov %2 , %% REG_c \n\t movzwl ( %% REG_c , %0 ) , %%eax \n\t movzwl 2 ( %% REG_c , %0 ) , %%ebx \n\t mov %5 , %% REG_c \n\t pxor %%mm4 , %%mm4 \n\t pxor %%mm5 , %%mm5 \n\t 2 : \n\t movq ( %1 ) , %%mm1 \n\t movq ( %1 , %6 ) , %%mm3 \n\t movd ( %% REG_c , %% REG_a ) , %%mm0\n\t movd ( %% REG_c , %% REG_b ) , %%mm2\n\t punpcklbw %%mm7 , %%mm0 \n\t punpcklbw %%mm7 , %%mm2 \n\t pmaddwd %%mm1 , %%mm0 \n\t pmaddwd %%mm2 , %%mm3 \n\t paddd %%mm3 , %%mm5 \n\t paddd %%mm0 , %%mm4 \n\t add 8 , %1 \n\t add 4 , %% REG_c \n\t cmp %4 , %% REG_c \n\t jb 2b \n\t add %6 , %1 \n\t psrad 8 , %%mm4 \n\t psrad 8 , %%mm5 \n\t packssdw %%mm5 , %%mm4 \n\t pmaddwd %%mm6 , %%mm4 \n\t packssdw %%mm4 , %%mm4 \n\t mov %3 , %% REG_a \n\t movd %%mm4 , ( %% REG_a , %0 ) \n\t add 4 , %0 \n\t jnc 1b \n\t : + r ( counter ) , + r ( filter ) : m ( filterPos ) , m ( dst ) , m ( offset ) , m ( src ) , r ( ( long ) filterSize * 2 ) : % REG_b , % REG_a , % REG_c ) ; } else ifdef HAVE_ALTIVEC hScale_altivec_real ( dst , dstW , src , srcW , xInc , filter , filterPos , filterSize ) ; else int i ; for ( i=0 ; i < dstW ; i + + ) { int j ; int srcPos= filterPos[i] ; int val=0 ; // printf ( filterPos : %d\n , filterPos[i] ) ; for ( j=0 ; j < filterSize ; j + + ) { // printf ( filter : %d , src : %d\n , filter[i] , src[srcPos + j] ) ; val + = ( ( int ) src[srcPos + j] ) * filter[filterSize * i + j] ; } // filter + = hFilterSize ; dst[i] = MIN ( MAX ( 0 , val > > 7 ) , ( 1 < < 15 ) - 1 ) ; // the cubic equation does overflow . . . // dst[i] = val > > 7 ; } endif endif }",1
"static int mov_read_dref ( MOVContext * c , AVIOContext * pb , MOVAtom atom ) { AVStream * st ; MOVStreamContext * sc ; int entries , i , j ; if ( c - > fc - > nb_streams < 1 ) return 0 ; st = c - > fc - > streams[c - > fc - > nb_streams - 1] ; sc = st - > priv_data ; avio_rb32 ( pb ) ; // version + flags entries = avio_rb32 ( pb ) ; if ( entries > ( atom . size - 1 ) / MIN_DATA_ENTRY_BOX_SIZE + 1 || entries > = UINT_MAX / sizeof ( * sc - > drefs ) ) return AVERROR_INVALIDDATA ; av_free ( sc - > drefs ) ; sc - > drefs_count = 0 ; sc - > drefs = av_mallocz ( entries * sizeof ( * sc - > drefs ) ) ; if ( ! sc - > drefs ) return AVERROR ( ENOMEM ) ; sc - > drefs_count = entries ; for ( i = 0 ; i < sc - > drefs_count ; i + + ) { MOVDref * dref = & sc - > drefs[i] ; uint32_t size = avio_rb32 ( pb ) ; int64_t next = avio_tell ( pb ) + size - 4 ; if ( size < 12 ) return AVERROR_INVALIDDATA ; dref - > type = avio_rl32 ( pb ) ; avio_rb32 ( pb ) ; // version + flags av_dlog ( c - > fc , type % . 4s size %d\n , ( char * ) & dref - > type , size ) ; if ( dref - > type == MKTAG ( ' a ' , ' l ' , ' i ' , ' s ' ) & & size > 150 ) { / * macintosh alias record * / uint16_t volume_len , len ; int16_t type ; avio_skip ( pb , 10 ) ; volume_len = avio_r8 ( pb ) ; volume_len = FFMIN ( volume_len , 27 ) ; avio_read ( pb , dref - > volume , 27 ) ; dref - > volume[volume_len] = 0 ; av_log ( c - > fc , AV_LOG_DEBUG , volume %s , len %d\n , dref - > volume , volume_len ) ; avio_skip ( pb , 12 ) ; len = avio_r8 ( pb ) ; len = FFMIN ( len , 63 ) ; avio_read ( pb , dref - > filename , 63 ) ; dref - > filename[len] = 0 ; av_log ( c - > fc , AV_LOG_DEBUG , filename %s , len %d\n , dref - > filename , len ) ; avio_skip ( pb , 16 ) ; / * read next level up_from_alias/down_to_target * / dref - > nlvl_from = avio_rb16 ( pb ) ; dref - > nlvl_to = avio_rb16 ( pb ) ; av_log ( c - > fc , AV_LOG_DEBUG , nlvl from %d , nlvl to %d\n , dref - > nlvl_from , dref - > nlvl_to ) ; avio_skip ( pb , 16 ) ; for ( type = 0 ; type ! = - 1 & & avio_tell ( pb ) < next ; ) { if ( url_feof ( pb ) ) return AVERROR_EOF ; type = avio_rb16 ( pb ) ; len = avio_rb16 ( pb ) ; av_log ( c - > fc , AV_LOG_DEBUG , type %d , len %d\n , type , len ) ; if ( len & 1 ) len + = 1 ; if ( type == 2 ) { // absolute path av_free ( dref - > path ) ; dref - > path = av_mallocz ( len + 1 ) ; if ( ! dref - > path ) return AVERROR ( ENOMEM ) ; avio_read ( pb , dref - > path , len ) ; if ( len > volume_len & & ! strncmp ( dref - > path , dref - > volume , volume_len ) ) { len - = volume_len ; memmove ( dref - > path , dref - > path + volume_len , len ) ; dref - > path[len] = 0 ; } for ( j = 0 ; j < len ; j + + ) if ( dref - > path[j] == ' : ' ) dref - > path[j] = ' / ' ; av_log ( c - > fc , AV_LOG_DEBUG , path %s\n , dref - > path ) ; } else if ( type == 0 ) { // directory name av_free ( dref - > dir ) ; dref - > dir = av_malloc ( len + 1 ) ; if ( ! dref - > dir ) return AVERROR ( ENOMEM ) ; avio_read ( pb , dref - > dir , len ) ; dref - > dir[len] = 0 ; for ( j = 0 ; j < len ; j + + ) if ( dref - > dir[j] == ' : ' ) dref - > dir[j] = ' / ' ; av_log ( c - > fc , AV_LOG_DEBUG , dir %s\n , dref - > dir ) ; } else avio_skip ( pb , len ) ; } } avio_seek ( pb , next , SEEK_SET ) ; } return 0 ; }",1
"int ff_pulse_audio_get_devices ( AVDeviceInfoList * devices , const char * server , int output ) { pa_mainloop * pa_ml = NULL ; pa_mainloop_api * pa_mlapi = NULL ; pa_operation * pa_op = NULL ; pa_context * pa_ctx = NULL ; enum pa_operation_state op_state ; enum PulseAudioContextState loop_state = PULSE_CONTEXT_INITIALIZING ; PulseAudioDeviceList dev_list = { 0 } ; int i ; dev_list . output = output ; dev_list . devices = devices ; if ( ! devices ) return AVERROR ( EINVAL ) ; devices - > nb_devices = 0 ; devices - > devices = NULL ; if ( ! ( pa_ml = pa_mainloop_new ( ) ) ) return AVERROR ( ENOMEM ) ; if ( ! ( pa_mlapi = pa_mainloop_get_api ( pa_ml ) ) ) { dev_list . error_code = AVERROR_EXTERNAL ; goto fail ; } if ( ! ( pa_ctx = pa_context_new ( pa_mlapi , Query devices ) ) ) { dev_list . error_code = AVERROR ( ENOMEM ) ; goto fail ; } pa_context_set_state_callback ( pa_ctx , pa_state_cb , & loop_state ) ; if ( pa_context_connect ( pa_ctx , server , 0 , NULL ) < 0 ) { dev_list . error_code = AVERROR_EXTERNAL ; goto fail ; } while ( loop_state == PULSE_CONTEXT_INITIALIZING ) pa_mainloop_iterate ( pa_ml , 1 , NULL ) ; if ( loop_state == PULSE_CONTEXT_FINISHED ) { dev_list . error_code = AVERROR_EXTERNAL ; goto fail ; } if ( output ) pa_op = pa_context_get_sink_info_list ( pa_ctx , pulse_audio_sink_device_cb , & dev_list ) ; else pa_op = pa_context_get_source_info_list ( pa_ctx , pulse_audio_source_device_cb , & dev_list ) ; while ( ( op_state = pa_operation_get_state ( pa_op ) ) == PA_OPERATION_RUNNING ) pa_mainloop_iterate ( pa_ml , 1 , NULL ) ; if ( op_state ! = PA_OPERATION_DONE ) dev_list . error_code = AVERROR_EXTERNAL ; pa_operation_unref ( pa_op ) ; if ( dev_list . error_code < 0 ) goto fail ; pa_op = pa_context_get_server_info ( pa_ctx , pulse_server_info_cb , & dev_list ) ; while ( ( op_state = pa_operation_get_state ( pa_op ) ) == PA_OPERATION_RUNNING ) pa_mainloop_iterate ( pa_ml , 1 , NULL ) ; if ( op_state ! = PA_OPERATION_DONE ) dev_list . error_code = AVERROR_EXTERNAL ; pa_operation_unref ( pa_op ) ; if ( dev_list . error_code < 0 ) goto fail ; devices - > default_device = - 1 ; for ( i = 0 ; i < devices - > nb_devices ; i + + ) { if ( ! strcmp ( devices - > devices[i] - > device_name , dev_list . default_device ) ) { devices - > default_device = i ; break ; } } fail : av_free ( dev_list . default_device ) ; if ( pa_ctx ) pa_context_disconnect ( pa_ctx ) ; if ( pa_ctx ) pa_context_unref ( pa_ctx ) ; if ( pa_ml ) pa_mainloop_free ( pa_ml ) ; return dev_list . error_code ; }",0
"static int encode_picture_lossless ( AVCodecContext * avctx , unsigned char * buf , int buf_size , void * data ) { MpegEncContext * const s = avctx - > priv_data ; MJpegContext * const m = s - > mjpeg_ctx ; AVFrame * pict = data ; const int width= s - > width ; const int height= s - > height ; AVFrame * const p= ( AVFrame * ) & s - > current_picture ; const int predictor= avctx - > prediction_method + 1 ; init_put_bits ( & s - > pb , buf , buf_size ) ; * p = * pict ; p - > pict_type= FF_I_TYPE ; p - > key_frame= 1 ; ff_mjpeg_encode_picture_header ( s ) ; s - > header_bits= put_bits_count ( & s - > pb ) ; if ( avctx - > pix_fmt == PIX_FMT_RGB32 ) { int x , y , i ; const int linesize= p - > linesize[0] ; uint16_t ( * buffer ) [4]= ( void * ) s - > rd_scratchpad ; int left[3] , top[3] , topleft[3] ; for ( i=0 ; i < 3 ; i + + ) { buffer[0][i]= 1 < < ( 9 - 1 ) ; } for ( y = 0 ; y < height ; y + + ) { const int modified_predictor= y ? predictor : 1 ; uint8_t * ptr = p - > data[0] + ( linesize * y ) ; if ( s - > pb . buf_end - s - > pb . buf - ( put_bits_count ( & s - > pb ) > > 3 ) < width * 3 * 4 ) { av_log ( s - > avctx , AV_LOG_ERROR , encoded frame too large\n ) ; return - 1 ; } for ( i=0 ; i < 3 ; i + + ) { top[i]= left[i]= topleft[i]= buffer[0][i] ; } for ( x = 0 ; x < width ; x + + ) { buffer[x][1] = ptr[4 * x + 0] - ptr[4 * x + 1] + 0x100 ; buffer[x][2] = ptr[4 * x + 2] - ptr[4 * x + 1] + 0x100 ; buffer[x][0] = ( ptr[4 * x + 0] + 2 * ptr[4 * x + 1] + ptr[4 * x + 2] ) > > 2 ; for ( i=0 ; i < 3 ; i + + ) { int pred , diff ; PREDICT ( pred , topleft[i] , top[i] , left[i] , modified_predictor ) ; topleft[i]= top[i] ; top[i]= buffer[x + 1][i] ; left[i]= buffer[x][i] ; diff= ( ( left[i] - pred + 0x100 ) & 0x1FF ) - 0x100 ; if ( i==0 ) ff_mjpeg_encode_dc ( s , diff , m - > huff_size_dc_luminance , m - > huff_code_dc_luminance ) ; //FIXME ugly else ff_mjpeg_encode_dc ( s , diff , m - > huff_size_dc_chrominance , m - > huff_code_dc_chrominance ) ; } } } } else { int mb_x , mb_y , i ; const int mb_width = ( width + s - > mjpeg_hsample[0] - 1 ) / s - > mjpeg_hsample[0] ; const int mb_height = ( height + s - > mjpeg_vsample[0] - 1 ) / s - > mjpeg_vsample[0] ; for ( mb_y = 0 ; mb_y < mb_height ; mb_y + + ) { if ( s - > pb . buf_end - s - > pb . buf - ( put_bits_count ( & s - > pb ) > > 3 ) < mb_width * 4 * 3 * s - > mjpeg_hsample[0] * s - > mjpeg_vsample[0] ) { av_log ( s - > avctx , AV_LOG_ERROR , encoded frame too large\n ) ; return - 1 ; } for ( mb_x = 0 ; mb_x < mb_width ; mb_x + + ) { if ( mb_x==0 || mb_y==0 ) { for ( i=0 ; i < 3 ; i + + ) { uint8_t * ptr ; int x , y , h , v , linesize ; h = s - > mjpeg_hsample[i] ; v = s - > mjpeg_vsample[i] ; linesize= p - > linesize[i] ; for ( y=0 ; y < v ; y + + ) { for ( x=0 ; x < h ; x + + ) { int pred ; ptr = p - > data[i] + ( linesize * ( v * mb_y + y ) ) + ( h * mb_x + x ) ; //FIXME optimize this crap if ( y==0 & & mb_y==0 ) { if ( x==0 & & mb_x==0 ) { pred= 128 ; } else { pred= ptr[ - 1] ; } } else { if ( x==0 & & mb_x==0 ) { pred= ptr[ - linesize] ; } else { PREDICT ( pred , ptr[ - linesize - 1] , ptr[ - linesize] , ptr[ - 1] , predictor ) ; } } if ( i==0 ) ff_mjpeg_encode_dc ( s , ( int8_t ) ( * ptr - pred ) , m - > huff_size_dc_luminance , m - > huff_code_dc_luminance ) ; //FIXME ugly else ff_mjpeg_encode_dc ( s , ( int8_t ) ( * ptr - pred ) , m - > huff_size_dc_chrominance , m - > huff_code_dc_chrominance ) ; } } } } else { for ( i=0 ; i < 3 ; i + + ) { uint8_t * ptr ; int x , y , h , v , linesize ; h = s - > mjpeg_hsample[i] ; v = s - > mjpeg_vsample[i] ; linesize= p - > linesize[i] ; for ( y=0 ; y < v ; y + + ) { for ( x=0 ; x < h ; x + + ) { int pred ; ptr = p - > data[i] + ( linesize * ( v * mb_y + y ) ) + ( h * mb_x + x ) ; //FIXME optimize this crap //printf ( %d %d %d %d %8X\n , mb_x , mb_y , x , y , ptr ) ; PREDICT ( pred , ptr[ - linesize - 1] , ptr[ - linesize] , ptr[ - 1] , predictor ) ; if ( i==0 ) ff_mjpeg_encode_dc ( s , ( int8_t ) ( * ptr - pred ) , m - > huff_size_dc_luminance , m - > huff_code_dc_luminance ) ; //FIXME ugly else ff_mjpeg_encode_dc ( s , ( int8_t ) ( * ptr - pred ) , m - > huff_size_dc_chrominance , m - > huff_code_dc_chrominance ) ; } } } } } } } emms_c ( ) ; ff_mjpeg_encode_picture_trailer ( s ) ; s - > picture_number + + ; flush_put_bits ( & s - > pb ) ; return pbBufPtr ( & s - > pb ) - s - > pb . buf ; // return ( put_bits_count ( & f - > pb ) + 7 ) /8 ; }",0
"static int ivi_decode_blocks ( GetBitContext * gb , IVIBandDesc * band , IVITile * tile , AVCodecContext * avctx ) { int mbn , blk , num_blocks , num_coeffs , blk_size , scan_pos , run , val , pos , is_intra , mc_type = 0 , mv_x , mv_y , col_mask ; uint8_t col_flags[8] ; int32_t prev_dc , trvec[64] ; uint32_t cbp , sym , lo , hi , quant , buf_offs , q ; IVIMbInfo * mb ; RVMapDesc * rvmap = band - > rv_map ; void ( * mc_with_delta_func ) ( int16_t * buf , const int16_t * ref_buf , uint32_t pitch , int mc_type ) ; void ( * mc_no_delta_func ) ( int16_t * buf , const int16_t * ref_buf , uint32_t pitch , int mc_type ) ; const uint16_t * base_tab ; const uint8_t * scale_tab ; prev_dc = 0 ; / * init intra prediction for the DC coefficient * / blk_size = band - > blk_size ; col_mask = blk_size - 1 ; / * column mask for tracking non - zero coeffs * / num_blocks = ( band - > mb_size ! = blk_size ) ? 4 : 1 ; / * number of blocks per mb * / num_coeffs = blk_size * blk_size ; if ( blk_size == 8 ) { mc_with_delta_func = ff_ivi_mc_8x8_delta ; mc_no_delta_func = ff_ivi_mc_8x8_no_delta ; } else { mc_with_delta_func = ff_ivi_mc_4x4_delta ; mc_no_delta_func = ff_ivi_mc_4x4_no_delta ; for ( mbn = 0 , mb = tile - > mbs ; mbn < tile - > num_MBs ; mb + + , mbn + + ) { is_intra = ! mb - > type ; cbp = mb - > cbp ; buf_offs = mb - > buf_offs ; quant = av_clip ( band - > glob_quant + mb - > q_delta , 0 , 23 ) ; base_tab = is_intra ? band - > intra_base : band - > inter_base ; scale_tab = is_intra ? band - > intra_scale : band - > inter_scale ; if ( scale_tab ) quant = scale_tab[quant] ; if ( ! is_intra ) { mv_x = mb - > mv_x ; mv_y = mb - > mv_y ; if ( band - > is_halfpel ) { mc_type = ( ( mv_y & 1 ) < < 1 ) | ( mv_x & 1 ) ; mv_x > > = 1 ; mv_y > > = 1 ; / * convert halfpel vectors into fullpel ones * / if ( mb - > type ) { int dmv_x , dmv_y , cx , cy ; dmv_x = mb - > mv_x > > band - > is_halfpel ; dmv_y = mb - > mv_y > > band - > is_halfpel ; cx = mb - > mv_x & band - > is_halfpel ; cy = mb - > mv_y & band - > is_halfpel ; if ( mb - > xpos + dmv_x < 0 || mb - > xpos + dmv_x + band - > mb_size + cx > band - > pitch || mb - > ypos + dmv_y < 0 || mb - > ypos + dmv_y + band - > mb_size + cy > band - > aheight ) { for ( blk = 0 ; blk < num_blocks ; blk + + ) { / * adjust block position in the buffer according to its number * / if ( blk & 1 ) { buf_offs + = blk_size ; } else if ( blk == 2 ) { buf_offs - = blk_size ; buf_offs + = blk_size * band - > pitch ; if ( cbp & 1 ) { / * block coded ? * / scan_pos = - 1 ; memset ( trvec , 0 , num_coeffs * sizeof ( trvec[0] ) ) ; / * zero transform vector * / memset ( col_flags , 0 , sizeof ( col_flags ) ) ; / * zero column flags * / while ( scan_pos < = num_coeffs ) { sym = get_vlc2 ( gb , band - > blk_vlc . tab - > table , IVI_VLC_BITS , 1 ) ; if ( sym == rvmap - > eob_sym ) break ; / * End of block * / if ( sym == rvmap - > esc_sym ) { / * Escape - run/val explicitly coded using 3 vlc codes * / run = get_vlc2 ( gb , band - > blk_vlc . tab - > table , IVI_VLC_BITS , 1 ) + 1 ; lo = get_vlc2 ( gb , band - > blk_vlc . tab - > table , IVI_VLC_BITS , 1 ) ; hi = get_vlc2 ( gb , band - > blk_vlc . tab - > table , IVI_VLC_BITS , 1 ) ; val = IVI_TOSIGNED ( ( hi < < 6 ) | lo ) ; / * merge them and convert into signed val * / } else { if ( sym > = 256U ) { av_log ( avctx , AV_LOG_ERROR , Invalid sym encountered : %d . \n , sym ) ; return - 1 ; run = rvmap - > runtab[sym] ; val = rvmap - > valtab[sym] ; / * de - zigzag and dequantize * / scan_pos + = run ; if ( scan_pos > = num_coeffs ) break ; pos = band - > scan[scan_pos] ; if ( ! val ) av_dlog ( avctx , Val = 0 encountered ! \n ) ; q = ( base_tab[pos] * quant ) > > 9 ; if ( q > 1 ) val = val * q + FFSIGN ( val ) * ( ( ( q 1 ) - 1 ) > > 1 ) ; trvec[pos] = val ; col_flags[pos & col_mask] |= ! ! val ; / * track columns containing non - zero coeffs * / } // while if ( scan_pos > = num_coeffs & & sym ! = rvmap - > eob_sym ) return - 1 ; / * corrupt block data * / / * undoing DC coeff prediction for intra - blocks * / if ( is_intra & & band - > is_2d_trans ) { prev_dc + = trvec[0] ; trvec[0] = prev_dc ; col_flags[0] |= ! ! prev_dc ; / * apply inverse transform * / band - > inv_transform ( trvec , band - > buf + buf_offs , band - > pitch , col_flags ) ; / * apply motion compensation * / if ( ! is_intra ) mc_with_delta_func ( band - > buf + buf_offs , band - > ref_buf + buf_offs + mv_y * band - > pitch + mv_x , band - > pitch , mc_type ) ; } else { / * block not coded * / / * for intra blocks apply the dc slant transform * / / * for inter - perform the motion compensation without delta * / if ( is_intra & & band - > dc_transform ) { band - > dc_transform ( & prev_dc , band - > buf + buf_offs , band - > pitch , blk_size ) ; } else mc_no_delta_func ( band - >",1
"static int skip_data_stream_element ( AACContext * ac , GetBitContext * gb ) { int byte_align = get_bits1 ( gb ) ; int count = get_bits ( gb , 8 ) ; if ( count == 255 ) count + = get_bits ( gb , 8 ) ; if ( byte_align ) align_get_bits ( gb ) ; if ( get_bits_left ( gb ) < 8 * count ) { av_log ( ac - > avctx , AV_LOG_ERROR , overread_err ) ; return - 1 ; } skip_bits_long ( gb , 8 * count ) ; return 0 ; }",1
"static int filter_frame ( AVFilterLink * inlink , AVFrame * inbuf ) { AudioPhaserContext * s = inlink - > dst - > priv ; AVFilterLink * outlink = inlink - > dst - > outputs[0] ; AVFrame * outbuf ; if ( av_frame_is_writable ( inbuf ) ) { outbuf = inbuf ; } else { outbuf = ff_get_audio_buffer ( inlink , inbuf - > nb_samples ) ; if ( ! outbuf ) return AVERROR ( ENOMEM ) ; av_frame_copy_props ( outbuf , inbuf ) ; } s - > phaser ( s , inbuf - > extended_data , outbuf - > extended_data , outbuf - > nb_samples , outbuf - > channels ) ; if ( inbuf ! = outbuf ) av_frame_free ( & inbuf ) ; return ff_filter_frame ( outlink , outbuf ) ; }",1
static void allocate_buffers ( ALACContext * alac ) { int chan ; for ( chan = 0 ; chan < alac - > numchannels ; chan + + ) { alac - > predicterror_buffer[chan] = av_malloc ( alac - > setinfo_max_samples_per_frame * 4 ) ; alac - > outputsamples_buffer[chan] = av_malloc ( alac - > setinfo_max_samples_per_frame * 4 ) ; alac - > wasted_bits_buffer[chan] = av_malloc ( alac - > setinfo_max_samples_per_frame * 4 ) ; } },1
"static inline void RENAME ( planar2x ) ( const uint8_t * src , uint8_t * dst , int srcWidth , int srcHeight , int srcStride , int dstStride ) { int x , y ; dst[0]= src[0] ; // first line for ( x=0 ; x < srcWidth - 1 ; x + + ) { dst[2 * x + 1]= ( 3 * src[x] + src[x + 1] ) > > 2 ; dst[2 * x + 2]= ( src[x] + 3 * src[x + 1] ) > > 2 ; } dst[2 * srcWidth - 1]= src[srcWidth - 1] ; dst + = dstStride ; for ( y=1 ; y < srcHeight ; y + + ) { if defined ( HAVE_MMX2 ) || defined ( HAVE_3DNOW ) const long mmxSize= srcWidth & 15 ; asm volatile ( mov %4 , %% REG_a \n\t 1 : \n\t movq ( %0 , %% REG_a ) , %%mm0 \n\t movq ( %1 , %% REG_a ) , %%mm1 \n\t movq 1 ( %0 , %% REG_a ) , %%mm2 \n\t movq 1 ( %1 , %% REG_a ) , %%mm3 \n\t movq - 1 ( %0 , %% REG_a ) , %%mm4 \n\t movq - 1 ( %1 , %% REG_a ) , %%mm5 \n\t PAVGB %%mm0 , %%mm5 \n\t PAVGB %%mm0 , %%mm3 \n\t PAVGB %%mm0 , %%mm5 \n\t PAVGB %%mm0 , %%mm3 \n\t PAVGB %%mm1 , %%mm4 \n\t PAVGB %%mm1 , %%mm2 \n\t PAVGB %%mm1 , %%mm4 \n\t PAVGB %%mm1 , %%mm2 \n\t movq %%mm5 , %%mm7 \n\t movq %%mm4 , %%mm6 \n\t punpcklbw %%mm3 , %%mm5 \n\t punpckhbw %%mm3 , %%mm7 \n\t punpcklbw %%mm2 , %%mm4 \n\t punpckhbw %%mm2 , %%mm6 \n\t if 1 MOVNTQ %%mm5 , ( %2 , %% REG_a , 2 ) \n\t MOVNTQ %%mm7 , 8 ( %2 , %% REG_a , 2 ) \n\t MOVNTQ %%mm4 , ( %3 , %% REG_a , 2 ) \n\t MOVNTQ %%mm6 , 8 ( %3 , %% REG_a , 2 ) \n\t else movq %%mm5 , ( %2 , %% REG_a , 2 ) \n\t movq %%mm7 , 8 ( %2 , %% REG_a , 2 ) \n\t movq %%mm4 , ( %3 , %% REG_a , 2 ) \n\t movq %%mm6 , 8 ( %3 , %% REG_a , 2 ) \n\t endif add 8 , %% REG_a \n\t js 1b \n\t : : r ( src + mmxSize ) , r ( src + srcStride + mmxSize ) , r ( dst + mmxSize * 2 ) , r ( dst + dstStride + mmxSize * 2 ) , g ( - mmxSize ) : % REG_a ) ; else const int mmxSize=1 ; endif dst[0 ]= ( 3 * src[0] + src[srcStride] ) > > 2 ; dst[dstStride]= ( src[0] + 3 * src[srcStride] ) > > 2 ; for ( x=mmxSize - 1 ; x < srcWidth - 1 ; x + + ) { dst[2 * x + 1]= ( 3 * src[x + 0] + src[x + srcStride + 1] ) > > 2 ; dst[2 * x + dstStride + 2]= ( src[x + 0] + 3 * src[x + srcStride + 1] ) > > 2 ; dst[2 * x + dstStride + 1]= ( src[x + 1] + 3 * src[x + srcStride ] ) > > 2 ; dst[2 * x + 2]= ( 3 * src[x + 1] + src[x + srcStride ] ) > > 2 ; } dst[srcWidth * 2 - 1 ]= ( 3 * src[srcWidth - 1] + src[srcWidth - 1 + srcStride] ) > > 2 ; dst[srcWidth * 2 - 1 + dstStride]= ( src[srcWidth - 1] + 3 * src[srcWidth - 1 + srcStride] ) > > 2 ; dst + =dstStride * 2 ; src + =srcStride ; } // last line if 1 dst[0]= src[0] ; for ( x=0 ; x < srcWidth - 1 ; x + + ) { dst[2 * x + 1]= ( 3 * src[x] + src[x + 1] ) > > 2 ; dst[2 * x + 2]= ( src[x] + 3 * src[x + 1] ) > > 2 ; } dst[2 * srcWidth - 1]= src[srcWidth - 1] ; else for ( x=0 ; x < srcWidth ; x + + ) { dst[2 * x + 0]= dst[2 * x + 1]= src[x] ; } endif ifdef HAVE_MMX asm volatile ( EMMS \n\t SFENCE \n\t : : : memory ) ; endif }",1
"static int mxf_parse_physical_source_package ( MXFContext * mxf , MXFTrack * source_track , AVStream * st ) { MXFPackage * temp_package = NULL ; MXFPackage * physical_package = NULL ; MXFTrack * physical_track = NULL ; MXFStructuralComponent * component = NULL ; MXFStructuralComponent * sourceclip = NULL ; MXFTimecodeComponent * mxf_tc = NULL ; MXFPulldownComponent * mxf_pulldown = NULL ; int i , j , k ; AVTimecode tc ; int flags ; int64_t start_position ; for ( i = 0 ; i < source_track - > sequence - > structural_components_count ; i + + ) { component = mxf_resolve_strong_ref ( mxf , & source_track - > sequence - > structural_components_refs[i] , SourceClip ) ; if ( ! component ) continue ; for ( j = 0 ; j < mxf - > packages_count ; j + + ) { temp_package = mxf_resolve_strong_ref ( mxf , & mxf - > packages_refs[j] , SourcePackage ) ; if ( ! temp_package ) continue ; if ( ! memcmp ( temp_package - > package_uid , component - > source_package_uid , 16 ) ) { physical_package = temp_package ; sourceclip = component ; break ; } } if ( ! physical_package ) break ; / * the name of physical source package is name of the reel or tape * / if ( physical_package - > name[0] ) av_dict_set ( & st - > metadata , reel_name , physical_package - > name , 0 ) ; / * the source timecode is calculated by adding the start_position of the sourceclip from the file source package track * to the start_frame of the timecode component located on one of the tracks of the physical source package . * / for ( j = 0 ; j < physical_package - > tracks_count ; j + + ) { if ( ! ( physical_track = mxf_resolve_strong_ref ( mxf , & physical_package - > tracks_refs[j] , Track ) ) ) { av_log ( mxf - > fc , AV_LOG_ERROR , could not resolve source track strong ref\n ) ; continue ; } if ( ! ( physical_track - > sequence = mxf_resolve_strong_ref ( mxf , & physical_track - > sequence_ref , Sequence ) ) ) { av_log ( mxf - > fc , AV_LOG_ERROR , could not resolve source track sequence strong ref\n ) ; continue ; } for ( k = 0 ; k < physical_track - > sequence - > structural_components_count ; k + + ) { component = mxf_resolve_strong_ref ( mxf , & physical_track - > sequence - > structural_components_refs[k] , TimecodeComponent ) ; if ( ! component ) { / * timcode component may be located on a pulldown component * / component = mxf_resolve_strong_ref ( mxf , & physical_track - > sequence - > structural_components_refs[k] , PulldownComponent ) ; if ( ! component ) continue ; mxf_pulldown = ( MXFPulldownComponent * ) component ; component = mxf_resolve_strong_ref ( mxf , & mxf_pulldown - > input_segment_ref , TimecodeComponent ) ; if ( ! component ) continue ; } mxf_tc = ( MXFTimecodeComponent * ) component ; flags = mxf_tc - > drop_frame == 1 ? AV_TIMECODE_FLAG_DROPFRAME : 0 ; / * scale sourceclip start_position to match physical track edit rate * / start_position = av_rescale_q ( sourceclip - > start_position , physical_track - > edit_rate , source_track - > edit_rate ) ; if ( av_timecode_init ( & tc , mxf_tc - > rate , flags , start_position + mxf_tc - > start_frame , mxf - > fc ) == 0 ) { mxf_add_timecode_metadata ( & st - > metadata , timecode , & tc ) ; return 0 ; } } } } return 0 ; }",1
"static AVStream * find_stream ( void * log , AVFormatContext * avf , const char * spec ) { int i , ret , already = 0 , stream_id = - 1 ; char type_char , dummy ; AVStream * found = NULL ; enum AVMediaType type ; ret = sscanf ( spec , d%[av]%d%c , & type_char , & stream_id , & dummy ) ; if ( ret > = 1 & & ret < = 2 ) { type = type_char == ' v ' ? AVMEDIA_TYPE_VIDEO : AVMEDIA_TYPE_AUDIO ; ret = av_find_best_stream ( avf , type , stream_id , - 1 , NULL , 0 ) ; if ( ret < 0 ) { av_log ( log , AV_LOG_ERROR , No %s stream with index ' %d ' found\n , av_get_media_type_string ( type ) , stream_id ) ; return NULL ; } return avf - > streams[ret] ; } for ( i = 0 ; i < avf - > nb_streams ; i + + ) { ret = avformat_match_stream_specifier ( avf , avf - > streams[i] , spec ) ; if ( ret < 0 ) { av_log ( log , AV_LOG_ERROR , Invalid stream specifier \ %s\ \n , spec ) ; return NULL ; } if ( ! ret ) continue ; if ( avf - > streams[i] - > discard ! = AVDISCARD_ALL ) { already + + ; continue ; } if ( found ) { av_log ( log , AV_LOG_WARNING , Ambiguous stream specifier \ %s\ , using %d\n , spec , i ) ; break ; } found = avf - > streams[i] ; } if ( ! found ) { av_log ( log , AV_LOG_WARNING , Stream specifier \ %s\ %s\n , spec , already ? matched only already used streams : did not match any stream ) ; return NULL ; } if ( found - > codec - > codec_type ! = AVMEDIA_TYPE_VIDEO & & found - > codec - > codec_type ! = AVMEDIA_TYPE_AUDIO ) { av_log ( log , AV_LOG_ERROR , Stream specifier \ %s\ matched a %s stream , currently unsupported by libavfilter\n , spec , av_get_media_type_string ( found - > codec - > codec_type ) ) ; return NULL ; } return found ; }",0
"static int set_string_number ( void * obj , const AVOption * o , const char * val , void * dst ) { int ret = 0 , notfirst = 0 ; for ( ; ; ) { int i , den = 1 ; char buf[256] ; int cmd = 0 ; double d , num = 1 ; int64_t intnum = 1 ; if ( * val == ' + ' || * val == ' - ' ) cmd = * ( val + + ) ; for ( i = 0 ; i < sizeof ( buf ) - 1 & & val[i] & & val[i] ! = ' + ' & & val[i] ! = ' - ' ; i + + ) buf[i] = val[i] ; buf[i] = 0 ; { const AVOption * o_named = av_opt_find ( obj , buf , o - > unit , 0 , 0 ) ; if ( o_named & & o_named - > type == AV_OPT_TYPE_CONST ) d = DEFAULT_NUMVAL ( o_named ) ; else if ( ! strcmp ( buf , default ) ) d = DEFAULT_NUMVAL ( o ) ; else if ( ! strcmp ( buf , max ) ) d = o - > max ; else if ( ! strcmp ( buf , min ) ) d = o - > min ; else if ( ! strcmp ( buf , none ) ) d = 0 ; else if ( ! strcmp ( buf , all ) ) d = 0 ; else { int res = av_expr_parse_and_eval ( & d , buf , const_names , const_values , NULL , NULL , NULL , NULL , NULL , 0 , obj ) ; if ( res < 0 ) { av_log ( obj , AV_LOG_ERROR , Unable to parse option value \ %s\ \n , val ) ; return res ; } } } if ( o - > type == AV_OPT_TYPE_FLAGS ) { read_number ( o , dst , NULL , NULL , & intnum ) ; if ( cmd == ' + ' ) d = intnum | ( int64_t ) d ; else if ( cmd == ' - ' ) d = intnum & ( int64_t ) d ; } else { read_number ( o , dst , & num , & den , & intnum ) ; if ( cmd == ' + ' ) d = notfirst * num * intnum/den + d ; else if ( cmd == ' - ' ) d = notfirst * num * intnum/den - d ; } if ( ( ret = write_number ( obj , o , dst , d , 1 , 1 ) ) < 0 ) return ret ; val + = i ; if ( ! * val ) return 0 ; notfirst = 1 ; } return 0 ; }",0
"static int amr_wb_encode_frame ( AVCodecContext * avctx , unsigned char * frame / * out * / , int buf_size , void * data / * in * / ) { AMRWBContext * s ; int size ; s = ( AMRWBContext * ) avctx - > priv_data ; s - > mode=getWBBitrateMode ( avctx - > bit_rate ) ; size = E_IF_encode ( s - > state , s - > mode , data , frame , s - > allow_dtx ) ; return size ; }",0
"static void check_rgb2yuv ( void ) { declare_func ( void , uint8_t * dst[3] , ptrdiff_t dst_stride[3] , int16_t * src[3] , ptrdiff_t src_stride , int w , int h , const int16_t coeff[3][3][8] , const int16_t off[8] ) ; ColorSpaceDSPContext dsp ; int odepth , fmt , n ; LOCAL_ALIGNED_32 ( int16_t , src_y , [W * H * 2] ) ; LOCAL_ALIGNED_32 ( int16_t , src_u , [W * H * 2] ) ; LOCAL_ALIGNED_32 ( int16_t , src_v , [W * H * 2] ) ; int16_t * src[3] = { src_y , src_u , src_v } ; LOCAL_ALIGNED_32 ( uint8_t , dst0_y , [W * H] ) ; LOCAL_ALIGNED_32 ( uint8_t , dst0_u , [W * H] ) ; LOCAL_ALIGNED_32 ( uint8_t , dst0_v , [W * H] ) ; LOCAL_ALIGNED_32 ( uint8_t , dst1_y , [W * H] ) ; LOCAL_ALIGNED_32 ( uint8_t , dst1_u , [W * H] ) ; LOCAL_ALIGNED_32 ( uint8_t , dst1_v , [W * H] ) ; uint8_t * dst0[3] = { dst0_y , dst0_u , dst0_v } , * dst1[3] = { dst1_y , dst1_u , dst1_v } ; LOCAL_ALIGNED_32 ( int16_t , offset , [8] ) ; LOCAL_ALIGNED_32 ( int16_t , coeff_buf , [3 * 3 * 8] ) ; int16_t ( * coeff ) [3][8] = ( int16_t ( * ) [3][8] ) coeff_buf ; ff_colorspacedsp_init ( & dsp ) ; for ( n = 0 ; n < 8 ; n + + ) { offset[n] = 16 ; // these somewhat resemble bt601/smpte170m coefficients coeff[0][0][n] = lrint ( 0 . 3 * ( 1 < < 14 ) ) ; coeff[0][1][n] = lrint ( 0 . 6 * ( 1 < < 14 ) ) ; coeff[0][2][n] = lrint ( 0 . 1 * ( 1 < < 14 ) ) ; coeff[1][0][n] = lrint ( - 0 . 15 * ( 1 < < 14 ) ) ; coeff[1][1][n] = lrint ( - 0 . 35 * ( 1 < < 14 ) ) ; coeff[1][2][n] = lrint ( 0 . 5 * ( 1 < < 14 ) ) ; coeff[2][0][n] = lrint ( 0 . 5 * ( 1 < < 14 ) ) ; coeff[2][1][n] = lrint ( - 0 . 42 * ( 1 < < 14 ) ) ; coeff[2][2][n] = lrint ( - 0 . 08 * ( 1 < < 14 ) ) ; } for ( odepth = 0 ; odepth < 3 ; odepth + + ) { for ( fmt = 0 ; fmt < 3 ; fmt + + ) { if ( check_func ( dsp . rgb2yuv[odepth][fmt] , ff_colorspacedsp_rgb2yuv_%sp%d , format_string[fmt] , odepth * 2 + 8 ) ) { int ss_w = ! ! fmt , ss_h = fmt == 2 ; int y_dst_stride = W < < ! ! odepth ; int uv_dst_stride = y_dst_stride > > ss_w ; randomize_buffers ( ) ; call_ref ( dst0 , ( ptrdiff_t[3] ) { y_dst_stride , uv_dst_stride , uv_dst_stride } , src , W , W , H , coeff , offset ) ; call_new ( dst1 , ( ptrdiff_t[3] ) { y_dst_stride , uv_dst_stride , uv_dst_stride } , src , W , W , H , coeff , offset ) ; if ( memcmp ( dst0[0] , dst1[0] , H * y_dst_stride ) || memcmp ( dst0[1] , dst1[1] , H * uv_dst_stride > > ss_h ) || memcmp ( dst0[2] , dst1[2] , H * uv_dst_stride > > ss_h ) ) { fail ( ) ; } } } } report ( rgb2yuv ) ; }",0
"static void lag_pred_line ( LagarithContext * l , uint8_t * buf , int width , int stride , int line ) { int L , TL ; / * Left pixel is actually prev_row[width] * / L = buf[width - stride - 1] ; if ( ! line ) { / * Left prediction only for first line * / L = l - > dsp . add_hfyu_left_prediction ( buf + 1 , buf + 1 , width - 1 , buf[0] ) ; return ; } else if ( line == 1 ) { / * Second line , left predict first pixel , the rest of the line is median predicted * NOTE : In the case of RGB this pixel is top predicted * / TL = l - > avctx - > pix_fmt == PIX_FMT_YUV420P ? buf[ - stride] : L ; } else { / * Top left is 2 rows back , last pixel * / TL = buf[width - ( 2 * stride ) - 1] ; } add_lag_median_prediction ( buf , buf - stride , buf , width , & L , & TL ) ; }",0
"flac_header ( AVFormatContext * s , int idx ) { struct ogg * ogg = s - > priv_data ; struct ogg_stream * os = ogg - > streams + idx ; AVStream * st = s - > streams[idx] ; GetBitContext gb ; FLACStreaminfo si ; int mdt ; if ( os - > buf[os - > pstart] == 0xff ) return 0 ; init_get_bits ( & gb , os - > buf + os - > pstart , os - > psize * 8 ) ; skip_bits1 ( & gb ) ; / * metadata_last * / mdt = get_bits ( & gb , 7 ) ; if ( mdt == OGG_FLAC_METADATA_TYPE_STREAMINFO ) { uint8_t * streaminfo_start = os - > buf + os - > pstart + 5 + 4 + 4 + 4 ; skip_bits_long ( & gb , 4 * 8 ) ; / * FLAC * / if ( get_bits ( & gb , 8 ) ! = 1 ) / * unsupported major version * / return - 1 ; skip_bits_long ( & gb , 8 + 16 ) ; / * minor version + header count * / skip_bits_long ( & gb , 4 * 8 ) ; / * fLaC * / / * METADATA_BLOCK_HEADER * / if ( get_bits_long ( & gb , 32 ) ! = FLAC_STREAMINFO_SIZE ) return - 1 ; avpriv_flac_parse_streaminfo ( st - > codec , & si , streaminfo_start ) ; st - > codec - > codec_type = AVMEDIA_TYPE_AUDIO ; st - > codec - > codec_id = AV_CODEC_ID_FLAC ; st - > need_parsing = AVSTREAM_PARSE_HEADERS ; ff_alloc_extradata ( st - > codec , FLAC_STREAMINFO_SIZE ) ; memcpy ( st - > codec - > extradata , streaminfo_start , st - > codec - > extradata_size ) ; avpriv_set_pts_info ( st , 64 , 1 , st - > codec - > sample_rate ) ; } else if ( mdt == FLAC_METADATA_TYPE_VORBIS_COMMENT ) { ff_vorbis_comment ( s , & st - > metadata , os - > buf + os - > pstart + 4 , os - > psize - 4 ) ; } return 1 ; }",0
"static int opt_input_file ( OptionsContext * o , const char * opt , const char * filename ) { AVFormatContext * ic ; AVInputFormat * file_iformat = NULL ; int err , i , ret ; int64_t timestamp ; uint8_t buf[128] ; AVDictionary * * opts ; int orig_nb_streams ; // number of streams before avformat_find_stream_info if ( o - > format ) { if ( ! ( file_iformat = av_find_input_format ( o - > format ) ) ) { av_log ( NULL , AV_LOG_FATAL , Unknown input format : ' %s ' \n , o - > format ) ; exit_program ( 1 ) ; } } if ( ! strcmp ( filename , - ) ) filename = pipe : ; using_stdin |= ! strncmp ( filename , pipe : , 5 ) || ! strcmp ( filename , /dev/stdin ) ; / * get default parameters from command line * / ic = avformat_alloc_context ( ) ; if ( ! ic ) { print_error ( filename , AVERROR ( ENOMEM ) ) ; exit_program ( 1 ) ; } if ( o - > nb_audio_sample_rate ) { snprintf ( buf , sizeof ( buf ) , %d , o - > audio_sample_rate[o - > nb_audio_sample_rate - 1] . u . i ) ; av_dict_set ( & format_opts , sample_rate , buf , 0 ) ; } if ( o - > nb_audio_channels ) { snprintf ( buf , sizeof ( buf ) , %d , o - > audio_channels[o - > nb_audio_channels - 1] . u . i ) ; av_dict_set ( & format_opts , channels , buf , 0 ) ; } if ( o - > nb_frame_rates ) { av_dict_set ( & format_opts , framerate , o - > frame_rates[o - > nb_frame_rates - 1] . u . str , 0 ) ; } if ( o - > nb_frame_sizes ) { av_dict_set ( & format_opts , video_size , o - > frame_sizes[o - > nb_frame_sizes - 1] . u . str , 0 ) ; } if ( o - > nb_frame_pix_fmts ) av_dict_set ( & format_opts , pixel_format , o - > frame_pix_fmts[o - > nb_frame_pix_fmts - 1] . u . str , 0 ) ; ic - > video_codec_id = video_codec_name ? find_codec_or_die ( video_codec_name , AVMEDIA_TYPE_VIDEO , 0 ) - > id : CODEC_ID_NONE ; ic - > audio_codec_id = audio_codec_name ? find_codec_or_die ( audio_codec_name , AVMEDIA_TYPE_AUDIO , 0 ) - > id : CODEC_ID_NONE ; ic - > subtitle_codec_id= subtitle_codec_name ? find_codec_or_die ( subtitle_codec_name , AVMEDIA_TYPE_SUBTITLE , 0 ) - > id : CODEC_ID_NONE ; ic - > flags |= AVFMT_FLAG_NONBLOCK ; ic - > interrupt_callback = int_cb ; if ( loop_input ) { av_log ( NULL , AV_LOG_WARNING , - loop_input is deprecated , use - loop 1\n ) ; ic - > loop_input = loop_input ; } / * open the input file with generic avformat function * / err = avformat_open_input ( & ic , filename , file_iformat , & format_opts ) ; if ( err < 0 ) { print_error ( filename , err ) ; exit_program ( 1 ) ; } assert_avoptions ( format_opts ) ; / * apply forced codec ids * / for ( i = 0 ; i < ic - > nb_streams ; i + + ) choose_decoder ( o , ic , ic - > streams[i] ) ; / * Set AVCodecContext options for avformat_find_stream_info * / opts = setup_find_stream_info_opts ( ic , codec_opts ) ; orig_nb_streams = ic - > nb_streams ; / * If not enough info to get the stream parameters , we decode the first frames to get it . ( used in mpeg case for example ) * / ret = avformat_find_stream_info ( ic , opts ) ; if ( ret < 0 ) { av_log ( NULL , AV_LOG_FATAL , %s : could not find codec parameters\n , filename ) ; av_close_input_file ( ic ) ; exit_program ( 1 ) ; } timestamp = o - > start_time ; / * add the stream start time * / if ( ic - > start_time ! = AV_NOPTS_VALUE ) timestamp + = ic - > start_time ; / * if seeking requested , we execute it * / if ( o - > start_time ! = 0 ) { ret = av_seek_frame ( ic , - 1 , timestamp , AVSEEK_FLAG_BACKWARD ) ; if ( ret < 0 ) { av_log ( NULL , AV_LOG_WARNING , %s : could not seek to position %0 . 3f\n , filename , ( double ) timestamp / AV_TIME_BASE ) ; } } / * update the current parameters so that they match the one of the input stream * / add_input_streams ( o , ic ) ; / * dump the file content * / av_dump_format ( ic , nb_input_files , filename , 0 ) ; input_files = grow_array ( input_files , sizeof ( * input_files ) , & nb_input_files , nb_input_files + 1 ) ; input_files[nb_input_files - 1] . ctx = ic ; input_files[nb_input_files - 1] . ist_index = nb_input_streams - ic - > nb_streams ; input_files[nb_input_files - 1] . ts_offset = o - > input_ts_offset - ( copy_ts ? 0 : timestamp ) ; input_files[nb_input_files - 1] . nb_streams = ic - > nb_streams ; input_files[nb_input_files - 1] . rate_emu = o - > rate_emu ; for ( i = 0 ; i < o - > nb_dump_attachment ; i + + ) { int j ; for ( j = 0 ; j < ic - > nb_streams ; j + + ) { AVStream * st = ic - > streams[j] ; if ( check_stream_specifier ( ic , st , o - > dump_attachment[i] . specifier ) == 1 ) dump_attachment ( st , o - > dump_attachment[i] . u . str ) ; } } for ( i = 0 ; i < orig_nb_streams ; i + + ) av_dict_free ( & opts[i] ) ; av_freep ( & opts ) ; reset_options ( o , 1 ) ; return 0 ; }",0
"static void fill_tone_level_array ( QDM2Context * q , int flag ) { int i , sb , ch , sb_used ; int tmp , tab ; // This should never happen if ( q - > nb_channels < = 0 ) return ; for ( ch = 0 ; ch < q - > nb_channels ; ch + + ) for ( sb = 0 ; sb < 30 ; sb + + ) for ( i = 0 ; i < 8 ; i + + ) { if ( ( tab=coeff_per_sb_for_dequant[q - > coeff_per_sb_select][sb] ) < ( last_coeff[q - > coeff_per_sb_select] - 1 ) ) tmp = q - > quantized_coeffs[ch][tab + 1][i] * dequant_table[q - > coeff_per_sb_select][tab + 1][sb] + q - > quantized_coeffs[ch][tab][i] * dequant_table[q - > coeff_per_sb_select][tab][sb] ; else tmp = q - > quantized_coeffs[ch][tab][i] * dequant_table[q - > coeff_per_sb_select][tab][sb] ; if ( tmp < 0 ) tmp + = 0xff ; q - > tone_level_idx_base[ch][sb][i] = ( tmp / 256 ) & 0xff ; } sb_used = QDM2_SB_USED ( q - > sub_sampling ) ; if ( ( q - > superblocktype_2_3 ! = 0 ) & & ! flag ) { for ( sb = 0 ; sb < sb_used ; sb + + ) for ( ch = 0 ; ch < q - > nb_channels ; ch + + ) for ( i = 0 ; i < 64 ; i + + ) { q - > tone_level_idx[ch][sb][i] = q - > tone_level_idx_base[ch][sb][i / 8] ; if ( q - > tone_level_idx[ch][sb][i] < 0 ) q - > tone_level[ch][sb][i] = 0 ; else q - > tone_level[ch][sb][i] = fft_tone_level_table[0][q - > tone_level_idx[ch][sb][i] & 0x3f] ; } } else { tab = q - > superblocktype_2_3 ? 0 : 1 ; for ( sb = 0 ; sb < sb_used ; sb + + ) { if ( ( sb > = 4 ) & & ( sb < = 23 ) ) { for ( ch = 0 ; ch < q - > nb_channels ; ch + + ) for ( i = 0 ; i < 64 ; i + + ) { tmp = q - > tone_level_idx_base[ch][sb][i / 8] - q - > tone_level_idx_hi1[ch][sb / 8][i / 8][i % 8] - q - > tone_level_idx_mid[ch][sb - 4][i / 8] - q - > tone_level_idx_hi2[ch][sb - 4] ; q - > tone_level_idx[ch][sb][i] = tmp & 0xff ; if ( ( tmp < 0 ) || ( ! q - > superblocktype_2_3 & & ! tmp ) ) q - > tone_level[ch][sb][i] = 0 ; else q - > tone_level[ch][sb][i] = fft_tone_level_table[tab][tmp & 0x3f] ; } } else { if ( sb > 4 ) { for ( ch = 0 ; ch < q - > nb_channels ; ch + + ) for ( i = 0 ; i < 64 ; i + + ) { tmp = q - > tone_level_idx_base[ch][sb][i / 8] - q - > tone_level_idx_hi1[ch][2][i / 8][i % 8] - q - > tone_level_idx_hi2[ch][sb - 4] ; q - > tone_level_idx[ch][sb][i] = tmp & 0xff ; if ( ( tmp < 0 ) || ( ! q - > superblocktype_2_3 & & ! tmp ) ) q - > tone_level[ch][sb][i] = 0 ; else q - > tone_level[ch][sb][i] = fft_tone_level_table[tab][tmp & 0x3f] ; } } else { for ( ch = 0 ; ch < q - > nb_channels ; ch + + ) for ( i = 0 ; i < 64 ; i + + ) { tmp = q - > tone_level_idx[ch][sb][i] = q - > tone_level_idx_base[ch][sb][i / 8] ; if ( ( tmp < 0 ) || ( ! q - > superblocktype_2_3 & & ! tmp ) ) q - > tone_level[ch][sb][i] = 0 ; else q - > tone_level[ch][sb][i] = fft_tone_level_table[tab][tmp & 0x3f] ; } } } } } return ; }",0
"static int filter_frame ( AVFilterLink * inlink , AVFrame * src_buffer ) { AVFilterContext * ctx = inlink - > dst ; ATempoContext * atempo = ctx - > priv ; AVFilterLink * outlink = ctx - > outputs[0] ; int ret = 0 ; int n_in = src_buffer - > nb_samples ; int n_out = ( int ) ( 0 . 5 + ( ( double ) n_in ) / atempo - > tempo ) ; const uint8_t * src = src_buffer - > data[0] ; const uint8_t * src_end = src + n_in * atempo - > stride ; while ( src < src_end ) { if ( ! atempo - > dst_buffer ) { atempo - > dst_buffer = ff_get_audio_buffer ( outlink , n_out ) ; av_frame_copy_props ( atempo - > dst_buffer , src_buffer ) ; atempo - > dst = atempo - > dst_buffer - > data[0] ; atempo - > dst_end = atempo - > dst + n_out * atempo - > stride ; } yae_apply ( atempo , & src , src_end , & atempo - > dst , atempo - > dst_end ) ; if ( atempo - > dst == atempo - > dst_end ) { ret = push_samples ( atempo , outlink , n_out ) ; if ( ret < 0 ) goto end ; atempo - > request_fulfilled = 1 ; } } atempo - > nsamples_in + = n_in ; end : av_frame_free ( & src_buffer ) ; return ret ; }",0
"static av_always_inline void decode_line ( FFV1Context * s , int w , int16_t * sample[2] , int plane_index , int bits ) { PlaneContext * const p = & s - > plane[plane_index] ; RangeCoder * const c = & s - > c ; int x ; int run_count = 0 ; int run_mode = 0 ; int run_index = s - > run_index ; for ( x = 0 ; x < w ; x + + ) { int diff , context , sign ; context = get_context ( p , sample[1] + x , sample[0] + x , sample[1] + x ) ; if ( context < 0 ) { context = - context ; sign = 1 ; } else sign = 0 ; av_assert2 ( context < p - > context_count ) ; if ( s - > ac ) { diff = get_symbol_inline ( c , p - > state[context] , 1 ) ; } else { if ( context == 0 & & run_mode == 0 ) run_mode = 1 ; if ( run_mode ) { if ( run_count == 0 & & run_mode == 1 ) { if ( get_bits1 ( & s - > gb ) ) { run_count = 1 < < ff_log2_run[run_index] ; if ( x + run_count < = w ) run_index + + ; } else { if ( ff_log2_run[run_index] ) run_count = get_bits ( & s - > gb , ff_log2_run[run_index] ) ; else run_count = 0 ; if ( run_index ) run_index - - ; run_mode = 2 ; } } run_count - - ; if ( run_count < 0 ) { run_mode = 0 ; run_count = 0 ; diff = get_vlc_symbol ( & s - > gb , & p - > vlc_state[context] , bits ) ; if ( diff > = 0 ) diff + + ; } else diff = 0 ; } else diff = get_vlc_symbol ( & s - > gb , & p - > vlc_state[context] , bits ) ; ff_dlog ( s - > avctx , count : %d index : %d , mode : %d , x : %d pos : %d\n , run_count , run_index , run_mode , x , get_bits_count ( & s - > gb ) ) ; } if ( sign ) diff = - diff ; sample[1][x] = ( predict ( sample[1] + x , sample[0] + x ) + diff ) & ( ( 1 < < bits ) - 1 ) ; } s - > run_index = run_index ; }",0
"static int decode_i_picture_header ( VC9Context * v ) { int pqindex , status = 0 , ac_pred , condover ; / * Prolog common to all frametypes should be done in caller * / //BF = Buffer Fullness if ( v - > profile < = PROFILE_MAIN & & get_bits ( & v - > gb , 7 ) ) { av_log ( v , AV_LOG_DEBUG , I BufferFullness not 0\n ) ; } / * Quantizer stuff * / pqindex = get_bits ( & v - > gb , 5 ) ; if ( v - > quantizer_mode == QUANT_FRAME_IMPLICIT ) v - > pq = pquant_table[0][pqindex] ; else { v - > pq = pquant_table[v - > quantizer_mode - 1][pqindex] ; } if ( pqindex < 9 ) v - > halfpq = get_bits ( & v - > gb , 1 ) ; if ( v - > quantizer_mode == QUANT_FRAME_EXPLICIT ) v - > pquantizer = get_bits ( & v - > gb , 1 ) ; av_log ( v - > avctx , AV_LOG_DEBUG , I frame : QP=%i ( + %i/2 ) \n , v - > pq , v - > halfpq ) ; if HAS_ADVANCED_PROFILE if ( v - > profile < = PROFILE_MAIN ) endif { if ( v - > extended_mv ) v - > mvrange = get_prefix ( & v - > gb , 0 , 3 ) ; if ( v - > multires ) v - > respic = get_bits ( & v - > gb , 2 ) ; } if HAS_ADVANCED_PROFILE else { ac_pred = get_bits ( & v - > gb , 1 ) ; if ( v - > postprocflag ) v - > postproc = get_bits ( & v - > gb , 1 ) ; / * 7 . 1 . 1 . 34 + 8 . 5 . 2 * / if ( v - > overlap & & v - > pq < 9 ) { condover = get_bits ( & v - > gb , 1 ) ; if ( condover ) { condover = 2 + get_bits ( & v - > gb , 1 ) ; if ( condover == 3 ) status = bitplane_decoding ( v - > over_flags_plane , v - > width_mb , v - > height_mb , v ) ; } } } endif / * Epilog should be done in caller * / return status ; }",0
"static void add_to_pool ( BufferPoolEntry * buf ) { AVBufferPool * pool ; BufferPoolEntry * cur , * end = buf ; if ( ! buf ) return ; pool = buf - > pool ; while ( end - > next ) end = end - > next ; while ( ( cur = avpriv_atomic_ptr_cas ( ( void * volatile * ) & pool - > pool , NULL , buf ) ) ) { / * pool is not empty , retrieve it and append it to our list * / cur = get_pool ( pool ) ; end - > next = cur ; while ( end - > next ) end = end - > next ; } }",1
"static int libquvi_read_seek ( AVFormatContext * s , int stream_index , int64_t timestamp , int flags ) { LibQuviContext * qc = s - > priv_data ; return av_seek_frame ( qc - > fmtctx , stream_index , timestamp , flags ) ; }",1
"static int asf_read_packet ( AVFormatContext * s , AVPacket * pkt ) { ASFContext * asf = s - > priv_data ; ASFStream * asf_st = 0 ; ByteIOContext * pb = & s - > pb ; //static int pc = 0 ; for ( ; ; ) { int rsize = 0 ; if ( asf - > packet_size_left < FRAME_HEADER_SIZE || asf - > packet_segments < 1 ) { //asf - > packet_size_left < = asf - > packet_padsize ) { int ret = asf - > packet_size_left + asf - > packet_padsize ; //printf ( PacketLeftSize : %d Pad : %d Pos : %Ld\n , asf - > packet_size_left , asf - > packet_padsize , url_ftell ( pb ) ) ; if ( ( url_ftell ( & s - > pb ) + ret - s - > data_offset ) % asf - > packet_size ) ret + = asf - > packet_size - ( ( url_ftell ( & s - > pb ) + ret - s - > data_offset ) % asf - > packet_size ) ; / * fail safe * / url_fskip ( pb , ret ) ; asf - > packet_pos= url_ftell ( & s - > pb ) ; ret = asf_get_packet ( s ) ; //printf ( READ ASF PACKET %d r : %d c : %d\n , ret , asf - > packet_size_left , pc + + ) ; if ( ret < 0 || url_feof ( pb ) ) return AVERROR_IO ; asf - > packet_time_start = 0 ; continue ; } if ( asf - > packet_time_start == 0 ) { / * read frame header * / int num = get_byte ( pb ) ; asf - > packet_segments - - ; rsize + + ; asf - > packet_key_frame = ( num & 0x80 ) > > 7 ; asf - > stream_index = asf - > asfid2avid[num & 0x7f] ; // sequence should be ignored ! DO_2BITS ( asf - > packet_property > > 4 , asf - > packet_seq , 0 ) ; DO_2BITS ( asf - > packet_property > > 2 , asf - > packet_frag_offset , 0 ) ; DO_2BITS ( asf - > packet_property , asf - > packet_replic_size , 0 ) ; //printf ( key : %d stream : %d seq : %d offset : %d replic_size : %d\n , asf - > packet_key_frame , asf - > stream_index , asf - > packet_seq , //asf - > packet_frag_offset , asf - > packet_replic_size ) ; if ( asf - > packet_replic_size > 1 ) { assert ( asf - > packet_replic_size > = 8 ) ; // it should be always at least 8 bytes - FIXME validate asf - > packet_obj_size = get_le32 ( pb ) ; asf - > packet_frag_timestamp = get_le32 ( pb ) ; // timestamp if ( asf - > packet_replic_size > 8 ) url_fskip ( pb , asf - > packet_replic_size - 8 ) ; rsize + = asf - > packet_replic_size ; // FIXME - check validity } else if ( asf - > packet_replic_size==1 ) { // multipacket - frag_offset is begining timestamp asf - > packet_time_start = asf - > packet_frag_offset ; asf - > packet_frag_offset = 0 ; asf - > packet_frag_timestamp = asf - > packet_timestamp ; asf - > packet_time_delta = get_byte ( pb ) ; rsize + + ; } else { assert ( asf - > packet_replic_size==0 ) ; } if ( asf - > packet_flags & 0x01 ) { DO_2BITS ( asf - > packet_segsizetype > > 6 , asf - > packet_frag_size , 0 ) ; // 0 is illegal undef DO_2BITS //printf ( Fragsize %d\n , asf - > packet_frag_size ) ; } else { asf - > packet_frag_size = asf - > packet_size_left - rsize ; //printf ( Using rest %d %d %d\n , asf - > packet_frag_size , asf - > packet_size_left , rsize ) ; } if ( asf - > packet_replic_size == 1 ) { asf - > packet_multi_size = asf - > packet_frag_size ; if ( asf - > packet_multi_size > asf - > packet_size_left ) { asf - > packet_segments = 0 ; continue ; } } asf - > packet_size_left - = rsize ; //printf ( ___objsize____ %d %d rs : %d\n , asf - > packet_obj_size , asf - > packet_frag_offset , rsize ) ; if ( asf - > stream_index < 0 || s - > streams[asf - > stream_index] - > discard > = AVDISCARD_ALL || ( ! asf - > packet_key_frame & & s - > streams[asf - > stream_index] - > discard > = AVDISCARD_NONKEY ) ) { asf - > packet_time_start = 0 ; / * unhandled packet ( should not happen ) * / url_fskip ( pb , asf - > packet_frag_size ) ; asf - > packet_size_left - = asf - > packet_frag_size ; if ( asf - > stream_index < 0 ) av_log ( s , AV_LOG_ERROR , ff asf skip %d %d\n , asf - > packet_frag_size , num & 0x7f ) ; continue ; } asf - > asf_st = s - > streams[asf - > stream_index] - > priv_data ; } asf_st = asf - > asf_st ; if ( ( asf - > packet_frag_offset ! = asf_st - > frag_offset || ( asf - > packet_frag_offset & & asf - > packet_seq ! = asf_st - > seq ) ) // seq should be ignored ) { / * cannot continue current packet : free it * / // FIXME better check if packet was already allocated av_log ( s , AV_LOG_INFO , ff asf parser skips : %d - %d o : %d - %d %d %d fl : %d\n , asf_st - > pkt . size , asf - > packet_obj_size , asf - > packet_frag_offset , asf_st - > frag_offset , asf - > packet_seq , asf_st - > seq , asf - > packet_frag_size ) ; if ( asf_st - > pkt . size ) av_free_packet ( & asf_st - > pkt ) ; asf_st - > frag_offset = 0 ; if ( asf - > packet_frag_offset ! = 0 ) { url_fskip ( pb , asf - > packet_frag_size ) ; av_log ( s , AV_LOG_INFO , ff asf parser skipping %db\n , asf - > packet_frag_size ) ; asf - > packet_size_left - = asf - > packet_frag_size ; continue ; } } if ( asf - > packet_replic_size == 1 ) { // frag_offset is here used as the begining timestamp asf - > packet_frag_timestamp = asf - > packet_time_start ; asf - > packet_time_start + = asf - > packet_time_delta ; asf - > packet_obj_size = asf - > packet_frag_size = get_byte ( pb ) ; asf - > packet_size_left - - ; asf - > packet_multi_size - - ; if ( asf - > packet_multi_size < asf - > packet_obj_size ) { asf - > packet_time_start = 0 ; url_fskip ( pb , asf - > packet_multi_size ) ; asf - > packet_size_left - = asf - > packet_multi_size ; continue",1
"static int decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; TiffContext * const s = avctx - > priv_data ; AVFrame * picture = data ; AVFrame * const p = & s - > picture ; const uint8_t * orig_buf = buf , * end_buf = buf + buf_size ; unsigned off ; int id , le , ret ; int i , j , entries ; int stride ; unsigned soff , ssize ; uint8_t * dst ; //parse image header if ( end_buf - buf < 8 ) return AVERROR_INVALIDDATA ; id = AV_RL16 ( buf ) ; buf + = 2 ; if ( id == 0x4949 ) le = 1 ; else if ( id == 0x4D4D ) le = 0 ; else { av_log ( avctx , AV_LOG_ERROR , TIFF header not found\n ) ; return - 1 ; } s - > le = le ; s - > invert = 0 ; s - > compr = TIFF_RAW ; s - > fill_order = 0 ; free_geotags ( s ) ; / * free existing metadata * / av_dict_free ( & s - > picture . metadata ) ; // As TIFF 6 . 0 specification puts it An arbitrary but carefully chosen number // that further identifies the file as a TIFF file if ( tget_short ( & buf , le ) ! = 42 ) { av_log ( avctx , AV_LOG_ERROR , The answer to life , universe and everything is not correct ! \n ) ; return - 1 ; } // Reset these pointers so we can tell if they were set this frame s - > stripsizes = s - > stripdata = NULL ; / * parse image file directory * / off = tget_long ( & buf , le ) ; if ( off > = UINT_MAX - 14 || end_buf - orig_buf < off + 14 ) { av_log ( avctx , AV_LOG_ERROR , IFD offset is greater than image size\n ) ; return AVERROR_INVALIDDATA ; } buf = orig_buf + off ; entries = tget_short ( & buf , le ) ; for ( i = 0 ; i < entries ; i + + ) { if ( tiff_decode_tag ( s , orig_buf , buf , end_buf ) < 0 ) return - 1 ; buf + = 12 ; } for ( i = 0 ; i < s - > geotag_count ; i + + ) { const char * keyname = get_geokey_name ( s - > geotags[i] . key ) ; if ( ! keyname ) { av_log ( avctx , AV_LOG_WARNING , Unknown or unsupported GeoTIFF key %d\n , s - > geotags[i] . key ) ; continue ; } if ( get_geokey_type ( s - > geotags[i] . key ) ! = s - > geotags[i] . type ) { av_log ( avctx , AV_LOG_WARNING , Type of GeoTIFF key %d is wrong\n , s - > geotags[i] . key ) ; continue ; } ret = av_dict_set ( & s - > picture . metadata , keyname , s - > geotags[i] . val , 0 ) ; if ( ret < 0 ) { av_log ( avctx , AV_LOG_ERROR , Writing metadata with key ' %s ' failed\n , keyname ) ; return ret ; } } if ( ! s - > stripdata & & ! s - > stripoff ) { av_log ( avctx , AV_LOG_ERROR , Image data is missing\n ) ; return - 1 ; } / * now we have the data and may start decoding * / if ( ( ret = init_image ( s ) ) < 0 ) return ret ; if ( s - > strips == 1 & & ! s - > stripsize ) { av_log ( avctx , AV_LOG_WARNING , Image data size missing\n ) ; s - > stripsize = buf_size - s - > stripoff ; } stride = p - > linesize[0] ; dst = p - > data[0] ; for ( i = 0 ; i < s - > height ; i + = s - > rps ) { if ( s - > stripsizes ) { if ( s - > stripsizes > = end_buf ) return AVERROR_INVALIDDATA ; ssize = tget ( & s - > stripsizes , s - > sstype , s - > le ) ; } else ssize = s - > stripsize ; if ( s - > stripdata ) { if ( s - > stripdata > = end_buf ) return AVERROR_INVALIDDATA ; soff = tget ( & s - > stripdata , s - > sot , s - > le ) ; } else soff = s - > stripoff ; if ( soff > buf_size || ssize > buf_size - soff ) { av_log ( avctx , AV_LOG_ERROR , Invalid strip size/offset\n ) ; return - 1 ; } if ( tiff_unpack_strip ( s , dst , stride , orig_buf + soff , ssize , FFMIN ( s - > rps , s - > height - i ) ) < 0 ) break ; dst + = s - > rps * stride ; } if ( s - > predictor == 2 ) { dst = p - > data[0] ; soff = s - > bpp > > 3 ; ssize = s - > width * soff ; if ( s - > avctx - > pix_fmt == PIX_FMT_RGB48LE || s - > avctx - > pix_fmt == PIX_FMT_RGBA64LE ) { for ( i = 0 ; i < s - > height ; i + + ) { for ( j = soff ; j < ssize ; j + = 2 ) AV_WL16 ( dst + j , AV_RL16 ( dst + j ) + AV_RL16 ( dst + j - soff ) ) ; dst + = stride ; } } else if ( s - > avctx - > pix_fmt == PIX_FMT_RGB48BE || s - > avctx - > pix_fmt == PIX_FMT_RGBA64BE ) { for ( i = 0 ; i < s - > height ; i + + ) { for ( j = soff ; j < ssize ; j + = 2 ) AV_WB16 ( dst + j , AV_RB16 ( dst + j ) + AV_RB16 ( dst + j - soff ) ) ; dst + = stride ; } } else { for ( i = 0 ; i < s - > height ; i + + ) { for ( j = soff ; j < ssize ; j + + ) dst[j] + = dst[j - soff] ; dst + = stride ; } } } if ( s - > invert ) { dst = s - > picture . data[0] ; for ( i = 0 ; i < s - > height ; i + +",0
"void ff_limiter_init_x86 ( LimiterDSPContext * dsp , int bpp ) { int cpu_flags = av_get_cpu_flags ( ) ; if ( ARCH_X86_64 & & EXTERNAL_SSE2 ( cpu_flags ) ) { if ( bpp < = 8 ) { dsp - > limiter = ff_limiter_8bit_sse2 ; } } if ( ARCH_X86_64 & & EXTERNAL_SSE4 ( cpu_flags ) ) { if ( bpp > 8 ) { dsp - > limiter = ff_limiter_16bit_sse4 ; } } }",0
"void ff_thread_release_buffer ( AVCodecContext * avctx , ThreadFrame * f ) { PerThreadContext * p = avctx - > internal - > thread_ctx ; FrameThreadContext * fctx ; AVFrame * dst , * tmp ; FF_DISABLE_DEPRECATION_WARNINGS int can_direct_free = ! ( avctx - > active_thread_type & FF_THREAD_FRAME ) || avctx - > thread_safe_callbacks || ( if FF_API_GET_BUFFER ! avctx - > get_buffer & & endif avctx - > get_buffer2 == avcodec_default_get_buffer2 ) ; FF_ENABLE_DEPRECATION_WARNINGS if ( ! f - > f - > buf[0] ) return ; if ( avctx - > debug & FF_DEBUG_BUFFERS ) av_log ( avctx , AV_LOG_DEBUG , thread_release_buffer called on pic %p\n , f ) ; av_buffer_unref ( & f - > progress ) ; f - > owner = NULL ; if ( can_direct_free ) { av_frame_unref ( f - > f ) ; return ; } fctx = p - > parent ; pthread_mutex_lock ( & fctx - > buffer_mutex ) ; if ( p - > num_released_buffers + 1 > = INT_MAX / sizeof ( * p - > released_buffers ) ) goto fail ; tmp = av_fast_realloc ( p - > released_buffers , & p - > released_buffers_allocated , ( p - > num_released_buffers + 1 ) * sizeof ( * p - > released_buffers ) ) ; if ( ! tmp ) goto fail ; p - > released_buffers = tmp ; dst = & p - > released_buffers[p - > num_released_buffers] ; av_frame_move_ref ( dst , f - > f ) ; p - > num_released_buffers + + ; fail : pthread_mutex_unlock ( & fctx - > buffer_mutex ) ; }",1
"static void dump ( unsigned char * buf , size_t len ) { int i ; for ( i=0 ; i < len ; i + + ) { if ( ( i & 15 ) ==0 ) printf ( %04x , i ) ; printf ( %02x , buf[i] ) ; if ( ( i & 15 ) ==15 ) printf ( \n ) ; } printf ( \n ) ; }",1
"static int hls_decode_entry_wpp ( AVCodecContext * avctxt , void * input_ctb_row , int job , int self_id ) { HEVCContext * s1 = avctxt - > priv_data , * s ; HEVCLocalContext * lc ; int ctb_size = 1 < < s1 - > ps . sps - > log2_ctb_size ; int more_data = 1 ; int * ctb_row_p = input_ctb_row ; int ctb_row = ctb_row_p[job] ; int ctb_addr_rs = s1 - > sh . slice_ctb_addr_rs + ctb_row * ( ( s1 - > ps . sps - > width + ctb_size - 1 ) > > s1 - > ps . sps - > log2_ctb_size ) ; int ctb_addr_ts = s1 - > ps . pps - > ctb_addr_rs_to_ts[ctb_addr_rs] ; int thread = ctb_row % s1 - > threads_number ; int ret ; s = s1 - > sList[self_id] ; lc = s - > HEVClc ; if ( ctb_row ) { ret = init_get_bits8 ( & lc - > gb , s - > data + s - > sh . offset[ctb_row - 1] , s - > sh . size[ctb_row - 1] ) ; if ( ret < 0 ) return ret ; ff_init_cabac_decoder ( & lc - > cc , s - > data + s - > sh . offset[ ( ctb_row ) - 1] , s - > sh . size[ctb_row - 1] ) ; } while ( more_data & & ctb_addr_ts < s - > ps . sps - > ctb_size ) { int x_ctb = ( ctb_addr_rs % s - > ps . sps - > ctb_width ) < < s - > ps . sps - > log2_ctb_size ; int y_ctb = ( ctb_addr_rs / s - > ps . sps - > ctb_width ) < < s - > ps . sps - > log2_ctb_size ; hls_decode_neighbour ( s , x_ctb , y_ctb , ctb_addr_ts ) ; ff_thread_await_progress2 ( s - > avctx , ctb_row , thread , SHIFT_CTB_WPP ) ; if ( avpriv_atomic_int_get ( & s1 - > wpp_err ) ) { ff_thread_report_progress2 ( s - > avctx , ctb_row , thread , SHIFT_CTB_WPP ) ; return 0 ; } ff_hevc_cabac_init ( s , ctb_addr_ts ) ; hls_sao_param ( s , x_ctb > > s - > ps . sps - > log2_ctb_size , y_ctb > > s - > ps . sps - > log2_ctb_size ) ; more_data = hls_coding_quadtree ( s , x_ctb , y_ctb , s - > ps . sps - > log2_ctb_size , 0 ) ; if ( more_data < 0 ) { s - > tab_slice_address[ctb_addr_rs] = - 1 ; return more_data ; } ctb_addr_ts + + ; ff_hevc_save_states ( s , ctb_addr_ts ) ; ff_thread_report_progress2 ( s - > avctx , ctb_row , thread , 1 ) ; ff_hevc_hls_filters ( s , x_ctb , y_ctb , ctb_size ) ; if ( ! more_data & & ( x_ctb + ctb_size ) < s - > ps . sps - > width & & ctb_row ! = s - > sh . num_entry_point_offsets ) { return 0 ; } if ( ( x_ctb + ctb_size ) > = s - > ps . sps - > width & & ( y_ctb + ctb_size ) > = s - > ps . sps - > height ) { ff_hevc_hls_filter ( s , x_ctb , y_ctb , ctb_size ) ; ff_thread_report_progress2 ( s - > avctx , ctb_row , thread , SHIFT_CTB_WPP ) ; return ctb_addr_ts ; } ctb_addr_rs = s - > ps . pps - > ctb_addr_ts_to_rs[ctb_addr_ts] ; x_ctb + =ctb_size ; if ( x_ctb > = s - > ps . sps - > width ) { break ; } } return 0 ; }",1
"static int mpegts_raw_read_packet ( AVFormatContext * s , AVPacket * pkt ) { MpegTSContext * ts = s - > priv_data ; int ret , i ; int64_t pcr_h , next_pcr_h , pos ; int pcr_l , next_pcr_l ; uint8_t pcr_buf[12] ; uint8_t * data ; if ( av_new_packet ( pkt , TS_PACKET_SIZE ) < 0 ) return AVERROR ( ENOMEM ) ; pkt - > pos= avio_tell ( s - > pb ) ; ret = read_packet ( s , pkt - > data , ts - > raw_packet_size , & data ) ; if ( ret < 0 ) { av_free_packet ( pkt ) ; return ret ; } if ( data ! = pkt - > data ) memcpy ( pkt - > data , data , ts - > raw_packet_size ) ; finished_reading_packet ( s , ts - > raw_packet_size ) ; if ( ts - > mpeg2ts_compute_pcr ) { / * compute exact PCR for each packet * / if ( parse_pcr ( & pcr_h , & pcr_l , pkt - > data ) == 0 ) { / * we read the next PCR ( XXX : optimize it by using a bigger buffer * / pos = avio_tell ( s - > pb ) ; for ( i = 0 ; i < MAX_PACKET_READAHEAD ; i + + ) { avio_seek ( s - > pb , pos + i * ts - > raw_packet_size , SEEK_SET ) ; avio_read ( s - > pb , pcr_buf , 12 ) ; if ( parse_pcr ( & next_pcr_h , & next_pcr_l , pcr_buf ) == 0 ) { / * XXX : not precise enough * / ts - > pcr_incr = ( ( next_pcr_h - pcr_h ) * 300 + ( next_pcr_l - pcr_l ) ) / ( i + 1 ) ; break ; } } avio_seek ( s - > pb , pos , SEEK_SET ) ; / * no next PCR found : we use previous increment * / ts - > cur_pcr = pcr_h * 300 + pcr_l ; } pkt - > pts = ts - > cur_pcr ; pkt - > duration = ts - > pcr_incr ; ts - > cur_pcr + = ts - > pcr_incr ; } pkt - > stream_index = 0 ; return 0 ; }",1
"static inline void RENAME ( rgb24tobgr16 ) ( const uint8_t * src , uint8_t * dst , int src_size ) { const uint8_t * s = src ; const uint8_t * end ; const uint8_t * mm_end ; uint16_t * d = ( uint16_t * ) dst ; end = s + src_size ; __asm__ volatile ( PREFETCH %0 : : m ( * src ) : memory ) ; __asm__ volatile ( movq %0 , %%mm7 \n\t movq %1 , %%mm6 \n\t : : m ( red_16mask ) , m ( green_16mask ) ) ; mm_end = end - 11 ; while ( s < mm_end ) { __asm__ volatile ( PREFETCH 32%1 \n\t movd %1 , %%mm0 \n\t movd 3%1 , %%mm3 \n\t punpckldq 6%1 , %%mm0 \n\t punpckldq 9%1 , %%mm3 \n\t movq %%mm0 , %%mm1 \n\t movq %%mm0 , %%mm2 \n\t movq %%mm3 , %%mm4 \n\t movq %%mm3 , %%mm5 \n\t psrlq 3 , %%mm0 \n\t psrlq 3 , %%mm3 \n\t pand %2 , %%mm0 \n\t pand %2 , %%mm3 \n\t psrlq 5 , %%mm1 \n\t psrlq 5 , %%mm4 \n\t pand %%mm6 , %%mm1 \n\t pand %%mm6 , %%mm4 \n\t psrlq 8 , %%mm2 \n\t psrlq 8 , %%mm5 \n\t pand %%mm7 , %%mm2 \n\t pand %%mm7 , %%mm5 \n\t por %%mm1 , %%mm0 \n\t por %%mm4 , %%mm3 \n\t por %%mm2 , %%mm0 \n\t por %%mm5 , %%mm3 \n\t psllq 16 , %%mm3 \n\t por %%mm3 , %%mm0 \n\t MOVNTQ %%mm0 , %0 \n\t : =m ( * d ) : m ( * s ) , m ( blue_16mask ) : memory ) ; d + = 4 ; s + = 12 ; } __asm__ volatile ( SFENCE : : : memory ) ; __asm__ volatile ( EMMS : : : memory ) ; while ( s < end ) { const int b = * s + + ; const int g = * s + + ; const int r = * s + + ; * d + + = ( b > > 3 ) | ( ( g & 0xFC ) < < 3 ) | ( ( r & 0xF8 ) < < 8 ) ; } }",1
"static char * time_value_string ( char * buf , int buf_size , int64_t val , const AVRational * time_base ) { if ( val == AV_NOPTS_VALUE ) { snprintf ( buf , buf_size , N/A ) ; } else { double d = val * av_q2d ( * time_base ) ; value_string ( buf , buf_size , ( struct unit_value ) { . val . d=d , . unit=unit_second_str } ) ; } return buf ; }",0
"static void png_save2 ( const char * filename , uint32_t * bitmap , int w , int h ) { int x , y , v ; FILE * f ; char fname[40] , fname2[40] ; char command[1024] ; snprintf ( fname , 40 , %s . ppm , filename ) ; f = fopen ( fname , w ) ; if ( ! f ) { perror ( fname ) ; exit ( 1 ) ; } fprintf ( f , P6\n %d %d\n %d\n , w , h , 255 ) ; for ( y = 0 ; y < h ; y + + ) { for ( x = 0 ; x < w ; x + + ) { v = bitmap[y * w + x] ; putc ( ( v > > 16 ) & 0xff , f ) ; putc ( ( v > > 8 ) & 0xff , f ) ; putc ( ( v > > 0 ) & 0xff , f ) ; } } fclose ( f ) ; snprintf ( fname2 , 40 , %s - a . pgm , filename ) ; f = fopen ( fname2 , w ) ; if ( ! f ) { perror ( fname2 ) ; exit ( 1 ) ; } fprintf ( f , P5\n %d %d\n %d\n , w , h , 255 ) ; for ( y = 0 ; y < h ; y + + ) { for ( x = 0 ; x < w ; x + + ) { v = bitmap[y * w + x] ; putc ( ( v > > 24 ) & 0xff , f ) ; } } fclose ( f ) ; snprintf ( command , 1024 , pnmtopng - alpha %s %s > %s . png 2 > /dev/null , fname2 , fname , filename ) ; system ( command ) ; snprintf ( command , 1024 , rm %s %s , fname , fname2 ) ; system ( command ) ; }",0
"static int spdif_write_packet ( struct AVFormatContext * s , AVPacket * pkt ) { IEC61937Context * ctx = s - > priv_data ; int ret , padding ; ctx - > out_buf = pkt - > data ; ctx - > out_bytes = pkt - > size ; ctx - > length_code = FFALIGN ( pkt - > size , 2 ) < < 3 ; ctx - > use_preamble = 1 ; ctx - > extra_bswap = 0 ; ret = ctx - > header_info ( s , pkt ) ; if ( ret < 0 ) return ret ; if ( ! ctx - > pkt_offset ) return 0 ; padding = ( ctx - > pkt_offset - ctx - > use_preamble * BURST_HEADER_SIZE - ctx - > out_bytes ) & 1 ; if ( padding < 0 ) { av_log ( s , AV_LOG_ERROR , bitrate is too high\n ) ; return AVERROR ( EINVAL ) ; } if ( ctx - > use_preamble ) { put_le16 ( s - > pb , SYNCWORD1 ) ; //Pa put_le16 ( s - > pb , SYNCWORD2 ) ; //Pb put_le16 ( s - > pb , ctx - > data_type ) ; //Pc put_le16 ( s - > pb , ctx - > length_code ) ; //Pd } if ( HAVE_BIGENDIAN ctx - > extra_bswap ) { put_buffer ( s - > pb , ctx - > out_buf , ctx - > out_bytes & 1 ) ; } else { av_fast_malloc ( & ctx - > buffer , & ctx - > buffer_size , ctx - > out_bytes + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! ctx - > buffer ) return AVERROR ( ENOMEM ) ; ff_spdif_bswap_buf16 ( ( uint16_t * ) ctx - > buffer , ( uint16_t * ) ctx - > out_buf , ctx - > out_bytes > > 1 ) ; put_buffer ( s - > pb , ctx - > buffer , ctx - > out_bytes & 1 ) ; } if ( ctx - > out_bytes & 1 ) put_be16 ( s - > pb , ctx - > out_buf[ctx - > out_bytes - 1] ) ; put_nbyte ( s - > pb , 0 , padding ) ; av_log ( s , AV_LOG_DEBUG , type=%x len=%i pkt_offset=%i\n , ctx - > data_type , ctx - > out_bytes , ctx - > pkt_offset ) ; put_flush_packet ( s - > pb ) ; return 0 ; }",0
"av_cold void ff_rl_init ( RLTable * rl , uint8_t static_store[2][2 * MAX_RUN + MAX_LEVEL + 3] ) { int8_t max_level[MAX_RUN + 1] , max_run[MAX_LEVEL + 1] ; uint8_t index_run[MAX_RUN + 1] ; int last , run , level , start , end , i ; / * If table is static , we can quit if rl - > max_level[0] is not NULL * / if ( static_store & & rl - > max_level[0] ) return ; / * compute max_level[] , max_run[] and index_run[] * / for ( last = 0 ; last < 2 ; last + + ) { if ( last == 0 ) { start = 0 ; end = rl - > last ; } else { start = rl - > last ; end = rl - > n ; } memset ( max_level , 0 , MAX_RUN + 1 ) ; memset ( max_run , 0 , MAX_LEVEL + 1 ) ; memset ( index_run , rl - > n , MAX_RUN + 1 ) ; for ( i = start ; i < end ; i + + ) { run = rl - > table_run[i] ; level = rl - > table_level[i] ; if ( index_run[run] == rl - > n ) index_run[run] = i ; if ( level > max_level[run] ) max_level[run] = level ; if ( run > max_run[level] ) max_run[level] = run ; } if ( static_store ) rl - > max_level[last] = static_store[last] ; else rl - > max_level[last] = av_malloc ( MAX_RUN + 1 ) ; memcpy ( rl - > max_level[last] , max_level , MAX_RUN + 1 ) ; if ( static_store ) rl - > max_run[last] = static_store[last] + MAX_RUN + 1 ; else rl - > max_run[last] = av_malloc ( MAX_LEVEL + 1 ) ; memcpy ( rl - > max_run[last] , max_run , MAX_LEVEL + 1 ) ; if ( static_store ) rl - > index_run[last] = static_store[last] + MAX_RUN + MAX_LEVEL + 2 ; else rl - > index_run[last] = av_malloc ( MAX_RUN + 1 ) ; memcpy ( rl - > index_run[last] , index_run , MAX_RUN + 1 ) ; } }",0
"int av_opencl_init ( AVDictionary * options , AVOpenCLExternalEnv * ext_opencl_env ) { int ret = 0 ; AVDictionaryEntry * opt_build_entry ; AVDictionaryEntry * opt_platform_entry ; AVDictionaryEntry * opt_device_entry ; LOCK_OPENCL if ( ! gpu_env . init_count ) { opt_platform_entry = av_dict_get ( options , platform_idx , NULL , 0 ) ; opt_device_entry = av_dict_get ( options , device_idx , NULL , 0 ) ; / * initialize devices , context , command_queue * / gpu_env . usr_spec_dev_info . platform_idx = - 1 ; gpu_env . usr_spec_dev_info . dev_idx = - 1 ; if ( opt_platform_entry ) { gpu_env . usr_spec_dev_info . platform_idx = strtol ( opt_platform_entry - > value , NULL , 10 ) ; } if ( opt_device_entry ) { gpu_env . usr_spec_dev_info . dev_idx = strtol ( opt_device_entry - > value , NULL , 10 ) ; } ret = init_opencl_env ( & gpu_env , ext_opencl_env ) ; if ( ret < 0 ) goto end ; } / * initialize program , kernel_name , kernel_count * / opt_build_entry = av_dict_get ( options , build_options , NULL , 0 ) ; if ( opt_build_entry ) ret = compile_kernel_file ( & gpu_env , opt_build_entry - > value ) ; else ret = compile_kernel_file ( & gpu_env , NULL ) ; if ( ret < 0 ) goto end ; av_assert1 ( gpu_env . kernel_code_count > 0 ) ; gpu_env . init_count + + ; end : UNLOCK_OPENCL return ret ; }",1
"static int msf_read_header ( AVFormatContext * s ) { unsigned codec , align , size ; AVStream * st ; avio_skip ( s - > pb , 4 ) ; st = avformat_new_stream ( s , NULL ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; st - > codec - > codec_type = AVMEDIA_TYPE_AUDIO ; codec = avio_rb32 ( s - > pb ) ; st - > codec - > channels = avio_rb32 ( s - > pb ) ; if ( st - > codec - > channels < = 0 ) return AVERROR_INVALIDDATA ; size = avio_rb32 ( s - > pb ) ; st - > codec - > sample_rate = avio_rb32 ( s - > pb ) ; if ( st - > codec - > sample_rate < = 0 ) return AVERROR_INVALIDDATA ; align = avio_rb32 ( s - > pb ) ; if ( align > INT_MAX / st - > codec - > channels ) return AVERROR_INVALIDDATA ; st - > codec - > block_align = align ; switch ( codec ) { case 0 : st - > codec - > codec_id = AV_CODEC_ID_PCM_S16BE ; break ; case 3 : st - > codec - > block_align = 16 * st - > codec - > channels ; st - > codec - > codec_id = AV_CODEC_ID_ADPCM_PSX ; break ; case 7 : st - > need_parsing = AVSTREAM_PARSE_FULL_RAW ; st - > codec - > codec_id = AV_CODEC_ID_MP3 ; break ; default : avpriv_request_sample ( s , Codec %d , codec ) ; return AVERROR_PATCHWELCOME ; } st - > duration = av_get_audio_frame_duration ( st - > codec , size ) ; avio_skip ( s - > pb , 0x40 - avio_tell ( s - > pb ) ) ; avpriv_set_pts_info ( st , 64 , 1 , st - > codec - > sample_rate ) ; return 0 ; }",1
"static int32_t tag_tree_size ( uint16_t w , uint16_t h ) { uint32_t res = 0 ; while ( w > 1 || h > 1 ) { res + = w * h ; if ( res + 1 > = INT32_MAX ) return - 1 ; w = ( w + 1 ) > > 1 ; h = ( h + 1 ) > > 1 ; } return ( int32_t ) ( res + 1 ) ; }",0
"static int mov_write_packet ( AVFormatContext * s , AVPacket * pkt ) { MOVContext * mov = s - > priv_data ; ByteIOContext * pb = s - > pb ; MOVTrack * trk = & mov - > tracks[pkt - > stream_index] ; AVCodecContext * enc = trk - > enc ; unsigned int samplesInChunk = 0 ; int size= pkt - > size ; if ( url_is_streamed ( s - > pb ) ) return 0 ; / * Can ' t handle that * / if ( ! size ) return 0 ; / * Discard 0 sized packets * / if ( enc - > codec_id == CODEC_ID_AMR_NB ) { / * We must find out how many AMR blocks there are in one packet * / static uint16_t packed_size[16] = { 13 , 14 , 16 , 18 , 20 , 21 , 27 , 32 , 6 , 0 , 0 , 0 , 0 , 0 , 0 , 0 } ; int len = 0 ; while ( len < size & & samplesInChunk < 100 ) { len + = packed_size[ ( pkt - > data[len] > > 3 ) & 0x0F] ; samplesInChunk + + ; } if ( samplesInChunk > 1 ) { av_log ( s , AV_LOG_ERROR , fatal error , input is not a single packet , implement a AVParser for it\n ) ; return - 1 ; } } else if ( trk - > sampleSize ) samplesInChunk = size/trk - > sampleSize ; else samplesInChunk = 1 ; / * copy extradata if it exists * / if ( trk - > vosLen == 0 & & enc - > extradata_size > 0 ) { trk - > vosLen = enc - > extradata_size ; trk - > vosData = av_malloc ( trk - > vosLen ) ; memcpy ( trk - > vosData , enc - > extradata , trk - > vosLen ) ; } if ( enc - > codec_id == CODEC_ID_H264 & & trk - > vosLen > 0 & & * ( uint8_t * ) trk - > vosData ! = 1 ) { / * from x264 or from bytestream h264 * / / * nal reformating needed * / int ret = ff_avc_parse_nal_units ( pkt - > data , & pkt - > data , & pkt - > size ) ; if ( ret < 0 ) return ret ; assert ( pkt - > size ) ; size = pkt - > size ; } else if ( enc - > codec_id == CODEC_ID_DNXHD & & ! trk - > vosLen ) { / * copy frame header to create needed atoms * / if ( size < 640 ) return - 1 ; trk - > vosLen = 640 ; trk - > vosData = av_malloc ( trk - > vosLen ) ; memcpy ( trk - > vosData , pkt - > data , 640 ) ; } if ( ! ( trk - > entry % MOV_INDEX_CLUSTER_SIZE ) ) { trk - > cluster = av_realloc ( trk - > cluster , ( trk - > entry + MOV_INDEX_CLUSTER_SIZE ) * sizeof ( * trk - > cluster ) ) ; if ( ! trk - > cluster ) return - 1 ; } trk - > cluster[trk - > entry] . pos = url_ftell ( pb ) ; trk - > cluster[trk - > entry] . samplesInChunk = samplesInChunk ; trk - > cluster[trk - > entry] . size = size ; trk - > cluster[trk - > entry] . entries = samplesInChunk ; trk - > cluster[trk - > entry] . dts = pkt - > dts ; trk - > trackDuration = pkt - > dts - trk - > cluster[0] . dts + pkt - > duration ; if ( enc - > codec_type == CODEC_TYPE_VIDEO ) { if ( pkt - > dts ! = pkt - > pts ) trk - > hasBframes = 1 ; trk - > cluster[trk - > entry] . cts = pkt - > pts - pkt - > dts ; trk - > cluster[trk - > entry] . key_frame = ! ! ( pkt - > flags & PKT_FLAG_KEY ) ; if ( trk - > cluster[trk - > entry] . key_frame ) trk - > hasKeyframes + + ; } trk - > entry + + ; trk - > sampleCount + = samplesInChunk ; mov - > mdat_size + = size ; put_buffer ( pb , pkt - > data , size ) ; put_flush_packet ( pb ) ; return 0 ; }",0
"static inline void RENAME ( rgb24tobgr24 ) ( const uint8_t * src , uint8_t * dst , long src_size ) { unsigned i ; if COMPILE_TEMPLATE_MMX x86_reg mmx_size= 23 - src_size ; __asm__ volatile ( test %% REG_a , %% REG_a \n\t jns 2f \n\t movq MANGLE ( mask24r ) , %%mm5 \n\t movq MANGLE ( mask24g ) , %%mm6 \n\t movq MANGLE ( mask24b ) , %%mm7 \n\t . p2align 4 \n\t 1 : \n\t PREFETCH 32 ( %1 , %% REG_a ) \n\t movq ( %1 , %% REG_a ) , %%mm0 \n\t // BGR BGR BG movq ( %1 , %% REG_a ) , %%mm1 \n\t // BGR BGR BG movq 2 ( %1 , %% REG_a ) , %%mm2 \n\t // R BGR BGR B psllq 16 , %%mm0 \n\t // 00 BGR BGR pand %%mm5 , %%mm0 \n\t pand %%mm6 , %%mm1 \n\t pand %%mm7 , %%mm2 \n\t por %%mm0 , %%mm1 \n\t por %%mm2 , %%mm1 \n\t movq 6 ( %1 , %% REG_a ) , %%mm0 \n\t // BGR BGR BG MOVNTQ %%mm1 , ( %2 , %% REG_a ) \n\t // RGB RGB RG movq 8 ( %1 , %% REG_a ) , %%mm1 \n\t // R BGR BGR B movq 10 ( %1 , %% REG_a ) , %%mm2 \n\t // GR BGR BGR pand %%mm7 , %%mm0 \n\t pand %%mm5 , %%mm1 \n\t pand %%mm6 , %%mm2 \n\t por %%mm0 , %%mm1 \n\t por %%mm2 , %%mm1 \n\t movq 14 ( %1 , %% REG_a ) , %%mm0 \n\t // R BGR BGR B MOVNTQ %%mm1 , 8 ( %2 , %% REG_a ) \n\t // B RGB RGB R movq 16 ( %1 , %% REG_a ) , %%mm1 \n\t // GR BGR BGR movq 18 ( %1 , %% REG_a ) , %%mm2 \n\t // BGR BGR BG pand %%mm6 , %%mm0 \n\t pand %%mm7 , %%mm1 \n\t pand %%mm5 , %%mm2 \n\t por %%mm0 , %%mm1 \n\t por %%mm2 , %%mm1 \n\t MOVNTQ %%mm1 , 16 ( %2 , %% REG_a ) \n\t add 24 , %% REG_a \n\t js 1b \n\t 2 : \n\t : + a ( mmx_size ) : r ( src - mmx_size ) , r ( dst - mmx_size ) ) ; __asm__ volatile ( SFENCE : : : memory ) ; __asm__ volatile ( EMMS : : : memory ) ; if ( mmx_size==23 ) return ; //finished , was multiple of 8 src + = src_size ; dst + = src_size ; src_size= 23 - mmx_size ; src - = src_size ; dst - = src_size ; endif for ( i=0 ; i < src_size ; i + =3 ) { register uint8_t x ; x = src[i + 2] ; dst[i + 1] = src[i + 1] ; dst[i + 2] = src[i + 0] ; dst[i + 0] = x ; } }",0
"static inline void mix_2f_2r_to_mono ( AC3DecodeContext * ctx ) { int i ; float ( * output ) [256] = ctx - > audio_block . block_output ; for ( i = 0 ; i < 256 ; i + + ) output[1][i] = ( output[2][i] + output[3][i] + output[4][i] ) ; memset ( output[2] , 0 , sizeof ( output[2] ) ) ; memset ( output[3] , 0 , sizeof ( output[3] ) ) ; memset ( output[4] , 0 , sizeof ( output[4] ) ) ; }",0
"static void ebml_free ( EbmlSyntax * syntax , void * data ) { int i , j ; for ( i = 0 ; syntax[i] . id ; i + + ) { void * data_off = ( char * ) data + syntax[i] . data_offset ; switch ( syntax[i] . type ) { case EBML_STR : case EBML_UTF8 : av_freep ( data_off ) ; break ; case EBML_BIN : av_freep ( & ( ( EbmlBin * ) data_off ) - > data ) ; break ; case EBML_LEVEL1 : case EBML_NEST : if ( syntax[i] . list_elem_size ) { EbmlList * list = data_off ; char * ptr = list - > elem ; for ( j = 0 ; j < list - > nb_elem ; j + + , ptr + = syntax[i] . list_elem_size ) ebml_free ( syntax[i] . def . n , ptr ) ; av_freep ( & list - > elem ) ; } else ebml_free ( syntax[i] . def . n , data_off ) ; default : break ; } } }",1
"int av_thread_message_queue_alloc ( AVThreadMessageQueue * * mq , unsigned nelem , unsigned elsize ) { if HAVE_THREADS AVThreadMessageQueue * rmq ; int ret = 0 ; if ( nelem > INT_MAX / elsize ) return AVERROR ( EINVAL ) ; if ( ! ( rmq = av_mallocz ( sizeof ( * rmq ) ) ) ) return AVERROR ( ENOMEM ) ; if ( ( ret = pthread_mutex_init ( & rmq - > lock , NULL ) ) ) { av_free ( rmq ) ; return AVERROR ( ret ) ; } if ( ( ret = pthread_cond_init ( & rmq - > cond , NULL ) ) ) { pthread_mutex_destroy ( & rmq - > lock ) ; av_free ( rmq ) ; return AVERROR ( ret ) ; } if ( ! ( rmq - > fifo = av_fifo_alloc ( elsize * nelem ) ) ) { pthread_cond_destroy ( & rmq - > cond ) ; pthread_mutex_destroy ( & rmq - > lock ) ; av_free ( rmq ) ; return AVERROR ( ret ) ; } rmq - > elsize = elsize ; * mq = rmq ; return 0 ; else * mq = NULL ; return AVERROR ( ENOSYS ) ; endif / * HAVE_THREADS * / }",1
"void ff_schro_queue_free ( FFSchroQueue * queue , void ( * free_func ) ( void * ) ) { while ( queue - > p_head ) free_func ( ff_schro_queue_pop ( queue ) ) ; }",1
"static void xvid_idct_put ( uint8_t * dest , ptrdiff_t line_size , int16_t * block ) { ff_xvid_idct ( block ) ; ff_put_pixels_clamped ( block , dest , line_size ) ; }",1
"int attribute_align_arg avcodec_encode_video2 ( AVCodecContext * avctx , AVPacket * avpkt , const AVFrame * frame , int * got_packet_ptr ) { int ret ; int user_packet = ! ! avpkt - > data ; * got_packet_ptr = 0 ; if ( ! ( avctx - > codec - > capabilities & CODEC_CAP_DELAY ) & & ! frame ) { av_free_packet ( avpkt ) ; av_init_packet ( avpkt ) ; avpkt - > size = 0 ; return 0 ; } if ( av_image_check_size ( avctx - > width , avctx - > height , 0 , avctx ) ) return AVERROR ( EINVAL ) ; av_assert0 ( avctx - > codec - > encode2 ) ; ret = avctx - > codec - > encode2 ( avctx , avpkt , frame , got_packet_ptr ) ; if ( ! ret ) { if ( ! * got_packet_ptr ) avpkt - > size = 0 ; else if ( ! ( avctx - > codec - > capabilities & CODEC_CAP_DELAY ) ) avpkt - > pts = avpkt - > dts = frame - > pts ; if ( ! user_packet & & avpkt - > data ) { uint8_t * new_data = av_realloc ( avpkt - > data , avpkt - > size ) ; if ( new_data ) avpkt - > data = new_data ; } avctx - > frame_number + + ; } if ( ret < 0 || ! * got_packet_ptr ) av_free_packet ( avpkt ) ; emms_c ( ) ; return ret ; }",1
"static int get_str ( ByteIOContext * bc , char * string , int maxlen ) { int len= get_v ( bc ) ; if ( len & & maxlen ) get_buffer ( bc , string , FFMIN ( len , maxlen ) ) ; while ( len > maxlen ) { get_byte ( bc ) ; len - - ; } if ( maxlen ) string[FFMIN ( len , maxlen - 1 ) ]= 0 ; if ( maxlen == len ) return - 1 ; else return 0 ; }",1
"static int dvbsub_decode ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; DVBSubContext * ctx = avctx - > priv_data ; AVSubtitle * sub = data ; const uint8_t * p , * p_end ; int segment_type ; int page_id ; int segment_length ; ifdef DEBUG_PACKET_CONTENTS int i ; av_log ( avctx , AV_LOG_INFO , DVB sub packet : \n ) ; for ( i=0 ; i < buf_size ; i + + ) { av_log ( avctx , AV_LOG_INFO , %02x , buf[i] ) ; if ( i % 16 == 15 ) av_log ( avctx , AV_LOG_INFO , \n ) ; } if ( i % 16 ) av_log ( avctx , AV_LOG_INFO , \n ) ; endif if ( buf_size < = 2 || * buf ! = 0x0f ) return - 1 ; p = buf ; p_end = buf + buf_size ; while ( p < p_end & & * p == 0x0f ) { p + = 1 ; segment_type = * p + + ; page_id = AV_RB16 ( p ) ; p + = 2 ; segment_length = AV_RB16 ( p ) ; p + = 2 ; if ( page_id == ctx - > composition_id || page_id == ctx - > ancillary_id || ctx - > composition_id == - 1 || ctx - > ancillary_id == - 1 ) { switch ( segment_type ) { case DVBSUB_PAGE_SEGMENT : dvbsub_parse_page_segment ( avctx , p , segment_length ) ; break ; case DVBSUB_REGION_SEGMENT : dvbsub_parse_region_segment ( avctx , p , segment_length ) ; break ; case DVBSUB_CLUT_SEGMENT : dvbsub_parse_clut_segment ( avctx , p , segment_length ) ; break ; case DVBSUB_OBJECT_SEGMENT : dvbsub_parse_object_segment ( avctx , p , segment_length ) ; break ; case DVBSUB_DISPLAYDEFINITION_SEGMENT : dvbsub_parse_display_definition_segment ( avctx , p , segment_length ) ; case DVBSUB_DISPLAY_SEGMENT : * data_size = dvbsub_display_end_segment ( avctx , p , segment_length , sub ) ; break ; default : av_dlog ( avctx , Subtitling segment type 0x%x , page id %d , length %d\n , segment_type , page_id , segment_length ) ; break ; } } p + = segment_length ; } return p - buf ; }",1
"static int tag_tree_decode ( Jpeg2000DecoderContext * s , Jpeg2000TgtNode * node , int threshold ) { Jpeg2000TgtNode * stack[30] ; int sp = - 1 , curval = 0 ; while ( node & & ! node - > vis ) { stack[ + + sp] = node ; node = node - > parent ; } if ( node ) curval = node - > val ; else curval = stack[sp] - > val ; while ( curval < threshold & & sp > = 0 ) { if ( curval < stack[sp] - > val ) curval = stack[sp] - > val ; while ( curval < threshold ) { int ret ; if ( ( ret = get_bits ( s , 1 ) ) > 0 ) { stack[sp] - > vis + + ; break ; } else if ( ! ret ) curval + + ; else return ret ; } stack[sp] - > val = curval ; sp - - ; } return curval ; }",1
"static int output_configure ( AACContext * ac , uint8_t layout_map[MAX_ELEM_ID * 4][3] , int tags , enum OCStatus oc_type , int get_new_frame ) { AVCodecContext * avctx = ac - > avctx ; int i , channels = 0 , ret ; uint64_t layout = 0 ; uint8_t id_map[TYPE_END][MAX_ELEM_ID] = { { 0 } } ; uint8_t type_counts[TYPE_END] = { 0 } ; if ( ac - > oc[1] . layout_map ! = layout_map ) { memcpy ( ac - > oc[1] . layout_map , layout_map , tags * sizeof ( layout_map[0] ) ) ; ac - > oc[1] . layout_map_tags = tags ; for ( i = 0 ; i < tags ; i + + ) { int type = layout_map[i][0] ; int id = layout_map[i][1] ; id_map[type][id] = type_counts[type] + + ; // Try to sniff a reasonable channel order , otherwise output the // channels in the order the PCE declared them . if ( avctx - > request_channel_layout ! = AV_CH_LAYOUT_NATIVE ) layout = sniff_channel_order ( layout_map , tags ) ; for ( i = 0 ; i < tags ; i + + ) { int type = layout_map[i][0] ; int id = layout_map[i][1] ; int iid = id_map[type][id] ; int position = layout_map[i][2] ; // Allocate or free elements depending on if they are in the // current program configuration . ret = che_configure ( ac , position , type , iid , & channels ) ; if ( ret < 0 ) return ret ; ac - > tag_che_map[type][id] = ac - > che[type][iid] ; if ( ac - > oc[1] . m4ac . ps == 1 & & channels == 2 ) { if ( layout == AV_CH_FRONT_CENTER ) { layout = AV_CH_FRONT_LEFT|AV_CH_FRONT_RIGHT ; } else { layout = 0 ; if ( layout ) avctx - > channel_layout = layout ; ac - > oc[1] . channel_layout = layout ; avctx - > channels = ac - > oc[1] . channels = channels ; ac - > oc[1] . status = oc_type ; if ( get_new_frame ) { if ( ( ret = frame_configure_elements ( ac - > avctx ) ) < 0 ) return ret ; return 0 ;",1
"static int decompress_i ( AVCodecContext * avctx , uint32_t * dst , int linesize ) { SCPRContext * s = avctx - > priv_data ; GetByteContext * gb = & s - > gb ; int cx = 0 , cx1 = 0 , k = 0 , clr = 0 ; int run , r , g , b , off , y = 0 , x = 0 , ret ; const int cxshift = s - > cxshift ; unsigned lx , ly , ptype ; reinit_tables ( s ) ; bytestream2_skip ( gb , 2 ) ; init_rangecoder ( & s - > rc , gb ) ; while ( k < avctx - > width + 1 ) { ret = decode_unit ( s , & s - > pixel_model[0][cx + cx1] , 400 , & r ) ; if ( ret < 0 ) return ret ; cx1 = ( cx < < 6 ) & 0xFC0 ; cx = r > > cxshift ; ret = decode_unit ( s , & s - > pixel_model[1][cx + cx1] , 400 , & g ) ; if ( ret < 0 ) return ret ; cx1 = ( cx < < 6 ) & 0xFC0 ; cx = g > > cxshift ; ret = decode_unit ( s , & s - > pixel_model[2][cx + cx1] , 400 , & b ) ; if ( ret < 0 ) return ret ; cx1 = ( cx < < 6 ) & 0xFC0 ; cx = b > > cxshift ; ret = decode_value ( s , s - > run_model[0] , 256 , 400 , & run ) ; if ( ret < 0 ) return ret ; clr = ( b < < 16 ) + ( g < < 8 ) + r ; k + = run ; while ( run - - > 0 ) { dst[y * linesize + x] = clr ; lx = x ; ly = y ; x + + ; if ( x > = avctx - > width ) { x = 0 ; y + + ; } } } off = - linesize - 1 ; ptype = 0 ; while ( x < avctx - > width & & y < avctx - > height ) { ret = decode_value ( s , s - > op_model[ptype] , 6 , 1000 , & ptype ) ; if ( ret < 0 ) return ret ; if ( ptype == 0 ) { ret = decode_unit ( s , & s - > pixel_model[0][cx + cx1] , 400 , & r ) ; if ( ret < 0 ) return ret ; cx1 = ( cx < < 6 ) & 0xFC0 ; cx = r > > cxshift ; ret = decode_unit ( s , & s - > pixel_model[1][cx + cx1] , 400 , & g ) ; if ( ret < 0 ) return ret ; cx1 = ( cx < < 6 ) & 0xFC0 ; cx = g > > cxshift ; ret = decode_unit ( s , & s - > pixel_model[2][cx + cx1] , 400 , & b ) ; if ( ret < 0 ) return ret ; cx1 = ( cx < < 6 ) & 0xFC0 ; cx = b > > cxshift ; clr = ( b < < 16 ) + ( g < < 8 ) + r ; } if ( ptype > 5 ) return AVERROR_INVALIDDATA ; ret = decode_value ( s , s - > run_model[ptype] , 256 , 400 , & run ) ; if ( ret < 0 ) return ret ; switch ( ptype ) { case 0 : while ( run - - > 0 ) { dst[y * linesize + x] = clr ; lx = x ; ly = y ; x + + ; if ( x > = avctx - > width ) { x = 0 ; y + + ; } } break ; case 1 : while ( run - - > 0 ) { dst[y * linesize + x] = dst[ly * linesize + lx] ; lx = x ; ly = y ; x + + ; if ( x > = avctx - > width ) { x = 0 ; y + + ; } } clr = dst[ly * linesize + lx] ; break ; case 2 : while ( run - - > 0 ) { clr = dst[y * linesize + x + off + 1] ; dst[y * linesize + x] = clr ; lx = x ; ly = y ; x + + ; if ( x > = avctx - > width ) { x = 0 ; y + + ; } } break ; case 4 : while ( run - - > 0 ) { uint8_t * odst = ( uint8_t * ) dst ; r = odst[ ( ly * linesize + lx ) * 4] + odst[ ( ( y * linesize + x ) + off ) * 4 + 4] - odst[ ( ( y * linesize + x ) + off ) * 4] ; g = odst[ ( ly * linesize + lx ) * 4 + 1] + odst[ ( ( y * linesize + x ) + off ) * 4 + 5] - odst[ ( ( y * linesize + x ) + off ) * 4 + 1] ; b = odst[ ( ly * linesize + lx ) * 4 + 2] + odst[ ( ( y * linesize + x ) + off ) * 4 + 6] - odst[ ( ( y * linesize + x ) + off ) * 4 + 2] ; clr = ( ( b & 0xFF ) < < 16 ) + ( ( g & 0xFF ) < < 8 ) + ( r & 0xFF ) ; dst[y * linesize + x] = clr ; lx = x ; ly = y ; x + + ; if ( x > = avctx - > width ) { x = 0 ; y + + ; } } break ; case 5 : while ( run - - > 0 ) { clr = dst[y * linesize + x + off] ; dst[y * linesize + x] = clr ; lx = x ; ly = y ; x + + ; if ( x > = avctx - > width ) { x = 0 ; y + + ; } } break ; } if ( avctx - > bits_per_coded_sample == 16 ) { cx1 = ( clr & 0xFF00 ) > > 2 ; cx = ( clr & 0xFFFFFF ) > > 16 ; } else { cx1 = ( clr & 0xFC00 ) > > 4 ; cx = ( clr & 0xFFFFFF ) > > 18 ; } } return 0 ; }",0
"AVInputFormat * av_find_input_format ( const char * short_name ) { AVInputFormat * fmt = NULL ; while ( ( fmt = av_iformat_next ( fmt ) ) ) if ( match_format ( short_name , fmt - > name ) ) return fmt ; return NULL ; }",0
"static inline int parse_nal_units ( AVCodecParserContext * s , const uint8_t * buf , int buf_size , AVCodecContext * avctx ) { HEVCParserContext * ctx = s - > priv_data ; HEVCContext * h = & ctx - > h ; GetBitContext * gb ; SliceHeader * sh = & h - > sh ; HEVCParamSets * ps = & h - > ps ; HEVCSEIContext * sei = & h - > sei ; int is_global = buf == avctx - > extradata ; int i , ret ; if ( ! h - > HEVClc ) h - > HEVClc = av_mallocz ( sizeof ( HEVCLocalContext ) ) ; if ( ! h - > HEVClc ) return AVERROR ( ENOMEM ) ; gb = & h - > HEVClc - > gb ; / * set some sane default values * / s - > pict_type = AV_PICTURE_TYPE_I ; s - > key_frame = 0 ; s - > picture_structure = AV_PICTURE_STRUCTURE_UNKNOWN ; h - > avctx = avctx ; ff_hevc_reset_sei ( sei ) ; ret = ff_h2645_packet_split ( & ctx - > pkt , buf , buf_size , avctx , 0 , 0 , AV_CODEC_ID_HEVC , 1 ) ; if ( ret < 0 ) return ret ; for ( i = 0 ; i < ctx - > pkt . nb_nals ; i + + ) { H2645NAL * nal = & ctx - > pkt . nals[i] ; int num = 0 , den = 0 ; h - > nal_unit_type = nal - > type ; h - > temporal_id = nal - > temporal_id ; * gb = nal - > gb ; switch ( h - > nal_unit_type ) { case HEVC_NAL_VPS : ff_hevc_decode_nal_vps ( gb , avctx , ps ) ; break ; case HEVC_NAL_SPS : ff_hevc_decode_nal_sps ( gb , avctx , ps , 1 ) ; break ; case HEVC_NAL_PPS : ff_hevc_decode_nal_pps ( gb , avctx , ps ) ; break ; case HEVC_NAL_SEI_PREFIX : case HEVC_NAL_SEI_SUFFIX : ff_hevc_decode_nal_sei ( gb , avctx , sei , ps , h - > nal_unit_type ) ; break ; case HEVC_NAL_TRAIL_N : case HEVC_NAL_TRAIL_R : case HEVC_NAL_TSA_N : case HEVC_NAL_TSA_R : case HEVC_NAL_STSA_N : case HEVC_NAL_STSA_R : case HEVC_NAL_RADL_N : case HEVC_NAL_RADL_R : case HEVC_NAL_RASL_N : case HEVC_NAL_RASL_R : case HEVC_NAL_BLA_W_LP : case HEVC_NAL_BLA_W_RADL : case HEVC_NAL_BLA_N_LP : case HEVC_NAL_IDR_W_RADL : case HEVC_NAL_IDR_N_LP : case HEVC_NAL_CRA_NUT : if ( is_global ) { av_log ( avctx , AV_LOG_ERROR , Invalid NAL unit : %d\n , h - > nal_unit_type ) ; return AVERROR_INVALIDDATA ; } sh - > first_slice_in_pic_flag = get_bits1 ( gb ) ; s - > picture_structure = h - > sei . picture_timing . picture_struct ; s - > field_order = h - > sei . picture_timing . picture_struct ; if ( IS_IRAP ( h ) ) { s - > key_frame = 1 ; sh - > no_output_of_prior_pics_flag = get_bits1 ( gb ) ; } sh - > pps_id = get_ue_golomb ( gb ) ; if ( sh - > pps_id > = HEVC_MAX_PPS_COUNT || ! ps - > pps_list[sh - > pps_id] ) { av_log ( avctx , AV_LOG_ERROR , PPS id out of range : %d\n , sh - > pps_id ) ; return AVERROR_INVALIDDATA ; } ps - > pps = ( HEVCPPS * ) ps - > pps_list[sh - > pps_id] - > data ; if ( ps - > pps - > sps_id > = HEVC_MAX_SPS_COUNT || ! ps - > sps_list[ps - > pps - > sps_id] ) { av_log ( avctx , AV_LOG_ERROR , SPS id out of range : %d\n , ps - > pps - > sps_id ) ; return AVERROR_INVALIDDATA ; } if ( ps - > sps ! = ( HEVCSPS * ) ps - > sps_list[ps - > pps - > sps_id] - > data ) { ps - > sps = ( HEVCSPS * ) ps - > sps_list[ps - > pps - > sps_id] - > data ; ps - > vps = ( HEVCVPS * ) ps - > vps_list[ps - > sps - > vps_id] - > data ; } s - > coded_width = ps - > sps - > width ; s - > coded_height = ps - > sps - > height ; s - > width = ps - > sps - > output_width ; s - > height = ps - > sps - > output_height ; s - > format = ps - > sps - > pix_fmt ; avctx - > profile = ps - > sps - > ptl . general_ptl . profile_idc ; avctx - > level = ps - > sps - > ptl . general_ptl . level_idc ; if ( ps - > vps - > vps_timing_info_present_flag ) { num = ps - > vps - > vps_num_units_in_tick ; den = ps - > vps - > vps_time_scale ; } else if ( ps - > sps - > vui . vui_timing_info_present_flag ) { num = ps - > sps - > vui . vui_num_units_in_tick ; den = ps - > sps - > vui . vui_time_scale ; } if ( num ! = 0 & & den ! = 0 ) av_reduce ( & avctx - > framerate . den , & avctx - > framerate . num , num , den , 1 < < 30 ) ; if ( ! sh - > first_slice_in_pic_flag ) { int slice_address_length ; if ( ps - > pps - > dependent_slice_segments_enabled_flag ) sh - > dependent_slice_segment_flag = get_bits1 ( gb ) ; else sh - > dependent_slice_segment_flag = 0 ; slice_address_length = av_ceil_log2_c ( ps - > sps - > ctb_width * ps - > sps - > ctb_height ) ; sh - > slice_segment_addr = get_bitsz ( gb , slice_address_length ) ; if ( sh - > slice_segment_addr > = ps - > sps - > ctb_width * ps - > sps - > ctb_height ) { av_log ( avctx , AV_LOG_ERROR , Invalid slice segment address : %u . \n , sh - > slice_segment_addr ) ; return AVERROR_INVALIDDATA ; } } else sh - > dependent_slice_segment_flag = 0 ; if ( sh - > dependent_slice_segment_flag ) break ; for ( i = 0 ; i < ps - > pps - > num_extra_slice_header_bits ; i + + ) skip_bits ( gb , 1 ) ; // slice_reserved_undetermined_flag[] sh - > slice_type = get_ue_golomb ( gb ) ; if ( ! ( sh - > slice_type == HEVC_SLICE_I || sh - > slice_type == HEVC_SLICE_P || sh - > slice_type == HEVC_SLICE_B ) ) { av_log ( avctx , AV_LOG_ERROR , Unknown slice type : %d . \n , sh - > slice_type ) ; return AVERROR_INVALIDDATA ; } s - > pict_type = sh - > slice_type == HEVC_SLICE_B ? AV_PICTURE_TYPE_B : sh - > slice_type == HEVC_SLICE_P ? AV_PICTURE_TYPE_P : AV_PICTURE_TYPE_I ; if ( ps - > pps - > output_flag_present_flag ) sh - > pic_output_flag = get_bits1 ( gb ) ; if ( ps - > sps - > separate_colour_plane_flag ) sh - > colour_plane_id = get_bits",0
"void ff_put_h264_qpel4_mc22_msa ( uint8_t * dst , const uint8_t * src , ptrdiff_t stride ) { avc_luma_mid_4w_msa ( src - ( 2 * stride ) - 2 , stride , dst , stride , 4 ) ; }",0
"static int read_sbr_single_channel_element ( AACContext * ac , SpectralBandReplication * sbr , GetBitContext * gb ) { int ret ; if ( get_bits1 ( gb ) ) // bs_data_extra skip_bits ( gb , 4 ) ; // bs_reserved if ( read_sbr_grid ( ac , sbr , gb , & sbr - > data[0] ) ) return - 1 ; read_sbr_dtdf ( sbr , gb , & sbr - > data[0] ) ; read_sbr_invf ( sbr , gb , & sbr - > data[0] ) ; read_sbr_envelope ( sbr , gb , & sbr - > data[0] , 0 ) ; if ( ( ret = read_sbr_noise ( ac , sbr , gb , & sbr - > data[0] , 0 ) ) < 0 ) return ret ; if ( ( sbr - > data[0] . bs_add_harmonic_flag = get_bits1 ( gb ) ) ) get_bits1_vector ( gb , sbr - > data[0] . bs_add_harmonic , sbr - > n[1] ) ; return 0 ; }",0
"int ff_h2645_packet_split ( H2645Packet * pkt , const uint8_t * buf , int length , void * logctx , int is_nalff , int nal_length_size , enum AVCodecID codec_id ) { int consumed , ret = 0 ; const uint8_t * next_avc = buf + ( is_nalff ? 0 : length ) ; pkt - > nb_nals = 0 ; while ( length > = 4 ) { H2645NAL * nal ; int extract_length = 0 ; int skip_trailing_zeros = 1 ; / * * Only parse an AVC1 length field if one is expected at the current * buffer position . There are unfortunately streams with multiple * NAL units covered by the length field . Those NAL units are delimited * by Annex B start code prefixes . ff_h2645_extract_rbsp ( ) detects it * correctly and consumes only the first NAL unit . The additional NAL * units are handled here in the Annex B parsing code . * / if ( buf == next_avc ) { int i ; for ( i = 0 ; i < nal_length_size ; i + + ) extract_length = ( extract_length < < 8 ) | buf[i] ; if ( extract_length > length ) { av_log ( logctx , AV_LOG_ERROR , Invalid NAL unit size . \n ) ; return AVERROR_INVALIDDATA ; } buf + = nal_length_size ; length - = nal_length_size ; // keep track of the next AVC1 length field next_avc = buf + extract_length ; } else { / * * expected to return immediately except for streams with mixed * NAL unit coding * / int buf_index = find_next_start_code ( buf , next_avc ) ; buf + = buf_index ; length - = buf_index ; / * * break if an AVC1 length field is expected at the current buffer * position * / if ( buf == next_avc ) continue ; if ( length > 0 ) { extract_length = length ; } else if ( pkt - > nb_nals == 0 ) { av_log ( logctx , AV_LOG_ERROR , No NAL unit found\n ) ; return AVERROR_INVALIDDATA ; } else { break ; } } if ( pkt - > nals_allocated < pkt - > nb_nals + 1 ) { int new_size = pkt - > nals_allocated + 1 ; H2645NAL * tmp = av_realloc_array ( pkt - > nals , new_size , sizeof ( * tmp ) ) ; if ( ! tmp ) return AVERROR ( ENOMEM ) ; pkt - > nals = tmp ; memset ( pkt - > nals + pkt - > nals_allocated , 0 , ( new_size - pkt - > nals_allocated ) * sizeof ( * tmp ) ) ; pkt - > nals_allocated = new_size ; } nal = & pkt - > nals[pkt - > nb_nals + + ] ; consumed = ff_h2645_extract_rbsp ( buf , extract_length , nal ) ; if ( consumed < 0 ) return consumed ; / * see commit 3566042a0 * / if ( consumed < length - 3 & & buf[consumed] == 0x00 & & buf[consumed + 1] == 0x00 & & buf[consumed + 2] == 0x01 & & buf[consumed + 3] == 0xE0 ) skip_trailing_zeros = 0 ; nal - > size_bits = get_bit_length ( nal , skip_trailing_zeros ) ; ret = init_get_bits ( & nal - > gb , nal - > data , nal - > size_bits ) ; if ( ret < 0 ) return ret ; if ( codec_id == AV_CODEC_ID_HEVC ) ret = hevc_parse_nal_header ( nal , logctx ) ; else ret = h264_parse_nal_header ( nal , logctx ) ; if ( ret < = 0 ) { if ( ret < 0 ) { av_log ( logctx , AV_LOG_ERROR , Invalid NAL unit %d , skipping . \n , nal - > type ) ; } pkt - > nb_nals - - ; } buf + = consumed ; length - = consumed ; } return 0 ; }",0
"static int output_packet ( AVInputStream * ist , int ist_index , AVOutputStream * * ost_table , int nb_ostreams , const AVPacket * pkt ) { AVFormatContext * os ; AVOutputStream * ost ; uint8_t * ptr ; int len , ret , i ; uint8_t * data_buf ; int data_size , got_picture ; AVFrame picture ; short samples[AVCODEC_MAX_AUDIO_FRAME_SIZE / 2] ; void * buffer_to_free ; if ( pkt & & pkt - > pts ! = AV_NOPTS_VALUE ) { //FIXME seems redundant , as libavformat does this too ist - > next_pts = ist - > pts = pkt - > dts ; } else { ist - > pts = ist - > next_pts ; } if ( pkt == NULL ) { / * EOF handling * / ptr = NULL ; len = 0 ; goto handle_eof ; } len = pkt - > size ; ptr = pkt - > data ; while ( len > 0 ) { handle_eof : / * decode the packet if needed * / data_buf = NULL ; / * fail safe * / data_size = 0 ; if ( ist - > decoding_needed ) { switch ( ist - > st - > codec . codec_type ) { case CODEC_TYPE_AUDIO : / * XXX : could avoid copy if PCM 16 bits with same endianness as CPU * / ret = avcodec_decode_audio ( & ist - > st - > codec , samples , & data_size , ptr , len ) ; if ( ret < 0 ) goto fail_decode ; ptr + = ret ; len - = ret ; / * Some bug in mpeg audio decoder gives * / / * data_size < 0 , it seems they are overflows * / if ( data_size < = 0 ) { / * no audio frame * / continue ; } data_buf = ( uint8_t * ) samples ; ist - > next_pts + = ( ( int64_t ) AV_TIME_BASE/2 * data_size ) / ( ist - > st - > codec . sample_rate * ist - > st - > codec . channels ) ; break ; case CODEC_TYPE_VIDEO : data_size = ( ist - > st - > codec . width * ist - > st - > codec . height * 3 ) / 2 ; / * XXX : allocate picture correctly * / avcodec_get_frame_defaults ( & picture ) ; ret = avcodec_decode_video ( & ist - > st - > codec , & picture , & got_picture , ptr , len ) ; ist - > st - > quality= picture . quality ; if ( ret < 0 ) goto fail_decode ; if ( ! got_picture ) { / * no picture yet * / goto discard_packet ; } if ( ist - > st - > codec . frame_rate_base ! = 0 ) { ist - > next_pts + = ( ( int64_t ) AV_TIME_BASE * ist - > st - > codec . frame_rate_base ) / ist - > st - > codec . frame_rate ; } len = 0 ; break ; default : goto fail_decode ; } } else { data_buf = ptr ; data_size = len ; ret = len ; len = 0 ; } buffer_to_free = NULL ; if ( ist - > st - > codec . codec_type == CODEC_TYPE_VIDEO ) { pre_process_video_frame ( ist , ( AVPicture * ) & picture , & buffer_to_free ) ; } / * frame rate emulation * / if ( ist - > st - > codec . rate_emu ) { int64_t pts = av_rescale ( ( int64_t ) ist - > frame * ist - > st - > codec . frame_rate_base , 1000000 , ist - > st - > codec . frame_rate ) ; int64_t now = av_gettime ( ) - ist - > start ; if ( pts > now ) usleep ( pts - now ) ; ist - > frame + + ; } if 0 / * mpeg PTS deordering : if it is a P or I frame , the PTS is the one of the next displayed one * / / * XXX : add mpeg4 too ? * / if ( ist - > st - > codec . codec_id == CODEC_ID_MPEG1VIDEO ) { if ( ist - > st - > codec . pict_type ! = B_TYPE ) { int64_t tmp ; tmp = ist - > last_ip_pts ; ist - > last_ip_pts = ist - > frac_pts . val ; ist - > frac_pts . val = tmp ; } } endif / * if output time reached then transcode raw format , encode packets and output them * / if ( start_time == 0 || ist - > pts > = start_time ) for ( i=0 ; i < nb_ostreams ; i + + ) { int frame_size ; ost = ost_table[i] ; if ( ost - > source_index == ist_index ) { os = output_files[ost - > file_index] ; if 0 printf ( %d : got pts=%0 . 3f %0 . 3f\n , i , ( double ) pkt - > pts / AV_TIME_BASE , ( ( double ) ist - > pts / AV_TIME_BASE ) - ( ( double ) ost - > st - > pts . val * ost - > time_base . num / ost - > time_base . den ) ) ; endif / * set the input output pts pairs * / ost - > sync_ipts = ( double ) ist - > pts / AV_TIME_BASE ; if ( ost - > encoding_needed ) { switch ( ost - > st - > codec . codec_type ) { case CODEC_TYPE_AUDIO : do_audio_out ( os , ost , ist , data_buf , data_size ) ; break ; case CODEC_TYPE_VIDEO : / * find an audio stream for synchro * / { int i ; AVOutputStream * audio_sync , * ost1 ; audio_sync = NULL ; for ( i=0 ; i < nb_ostreams ; i + + ) { ost1 = ost_table[i] ; if ( ost1 - > file_index == ost - > file_index & & ost1 - > st - > codec . codec_type == CODEC_TYPE_AUDIO ) { audio_sync = ost1 ; break ; } } do_video_out ( os , ost , ist , & picture , & frame_size , audio_sync ) ; video_size + = frame_size ; if ( do_vstats & & frame_size ) do_video_stats ( os , ost , frame_size ) ; } break ; default : av_abort ( ) ; } } else { AVFrame avframe ; //FIXME/XXX remove this AVPacket opkt ; av_init_packet ( & opkt ) ; / * no reencoding needed : output the packet directly * / / * force the input stream PTS * / avcodec_get_frame_defaults ( & avframe ) ; ost - > st - > codec . coded_frame= & avframe ; avframe . key_frame = pkt - > flags & PKT_FLAG_KEY ; if ( ost - > st - > codec . codec_type == CODEC_TYPE_AUDIO ) audio_size + = data_size ; else if ( ost - >",0
"static void count_frame_bits ( AC3EncodeContext * s ) { AC3EncOptions * opt = & s - > options ; int blk , ch ; int frame_bits = 0 ; / * header * / if ( s - > eac3 ) { / * coupling * / if ( s - > channel_mode > AC3_CHMODE_MONO ) { frame_bits + + ; for ( blk = 1 ; blk < AC3_MAX_BLOCKS ; blk + + ) { AC3Block * block = & s - > blocks[blk] ; frame_bits + + ; if ( block - > new_cpl_strategy ) frame_bits + + ; } } / * coupling exponent strategy * / for ( blk = 0 ; blk < AC3_MAX_BLOCKS ; blk + + ) frame_bits + = 2 * s - > blocks[blk] . cpl_in_use ; } else { if ( opt - > audio_production_info ) frame_bits + = 7 ; if ( s - > bitstream_id == 6 ) { if ( opt - > extended_bsi_1 ) frame_bits + = 14 ; if ( opt - > extended_bsi_2 ) frame_bits + = 14 ; } } / * audio blocks * / for ( blk = 0 ; blk < AC3_MAX_BLOCKS ; blk + + ) { AC3Block * block = & s - > blocks[blk] ; / * coupling strategy * / if ( ! s - > eac3 ) frame_bits + + ; if ( block - > new_cpl_strategy ) { if ( ! s - > eac3 ) frame_bits + + ; if ( block - > cpl_in_use ) { if ( s - > eac3 ) frame_bits + + ; if ( ! s - > eac3 || s - > channel_mode ! = AC3_CHMODE_STEREO ) frame_bits + = s - > fbw_channels ; if ( s - > channel_mode == AC3_CHMODE_STEREO ) frame_bits + + ; frame_bits + = 4 + 4 ; if ( s - > eac3 ) frame_bits + + ; else frame_bits + = s - > num_cpl_subbands - 1 ; } } / * coupling coordinates * / if ( block - > cpl_in_use ) { for ( ch = 1 ; ch < = s - > fbw_channels ; ch + + ) { if ( block - > channel_in_cpl[ch] ) { if ( ! s - > eac3 || block - > new_cpl_coords ! = 2 ) frame_bits + + ; if ( block - > new_cpl_coords ) { frame_bits + = 2 ; frame_bits + = ( 4 + 4 ) * s - > num_cpl_bands ; } } } } / * stereo rematrixing * / if ( s - > channel_mode == AC3_CHMODE_STEREO ) { if ( ! s - > eac3 || blk > 0 ) frame_bits + + ; if ( s - > blocks[blk] . new_rematrixing_strategy ) frame_bits + = block - > num_rematrixing_bands ; } / * bandwidth codes & gain range * / for ( ch = 1 ; ch < = s - > fbw_channels ; ch + + ) { if ( s - > exp_strategy[ch][blk] ! = EXP_REUSE ) { if ( ! block - > channel_in_cpl[ch] ) frame_bits + = 6 ; frame_bits + = 2 ; } } / * coupling exponent strategy * / if ( ! s - > eac3 & & block - > cpl_in_use ) frame_bits + = 2 ; / * snr offsets and fast gain codes * / if ( ! s - > eac3 ) { frame_bits + + ; if ( block - > new_snr_offsets ) frame_bits + = 6 + ( s - > channels + block - > cpl_in_use ) * ( 4 + 3 ) ; } / * coupling leak info * / if ( block - > cpl_in_use ) { if ( ! s - > eac3 || block - > new_cpl_leak ! = 2 ) frame_bits + + ; if ( block - > new_cpl_leak ) frame_bits + = 3 + 3 ; } } s - > frame_bits = s - > frame_bits_fixed + frame_bits ; }",0
const char * swscale_configuration ( void ) { return FFMPEG_CONFIGURATION ; },0
"static void load_module ( const char * filename ) { void * dll ; void ( * init_func ) ( void ) ; dll = dlopen ( filename , RTLD_NOW ) ; if ( ! dll ) { fprintf ( stderr , Could not load module ' %s ' - %s\n , filename , dlerror ( ) ) ; } init_func = dlsym ( dll , ffserver_module_init ) ; if ( ! init_func ) { fprintf ( stderr , %s : init function ' ffserver_module_init ( ) ' not found\n , filename ) ; dlclose ( dll ) ; } init_func ( ) ; }",1
"DVDemuxContext * avpriv_dv_init_demux ( AVFormatContext * s ) { DVDemuxContext * c ; c = av_mallocz ( sizeof ( DVDemuxContext ) ) ; if ( ! c ) return NULL ; c - > vst = avformat_new_stream ( s , NULL ) ; if ( ! c - > vst ) { av_free ( c ) ; return NULL ; } c - > sys = NULL ; c - > fctx = s ; memset ( c - > ast , 0 , sizeof ( c - > ast ) ) ; c - > ach = 0 ; c - > frames = 0 ; c - > abytes = 0 ; c - > vst - > codec - > codec_type = AVMEDIA_TYPE_VIDEO ; c - > vst - > codec - > codec_id = CODEC_ID_DVVIDEO ; c - > vst - > codec - > bit_rate = 25000000 ; c - > vst - > start_time = 0 ; return c ; }",0
"int ff_read_riff_info ( AVFormatContext * s , int64_t size ) { int64_t start , end , cur ; AVIOContext * pb = s - > pb ; start = avio_tell ( pb ) ; end = start + size ; while ( ( cur = avio_tell ( pb ) ) > = 0 & & cur < = end - 8 / * = tag + size * / ) { uint32_t chunk_code ; int64_t chunk_size ; char key[5] = { 0 } ; char * value ; chunk_code = avio_rl32 ( pb ) ; chunk_size = avio_rl32 ( pb ) ; if ( chunk_size > end || end - chunk_size < cur || chunk_size == UINT_MAX ) { av_log ( s , AV_LOG_ERROR , too big INFO subchunk\n ) ; return AVERROR_INVALIDDATA ; } chunk_size + = ( chunk_size & 1 ) ; value = av_malloc ( chunk_size + 1 ) ; if ( ! value ) { av_log ( s , AV_LOG_ERROR , out of memory , unable to read INFO tag\n ) ; return AVERROR ( ENOMEM ) ; } AV_WL32 ( key , chunk_code ) ; if ( avio_read ( pb , value , chunk_size ) ! = chunk_size ) { av_freep ( key ) ; av_freep ( value ) ; av_log ( s , AV_LOG_ERROR , premature end of file while reading INFO tag\n ) ; return AVERROR_INVALIDDATA ; } value[chunk_size] = 0 ; av_dict_set ( & s - > metadata , key , value , AV_DICT_DONT_STRDUP_VAL ) ; } return 0 ; }",1
"static int h261_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; H261Context * h = avctx - > priv_data ; MpegEncContext * s = & h - > s ; int ret ; AVFrame * pict = data ; av_dlog ( avctx , * * * * * frame %d size=%d\n , avctx - > frame_number , buf_size ) ; av_dlog ( avctx , bytes=%x %x %x %x\n , buf[0] , buf[1] , buf[2] , buf[3] ) ; s - > flags = avctx - > flags ; s - > flags2 = avctx - > flags2 ; h - > gob_start_code_skipped = 0 ; retry : init_get_bits ( & s - > gb , buf , buf_size * 8 ) ; if ( ! s - > context_initialized ) // we need the IDCT permutaton for reading a custom matrix if ( ff_MPV_common_init ( s ) < 0 ) return - 1 ; ret = h261_decode_picture_header ( h ) ; / * skip if the header was thrashed * / if ( ret < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , header damaged\n ) ; return - 1 ; } if ( s - > width ! = avctx - > coded_width || s - > height ! = avctx - > coded_height ) { ParseContext pc = s - > parse_context ; // FIXME move this demuxing hack to libavformat s - > parse_context . buffer = 0 ; ff_MPV_common_end ( s ) ; s - > parse_context = pc ; } if ( ! s - > context_initialized ) { ret = ff_set_dimensions ( avctx , s - > width , s - > height ) ; if ( ret < 0 ) return ret ; goto retry ; } // for skipping the frame s - > current_picture . f . pict_type = s - > pict_type ; s - > current_picture . f . key_frame = s - > pict_type == AV_PICTURE_TYPE_I ; if ( ( avctx - > skip_frame > = AVDISCARD_NONREF & & s - > pict_type == AV_PICTURE_TYPE_B ) || ( avctx - > skip_frame > = AVDISCARD_NONKEY & & s - > pict_type ! = AV_PICTURE_TYPE_I ) || avctx - > skip_frame > = AVDISCARD_ALL ) return get_consumed_bytes ( s , buf_size ) ; if ( ff_MPV_frame_start ( s , avctx ) < 0 ) return - 1 ; ff_mpeg_er_frame_start ( s ) ; / * decode each macroblock * / s - > mb_x = 0 ; s - > mb_y = 0 ; while ( h - > gob_number < ( s - > mb_height == 18 ? 12 : 5 ) ) { if ( h261_resync ( h ) < 0 ) break ; h261_decode_gob ( h ) ; } ff_MPV_frame_end ( s ) ; assert ( s - > current_picture . f . pict_type == s - > current_picture_ptr - > f . pict_type ) ; assert ( s - > current_picture . f . pict_type == s - > pict_type ) ; if ( ( ret = av_frame_ref ( pict , & s - > current_picture_ptr - > f ) ) < 0 ) return ret ; ff_print_debug_info ( s , s - > current_picture_ptr ) ; * got_frame = 1 ; return get_consumed_bytes ( s , buf_size ) ; }",1
"static int aasc_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; AascContext * s = avctx - > priv_data ; int compr , i , stride , ret ; if ( ( ret = ff_reget_buffer ( avctx , s - > frame ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , reget_buffer ( ) failed\n ) ; return ret ; } compr = AV_RL32 ( buf ) ; buf + = 4 ; buf_size - = 4 ; switch ( compr ) { case 0 : stride = ( avctx - > width * 3 + 3 ) & 3 ; if ( buf_size < stride * avctx - > height ) for ( i = avctx - > height - 1 ; i > = 0 ; i - - ) { memcpy ( s - > frame - > data[0] + i * s - > frame - > linesize[0] , buf , avctx - > width * 3 ) ; buf + = stride ; } break ; case 1 : bytestream2_init ( & s - > gb , buf , buf_size ) ; ff_msrle_decode ( avctx , ( AVPicture * ) s - > frame , 8 , & s - > gb ) ; break ; default : av_log ( avctx , AV_LOG_ERROR , Unknown compression type %d\n , compr ) ; } * got_frame = 1 ; if ( ( ret = av_frame_ref ( data , s - > frame ) ) < 0 ) return ret ; / * report that the buffer was completely consumed * / return buf_size ; }",1
"static av_always_inline void filter_common ( uint8_t * p , ptrdiff_t stride , int is4tap ) { LOAD_PIXELS int a , f1 , f2 ; const uint8_t * cm = ff_crop_tab + MAX_NEG_CROP ; a = 3 * ( q0 - p0 ) ; if ( is4tap ) a + = clip_int8 ( p1 - q1 ) ; a = clip_int8 ( a ) ; // We deviate from the spec here with c ( a + 3 ) > > 3 // since that ' s what libvpx does . f1 = FFMIN ( a + 4 , 127 ) > > 3 ; f2 = FFMIN ( a + 3 , 127 ) > > 3 ; // Despite what the spec says , we do need to clamp here to // be bitexact with libvpx . p[ - 1 * stride] = cm[p0 + f2] ; p[ 0 * stride] = cm[q0 - f1] ; // only used for _inner on blocks without high edge variance if ( ! is4tap ) { a = ( f1 + 1 ) > > 1 ; p[ - 2 * stride] = cm[p1 + a] ; p[ 1 * stride] = cm[q1 - a] ; } }",1
"static int mkv_write_track ( AVFormatContext * s , MatroskaMuxContext * mkv , int i , AVIOContext * pb , int default_stream_exists ) { AVStream * st = s - > streams[i] ; AVCodecContext * codec = st - > codec ; ebml_master subinfo , track ; int native_id = 0 ; int qt_id = 0 ; int bit_depth = av_get_bits_per_sample ( codec - > codec_id ) ; int sample_rate = codec - > sample_rate ; int output_sample_rate = 0 ; int display_width_div = 1 ; int display_height_div = 1 ; int j , ret ; AVDictionaryEntry * tag ; // ms precision is the de - facto standard timescale for mkv files avpriv_set_pts_info ( st , 64 , 1 , 1000 ) ; if ( codec - > codec_type == AVMEDIA_TYPE_ATTACHMENT ) { mkv - > have_attachments = 1 ; return 0 ; } if ( ! bit_depth & & codec - > codec_id ! = AV_CODEC_ID_ADPCM_G726 ) bit_depth = av_get_bytes_per_sample ( codec - > sample_fmt ) < < 3 ; if ( ! bit_depth ) bit_depth = codec - > bits_per_coded_sample ; if ( codec - > codec_id == AV_CODEC_ID_AAC ) get_aac_sample_rates ( s , codec , & sample_rate , & output_sample_rate ) ; track = start_ebml_master ( pb , MATROSKA_ID_TRACKENTRY , 0 ) ; put_ebml_uint ( pb , MATROSKA_ID_TRACKNUMBER , mkv - > is_dash ? mkv - > dash_track_number : i + 1 ) ; put_ebml_uint ( pb , MATROSKA_ID_TRACKUID , mkv - > is_dash ? mkv - > dash_track_number : i + 1 ) ; put_ebml_uint ( pb , MATROSKA_ID_TRACKFLAGLACING , 0 ) ; // no lacing ( yet ) if ( ( tag = av_dict_get ( st - > metadata , title , NULL , 0 ) ) ) put_ebml_string ( pb , MATROSKA_ID_TRACKNAME , tag - > value ) ; tag = av_dict_get ( st - > metadata , language , NULL , 0 ) ; if ( mkv - > mode ! = MODE_WEBM || codec - > codec_id ! = AV_CODEC_ID_WEBVTT ) { put_ebml_string ( pb , MATROSKA_ID_TRACKLANGUAGE , tag & & tag - > value ? tag - > value : und ) ; } else if ( tag & & tag - > value ) { put_ebml_string ( pb , MATROSKA_ID_TRACKLANGUAGE , tag - > value ) ; } // The default value for TRACKFLAGDEFAULT is 1 , so add element // if we need to clear it . if ( default_stream_exists & & ! ( st - > disposition & AV_DISPOSITION_DEFAULT ) ) put_ebml_uint ( pb , MATROSKA_ID_TRACKFLAGDEFAULT , ! ! ( st - > disposition & AV_DISPOSITION_DEFAULT ) ) ; if ( st - > disposition & AV_DISPOSITION_FORCED ) put_ebml_uint ( pb , MATROSKA_ID_TRACKFLAGFORCED , 1 ) ; if ( mkv - > mode == MODE_WEBM & & codec - > codec_id == AV_CODEC_ID_WEBVTT ) { const char * codec_id ; if ( st - > disposition & AV_DISPOSITION_CAPTIONS ) { codec_id = D_WEBVTT/CAPTIONS ; native_id = MATROSKA_TRACK_TYPE_SUBTITLE ; } else if ( st - > disposition & AV_DISPOSITION_DESCRIPTIONS ) { codec_id = D_WEBVTT/DESCRIPTIONS ; native_id = MATROSKA_TRACK_TYPE_METADATA ; } else if ( st - > disposition & AV_DISPOSITION_METADATA ) { codec_id = D_WEBVTT/METADATA ; native_id = MATROSKA_TRACK_TYPE_METADATA ; } else { codec_id = D_WEBVTT/SUBTITLES ; native_id = MATROSKA_TRACK_TYPE_SUBTITLE ; } put_ebml_string ( pb , MATROSKA_ID_CODECID , codec_id ) ; } else { // look for a codec ID string specific to mkv to use , // if none are found , use AVI codes for ( j = 0 ; ff_mkv_codec_tags[j] . id ! = AV_CODEC_ID_NONE ; j + + ) { if ( ff_mkv_codec_tags[j] . id == codec - > codec_id ) { put_ebml_string ( pb , MATROSKA_ID_CODECID , ff_mkv_codec_tags[j] . str ) ; native_id = 1 ; break ; } } } if ( codec - > codec_type == AVMEDIA_TYPE_AUDIO & & codec - > delay & & codec - > codec_id == AV_CODEC_ID_OPUS ) { // mkv - > tracks[i] . ts_offset = av_rescale_q ( codec - > delay , // ( AVRational ) { 1 , codec - > sample_rate } , // st - > time_base ) ; put_ebml_uint ( pb , MATROSKA_ID_CODECDELAY , av_rescale_q ( codec - > delay , ( AVRational ) { 1 , codec - > sample_rate } , ( AVRational ) { 1 , 1000000000 } ) ) ; } if ( codec - > codec_id == AV_CODEC_ID_OPUS ) { put_ebml_uint ( pb , MATROSKA_ID_SEEKPREROLL , OPUS_SEEK_PREROLL ) ; } if ( mkv - > mode == MODE_WEBM & & ! ( codec - > codec_id == AV_CODEC_ID_VP8 || codec - > codec_id == AV_CODEC_ID_VP9 || codec - > codec_id == AV_CODEC_ID_OPUS || codec - > codec_id == AV_CODEC_ID_VORBIS || codec - > codec_id == AV_CODEC_ID_WEBVTT ) ) { av_log ( s , AV_LOG_ERROR , Only VP8 or VP9 video and Vorbis or Opus audio and WebVTT subtitles are supported for WebM . \n ) ; return AVERROR ( EINVAL ) ; } switch ( codec - > codec_type ) { case AVMEDIA_TYPE_VIDEO : put_ebml_uint ( pb , MATROSKA_ID_TRACKTYPE , MATROSKA_TRACK_TYPE_VIDEO ) ; if ( st - > avg_frame_rate . num > 0 & & st - > avg_frame_rate . den > 0 & & 1 . 0/av_q2d ( st - > avg_frame_rate ) > av_q2d ( codec - > time_base ) ) put_ebml_uint ( pb , MATROSKA_ID_TRACKDEFAULTDURATION , 1E9 / av_q2d ( st - > avg_frame_rate ) ) ; else put_ebml_uint ( pb , MATROSKA_ID_TRACKDEFAULTDURATION , av_q2d ( codec - > time_base ) * 1E9 ) ; if ( ! native_id & & ff_codec_get_tag ( ff_codec_movvideo_tags , codec - > codec_id ) & & ( ! ff_codec_get_tag ( ff_codec_bmp_tags , codec - > codec_id ) || codec - > codec_id == AV_CODEC_ID_SVQ1 || codec - > codec_id == AV_CODEC_ID_SVQ3 || codec - > codec_id == AV_CODEC_ID_CINEPAK ) ) qt_id = 1 ; if ( qt_id ) put_ebml_string ( pb , MATROSKA_ID_CODECID , V_QUICKTIME ) ; else if ( ! native_id ) { // if there is no mkv - specific codec ID , use VFW mode put_ebml_string ( pb , MATROSKA_ID_CODECID , V_MS/VFW/FOURCC ) ; mkv - > tracks[i] . write_dts = 1 ; } subinfo = start_ebml_master ( pb , MATROSKA_ID_TRACKVIDEO , 0 ) ; // XXX : interlace flag ? put_ebml_uint ( pb , MATROSKA_ID_VIDEOPIXELWIDTH , codec - > width ) ; put_ebml_uint ( pb , MATROSKA_ID_VIDEOPIXELHEIGHT , codec - > height ) ; if ( ( tag = av_dict_get ( st - > metadata , stereo_mode , NULL , 0 ) ) || ( tag = av_dict_get ( s - > metadata , stereo_mode , NULL , 0 ) ) ) { int st_mode = MATROSKA_VIDEO_STEREO_MODE_COUNT ; for ( j=0 ; j < MATROSKA_VIDEO_STEREO_MODE_COUNT ; j + + ) if ( ! strcmp ( tag - > value , ff_matroska_video_stereo_mode[j] ) ) { st_mode = j ; break ; } if ( mkv_write_stereo_mode ( s , pb , st_mode , mkv - > mode ) < 0 ) return AVERROR ( EINVAL ) ; switch ( st_mode ) { case 1 : case 8 : case 9 : case 11 : display_width_div = 2",0
static int ffm_probe ( AVProbeData * p ) { if ( p - > buf_size > = 4 & & p - > buf[0] == ' F ' & & p - > buf[1] == ' F ' & & p - > buf[2] == ' M ' & & p - > buf[3] == ' 1 ' ) return AVPROBE_SCORE_MAX + 1 ; return 0 ; },0
"static inline void RENAME ( duplicate ) ( uint8_t src[] , int stride ) { if TEMPLATE_PP_MMX __asm__ volatile ( movq ( %0 ) , %%mm0 \n\t add %1 , %0 \n\t movq %%mm0 , ( %0 ) \n\t movq %%mm0 , ( %0 , %1 ) \n\t movq %%mm0 , ( %0 , %1 , 2 ) \n\t : + r ( src ) : r ( ( x86_reg ) - stride ) ) ; else int i ; uint8_t * p=src ; for ( i=0 ; i < 3 ; i + + ) { p - = stride ; memcpy ( p , src , 8 ) ; } endif }",1
"static void compute_pkt_fields ( AVFormatContext * s , AVStream * st , AVCodecParserContext * pc , AVPacket * pkt , int64_t next_dts , int64_t next_pts ) { int num , den , presentation_delayed , delay , i ; int64_t offset ; AVRational duration ; int onein_oneout = st - > codec - > codec_id ! = AV_CODEC_ID_H264 & & st - > codec - > codec_id ! = AV_CODEC_ID_HEVC ; if ( s - > flags & AVFMT_FLAG_NOFILLIN ) return ; if ( st - > codec - > codec_type == AVMEDIA_TYPE_VIDEO & & pkt - > dts ! = AV_NOPTS_VALUE ) { if ( pkt - > dts == pkt - > pts & & st - > last_dts_for_order_check ! = AV_NOPTS_VALUE ) { if ( st - > last_dts_for_order_check < = pkt - > dts ) { st - > dts_ordered + + ; } else { av_log ( s , st - > dts_misordered ? AV_LOG_DEBUG : AV_LOG_WARNING , DTS % PRIi64 < % PRIi64 out of order\n , pkt - > dts , st - > last_dts_for_order_check ) ; st - > dts_misordered + + ; } if ( st - > dts_ordered + st - > dts_misordered > 250 ) { st - > dts_ordered > > = 1 ; st - > dts_misordered > > = 1 ; } } st - > last_dts_for_order_check = pkt - > dts ; if ( st - > dts_ordered < 8 * st - > dts_misordered & & pkt - > dts == pkt - > pts ) pkt - > dts = AV_NOPTS_VALUE ; } if ( ( s - > flags & AVFMT_FLAG_IGNDTS ) & & pkt - > pts ! = AV_NOPTS_VALUE ) pkt - > dts = AV_NOPTS_VALUE ; if ( pc & & pc - > pict_type == AV_PICTURE_TYPE_B & & ! st - > codec - > has_b_frames ) //FIXME Set low_delay = 0 when has_b_frames = 1 st - > codec - > has_b_frames = 1 ; / * do we have a video B - frame ? * / delay = st - > codec - > has_b_frames ; presentation_delayed = 0 ; / * XXX : need has_b_frame , but cannot get it if the codec is * not initialized * / if ( delay & & pc & & pc - > pict_type ! = AV_PICTURE_TYPE_B ) presentation_delayed = 1 ; if ( pkt - > pts ! = AV_NOPTS_VALUE & & pkt - > dts ! = AV_NOPTS_VALUE & & st - > pts_wrap_bits < 63 & & pkt - > dts - ( 1LL < < ( st - > pts_wrap_bits - 1 ) ) > pkt - > pts ) { if ( is_relative ( st - > cur_dts ) || pkt - > dts - ( 1LL < < ( st - > pts_wrap_bits - 1 ) ) > st - > cur_dts ) { pkt - > dts - = 1LL < < st - > pts_wrap_bits ; } else pkt - > pts + = 1LL < < st - > pts_wrap_bits ; } / * Some MPEG - 2 in MPEG - PS lack dts ( issue 171 / input_file . mpg ) . * We take the conservative approach and discard both . * Note : If this is misbehaving for an H . 264 file , then possibly * presentation_delayed is not set correctly . * / if ( delay == 1 & & pkt - > dts == pkt - > pts & & pkt - > dts ! = AV_NOPTS_VALUE & & presentation_delayed ) { av_log ( s , AV_LOG_DEBUG , invalid dts/pts combination % PRIi64 \n , pkt - > dts ) ; if ( strcmp ( s - > iformat - > name , mov , mp4 , m4a , 3gp , 3g2 , mj2 ) & & strcmp ( s - > iformat - > name , flv ) ) // otherwise we discard correct timestamps for vc1 - wmapro . ism pkt - > dts = AV_NOPTS_VALUE ; } duration = av_mul_q ( ( AVRational ) { pkt - > duration , 1 } , st - > time_base ) ; if ( pkt - > duration == 0 ) { ff_compute_frame_duration ( s , & num , & den , st , pc , pkt ) ; if ( den & & num ) { duration = ( AVRational ) { num , den } ; pkt - > duration = av_rescale_rnd ( 1 , num * ( int64_t ) st - > time_base . den , den * ( int64_t ) st - > time_base . num , AV_ROUND_DOWN ) ; } } if ( pkt - > duration ! = 0 & & ( s - > packet_buffer || s - > parse_queue ) ) update_initial_durations ( s , st , pkt - > stream_index , pkt - > duration ) ; / * Correct timestamps with byte offset if demuxers only have timestamps * on packet boundaries * / if ( pc & & st - > need_parsing == AVSTREAM_PARSE_TIMESTAMPS & & pkt - > size ) { / * this will estimate bitrate based on this frame ' s duration and size * / offset = av_rescale ( pc - > offset , pkt - > duration , pkt - > size ) ; if ( pkt - > pts ! = AV_NOPTS_VALUE ) pkt - > pts + = offset ; if ( pkt - > dts ! = AV_NOPTS_VALUE ) pkt - > dts + = offset ; } / * This may be redundant , but it should not hurt . * / if ( pkt - > dts ! = AV_NOPTS_VALUE & & pkt - > pts ! = AV_NOPTS_VALUE & & pkt - > pts > pkt - > dts ) presentation_delayed = 1 ; av_dlog ( NULL , IN delayed : %d pts : %s , dts : %s cur_dts : %s st : %d pc : %p duration : %d delay : %d onein_oneout : %d\n , presentation_delayed , av_ts2str ( pkt - > pts ) , av_ts2str ( pkt - > dts ) , av_ts2str ( st - > cur_dts ) , pkt - > stream_index , pc , pkt - > duration , delay , onein_oneout ) ; / * Interpolate PTS and DTS if they are not present . We skip H264 * currently because delay and has_b_frames are not reliably set . * / if ( ( delay == 0 || ( delay == 1 & & pc ) ) & & onein_oneout ) { if ( presentation_delayed ) { / * DTS = decompression timestamp * / / * PTS = presentation timestamp * / if ( pkt - > dts == AV_NOPTS_VALUE ) pkt - > dts = st - > last_IP_pts ; update_initial_timestamps ( s , pkt - > stream_index , pkt - > dts , pkt - > pts , pkt ) ; if ( pkt - > dts == AV_NOPTS_VALUE ) pkt - > dts = st - > cur_dts ;",1
"static inline int vertClassify_altivec ( uint8_t src[] , int stride , PPContext * c ) { / * this code makes no assumption on src or stride . One could remove the recomputation of the perm vector by assuming ( stride % 16 ) == 0 , unfortunately this is not always true . * / DECLARE_ALIGNED ( 16 , short , data ) [8] = { ( ( c - > nonBQP * c - > ppMode . baseDcDiff ) > > 8 ) + 1 , data[0] * 2 + 1 , c - > QP * 2 , c - > QP * 4 } ; int numEq ; uint8_t * src2 = src ; vector signed short v_dcOffset ; vector signed short v2QP ; vector unsigned short v4QP ; vector unsigned short v_dcThreshold ; const int properStride = ( stride % 16 ) ; const int srcAlign = ( ( unsigned long ) src2 % 16 ) ; const int two_vectors = ( ( srcAlign > 8 ) || properStride ) ? 1 : 0 ; const vector signed int zero = vec_splat_s32 ( 0 ) ; const vector signed short mask = vec_splat_s16 ( 1 ) ; vector signed int v_numEq = vec_splat_s32 ( 0 ) ; vector signed short v_data = vec_ld ( 0 , data ) ; vector signed short v_srcAss0 , v_srcAss1 , v_srcAss2 , v_srcAss3 , v_srcAss4 , v_srcAss5 , v_srcAss6 , v_srcAss7 ; //FIXME avoid this mess if possible register int j0 = 0 , j1 = stride , j2 = 2 * stride , j3 = 3 * stride , j4 = 4 * stride , j5 = 5 * stride , j6 = 6 * stride , j7 = 7 * stride ; vector unsigned char v_srcA0 , v_srcA1 , v_srcA2 , v_srcA3 , v_srcA4 , v_srcA5 , v_srcA6 , v_srcA7 ; v_dcOffset = vec_splat ( v_data , 0 ) ; v_dcThreshold = ( vector unsigned short ) vec_splat ( v_data , 1 ) ; v2QP = vec_splat ( v_data , 2 ) ; v4QP = ( vector unsigned short ) vec_splat ( v_data , 3 ) ; src2 + = stride * 4 ; define LOAD_LINE ( i ) \ { \ vector unsigned char perm i = vec_lvsl ( j i , src2 ) ; \ vector unsigned char v_srcA2 i ; \ vector unsigned char v_srcA1 i = vec_ld ( j i , src2 ) ; \ if ( two_vectors ) \ v_srcA2 i = vec_ld ( j i + 16 , src2 ) ; \ v_srcA i = \ vec_perm ( v_srcA1 i , v_srcA2 i , perm i ) ; \ v_srcAss i = \ ( vector signed short ) vec_mergeh ( ( vector signed char ) zero , \ ( vector signed char ) v_srcA i ) ; } define LOAD_LINE_ALIGNED ( i ) \ v_srcA i = vec_ld ( j i , src2 ) ; \ v_srcAss i = \ ( vector signed short ) vec_mergeh ( ( vector signed char ) zero , \ ( vector signed char ) v_srcA i ) / * Special - casing the aligned case is worthwhile , as all calls from * the ( transposed ) horizontable deblocks will be aligned , in addition * to the naturally aligned vertical deblocks . * / if ( properStride & & srcAlign ) { LOAD_LINE_ALIGNED ( 0 ) ; LOAD_LINE_ALIGNED ( 1 ) ; LOAD_LINE_ALIGNED ( 2 ) ; LOAD_LINE_ALIGNED ( 3 ) ; LOAD_LINE_ALIGNED ( 4 ) ; LOAD_LINE_ALIGNED ( 5 ) ; LOAD_LINE_ALIGNED ( 6 ) ; LOAD_LINE_ALIGNED ( 7 ) ; } else { LOAD_LINE ( 0 ) ; LOAD_LINE ( 1 ) ; LOAD_LINE ( 2 ) ; LOAD_LINE ( 3 ) ; LOAD_LINE ( 4 ) ; LOAD_LINE ( 5 ) ; LOAD_LINE ( 6 ) ; LOAD_LINE ( 7 ) ; } undef LOAD_LINE undef LOAD_LINE_ALIGNED define ITER ( i , j ) \ const vector signed short v_diff i = \ vec_sub ( v_srcAss i , v_srcAss j ) ; \ const vector signed short v_sum i = \ vec_add ( v_diff i , v_dcOffset ) ; \ const vector signed short v_comp i = \ ( vector signed short ) vec_cmplt ( ( vector unsigned short ) v_sum i , \ v_dcThreshold ) ; \ const vector signed short v_part i = vec_and ( mask , v_comp i ) ; { ITER ( 0 , 1 ) ITER ( 1 , 2 ) ITER ( 2 , 3 ) ITER ( 3 , 4 ) ITER ( 4 , 5 ) ITER ( 5 , 6 ) ITER ( 6 , 7 ) v_numEq = vec_sum4s ( v_part0 , v_numEq ) ; v_numEq = vec_sum4s ( v_part1 , v_numEq ) ; v_numEq = vec_sum4s ( v_part2 , v_numEq ) ; v_numEq = vec_sum4s ( v_part3 , v_numEq ) ; v_numEq = vec_sum4s ( v_part4 , v_numEq ) ; v_numEq = vec_sum4s ( v_part5 , v_numEq ) ; v_numEq = vec_sum4s ( v_part6 , v_numEq ) ; } undef ITER v_numEq = vec_sums ( v_numEq , zero ) ; v_numEq = vec_splat ( v_numEq , 3 ) ; vec_ste ( v_numEq , 0 , & numEq ) ; if ( numEq > c - > ppMode . flatnessThreshold ) { const vector unsigned char mmoP1 = ( const vector unsigned char ) { 0x1f , 0x1f , 0x1f , 0x1f , 0x1f , 0x1f , 0x1f , 0x1f , 0x00 , 0x01 , 0x12 , 0x13 , 0x08 , 0x09 , 0x1A , 0x1B } ; const vector unsigned char mmoP2 = ( const vector unsigned char ) { 0x04 , 0x05 , 0x16 , 0x17 , 0x0C , 0x0D , 0x1E , 0x1F , 0x1f , 0x1f , 0x1f , 0x1f , 0x1f , 0x1f , 0x1f , 0x1f } ; const vector unsigned char mmoP = ( const vector unsigned char ) vec_lvsl ( 8 , ( unsigned char * ) 0 ) ; vector signed short mmoL1 = vec_perm ( v_srcAss0 , v_srcAss2 , mmoP1 ) ; vector signed short mmoL2 = vec_perm ( v_srcAss4 , v_srcAss6 , mmoP2 ) ; vector signed short mmoL = vec_perm ( mmoL1 , mmoL2 , mmoP ) ; vector signed short mmoR1 = vec_perm ( v_srcAss5 , v_srcAss7 , mmoP1 ) ; vector signed short mmoR2 = vec_perm ( v_srcAss1 , v_srcAss3 , mmoP2 ) ; vector signed short mmoR = vec_perm ( mmoR1 , mmoR2 , mmoP ) ; vector signed short mmoDiff = vec_sub ( mmoL , mmoR ) ; vector unsigned short mmoSum = ( vector unsigned short ) vec_add ( mmoDiff , v2QP ) ; if ( vec_any_gt ( mmoSum , v4QP ) ) return 0 ; else return 1 ; } else return 2 ; }",1
"static int vaapi_vc1_start_frame ( AVCodecContext * avctx , av_unused const uint8_t * buffer , av_unused uint32_t size ) { VC1Context * const v = avctx - > priv_data ; MpegEncContext * const s = & v - > s ; struct vaapi_context * const vactx = avctx - > hwaccel_context ; VAPictureParameterBufferVC1 * pic_param ; av_dlog ( avctx , vaapi_vc1_start_frame ( ) \n ) ; vactx - > slice_param_size = sizeof ( VASliceParameterBufferVC1 ) ; / * Fill in VAPictureParameterBufferVC1 * / pic_param = ff_vaapi_alloc_pic_param ( vactx , sizeof ( VAPictureParameterBufferVC1 ) ) ; if ( ! pic_param ) return - 1 ; pic_param - > forward_reference_picture = VA_INVALID_ID ; pic_param - > backward_reference_picture = VA_INVALID_ID ; pic_param - > inloop_decoded_picture = VA_INVALID_ID ; pic_param - > sequence_fields . value = 0 ; / * reset all bits * / pic_param - > sequence_fields . bits . pulldown = v - > broadcast ; pic_param - > sequence_fields . bits . interlace = v - > interlace ; pic_param - > sequence_fields . bits . tfcntrflag = v - > tfcntrflag ; pic_param - > sequence_fields . bits . finterpflag = v - > finterpflag ; pic_param - > sequence_fields . bits . psf = v - > psf ; pic_param - > sequence_fields . bits . multires = v - > multires ; pic_param - > sequence_fields . bits . overlap = v - > overlap ; pic_param - > sequence_fields . bits . syncmarker = v - > resync_marker ; pic_param - > sequence_fields . bits . rangered = v - > rangered ; pic_param - > sequence_fields . bits . max_b_frames = s - > avctx - > max_b_frames ; if VA_CHECK_VERSION ( 0 , 32 , 0 ) pic_param - > sequence_fields . bits . profile = v - > profile ; endif pic_param - > coded_width = s - > avctx - > coded_width ; pic_param - > coded_height = s - > avctx - > coded_height ; pic_param - > entrypoint_fields . value = 0 ; / * reset all bits * / pic_param - > entrypoint_fields . bits . broken_link = v - > broken_link ; pic_param - > entrypoint_fields . bits . closed_entry = v - > closed_entry ; pic_param - > entrypoint_fields . bits . panscan_flag = v - > panscanflag ; pic_param - > entrypoint_fields . bits . loopfilter = s - > loop_filter ; pic_param - > conditional_overlap_flag = v - > condover ; pic_param - > fast_uvmc_flag = v - > fastuvmc ; pic_param - > range_mapping_fields . value = 0 ; / * reset all bits * / pic_param - > range_mapping_fields . bits . luma_flag = v - > range_mapy_flag ; pic_param - > range_mapping_fields . bits . luma = v - > range_mapy ; pic_param - > range_mapping_fields . bits . chroma_flag = v - > range_mapuv_flag ; pic_param - > range_mapping_fields . bits . chroma = v - > range_mapuv ; pic_param - > b_picture_fraction = v - > bfraction_lut_index ; pic_param - > cbp_table = v - > cbpcy_vlc ? v - > cbpcy_vlc - ff_vc1_cbpcy_p_vlc : 0 ; pic_param - > mb_mode_table = 0 ; / * XXX : interlaced frame * / pic_param - > range_reduction_frame = v - > rangeredfrm ; pic_param - > rounding_control = v - > rnd ; pic_param - > post_processing = v - > postproc ; pic_param - > picture_resolution_index = v - > respic ; pic_param - > luma_scale = v - > lumscale ; pic_param - > luma_shift = v - > lumshift ; pic_param - > picture_fields . value = 0 ; / * reset all bits * / pic_param - > picture_fields . bits . picture_type = vc1_get_PTYPE ( v ) ; pic_param - > picture_fields . bits . frame_coding_mode = v - > fcm ; pic_param - > picture_fields . bits . top_field_first = v - > tff ; pic_param - > picture_fields . bits . is_first_field = v - > fcm == 0 ; / * XXX : interlaced frame * / pic_param - > picture_fields . bits . intensity_compensation = v - > mv_mode == MV_PMODE_INTENSITY_COMP ; pic_param - > raw_coding . value = 0 ; / * reset all bits * / pic_param - > raw_coding . flags . mv_type_mb = v - > mv_type_is_raw ; pic_param - > raw_coding . flags . direct_mb = v - > dmb_is_raw ; pic_param - > raw_coding . flags . skip_mb = v - > skip_is_raw ; pic_param - > raw_coding . flags . field_tx = 0 ; / * XXX : interlaced frame * / pic_param - > raw_coding . flags . forward_mb = 0 ; / * XXX : interlaced frame * / pic_param - > raw_coding . flags . ac_pred = v - > acpred_is_raw ; pic_param - > raw_coding . flags . overflags = v - > overflg_is_raw ; pic_param - > bitplane_present . value = 0 ; / * reset all bits * / pic_param - > bitplane_present . flags . bp_mv_type_mb = vc1_has_MVTYPEMB_bitplane ( v ) ; pic_param - > bitplane_present . flags . bp_direct_mb = vc1_has_DIRECTMB_bitplane ( v ) ; pic_param - > bitplane_present . flags . bp_skip_mb = vc1_has_SKIPMB_bitplane ( v ) ; pic_param - > bitplane_present . flags . bp_field_tx = 0 ; / * XXX : interlaced frame * / pic_param - > bitplane_present . flags . bp_forward_mb = 0 ; / * XXX : interlaced frame * / pic_param - > bitplane_present . flags . bp_ac_pred = vc1_has_ACPRED_bitplane ( v ) ; pic_param - > bitplane_present . flags . bp_overflags = vc1_has_OVERFLAGS_bitplane ( v ) ; pic_param - > reference_fields . value = 0 ; / * reset all bits * / pic_param - > reference_fields . bits . reference_distance_flag = v - > refdist_flag ; pic_param - > reference_fields . bits . reference_distance = 0 ; / * XXX : interlaced frame * / pic_param - > reference_fields . bits . num_reference_pictures = 0 ; / * XXX : interlaced frame * / pic_param - > reference_fields . bits . reference_field_pic_indicator = 0 ; / * XXX : interlaced frame * / pic_param - > mv_fields . value = 0 ; / * reset all bits * / pic_param - > mv_fields . bits . mv_mode = vc1_get_MVMODE ( v ) ; pic_param - > mv_fields . bits . mv_mode2 = vc1_get_MVMODE2 ( v ) ; pic_param - > mv_fields . bits . mv_table = s - > mv_table_index ; pic_param - > mv_fields . bits . two_mv_block_pattern_table = 0 ; / * XXX : interlaced frame * / pic_param - > mv_fields . bits . four_mv_switch = 0 ; / * XXX : interlaced frame * / pic_param - > mv_fields . bits . four_mv_block_pattern_table = 0 ; / * XXX : interlaced frame * / pic_param - > mv_fields . bits . extended_mv_flag = v - > extended_mv ; pic_param - > mv_fields . bits . extended_mv_range = v - > mvrange ; pic_param - > mv_fields . bits . extended_dmv_flag = v - > extended_dmv ; pic_param - > mv_fields . bits . extended_dmv_range =",1
"static int dxv_decompress_raw ( AVCodecContext * avctx ) { DXVContext * ctx = avctx - > priv_data ; GetByteContext * gbc = & ctx - > gbc ; bytestream2_get_buffer ( gbc , ctx - > tex_data , ctx - > tex_size ) ; return 0 ; }",1
"static av_cold void dsputil_init_sse2 ( DSPContext * c , AVCodecContext * avctx , int mm_flags ) { if HAVE_SSE2_INLINE const int high_bit_depth = avctx - > bits_per_raw_sample > 8 ; if ( ! high_bit_depth & & avctx - > idct_algo == FF_IDCT_XVIDMMX ) { c - > idct_put = ff_idct_xvid_sse2_put ; c - > idct_add = ff_idct_xvid_sse2_add ; c - > idct = ff_idct_xvid_sse2 ; c - > idct_permutation_type = FF_SSE2_IDCT_PERM ; } endif / * HAVE_SSE2_INLINE * / if HAVE_SSE2_EXTERNAL c - > scalarproduct_int16 = ff_scalarproduct_int16_sse2 ; c - > scalarproduct_and_madd_int16 = ff_scalarproduct_and_madd_int16_sse2 ; if ( mm_flags & AV_CPU_FLAG_ATOM ) { c - > vector_clip_int32 = ff_vector_clip_int32_int_sse2 ; } else { c - > vector_clip_int32 = ff_vector_clip_int32_sse2 ; } if ( avctx - > flags & CODEC_FLAG_BITEXACT ) { c - > apply_window_int16 = ff_apply_window_int16_sse2 ; } else if ( ! ( mm_flags & AV_CPU_FLAG_SSE2SLOW ) ) { c - > apply_window_int16 = ff_apply_window_int16_round_sse2 ; } c - > bswap_buf = ff_bswap32_buf_sse2 ; endif / * HAVE_SSE2_EXTERNAL * / }",1
"static int mxf_read_local_tags ( MXFContext * mxf , KLVPacket * klv , int ( * read_child ) ( ) , int ctx_size , enum MXFMetadataSetType type ) { ByteIOContext * pb = mxf - > fc - > pb ; MXFMetadataSet * ctx = ctx_size ? av_mallocz ( ctx_size ) : mxf ; uint64_t klv_end = url_ftell ( pb ) + klv - > length ; if ( ! ctx ) return - 1 ; while ( url_ftell ( pb ) + 4 < klv_end ) { int tag = get_be16 ( pb ) ; int size = get_be16 ( pb ) ; / * KLV specified by 0x53 * / uint64_t next = url_ftell ( pb ) + size ; UID uid ; if ( ! size ) { / * ignore empty tag , needed for some files with empty UMID tag * / av_log ( mxf - > fc , AV_LOG_ERROR , local tag 0x%04X with 0 size\n , tag ) ; continue ; } if ( tag > 0x7FFF ) { / * dynamic tag * / int i ; for ( i = 0 ; i < mxf - > local_tags_count ; i + + ) { int local_tag = AV_RB16 ( mxf - > local_tags + i * 18 ) ; if ( local_tag == tag ) { memcpy ( uid , mxf - > local_tags + i * 18 + 2 , 16 ) ; dprintf ( mxf - > fc , local tag 0x%04X\n , local_tag ) ; ifdef DEBUG PRINT_KEY ( mxf - > fc , uid , uid ) ; endif } } } if ( ctx_size & & tag == 0x3C0A ) get_buffer ( pb , ctx - > uid , 16 ) ; else read_child ( ctx , pb , tag , size , uid ) ; url_fseek ( pb , next , SEEK_SET ) ; } if ( ctx_size ) ctx - > type = type ; return ctx_size ? mxf_add_metadata_set ( mxf , ctx ) : 0 ; }",0
"static void RENAME ( extract_even2 ) ( const uint8_t * src , uint8_t * dst0 , uint8_t * dst1 , x86_reg count ) { dst0 + = count ; dst1 + = count ; src + = 4 * count ; count= - count ; if COMPILE_TEMPLATE_MMX if ( count < = - 8 ) { count + = 7 ; __asm__ volatile ( pcmpeqw %%mm7 , %%mm7 \n\t psrlw 8 , %%mm7 \n\t 1 : \n\t movq - 28 ( %1 , %0 , 4 ) , %%mm0 \n\t movq - 20 ( %1 , %0 , 4 ) , %%mm1 \n\t movq - 12 ( %1 , %0 , 4 ) , %%mm2 \n\t movq - 4 ( %1 , %0 , 4 ) , %%mm3 \n\t pand %%mm7 , %%mm0 \n\t pand %%mm7 , %%mm1 \n\t pand %%mm7 , %%mm2 \n\t pand %%mm7 , %%mm3 \n\t packuswb %%mm1 , %%mm0 \n\t packuswb %%mm3 , %%mm2 \n\t movq %%mm0 , %%mm1 \n\t movq %%mm2 , %%mm3 \n\t psrlw 8 , %%mm0 \n\t psrlw 8 , %%mm2 \n\t pand %%mm7 , %%mm1 \n\t pand %%mm7 , %%mm3 \n\t packuswb %%mm2 , %%mm0 \n\t packuswb %%mm3 , %%mm1 \n\t MOVNTQ %%mm0 , - 7 ( %3 , %0 ) \n\t MOVNTQ %%mm1 , - 7 ( %2 , %0 ) \n\t add 8 , %0 \n\t js 1b \n\t : + r ( count ) : r ( src ) , r ( dst0 ) , r ( dst1 ) ) ; count - = 7 ; } endif while ( count < 0 ) { dst0[count]= src[4 * count + 0] ; dst1[count]= src[4 * count + 2] ; count + + ; } }",0
static int au_probe ( AVProbeData * p ) { / * check file header * / if ( p - > buf_size < = 24 ) return 0 ; if ( p - > buf[0] == ' . ' & & p - > buf[1] == ' s ' & & p - > buf[2] == ' n ' & & p - > buf[3] == ' d ' ) return AVPROBE_SCORE_MAX ; else return 0 ; },0
"static int X264_frame ( AVCodecContext * ctx , AVPacket * pkt , const AVFrame * frame , int * got_packet ) { X264Context * x4 = ctx - > priv_data ; x264_nal_t * nal ; int nnal , i , ret ; x264_picture_t pic_out = { 0 } ; int pict_type ; x264_picture_init ( & x4 - > pic ) ; x4 - > pic . img . i_csp = x4 - > params . i_csp ; if ( x264_bit_depth > 8 ) x4 - > pic . img . i_csp |= X264_CSP_HIGH_DEPTH ; x4 - > pic . img . i_plane = avfmt2_num_planes ( ctx - > pix_fmt ) ; if ( frame ) { for ( i = 0 ; i < x4 - > pic . img . i_plane ; i + + ) { x4 - > pic . img . plane[i] = frame - > data[i] ; x4 - > pic . img . i_stride[i] = frame - > linesize[i] ; } x4 - > pic . i_pts = frame - > pts ; switch ( frame - > pict_type ) { case AV_PICTURE_TYPE_I : x4 - > pic . i_type = x4 - > forced_idr > 0 ? X264_TYPE_IDR : X264_TYPE_KEYFRAME ; break ; case AV_PICTURE_TYPE_P : x4 - > pic . i_type = X264_TYPE_P ; break ; case AV_PICTURE_TYPE_B : x4 - > pic . i_type = X264_TYPE_B ; break ; default : x4 - > pic . i_type = X264_TYPE_AUTO ; break ; } reconfig_encoder ( ctx , frame ) ; if ( x4 - > a53_cc ) { void * sei_data ; size_t sei_size ; ret = ff_alloc_a53_sei ( frame , 0 , & sei_data , & sei_size ) ; if ( ret < 0 ) { av_log ( ctx , AV_LOG_ERROR , Not enough memory for closed captions , skipping\n ) ; } else if ( sei_data ) { x4 - > pic . extra_sei . payloads = av_mallocz ( sizeof ( x4 - > pic . extra_sei . payloads[0] ) ) ; if ( x4 - > pic . extra_sei . payloads == NULL ) { av_log ( ctx , AV_LOG_ERROR , Not enough memory for closed captions , skipping\n ) ; av_free ( sei_data ) ; } else { x4 - > pic . extra_sei . sei_free = av_free ; x4 - > pic . extra_sei . payloads[0] . payload_size = sei_size ; x4 - > pic . extra_sei . payloads[0] . payload = sei_data ; x4 - > pic . extra_sei . num_payloads = 1 ; x4 - > pic . extra_sei . payloads[0] . payload_type = 4 ; } } } } do { if ( x264_encoder_encode ( x4 - > enc , & nal , & nnal , frame ? & x4 - > pic : NULL , & pic_out ) < 0 ) return AVERROR_EXTERNAL ; ret = encode_nals ( ctx , pkt , nal , nnal ) ; if ( ret < 0 ) return ret ; } while ( ! ret & & ! frame & & x264_encoder_delayed_frames ( x4 - > enc ) ) ; pkt - > pts = pic_out . i_pts ; pkt - > dts = pic_out . i_dts ; switch ( pic_out . i_type ) { case X264_TYPE_IDR : case X264_TYPE_I : pict_type = AV_PICTURE_TYPE_I ; break ; case X264_TYPE_P : pict_type = AV_PICTURE_TYPE_P ; break ; case X264_TYPE_B : case X264_TYPE_BREF : pict_type = AV_PICTURE_TYPE_B ; break ; default : pict_type = AV_PICTURE_TYPE_NONE ; } if FF_API_CODED_FRAME FF_DISABLE_DEPRECATION_WARNINGS ctx - > coded_frame - > pict_type = pict_type ; FF_ENABLE_DEPRECATION_WARNINGS endif pkt - > flags |= AV_PKT_FLAG_KEY * pic_out . b_keyframe ; if ( ret ) { ff_side_data_set_encoder_stats ( pkt , ( pic_out . i_qpplus1 - 1 ) * FF_QP2LAMBDA , NULL , 0 , pict_type ) ; if FF_API_CODED_FRAME FF_DISABLE_DEPRECATION_WARNINGS ctx - > coded_frame - > quality = ( pic_out . i_qpplus1 - 1 ) * FF_QP2LAMBDA ; FF_ENABLE_DEPRECATION_WARNINGS endif } * got_packet = ret ; return 0 ; }",0
"int flv_h263_decode_picture_header ( MpegEncContext * s ) { int format , width , height ; / * picture header * / if ( get_bits_long ( & s - > gb , 17 ) ! = 1 ) { av_log ( s - > avctx , AV_LOG_ERROR , Bad picture start code\n ) ; return - 1 ; } format = get_bits ( & s - > gb , 5 ) ; if ( format ! = 0 & & format ! = 1 ) { av_log ( s - > avctx , AV_LOG_ERROR , Bad picture format\n ) ; return - 1 ; } s - > h263_flv = format + 1 ; s - > picture_number = get_bits ( & s - > gb , 8 ) ; / * picture timestamp * / format = get_bits ( & s - > gb , 3 ) ; switch ( format ) { case 0 : width = get_bits ( & s - > gb , 8 ) ; height = get_bits ( & s - > gb , 8 ) ; break ; case 1 : width = get_bits ( & s - > gb , 16 ) ; height = get_bits ( & s - > gb , 16 ) ; break ; case 2 : width = 352 ; height = 288 ; break ; case 3 : width = 176 ; height = 144 ; break ; case 4 : width = 128 ; height = 96 ; break ; case 5 : width = 320 ; height = 240 ; break ; case 6 : width = 160 ; height = 120 ; break ; default : width = height = 0 ; break ; } if ( ( width == 0 ) || ( height == 0 ) ) return - 1 ; s - > width = width ; s - > height = height ; s - > pict_type = I_TYPE + get_bits ( & s - > gb , 2 ) ; if ( s - > pict_type > P_TYPE ) s - > pict_type = P_TYPE ; skip_bits1 ( & s - > gb ) ; / * deblocking flag * / s - > qscale = get_bits ( & s - > gb , 5 ) ; s - > h263_plus = 0 ; s - > unrestricted_mv = 1 ; s - > h263_long_vectors = 0 ; / * PEI * / while ( get_bits1 ( & s - > gb ) ! = 0 ) { skip_bits ( & s - > gb , 8 ) ; } s - > f_code = 1 ; if ( s - > avctx - > debug & FF_DEBUG_PICT_INFO ) { av_log ( s - > avctx , AV_LOG_DEBUG , %c esc_type : %d , qp : %d num : %d\n , av_get_pict_type_char ( s - > pict_type ) , s - > h263_flv - 1 , s - > qscale , s - > picture_number ) ; } s - > y_dc_scale_table= s - > c_dc_scale_table= ff_mpeg1_dc_scale_table ; return 0 ; }",0
"static int libopenjpeg_copy_unpacked8 ( AVCodecContext * avctx , const AVFrame * frame , opj_image_t * image ) { int compno ; int x ; int y ; int width ; int height ; int * image_line ; int frame_index ; const int numcomps = image - > numcomps ; for ( compno = 0 ; compno < numcomps ; + + compno ) { if ( image - > comps[compno] . w > frame - > linesize[compno] ) { av_log ( avctx , AV_LOG_ERROR , Error : frame ' s linesize is too small for the image\n ) ; return 0 ; } } for ( compno = 0 ; compno < numcomps ; + + compno ) { width = avctx - > width / image - > comps[compno] . dx ; height = avctx - > height / image - > comps[compno] . dy ; for ( y = 0 ; y < height ; + + y ) { image_line = image - > comps[compno] . data + y * image - > comps[compno] . w ; frame_index = y * frame - > linesize[compno] ; for ( x = 0 ; x < width ; + + x ) image_line[x] = frame - > data[compno][frame_index + + ] ; for ( ; x < image - > comps[compno] . w ; + + x ) { image_line[x] = image_line[x - 1] ; } } for ( ; y < image - > comps[compno] . h ; + + y ) { image_line = image - > comps[compno] . data + y * image - > comps[compno] . w ; for ( x = 0 ; x < image - > comps[compno] . w ; + + x ) { image_line[x] = image_line[x - image - > comps[compno] . w] ; } } } return 1 ; }",1
"static int url_alloc_for_protocol ( URLContext * * puc , struct URLProtocol * up , const char * filename , int flags , const AVIOInterruptCB * int_cb ) { URLContext * uc ; int err ; if CONFIG_NETWORK if ( up - > flags & URL_PROTOCOL_FLAG_NETWORK & & ! ff_network_init ( ) ) return AVERROR ( EIO ) ; endif if ( ( flags & AVIO_FLAG_READ ) & & ! up - > url_read ) { av_log ( NULL , AV_LOG_ERROR , Impossible to open the ' %s ' protocol for reading\n , up - > name ) ; return AVERROR ( EIO ) ; } if ( ( flags & AVIO_FLAG_WRITE ) & & ! up - > url_write ) { av_log ( NULL , AV_LOG_ERROR , Impossible to open the ' %s ' protocol for writing\n , up - > name ) ; return AVERROR ( EIO ) ; } uc = av_mallocz ( sizeof ( URLContext ) + strlen ( filename ) + 1 ) ; if ( ! uc ) { err = AVERROR ( ENOMEM ) ; goto fail ; } uc - > av_class = & ffurl_context_class ; uc - > filename = ( char * ) & uc[1] ; strcpy ( uc - > filename , filename ) ; uc - > prot = up ; uc - > flags = flags ; uc - > is_streamed = 0 ; / * default = not streamed * / uc - > max_packet_size = 0 ; / * default : stream file * / if ( up - > priv_data_size ) { uc - > priv_data = av_mallocz ( up - > priv_data_size ) ; if ( ! uc - > priv_data ) { err = AVERROR ( ENOMEM ) ; goto fail ; } if ( up - > priv_data_class ) { int proto_len= strlen ( up - > name ) ; char * start = strchr ( uc - > filename , ' , ' ) ; * ( const AVClass * * ) uc - > priv_data = up - > priv_data_class ; av_opt_set_defaults ( uc - > priv_data ) ; if ( ! strncmp ( up - > name , uc - > filename , proto_len ) & & uc - > filename + proto_len == start ) { int ret= 0 ; char * p= start ; char sep= * + + p ; char * key , * val ; p + + ; while ( ret > = 0 & & ( key= strchr ( p , sep ) ) & & p < key & & ( val = strchr ( key + 1 , sep ) ) ) { * val= * key= 0 ; ret= av_opt_set ( uc - > priv_data , p , key + 1 , 0 ) ; if ( ret == AVERROR_OPTION_NOT_FOUND ) av_log ( uc , AV_LOG_ERROR , Key ' %s ' not found . \n , p ) ; * val= * key= sep ; p= val + 1 ; } if ( ret < 0 || p ! =key ) { av_log ( uc , AV_LOG_ERROR , Error parsing options string %s\n , start ) ; av_freep ( & uc - > priv_data ) ; av_freep ( & uc ) ; err = AVERROR ( EINVAL ) ; goto fail ; } memmove ( start , key + 1 , strlen ( key ) ) ; } } } if ( int_cb ) uc - > interrupt_callback = * int_cb ; * puc = uc ; return 0 ; fail : * puc = NULL ; if ( uc ) av_freep ( & uc - > priv_data ) ; av_freep ( & uc ) ; if CONFIG_NETWORK if ( up - > flags & URL_PROTOCOL_FLAG_NETWORK ) ff_network_close ( ) ; endif return err ; }",1
"void ff_write_pass1_stats ( MpegEncContext * s ) { snprintf ( s - > avctx - > stats_out , 256 , in : %d out : %d type : %d q : %d itex : %d ptex : %d mv : %d misc : %d fcode : %d bcode : %d mc - var : %d var : %d icount : %d skipcount : %d hbits : %d ; \n , s - > current_picture_ptr - > f . display_picture_number , s - > current_picture_ptr - > f . coded_picture_number , s - > pict_type , s - > current_picture . f . quality , s - > i_tex_bits , s - > p_tex_bits , s - > mv_bits , s - > misc_bits , s - > f_code , s - > b_code , s - > current_picture . mc_mb_var_sum , s - > current_picture . mb_var_sum , s - > i_count , s - > skip_count , s - > header_bits ) ; }",1
"static int ff_vp56_decode_mbs ( AVCodecContext * avctx , void * data , int jobnr , int threadnr ) { VP56Context * s0 = avctx - > priv_data ; int is_alpha = ( jobnr == 1 ) ; VP56Context * s = is_alpha ? s0 - > alpha_context : s0 ; AVFrame * const p = s - > frames[VP56_FRAME_CURRENT] ; int mb_row , mb_col , mb_row_flip , mb_offset = 0 ; int block , y , uv ; ptrdiff_t stride_y , stride_uv ; int res ; int damaged = 0 ; if ( p - > key_frame ) { p - > pict_type = AV_PICTURE_TYPE_I ; s - > default_models_init ( s ) ; for ( block=0 ; block < s - > mb_height * s - > mb_width ; block + + ) s - > macroblocks[block] . type = VP56_MB_INTRA ; } else { p - > pict_type = AV_PICTURE_TYPE_P ; vp56_parse_mb_type_models ( s ) ; s - > parse_vector_models ( s ) ; s - > mb_type = VP56_MB_INTER_NOVEC_PF ; } if ( s - > parse_coeff_models ( s ) ) goto next ; memset ( s - > prev_dc , 0 , sizeof ( s - > prev_dc ) ) ; s - > prev_dc[1][VP56_FRAME_CURRENT] = 128 ; s - > prev_dc[2][VP56_FRAME_CURRENT] = 128 ; for ( block=0 ; block < 4 * s - > mb_width + 6 ; block + + ) { s - > above_blocks[block] . ref_frame = VP56_FRAME_NONE ; s - > above_blocks[block] . dc_coeff = 0 ; s - > above_blocks[block] . not_null_dc = 0 ; } s - > above_blocks[2 * s - > mb_width + 2] . ref_frame = VP56_FRAME_CURRENT ; s - > above_blocks[3 * s - > mb_width + 4] . ref_frame = VP56_FRAME_CURRENT ; stride_y = p - > linesize[0] ; stride_uv = p - > linesize[1] ; if ( s - > flip < 0 ) mb_offset = 7 ; / * main macroblocks loop * / for ( mb_row=0 ; mb_row < s - > mb_height ; mb_row + + ) { if ( s - > flip < 0 ) mb_row_flip = s - > mb_height - mb_row - 1 ; else mb_row_flip = mb_row ; for ( block=0 ; block < 4 ; block + + ) { s - > left_block[block] . ref_frame = VP56_FRAME_NONE ; s - > left_block[block] . dc_coeff = 0 ; s - > left_block[block] . not_null_dc = 0 ; } memset ( s - > coeff_ctx , 0 , sizeof ( s - > coeff_ctx ) ) ; memset ( s - > coeff_ctx_last , 24 , sizeof ( s - > coeff_ctx_last ) ) ; s - > above_block_idx[0] = 1 ; s - > above_block_idx[1] = 2 ; s - > above_block_idx[2] = 1 ; s - > above_block_idx[3] = 2 ; s - > above_block_idx[4] = 2 * s - > mb_width + 2 + 1 ; s - > above_block_idx[5] = 3 * s - > mb_width + 4 + 1 ; s - > block_offset[s - > frbi] = ( mb_row_flip * 16 + mb_offset ) * stride_y ; s - > block_offset[s - > srbi] = s - > block_offset[s - > frbi] + 8 * stride_y ; s - > block_offset[1] = s - > block_offset[0] + 8 ; s - > block_offset[3] = s - > block_offset[2] + 8 ; s - > block_offset[4] = ( mb_row_flip * 8 + mb_offset ) * stride_uv ; s - > block_offset[5] = s - > block_offset[4] ; for ( mb_col=0 ; mb_col < s - > mb_width ; mb_col + + ) { if ( ! damaged ) { int ret = vp56_decode_mb ( s , mb_row , mb_col , is_alpha ) ; if ( ret < 0 ) damaged = 1 ; } if ( damaged ) vp56_conceal_mb ( s , mb_row , mb_col , is_alpha ) ; for ( y=0 ; y < 4 ; y + + ) { s - > above_block_idx[y] + = 2 ; s - > block_offset[y] + = 16 ; } for ( uv=4 ; uv < 6 ; uv + + ) { s - > above_block_idx[uv] + = 1 ; s - > block_offset[uv] + = 8 ; } } } next : if ( p - > key_frame || s - > golden_frame ) { av_frame_unref ( s - > frames[VP56_FRAME_GOLDEN] ) ; if ( ( res = av_frame_ref ( s - > frames[VP56_FRAME_GOLDEN] , p ) ) < 0 ) return res ; } av_frame_unref ( s - > frames[VP56_FRAME_PREVIOUS] ) ; FFSWAP ( AVFrame * , s - > frames[VP56_FRAME_CURRENT] , s - > frames[VP56_FRAME_PREVIOUS] ) ; return 0 ; }",1
"static int draw_slice ( AVFilterLink * inlink , int y0 , int h , int slice_dir ) { AlphaExtractContext * extract = inlink - > dst - > priv ; AVFilterBufferRef * cur_buf = inlink - > cur_buf ; AVFilterBufferRef * out_buf = inlink - > dst - > outputs[0] - > out_buf ; if ( extract - > is_packed_rgb ) { int x , y ; uint8_t * pin , * pout ; for ( y = y0 ; y < ( y0 + h ) ; y + + ) { pin = cur_buf - > data[0] + y * cur_buf - > linesize[0] + extract - > rgba_map[A] ; pout = out_buf - > data[0] + y * out_buf - > linesize[0] ; for ( x = 0 ; x < out_buf - > video - > w ; x + + ) { * pout = * pin ; pout + = 1 ; pin + = 4 ; } } } else if ( cur_buf - > linesize[A] == out_buf - > linesize[Y] ) { const int linesize = cur_buf - > linesize[A] ; memcpy ( out_buf - > data[Y] + y0 * linesize , cur_buf - > data[A] + y0 * linesize , linesize * h ) ; } else { const int linesize = FFMIN ( out_buf - > linesize[Y] , cur_buf - > linesize[A] ) ; int y ; for ( y = y0 ; y < ( y0 + h ) ; y + + ) { memcpy ( out_buf - > data[Y] + y * out_buf - > linesize[Y] , cur_buf - > data[A] + y * cur_buf - > linesize[A] , linesize ) ; } } return ff_draw_slice ( inlink - > dst - > outputs[0] , y0 , h , slice_dir ) ; }",1
"static int sad16_altivec ( void * v , uint8_t * pix1 , uint8_t * pix2 , int line_size , int h ) { int i ; int s ; const vector unsigned int zero = ( const vector unsigned int ) vec_splat_u32 ( 0 ) ; vector unsigned char perm1 , perm2 , * pix1v , * pix2v ; vector unsigned char t1 , t2 , t3 , t4 , t5 ; vector unsigned int sad ; vector signed int sumdiffs ; sad = ( vector unsigned int ) vec_splat_u32 ( 0 ) ; for ( i = 0 ; i < h ; i + + ) { / * Read potentially unaligned pixels into t1 and t2 * / perm1 = vec_lvsl ( 0 , pix1 ) ; pix1v = ( vector unsigned char * ) pix1 ; perm2 = vec_lvsl ( 0 , pix2 ) ; pix2v = ( vector unsigned char * ) pix2 ; t1 = vec_perm ( pix1v[0] , pix1v[1] , perm1 ) ; t2 = vec_perm ( pix2v[0] , pix2v[1] , perm2 ) ; / * Calculate a sum of abs differences vector * / t3 = vec_max ( t1 , t2 ) ; t4 = vec_min ( t1 , t2 ) ; t5 = vec_sub ( t3 , t4 ) ; / * Add each 4 pixel group together and put 4 results into sad * / sad = vec_sum4s ( t5 , sad ) ; pix1 + = line_size ; pix2 + = line_size ; } / * Sum up the four partial sums , and put the result into s * / sumdiffs = vec_sums ( ( vector signed int ) sad , ( vector signed int ) zero ) ; sumdiffs = vec_splat ( sumdiffs , 3 ) ; vec_ste ( sumdiffs , 0 , & s ) ; return s ; }",1
"void rgb8tobgr8 ( const uint8_t * src , uint8_t * dst , unsigned int src_size ) { unsigned i ; unsigned num_pixels = src_size ; for ( i=0 ; i < num_pixels ; i + + ) { unsigned b , g , r ; register uint8_t rgb ; rgb = src[i] ; r = ( rgb & 0x07 ) ; g = ( rgb & 0x38 ) > > 3 ; b = ( rgb & 0xC0 ) > > 6 ; dst[i] = ( ( b < < 1 ) & 0x07 ) | ( ( g & 0x07 ) < < 3 ) | ( ( r & 0x03 ) < < 6 ) ; } }",1
"static int vorbis_parse_setup_hdr_residues ( vorbis_context * vc ) { GetBitContext * gb= & vc - > gb ; uint_fast8_t i , j , k ; vc - > residue_count=get_bits ( gb , 6 ) + 1 ; vc - > residues=av_mallocz ( vc - > residue_count * sizeof ( vorbis_residue ) ) ; AV_DEBUG ( There are %d residues . \n , vc - > residue_count ) ; for ( i=0 ; i < vc - > residue_count ; + + i ) { vorbis_residue * res_setup= & vc - > residues[i] ; uint_fast8_t cascade[64] ; uint_fast8_t high_bits ; uint_fast8_t low_bits ; res_setup - > type=get_bits ( gb , 16 ) ; AV_DEBUG ( %d . residue type %d \n , i , res_setup - > type ) ; res_setup - > begin=get_bits ( gb , 24 ) ; res_setup - > end=get_bits ( gb , 24 ) ; res_setup - > partition_size=get_bits ( gb , 24 ) + 1 ; res_setup - > classifications=get_bits ( gb , 6 ) + 1 ; res_setup - > classbook=get_bits ( gb , 8 ) ; if ( res_setup - > classbook > =vc - > codebook_count ) { av_log ( vc - > avccontext , AV_LOG_ERROR , classbook value %d out of range . \n , res_setup - > classbook ) ; AV_DEBUG ( begin %d end %d part . size %d classif . s %d classbook %d \n , res_setup - > begin , res_setup - > end , res_setup - > partition_size , res_setup - > classifications , res_setup - > classbook ) ; for ( j=0 ; j < res_setup - > classifications ; + + j ) { high_bits=0 ; low_bits=get_bits ( gb , 3 ) ; if ( get_bits1 ( gb ) ) { high_bits=get_bits ( gb , 5 ) ; cascade[j]= ( high_bits < < 3 ) + low_bits ; AV_DEBUG ( %d class casscade depth : %d \n , j , ilog ( cascade[j] ) ) ; res_setup - > maxpass=0 ; for ( j=0 ; j < res_setup - > classifications ; + + j ) { for ( k=0 ; k < 8 ; + + k ) { if ( cascade[j] & ( 1 < < k ) ) { int bits=get_bits ( gb , 8 ) ; if ( bits > =vc - > codebook_count ) { av_log ( vc - > avccontext , AV_LOG_ERROR , book value %d out of range . \n , bits ) ; res_setup - > books[j][k]=bits ; AV_DEBUG ( %d class casscade depth %d book : %d \n , j , k , res_setup - > books[j][k] ) ; if ( k > res_setup - > maxpass ) { res_setup - > maxpass=k ; } else { res_setup - > books[j][k]= - 1 ; return 0 ;",1
"static int flashsv_decode_block ( AVCodecContext * avctx , AVPacket * avpkt , GetBitContext * gb , int block_size , int width , int height , int x_pos , int y_pos , int blk_idx ) { struct FlashSVContext * s = avctx - > priv_data ; uint8_t * line = s - > tmpblock ; int k ; int ret = inflateReset ( & s - > zstream ) ; if ( ret ! = Z_OK ) { av_log ( avctx , AV_LOG_ERROR , Inflate reset error : %d\n , ret ) ; return AVERROR_UNKNOWN ; } if ( s - > zlibprime_curr || s - > zlibprime_prev ) { ret = flashsv2_prime ( s , s - > blocks[blk_idx] . pos , s - > blocks[blk_idx] . size ) ; if ( ret < 0 ) return ret ; } s - > zstream . next_in = avpkt - > data + get_bits_count ( gb ) / 8 ; s - > zstream . avail_in = block_size ; s - > zstream . next_out = s - > tmpblock ; s - > zstream . avail_out = s - > block_size * 3 ; ret = inflate ( & s - > zstream , Z_FINISH ) ; if ( ret == Z_DATA_ERROR ) { av_log ( avctx , AV_LOG_ERROR , Zlib resync occurred\n ) ; inflateSync ( & s - > zstream ) ; ret = inflate ( & s - > zstream , Z_FINISH ) ; } if ( ret ! = Z_OK & & ret ! = Z_STREAM_END ) { //return - 1 ; } if ( s - > is_keyframe ) { s - > blocks[blk_idx] . pos = s - > keyframedata + ( get_bits_count ( gb ) / 8 ) ; s - > blocks[blk_idx] . size = block_size ; } y_pos + = s - > diff_start ; if ( ! s - > color_depth ) { / * Flash Screen Video stores the image upside down , so copy * lines to destination in reverse order . * / for ( k = 1 ; k < = s - > diff_height ; k + + ) { memcpy ( s - > frame - > data[0] + x_pos * 3 + ( s - > image_height - y_pos - k ) * s - > frame - > linesize[0] , line , width * 3 ) ; / * advance source pointer to next line * / line + = width * 3 ; } } else { / * hybrid 15 - bit/palette mode * / decode_hybrid ( s - > tmpblock , s - > frame - > data[0] , s - > image_height - ( y_pos + 1 + s - > diff_height ) , x_pos , s - > diff_height , width , s - > frame - > linesize[0] , s - > pal ) ; } skip_bits_long ( gb , 8 * block_size ) ; / * skip the consumed bits * / return 0 ; }",1
"static void evaluate_utility_inc ( elbg_data * elbg ) { int i , inc=0 ; for ( i=0 ; i < elbg - > numCB ; i + + ) { if ( elbg - > numCB * elbg - > utility[i] > elbg - > error ) inc + = elbg - > utility[i] ; elbg - > utility_inc[i] = inc ; } }",1
"static av_always_inline void filter_mb_dir ( H264Context * h , int mb_x , int mb_y , uint8_t * img_y , uint8_t * img_cb , uint8_t * img_cr , unsigned int linesize , unsigned int uvlinesize , int mb_xy , int mb_type , int mvy_limit , int first_vertical_edge_done , int chroma , int chroma444 , int dir ) { MpegEncContext * const s = & h - > s ; int edge ; int chroma_qp_avg[2] ; const int mbm_xy = dir == 0 ? mb_xy - 1 : h - > top_mb_xy ; const int mbm_type = dir == 0 ? h - > left_type[LTOP] : h - > top_type ; // how often to recheck mv - based bS when iterating between edges static const uint8_t mask_edge_tab[2][8]= { { 0 , 3 , 3 , 3 , 1 , 1 , 1 , 1 } , { 0 , 3 , 1 , 1 , 3 , 3 , 3 , 3 } } ; const int mask_edge = mask_edge_tab[dir][ ( mb_type > > 3 ) & 7] ; const int edges = mask_edge== 3 & & ! ( h - > cbp & 15 ) ? 1 : 4 ; // how often to recheck mv - based bS when iterating along each edge const int mask_par0 = mb_type & ( MB_TYPE_16x16 | ( MB_TYPE_8x16 > > dir ) ) ; if ( mbm_type & & ! first_vertical_edge_done ) { if ( FRAME_MBAFF & & ( dir == 1 ) & & ( ( mb_y & 1 ) == 0 ) & & IS_INTERLACED ( mbm_type & mb_type ) ) { // This is a special case in the norm where the filtering must // be done twice ( one each of the field ) even if we are in a // frame macroblock . // unsigned int tmp_linesize = 2 * linesize ; unsigned int tmp_uvlinesize = 2 * uvlinesize ; int mbn_xy = mb_xy - 2 * s - > mb_stride ; int j ; for ( j=0 ; j < 2 ; j + + , mbn_xy + = s - > mb_stride ) { DECLARE_ALIGNED ( 8 , int16_t , bS ) [4] ; int qp ; if ( IS_INTRA ( mb_type | s - > current_picture . f . mb_type[mbn_xy] ) ) { AV_WN64A ( bS , 0x0003000300030003ULL ) ; } else { if ( ! CABAC & & IS_8x8DCT ( s - > current_picture . f . mb_type[mbn_xy] ) ) { bS[0]= 1 + ( ( h - > cbp_table[mbn_xy] & 0x4000 ) ||h - > non_zero_count_cache[scan8[0] + 0] ) ; bS[1]= 1 + ( ( h - > cbp_table[mbn_xy] & 0x4000 ) ||h - > non_zero_count_cache[scan8[0] + 1] ) ; bS[2]= 1 + ( ( h - > cbp_table[mbn_xy] & 0x8000 ) ||h - > non_zero_count_cache[scan8[0] + 2] ) ; bS[3]= 1 + ( ( h - > cbp_table[mbn_xy] & 0x8000 ) ||h - > non_zero_count_cache[scan8[0] + 3] ) ; } else { const uint8_t * mbn_nnz = h - > non_zero_count[mbn_xy] + 3 * 4 ; int i ; for ( i = 0 ; i < 4 ; i + + ) { bS[i] = 1 + ! ! ( h - > non_zero_count_cache[scan8[0] + i] | mbn_nnz[i] ) ; } } } // Do not use s - > qscale as luma quantizer because it has not the same // value in IPCM macroblocks . qp = ( s - > current_picture . f . qscale_table[mb_xy] + s - > current_picture . f . qscale_table[mbn_xy] + 1 ) > > 1 ; tprintf ( s - > avctx , filter mb : %d/%d dir : %d edge : %d , QPy : %d ls : %d uvls : %d , mb_x , mb_y , dir , edge , qp , tmp_linesize , tmp_uvlinesize ) ; { int i ; for ( i = 0 ; i < 4 ; i + + ) tprintf ( s - > avctx , bS[%d] : %d , i , bS[i] ) ; tprintf ( s - > avctx , \n ) ; } filter_mb_edgeh ( & img_y[j * linesize] , tmp_linesize , bS , qp , h ) ; chroma_qp_avg[0] = ( h - > chroma_qp[0] + get_chroma_qp ( h , 0 , s - > current_picture . f . qscale_table[mbn_xy] ) + 1 ) > > 1 ; chroma_qp_avg[1] = ( h - > chroma_qp[1] + get_chroma_qp ( h , 1 , s - > current_picture . f . qscale_table[mbn_xy] ) + 1 ) > > 1 ; if ( chroma ) { if ( chroma444 ) { filter_mb_edgeh ( & img_cb[j * uvlinesize] , tmp_uvlinesize , bS , chroma_qp_avg[0] , h ) ; filter_mb_edgeh ( & img_cr[j * uvlinesize] , tmp_uvlinesize , bS , chroma_qp_avg[1] , h ) ; } else { filter_mb_edgech ( & img_cb[j * uvlinesize] , tmp_uvlinesize , bS , chroma_qp_avg[0] , h ) ; filter_mb_edgech ( & img_cr[j * uvlinesize] , tmp_uvlinesize , bS , chroma_qp_avg[1] , h ) ; } } } } else { DECLARE_ALIGNED ( 8 , int16_t , bS ) [4] ; int qp ; if ( IS_INTRA ( mb_type|mbm_type ) ) { AV_WN64A ( bS , 0x0003000300030003ULL ) ; if ( ( ! IS_INTERLACED ( mb_type|mbm_type ) ) || ( ( FRAME_MBAFF || ( s - > picture_structure ! = PICT_FRAME ) ) & & ( dir == 0 ) ) ) AV_WN64A ( bS , 0x0004000400040004ULL ) ; } else { int i ; int mv_done ; if ( dir & & FRAME_MBAFF & & IS_INTERLACED ( mb_type mbm_type ) ) { AV_WN64A ( bS , 0x0001000100010001ULL ) ; mv_done = 1 ; } else if ( mask_par0 & & ( ( mbm_type & ( MB_TYPE_16x16 | ( MB_TYPE_8x16 > > dir ) ) ) ) ) { int b_idx= 8 + 4 ; int bn_idx= b_idx - ( dir ? 8 : 1 ) ; bS[0] = bS[1] = bS[2] = bS[3] = check_mv ( h , 8 + 4 , bn_idx , mvy_limit ) ; mv_done = 1 ; } else mv_done = 0 ; for ( i = 0 ; i < 4 ; i + + ) { int x = dir == 0 ? 0 : i ; int y = dir == 0 ? i : 0 ; int b_idx= 8 + 4 + x + 8 * y ; int bn_idx= b_idx - ( dir ? 8 : 1 ) ; if ( h - > non_zero_count_cache[b_idx] | h - > non_zero_count_cache[bn_idx] ) { bS[i] = 2 ; } else if ( ! mv_done ) { bS[i] = check_mv ( h , b_idx , bn_idx , mvy_limit ) ; } } } / * Filter edge * / // Do not use s - > qscale as luma quantizer because it has not the same // value in IPCM macroblocks . if ( bS[0] + bS[1] + bS[2] + bS[3] ) { qp = ( s - > current_picture . f . qscale_table[mb_xy] + s - > current_picture . f . qscale_table[mbm_xy] + 1 ) > > 1 ; //tprintf ( s - >",0
"static int mov_read_close ( AVFormatContext * s ) { MOVContext * mov = s - > priv_data ; int i , j ; for ( i = 0 ; i < s - > nb_streams ; i + + ) { AVStream * st = s - > streams[i] ; MOVStreamContext * sc = st - > priv_data ; av_freep ( & sc - > ctts_data ) ; for ( j = 0 ; j < sc - > drefs_count ; j + + ) { av_freep ( & sc - > drefs[j] . path ) ; av_freep ( & sc - > drefs[j] . dir ) ; } av_freep ( & sc - > drefs ) ; if ( sc - > pb & & sc - > pb ! = s - > pb ) avio_close ( sc - > pb ) ; av_freep ( & sc - > chunk_offsets ) ; av_freep ( & sc - > stsc_data ) ; av_freep ( & sc - > sample_sizes ) ; av_freep ( & sc - > keyframes ) ; av_freep ( & sc - > stts_data ) ; av_freep ( & sc - > stps_data ) ; av_freep ( & sc - > rap_group ) ; av_freep ( & sc - > display_matrix ) ; } if ( mov - > dv_demux ) { avformat_free_context ( mov - > dv_fctx ) ; mov - > dv_fctx = NULL ; } av_freep ( & mov - > trex_data ) ; return 0 ; }",0
"static int color_request_frame ( AVFilterLink * link ) { ColorContext * color = link - > src - > priv ; AVFilterBufferRef * picref = ff_get_video_buffer ( link , AV_PERM_WRITE , color - > w , color - > h ) ; int ret ; picref - > video - > pixel_aspect = ( AVRational ) { 1 , 1 } ; picref - > pts = color - > pts + + ; picref - > pos = - 1 ; ret = ff_start_frame ( link , avfilter_ref_buffer ( picref , 0 ) ) ; if ( ret < 0 ) goto fail ; ff_draw_rectangle ( picref - > data , picref - > linesize , color - > line , color - > line_step , color - > hsub , color - > vsub , 0 , 0 , color - > w , color - > h ) ; ret = ff_draw_slice ( link , 0 , color - > h , 1 ) ; if ( ret < 0 ) goto fail ; ret = ff_end_frame ( link ) ; fail : avfilter_unref_buffer ( picref ) ; return ret ; }",0
"static int mov_read_stsd ( MOVContext * c , ByteIOContext * pb , MOV_atom_t atom ) { AVStream * st = c - > fc - > streams[c - > fc - > nb_streams - 1] ; MOVStreamContext * sc = st - > priv_data ; int j , entries , pseudo_stream_id ; get_byte ( pb ) ; / * version * / get_be24 ( pb ) ; / * flags * / entries = get_be32 ( pb ) ; for ( pseudo_stream_id=0 ; pseudo_stream_id < entries ; pseudo_stream_id + + ) { //Parsing Sample description table enum CodecID id ; int dref_id ; MOV_atom_t a = { 0 , 0 , 0 } ; offset_t start_pos = url_ftell ( pb ) ; int size = get_be32 ( pb ) ; / * size * / uint32_t format = get_le32 ( pb ) ; / * data format * / get_be32 ( pb ) ; / * reserved * / get_be16 ( pb ) ; / * reserved * / dref_id = get_be16 ( pb ) ; if ( st - > codec - > codec_tag & & st - > codec - > codec_tag ! = format & & ( c - > fc - > video_codec_id ? codec_get_id ( codec_movvideo_tags , format ) ! = c - > fc - > video_codec_id : st - > codec - > codec_tag ! = MKTAG ( ' j ' , ' p ' , ' e ' , ' g ' ) ) ) { / * Multiple fourcc , we skip JPEG . This is not correct , we should * export it as a separate AVStream but this needs a few changes * in the MOV demuxer , patch welcome . * / av_log ( c - > fc , AV_LOG_WARNING , multiple fourcc not supported\n ) ; url_fskip ( pb , size - ( url_ftell ( pb ) - start_pos ) ) ; continue ; } sc - > pseudo_stream_id = st - > codec - > codec_tag ? - 1 : pseudo_stream_id ; sc - > dref_id= dref_id ; st - > codec - > codec_tag = format ; id = codec_get_id ( codec_movaudio_tags , format ) ; if ( id < =0 & & ( format & 0xFFFF ) == ' m ' + ( ' s ' < < 8 ) ) id = codec_get_id ( codec_wav_tags , bswap_32 ( format ) & 0xFFFF ) ; if ( st - > codec - > codec_type ! = CODEC_TYPE_VIDEO & & id > 0 ) { st - > codec - > codec_type = CODEC_TYPE_AUDIO ; } else if ( st - > codec - > codec_type ! = CODEC_TYPE_AUDIO & & / * do not overwrite codec type * / format & & format ! = MKTAG ( ' m ' , ' p ' , ' 4 ' , ' s ' ) ) { / * skip old asf mpeg4 tag * / id = codec_get_id ( codec_movvideo_tags , format ) ; if ( id < = 0 ) id = codec_get_id ( codec_bmp_tags , format ) ; if ( id > 0 ) st - > codec - > codec_type = CODEC_TYPE_VIDEO ; else if ( st - > codec - > codec_type == CODEC_TYPE_DATA ) { id = codec_get_id ( ff_codec_movsubtitle_tags , format ) ; if ( id > 0 ) st - > codec - > codec_type = CODEC_TYPE_SUBTITLE ; } } dprintf ( c - > fc , size=%d 4CC= %c%c%c%c codec_type=%d\n , size , ( format > > 0 ) & 0xff , ( format > > 8 ) & 0xff , ( format > > 16 ) & 0xff , ( format > > 24 ) & 0xff , st - > codec - > codec_type ) ; if ( st - > codec - > codec_type==CODEC_TYPE_VIDEO ) { uint8_t codec_name[32] ; unsigned int color_depth ; int color_greyscale ; st - > codec - > codec_id = id ; get_be16 ( pb ) ; / * version * / get_be16 ( pb ) ; / * revision level * / get_be32 ( pb ) ; / * vendor * / get_be32 ( pb ) ; / * temporal quality * / get_be32 ( pb ) ; / * spatial quality * / st - > codec - > width = get_be16 ( pb ) ; / * width * / st - > codec - > height = get_be16 ( pb ) ; / * height * / get_be32 ( pb ) ; / * horiz resolution * / get_be32 ( pb ) ; / * vert resolution * / get_be32 ( pb ) ; / * data size , always 0 * / get_be16 ( pb ) ; / * frames per samples * / get_buffer ( pb , codec_name , 32 ) ; / * codec name , pascal string * / if ( codec_name[0] < = 31 ) { memcpy ( st - > codec - > codec_name , & codec_name[1] , codec_name[0] ) ; st - > codec - > codec_name[codec_name[0]] = 0 ; } st - > codec - > bits_per_coded_sample = get_be16 ( pb ) ; / * depth * / st - > codec - > color_table_id = get_be16 ( pb ) ; / * colortable id * / dprintf ( c - > fc , depth %d , ctab id %d\n , st - > codec - > bits_per_coded_sample , st - > codec - > color_table_id ) ; / * figure out the palette situation * / color_depth = st - > codec - > bits_per_coded_sample & 0x1F ; color_greyscale = st - > codec - > bits_per_coded_sample & 0x20 ; / * if the depth is 2 , 4 , or 8 bpp , file is palettized * / if ( ( color_depth == 2 ) || ( color_depth == 4 ) || ( color_depth == 8 ) ) { / * for palette traversal * / unsigned int color_start , color_count , color_end ; unsigned char r , g , b ; if ( color_greyscale ) { int color_index , color_dec ; / * compute the greyscale palette * / st - > codec - > bits_per_coded_sample = color_depth ; color_count = 1 < < color_depth ; color_index = 255 ; color_dec = 256 / ( color_count - 1 ) ; for ( j = 0 ; j < color_count ; j + + ) { r = g = b = color_index ; c - > palette_control . palette[j] = ( r < < 16 ) | ( g < < 8 ) | ( b ) ; color_index - = color_dec ; if ( color_index < 0 ) color_index = 0 ; } } else if ( st - > codec - > color_table_id ) { const uint8_t * color_table ; / * if flag bit 3 is set , use the default palette * / color_count = 1 < < color_depth ; if ( color_depth == 2 ) color_table = ff_qt_default_palette_4 ; else if ( color_depth == 4 ) color_table = ff_qt_default_palette_16 ;",0
"void ff_hevc_deblocking_boundary_strengths ( HEVCContext * s , int x0 , int y0 , int log2_trafo_size ) { HEVCLocalContext * lc = & s - > HEVClc ; MvField * tab_mvf = s - > ref - > tab_mvf ; int log2_min_pu_size = s - > sps - > log2_min_pu_size ; int log2_min_tu_size = s - > sps - > log2_min_tb_size ; int min_pu_width = s - > sps - > min_pu_width ; int min_tu_width = s - > sps - > min_tb_width ; int is_intra = tab_mvf[ ( y0 > > log2_min_pu_size ) * min_pu_width + ( x0 > > log2_min_pu_size ) ] . is_intra ; int i , j , bs ; if ( y0 > 0 & & ( y0 & 7 ) == 0 ) { int yp_pu = ( y0 - 1 ) > > log2_min_pu_size ; int yq_pu = y0 > > log2_min_pu_size ; int yp_tu = ( y0 - 1 ) > > log2_min_tu_size ; int yq_tu = y0 > > log2_min_tu_size ; for ( i = 0 ; i < ( 1 < < log2_trafo_size ) ; i + = 4 ) { int x_pu = ( x0 + i ) > > log2_min_pu_size ; int x_tu = ( x0 + i ) > > log2_min_tu_size ; MvField * top = & tab_mvf[yp_pu * min_pu_width + x_pu] ; MvField * curr = & tab_mvf[yq_pu * min_pu_width + x_pu] ; uint8_t top_cbf_luma = s - > cbf_luma[yp_tu * min_tu_width + x_tu] ; uint8_t curr_cbf_luma = s - > cbf_luma[yq_tu * min_tu_width + x_tu] ; RefPicList * top_refPicList = ff_hevc_get_ref_list ( s , s - > ref , x0 + i , y0 - 1 ) ; bs = boundary_strength ( s , curr , curr_cbf_luma , top , top_cbf_luma , top_refPicList , 1 ) ; if ( ! s - > sh . slice_loop_filter_across_slices_enabled_flag & & lc - > boundary_flags & BOUNDARY_UPPER_SLICE & & ( y0 % ( 1 < < s - > sps - > log2_ctb_size ) ) == 0 ) bs = 0 ; else if ( ! s - > pps - > loop_filter_across_tiles_enabled_flag & & lc - > boundary_flags & BOUNDARY_UPPER_TILE & & ( y0 % ( 1 < < s - > sps - > log2_ctb_size ) ) == 0 ) bs = 0 ; if ( bs ) s - > horizontal_bs[ ( ( x0 + i ) + y0 * s - > bs_width ) > > 2] = bs ; } } // bs for TU internal horizontal PU boundaries if ( log2_trafo_size > s - > sps - > log2_min_pu_size & & ! is_intra ) for ( j = 8 ; j < ( 1 < < log2_trafo_size ) ; j + = 8 ) { int yp_pu = ( y0 + j - 1 ) > > log2_min_pu_size ; int yq_pu = ( y0 + j ) > > log2_min_pu_size ; int yp_tu = ( y0 + j - 1 ) > > log2_min_tu_size ; int yq_tu = ( y0 + j ) > > log2_min_tu_size ; for ( i = 0 ; i < ( 1 < < log2_trafo_size ) ; i + = 4 ) { int x_pu = ( x0 + i ) > > log2_min_pu_size ; int x_tu = ( x0 + i ) > > log2_min_tu_size ; MvField * top = & tab_mvf[yp_pu * min_pu_width + x_pu] ; MvField * curr = & tab_mvf[yq_pu * min_pu_width + x_pu] ; uint8_t top_cbf_luma = s - > cbf_luma[yp_tu * min_tu_width + x_tu] ; uint8_t curr_cbf_luma = s - > cbf_luma[yq_tu * min_tu_width + x_tu] ; RefPicList * top_refPicList = ff_hevc_get_ref_list ( s , s - > ref , x0 + i , y0 + j - 1 ) ; bs = boundary_strength ( s , curr , curr_cbf_luma , top , top_cbf_luma , top_refPicList , 0 ) ; if ( bs ) s - > horizontal_bs[ ( ( x0 + i ) + ( y0 + j ) * s - > bs_width ) > > 2] = bs ; } } // bs for vertical TU boundaries if ( x0 > 0 & & ( x0 & 7 ) == 0 ) { int xp_pu = ( x0 - 1 ) > > log2_min_pu_size ; int xq_pu = x0 > > log2_min_pu_size ; int xp_tu = ( x0 - 1 ) > > log2_min_tu_size ; int xq_tu = x0 > > log2_min_tu_size ; for ( i = 0 ; i < ( 1 < < log2_trafo_size ) ; i + = 4 ) { int y_pu = ( y0 + i ) > > log2_min_pu_size ; int y_tu = ( y0 + i ) > > log2_min_tu_size ; MvField * left = & tab_mvf[y_pu * min_pu_width + xp_pu] ; MvField * curr = & tab_mvf[y_pu * min_pu_width + xq_pu] ; uint8_t left_cbf_luma = s - > cbf_luma[y_tu * min_tu_width + xp_tu] ; uint8_t curr_cbf_luma = s - > cbf_luma[y_tu * min_tu_width + xq_tu] ; RefPicList * left_refPicList = ff_hevc_get_ref_list ( s , s - > ref , x0 - 1 , y0 + i ) ; bs = boundary_strength ( s , curr , curr_cbf_luma , left , left_cbf_luma , left_refPicList , 1 ) ; if ( ! s - > sh . slice_loop_filter_across_slices_enabled_flag & & lc - > boundary_flags & BOUNDARY_LEFT_SLICE & & ( x0 % ( 1 < < s - > sps - > log2_ctb_size ) ) == 0 ) bs = 0 ; else if ( ! s - > pps - > loop_filter_across_tiles_enabled_flag & & lc - > boundary_flags & BOUNDARY_LEFT_TILE & & ( x0 % ( 1 < < s - > sps - > log2_ctb_size ) ) == 0 ) bs = 0 ; if ( bs ) s - > vertical_bs[ ( x0 > > 3 ) + ( ( y0 + i ) > > 2 ) * s - > bs_width] = bs ; } } // bs for TU internal vertical PU boundaries if ( log2_trafo_size > log2_min_pu_size & & ! is_intra ) for ( j = 0 ; j < ( 1 < < log2_trafo_size ) ; j + = 4 ) { int y_pu = ( y0 + j ) > > log2_min_pu_size ; int y_tu = ( y0 + j ) > > log2_min_tu_size ; for ( i = 8 ; i < ( 1 < < log2_trafo_size ) ; i + = 8 ) { int xp_pu = ( x0 + i - 1 ) > > log2_min_pu_size ; int xq_pu = ( x0 + i ) > > log2_min_pu_size ; int xp_tu = ( x0 + i - 1 ) > > log2_min_tu_size ; int xq_tu = ( x0 + i ) > > log2_min_tu_size ; MvField * left = & tab_mvf[y_pu * min_pu_width + xp_pu] ; MvField * curr = & tab_mvf[y_pu * min_pu_width + xq_pu] ; uint8_t left_cbf_luma = s - > cbf_luma[y_tu * min_tu_width + xp_tu] ; uint8_t curr_cbf_luma = s - > cbf_luma[y_tu * min_tu_width + xq_tu] ; RefPicList * left_refPicList = ff_hevc_get_ref_list ( s , s - > ref , x0 + i - 1 , y0 +",0
"int ffv1_init_slice_state ( FFV1Context * f , FFV1Context * fs ) { int j ; fs - > plane_count = f - > plane_count ; fs - > transparency = f - > transparency ; for ( j = 0 ; j < f - > plane_count ; j + + ) { PlaneContext * const p = & fs - > plane[j] ; if ( fs - > ac ) { if ( ! p - > state ) p - > state = av_malloc ( CONTEXT_SIZE * p - > context_count * sizeof ( uint8_t ) ) ; if ( ! p - > state ) return AVERROR ( ENOMEM ) ; } else { if ( ! p - > vlc_state ) p - > vlc_state = av_malloc ( p - > context_count * sizeof ( VlcState ) ) ; if ( ! p - > vlc_state ) return AVERROR ( ENOMEM ) ; } } if ( fs - > ac > 1 ) { //FIXME only redo if state_transition changed for ( j = 1 ; j < 256 ; j + + ) { fs - > c . one_state[j] = f - > state_transition[j] ; fs - > c . zero_state[256 - j] = 256 - fs - > c . one_state[j] ; } } return 0 ; }",0
"static int vdpau_vc1_start_frame ( AVCodecContext * avctx , const uint8_t * buffer , uint32_t size ) { VC1Context * const v = avctx - > priv_data ; MpegEncContext * const s = & v - > s ; Picture * pic = s - > current_picture_ptr ; struct vdpau_picture_context * pic_ctx = pic - > hwaccel_picture_private ; VdpPictureInfoVC1 * info = & pic_ctx - > info . vc1 ; VdpVideoSurface ref ; / * fill LvPictureInfoVC1 struct * / info - > forward_reference = VDP_INVALID_HANDLE ; info - > backward_reference = VDP_INVALID_HANDLE ; switch ( s - > pict_type ) { case AV_PICTURE_TYPE_B : ref = ff_vdpau_get_surface_id ( & s - > next_picture . f ) ; assert ( ref ! = VDP_INVALID_HANDLE ) ; info - > backward_reference = ref ; / * fall - through * / case AV_PICTURE_TYPE_P : ref = ff_vdpau_get_surface_id ( & s - > last_picture . f ) ; assert ( ref ! = VDP_INVALID_HANDLE ) ; info - > forward_reference = ref ; } info - > slice_count = 0 ; if ( v - > bi_type ) info - > picture_type = 4 ; else info - > picture_type = s - > pict_type - 1 + s - > pict_type / 3 ; info - > frame_coding_mode = v - > fcm ? ( v - > fcm + 1 ) : 0 ; info - > postprocflag = v - > postprocflag ; info - > pulldown = v - > broadcast ; info - > interlace = v - > interlace ; info - > tfcntrflag = v - > tfcntrflag ; info - > finterpflag = v - > finterpflag ; info - > psf = v - > psf ; info - > dquant = v - > dquant ; info - > panscan_flag = v - > panscanflag ; info - > refdist_flag = v - > refdist_flag ; info - > quantizer = v - > quantizer_mode ; info - > extended_mv = v - > extended_mv ; info - > extended_dmv = v - > extended_dmv ; info - > overlap = v - > overlap ; info - > vstransform = v - > vstransform ; info - > loopfilter = v - > s . loop_filter ; info - > fastuvmc = v - > fastuvmc ; info - > range_mapy_flag = v - > range_mapy_flag ; info - > range_mapy = v - > range_mapy ; info - > range_mapuv_flag = v - > range_mapuv_flag ; info - > range_mapuv = v - > range_mapuv ; / * Specific to simple/main profile only * / info - > multires = v - > multires ; info - > syncmarker = v - > resync_marker ; info - > rangered = v - > rangered | ( v - > rangeredfrm < < 1 ) ; info - > maxbframes = v - > s . max_b_frames ; info - > deblockEnable = v - > postprocflag & 1 ; info - > pquant = v - > pq ; return ff_vdpau_common_start_frame ( pic_ctx , buffer , size ) ; }",1
"static int cinvideo_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; CinVideoContext * cin = avctx - > priv_data ; int i , y , palette_type , palette_colors_count , bitmap_frame_type , bitmap_frame_size ; cin - > frame . buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE ; if ( avctx - > reget_buffer ( avctx , & cin - > frame ) ) { av_log ( cin - > avctx , AV_LOG_ERROR , delphinecinvideo : reget_buffer ( ) failed to allocate a frame\n ) ; return - 1 ; } palette_type = buf[0] ; palette_colors_count = AV_RL16 ( buf + 1 ) ; bitmap_frame_type = buf[3] ; buf + = 4 ; bitmap_frame_size = buf_size - 4 ; / * handle palette * / if ( palette_type == 0 ) { for ( i = 0 ; i < palette_colors_count ; + + i ) { cin - > palette[i] = bytestream_get_le24 ( & buf ) ; bitmap_frame_size - = 3 ; } } else { for ( i = 0 ; i < palette_colors_count ; + + i ) { cin - > palette[buf[0]] = AV_RL24 ( buf + 1 ) ; buf + = 4 ; bitmap_frame_size - = 4 ; } } memcpy ( cin - > frame . data[1] , cin - > palette , sizeof ( cin - > palette ) ) ; cin - > frame . palette_has_changed = 1 ; / * note : the decoding routines below assumes that surface . width = surface . pitch * / switch ( bitmap_frame_type ) { case 9 : cin_decode_rle ( buf , bitmap_frame_size , cin - > bitmap_table[CIN_CUR_BMP] , cin - > bitmap_size ) ; break ; case 34 : cin_decode_rle ( buf , bitmap_frame_size , cin - > bitmap_table[CIN_CUR_BMP] , cin - > bitmap_size ) ; cin_apply_delta_data ( cin - > bitmap_table[CIN_PRE_BMP] , cin - > bitmap_table[CIN_CUR_BMP] , cin - > bitmap_size ) ; break ; case 35 : cin_decode_huffman ( buf , bitmap_frame_size , cin - > bitmap_table[CIN_INT_BMP] , cin - > bitmap_size ) ; cin_decode_rle ( cin - > bitmap_table[CIN_INT_BMP] , bitmap_frame_size , cin - > bitmap_table[CIN_CUR_BMP] , cin - > bitmap_size ) ; break ; case 36 : bitmap_frame_size = cin_decode_huffman ( buf , bitmap_frame_size , cin - > bitmap_table[CIN_INT_BMP] , cin - > bitmap_size ) ; cin_decode_rle ( cin - > bitmap_table[CIN_INT_BMP] , bitmap_frame_size , cin - > bitmap_table[CIN_CUR_BMP] , cin - > bitmap_size ) ; cin_apply_delta_data ( cin - > bitmap_table[CIN_PRE_BMP] , cin - > bitmap_table[CIN_CUR_BMP] , cin - > bitmap_size ) ; break ; case 37 : cin_decode_huffman ( buf , bitmap_frame_size , cin - > bitmap_table[CIN_CUR_BMP] , cin - > bitmap_size ) ; break ; case 38 : cin_decode_lzss ( buf , bitmap_frame_size , cin - > bitmap_table[CIN_CUR_BMP] , cin - > bitmap_size ) ; break ; case 39 : cin_decode_lzss ( buf , bitmap_frame_size , cin - > bitmap_table[CIN_CUR_BMP] , cin - > bitmap_size ) ; cin_apply_delta_data ( cin - > bitmap_table[CIN_PRE_BMP] , cin - > bitmap_table[CIN_CUR_BMP] , cin - > bitmap_size ) ; break ; } for ( y = 0 ; y < cin - > avctx - > height ; + + y ) memcpy ( cin - > frame . data[0] + ( cin - > avctx - > height - 1 - y ) * cin - > frame . linesize[0] , cin - > bitmap_table[CIN_CUR_BMP] + y * cin - > avctx - > width , cin - > avctx - > width ) ; FFSWAP ( uint8_t * , cin - > bitmap_table[CIN_CUR_BMP] , cin - > bitmap_table[CIN_PRE_BMP] ) ; * data_size = sizeof ( AVFrame ) ; * ( AVFrame * ) data = cin - > frame ; return buf_size ; }",1
"static void RENAME ( decode_rgb_frame ) ( FFV1Context * s , uint8_t * src[3] , int w , int h , int stride[3] ) { int x , y , p ; TYPE * sample[4][2] ; int lbd = s - > avctx - > bits_per_raw_sample < = 8 ; int bits = s - > avctx - > bits_per_raw_sample > 0 ? s - > avctx - > bits_per_raw_sample : 8 ; int offset = 1 < < bits ; for ( x = 0 ; x < 4 ; x + + ) { sample[x][0] = RENAME ( s - > sample_buffer ) + x * 2 * ( w + 6 ) + 3 ; sample[x][1] = RENAME ( s - > sample_buffer ) + ( x * 2 + 1 ) * ( w + 6 ) + 3 ; } s - > run_index = 0 ; memset ( RENAME ( s - > sample_buffer ) , 0 , 8 * ( w + 6 ) * sizeof ( * RENAME ( s - > sample_buffer ) ) ) ; for ( y = 0 ; y < h ; y + + ) { for ( p = 0 ; p < 3 + s - > transparency ; p + + ) { TYPE * temp = sample[p][0] ; // FIXME : try a normal buffer sample[p][0] = sample[p][1] ; sample[p][1] = temp ; sample[p][1][ - 1]= sample[p][0][0 ] ; sample[p][0][ w]= sample[p][0][w - 1] ; if ( lbd & & s - > slice_coding_mode == 0 ) RENAME ( decode_line ) ( s , w , sample[p] , ( p + 1 ) /2 , 9 ) ; else RENAME ( decode_line ) ( s , w , sample[p] , ( p + 1 ) /2 , bits + ( s - > slice_coding_mode ! = 1 ) ) ; } for ( x = 0 ; x < w ; x + + ) { int g = sample[0][1][x] ; int b = sample[1][1][x] ; int r = sample[2][1][x] ; int a = sample[3][1][x] ; if ( s - > slice_coding_mode ! = 1 ) { b - = offset ; r - = offset ; g - = ( b * s - > slice_rct_by_coef + r * s - > slice_rct_ry_coef ) > > 2 ; b + = g ; r + = g ; } if ( lbd ) * ( ( uint32_t * ) ( src[0] + x * 4 + stride[0] * y ) ) = b + ( g < < 8 ) + ( r < < 16 ) + ( a < < 24 ) ; else if ( sizeof ( TYPE ) == 4 ) { * ( ( uint16_t * ) ( src[0] + x * 2 + stride[0] * y ) ) = g ; * ( ( uint16_t * ) ( src[1] + x * 2 + stride[1] * y ) ) = b ; * ( ( uint16_t * ) ( src[2] + x * 2 + stride[2] * y ) ) = r ; } else { * ( ( uint16_t * ) ( src[0] + x * 2 + stride[0] * y ) ) = b ; * ( ( uint16_t * ) ( src[1] + x * 2 + stride[1] * y ) ) = g ; * ( ( uint16_t * ) ( src[2] + x * 2 + stride[2] * y ) ) = r ; } } } }",1
"void ff_af_queue_remove ( AudioFrameQueue * afq , int nb_samples , int64_t * pts , int * duration ) { int64_t out_pts = AV_NOPTS_VALUE ; int removed_samples = 0 ; ifdef DEBUG ff_af_queue_log_state ( afq ) ; endif / * get output pts from the next frame or generated pts * / if ( afq - > frame_queue ) { if ( afq - > frame_queue - > pts ! = AV_NOPTS_VALUE ) out_pts = afq - > frame_queue - > pts - afq - > remaining_delay ; } else { if ( afq - > next_pts ! = AV_NOPTS_VALUE ) out_pts = afq - > next_pts - afq - > remaining_delay ; } if ( pts ) { if ( out_pts ! = AV_NOPTS_VALUE ) * pts = ff_samples_to_time_base ( afq - > avctx , out_pts ) ; else * pts = AV_NOPTS_VALUE ; } / * if the delay is larger than the packet duration , we use up delay samples for the output packet and leave all frames in the queue * / if ( afq - > remaining_delay > = nb_samples ) { removed_samples + = nb_samples ; afq - > remaining_delay - = nb_samples ; } / * remove frames from the queue until we have enough to cover the requested number of samples or until the queue is empty * / while ( removed_samples < nb_samples & & afq - > frame_queue ) { removed_samples + = afq - > frame_queue - > duration ; delete_next_frame ( afq ) ; } afq - > remaining_samples - = removed_samples ; / * if there are no frames left and we have room for more samples , use any remaining delay samples * / if ( removed_samples < nb_samples & & afq - > remaining_samples > 0 ) { int add_samples = FFMIN ( afq - > remaining_samples , nb_samples - removed_samples ) ; removed_samples + = add_samples ; afq - > remaining_samples - = add_samples ; } if ( removed_samples > nb_samples ) av_log ( afq - > avctx , AV_LOG_WARNING , frame_size is too large\n ) ; if ( duration ) * duration = ff_samples_to_time_base ( afq - > avctx , removed_samples ) ; }",0
"QPEL_H264 ( put_ , PUT_OP , mmxext ) QPEL_H264 ( avg_ , AVG_MMXEXT_OP , mmxext ) QPEL_H264_V_XMM ( put_ , PUT_OP , sse2 ) QPEL_H264_V_XMM ( avg_ , AVG_MMXEXT_OP , sse2 ) QPEL_H264_HV_XMM ( put_ , PUT_OP , sse2 ) QPEL_H264_HV_XMM ( avg_ , AVG_MMXEXT_OP , sse2 ) QPEL_H264_H_XMM ( put_ , PUT_OP , ssse3 ) QPEL_H264_H_XMM ( avg_ , AVG_MMXEXT_OP , ssse3 ) QPEL_H264_HV_XMM ( put_ , PUT_OP , ssse3 ) QPEL_H264_HV_XMM ( avg_ , AVG_MMXEXT_OP , ssse3 ) undef PAVGB H264_MC_4816 ( mmxext ) H264_MC_816 ( H264_MC_V , sse2 ) H264_MC_816 ( H264_MC_HV , sse2 ) H264_MC_816 ( H264_MC_H , ssse3 ) H264_MC_816 ( H264_MC_HV , ssse3 ) //10bit define LUMA_MC_OP ( OP , NUM , DEPTH , TYPE , OPT ) \ void ff_ OP _h264_qpel NUM _ TYPE _ DEPTH _ OPT \ ( uint8_t * dst , uint8_t * src , int stride ) ; define LUMA_MC_ALL ( DEPTH , TYPE , OPT ) \ LUMA_MC_OP ( put , 4 , DEPTH , TYPE , OPT ) \ LUMA_MC_OP ( avg , 4 , DEPTH , TYPE , OPT ) \ LUMA_MC_OP ( put , 8 , DEPTH , TYPE , OPT ) \ LUMA_MC_OP ( avg , 8 , DEPTH , TYPE , OPT ) \ LUMA_MC_OP ( put , 16 , DEPTH , TYPE , OPT ) \ LUMA_MC_OP ( avg , 16 , DEPTH , TYPE , OPT ) define LUMA_MC_816 ( DEPTH , TYPE , OPT ) \ LUMA_MC_OP ( put , 8 , DEPTH , TYPE , OPT ) \ LUMA_MC_OP ( avg , 8 , DEPTH , TYPE , OPT ) \ LUMA_MC_OP ( put , 16 , DEPTH , TYPE , OPT ) \ LUMA_MC_OP ( avg , 16 , DEPTH , TYPE , OPT ) LUMA_MC_ALL ( 10 , mc00 , mmxext ) LUMA_MC_ALL ( 10 , mc10 , mmxext ) LUMA_MC_ALL ( 10 , mc20 , mmxext ) LUMA_MC_ALL ( 10 , mc30 , mmxext ) LUMA_MC_ALL ( 10 , mc01 , mmxext ) LUMA_MC_ALL ( 10 , mc11 , mmxext ) LUMA_MC_ALL ( 10 , mc21 , mmxext ) LUMA_MC_ALL ( 10 , mc31 , mmxext ) LUMA_MC_ALL ( 10 , mc02 , mmxext ) LUMA_MC_ALL ( 10 , mc12 , mmxext ) LUMA_MC_ALL ( 10 , mc22 , mmxext ) LUMA_MC_ALL ( 10 , mc32 , mmxext ) LUMA_MC_ALL ( 10 , mc03 , mmxext ) LUMA_MC_ALL ( 10 , mc13 , mmxext ) LUMA_MC_ALL ( 10 , mc23 , mmxext ) LUMA_MC_ALL ( 10 , mc33 , mmxext ) LUMA_MC_816 ( 10 , mc00 , sse2 ) LUMA_MC_816 ( 10 , mc10 , sse2 ) LUMA_MC_816 ( 10 , mc10 , sse2_cache64 ) LUMA_MC_816 ( 10 , mc10 , ssse3_cache64 ) LUMA_MC_816 ( 10 , mc20 , sse2 ) LUMA_MC_816 ( 10 , mc20 , sse2_cache64 ) LUMA_MC_816 ( 10 , mc20 , ssse3_cache64 ) LUMA_MC_816 ( 10 , mc30 , sse2 ) LUMA_MC_816 ( 10 , mc30 , sse2_cache64 ) LUMA_MC_816 ( 10 , mc30 , ssse3_cache64 ) LUMA_MC_816 ( 10 , mc01 , sse2 ) LUMA_MC_816 ( 10 , mc11 , sse2 ) LUMA_MC_816 ( 10 , mc21 , sse2 ) LUMA_MC_816 ( 10 , mc31 , sse2 ) LUMA_MC_816 ( 10 , mc02 , sse2 ) LUMA_MC_816 ( 10 , mc12 , sse2 ) LUMA_MC_816 ( 10 , mc22 , sse2 ) LUMA_MC_816 ( 10 , mc32 , sse2 ) LUMA_MC_816 ( 10 , mc03 , sse2 ) LUMA_MC_816 ( 10 , mc13 , sse2 ) LUMA_MC_816 ( 10 , mc23 , sse2 ) LUMA_MC_816 ( 10 , mc33 , sse2 ) define QPEL16_OPMC ( OP , MC , MMX ) \ void ff_ OP _h264_qpel16_ MC _10_ MMX ( uint8_t * dst , uint8_t * src , int stride ) { \ ff_ OP _h264_qpel8_ MC _10_ MMX ( dst , src , stride ) ; \ ff_ OP _h264_qpel8_ MC _10_ MMX ( dst + 16 , src + 16 , stride ) ; \ src + = 8 * stride ; \ dst + = 8 * stride ; \ ff_ OP _h264_qpel8_ MC _10_ MMX ( dst , src , stride ) ; \ ff_ OP _h264_qpel8_ MC _10_ MMX ( dst + 16 , src + 16 , stride ) ; \ } define QPEL16_OP ( MC , MMX ) \ QPEL16_OPMC ( put , MC , MMX ) \ QPEL16_OPMC ( avg , MC , MMX ) define QPEL16 ( MMX ) \ QPEL16_OP ( mc00 , MMX ) \ QPEL16_OP ( mc01 , MMX ) \ QPEL16_OP ( mc02 , MMX ) \ QPEL16_OP ( mc03 , MMX ) \ QPEL16_OP ( mc10 , MMX ) \ QPEL16_OP ( mc11 , MMX ) \ QPEL16_OP ( mc12 , MMX ) \ QPEL16_OP ( mc13 , MMX ) \ QPEL16_OP ( mc20 , MMX ) \ QPEL16_OP ( mc21 , MMX ) \ QPEL16_OP ( mc22 , MMX ) \ QPEL16_OP ( mc23 , MMX ) \ QPEL16_OP ( mc30 , MMX ) \ QPEL16_OP ( mc31 , MMX ) \ QPEL16_OP ( mc32 , MMX ) \ QPEL16_OP ( mc33 , MMX ) if ARCH_X86_32 & & HAVE_YASM & & CONFIG_H264QPEL // ARCH_X86_64 implies SSE2 + QPEL16 ( mmxext ) endif endif / * HAVE_YASM * / define SET_QPEL_FUNCS ( PFX , IDX , SIZE , CPU , PREFIX ) \ do { \ c - > PFX _pixels_tab[IDX][ 0] = PREFIX PFX SIZE _mc00_ CPU ; \ c - > PFX _pixels_tab[IDX][ 1] = PREFIX PFX SIZE _mc10_ CPU ; \ c - > PFX _pixels_tab[IDX][ 2] = PREFIX PFX SIZE _mc20_ CPU ; \ c - > PFX _pixels_tab[IDX][ 3] = PREFIX PFX SIZE _mc30_ CPU ; \ c - > PFX _pixels_tab[IDX][ 4] = PREFIX PFX SIZE _mc01_ CPU ; \ c - > PFX _pixels_tab[IDX][ 5] = PREFIX PFX SIZE _mc11_ CPU ; \ c - > PFX _pixels_tab[IDX][ 6] = PREFIX PFX SIZE _mc21_ CPU ; \ c - > PFX _pixels_tab[IDX][ 7] = PREFIX PFX SIZE _mc31_ CPU ; \ c - > PFX _pixels_tab[IDX][ 8] = PREFIX PFX SIZE _mc02_ CPU ; \ c - > PFX _pixels_tab[IDX][ 9] = PREFIX PFX SIZE _mc12_ CPU ; \ c - > PFX _pixels_tab[IDX][10] = PREFIX PFX SIZE _mc22_ CPU ; \ c - > PFX _pixels_tab[IDX][11] = PREFIX PFX SIZE _mc32_ CPU ; \ c - > PFX _pixels_tab[IDX][12] = PREFIX PFX SIZE _mc03_ CPU ; \ c - > PFX _pixels_tab[IDX][13] = PREFIX PFX SIZE _mc13_ CPU ; \ c - > PFX _pixels_tab[IDX][14] = PREFIX PFX SIZE _mc23_ CPU ; \ c - > PFX _pixels_tab[IDX][15] = PREFIX PFX SIZE _mc33_ CPU ; \ } while ( 0 ) define H264_QPEL_FUNCS ( x , y , CPU ) \ do { \ c - > put_h264_qpel_pixels_tab[0][x + y * 4] = put_h264_qpel16_mc x y _ CPU ; \ c - > put_h264_qpel_pixels_tab[1][x + y * 4] = put_h264_qpel8_mc x y _ CPU ; \ c - > avg_h264_qpel_pixels_tab[0][x + y * 4] = avg_h264_qpel16_mc x y _ CPU ; \ c - > avg_h264_qpel_pixels_tab[1][x + y * 4] = avg_h264_qpel8_mc x y _ CPU ;",0
"static int decode_lowdelay ( DiracContext * s ) { AVCodecContext * avctx = s - > avctx ; int slice_x , slice_y , bufsize ; int64_t coef_buf_size , bytes = 0 ; const uint8_t * buf ; DiracSlice * slices ; SliceCoeffs tmp[MAX_DWT_LEVELS] ; int slice_num = 0 ; if ( s - > slice_params_num_buf ! = ( s - > num_x * s - > num_y ) ) { s - > slice_params_buf = av_realloc_f ( s - > slice_params_buf , s - > num_x * s - > num_y , sizeof ( DiracSlice ) ) ; if ( ! s - > slice_params_buf ) { av_log ( s - > avctx , AV_LOG_ERROR , slice params buffer allocation failure\n ) ; return AVERROR ( ENOMEM ) ; } s - > slice_params_num_buf = s - > num_x * s - > num_y ; } slices = s - > slice_params_buf ; / * 8 becacuse that ' s how much the golomb reader could overread junk data * from another plane/slice at most , and 512 because SIMD * / coef_buf_size = subband_coeffs ( s , s - > num_x - 1 , s - > num_y - 1 , 0 , tmp ) + 8 ; coef_buf_size = ( coef_buf_size < < ( 1 + s - > pshift ) ) + 512 ; if ( s - > threads_num_buf ! = avctx - > thread_count || s - > thread_buf_size ! = coef_buf_size ) { s - > threads_num_buf = avctx - > thread_count ; s - > thread_buf_size = coef_buf_size ; s - > thread_buf = av_realloc_f ( s - > thread_buf , avctx - > thread_count , s - > thread_buf_size ) ; if ( ! s - > thread_buf ) { av_log ( s - > avctx , AV_LOG_ERROR , thread buffer allocation failure\n ) ; return AVERROR ( ENOMEM ) ; } } align_get_bits ( & s - > gb ) ; / * [DIRAC_STD] 13 . 5 . 2 Slices . slice ( sx , sy ) * / buf = s - > gb . buffer + get_bits_count ( & s - > gb ) /8 ; bufsize = get_bits_left ( & s - > gb ) ; if ( s - > hq_picture ) { int i ; for ( slice_y = 0 ; bufsize > 0 & & slice_y < s - > num_y ; slice_y + + ) { for ( slice_x = 0 ; bufsize > 0 & & slice_x < s - > num_x ; slice_x + + ) { bytes = s - > highquality . prefix_bytes + 1 ; for ( i = 0 ; i < 3 ; i + + ) { if ( bytes < = bufsize/8 ) bytes + = buf[bytes] * s - > highquality . size_scaler + 1 ; } if ( bytes > = INT_MAX || bytes * 8 > bufsize ) { av_log ( s - > avctx , AV_LOG_ERROR , too many bytes\n ) ; return AVERROR_INVALIDDATA ; } slices[slice_num] . bytes = bytes ; slices[slice_num] . slice_x = slice_x ; slices[slice_num] . slice_y = slice_y ; init_get_bits ( & slices[slice_num] . gb , buf , bufsize ) ; slice_num + + ; buf + = bytes ; if ( bufsize/8 > = bytes ) bufsize - = bytes * 8 ; else bufsize = 0 ; } } if ( s - > num_x * s - > num_y ! = slice_num ) { av_log ( s - > avctx , AV_LOG_ERROR , too few slices\n ) ; return AVERROR_INVALIDDATA ; } avctx - > execute2 ( avctx , decode_hq_slice_row , slices , NULL , s - > num_y ) ; } else { for ( slice_y = 0 ; bufsize > 0 & & slice_y < s - > num_y ; slice_y + + ) { for ( slice_x = 0 ; bufsize > 0 & & slice_x < s - > num_x ; slice_x + + ) { bytes = ( slice_num + 1 ) * ( int64_t ) s - > lowdelay . bytes . num / s - > lowdelay . bytes . den - slice_num * ( int64_t ) s - > lowdelay . bytes . num / s - > lowdelay . bytes . den ; slices[slice_num] . bytes = bytes ; slices[slice_num] . slice_x = slice_x ; slices[slice_num] . slice_y = slice_y ; init_get_bits ( & slices[slice_num] . gb , buf , bufsize ) ; slice_num + + ; buf + = bytes ; if ( bufsize/8 > = bytes ) bufsize - = bytes * 8 ; else bufsize = 0 ; } } avctx - > execute ( avctx , decode_lowdelay_slice , slices , NULL , slice_num , sizeof ( DiracSlice ) ) ; / * [DIRAC_STD] 13 . 5 . 2 Slices * / } if ( s - > dc_prediction ) { if ( s - > pshift ) { intra_dc_prediction_10 ( & s - > plane[0] . band[0][0] ) ; / * [DIRAC_STD] 13 . 3 intra_dc_prediction ( ) * / intra_dc_prediction_10 ( & s - > plane[1] . band[0][0] ) ; / * [DIRAC_STD] 13 . 3 intra_dc_prediction ( ) * / intra_dc_prediction_10 ( & s - > plane[2] . band[0][0] ) ; / * [DIRAC_STD] 13 . 3 intra_dc_prediction ( ) * / } else { intra_dc_prediction_8 ( & s - > plane[0] . band[0][0] ) ; intra_dc_prediction_8 ( & s - > plane[1] . band[0][0] ) ; intra_dc_prediction_8 ( & s - > plane[2] . band[0][0] ) ; } } return 0 ; }",1
"static int xface_encode_frame ( AVCodecContext * avctx , AVPacket * pkt , const AVFrame * frame , int * got_packet ) { XFaceContext * xface = avctx - > priv_data ; ProbRangesQueue pq = { { 0 } , 0 } ; uint8_t bitmap_copy[XFACE_PIXELS] ; BigInt b = { 0 } ; int i , j , k , ret = 0 ; const uint8_t * buf ; uint8_t * p ; char intbuf[XFACE_MAX_DIGITS] ; if ( avctx - > width || avctx - > height ) { if ( avctx - > width ! = XFACE_WIDTH || avctx - > height ! = XFACE_HEIGHT ) { av_log ( avctx , AV_LOG_ERROR , Size value %dx%d not supported , only accepts a size of %dx%d\n , avctx - > width , avctx - > height , XFACE_WIDTH , XFACE_HEIGHT ) ; return AVERROR ( EINVAL ) ; } } avctx - > width = XFACE_WIDTH ; avctx - > height = XFACE_HEIGHT ; / * convert image from MONOWHITE to 1=black 0=white bitmap * / buf = frame - > data[0] ; i = j = 0 ; do { for ( k = 0 ; k < 8 ; k + + ) xface - > bitmap[i + + ] = ( buf[j] > > ( 7 - k ) ) & 1 ; if ( + + j == XFACE_WIDTH/8 ) { buf + = frame - > linesize[0] ; j = 0 ; } } while ( i < XFACE_PIXELS ) ; / * create a copy of bitmap * / memcpy ( bitmap_copy , xface - > bitmap , XFACE_PIXELS ) ; ff_xface_generate_face ( xface - > bitmap , bitmap_copy ) ; encode_block ( xface - > bitmap , 16 , 16 , 0 , & pq ) ; encode_block ( xface - > bitmap + 16 , 16 , 16 , 0 , & pq ) ; encode_block ( xface - > bitmap + 32 , 16 , 16 , 0 , & pq ) ; encode_block ( xface - > bitmap + XFACE_WIDTH * 16 , 16 , 16 , 0 , & pq ) ; encode_block ( xface - > bitmap + XFACE_WIDTH * 16 + 16 , 16 , 16 , 0 , & pq ) ; encode_block ( xface - > bitmap + XFACE_WIDTH * 16 + 32 , 16 , 16 , 0 , & pq ) ; encode_block ( xface - > bitmap + XFACE_WIDTH * 32 , 16 , 16 , 0 , & pq ) ; encode_block ( xface - > bitmap + XFACE_WIDTH * 32 + 16 , 16 , 16 , 0 , & pq ) ; encode_block ( xface - > bitmap + XFACE_WIDTH * 32 + 32 , 16 , 16 , 0 , & pq ) ; while ( pq . prob_ranges_idx > 0 ) push_integer ( & b , pq . prob_ranges[ - - pq . prob_ranges_idx] ) ; / * write the inverted big integer in b to intbuf * / i = 0 ; while ( b . nb_words ) { uint8_t r ; ff_big_div ( & b , XFACE_PRINTS , & r ) ; intbuf[i + + ] = r + XFACE_FIRST_PRINT ; } if ( ( ret = ff_alloc_packet2 ( avctx , pkt , i + 2 ) ) < 0 ) return ret ; / * revert the number , and close the buffer * / p = pkt - > data ; while ( - - i > = 0 ) * ( p + + ) = intbuf[i] ; * ( p + + ) = ' \n ' ; * ( p + + ) = 0 ; pkt - > flags |= AV_PKT_FLAG_KEY ; * got_packet = 1 ; return 0 ; }",1
"static int mov_text_decode_frame ( AVCodecContext * avctx , void * data , int * got_sub_ptr , AVPacket * avpkt ) { AVSubtitle * sub = data ; int ret , ts_start , ts_end ; AVBPrint buf ; char * ptr = avpkt - > data ; char * end ; //char * ptr_temp ; int text_length , tsmb_type , style_entries , tsmb_size ; int * * style_start = { 0 , } ; int * * style_end = { 0 , } ; int * * style_flags = { 0 , } ; const uint8_t * tsmb ; int index , i ; int * flag ; int * style_pos ; if ( ! ptr || avpkt - > size < 2 ) return AVERROR_INVALIDDATA ; / * * A packet of size two with value zero is an empty subtitle * used to mark the end of the previous non - empty subtitle . * We can just drop them here as we have duration information * already . If the value is non - zero , then it ' s technically a * bad packet . * / if ( avpkt - > size == 2 ) return AV_RB16 ( ptr ) == 0 ? 0 : AVERROR_INVALIDDATA ; / * * The first two bytes of the packet are the length of the text string * In complex cases , there are style descriptors appended to the string * so we can ' t just assume the packet size is the string size . * / text_length = AV_RB16 ( ptr ) ; end = ptr + FFMIN ( 2 + text_length , avpkt - > size ) ; ptr + = 2 ; ts_start = av_rescale_q ( avpkt - > pts , avctx - > time_base , ( AVRational ) { 1 , 100 } ) ; ts_end = av_rescale_q ( avpkt - > pts + avpkt - > duration , avctx - > time_base , ( AVRational ) { 1 , 100 } ) ; tsmb_size = 0 ; // Note that the spec recommends lines be no longer than 2048 characters . av_bprint_init ( & buf , 0 , AV_BPRINT_SIZE_UNLIMITED ) ; if ( text_length + 2 ! = avpkt - > size ) { while ( text_length + 2 + tsmb_size < avpkt - > size ) { tsmb = ptr + text_length + tsmb_size ; tsmb_size = AV_RB32 ( tsmb ) ; tsmb + = 4 ; tsmb_type = AV_RB32 ( tsmb ) ; tsmb + = 4 ; if ( tsmb_type == MKBETAG ( ' s ' , ' t ' , ' y ' , ' l ' ) ) { style_entries = AV_RB16 ( tsmb ) ; tsmb + = 2 ; for ( i = 0 ; i < style_entries ; i + + ) { style_pos = av_malloc ( 4 ) ; * style_pos = AV_RB16 ( tsmb ) ; index = i ; av_dynarray_add ( & style_start , & index , style_pos ) ; tsmb + = 2 ; style_pos = av_malloc ( 4 ) ; * style_pos = AV_RB16 ( tsmb ) ; index = i ; av_dynarray_add ( & style_end , & index , style_pos ) ; tsmb + = 2 ; // fontID = AV_RB16 ( tsmb ) ; tsmb + = 2 ; flag = av_malloc ( 4 ) ; * flag = AV_RB8 ( tsmb ) ; index = i ; av_dynarray_add ( & style_flags , & index , flag ) ; //fontsize=AV_RB8 ( tsmb ) ; tsmb + = 2 ; // text - color - rgba tsmb + = 4 ; } text_to_ass ( & buf , ptr , end , style_start , style_end , style_flags , style_entries ) ; av_freep ( & style_start ) ; av_freep ( & style_end ) ; av_freep ( & style_flags ) ; } } } else text_to_ass ( & buf , ptr , end , NULL , NULL , 0 , 0 ) ; ret = ff_ass_add_rect_bprint ( sub , & buf , ts_start , ts_end - ts_start ) ; av_bprint_finalize ( & buf , NULL ) ; if ( ret < 0 ) return ret ; * got_sub_ptr = sub - > num_rects > 0 ; return avpkt - > size ; }",1
"av_cold void ff_snow_common_end ( SnowContext * s ) { int plane_index , level , orientation , i ; av_freep ( & s - > spatial_dwt_buffer ) ; av_freep ( & s - > temp_dwt_buffer ) ; av_freep ( & s - > spatial_idwt_buffer ) ; av_freep ( & s - > temp_idwt_buffer ) ; av_freep ( & s - > run_buffer ) ; s - > m . me . temp= NULL ; av_freep ( & s - > m . me . scratchpad ) ; av_freep ( & s - > m . me . map ) ; av_freep ( & s - > m . me . score_map ) ; av_freep ( & s - > m . obmc_scratchpad ) ; av_freep ( & s - > block ) ; av_freep ( & s - > scratchbuf ) ; av_freep ( & s - > emu_edge_buffer ) ; for ( i=0 ; i < MAX_REF_FRAMES ; i + + ) { av_freep ( & s - > ref_mvs[i] ) ; av_freep ( & s - > ref_scores[i] ) ; if ( s - > last_picture[i] - > data[0] ) { av_assert0 ( s - > last_picture[i] - > data[0] ! = s - > current_picture - > data[0] ) ; } av_frame_free ( & s - > last_picture[i] ) ; } for ( plane_index=0 ; plane_index < s - > nb_planes ; plane_index + + ) { for ( level=s - > spatial_decomposition_count - 1 ; level > =0 ; level - - ) { for ( orientation=level ? 1 : 0 ; orientation < 4 ; orientation + + ) { SubBand * b= & s - > plane[plane_index] . band[level][orientation] ; av_freep ( & b - > x_coeff ) ; } } } av_frame_free ( & s - > mconly_picture ) ; av_frame_free ( & s - > current_picture ) ; }",1
"static int decode_frame ( AVCodecContext * avctx , void * data , int * data_size , UINT8 * buf , int buf_size ) { MPADecodeContext * s = avctx - > priv_data ; UINT32 header ; UINT8 * buf_ptr ; int len , out_size ; short * out_samples = data ; * data_size = 0 ; buf_ptr = buf ; while ( buf_size > 0 ) { len = s - > inbuf_ptr - s - > inbuf ; if ( s - > frame_size == 0 ) { / * special case for next header for first frame in free format case ( XXX : find a simpler method ) * / if ( s - > free_format_next_header ! = 0 ) { s - > inbuf[0] = s - > free_format_next_header > > 24 ; s - > inbuf[1] = s - > free_format_next_header > > 16 ; s - > inbuf[2] = s - > free_format_next_header > > 8 ; s - > inbuf[3] = s - > free_format_next_header ; s - > inbuf_ptr = s - > inbuf + 4 ; s - > free_format_next_header = 0 ; goto got_header ; } / * no header seen : find one . We need at least HEADER_SIZE bytes to parse it * / len = HEADER_SIZE - len ; if ( len > buf_size ) len = buf_size ; if ( len > 0 ) { memcpy ( s - > inbuf_ptr , buf_ptr , len ) ; buf_ptr + = len ; buf_size - = len ; s - > inbuf_ptr + = len ; } if ( ( s - > inbuf_ptr - s - > inbuf ) > = HEADER_SIZE ) { got_header : header = ( s - > inbuf[0] < < 24 ) | ( s - > inbuf[1] < < 16 ) | ( s - > inbuf[2] < < 8 ) | s - > inbuf[3] ; if ( check_header ( header ) < 0 ) { / * no sync found : move by one byte ( inefficient , but simple ! ) * / memcpy ( s - > inbuf , s - > inbuf + 1 , s - > inbuf_ptr - s - > inbuf - 1 ) ; s - > inbuf_ptr - - ; dprintf ( skip %x\n , header ) ; / * reset free format frame size to give a chance to get a new bitrate * / s - > free_format_frame_size = 0 ; } else { if ( decode_header ( s , header ) == 1 ) { / * free format : compute frame size * / s - > frame_size = - 1 ; memcpy ( s - > inbuf , s - > inbuf + 1 , s - > inbuf_ptr - s - > inbuf - 1 ) ; s - > inbuf_ptr - - ; } else { / * update codec info * / avctx - > sample_rate = s - > sample_rate ; avctx - > channels = s - > nb_channels ; avctx - > bit_rate = s - > bit_rate ; avctx - > frame_size = s - > frame_size ; } } } } else if ( s - > frame_size == - 1 ) { / * free format : find next sync to compute frame size * / len = MPA_MAX_CODED_FRAME_SIZE - len ; if ( len > buf_size ) len = buf_size ; if ( len == 0 ) { / * frame too long : resync * / s - > frame_size = 0 ; } else { UINT8 * p , * pend ; UINT32 header1 ; int padding ; memcpy ( s - > inbuf_ptr , buf_ptr , len ) ; / * check for header * / p = s - > inbuf_ptr - 3 ; pend = s - > inbuf_ptr + len - 4 ; while ( p < = pend ) { header = ( p[0] < < 24 ) | ( p[1] < < 16 ) | ( p[2] < < 8 ) | p[3] ; header1 = ( s - > inbuf[0] < < 24 ) | ( s - > inbuf[1] < < 16 ) | ( s - > inbuf[2] < < 8 ) | s - > inbuf[3] ; / * check with high probability that we have a valid header * / if ( ( header & SAME_HEADER_MASK ) == ( header1 & SAME_HEADER_MASK ) ) { / * header found : update pointers * / len = ( p + 4 ) - s - > inbuf_ptr ; buf_ptr + = len ; buf_size - = len ; s - > inbuf_ptr = p ; / * compute frame size * / s - > free_format_next_header = header ; s - > free_format_frame_size = s - > inbuf_ptr - s - > inbuf ; padding = ( header1 > > 9 ) & 1 ; if ( s - > layer == 1 ) s - > free_format_frame_size - = padding * 4 ; else s - > free_format_frame_size - = padding ; dprintf ( free frame size=%d padding=%d\n , s - > free_format_frame_size , padding ) ; decode_header ( s , header1 ) ; goto next_data ; } p + + ; } / * not found : simply increase pointers * / buf_ptr + = len ; s - > inbuf_ptr + = len ; buf_size - = len ; } } else if ( len < s - > frame_size ) { if ( s - > frame_size > MPA_MAX_CODED_FRAME_SIZE ) s - > frame_size = MPA_MAX_CODED_FRAME_SIZE ; len = s - > frame_size - len ; if ( len > buf_size ) len = buf_size ; else if ( len < 4 ) len = buf_size > 4 ? 4 : buf_size ; memcpy ( s - > inbuf_ptr , buf_ptr , len ) ; buf_ptr + = len ; s - > inbuf_ptr + = len ; buf_size - = len ; } else { out_size = mp_decode_frame ( s , out_samples ) ; s - > inbuf_ptr = s - > inbuf ; s - > frame_size = 0 ; * data_size = out_size ; break ; } next_data : } return buf_ptr - buf ; }",0
"static void mov_write_uuidprof_tag ( AVIOContext * pb , AVFormatContext * s ) { AVStream * video_st = s - > streams[0] ; AVCodecParameters * video_par = s - > streams[0] - > codecpar ; AVCodecParameters * audio_par = s - > streams[1] - > codecpar ; int audio_rate = audio_par - > sample_rate ; int64_t frame_rate = ( video_st - > avg_frame_rate . num * 0x10000LL ) / video_st - > avg_frame_rate . den ; int audio_kbitrate = audio_par - > bit_rate / 1000 ; int video_kbitrate = FFMIN ( video_par - > bit_rate / 1000 , 800 - audio_kbitrate ) ; avio_wb32 ( pb , 0x94 ) ; / * size * / ffio_wfourcc ( pb , uuid ) ; ffio_wfourcc ( pb , PROF ) ; avio_wb32 ( pb , 0x21d24fce ) ; / * 96 bit UUID * / avio_wb32 ( pb , 0xbb88695c ) ; avio_wb32 ( pb , 0xfac9c740 ) ; avio_wb32 ( pb , 0x0 ) ; / * ? * / avio_wb32 ( pb , 0x3 ) ; / * 3 sections ? * / avio_wb32 ( pb , 0x14 ) ; / * size * / ffio_wfourcc ( pb , FPRF ) ; avio_wb32 ( pb , 0x0 ) ; / * ? * / avio_wb32 ( pb , 0x0 ) ; / * ? * / avio_wb32 ( pb , 0x0 ) ; / * ? * / avio_wb32 ( pb , 0x2c ) ; / * size * / ffio_wfourcc ( pb , APRF ) ; / * audio * / avio_wb32 ( pb , 0x0 ) ; avio_wb32 ( pb , 0x2 ) ; / * TrackID * / ffio_wfourcc ( pb , mp4a ) ; avio_wb32 ( pb , 0x20f ) ; avio_wb32 ( pb , 0x0 ) ; avio_wb32 ( pb , audio_kbitrate ) ; avio_wb32 ( pb , audio_kbitrate ) ; avio_wb32 ( pb , audio_rate ) ; avio_wb32 ( pb , audio_par - > channels ) ; avio_wb32 ( pb , 0x34 ) ; / * size * / ffio_wfourcc ( pb , VPRF ) ; / * video * / avio_wb32 ( pb , 0x0 ) ; avio_wb32 ( pb , 0x1 ) ; / * TrackID * / if ( video_par - > codec_id == AV_CODEC_ID_H264 ) { ffio_wfourcc ( pb , avc1 ) ; avio_wb16 ( pb , 0x014D ) ; avio_wb16 ( pb , 0x0015 ) ; } else { ffio_wfourcc ( pb , mp4v ) ; avio_wb16 ( pb , 0x0000 ) ; avio_wb16 ( pb , 0x0103 ) ; } avio_wb32 ( pb , 0x0 ) ; avio_wb32 ( pb , video_kbitrate ) ; avio_wb32 ( pb , video_kbitrate ) ; avio_wb32 ( pb , frame_rate ) ; avio_wb32 ( pb , frame_rate ) ; avio_wb16 ( pb , video_par - > width ) ; avio_wb16 ( pb , video_par - > height ) ; avio_wb32 ( pb , 0x010001 ) ; / * ? * / }",0
"void rgb32tobgr24 ( const uint8_t * src , uint8_t * dst , unsigned int src_size ) { unsigned i ; unsigned num_pixels = src_size > > 2 ; for ( i=0 ; i < num_pixels ; i + + ) { dst[3 * i + 0] = src[4 * i + 2] ; dst[3 * i + 1] = src[4 * i + 1] ; dst[3 * i + 2] = src[4 * i + 0] ; } }",1
"static double get_diff_limited_q ( MpegEncContext * s , RateControlEntry * rce , double q ) { RateControlContext * rcc= & s - > rc_context ; AVCodecContext * a= s - > avctx ; const int pict_type= rce - > new_pict_type ; const double last_p_q = rcc - > last_qscale_for[P_TYPE] ; const double last_non_b_q= rcc - > last_qscale_for[rcc - > last_non_b_pict_type] ; if ( pict_type==I_TYPE & & ( a - > i_quant_factor > 0 . 0 || rcc - > last_non_b_pict_type==P_TYPE ) ) q= last_p_q * FFABS ( a - > i_quant_factor ) + a - > i_quant_offset ; else if ( pict_type==B_TYPE & & a - > b_quant_factor > 0 . 0 ) q= last_non_b_q * a - > b_quant_factor + a - > b_quant_offset ; / * last qscale / qdiff stuff * / if ( rcc - > last_non_b_pict_type==pict_type || pict_type ! =I_TYPE ) { double last_q= rcc - > last_qscale_for[pict_type] ; const int maxdiff= FF_QP2LAMBDA * a - > max_qdiff ; if ( q > last_q + maxdiff ) q= last_q + maxdiff ; else if ( q < last_q - maxdiff ) q= last_q - maxdiff ; } rcc - > last_qscale_for[pict_type]= q ; //Note we cannot do that after blurring if ( pict_type ! =B_TYPE ) rcc - > last_non_b_pict_type= pict_type ; return q ; }",1
"static int ftp_store ( FTPContext * s ) { char command[CONTROL_BUFFER_SIZE] ; const int stor_codes[] = { 150 , 0 } ; snprintf ( command , sizeof ( command ) , STOR %s\r\n , s - > path ) ; if ( ! ftp_send_command ( s , command , stor_codes , NULL ) ) return AVERROR ( EIO ) ; s - > state = UPLOADING ; return 0 ; }",0
"enum AVPixelFormat avpriv_fmt_v4l2ff ( uint32_t v4l2_fmt , enum AVCodecID codec_id ) { int i ; for ( i = 0 ; avpriv_fmt_conversion_table[i] . codec_id ! = AV_CODEC_ID_NONE ; i + + ) { if ( avpriv_fmt_conversion_table[i] . v4l2_fmt == v4l2_fmt & & avpriv_fmt_conversion_table[i] . codec_id == codec_id ) { return avpriv_fmt_conversion_table[i] . ff_fmt ; } } return AV_PIX_FMT_NONE ; }",0
"void ff_rtp_send_mpegvideo ( AVFormatContext * s1 , const uint8_t * buf1 , int size ) { RTPDemuxContext * s = s1 - > priv_data ; int len , h , max_packet_size ; uint8_t * q ; int begin_of_slice , end_of_slice , frame_type , temporal_reference ; max_packet_size = s - > max_payload_size ; begin_of_slice = 1 ; end_of_slice = 0 ; frame_type = 0 ; temporal_reference = 0 ; while ( size > 0 ) { int begin_of_sequence ; begin_of_sequence = 0 ; len = max_packet_size - 4 ; if ( len > = size ) { len = size ; end_of_slice = 1 ; } else { const uint8_t * r , * r1 ; int start_code ; r1 = buf1 ; while ( 1 ) { start_code = - 1 ; r = ff_find_start_code ( r1 , buf1 + size , & start_code ) ; if ( ( start_code & 0xFFFFFF00 ) == 0x100 ) { / * New start code found * / if ( start_code == 0x100 ) { frame_type = ( r[1] & 0x38 ) > > 3 ; temporal_reference = ( int ) r[0] < < 2 | r[1] > > 6 ; } if ( start_code == 0x1B8 ) { begin_of_sequence = 1 ; } if ( r - buf1 < len ) { / * The current slice fits in the packet * / if ( begin_of_slice == 0 ) { / * no slice at the beginning of the packet . . . * / end_of_slice = 1 ; len = r - buf1 - 4 ; break ; } r1 = r ; } else { if ( r - r1 < max_packet_size ) { len = r1 - buf1 - 4 ; end_of_slice = 1 ; } break ; } } else { break ; } } } h = 0 ; h |= temporal_reference < < 16 ; h |= begin_of_sequence < < 13 ; h |= begin_of_slice < < 12 ; h |= end_of_slice < < 11 ; h |= frame_type < < 8 ; q = s - > buf ; * q + + = h > > 24 ; * q + + = h > > 16 ; * q + + = h > > 8 ; * q + + = h ; memcpy ( q , buf1 , len ) ; q + = len ; / * 90 KHz time stamp * / s - > timestamp = s - > cur_timestamp ; ff_rtp_send_data ( s1 , s - > buf , q - s - > buf , ( len == size ) ) ; buf1 + = len ; size - = len ; begin_of_slice = end_of_slice ; end_of_slice = 0 ; } }",0
"static int mov_write_hdlr_tag ( AVIOContext * pb , MOVTrack * track ) { const char * hdlr , * descr = NULL , * hdlr_type = NULL ; int64_t pos = avio_tell ( pb ) ; if ( ! track ) { / * no media - - > data handler * / hdlr = dhlr ; hdlr_type = url ; descr = DataHandler ; } else { hdlr = ( track - > mode == MODE_MOV ) ? mhlr : \0\0\0\0 ; if ( track - > enc - > codec_type == AVMEDIA_TYPE_VIDEO ) { hdlr_type = vide ; descr = VideoHandler ; } else if ( track - > enc - > codec_type == AVMEDIA_TYPE_AUDIO ) { hdlr_type = soun ; descr = SoundHandler ; } else if ( track - > enc - > codec_type == AVMEDIA_TYPE_SUBTITLE ) { if ( track - > tag == MKTAG ( ' t ' , ' x ' , ' 3 ' , ' g ' ) ) hdlr_type = sbtl ; else hdlr_type = text ; descr = SubtitleHandler ; } else if ( track - > enc - > codec_tag == MKTAG ( ' r ' , ' t ' , ' p ' , ' ' ) ) { hdlr_type = hint ; descr = HintHandler ; } } avio_wb32 ( pb , 0 ) ; / * size * / ffio_wfourcc ( pb , hdlr ) ; avio_wb32 ( pb , 0 ) ; / * Version & flags * / avio_write ( pb , hdlr , 4 ) ; / * handler * / ffio_wfourcc ( pb , hdlr_type ) ; / * handler type * / avio_wb32 ( pb , 0 ) ; / * reserved * / avio_wb32 ( pb , 0 ) ; / * reserved * / avio_wb32 ( pb , 0 ) ; / * reserved * / if ( ! track || track - > mode == MODE_MOV ) avio_w8 ( pb , strlen ( descr ) ) ; / * pascal string * / avio_write ( pb , descr , strlen ( descr ) ) ; / * handler description * / if ( track & & track - > mode ! = MODE_MOV ) avio_w8 ( pb , 0 ) ; / * c string * / return update_size ( pb , pos ) ; }",0
"static void check_consistency ( FFFrameQueue * fq ) { if ASSERT_LEVEL > = 2 uint64_t nb_samples = 0 ; size_t i ; av_assert0 ( fq - > queued == fq - > total_frames_head - fq - > total_frames_tail ) ; for ( i = 0 ; i < fq - > queued ; i + + ) nb_samples + = bucket ( fq , i ) - > frame - > nb_samples ; av_assert0 ( nb_samples == fq - > total_samples_head - fq - > total_samples_tail ) ; endif }",0
"static void sdt_cb ( MpegTSFilter * filter , const uint8_t * section , int section_len ) { MpegTSContext * ts = filter - > u . section_filter . opaque ; SectionHeader h1 , * h = & h1 ; const uint8_t * p , * p_end , * desc_list_end , * desc_end ; int onid , val , sid , desc_list_len , desc_tag , desc_len , service_type ; char * name , * provider_name ; av_dlog ( ts - > stream , SDT : \n ) ; hex_dump_debug ( ts - > stream , section , section_len ) ; p_end = section + section_len - 4 ; p = section ; if ( parse_section_header ( h , & p , p_end ) < 0 ) return ; if ( h - > tid ! = SDT_TID ) return ; if ( ts - > skip_changes ) return ; onid = get16 ( & p , p_end ) ; if ( onid < 0 ) return ; val = get8 ( & p , p_end ) ; if ( val < 0 ) return ; for ( ; ; ) { sid = get16 ( & p , p_end ) ; if ( sid < 0 ) break ; val = get8 ( & p , p_end ) ; if ( val < 0 ) break ; desc_list_len = get16 ( & p , p_end ) ; if ( desc_list_len < 0 ) break ; desc_list_len & = 0xfff ; desc_list_end = p + desc_list_len ; if ( desc_list_end > p_end ) break ; for ( ; ; ) { desc_tag = get8 ( & p , desc_list_end ) ; if ( desc_tag < 0 ) break ; desc_len = get8 ( & p , desc_list_end ) ; desc_end = p + desc_len ; if ( desc_end > desc_list_end ) break ; av_dlog ( ts - > stream , tag : 0x%02x len=%d\n , desc_tag , desc_len ) ; switch ( desc_tag ) { case 0x48 : service_type = get8 ( & p , p_end ) ; if ( service_type < 0 ) break ; provider_name = getstr8 ( & p , p_end ) ; if ( ! provider_name ) break ; name = getstr8 ( & p , p_end ) ; if ( name ) { AVProgram * program = av_new_program ( ts - > stream , sid ) ; if ( program ) { av_dict_set ( & program - > metadata , service_name , name , 0 ) ; av_dict_set ( & program - > metadata , service_provider , provider_name , 0 ) ; } } av_free ( name ) ; av_free ( provider_name ) ; break ; default : break ; } p = desc_end ; } p = desc_list_end ; } }",0
"void ff_hevc_deblocking_boundary_strengths ( HEVCContext * s , int x0 , int y0 , int log2_trafo_size , int slice_or_tiles_up_boundary , int slice_or_tiles_left_boundary ) { MvField * tab_mvf = s - > ref - > tab_mvf ; int log2_min_pu_size = s - > sps - > log2_min_pu_size ; int log2_min_tu_size = s - > sps - > log2_min_tb_size ; int min_pu_width = s - > sps - > min_pu_width ; int min_tu_width = s - > sps - > min_tb_width ; int is_intra = tab_mvf[ ( y0 > > log2_min_pu_size ) * min_pu_width + ( x0 > > log2_min_pu_size ) ] . is_intra ; int i , j , bs ; if ( y0 > 0 & & ( y0 & 7 ) == 0 ) { int yp_pu = ( y0 - 1 ) > > log2_min_pu_size ; int yq_pu = y0 > > log2_min_pu_size ; int yp_tu = ( y0 - 1 ) > > log2_min_tu_size ; int yq_tu = y0 > > log2_min_tu_size ; for ( i = 0 ; i < ( 1 < < log2_trafo_size ) ; i + = 4 ) { int x_pu = ( x0 + i ) > > log2_min_pu_size ; int x_tu = ( x0 + i ) > > log2_min_tu_size ; MvField * top = & tab_mvf[yp_pu * min_pu_width + x_pu] ; MvField * curr = & tab_mvf[yq_pu * min_pu_width + x_pu] ; uint8_t top_cbf_luma = s - > cbf_luma[yp_tu * min_tu_width + x_tu] ; uint8_t curr_cbf_luma = s - > cbf_luma[yq_tu * min_tu_width + x_tu] ; RefPicList * top_refPicList = ff_hevc_get_ref_list ( s , s - > ref , x0 + i , y0 - 1 ) ; bs = boundary_strength ( s , curr , curr_cbf_luma , top , top_cbf_luma , top_refPicList , 1 ) ; if ( ! s - > sh . slice_loop_filter_across_slices_enabled_flag & & ( slice_or_tiles_up_boundary & 1 ) & & ( y0 % ( 1 < < s - > sps - > log2_ctb_size ) ) == 0 ) bs = 0 ; else if ( ! s - > pps - > loop_filter_across_tiles_enabled_flag & & ( slice_or_tiles_up_boundary & 2 ) & & ( y0 % ( 1 < < s - > sps - > log2_ctb_size ) ) == 0 ) bs = 0 ; if ( y0 == 0 || s - > sh . disable_deblocking_filter_flag == 1 ) bs = 0 ; if ( bs ) s - > horizontal_bs[ ( ( x0 + i ) + y0 * s - > bs_width ) > > 2] = bs ; } } // bs for TU internal horizontal PU boundaries if ( log2_trafo_size > s - > sps - > log2_min_pu_size & & ! is_intra ) for ( j = 8 ; j < ( 1 < < log2_trafo_size ) ; j + = 8 ) { int yp_pu = ( y0 + j - 1 ) > > log2_min_pu_size ; int yq_pu = ( y0 + j ) > > log2_min_pu_size ; int yp_tu = ( y0 + j - 1 ) > > log2_min_tu_size ; int yq_tu = ( y0 + j ) > > log2_min_tu_size ; for ( i = 0 ; i < ( 1 < < log2_trafo_size ) ; i + = 4 ) { int x_pu = ( x0 + i ) > > log2_min_pu_size ; int x_tu = ( x0 + i ) > > log2_min_tu_size ; MvField * top = & tab_mvf[yp_pu * min_pu_width + x_pu] ; MvField * curr = & tab_mvf[yq_pu * min_pu_width + x_pu] ; uint8_t top_cbf_luma = s - > cbf_luma[yp_tu * min_tu_width + x_tu] ; uint8_t curr_cbf_luma = s - > cbf_luma[yq_tu * min_tu_width + x_tu] ; RefPicList * top_refPicList = ff_hevc_get_ref_list ( s , s - > ref , x0 + i , y0 + j - 1 ) ; bs = boundary_strength ( s , curr , curr_cbf_luma , top , top_cbf_luma , top_refPicList , 0 ) ; if ( s - > sh . disable_deblocking_filter_flag == 1 ) bs = 0 ; if ( bs ) s - > horizontal_bs[ ( ( x0 + i ) + ( y0 + j ) * s - > bs_width ) > > 2] = bs ; } } // bs for vertical TU boundaries if ( x0 > 0 & & ( x0 & 7 ) == 0 ) { int xp_pu = ( x0 - 1 ) > > log2_min_pu_size ; int xq_pu = x0 > > log2_min_pu_size ; int xp_tu = ( x0 - 1 ) > > log2_min_tu_size ; int xq_tu = x0 > > log2_min_tu_size ; for ( i = 0 ; i < ( 1 < < log2_trafo_size ) ; i + = 4 ) { int y_pu = ( y0 + i ) > > log2_min_pu_size ; int y_tu = ( y0 + i ) > > log2_min_tu_size ; MvField * left = & tab_mvf[y_pu * min_pu_width + xp_pu] ; MvField * curr = & tab_mvf[y_pu * min_pu_width + xq_pu] ; uint8_t left_cbf_luma = s - > cbf_luma[y_tu * min_tu_width + xp_tu] ; uint8_t curr_cbf_luma = s - > cbf_luma[y_tu * min_tu_width + xq_tu] ; RefPicList * left_refPicList = ff_hevc_get_ref_list ( s , s - > ref , x0 - 1 , y0 + i ) ; bs = boundary_strength ( s , curr , curr_cbf_luma , left , left_cbf_luma , left_refPicList , 1 ) ; if ( ! s - > sh . slice_loop_filter_across_slices_enabled_flag & & ( slice_or_tiles_left_boundary & 1 ) & & ( x0 % ( 1 < < s - > sps - > log2_ctb_size ) ) == 0 ) bs = 0 ; else if ( ! s - > pps - > loop_filter_across_tiles_enabled_flag & & ( slice_or_tiles_left_boundary & 2 ) & & ( x0 % ( 1 < < s - > sps - > log2_ctb_size ) ) == 0 ) bs = 0 ; if ( x0 == 0 || s - > sh . disable_deblocking_filter_flag == 1 ) bs = 0 ; if ( bs ) s - > vertical_bs[ ( x0 > > 3 ) + ( ( y0 + i ) > > 2 ) * s - > bs_width] = bs ; } } // bs for TU internal vertical PU boundaries if ( log2_trafo_size > log2_min_pu_size & & ! is_intra ) for ( j = 0 ; j < ( 1 < < log2_trafo_size ) ; j + = 4 ) { int y_pu = ( y0 + j ) > > log2_min_pu_size ; int y_tu = ( y0 + j ) > > log2_min_tu_size ; for ( i = 8 ; i < ( 1 < < log2_trafo_size ) ; i + = 8 ) { int xp_pu = ( x0 + i - 1 ) > > log2_min_pu_size ; int xq_pu = ( x0 + i ) > > log2_min_pu_size ; int xp_tu = ( x0 + i - 1 ) > > log2_min_tu_size ; int xq_tu = ( x0 + i ) > > log2_min_tu_size ; MvField * left = & tab_mvf[y_pu * min_pu_width + xp_pu] ; MvField * curr = & tab_mvf[y_pu * min_pu_width + xq_pu] ;",0
"static int swf_write_audio ( AVFormatContext * s , const uint8_t * buf , int size ) { ByteIOContext * pb = & s - > pb ; put_swf_tag ( s , TAG_STREAMBLOCK | TAG_LONG ) ; put_buffer ( pb , buf , size ) ; put_swf_end_tag ( s ) ; put_flush_packet ( & s - > pb ) ; return 0 ; }",1
"static int avisynth_read_packet_audio ( AVFormatContext * s , AVPacket * pkt , int discard ) { AviSynthContext * avs = s - > priv_data ; AVRational fps , samplerate ; int samples ; const char * error ; if ( avs - > curr_sample > = avs - > vi - > num_audio_samples ) return AVERROR_EOF ; fps . num = avs - > vi - > fps_numerator ; fps . den = avs - > vi - > fps_denominator ; samplerate . num = avs - > vi - > audio_samples_per_second ; samplerate . den = 1 ; if ( avs_has_video ( avs - > vi ) ) { if ( avs - > curr_frame < avs - > vi - > num_frames ) samples = av_rescale_q ( avs - > curr_frame , samplerate , fps ) - avs - > curr_sample ; else samples = av_rescale_q ( 1 , samplerate , fps ) ; } else { samples = 1000 ; } // After seeking , audio may catch up with video . if ( samples < = 0 ) { pkt - > size = 0 ; pkt - > data = NULL ; return 0 ; } if ( avs - > curr_sample + samples > avs - > vi - > num_audio_samples ) samples = avs - > vi - > num_audio_samples - avs - > curr_sample ; // This must happen even if the stream is discarded to prevent desync . avs - > curr_sample + = samples ; if ( discard ) return 0 ; pkt - > pts = avs - > curr_sample ; pkt - > dts = avs - > curr_sample ; pkt - > duration = samples ; pkt - > size = avs_bytes_per_channel_sample ( avs - > vi ) * samples * avs - > vi - > nchannels ; if ( ! pkt - > size ) return AVERROR_UNKNOWN ; pkt - > data = av_malloc ( pkt - > size ) ; if ( ! pkt - > data ) return AVERROR_UNKNOWN ; avs_library - > avs_get_audio ( avs - > clip , pkt - > data , avs - > curr_sample , samples ) ; error = avs_library - > avs_clip_get_error ( avs - > clip ) ; if ( error ) { av_log ( s , AV_LOG_ERROR , %s\n , error ) ; avs - > error = 1 ; av_freep ( & pkt - > data ) ; return AVERROR_UNKNOWN ; } return 0 ; }",1
"static int vc1_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size , n_slices = 0 , i , ret ; VC1Context * v = avctx - > priv_data ; MpegEncContext * s = & v - > s ; AVFrame * pict = data ; uint8_t * buf2 = NULL ; const uint8_t * buf_start = buf ; int mb_height , n_slices1 ; struct { uint8_t * buf ; GetBitContext gb ; int mby_start ; } * slices = NULL , * tmp ; / * no supplementary picture * / if ( buf_size == 0 || ( buf_size == 4 & & AV_RB32 ( buf ) == VC1_CODE_ENDOFSEQ ) ) { / * special case for last picture * / if ( s - > low_delay == 0 & & s - > next_picture_ptr ) { if ( ( ret = av_frame_ref ( pict , & s - > next_picture_ptr - > f ) ) < 0 ) return ret ; s - > next_picture_ptr = NULL ; * got_frame = 1 ; } return 0 ; } //for advanced profile we may need to parse and unescape data if ( avctx - > codec_id == AV_CODEC_ID_VC1 || avctx - > codec_id == AV_CODEC_ID_VC1IMAGE ) { int buf_size2 = 0 ; buf2 = av_mallocz ( buf_size + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( IS_MARKER ( AV_RB32 ( buf ) ) ) { / * frame starts with marker and needs to be parsed * / const uint8_t * start , * end , * next ; int size ; next = buf ; for ( start = buf , end = buf + buf_size ; next < end ; start = next ) { next = find_next_marker ( start + 4 , end ) ; size = next - start - 4 ; if ( size < = 0 ) continue ; switch ( AV_RB32 ( start ) ) { case VC1_CODE_FRAME : if ( avctx - > hwaccel ) buf_start = start ; buf_size2 = vc1_unescape_buffer ( start + 4 , size , buf2 ) ; break ; case VC1_CODE_FIELD : { int buf_size3 ; tmp = av_realloc ( slices , sizeof ( * slices ) * ( n_slices + 1 ) ) ; if ( ! tmp ) goto err ; slices = tmp ; slices[n_slices] . buf = av_mallocz ( buf_size + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! slices[n_slices] . buf ) goto err ; buf_size3 = vc1_unescape_buffer ( start + 4 , size , slices[n_slices] . buf ) ; init_get_bits ( & slices[n_slices] . gb , slices[n_slices] . buf , buf_size3 < < 3 ) ; / * assuming that the field marker is at the exact middle , hope it ' s correct * / slices[n_slices] . mby_start = s - > mb_height > > 1 ; n_slices1 = n_slices - 1 ; // index of the last slice of the first field n_slices + + ; break ; } case VC1_CODE_ENTRYPOINT : / * it should be before frame data * / buf_size2 = vc1_unescape_buffer ( start + 4 , size , buf2 ) ; init_get_bits ( & s - > gb , buf2 , buf_size2 * 8 ) ; ff_vc1_decode_entry_point ( avctx , v , & s - > gb ) ; break ; case VC1_CODE_SLICE : { int buf_size3 ; tmp = av_realloc ( slices , sizeof ( * slices ) * ( n_slices + 1 ) ) ; if ( ! tmp ) goto err ; slices = tmp ; slices[n_slices] . buf = av_mallocz ( buf_size + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! slices[n_slices] . buf ) goto err ; buf_size3 = vc1_unescape_buffer ( start + 4 , size , slices[n_slices] . buf ) ; init_get_bits ( & slices[n_slices] . gb , slices[n_slices] . buf , buf_size3 < < 3 ) ; slices[n_slices] . mby_start = get_bits ( & slices[n_slices] . gb , 9 ) ; n_slices + + ; break ; } } } } else if ( v - > interlace & & ( ( buf[0] & 0xC0 ) == 0xC0 ) ) { / * WVC1 interlaced stores both fields divided by marker * / const uint8_t * divider ; int buf_size3 ; divider = find_next_marker ( buf , buf + buf_size ) ; if ( ( divider == ( buf + buf_size ) ) || AV_RB32 ( divider ) ! = VC1_CODE_FIELD ) { av_log ( avctx , AV_LOG_ERROR , Error in WVC1 interlaced frame\n ) ; goto err ; } else { // found field marker , unescape second field tmp = av_realloc ( slices , sizeof ( * slices ) * ( n_slices + 1 ) ) ; if ( ! tmp ) goto err ; slices = tmp ; slices[n_slices] . buf = av_mallocz ( buf_size + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! slices[n_slices] . buf ) goto err ; buf_size3 = vc1_unescape_buffer ( divider + 4 , buf + buf_size - divider - 4 , slices[n_slices] . buf ) ; init_get_bits ( & slices[n_slices] . gb , slices[n_slices] . buf , buf_size3 < < 3 ) ; slices[n_slices] . mby_start = s - > mb_height > > 1 ; n_slices1 = n_slices - 1 ; n_slices + + ; } buf_size2 = vc1_unescape_buffer ( buf , divider - buf , buf2 ) ; } else { buf_size2 = vc1_unescape_buffer ( buf , buf_size , buf2 ) ; } init_get_bits ( & s - > gb , buf2 , buf_size2 * 8 ) ; } else init_get_bits ( & s - > gb , buf , buf_size * 8 ) ; if ( v - > res_sprite ) { v - > new_sprite = ! get_bits1 ( & s - > gb ) ; v - > two_sprites = get_bits1 ( & s - > gb ) ; / * res_sprite means a Windows Media Image stream , AV_CODEC_ID_ * IMAGE means we ' re using the sprite compositor . These are intentionally kept separate so you can get the raw sprites by using the wmv3 decoder for WMVP or the vc1 one for WVP2 * / if ( avctx - > codec_id == AV_CODEC_ID_WMV3IMAGE || avctx - > codec_id == AV_CODEC_ID_VC1IMAGE ) { if ( v - > new_sprite ) { // switch AVCodecContext parameters to those of the sprites avctx - > width = avctx - > coded_width = v - > sprite_width ; avctx - > height = avctx - > coded_height = v - > sprite_height ; } else { goto image ; } } } if ( s - > context_initialized & & ( s - > width ! = avctx - > coded_width || s - > height ! = avctx - > coded_height ) ) { ff_vc1_decode_end ( avctx ) ; } if ( ! s - > context_initialized ) { if ( ff_msmpeg4_decode_init ( avctx ) < 0 ) goto err ; if ( ff_vc1_decode_init_alloc_tables ( v ) < 0 ) { ff_MPV_common_end ( s ) ; goto",1
"altivec_yuv2packedX ( SwsContext * c , int16_t * lumFilter , int16_t * * lumSrc , int lumFilterSize , int16_t * chrFilter , int16_t * * chrSrc , int chrFilterSize , uint8_t * dest , int dstW , int dstY ) { int i , j ; short tmp __attribute__ ( ( aligned ( 16 ) ) ) ; int16_t * p ; short * f ; vector signed short X , X0 , X1 , Y0 , U0 , V0 , Y1 , U1 , V1 , U , V ; vector signed short R0 , G0 , B0 , R1 , G1 , B1 ; vector unsigned char R , G , B , pels[3] ; vector unsigned char * out , * nout ; vector signed short RND = vec_splat ( ( vector signed short ) AVV ( 1 < < 3 ) , 0 ) ; vector unsigned short SCL = vec_splat ( ( vector unsigned short ) AVV ( 4 ) , 0 ) ; unsigned long scratch[16] __attribute__ ( ( aligned ( 16 ) ) ) ; vector signed short * vYCoeffsBank , * vCCoeffsBank ; vector signed short * YCoeffs , * CCoeffs ; vYCoeffsBank = malloc ( sizeof ( vector signed short ) * lumFilterSize * dstW ) ; vCCoeffsBank = malloc ( sizeof ( vector signed short ) * chrFilterSize * dstW ) ; for ( i=0 ; i < lumFilterSize * dstW ; i + + ) { tmp = c - > vLumFilter[i] ; p = & vYCoeffsBank[i] ; for ( j=0 ; j < 8 ; j + + ) p[j] = tmp ; } for ( i=0 ; i < chrFilterSize * dstW ; i + + ) { tmp = c - > vChrFilter[i] ; p = & vCCoeffsBank[i] ; for ( j=0 ; j < 8 ; j + + ) p[j] = tmp ; } YCoeffs = vYCoeffsBank + dstY * lumFilterSize ; CCoeffs = vCCoeffsBank + dstY * chrFilterSize ; out = ( vector unsigned char * ) dest ; for ( i=0 ; i < dstW ; i + =16 ) { Y0 = RND ; Y1 = RND ; / * extract 16 coeffs from lumSrc * / for ( j=0 ; j < lumFilterSize ; j + + ) { X0 = vec_ld ( 0 , & lumSrc[j][i] ) ; X1 = vec_ld ( 16 , & lumSrc[j][i] ) ; Y0 = vec_mradds ( X0 , YCoeffs[j] , Y0 ) ; Y1 = vec_mradds ( X1 , YCoeffs[j] , Y1 ) ; } U = RND ; V = RND ; / * extract 8 coeffs from U , V * / for ( j=0 ; j < chrFilterSize ; j + + ) { X = vec_ld ( 0 , & chrSrc[j][i/2] ) ; U = vec_mradds ( X , CCoeffs[j] , U ) ; X = vec_ld ( 0 , & chrSrc[j][i/2 + 2048] ) ; V = vec_mradds ( X , CCoeffs[j] , V ) ; } / * scale and clip signals * / Y0 = vec_sra ( Y0 , SCL ) ; Y1 = vec_sra ( Y1 , SCL ) ; U = vec_sra ( U , SCL ) ; V = vec_sra ( V , SCL ) ; Y0 = vec_clip ( Y0 ) ; Y1 = vec_clip ( Y1 ) ; U = vec_clip ( U ) ; V = vec_clip ( V ) ; / * now we have Y0= y0 y1 y2 y3 y4 y5 y6 y7 Y1= y8 y9 y10 y11 y12 y13 y14 y15 U= u0 u1 u2 u3 u4 u5 u6 u7 V= v0 v1 v2 v3 v4 v5 v6 v7 Y0= y0 y1 y2 y3 y4 y5 y6 y7 Y1= y8 y9 y10 y11 y12 y13 y14 y15 U0= u0 u0 u1 u1 u2 u2 u3 u3 U1= u4 u4 u5 u5 u6 u6 u7 u7 V0= v0 v0 v1 v1 v2 v2 v3 v3 V1= v4 v4 v5 v5 v6 v6 v7 v7 * / U0 = vec_mergeh ( U , U ) ; V0 = vec_mergeh ( V , V ) ; U1 = vec_mergel ( U , U ) ; V1 = vec_mergel ( V , V ) ; cvtyuvtoRGB ( c , Y0 , U0 , V0 , & R0 , & G0 , & B0 ) ; cvtyuvtoRGB ( c , Y1 , U1 , V1 , & R1 , & G1 , & B1 ) ; R = vec_packclp ( R0 , R1 ) ; G = vec_packclp ( G0 , G1 ) ; B = vec_packclp ( B0 , B1 ) ; out_rgba ( R , G , B , out ) ; } if ( i < dstW ) { i - = 16 ; Y0 = RND ; Y1 = RND ; / * extract 16 coeffs from lumSrc * / for ( j=0 ; j < lumFilterSize ; j + + ) { X0 = vec_ld ( 0 , & lumSrc[j][i] ) ; X1 = vec_ld ( 16 , & lumSrc[j][i] ) ; Y0 = vec_mradds ( X0 , YCoeffs[j] , Y0 ) ; Y1 = vec_mradds ( X1 , YCoeffs[j] , Y1 ) ; } U = RND ; V = RND ; / * extract 8 coeffs from U , V * / for ( j=0 ; j < chrFilterSize ; j + + ) { X = vec_ld ( 0 , & chrSrc[j][i/2] ) ; U = vec_mradds ( X , CCoeffs[j] , U ) ; X = vec_ld ( 0 , & chrSrc[j][i/2 + 2048] ) ; V = vec_mradds ( X , CCoeffs[j] , V ) ; } / * scale and clip signals * / Y0 = vec_sra ( Y0 , SCL ) ; Y1 = vec_sra ( Y1 , SCL ) ; U = vec_sra ( U , SCL ) ; V = vec_sra ( V , SCL ) ; Y0 = vec_clip ( Y0 ) ; Y1 = vec_clip ( Y1 ) ; U = vec_clip ( U ) ; V = vec_clip ( V ) ; / * now we have Y0= y0 y1 y2 y3 y4 y5 y6 y7 Y1= y8 y9 y10 y11 y12 y13 y14 y15 U= u0 u1 u2 u3 u4 u5 u6 u7 V= v0 v1 v2 v3 v4 v5 v6 v7 Y0= y0 y1 y2 y3 y4 y5 y6 y7 Y1= y8 y9 y10 y11 y12 y13 y14 y15 U0= u0 u0 u1 u1 u2 u2 u3 u3 U1= u4 u4 u5 u5 u6 u6 u7 u7 V0= v0 v0 v1 v1 v2 v2 v3 v3 V1= v4 v4 v5 v5 v6 v6 v7 v7 * / U0 = vec_mergeh ( U , U ) ; V0 = vec_mergeh ( V , V ) ; U1 = vec_mergel ( U , U ) ; V1 = vec_mergel ( V , V ) ; cvtyuvtoRGB ( c , Y0 , U0 , V0 , & R0 , & G0 , & B0 ) ; cvtyuvtoRGB ( c , Y1 , U1 , V1 , & R1 , & G1 , & B1 ) ;",0
"static av_cold int vaapi_encode_h265_init_fixed_qp ( AVCodecContext * avctx ) { VAAPIEncodeContext * ctx = avctx - > priv_data ; VAAPIEncodeH265Context * priv = ctx - > priv_data ; VAAPIEncodeH265Options * opt = ctx - > codec_options ; priv - > fixed_qp_p = opt - > qp ; if ( avctx - > i_quant_factor > 0 . 0 ) priv - > fixed_qp_idr = ( int ) ( ( priv - > fixed_qp_p * avctx - > i_quant_factor + avctx - > i_quant_offset ) + 0 . 5 ) ; else priv - > fixed_qp_idr = priv - > fixed_qp_p ; if ( avctx - > b_quant_factor > 0 . 0 ) priv - > fixed_qp_b = ( int ) ( ( priv - > fixed_qp_p * avctx - > b_quant_factor + avctx - > b_quant_offset ) + 0 . 5 ) ; else priv - > fixed_qp_b = priv - > fixed_qp_p ; av_log ( avctx , AV_LOG_DEBUG , Using fixed QP = %d / %d / %d for IDR - / P - / B - frames . \n , priv - > fixed_qp_idr , priv - > fixed_qp_p , priv - > fixed_qp_b ) ; return 0 ; }",0
"int av_parser_parse2 ( AVCodecParserContext * s , AVCodecContext * avctx , uint8_t * * poutbuf , int * poutbuf_size , const uint8_t * buf , int buf_size , int64_t pts , int64_t dts , int64_t pos ) { int index , i ; uint8_t dummy_buf[FF_INPUT_BUFFER_PADDING_SIZE] ; if ( ! ( s - > flags & PARSER_FLAG_FETCHED_OFFSET ) ) { s - > next_frame_offset = s - > cur_offset = pos ; s - > flags |= PARSER_FLAG_FETCHED_OFFSET ; } if ( buf_size == 0 ) { / * padding is always necessary even if EOF , so we add it here * / memset ( dummy_buf , 0 , sizeof ( dummy_buf ) ) ; buf = dummy_buf ; } else if ( s - > cur_offset + buf_size ! = s - > cur_frame_end[s - > cur_frame_start_index] ) { / * skip remainder packets * / / * add a new packet descriptor * / i = ( s - > cur_frame_start_index + 1 ) & ( AV_PARSER_PTS_NB - 1 ) ; s - > cur_frame_start_index = i ; s - > cur_frame_offset[i] = s - > cur_offset ; s - > cur_frame_end[i] = s - > cur_offset + buf_size ; s - > cur_frame_pts[i] = pts ; s - > cur_frame_dts[i] = dts ; s - > cur_frame_pos[i] = pos ; } if ( s - > fetch_timestamp ) { s - > fetch_timestamp = 0 ; s - > last_pts = s - > pts ; s - > last_dts = s - > dts ; s - > last_pos = s - > pos ; ff_fetch_timestamp ( s , 0 , 0 ) ; } / * WARNING : the returned index can be negative * / index = s - > parser - > parser_parse ( s , avctx , ( const uint8_t * * ) poutbuf , poutbuf_size , buf , buf_size ) ; / * update the file pointer * / if ( * poutbuf_size ) { / * fill the data for the current frame * / s - > frame_offset = s - > next_frame_offset ; / * offset of the next frame * / s - > next_frame_offset = s - > cur_offset + index ; s - > fetch_timestamp = 1 ; } if ( index < 0 ) index = 0 ; s - > cur_offset + = index ; return index ; }",1
"av_cold int ff_ac3_encode_init ( AVCodecContext * avctx ) { AC3EncodeContext * s = avctx - > priv_data ; int ret , frame_size_58 ; s - > avctx = avctx ; s - > eac3 = avctx - > codec_id == AV_CODEC_ID_EAC3 ; ff_ac3_common_init ( ) ; ret = validate_options ( s ) ; if ( ret ) return ret ; avctx - > frame_size = AC3_BLOCK_SIZE * s - > num_blocks ; avctx - > delay = AC3_BLOCK_SIZE ; s - > bitstream_mode = avctx - > audio_service_type ; if ( s - > bitstream_mode == AV_AUDIO_SERVICE_TYPE_KARAOKE ) s - > bitstream_mode = 0x7 ; s - > bits_written = 0 ; s - > samples_written = 0 ; / * calculate crc_inv for both possible frame sizes * / frame_size_58 = ( ( s - > frame_size > > 2 ) + ( s - > frame_size > > 4 ) ) < < 1 ; s - > crc_inv[0] = pow_poly ( ( CRC16_POLY > > 1 ) , ( 8 * frame_size_58 ) - 16 , CRC16_POLY ) ; if ( s - > bit_alloc . sr_code == 1 ) { frame_size_58 = ( ( ( s - > frame_size + 2 ) > > 2 ) + ( ( s - > frame_size + 2 ) > > 4 ) ) < < 1 ; s - > crc_inv[1] = pow_poly ( ( CRC16_POLY > > 1 ) , ( 8 * frame_size_58 ) - 16 , CRC16_POLY ) ; } / * set function pointers * / if ( CONFIG_AC3_FIXED_ENCODER & & s - > fixed_point ) { s - > mdct_end = ff_ac3_fixed_mdct_end ; s - > mdct_init = ff_ac3_fixed_mdct_init ; s - > allocate_sample_buffers = ff_ac3_fixed_allocate_sample_buffers ; } else if ( CONFIG_AC3_ENCODER || CONFIG_EAC3_ENCODER ) { s - > mdct_end = ff_ac3_float_mdct_end ; s - > mdct_init = ff_ac3_float_mdct_init ; s - > allocate_sample_buffers = ff_ac3_float_allocate_sample_buffers ; } if ( CONFIG_EAC3_ENCODER & & s - > eac3 ) s - > output_frame_header = ff_eac3_output_frame_header ; else s - > output_frame_header = ac3_output_frame_header ; set_bandwidth ( s ) ; exponent_init ( s ) ; bit_alloc_init ( s ) ; ret = s - > mdct_init ( s ) ; if ( ret ) goto init_fail ; ret = allocate_buffers ( s ) ; if ( ret ) goto init_fail ; ff_audiodsp_init ( & s - > adsp ) ; ff_me_cmp_init ( & s - > mecc , avctx ) ; ff_ac3dsp_init ( & s - > ac3dsp , avctx - > flags & CODEC_FLAG_BITEXACT ) ; dprint_options ( s ) ; return 0 ; init_fail : ff_ac3_encode_close ( avctx ) ; return ret ; }",0
"static int dirac_unpack_prediction_parameters ( DiracContext * s ) { static const uint8_t default_blen[] = { 4 , 12 , 16 , 24 } ; static const uint8_t default_bsep[] = { 4 , 8 , 12 , 16 } ; GetBitContext * gb = & s - > gb ; unsigned idx , ref ; align_get_bits ( gb ) ; / * [DIRAC_STD] 11 . 2 . 2 Block parameters . block_parameters ( ) * / / * Luma and Chroma are equal . 11 . 2 . 3 * / idx = svq3_get_ue_golomb ( gb ) ; / * [DIRAC_STD] index * / if ( idx > 4 ) { av_log ( s - > avctx , AV_LOG_ERROR , Block prediction index too high\n ) ; return - 1 ; } if ( idx == 0 ) { s - > plane[0] . xblen = svq3_get_ue_golomb ( gb ) ; s - > plane[0] . yblen = svq3_get_ue_golomb ( gb ) ; s - > plane[0] . xbsep = svq3_get_ue_golomb ( gb ) ; s - > plane[0] . ybsep = svq3_get_ue_golomb ( gb ) ; } else { / * [DIRAC_STD] preset_block_params ( index ) . Table 11 . 1 * / s - > plane[0] . xblen = default_blen[idx - 1] ; s - > plane[0] . yblen = default_blen[idx - 1] ; s - > plane[0] . xbsep = default_bsep[idx - 1] ; s - > plane[0] . ybsep = default_bsep[idx - 1] ; } / * [DIRAC_STD] 11 . 2 . 4 motion_data_dimensions ( ) Calculated in function dirac_unpack_block_motion_data * / if ( s - > plane[0] . xbsep < s - > plane[0] . xblen/2 || s - > plane[0] . ybsep < s - > plane[0] . yblen/2 ) { av_log ( s - > avctx , AV_LOG_ERROR , Block separation too small\n ) ; return - 1 ; } if ( s - > plane[0] . xbsep > s - > plane[0] . xblen || s - > plane[0] . ybsep > s - > plane[0] . yblen ) { av_log ( s - > avctx , AV_LOG_ERROR , Block seperation greater than size\n ) ; return - 1 ; } if ( FFMAX ( s - > plane[0] . xblen , s - > plane[0] . yblen ) > MAX_BLOCKSIZE ) { av_log ( s - > avctx , AV_LOG_ERROR , Unsupported large block size\n ) ; return - 1 ; } / * [DIRAC_STD] 11 . 2 . 5 Motion vector precision . motion_vector_precision ( ) Read motion vector precision * / s - > mv_precision = svq3_get_ue_golomb ( gb ) ; if ( s - > mv_precision > 3 ) { av_log ( s - > avctx , AV_LOG_ERROR , MV precision finer than eighth - pel\n ) ; return - 1 ; } / * [DIRAC_STD] 11 . 2 . 6 Global motion . global_motion ( ) Read the global motion compensation parameters * / s - > globalmc_flag = get_bits1 ( gb ) ; if ( s - > globalmc_flag ) { memset ( s - > globalmc , 0 , sizeof ( s - > globalmc ) ) ; / * [DIRAC_STD] pan_tilt ( gparams ) * / for ( ref = 0 ; ref < s - > num_refs ; ref + + ) { if ( get_bits1 ( gb ) ) { s - > globalmc[ref] . pan_tilt[0] = dirac_get_se_golomb ( gb ) ; s - > globalmc[ref] . pan_tilt[1] = dirac_get_se_golomb ( gb ) ; } / * [DIRAC_STD] zoom_rotate_shear ( gparams ) zoom/rotation/shear parameters * / if ( get_bits1 ( gb ) ) { s - > globalmc[ref] . zrs_exp = svq3_get_ue_golomb ( gb ) ; s - > globalmc[ref] . zrs[0][0] = dirac_get_se_golomb ( gb ) ; s - > globalmc[ref] . zrs[0][1] = dirac_get_se_golomb ( gb ) ; s - > globalmc[ref] . zrs[1][0] = dirac_get_se_golomb ( gb ) ; s - > globalmc[ref] . zrs[1][1] = dirac_get_se_golomb ( gb ) ; } else { s - > globalmc[ref] . zrs[0][0] = 1 ; s - > globalmc[ref] . zrs[1][1] = 1 ; } / * [DIRAC_STD] perspective ( gparams ) * / if ( get_bits1 ( gb ) ) { s - > globalmc[ref] . perspective_exp = svq3_get_ue_golomb ( gb ) ; s - > globalmc[ref] . perspective[0] = dirac_get_se_golomb ( gb ) ; s - > globalmc[ref] . perspective[1] = dirac_get_se_golomb ( gb ) ; } } } / * [DIRAC_STD] 11 . 2 . 7 Picture prediction mode . prediction_mode ( ) Picture prediction mode , not currently used . * / if ( svq3_get_ue_golomb ( gb ) ) { av_log ( s - > avctx , AV_LOG_ERROR , Unknown picture prediction mode\n ) ; return - 1 ; } / * [DIRAC_STD] 11 . 2 . 8 Reference picture weight . reference_picture_weights ( ) just data read , weight calculation will be done later on . * / s - > weight_log2denom = 1 ; s - > weight[0] = 1 ; s - > weight[1] = 1 ; if ( get_bits1 ( gb ) ) { s - > weight_log2denom = svq3_get_ue_golomb ( gb ) ; s - > weight[0] = dirac_get_se_golomb ( gb ) ; if ( s - > num_refs == 2 ) s - > weight[1] = dirac_get_se_golomb ( gb ) ; } return 0 ; }",0
"static inline void xchg_mb_border ( H264Context * h , uint8_t * src_y , uint8_t * src_cb , uint8_t * src_cr , int linesize , int uvlinesize , int xchg ) { MpegEncContext * const s = & h - > s ; int temp8 , i ; uint64_t temp64 ; src_y - = linesize + 1 ; src_cb - = uvlinesize + 1 ; src_cr - = uvlinesize + 1 ; define XCHG ( a , b , t , xchg ) \ t= a ; \ if ( xchg ) \ a= b ; \ b= t ; for ( i=0 ; i < 17 ; i + + ) { XCHG ( h - > left_border[i ] , src_y [i * linesize] , temp8 , xchg ) ; } XCHG ( * ( uint64_t * ) ( h - > top_border[s - > mb_x] + 0 ) , * ( uint64_t * ) ( src_y + 1 ) , temp64 , xchg ) ; XCHG ( * ( uint64_t * ) ( h - > top_border[s - > mb_x] + 8 ) , * ( uint64_t * ) ( src_y + 9 ) , temp64 , 1 ) ; if ( ! ( s - > flags & CODEC_FLAG_GRAY ) ) { for ( i=0 ; i < 9 ; i + + ) { XCHG ( h - > left_border[i + 17 ] , src_cb[i * uvlinesize] , temp8 , xchg ) ; XCHG ( h - > left_border[i + 17 + 9] , src_cr[i * uvlinesize] , temp8 , xchg ) ; } XCHG ( * ( uint64_t * ) ( h - > top_border[s - > mb_x] + 16 ) , * ( uint64_t * ) ( src_cb + 1 ) , temp64 , 1 ) ; XCHG ( * ( uint64_t * ) ( h - > top_border[s - > mb_x] + 24 ) , * ( uint64_t * ) ( src_cr + 1 ) , temp64 , 1 ) ; } }",1
"void ff_free_stream ( AVFormatContext * s , AVStream * st ) { av_assert0 ( s - > nb_streams > 0 ) ; av_assert0 ( s - > streams[ s - > nb_streams - 1 ] == st ) ; if ( st - > codec ) { avcodec_close ( st - > codec ) ; } if ( st - > parser ) { av_parser_close ( st - > parser ) ; } if ( st - > attached_pic . data ) av_free_packet ( & st - > attached_pic ) ; av_dict_free ( & st - > metadata ) ; av_freep ( & st - > probe_data . buf ) ; av_freep ( & st - > index_entries ) ; av_freep ( & st - > codec - > extradata ) ; av_freep ( & st - > codec - > subtitle_header ) ; av_freep ( & st - > codec ) ; av_freep ( & st - > priv_data ) ; if ( st - > info ) av_freep ( & st - > info - > duration_error ) ; av_freep ( & st - > info ) ; av_freep ( & s - > streams[ - - s - > nb_streams ] ) ; }",1
"ImgReSampleContext * img_resample_full_init ( int owidth , int oheight , int iwidth , int iheight , int topBand , int bottomBand , int leftBand , int rightBand , int padtop , int padbottom , int padleft , int padright ) { ImgReSampleContext * s ; s = av_mallocz ( sizeof ( ImgReSampleContext ) ) ; if ( ! s ) if ( ( unsigned ) owidth > = UINT_MAX / ( LINE_BUF_HEIGHT + NB_TAPS ) ) s - > line_buf = av_mallocz ( owidth * ( LINE_BUF_HEIGHT + NB_TAPS ) ) ; if ( ! s - > line_buf ) goto fail ; s - > owidth = owidth ; s - > oheight = oheight ; s - > iwidth = iwidth ; s - > iheight = iheight ; s - > topBand = topBand ; s - > bottomBand = bottomBand ; s - > leftBand = leftBand ; s - > rightBand = rightBand ; s - > padtop = padtop ; s - > padbottom = padbottom ; s - > padleft = padleft ; s - > padright = padright ; s - > pad_owidth = owidth - ( padleft + padright ) ; s - > pad_oheight = oheight - ( padtop + padbottom ) ; s - > h_incr = ( ( iwidth - leftBand - rightBand ) * POS_FRAC ) / s - > pad_owidth ; s - > v_incr = ( ( iheight - topBand - bottomBand ) * POS_FRAC ) / s - > pad_oheight ; av_build_filter ( & s - > h_filters[0][0] , ( float ) s - > pad_owidth / ( float ) ( iwidth - leftBand - rightBand ) , NB_TAPS , NB_PHASES , 1 < < FILTER_BITS , 0 ) ; av_build_filter ( & s - > v_filters[0][0] , ( float ) s - > pad_oheight / ( float ) ( iheight - topBand - bottomBand ) , NB_TAPS , NB_PHASES , 1 < < FILTER_BITS , 0 ) ; return s ; fail : av_free ( s ) ; }",1
"static void FUNCC ( pred8x16_vertical_add ) ( uint8_t * pix , const int * block_offset , const int16_t * block , ptrdiff_t stride ) { int i ; for ( i=0 ; i < 4 ; i + + ) FUNCC ( pred4x4_vertical_add ) ( pix + block_offset[i] , block + i * 16 * sizeof ( pixel ) , stride ) ; for ( i=4 ; i < 8 ; i + + ) FUNCC ( pred4x4_vertical_add ) ( pix + block_offset[i + 4] , block + i * 16 * sizeof ( pixel ) , stride ) ; }",0
"static int cmv_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; CmvContext * s = avctx - > priv_data ; const uint8_t * buf_end = buf + buf_size ; if ( AV_RL32 ( buf ) ==MVIh_TAG||AV_RB32 ( buf ) ==MVIh_TAG ) { cmv_process_header ( s , buf + EA_PREAMBLE_SIZE , buf_end ) ; return buf_size ; } if ( av_image_check_size ( s - > width , s - > height , 0 , s - > avctx ) ) return - 1 ; / * shuffle * / if ( s - > last2_frame . data[0] ) avctx - > release_buffer ( avctx , & s - > last2_frame ) ; FFSWAP ( AVFrame , s - > last_frame , s - > last2_frame ) ; FFSWAP ( AVFrame , s - > frame , s - > last_frame ) ; s - > frame . reference = 1 ; s - > frame . buffer_hints = FF_BUFFER_HINTS_VALID ; if ( avctx - > get_buffer ( avctx , & s - > frame ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed\n ) ; return - 1 ; } memcpy ( s - > frame . data[1] , s - > palette , AVPALETTE_SIZE ) ; buf + = EA_PREAMBLE_SIZE ; if ( ( buf[0] & 1 ) ) { // subtype cmv_decode_inter ( s , buf + 2 , buf_end ) ; s - > frame . key_frame = 0 ; s - > frame . pict_type = AV_PICTURE_TYPE_P ; } else { s - > frame . key_frame = 1 ; s - > frame . pict_type = AV_PICTURE_TYPE_I ; cmv_decode_intra ( s , buf + 2 , buf_end ) ; } * data_size = sizeof ( AVFrame ) ; * ( AVFrame * ) data = s - > frame ; return buf_size ; }",1
"static void save_display_set ( DVBSubContext * ctx ) { DVBSubRegion * region ; DVBSubRegionDisplay * display ; DVBSubCLUT * clut ; uint32_t * clut_table ; int x_pos , y_pos , width , height ; int x , y , y_off , x_off ; uint32_t * pbuf ; char filename[32] ; static int fileno_index = 0 ; x_pos = - 1 ; y_pos = - 1 ; width = 0 ; height = 0 ; for ( display = ctx - > display_list ; display ! = NULL ; display = display - > next ) { region = get_region ( ctx , display - > region_id ) ; if ( x_pos == - 1 ) { x_pos = display - > x_pos ; y_pos = display - > y_pos ; width = region - > width ; height = region - > height ; } else { if ( display - > x_pos < x_pos ) { width + = ( x_pos - display - > x_pos ) ; x_pos = display - > x_pos ; } if ( display - > y_pos < y_pos ) { height + = ( y_pos - display - > y_pos ) ; y_pos = display - > y_pos ; } if ( display - > x_pos + region - > width > x_pos + width ) { width = display - > x_pos + region - > width - x_pos ; } if ( display - > y_pos + region - > height > y_pos + height ) { height = display - > y_pos + region - > height - y_pos ; } } } if ( x_pos > = 0 ) { pbuf = av_malloc ( width * height * 4 ) ; for ( display = ctx - > display_list ; display ! = NULL ; display = display - > next ) { region = get_region ( ctx , display - > region_id ) ; x_off = display - > x_pos - x_pos ; y_off = display - > y_pos - y_pos ; clut = get_clut ( ctx , region - > clut ) ; if ( clut == 0 ) clut = & default_clut ; switch ( region - > depth ) { case 2 : clut_table = clut - > clut4 ; break ; case 8 : clut_table = clut - > clut256 ; break ; case 4 : default : clut_table = clut - > clut16 ; break ; } for ( y = 0 ; y < region - > height ; y + + ) { for ( x = 0 ; x < region - > width ; x + + ) { pbuf[ ( ( y + y_off ) * width ) + x_off + x] = clut_table[region - > pbuf[y * region - > width + x]] ; } } } snprintf ( filename , 32 , dvbs . %d , fileno_index ) ; png_save2 ( filename , pbuf , width , height ) ; av_free ( pbuf ) ; } fileno_index + + ; }",0
"static int fic_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { FICContext * ctx = avctx - > priv_data ; uint8_t * src = avpkt - > data ; int ret ; int slice , nslices ; int msize ; int tsize ; uint8_t * sdata ; if ( ( ret = ff_reget_buffer ( avctx , ctx - > frame ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , reget_buffer ( ) failed\n ) ; return ret ; } / * Header + at least one slice ( 4 ) * / if ( avpkt - > size < FIC_HEADER_SIZE + 4 ) { av_log ( avctx , AV_LOG_ERROR , Frame data is too small . \n ) ; return AVERROR_INVALIDDATA ; } / * Check for header . * / if ( memcmp ( src , fic_header , 7 ) ) av_log ( avctx , AV_LOG_WARNING , Invalid FIC Header . \n ) ; / * Is it a skip frame ? * / if ( src[17] ) goto skip ; nslices = src[13] ; if ( ! nslices ) { av_log ( avctx , AV_LOG_ERROR , Zero slices found . \n ) ; return AVERROR_INVALIDDATA ; } / * High or Low Quality Matrix ? * / ctx - > qmat = src[23] ? fic_qmat_hq : fic_qmat_lq ; / * Skip cursor data . * / tsize = AV_RB24 ( src + 24 ) ; if ( tsize > avpkt - > size - FIC_HEADER_SIZE ) { av_log ( avctx , AV_LOG_ERROR , Invalid cursor data size . \n ) ; return AVERROR_INVALIDDATA ; } / * Slice height for all but the last slice . * / ctx - > slice_h = 16 * ( ctx - > aligned_height > > 4 ) / nslices ; if ( ctx - > slice_h % 16 ) ctx - > slice_h = FFALIGN ( ctx - > slice_h - 16 , 16 ) ; / * First slice offset and remaining data . * / sdata = src + tsize + FIC_HEADER_SIZE + 4 * nslices ; msize = avpkt - > size - nslices * 4 - tsize - FIC_HEADER_SIZE ; if ( msize < = 0 ) { av_log ( avctx , AV_LOG_ERROR , Not enough frame data to decode . \n ) ; return AVERROR_INVALIDDATA ; } / * * Set the frametype to I initially . It will be set to P if the frame * has any dependencies ( skip blocks ) . There will be a race condition * inside the slice decode function to set these , but we do not care . * since they will only ever be set to 0/P . * / ctx - > frame - > key_frame = 1 ; ctx - > frame - > pict_type = AV_PICTURE_TYPE_I ; / * Allocate slice data . * / av_fast_malloc ( & ctx - > slice_data , & ctx - > slice_data_size , nslices * sizeof ( ctx - > slice_data[0] ) ) ; if ( ! ctx - > slice_data_size ) { av_log ( avctx , AV_LOG_ERROR , Could not allocate slice data . \n ) ; return AVERROR ( ENOMEM ) ; } memset ( ctx - > slice_data , 0 , nslices * sizeof ( ctx - > slice_data[0] ) ) ; for ( slice = 0 ; slice < nslices ; slice + + ) { unsigned slice_off = AV_RB32 ( src + tsize + FIC_HEADER_SIZE + slice * 4 ) ; unsigned slice_size ; int y_off = ctx - > slice_h * slice ; int slice_h = ctx - > slice_h ; / * * Either read the slice size , or consume all data left . * Also , special case the last slight height . * / if ( slice == nslices - 1 ) { slice_size = msize ; slice_h = FFALIGN ( avctx - > height - ctx - > slice_h * ( nslices - 1 ) , 16 ) ; } else { slice_size = AV_RB32 ( src + tsize + FIC_HEADER_SIZE + slice * 4 + 4 ) ; } if ( slice_size < slice_off || slice_size > msize ) continue ; slice_size - = slice_off ; ctx - > slice_data[slice] . src = sdata + slice_off ; ctx - > slice_data[slice] . src_size = slice_size ; ctx - > slice_data[slice] . slice_h = slice_h ; ctx - > slice_data[slice] . y_off = y_off ; } if ( ret = avctx - > execute ( avctx , fic_decode_slice , ctx - > slice_data , NULL , nslices , sizeof ( ctx - > slice_data[0] ) ) < 0 ) return ret ; skip : * got_frame = 1 ; if ( ( ret = av_frame_ref ( data , ctx - > frame ) ) < 0 ) return ret ; return avpkt - > size ; }",0
"static int nppscale_query_formats ( AVFilterContext * ctx ) { static const enum AVPixelFormat pixel_formats[] = { AV_PIX_FMT_CUDA , AV_PIX_FMT_NONE , } ; AVFilterFormats * pix_fmts = ff_make_format_list ( pixel_formats ) ; ff_set_common_formats ( ctx , pix_fmts ) ; return 0 ; }",0
"static int decode_update_thread_context ( AVCodecContext * dst , const AVCodecContext * src ) { H264Context * h= dst - > priv_data , * h1= src - > priv_data ; MpegEncContext * const s = & h - > s , * const s1 = & h1 - > s ; int inited = s - > context_initialized , err ; int i ; if ( dst == src || ! s1 - > context_initialized ) return 0 ; err = ff_mpeg_update_thread_context ( dst , src ) ; if ( err ) return err ; //FIXME handle width/height changing if ( ! inited ) { for ( i = 0 ; i < MAX_SPS_COUNT ; i + + ) av_freep ( h - > sps_buffers + i ) ; for ( i = 0 ; i < MAX_PPS_COUNT ; i + + ) av_freep ( h - > pps_buffers + i ) ; memcpy ( & h - > s + 1 , & h1 - > s + 1 , sizeof ( H264Context ) - sizeof ( MpegEncContext ) ) ; //copy all fields after MpegEnc memset ( h - > sps_buffers , 0 , sizeof ( h - > sps_buffers ) ) ; memset ( h - > pps_buffers , 0 , sizeof ( h - > pps_buffers ) ) ; if ( ff_h264_alloc_tables ( h ) < 0 ) { av_log ( dst , AV_LOG_ERROR , Could not allocate memory for h264\n ) ; return AVERROR ( ENOMEM ) ; } context_init ( h ) ; for ( i=0 ; i < 2 ; i + + ) { h - > rbsp_buffer[i] = NULL ; h - > rbsp_buffer_size[i] = 0 ; } h - > thread_context[0] = h ; // frame_start may not be called for the next thread ( if it ' s decoding a bottom field ) // so this has to be allocated here h - > s . obmc_scratchpad = av_malloc ( 16 * 6 * s - > linesize ) ; s - > dsp . clear_blocks ( h - > mb ) ; s - > dsp . clear_blocks ( h - > mb + ( 24 * 16 < < h - > pixel_shift ) ) ; } //extradata/NAL handling h - > is_avc = h1 - > is_avc ; //SPS/PPS copy_parameter_set ( ( void * * ) h - > sps_buffers , ( void * * ) h1 - > sps_buffers , MAX_SPS_COUNT , sizeof ( SPS ) ) ; h - > sps = h1 - > sps ; copy_parameter_set ( ( void * * ) h - > pps_buffers , ( void * * ) h1 - > pps_buffers , MAX_PPS_COUNT , sizeof ( PPS ) ) ; h - > pps = h1 - > pps ; //Dequantization matrices //FIXME these are big - can they be only copied when PPS changes ? copy_fields ( h , h1 , dequant4_buffer , dequant4_coeff ) ; for ( i=0 ; i < 6 ; i + + ) h - > dequant4_coeff[i] = h - > dequant4_buffer[0] + ( h1 - > dequant4_coeff[i] - h1 - > dequant4_buffer[0] ) ; for ( i=0 ; i < 6 ; i + + ) h - > dequant8_coeff[i] = h - > dequant8_buffer[0] + ( h1 - > dequant8_coeff[i] - h1 - > dequant8_buffer[0] ) ; h - > dequant_coeff_pps = h1 - > dequant_coeff_pps ; //POC timing copy_fields ( h , h1 , poc_lsb , redundant_pic_count ) ; //reference lists copy_fields ( h , h1 , ref_count , list_count ) ; copy_fields ( h , h1 , ref_list , intra_gb ) ; copy_fields ( h , h1 , short_ref , cabac_init_idc ) ; copy_picture_range ( h - > short_ref , h1 - > short_ref , 32 , s , s1 ) ; copy_picture_range ( h - > long_ref , h1 - > long_ref , 32 , s , s1 ) ; copy_picture_range ( h - > delayed_pic , h1 - > delayed_pic , MAX_DELAYED_PIC_COUNT + 2 , s , s1 ) ; h - > last_slice_type = h1 - > last_slice_type ; h - > sync = h1 - > sync ; if ( ! s - > current_picture_ptr ) return 0 ; if ( ! s - > dropable ) { err = ff_h264_execute_ref_pic_marking ( h , h - > mmco , h - > mmco_index ) ; h - > prev_poc_msb = h - > poc_msb ; h - > prev_poc_lsb = h - > poc_lsb ; } h - > prev_frame_num_offset= h - > frame_num_offset ; h - > prev_frame_num = h - > frame_num ; h - > outputed_poc = h - > next_outputed_poc ; return err ; }",0
static void delete_next_frame ( AudioFrameQueue * afq ) { AudioFrame * f = afq - > frame_queue ; if ( f ) { afq - > frame_queue = f - > next ; f - > next = NULL ; av_freep ( & f ) ; } },0
"static int srt_probe ( AVProbeData * p ) { const unsigned char * ptr = p - > buf ; int i , v , num = 0 ; if ( AV_RB24 ( ptr ) == 0xEFBBBF ) ptr + = 3 ; / * skip UTF - 8 BOM * / while ( * ptr == ' \r ' || * ptr == ' \n ' ) ptr + + ; for ( i=0 ; i < 2 ; i + + ) { if ( ( num == i || num + 1 == i ) & & sscanf ( ptr , % * d : % * 2d : % * 2d% * 1[ , . ]% * 3d - - > % * d : % * 2d : % * 2d% * 1[ , . ]%3d , & v ) == 1 ) return AVPROBE_SCORE_MAX ; num = atoi ( ptr ) ; ptr + = strcspn ( ptr , \n ) + 1 ; } return 0 ; }",1
static int dvvideo_close ( AVCodecContext * c ) { DVVideoContext * s = c - > priv_data ; av_free ( s - > dv_anchor ) ; return 0 ; },1
"static int filter_frame ( AVFilterLink * inlink , AVFilterBufferRef * insamples ) { AVFilterContext * ctx = inlink - > dst ; AVFilterLink * outlink = ctx - > outputs[0] ; ShowWavesContext * showwaves = ctx - > priv ; const int nb_samples = insamples - > audio - > nb_samples ; AVFilterBufferRef * outpicref = showwaves - > outpicref ; int linesize = outpicref ? outpicref - > linesize[0] : 0 ; int16_t * p = ( int16_t * ) insamples - > data[0] ; int nb_channels = av_get_channel_layout_nb_channels ( insamples - > audio - > channel_layout ) ; int i , j , h ; const int n = showwaves - > n ; const int x = 255 / ( nb_channels * n ) ; / * multiplication factor , pre - computed to avoid in - loop divisions * / / * draw data in the buffer * / for ( i = 0 ; i < nb_samples ; i + + ) { if ( ! outpicref ) { showwaves - > outpicref = outpicref = ff_get_video_buffer ( outlink , AV_PERM_WRITE|AV_PERM_ALIGN , outlink - > w , outlink - > h ) ; if ( ! outpicref ) return AVERROR ( ENOMEM ) ; outpicref - > video - > w = outlink - > w ; outpicref - > video - > h = outlink - > h ; outpicref - > pts = insamples - > pts + av_rescale_q ( ( p - ( int16_t * ) insamples - > data[0] ) / nb_channels , ( AVRational ) { 1 , inlink - > sample_rate } , outlink - > time_base ) ; linesize = outpicref - > linesize[0] ; memset ( outpicref - > data[0] , 0 , showwaves - > h * linesize ) ; } for ( j = 0 ; j < nb_channels ; j + + ) { h = showwaves - > h/2 - av_rescale ( * p + + , showwaves - > h/2 , MAX_INT16 ) ; if ( h > = 0 & & h < outlink - > h ) * ( outpicref - > data[0] + showwaves - > buf_idx + h * linesize ) + = x ; } showwaves - > sample_count_mod + + ; if ( showwaves - > sample_count_mod == n ) { showwaves - > sample_count_mod = 0 ; showwaves - > buf_idx + + ; } if ( showwaves - > buf_idx == showwaves - > w ) push_frame ( outlink ) ; } avfilter_unref_buffer ( insamples ) ; return 0 ; }",1
"rgb16_32ToUV_half_c_template ( uint8_t * dstU , uint8_t * dstV , const uint8_t * src , int width , enum PixelFormat origin , int shr , int shg , int shb , int shp , int maskr , int maskg , int maskb , int rsh , int gsh , int bsh , int S ) { const int ru = RU < < rsh , gu = GU < < gsh , bu = BU < < bsh , rv = RV < < rsh , gv = GV < < gsh , bv = BV < < bsh , rnd = 257 < < S , maskgx = ( maskr | maskb ) ; int i ; maskr |= maskr < < 1 ; maskb |= maskb < < 1 ; maskg |= maskg < < 1 ; for ( i = 0 ; i < width ; i + + ) { int px0 = input_pixel ( 2 * i + 0 ) > > shp ; int px1 = input_pixel ( 2 * i + 1 ) > > shp ; int b , r , g = ( px0 & maskgx ) + ( px1 & maskgx ) ; int rb = px0 + px1 - g ; b = ( rb & maskb ) > > shb ; if ( shp || origin == PIX_FMT_BGR565LE || origin == PIX_FMT_BGR565BE || origin == PIX_FMT_RGB565LE || origin == PIX_FMT_RGB565BE ) { g > > = shg ; } else { g = ( g & maskg ) > > shg ; } r = ( rb & maskr ) > > shr ; dstU[i] = ( ru * r + gu * g + bu * b + rnd ) > > ( S + 1 ) ; dstV[i] = ( rv * r + gv * g + bv * b + rnd ) > > ( S + 1 ) ; } }",1
"int ff_thread_get_buffer ( AVCodecContext * avctx , ThreadFrame * f , int flags ) { f - > owner = avctx ; return ff_get_buffer ( avctx , f - > f , flags ) ; }",1
"int av_reallocp_array ( void * ptr , size_t nmemb , size_t size ) { void * * ptrptr = ptr ; * ptrptr = av_realloc_f ( * ptrptr , nmemb , size ) ; if ( ! * ptrptr & & ! ( nmemb & & size ) ) return AVERROR ( ENOMEM ) ; return 0 ; }",1
"static int aac_decode_frame_int ( AVCodecContext * avctx , void * data , int * got_frame_ptr , GetBitContext * gb , AVPacket * avpkt ) { AACContext * ac = avctx - > priv_data ; ChannelElement * che = NULL , * che_prev = NULL ; enum RawDataBlockType elem_type , che_prev_type = TYPE_END ; int err , elem_id ; int samples = 0 , multiplier , audio_found = 0 , pce_found = 0 ; int is_dmono , sce_count = 0 ; int payload_alignment ; ac - > frame = data ; if ( show_bits ( gb , 12 ) == 0xfff ) { if ( ( err = parse_adts_frame_header ( ac , gb ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , Error decoding AAC frame header . \n ) ; goto fail ; } if ( ac - > oc[1] . m4ac . sampling_index > 12 ) { av_log ( ac - > avctx , AV_LOG_ERROR , invalid sampling rate index %d\n , ac - > oc[1] . m4ac . sampling_index ) ; err = AVERROR_INVALIDDATA ; goto fail ; } } if ( ( err = frame_configure_elements ( avctx ) ) < 0 ) goto fail ; // The FF_PROFILE_AAC_ * defines are all object_type - 1 // This may lead to an undefined profile being signaled ac - > avctx - > profile = ac - > oc[1] . m4ac . object_type - 1 ; payload_alignment = get_bits_count ( gb ) ; ac - > tags_mapped = 0 ; // parse while ( ( elem_type = get_bits ( gb , 3 ) ) ! = TYPE_END ) { elem_id = get_bits ( gb , 4 ) ; if ( avctx - > debug & FF_DEBUG_STARTCODE ) av_log ( avctx , AV_LOG_DEBUG , Elem type : %x id : %x\n , elem_type , elem_id ) ; if ( ! avctx - > channels & & elem_type ! = TYPE_PCE ) { err = AVERROR_INVALIDDATA ; goto fail ; } if ( elem_type < TYPE_DSE ) { if ( ! ( che=get_che ( ac , elem_type , elem_id ) ) ) { av_log ( ac - > avctx , AV_LOG_ERROR , channel element %d . %d is not allocated\n , elem_type , elem_id ) ; err = AVERROR_INVALIDDATA ; goto fail ; } samples = 1024 ; che - > present = 1 ; } switch ( elem_type ) { case TYPE_SCE : err = decode_ics ( ac , & che - > ch[0] , gb , 0 , 0 ) ; audio_found = 1 ; sce_count + + ; break ; case TYPE_CPE : err = decode_cpe ( ac , gb , che ) ; audio_found = 1 ; break ; case TYPE_CCE : err = decode_cce ( ac , gb , che ) ; break ; case TYPE_LFE : err = decode_ics ( ac , & che - > ch[0] , gb , 0 , 0 ) ; audio_found = 1 ; break ; case TYPE_DSE : err = skip_data_stream_element ( ac , gb ) ; break ; case TYPE_PCE : { uint8_t layout_map[MAX_ELEM_ID * 4][3] ; int tags ; push_output_configuration ( ac ) ; tags = decode_pce ( avctx , & ac - > oc[1] . m4ac , layout_map , gb , payload_alignment ) ; if ( tags < 0 ) { err = tags ; break ; } if ( pce_found ) { av_log ( avctx , AV_LOG_ERROR , Not evaluating a further program_config_element as this construct is dubious at best . \n ) ; pop_output_configuration ( ac ) ; } else { err = output_configure ( ac , layout_map , tags , OC_TRIAL_PCE , 1 ) ; if ( ! err ) ac - > oc[1] . m4ac . chan_config = 0 ; pce_found = 1 ; } break ; } case TYPE_FIL : if ( elem_id == 15 ) elem_id + = get_bits ( gb , 8 ) - 1 ; if ( get_bits_left ( gb ) < 8 * elem_id ) { av_log ( avctx , AV_LOG_ERROR , TYPE_FIL : overread_err ) ; err = AVERROR_INVALIDDATA ; goto fail ; } while ( elem_id > 0 ) elem_id - = decode_extension_payload ( ac , gb , elem_id , che_prev , che_prev_type ) ; err = 0 ; / * FIXME * / break ; default : err = AVERROR_BUG ; / * should not happen , but keeps compiler happy * / break ; } if ( elem_type < TYPE_DSE ) { che_prev = che ; che_prev_type = elem_type ; } if ( err ) goto fail ; if ( get_bits_left ( gb ) < 3 ) { av_log ( avctx , AV_LOG_ERROR , overread_err ) ; err = AVERROR_INVALIDDATA ; goto fail ; } } if ( ! avctx - > channels ) { * got_frame_ptr = 0 ; return 0 ; } multiplier = ( ac - > oc[1] . m4ac . sbr == 1 ) ? ac - > oc[1] . m4ac . ext_sample_rate > ac - > oc[1] . m4ac . sample_rate : 0 ; samples < < = multiplier ; spectral_to_sample ( ac , samples ) ; if ( ac - > oc[1] . status & & audio_found ) { avctx - > sample_rate = ac - > oc[1] . m4ac . sample_rate < < multiplier ; avctx - > frame_size = samples ; ac - > oc[1] . status = OC_LOCKED ; } if ( multiplier ) avctx - > internal - > skip_samples_multiplier = 2 ; if ( ! ac - > frame - > data[0] & & samples ) { av_log ( avctx , AV_LOG_ERROR , no frame data found\n ) ; err = AVERROR_INVALIDDATA ; goto fail ; } if ( samples ) { ac - > frame - > nb_samples = samples ; ac - > frame - > sample_rate = avctx - > sample_rate ; } else av_frame_unref ( ac - > frame ) ; * got_frame_ptr = ! ! samples ; / * for dual - mono audio ( SCE + SCE ) * / is_dmono = ac - > dmono_mode & & sce_count == 2 & & ac - > oc[1] . channel_layout == ( AV_CH_FRONT_LEFT | AV_CH_FRONT_RIGHT ) ; if ( is_dmono ) { if ( ac - > dmono_mode == 1 ) ( ( AVFrame * ) data ) - > data[1] = ( ( AVFrame * ) data ) - > data[0] ; else if ( ac - > dmono_mode == 2 ) ( ( AVFrame * ) data ) - > data[0] = ( ( AVFrame * ) data ) - > data[1] ; } return 0 ; fail : pop_output_configuration ( ac ) ; return err ; }",1
static av_cold int dnxhd_decode_close ( AVCodecContext * avctx ) { DNXHDContext * ctx = avctx - > priv_data ; ff_free_vlc ( & ctx - > ac_vlc ) ; ff_free_vlc ( & ctx - > dc_vlc ) ; ff_free_vlc ( & ctx - > run_vlc ) ; av_freep ( & ctx - > mb_scan_index ) ; av_freep ( & ctx - > rows ) ; return 0 ; },1
"static void spatial_compose97i_dy_buffered ( dwt_compose_t * cs , slice_buffer * sb , int width , int height , int stride_line ) { int y = cs - > y ; int mirror0 = mirror ( y - 1 , height - 1 ) ; int mirror1 = mirror ( y + 0 , height - 1 ) ; int mirror2 = mirror ( y + 1 , height - 1 ) ; int mirror3 = mirror ( y + 2 , height - 1 ) ; int mirror4 = mirror ( y + 3 , height - 1 ) ; int mirror5 = mirror ( y + 4 , height - 1 ) ; DWTELEM * b0= cs - > b0 ; DWTELEM * b1= cs - > b1 ; DWTELEM * b2= cs - > b2 ; DWTELEM * b3= cs - > b3 ; DWTELEM * b4= slice_buffer_get_line ( sb , mirror4 * stride_line ) ; DWTELEM * b5= slice_buffer_get_line ( sb , mirror5 * stride_line ) ; { START_TIMER if ( y > 0 & & y + 4 < height ) { vertical_compose97i ( b0 , b1 , b2 , b3 , b4 , b5 , width ) ; } else { if ( mirror3 < = mirror5 ) vertical_compose97iL1 ( b3 , b4 , b5 , width ) ; if ( mirror2 < = mirror4 ) vertical_compose97iH1 ( b2 , b3 , b4 , width ) ; if ( mirror1 < = mirror3 ) vertical_compose97iL0 ( b1 , b2 , b3 , width ) ; if ( mirror0 < = mirror2 ) vertical_compose97iH0 ( b0 , b1 , b2 , width ) ; } if ( width > 400 ) { STOP_TIMER ( vertical_compose97i ) } } { START_TIMER if ( y - 1 > = 0 ) horizontal_compose97i ( b0 , width ) ; if ( mirror0 < = mirror2 ) horizontal_compose97i ( b1 , width ) ; if ( width > 400 & & mirror0 < = mirror2 ) { STOP_TIMER ( horizontal_compose97i ) } } cs - > b0=b2 ; cs - > b1=b3 ; cs - > b2=b4 ; cs - > b3=b5 ; cs - > y + = 2 ; }",1
"static void read_table ( AVFormatContext * avctx , AVStream * st , int ( * parse ) ( AVFormatContext * avctx , AVStream * st , const char * name , int size ) ) { int count , i ; AVIOContext * pb = avctx - > pb ; avio_skip ( pb , 4 ) ; count = avio_rb32 ( pb ) ; avio_skip ( pb , 4 ) ; for ( i = 0 ; i < count ; i + + ) { char name[17] ; int size ; avio_read ( pb , name , 16 ) ; name[sizeof ( name ) - 1] = 0 ; size = avio_rb32 ( pb ) ; if ( parse ( avctx , st , name , size ) < 0 ) { avpriv_request_sample ( avctx , Variable %s , name ) ; avio_skip ( pb , size ) ; } } }",1
"static inline void RENAME ( rgb24to15 ) ( const uint8_t * src , uint8_t * dst , long src_size ) { const uint8_t * s = src ; const uint8_t * end ; if COMPILE_TEMPLATE_MMX const uint8_t * mm_end ; endif uint16_t * d = ( uint16_t * ) dst ; end = s + src_size ; if COMPILE_TEMPLATE_MMX __asm__ volatile ( PREFETCH %0 : : m ( * src ) : memory ) ; __asm__ volatile ( movq %0 , %%mm7 \n\t movq %1 , %%mm6 \n\t : : m ( red_15mask ) , m ( green_15mask ) ) ; mm_end = end - 15 ; while ( s < mm_end ) { __asm__ volatile ( PREFETCH 32%1 \n\t movd %1 , %%mm0 \n\t movd 3%1 , %%mm3 \n\t punpckldq 6%1 , %%mm0 \n\t punpckldq 9%1 , %%mm3 \n\t movq %%mm0 , %%mm1 \n\t movq %%mm0 , %%mm2 \n\t movq %%mm3 , %%mm4 \n\t movq %%mm3 , %%mm5 \n\t psllq 7 , %%mm0 \n\t psllq 7 , %%mm3 \n\t pand %%mm7 , %%mm0 \n\t pand %%mm7 , %%mm3 \n\t psrlq 6 , %%mm1 \n\t psrlq 6 , %%mm4 \n\t pand %%mm6 , %%mm1 \n\t pand %%mm6 , %%mm4 \n\t psrlq 19 , %%mm2 \n\t psrlq 19 , %%mm5 \n\t pand %2 , %%mm2 \n\t pand %2 , %%mm5 \n\t por %%mm1 , %%mm0 \n\t por %%mm4 , %%mm3 \n\t por %%mm2 , %%mm0 \n\t por %%mm5 , %%mm3 \n\t psllq 16 , %%mm3 \n\t por %%mm3 , %%mm0 \n\t MOVNTQ %%mm0 , %0 \n\t : =m ( * d ) : m ( * s ) , m ( blue_15mask ) : memory ) ; d + = 4 ; s + = 12 ; } __asm__ volatile ( SFENCE : : : memory ) ; __asm__ volatile ( EMMS : : : memory ) ; endif while ( s < end ) { const int r = * s + + ; const int g = * s + + ; const int b = * s + + ; * d + + = ( b > > 3 ) | ( ( g & 0xF8 ) < < 2 ) | ( ( r & 0xF8 ) < < 7 ) ; } }",0
"static int avi_extract_stream_metadata ( AVFormatContext * s , AVStream * st ) { GetByteContext gb ; uint8_t * data = st - > codecpar - > extradata ; int data_size = st - > codecpar - > extradata_size ; int tag , offset ; if ( ! data || data_size < 8 ) { return AVERROR_INVALIDDATA ; } bytestream2_init ( & gb , data , data_size ) ; tag = bytestream2_get_le32 ( & gb ) ; switch ( tag ) { case MKTAG ( ' A ' , ' V ' , ' I ' , ' F ' ) : // skip 4 byte padding bytestream2_skip ( & gb , 4 ) ; offset = bytestream2_tell ( & gb ) ; bytestream2_init ( & gb , data + offset , data_size - offset ) ; // decode EXIF tags from IFD , AVI is always little - endian return avpriv_exif_decode_ifd ( s , & gb , 1 , 0 , & st - > metadata ) ; break ; case MKTAG ( ' C ' , ' A ' , ' S ' , ' I ' ) : avpriv_request_sample ( s , RIFF stream data tag type CASI ( %u ) , tag ) ; break ; case MKTAG ( ' Z ' , ' o ' , ' r ' , ' a ' ) : avpriv_request_sample ( s , RIFF stream data tag type Zora ( %u ) , tag ) ; break ; default : break ; } return 0 ; }",0
"static void av_always_inline filter_mb_edgecv ( uint8_t * pix , int stride , const int16_t bS[4] , unsigned int qp , H264Context * h , int intra ) { const int qp_bd_offset = 6 * ( h - > sps . bit_depth_luma - 8 ) ; const unsigned int index_a = qp - qp_bd_offset + h - > slice_alpha_c0_offset ; const int alpha = alpha_table[index_a] ; const int beta = beta_table[qp - qp_bd_offset + h - > slice_beta_offset] ; if ( alpha ==0 || beta == 0 ) return ; if ( bS[0] < 4 || ! intra ) { int8_t tc[4] ; tc[0] = tc0_table[index_a][bS[0]] + 1 ; tc[1] = tc0_table[index_a][bS[1]] + 1 ; tc[2] = tc0_table[index_a][bS[2]] + 1 ; tc[3] = tc0_table[index_a][bS[3]] + 1 ; h - > h264dsp . h264_h_loop_filter_chroma ( pix , stride , alpha , beta , tc ) ; } else { h - > h264dsp . h264_h_loop_filter_chroma_intra ( pix , stride , alpha , beta ) ; } }",0
"static int flic_decode_frame_8BPP ( AVCodecContext * avctx , void * data , int * got_frame , const uint8_t * buf , int buf_size ) { FlicDecodeContext * s = avctx - > priv_data ; GetByteContext g2 ; int pixel_ptr ; int palette_ptr ; unsigned char palette_idx1 ; unsigned char palette_idx2 ; unsigned int frame_size ; int num_chunks ; unsigned int chunk_size ; int chunk_type ; int i , j , ret ; int color_packets ; int color_changes ; int color_shift ; unsigned char r , g , b ; int lines ; int compressed_lines ; int starting_line ; signed short line_packets ; int y_ptr ; int byte_run ; int pixel_skip ; int pixel_countdown ; unsigned char * pixels ; unsigned int pixel_limit ; bytestream2_init ( & g2 , buf , buf_size ) ; if ( ( ret = ff_reget_buffer ( avctx , s - > frame ) ) < 0 ) return ret ; pixels = s - > frame - > data[0] ; pixel_limit = s - > avctx - > height * s - > frame - > linesize[0] ; if ( buf_size < 16 || buf_size > INT_MAX - ( 3 * 256 + AV_INPUT_BUFFER_PADDING_SIZE ) ) frame_size = bytestream2_get_le32 ( & g2 ) ; if ( frame_size > buf_size ) frame_size = buf_size ; bytestream2_skip ( & g2 , 2 ) ; / * skip the magic number * / num_chunks = bytestream2_get_le16 ( & g2 ) ; bytestream2_skip ( & g2 , 8 ) ; / * skip padding * / frame_size - = 16 ; / * iterate through the chunks * / while ( ( frame_size > = 6 ) & & ( num_chunks > 0 ) & & bytestream2_get_bytes_left ( & g2 ) > = 4 ) { int stream_ptr_after_chunk ; chunk_size = bytestream2_get_le32 ( & g2 ) ; if ( chunk_size > frame_size ) { av_log ( avctx , AV_LOG_WARNING , Invalid chunk_size = %u > frame_size = %u\n , chunk_size , frame_size ) ; chunk_size = frame_size ; } stream_ptr_after_chunk = bytestream2_tell ( & g2 ) - 4 + chunk_size ; chunk_type = bytestream2_get_le16 ( & g2 ) ; switch ( chunk_type ) { case FLI_256_COLOR : case FLI_COLOR : / * check special case : If this file is from the Magic Carpet * game and uses 6 - bit colors even though it reports 256 - color * chunks in a 0xAF12 - type file ( fli_type is set to 0xAF13 during * initialization ) * / if ( ( chunk_type == FLI_256_COLOR ) & & ( s - > fli_type ! = FLC_MAGIC_CARPET_SYNTHETIC_TYPE_CODE ) ) color_shift = 0 ; else color_shift = 2 ; / * set up the palette * / color_packets = bytestream2_get_le16 ( & g2 ) ; palette_ptr = 0 ; for ( i = 0 ; i < color_packets ; i + + ) { / * first byte is how many colors to skip * / palette_ptr + = bytestream2_get_byte ( & g2 ) ; / * next byte indicates how many entries to change * / color_changes = bytestream2_get_byte ( & g2 ) ; / * if there are 0 color changes , there are actually 256 * / if ( color_changes == 0 ) color_changes = 256 ; if ( bytestream2_tell ( & g2 ) + color_changes * 3 > stream_ptr_after_chunk ) break ; for ( j = 0 ; j < color_changes ; j + + ) { unsigned int entry ; / * wrap around , for good measure * / if ( ( unsigned ) palette_ptr > = 256 ) palette_ptr = 0 ; r = bytestream2_get_byte ( & g2 ) < < color_shift ; g = bytestream2_get_byte ( & g2 ) < < color_shift ; b = bytestream2_get_byte ( & g2 ) < < color_shift ; entry = 0xFFU < < 24 | r < < 16 | g < < 8 | b ; if ( color_shift == 2 ) entry |= entry > > 6 & 0x30303 ; if ( s - > palette[palette_ptr] ! = entry ) s - > new_palette = 1 ; s - > palette[palette_ptr + + ] = entry ; } } break ; case FLI_DELTA : y_ptr = 0 ; compressed_lines = bytestream2_get_le16 ( & g2 ) ; while ( compressed_lines > 0 ) { if ( bytestream2_tell ( & g2 ) + 2 > stream_ptr_after_chunk ) break ; line_packets = bytestream2_get_le16 ( & g2 ) ; if ( ( line_packets & 0xC000 ) == 0xC000 ) { // line skip opcode line_packets = - line_packets ; y_ptr + = line_packets * s - > frame - > linesize[0] ; } else if ( ( line_packets & 0xC000 ) == 0x4000 ) { av_log ( avctx , AV_LOG_ERROR , Undefined opcode ( %x ) in DELTA_FLI\n , line_packets ) ; } else if ( ( line_packets & 0xC000 ) == 0x8000 ) { // last byte opcode pixel_ptr= y_ptr + s - > frame - > linesize[0] - 1 ; CHECK_PIXEL_PTR ( 0 ) ; pixels[pixel_ptr] = line_packets & 0xff ; } else { compressed_lines - - ; pixel_ptr = y_ptr ; CHECK_PIXEL_PTR ( 0 ) ; pixel_countdown = s - > avctx - > width ; for ( i = 0 ; i < line_packets ; i + + ) { if ( bytestream2_tell ( & g2 ) + 2 > stream_ptr_after_chunk ) break ; / * account for the skip bytes * / pixel_skip = bytestream2_get_byte ( & g2 ) ; pixel_ptr + = pixel_skip ; pixel_countdown - = pixel_skip ; byte_run = sign_extend ( bytestream2_get_byte ( & g2 ) , 8 ) ; if ( byte_run < 0 ) { byte_run = - byte_run ; palette_idx1 = bytestream2_get_byte ( & g2 ) ; palette_idx2 = bytestream2_get_byte ( & g2 ) ; CHECK_PIXEL_PTR ( byte_run * 2 ) ; for ( j = 0 ; j < byte_run ; j + + , pixel_countdown - = 2 ) { pixels[pixel_ptr + + ] = palette_idx1 ; pixels[pixel_ptr + + ] = palette_idx2 ; } } else { CHECK_PIXEL_PTR ( byte_run * 2 ) ; if ( bytestream2_tell ( & g2 ) + byte_run * 2 > stream_ptr_after_chunk ) break ; for ( j = 0 ; j < byte_run * 2 ; j + + , pixel_countdown - - ) { pixels[pixel_ptr + + ] = bytestream2_get_byte ( & g2 ) ; } } } y_ptr + = s - > frame - > linesize[0] ; } } break ; case FLI_LC : / * line compressed * / starting_line = bytestream2_get_le16 ( & g2 ) ; y_ptr = 0 ; y_ptr + = starting_line * s - > frame - > linesize[0] ; compressed_lines = bytestream2_get_le16 ( & g2 ) ; while ( compressed_lines > 0 ) { pixel_ptr = y_ptr ; CHECK_PIXEL_PTR ( 0 ) ; pixel_countdown = s - > avctx - > width ; if ( bytestream2_tell ( & g2 ) + 1 > stream_ptr_after_chunk ) break ; line_packets = bytestream2_get_byte ( & g2 ) ; if ( line_packets > 0 ) { for ( i = 0 ; i < line_packets",1
"static int cmp_color ( const void * a , const void * b ) { const struct range_box * box1 = a ; const struct range_box * box2 = b ; return box1 - > color - box2 - > color ; }",1
"static void reconstruct_stereo_16 ( int32_t * buffer[MAX_CHANNELS] , int16_t * buffer_out , int numchannels , int numsamples , uint8_t interlacing_shift , uint8_t interlacing_leftweight ) { int i ; if ( numsamples < = 0 ) return ; / * weighted interlacing * / if ( interlacing_leftweight ) { for ( i = 0 ; i < numsamples ; i + + ) { int32_t a , b ; a = buffer[0][i] ; b = buffer[1][i] ; a - = ( b * interlacing_leftweight ) > > interlacing_shift ; b + = a ; buffer_out[i * numchannels] = b ; buffer_out[i * numchannels + 1] = a ; } return ; } / * otherwise basic interlacing took place * / for ( i = 0 ; i < numsamples ; i + + ) { int16_t left , right ; left = buffer[0][i] ; right = buffer[1][i] ; buffer_out[i * numchannels] = left ; buffer_out[i * numchannels + 1] = right ; } }",0
av_cold void ff_vp9_init_static ( AVCodec * codec ) { if ( vpx_codec_version_major ( ) < 1 || ( vpx_codec_version_major ( ) == 1 & & vpx_codec_version_minor ( ) < 3 ) ) codec - > capabilities |= AV_CODEC_CAP_EXPERIMENTAL ; codec - > pix_fmts = vp9_pix_fmts_def ; if CONFIG_LIBVPX_VP9_ENCODER if ( vpx_codec_version_major ( ) > 1 || ( vpx_codec_version_major ( ) == 1 & & vpx_codec_version_minor ( ) > = 4 ) ) { ifdef VPX_CODEC_CAP_HIGHBITDEPTH vpx_codec_caps_t codec_caps = vpx_codec_get_caps ( vpx_codec_vp9_cx ( ) ) ; if ( codec_caps & VPX_CODEC_CAP_HIGHBITDEPTH ) codec - > pix_fmts = vp9_pix_fmts_highbd ; else endif codec - > pix_fmts = vp9_pix_fmts_highcol ; } endif },0
"static void decode_tones_amplitude ( GetBitContext * gb , Atrac3pChanUnitCtx * ctx , int ch_num , int band_has_tones[] ) { int mode , sb , j , i , diff , maxdiff , fi , delta , pred ; Atrac3pWaveParam * wsrc , * wref ; int refwaves[48] ; Atrac3pWavesData * dst = ctx - > channels[ch_num] . tones_info ; Atrac3pWavesData * ref = ctx - > channels[0] . tones_info ; if ( ch_num ) { for ( sb = 0 ; sb < ctx - > waves_info - > num_tone_bands ; sb + + ) { if ( ! band_has_tones[sb] || ! dst[sb] . num_wavs ) continue ; wsrc = & ctx - > waves_info - > waves[dst[sb] . start_index] ; wref = & ctx - > waves_info - > waves[ref[sb] . start_index] ; for ( j = 0 ; j < dst[sb] . num_wavs ; j + + ) { for ( i = 0 , fi = 0 , maxdiff = 1024 ; i < ref[sb] . num_wavs ; i + + ) { diff = FFABS ( wsrc[j] . freq_index - wref[i] . freq_index ) ; if ( diff < maxdiff ) { maxdiff = diff ; fi = i ; } } if ( maxdiff < 8 ) refwaves[dst[sb] . start_index + j] = fi + ref[sb] . start_index ; else if ( j < ref[sb] . num_wavs ) refwaves[dst[sb] . start_index + j] = j + ref[sb] . start_index ; else refwaves[dst[sb] . start_index + j] = - 1 ; } } } mode = get_bits ( gb , ch_num + 1 ) ; switch ( mode ) { case 0 : / * * fixed - length coding * / for ( sb = 0 ; sb < ctx - > waves_info - > num_tone_bands ; sb + + ) { if ( ! band_has_tones[sb] || ! dst[sb] . num_wavs ) continue ; if ( ctx - > waves_info - > amplitude_mode ) for ( i = 0 ; i < dst[sb] . num_wavs ; i + + ) ctx - > waves_info - > waves[dst[sb] . start_index + i] . amp_sf = get_bits ( gb , 6 ) ; else ctx - > waves_info - > waves[dst[sb] . start_index] . amp_sf = get_bits ( gb , 6 ) ; } break ; case 1 : / * * min + VLC delta * / for ( sb = 0 ; sb < ctx - > waves_info - > num_tone_bands ; sb + + ) { if ( ! band_has_tones[sb] || ! dst[sb] . num_wavs ) continue ; if ( ctx - > waves_info - > amplitude_mode ) for ( i = 0 ; i < dst[sb] . num_wavs ; i + + ) ctx - > waves_info - > waves[dst[sb] . start_index + i] . amp_sf = get_vlc2 ( gb , tone_vlc_tabs[3] . table , tone_vlc_tabs[3] . bits , 1 ) + 20 ; else ctx - > waves_info - > waves[dst[sb] . start_index] . amp_sf = get_vlc2 ( gb , tone_vlc_tabs[4] . table , tone_vlc_tabs[4] . bits , 1 ) + 24 ; } break ; case 2 : / * * VLC modulo delta to master ( slave only ) * / for ( sb = 0 ; sb < ctx - > waves_info - > num_tone_bands ; sb + + ) { if ( ! band_has_tones[sb] || ! dst[sb] . num_wavs ) continue ; for ( i = 0 ; i < dst[sb] . num_wavs ; i + + ) { delta = get_vlc2 ( gb , tone_vlc_tabs[5] . table , tone_vlc_tabs[5] . bits , 1 ) ; delta = sign_extend ( delta , 5 ) ; pred = refwaves[dst[sb] . start_index + i] > = 0 ? ctx - > waves_info - > waves[refwaves[dst[sb] . start_index + i]] . amp_sf : 34 ; ctx - > waves_info - > waves[dst[sb] . start_index + i] . amp_sf = ( pred + delta ) & 0x3F ; } } break ; case 3 : / * * clone master ( slave only ) * / for ( sb = 0 ; sb < ctx - > waves_info - > num_tone_bands ; sb + + ) { if ( ! band_has_tones[sb] ) continue ; for ( i = 0 ; i < dst[sb] . num_wavs ; i + + ) ctx - > waves_info - > waves[dst[sb] . start_index + i] . amp_sf = refwaves[dst[sb] . start_index + i] > = 0 ? ctx - > waves_info - > waves[refwaves[dst[sb] . start_index + i]] . amp_sf : 32 ; } break ; } }",0
"int attribute_align_arg avcodec_decode_video2 ( AVCodecContext * avctx , AVFrame * picture , int * got_picture_ptr , const AVPacket * avpkt ) { AVCodecInternal * avci = avctx - > internal ; int ret ; // copy to ensure we do not change avpkt AVPacket tmp = * avpkt ; if ( ! avctx - > codec ) return AVERROR ( EINVAL ) ; if ( avctx - > codec - > type ! = AVMEDIA_TYPE_VIDEO ) { av_log ( avctx , AV_LOG_ERROR , Invalid media type for video\n ) ; return AVERROR ( EINVAL ) ; } * got_picture_ptr = 0 ; if ( ( avctx - > coded_width || avctx - > coded_height ) & & av_image_check_size ( avctx - > coded_width , avctx - > coded_height , 0 , avctx ) ) return AVERROR ( EINVAL ) ; avcodec_get_frame_defaults ( picture ) ; if ( ( avctx - > codec - > capabilities & CODEC_CAP_DELAY ) || avpkt - > size || ( avctx - > active_thread_type & FF_THREAD_FRAME ) ) { int did_split = av_packet_split_side_data ( & tmp ) ; ret = apply_param_change ( avctx , & tmp ) ; if ( ret < 0 ) { av_log ( avctx , AV_LOG_ERROR , Error applying parameter changes . \n ) ; if ( avctx - > err_recognition & AV_EF_EXPLODE ) goto fail ; } avctx - > internal - > pkt = & tmp ; if ( HAVE_THREADS & & avctx - > active_thread_type & FF_THREAD_FRAME ) ret = ff_thread_decode_frame ( avctx , picture , got_picture_ptr , & tmp ) ; else { ret = avctx - > codec - > decode ( avctx , picture , got_picture_ptr , & tmp ) ; picture - > pkt_dts = avpkt - > dts ; if ( ! avctx - > has_b_frames ) { av_frame_set_pkt_pos ( picture , avpkt - > pos ) ; } //FIXME these should be under if ( ! avctx - > has_b_frames ) / * get_buffer is supposed to set frame parameters * / if ( ! ( avctx - > codec - > capabilities & CODEC_CAP_DR1 ) ) { if ( ! picture - > sample_aspect_ratio . num ) picture - > sample_aspect_ratio = avctx - > sample_aspect_ratio ; if ( ! picture - > width ) picture - > width = avctx - > width ; if ( ! picture - > height ) picture - > height = avctx - > height ; if ( picture - > format == AV_PIX_FMT_NONE ) picture - > format = avctx - > pix_fmt ; } } add_metadata_from_side_data ( avctx , picture ) ; fail : emms_c ( ) ; //needed to avoid an emms_c ( ) call before every return ; avctx - > internal - > pkt = NULL ; if ( did_split ) { av_packet_free_side_data ( & tmp ) ; if ( ret == tmp . size ) ret = avpkt - > size ; } if ( * got_picture_ptr ) { if ( ! avctx - > refcounted_frames ) { int err = unrefcount_frame ( avci , picture ) ; if ( err < 0 ) return err ; } avctx - > frame_number + + ; av_frame_set_best_effort_timestamp ( picture , guess_correct_pts ( avctx , picture - > pkt_pts , picture - > pkt_dts ) ) ; } else av_frame_unref ( picture ) ; } else ret = 0 ; / * many decoders assign whole AVFrames , thus overwriting extended_data ; * make sure it ' s set correctly * / picture - > extended_data = picture - > data ; return ret ; }",0
"static int init ( AVFilterContext * ctx , const char * args , void * opaque ) { GraphContext * gctx = ctx - > priv ; if ( ! args ) return 0 ; if ( ! ( gctx - > link_filter = avfilter_open ( & vf_graph_dummy , NULL ) ) ) return - 1 ; if ( avfilter_init_filter ( gctx - > link_filter , NULL , ctx ) ) goto fail ; return graph_load_chain_from_string ( ctx , args , NULL , NULL ) ; fail : avfilter_destroy ( gctx - > link_filter ) ; return - 1 ; }",0
"matroska_parse_block ( MatroskaDemuxContext * matroska , uint8_t * data , int size , int64_t pos , uint64_t cluster_time , int is_keyframe , int * ptrack , AVPacket * * ppkt ) { int res = 0 ; int track ; AVPacket * pkt ; uint8_t * origdata = data ; int16_t block_time ; uint32_t * lace_size = NULL ; int n , flags , laces = 0 ; uint64_t num ; / * first byte ( s ) : tracknum * / if ( ( n = matroska_ebmlnum_uint ( data , size , & num ) ) < 0 ) { av_log ( matroska - > ctx , AV_LOG_ERROR , EBML block data error\n ) ; av_free ( origdata ) ; return res ; } data + = n ; size - = n ; / * fetch track from num * / track = matroska_find_track_by_num ( matroska , num ) ; if ( ptrack ) * ptrack = track ; if ( size < = 3 || track < 0 || track > = matroska - > num_tracks ) { av_log ( matroska - > ctx , AV_LOG_INFO , Invalid stream %d or size %u\n , track , size ) ; av_free ( origdata ) ; return res ; } if ( matroska - > ctx - > streams[ matroska - > tracks[track] - > stream_index ] - > discard > = AVDISCARD_ALL ) { av_free ( origdata ) ; return res ; } / * block_time ( relative to cluster time ) * / block_time = ( data[0] < < 8 ) | data[1] ; data + = 2 ; size - = 2 ; flags = * data ; data + = 1 ; size - = 1 ; if ( is_keyframe == - 1 ) is_keyframe = flags & 1 ? PKT_FLAG_KEY : 0 ; switch ( ( flags & 0x06 ) > > 1 ) { case 0x0 : / * no lacing * / laces = 1 ; lace_size = av_mallocz ( sizeof ( int ) ) ; lace_size[0] = size ; break ; case 0x1 : / * xiph lacing * / case 0x2 : / * fixed - size lacing * / case 0x3 : / * EBML lacing * / if ( size == 0 ) { res = - 1 ; break ; } laces = ( * data ) + 1 ; data + = 1 ; size - = 1 ; lace_size = av_mallocz ( laces * sizeof ( int ) ) ; switch ( ( flags & 0x06 ) > > 1 ) { case 0x1 : / * xiph lacing * / { uint8_t temp ; uint32_t total = 0 ; for ( n = 0 ; res == 0 & & n < laces - 1 ; n + + ) { while ( 1 ) { if ( size == 0 ) { res = - 1 ; break ; } temp = * data ; lace_size[n] + = temp ; data + = 1 ; size - = 1 ; if ( temp ! = 0xff ) break ; } total + = lace_size[n] ; } lace_size[n] = size - total ; break ; } case 0x2 : / * fixed - size lacing * / for ( n = 0 ; n < laces ; n + + ) lace_size[n] = size / laces ; break ; case 0x3 : / * EBML lacing * / { uint32_t total ; n = matroska_ebmlnum_uint ( data , size , & num ) ; if ( n < 0 ) { av_log ( matroska - > ctx , AV_LOG_INFO , EBML block data error\n ) ; break ; } data + = n ; size - = n ; total = lace_size[0] = num ; for ( n = 1 ; res == 0 & & n < laces - 1 ; n + + ) { int64_t snum ; int r ; r = matroska_ebmlnum_sint ( data , size , & snum ) ; if ( r < 0 ) { av_log ( matroska - > ctx , AV_LOG_INFO , EBML block data error\n ) ; break ; } data + = r ; size - = r ; lace_size[n] = lace_size[n - 1] + snum ; total + = lace_size[n] ; } lace_size[n] = size - total ; break ; } } break ; } if ( res == 0 ) { int real_v = matroska - > tracks[track] - > flags & MATROSKA_TRACK_REAL_V ; for ( n = 0 ; n < laces ; n + + ) { uint64_t timecode = AV_NOPTS_VALUE ; int slice , slices = 1 ; if ( real_v ) { slices = * data + + + 1 ; lace_size[n] - - ; } if ( cluster_time ! = ( uint64_t ) - 1 & & n == 0 ) { if ( cluster_time + block_time > = 0 ) timecode = ( cluster_time + block_time ) * matroska - > time_scale ; } / * FIXME : duration * / for ( slice=0 ; slice < slices ; slice + + ) { int slice_size , slice_offset = 0 ; if ( real_v ) slice_offset = rv_offset ( data , slice , slices ) ; if ( slice + 1 == slices ) slice_size = lace_size[n] - slice_offset ; else slice_size = rv_offset ( data , slice + 1 , slices ) - slice_offset ; pkt = av_mallocz ( sizeof ( AVPacket ) ) ; if ( ppkt ) * ppkt = pkt ; / * XXX : prevent data copy . . . * / if ( av_new_packet ( pkt , slice_size ) < 0 ) { res = AVERROR_NOMEM ; n = laces - 1 ; break ; } memcpy ( pkt - > data , data + slice_offset , slice_size ) ; if ( n == 0 ) pkt - > flags = is_keyframe ; pkt - > stream_index = matroska - > tracks[track] - > stream_index ; pkt - > pts = timecode ; pkt - > pos = pos ; matroska_queue_packet ( matroska , pkt ) ; } data + = lace_size[n] ; } } av_free ( lace_size ) ; av_free ( origdata ) ; return res ; }",0
"static void return_frame ( AVFilterContext * ctx , int is_second ) { YADIFContext * yadif = ctx - > priv ; AVFilterLink * link= ctx - > outputs[0] ; int tff ; if ( yadif - > parity == - 1 ) { tff = yadif - > cur - > video - > interlaced ? yadif - > cur - > video - > top_field_first : 1 ; } else { tff = yadif - > parity 1 ; } if ( is_second ) { yadif - > out = ff_get_video_buffer ( link , AV_PERM_WRITE | AV_PERM_PRESERVE | AV_PERM_REUSE , link - > w , link - > h ) ; avfilter_copy_buffer_ref_props ( yadif - > out , yadif - > cur ) ; yadif - > out - > video - > interlaced = 0 ; } if ( ! yadif - > csp ) yadif - > csp = & av_pix_fmt_descriptors[link - > format] ; if ( yadif - > csp - > comp[0] . depth_minus1 / 8 == 1 ) yadif - > filter_line = filter_line_c_16bit ; filter ( ctx , yadif - > out , tff ! is_second , tff ) ; if ( is_second ) { int64_t cur_pts = yadif - > cur - > pts ; int64_t next_pts = yadif - > next - > pts ; if ( next_pts ! = AV_NOPTS_VALUE & & cur_pts ! = AV_NOPTS_VALUE ) { yadif - > out - > pts = cur_pts + next_pts ; } else { yadif - > out - > pts = AV_NOPTS_VALUE ; } ff_start_frame ( ctx - > outputs[0] , yadif - > out ) ; } ff_draw_slice ( ctx - > outputs[0] , 0 , link - > h , 1 ) ; ff_end_frame ( ctx - > outputs[0] ) ; yadif - > frame_pending = ( yadif - > mode & 1 ) & & ! is_second ; }",0
"static void quantize_and_encode_band ( struct AACEncContext * s , PutBitContext * pb , const float * in , int size , int scale_idx , int cb , const float lambda ) { const float IQ = ff_aac_pow2sf_tab[200 + scale_idx - SCALE_ONE_POS + SCALE_DIV_512] ; const float Q = ff_aac_pow2sf_tab[200 - scale_idx + SCALE_ONE_POS - SCALE_DIV_512] ; const float CLIPPED_ESCAPE = 165140 . 0f * IQ ; const int dim = ( cb < FIRST_PAIR_BT ) ? 4 : 2 ; int i , j , k ; ifndef USE_REALLY_FULL_SEARCH const float Q34 = sqrtf ( Q * sqrtf ( Q ) ) ; const int range = aac_cb_range[cb] ; const int maxval = aac_cb_maxval[cb] ; int offs[4] ; float * scaled = s - > scoefs ; endif / * USE_REALLY_FULL_SEARCH * / //START_TIMER if ( ! cb ) return ; ifndef USE_REALLY_FULL_SEARCH offs[0] = 1 ; for ( i = 1 ; i < dim ; i + + ) offs[i] = offs[i - 1] * range ; abs_pow34_v ( scaled , in , size ) ; quantize_bands ( s - > qcoefs , in , scaled , size , Q34 , ! IS_CODEBOOK_UNSIGNED ( cb ) , maxval ) ; endif / * USE_REALLY_FULL_SEARCH * / for ( i = 0 ; i < size ; i + = dim ) { float mincost ; int minidx = 0 ; int minbits = 0 ; const float * vec ; ifndef USE_REALLY_FULL_SEARCH int ( * quants ) [2] = & s - > qcoefs[i] ; mincost = 0 . 0f ; for ( j = 0 ; j < dim ; j + + ) mincost + = in[i + j] * in[i + j] * lambda ; minidx = IS_CODEBOOK_UNSIGNED ( cb ) ? 0 : 40 ; minbits = ff_aac_spectral_bits[cb - 1][minidx] ; mincost + = minbits ; for ( j = 0 ; j < ( 1 < < dim ) ; j + + ) { float rd = 0 . 0f ; int curbits ; int curidx = IS_CODEBOOK_UNSIGNED ( cb ) ? 0 : 40 ; int same = 0 ; for ( k = 0 ; k < dim ; k + + ) { if ( ( j & ( 1 < < k ) ) & & quants[k][0] == quants[k][1] ) { same = 1 ; break ; } } if ( same ) continue ; for ( k = 0 ; k < dim ; k + + ) curidx + = quants[k][ ! ! ( j & ( 1 < < k ) ) ] * offs[dim - 1 - k] ; curbits = ff_aac_spectral_bits[cb - 1][curidx] ; vec = & ff_aac_codebook_vectors[cb - 1][curidx * dim] ; else vec = ff_aac_codebook_vectors[cb - 1] ; mincost = INFINITY ; for ( j = 0 ; j < ff_aac_spectral_sizes[cb - 1] ; j + + , vec + = dim ) { float rd = 0 . 0f ; int curbits = ff_aac_spectral_bits[cb - 1][j] ; int curidx = j ; endif / * USE_REALLY_FULL_SEARCH * / if ( IS_CODEBOOK_UNSIGNED ( cb ) ) { for ( k = 0 ; k < dim ; k + + ) { float t = fabsf ( in[i + k] ) ; float di ; //do not code with escape sequence small values if ( vec[k] == 64 . 0f & & t < 39 . 0f * IQ ) { rd = INFINITY ; break ; } if ( vec[k] == 64 . 0f ) { //FIXME : slow if ( t > = CLIPPED_ESCAPE ) { di = t - CLIPPED_ESCAPE ; curbits + = 21 ; } else { int c = av_clip ( quant ( t , Q ) , 0 , 8191 ) ; di = t - c * cbrt ( c ) * IQ ; curbits + = av_log2 ( c ) * 2 - 4 + 1 ; } } else { di = t - vec[k] * IQ ; } if ( vec[k] ! = 0 . 0f ) curbits + + ; rd + = di * di * lambda ; } } else { for ( k = 0 ; k < dim ; k + + ) { float di = in[i + k] - vec[k] * IQ ; rd + = di * di * lambda ; } } rd + = curbits ; if ( rd < mincost ) { mincost = rd ; minidx = curidx ; minbits = curbits ; } } put_bits ( pb , ff_aac_spectral_bits[cb - 1][minidx] , ff_aac_spectral_codes[cb - 1][minidx] ) ; if ( IS_CODEBOOK_UNSIGNED ( cb ) ) for ( j = 0 ; j < dim ; j + + ) if ( ff_aac_codebook_vectors[cb - 1][minidx * dim + j] ! = 0 . 0f ) put_bits ( pb , 1 , in[i + j] < 0 . 0f ) ; if ( cb == ESC_BT ) { for ( j = 0 ; j < 2 ; j + + ) { if ( ff_aac_codebook_vectors[cb - 1][minidx * 2 + j] == 64 . 0f ) { int coef = av_clip ( quant ( fabsf ( in[i + j] ) , Q ) , 0 , 8191 ) ; int len = av_log2 ( coef ) ; put_bits ( pb , len - 4 + 1 , ( 1 < < ( len - 4 + 1 ) ) - 2 ) ; put_bits ( pb , len , coef & ( ( 1 < < len ) - 1 ) ) ; } } } } //STOP_TIMER ( quantize_and_encode ) }",0
"static int seg_check_bitstream ( struct AVFormatContext * s , const AVPacket * pkt ) { SegmentContext * seg = s - > priv_data ; AVFormatContext * oc = seg - > avf ; if ( oc - > oformat - > check_bitstream ) { int ret = oc - > oformat - > check_bitstream ( oc , pkt ) ; if ( ret == 1 ) { AVStream * st = s - > streams[pkt - > stream_index] ; AVStream * ost = oc - > streams[pkt - > stream_index] ; st - > internal - > bsfcs = ost - > internal - > bsfcs ; st - > internal - > nb_bsfcs = ost - > internal - > nb_bsfcs ; ost - > internal - > bsfcs = NULL ; ost - > internal - > nb_bsfcs = 0 ; } return ret ; } return 1 ; }",0
"static int gen_check_bw ( URLContext * s , RTMPContext * rt ) { RTMPPacket pkt ; uint8_t * p ; int ret ; if ( ( ret = ff_rtmp_packet_create ( & pkt , RTMP_SYSTEM_CHANNEL , RTMP_PT_INVOKE , 0 , 21 ) ) < 0 ) return ret ; p = pkt . data ; ff_amf_write_string ( & p , _checkbw ) ; ff_amf_write_number ( & p , + + rt - > nb_invokes ) ; ff_amf_write_null ( & p ) ; ret = ff_rtmp_packet_write ( rt - > stream , & pkt , rt - > chunk_size , rt - > prev_pkt[1] ) ; ff_rtmp_packet_destroy ( & pkt ) ; return ret ; }",0
"static int decode_video ( InputStream * ist , AVPacket * pkt , int * got_output ) { AVFrame * decoded_frame , * f ; int i , ret = 0 , err = 0 ; if ( ! ist - > decoded_frame & & ! ( ist - > decoded_frame = av_frame_alloc ( ) ) ) return AVERROR ( ENOMEM ) ; if ( ! ist - > filter_frame & & ! ( ist - > filter_frame = av_frame_alloc ( ) ) ) return AVERROR ( ENOMEM ) ; decoded_frame = ist - > decoded_frame ; ret = decode ( ist - > dec_ctx , decoded_frame , got_output , pkt ) ; if ( ! * got_output || ret < 0 ) return ret ; ist - > frames_decoded + + ; if ( ist - > hwaccel_retrieve_data & & decoded_frame - > format == ist - > hwaccel_pix_fmt ) { err = ist - > hwaccel_retrieve_data ( ist - > dec_ctx , decoded_frame ) ; if ( err < 0 ) goto fail ; } ist - > hwaccel_retrieved_pix_fmt = decoded_frame - > format ; decoded_frame - > pts = guess_correct_pts ( & ist - > pts_ctx , decoded_frame - > pts , decoded_frame - > pkt_dts ) ; if ( ist - > framerate . num ) decoded_frame - > pts = ist - > cfr_next_pts + + ; if ( ist - > st - > sample_aspect_ratio . num ) decoded_frame - > sample_aspect_ratio = ist - > st - > sample_aspect_ratio ; for ( i = 0 ; i < ist - > nb_filters ; i + + ) { if ( i < ist - > nb_filters - 1 ) { f = ist - > filter_frame ; err = av_frame_ref ( f , decoded_frame ) ; if ( err < 0 ) break ; } else f = decoded_frame ; err = ifilter_send_frame ( ist - > filters[i] , f ) ; if ( err < 0 ) break ; } fail : av_frame_unref ( ist - > filter_frame ) ; av_frame_unref ( decoded_frame ) ; return err < 0 ? err : ret ; }",1
"static int avi_read_seek ( AVFormatContext * s , int stream_index , int64_t timestamp , int flags ) { AVIContext * avi = s - > priv_data ; AVStream * st ; int i , index ; int64_t pos , pos_min ; AVIStream * ast ; if ( ! avi - > index_loaded ) { / * we only load the index on demand * / avi_load_index ( s ) ; avi - > index_loaded = 1 ; } assert ( stream_index > = 0 ) ; st = s - > streams[stream_index] ; ast= st - > priv_data ; index= av_index_search_timestamp ( st , timestamp * FFMAX ( ast - > sample_size , 1 ) , flags ) ; if ( index < 0 ) return - 1 ; / * find the position * / pos = st - > index_entries[index] . pos ; timestamp = st - > index_entries[index] . timestamp / FFMAX ( ast - > sample_size , 1 ) ; // av_log ( s , AV_LOG_DEBUG , XX % PRId64 %d % PRId64 \n , timestamp , index , st - > index_entries[index] . timestamp ) ; if ( CONFIG_DV_DEMUXER & & avi - > dv_demux ) { / * One and only one real stream for DV in AVI , and it has video * / / * offsets . Calling with other stream indexes should have failed * / / * the av_index_search_timestamp call above . * / assert ( stream_index == 0 ) ; / * Feed the DV video stream version of the timestamp to the * / / * DV demux so it can synthesize correct timestamps . * / dv_offset_reset ( avi - > dv_demux , timestamp ) ; avio_seek ( s - > pb , pos , SEEK_SET ) ; avi - > stream_index= - 1 ; return 0 ; } pos_min= pos ; for ( i = 0 ; i < s - > nb_streams ; i + + ) { AVStream * st2 = s - > streams[i] ; AVIStream * ast2 = st2 - > priv_data ; ast2 - > packet_size= ast2 - > remaining= 0 ; if ( ast2 - > sub_ctx ) { seek_subtitle ( st , st2 , timestamp ) ; continue ; } if ( st2 - > nb_index_entries < = 0 ) continue ; // assert ( st2 - > codec - > block_align ) ; assert ( ( int64_t ) st2 - > time_base . num * ast2 - > rate == ( int64_t ) st2 - > time_base . den * ast2 - > scale ) ; index = av_index_search_timestamp ( st2 , av_rescale_q ( timestamp , st - > time_base , st2 - > time_base ) * FFMAX ( ast2 - > sample_size , 1 ) , flags | AVSEEK_FLAG_BACKWARD | ( st2 - > codec - > codec_type ! = AVMEDIA_TYPE_VIDEO ? AVSEEK_FLAG_ANY : 0 ) ) ; if ( index < 0 ) index=0 ; ast2 - > seek_pos= st2 - > index_entries[index] . pos ; pos_min= FFMIN ( pos_min , ast2 - > seek_pos ) ; } for ( i = 0 ; i < s - > nb_streams ; i + + ) { AVStream * st2 = s - > streams[i] ; AVIStream * ast2 = st2 - > priv_data ; if ( ast2 - > sub_ctx || st2 - > nb_index_entries < = 0 ) continue ; index = av_index_search_timestamp ( st2 , av_rescale_q ( timestamp , st - > time_base , st2 - > time_base ) * FFMAX ( ast2 - > sample_size , 1 ) , flags | AVSEEK_FLAG_BACKWARD | ( st2 - > codec - > codec_type ! = AVMEDIA_TYPE_VIDEO ? AVSEEK_FLAG_ANY : 0 ) ) ; if ( index < 0 ) index=0 ; while ( ! avi - > non_interleaved & & index > 0 & & st2 - > index_entries[index - 1] . pos > = pos_min ) index - - ; ast2 - > frame_offset = st2 - > index_entries[index] . timestamp ; } / * do the seek * / avio_seek ( s - > pb , pos_min , SEEK_SET ) ; avi - > stream_index= - 1 ; avi - > dts_max= INT_MIN ; return 0 ; }",1
"static int dfa_read_packet ( AVFormatContext * s , AVPacket * pkt ) { AVIOContext * pb = s - > pb ; uint32_t frame_size ; int ret , first = 1 ; if ( avio_feof ( pb ) ) return AVERROR_EOF ; if ( av_get_packet ( pb , pkt , 12 ) ! = 12 ) return AVERROR ( EIO ) ; while ( ! avio_feof ( pb ) ) { if ( ! first ) { ret = av_append_packet ( pb , pkt , 12 ) ; if ( ret < 0 ) { return ret ; } } else first = 0 ; frame_size = AV_RL32 ( pkt - > data + pkt - > size - 8 ) ; if ( frame_size > INT_MAX - 4 ) { av_log ( s , AV_LOG_ERROR , Too large chunk size : % PRIu32 \n , frame_size ) ; return AVERROR ( EIO ) ; } if ( AV_RL32 ( pkt - > data + pkt - > size - 12 ) == MKTAG ( ' E ' , ' O ' , ' F ' , ' R ' ) ) { if ( frame_size ) { av_log ( s , AV_LOG_WARNING , skipping % PRIu32 bytes of end - of - frame marker chunk\n , frame_size ) ; avio_skip ( pb , frame_size ) ; } return 0 ; } ret = av_append_packet ( pb , pkt , frame_size ) ; if ( ret < 0 ) { return ret ; } } return 0 ; }",1
static int nut_read_close ( AVFormatContext * s ) { NUTContext * nut = s - > priv_data ; av_freep ( & nut - > time_base ) ; av_freep ( & nut - > stream ) ; return 0 ; },1
"static int64_t pva_read_timestamp ( struct AVFormatContext * s , int stream_index , int64_t * pos , int64_t pos_limit ) { ByteIOContext * pb = s - > pb ; PVAContext * pvactx = s - > priv_data ; int length , streamid ; int64_t res ; pos_limit = FFMIN ( * pos + PVA_MAX_PAYLOAD_LENGTH * 8 , ( uint64_t ) * pos + pos_limit ) ; while ( * pos < pos_limit ) { res = AV_NOPTS_VALUE ; url_fseek ( pb , * pos , SEEK_SET ) ; pvactx - > continue_pes = 0 ; if ( read_part_of_packet ( s , & res , & length , & streamid , 0 ) ) { ( * pos ) + + ; continue ; } if ( streamid - 1 ! = stream_index || res == AV_NOPTS_VALUE ) { * pos = url_ftell ( pb ) + length ; continue ; } break ; } pvactx - > continue_pes = 0 ; return res ; }",1
"static int filter_slice ( AVFilterContext * ctx , void * arg , int job , int nb_jobs ) { FrameRateContext * s = ctx - > priv ; ThreadData * td = arg ; uint16_t src1_factor = td - > src1_factor ; uint16_t src2_factor = td - > src2_factor ; int plane ; for ( plane = 0 ; plane < 4 & & td - > copy_src1 - > data[plane] & & td - > copy_src2 - > data[plane] ; plane + + ) { int cpy_line_width = s - > line_size[plane] ; uint8_t * cpy_src1_data = td - > copy_src1 - > data[plane] ; int cpy_src1_line_size = td - > copy_src1 - > linesize[plane] ; uint8_t * cpy_src2_data = td - > copy_src2 - > data[plane] ; int cpy_src2_line_size = td - > copy_src2 - > linesize[plane] ; int cpy_src_h = ( plane > 0 & & plane < 3 ) ? ( td - > copy_src1 - > height > > s - > vsub ) : ( td - > copy_src1 - > height ) ; uint8_t * cpy_dst_data = s - > work - > data[plane] ; int cpy_dst_line_size = s - > work - > linesize[plane] ; const int start = ( cpy_src_h * job ) / nb_jobs ; const int end = ( cpy_src_h * ( job + 1 ) ) / nb_jobs ; cpy_src1_data + = start * cpy_src1_line_size ; cpy_src2_data + = start * cpy_src2_line_size ; cpy_dst_data + = start * cpy_dst_line_size ; s - > blend ( cpy_src1_data , cpy_src1_line_size , cpy_src2_data , cpy_src2_line_size , cpy_dst_data , cpy_dst_line_size , cpy_line_width , end - start , src1_factor , src2_factor , s - > max / 2 , s - > bitdepth ) ; } return 0 ; }",1
"void ff_msmpeg4_encode_init ( MpegEncContext * s ) { static int init_done=0 ; int i ; common_init ( s ) ; if ( s - > msmpeg4_version > =4 ) { s - > min_qcoeff= - 255 ; s - > max_qcoeff= 255 ; } if ( ! init_done ) { / * init various encoding tables * / init_done = 1 ; init_mv_table ( & mv_tables[0] ) ; init_mv_table ( & mv_tables[1] ) ; for ( i=0 ; i < NB_RL_TABLES ; i + + ) init_rl ( & rl_table[i] ) ; for ( i=0 ; i < NB_RL_TABLES ; i + + ) { int level ; for ( level=0 ; level < =MAX_LEVEL ; level + + ) { int run ; for ( run=0 ; run < =MAX_RUN ; run + + ) { int last ; for ( last=0 ; last < 2 ; last + + ) { rl_length[i][level][run][last]= get_size_of_code ( s , & rl_table[ i] , last , run , level , 0 ) ; } } } } } }",1
"static void update_initial_timestamps ( AVFormatContext * s , int stream_index , int64_t dts , int64_t pts , AVPacket * pkt ) { AVStream * st = s - > streams[stream_index] ; AVPacketList * pktl = s - > internal - > packet_buffer ? s - > internal - > packet_buffer : s - > internal - > parse_queue ; int64_t pts_buffer[MAX_REORDER_DELAY + 1] ; int64_t shift ; int i , delay ; if ( st - > first_dts ! = AV_NOPTS_VALUE || dts == AV_NOPTS_VALUE || st - > cur_dts == AV_NOPTS_VALUE || is_relative ( dts ) ) return ; delay = st - > codec - > has_b_frames ; st - > first_dts = dts - ( st - > cur_dts - RELATIVE_TS_BASE ) ; st - > cur_dts = dts ; shift = st - > first_dts - RELATIVE_TS_BASE ; for ( i = 0 ; i < MAX_REORDER_DELAY + 1 ; i + + ) pts_buffer[i] = AV_NOPTS_VALUE ; if ( is_relative ( pts ) ) pts + = shift ; for ( ; pktl ; pktl = get_next_pkt ( s , st , pktl ) ) { if ( pktl - > pkt . stream_index ! = stream_index ) continue ; if ( is_relative ( pktl - > pkt . pts ) ) pktl - > pkt . pts + = shift ; if ( is_relative ( pktl - > pkt . dts ) ) pktl - > pkt . dts + = shift ; if ( st - > start_time == AV_NOPTS_VALUE & & pktl - > pkt . pts ! = AV_NOPTS_VALUE ) st - > start_time = pktl - > pkt . pts ; if ( pktl - > pkt . pts ! = AV_NOPTS_VALUE & & delay < = MAX_REORDER_DELAY & & has_decode_delay_been_guessed ( st ) ) { pts_buffer[0] = pktl - > pkt . pts ; for ( i = 0 ; i < delay & & pts_buffer[i] > pts_buffer[i + 1] ; i + + ) FFSWAP ( int64_t , pts_buffer[i] , pts_buffer[i + 1] ) ; pktl - > pkt . dts = select_from_pts_buffer ( st , pts_buffer , pktl - > pkt . dts ) ; } } if ( st - > start_time == AV_NOPTS_VALUE ) st - > start_time = pts ; }",1
"static int update_prob ( VP56RangeCoder * c , int p ) { static const int inv_map_table[254] = { 7 , 20 , 33 , 46 , 59 , 72 , 85 , 98 , 111 , 124 , 137 , 150 , 163 , 176 , 189 , 202 , 215 , 228 , 241 , 254 , 1 , 2 , 3 , 4 , 5 , 6 , 8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 21 , 22 , 23 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44 , 45 , 47 , 48 , 49 , 50 , 51 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 60 , 61 , 62 , 63 , 64 , 65 , 66 , 67 , 68 , 69 , 70 , 71 , 73 , 74 , 75 , 76 , 77 , 78 , 79 , 80 , 81 , 82 , 83 , 84 , 86 , 87 , 88 , 89 , 90 , 91 , 92 , 93 , 94 , 95 , 96 , 97 , 99 , 100 , 101 , 102 , 103 , 104 , 105 , 106 , 107 , 108 , 109 , 110 , 112 , 113 , 114 , 115 , 116 , 117 , 118 , 119 , 120 , 121 , 122 , 123 , 125 , 126 , 127 , 128 , 129 , 130 , 131 , 132 , 133 , 134 , 135 , 136 , 138 , 139 , 140 , 141 , 142 , 143 , 144 , 145 , 146 , 147 , 148 , 149 , 151 , 152 , 153 , 154 , 155 , 156 , 157 , 158 , 159 , 160 , 161 , 162 , 164 , 165 , 166 , 167 , 168 , 169 , 170 , 171 , 172 , 173 , 174 , 175 , 177 , 178 , 179 , 180 , 181 , 182 , 183 , 184 , 185 , 186 , 187 , 188 , 190 , 191 , 192 , 193 , 194 , 195 , 196 , 197 , 198 , 199 , 200 , 201 , 203 , 204 , 205 , 206 , 207 , 208 , 209 , 210 , 211 , 212 , 213 , 214 , 216 , 217 , 218 , 219 , 220 , 221 , 222 , 223 , 224 , 225 , 226 , 227 , 229 , 230 , 231 , 232 , 233 , 234 , 235 , 236 , 237 , 238 , 239 , 240 , 242 , 243 , 244 , 245 , 246 , 247 , 248 , 249 , 250 , 251 , 252 , 253 , } ; int d ; / * This code is trying to do a differential probability update . For a * current probability A in the range [1 , 255] , the difference to a new * probability of any value can be expressed differentially as 1 - A , 255 - A * where some part of this ( absolute range ) exists both in positive as * well as the negative part , whereas another part only exists in one * half . We ' re trying to code this shared part differentially , i . e . * times two where the value of the lowest bit specifies the sign , and * the single part is then coded on top of this . This absolute difference * then again has a value of [0 , 254] , but a bigger value in this range * indicates that we ' re further away from the original value A , so we * can code this as a VLC code , since higher values are increasingly * unlikely . The first 20 values in inv_map_table[] allow ' cheap , rough ' * updates vs . the ' fine , exact ' updates further down the range , which * adds one extra dimension to this differential update model . * / if ( ! vp8_rac_get ( c ) ) { d = vp8_rac_get_uint ( c , 4 ) + 0 ; } else if ( ! vp8_rac_get ( c ) ) { d = vp8_rac_get_uint ( c , 4 ) + 16 ; } else if ( ! vp8_rac_get ( c ) ) { d = vp8_rac_get_uint ( c , 5 ) + 32 ; } else { d = vp8_rac_get_uint ( c , 7 ) ; if ( d > = 65 ) d = ( d < < 1 ) - 65 + vp8_rac_get ( c ) ; d + = 64 ; } return p < = 128 ? 1 + inv_recenter_nonneg ( inv_map_table[d] , p - 1 ) : 255 - inv_recenter_nonneg ( inv_map_table[d] , 255 - p ) ; }",1
"static int kmvc_decode_inter_8x8 ( KmvcContext * ctx , const uint8_t * src , int src_size , int w , int h ) { BitBuf bb ; int res , val ; int i , j ; int bx , by ; int l0x , l1x , l0y , l1y ; int mx , my ; const uint8_t * src_end = src + src_size ; kmvc_init_getbits ( bb , src ) ; for ( by = 0 ; by < h ; by + = 8 ) for ( bx = 0 ; bx < w ; bx + = 8 ) { kmvc_getbit ( bb , src , src_end , res ) ; if ( ! res ) { kmvc_getbit ( bb , src , src_end , res ) ; if ( ! res ) { // fill whole 8x8 block if ( src > = src_end ) { av_log ( ctx - > avctx , AV_LOG_ERROR , Data overrun\n ) ; return AVERROR_INVALIDDATA ; } val = * src + + ; for ( i = 0 ; i < 64 ; i + + ) BLK ( ctx - > cur , bx + ( i & 0x7 ) , by + ( i > > 3 ) ) = val ; } else { // copy block from previous frame for ( i = 0 ; i < 64 ; i + + ) BLK ( ctx - > cur , bx + ( i & 0x7 ) , by + ( i > > 3 ) ) = BLK ( ctx - > prev , bx + ( i & 0x7 ) , by + ( i > > 3 ) ) ; } } else { // handle four 4x4 subblocks for ( i = 0 ; i < 4 ; i + + ) { l0x = bx + ( i & 1 ) * 4 ; l0y = by + ( i & 2 ) * 2 ; kmvc_getbit ( bb , src , src_end , res ) ; if ( ! res ) { kmvc_getbit ( bb , src , src_end , res ) ; if ( ! res ) { // fill whole 4x4 block if ( src > = src_end ) { av_log ( ctx - > avctx , AV_LOG_ERROR , Data overrun\n ) ; return AVERROR_INVALIDDATA ; } val = * src + + ; for ( j = 0 ; j < 16 ; j + + ) BLK ( ctx - > cur , l0x + ( j & 3 ) , l0y + ( j > > 2 ) ) = val ; } else { // copy block if ( src > = src_end ) { av_log ( ctx - > avctx , AV_LOG_ERROR , Data overrun\n ) ; return AVERROR_INVALIDDATA ; } val = * src + + ; mx = ( val & 0xF ) - 8 ; my = ( val > > 4 ) - 8 ; for ( j = 0 ; j < 16 ; j + + ) BLK ( ctx - > cur , l0x + ( j & 3 ) , l0y + ( j > > 2 ) ) = BLK ( ctx - > prev , l0x + ( j & 3 ) + mx , l0y + ( j > > 2 ) + my ) ; } } else { // descend to 2x2 sub - sub - blocks for ( j = 0 ; j < 4 ; j + + ) { l1x = l0x + ( j & 1 ) * 2 ; l1y = l0y + ( j & 2 ) ; kmvc_getbit ( bb , src , src_end , res ) ; if ( ! res ) { kmvc_getbit ( bb , src , src_end , res ) ; if ( ! res ) { // fill whole 2x2 block if ( src > = src_end ) { av_log ( ctx - > avctx , AV_LOG_ERROR , Data overrun\n ) ; return AVERROR_INVALIDDATA ; } val = * src + + ; BLK ( ctx - > cur , l1x , l1y ) = val ; BLK ( ctx - > cur , l1x + 1 , l1y ) = val ; BLK ( ctx - > cur , l1x , l1y + 1 ) = val ; BLK ( ctx - > cur , l1x + 1 , l1y + 1 ) = val ; } else { // copy block if ( src > = src_end ) { av_log ( ctx - > avctx , AV_LOG_ERROR , Data overrun\n ) ; return AVERROR_INVALIDDATA ; } val = * src + + ; mx = ( val & 0xF ) - 8 ; my = ( val > > 4 ) - 8 ; BLK ( ctx - > cur , l1x , l1y ) = BLK ( ctx - > prev , l1x + mx , l1y + my ) ; BLK ( ctx - > cur , l1x + 1 , l1y ) = BLK ( ctx - > prev , l1x + 1 + mx , l1y + my ) ; BLK ( ctx - > cur , l1x , l1y + 1 ) = BLK ( ctx - > prev , l1x + mx , l1y + 1 + my ) ; BLK ( ctx - > cur , l1x + 1 , l1y + 1 ) = BLK ( ctx - > prev , l1x + 1 + mx , l1y + 1 + my ) ; } } else { // read values for block BLK ( ctx - > cur , l1x , l1y ) = * src + + ; BLK ( ctx - > cur , l1x + 1 , l1y ) = * src + + ; BLK ( ctx - > cur , l1x , l1y + 1 ) = * src + + ; BLK ( ctx - > cur , l1x + 1 , l1y + 1 ) = * src + + ; } } } } } } return 0 ; }",1
"int ff_write_chained ( AVFormatContext * dst , int dst_stream , AVPacket * pkt , AVFormatContext * src ) { AVPacket local_pkt ; local_pkt = * pkt ; local_pkt . stream_index = dst_stream ; if ( pkt - > pts ! = AV_NOPTS_VALUE ) local_pkt . pts = av_rescale_q ( pkt - > pts , src - > streams[pkt - > stream_index] - > time_base , dst - > streams[dst_stream] - > time_base ) ; if ( pkt - > dts ! = AV_NOPTS_VALUE ) local_pkt . dts = av_rescale_q ( pkt - > dts , src - > streams[pkt - > stream_index] - > time_base , dst - > streams[dst_stream] - > time_base ) ; if ( pkt - > duration ) local_pkt . duration = av_rescale_q ( pkt - > duration , src - > streams[pkt - > stream_index] - > time_base , dst - > streams[dst_stream] - > time_base ) ; return av_write_frame ( dst , & local_pkt ) ; }",1
"static int tm2_read_stream ( TM2Context * ctx , const uint8_t * buf , int stream_id , int buf_size ) { int i ; int skip = 0 ; int len , toks , pos ; TM2Codes codes ; GetByteContext gb ; if ( buf_size < 4 ) { av_log ( ctx - > avctx , AV_LOG_ERROR , not enough space for len left\n ) ; return AVERROR_INVALIDDATA ; } / * get stream length in dwords * / bytestream2_init ( & gb , buf , buf_size ) ; len = bytestream2_get_be32 ( & gb ) ; skip = len * 4 + 4 ; if ( len == 0 ) return 4 ; if ( len > = INT_MAX/4 - 1 || len < 0 || skip > buf_size ) { av_log ( ctx - > avctx , AV_LOG_ERROR , invalid stream size\n ) ; return AVERROR_INVALIDDATA ; } toks = bytestream2_get_be32 ( & gb ) ; if ( toks & 1 ) { len = bytestream2_get_be32 ( & gb ) ; if ( len == TM2_ESCAPE ) { len = bytestream2_get_be32 ( & gb ) ; } if ( len > 0 ) { pos = bytestream2_tell ( & gb ) ; if ( skip < = pos ) return AVERROR_INVALIDDATA ; init_get_bits ( & ctx - > gb , buf + pos , ( skip - pos ) * 8 ) ; if ( tm2_read_deltas ( ctx , stream_id ) == - 1 ) return AVERROR_INVALIDDATA ; bytestream2_skip ( & gb , ( ( get_bits_count ( & ctx - > gb ) + 31 ) > > 5 ) < < 2 ) ; } } / * skip unused fields * / len = bytestream2_get_be32 ( & gb ) ; if ( len == TM2_ESCAPE ) { / * some unknown length - could be escaped too * / bytestream2_skip ( & gb , 8 ) ; / * unused by decoder * / } else { bytestream2_skip ( & gb , 4 ) ; / * unused by decoder * / } pos = bytestream2_tell ( & gb ) ; if ( skip < = pos ) return AVERROR_INVALIDDATA ; init_get_bits ( & ctx - > gb , buf + pos , ( skip - pos ) * 8 ) ; if ( tm2_build_huff_table ( ctx , & codes ) == - 1 ) return AVERROR_INVALIDDATA ; bytestream2_skip ( & gb , ( ( get_bits_count ( & ctx - > gb ) + 31 ) > > 5 ) < < 2 ) ; toks > > = 1 ; / * check if we have sane number of tokens * / if ( ( toks < 0 ) || ( toks > 0xFFFFFF ) ) { av_log ( ctx - > avctx , AV_LOG_ERROR , Incorrect number of tokens : %i\n , toks ) ; tm2_free_codes ( & codes ) ; return AVERROR_INVALIDDATA ; } ctx - > tokens[stream_id] = av_realloc ( ctx - > tokens[stream_id] , toks * sizeof ( int ) ) ; ctx - > tok_lens[stream_id] = toks ; len = bytestream2_get_be32 ( & gb ) ; if ( len > 0 ) { pos = bytestream2_tell ( & gb ) ; if ( skip < = pos ) return AVERROR_INVALIDDATA ; init_get_bits ( & ctx - > gb , buf + pos , ( skip - pos ) * 8 ) ; for ( i = 0 ; i < toks ; i + + ) { if ( get_bits_left ( & ctx - > gb ) < = 0 ) { av_log ( ctx - > avctx , AV_LOG_ERROR , Incorrect number of tokens : %i\n , toks ) ; return AVERROR_INVALIDDATA ; } ctx - > tokens[stream_id][i] = tm2_get_token ( & ctx - > gb , & codes ) ; if ( stream_id < = TM2_MOT & & ctx - > tokens[stream_id][i] > = TM2_DELTAS ) { av_log ( ctx - > avctx , AV_LOG_ERROR , Invalid delta token index %d for type %d , n=%d\n , ctx - > tokens[stream_id][i] , stream_id , i ) ; return AVERROR_INVALIDDATA ; } } } else { for ( i = 0 ; i < toks ; i + + ) { ctx - > tokens[stream_id][i] = codes . recode[0] ; if ( stream_id < = TM2_MOT & & ctx - > tokens[stream_id][i] > = TM2_DELTAS ) { av_log ( ctx - > avctx , AV_LOG_ERROR , Invalid delta token index %d for type %d , n=%d\n , ctx - > tokens[stream_id][i] , stream_id , i ) ; return AVERROR_INVALIDDATA ; } } } tm2_free_codes ( & codes ) ; return skip ; }",0
"static int parse_section_header ( GetByteContext * gbc , int * section_size , enum HapSectionType * section_type ) { if ( bytestream2_get_bytes_left ( gbc ) < 4 ) return AVERROR_INVALIDDATA ; * section_size = bytestream2_get_le24 ( gbc ) ; * section_type = bytestream2_get_byte ( gbc ) ; if ( * section_size == 0 ) { if ( bytestream2_get_bytes_left ( gbc ) < 4 ) return AVERROR_INVALIDDATA ; * section_size = bytestream2_get_le32 ( gbc ) ; } if ( * section_size > bytestream2_get_bytes_left ( gbc ) ) return AVERROR_INVALIDDATA ; else return 0 ; }",0
"static int amr_nb_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; AMRContext * s = avctx - > priv_data ; static const uint8_t block_size[16] = { 12 , 13 , 15 , 17 , 19 , 20 , 26 , 31 , 5 , 0 , 0 , 0 , 0 , 0 , 0 , 0 } ; enum Mode dec_mode ; int packet_size ; av_dlog ( avctx , amr_decode_frame buf=%p buf_size=%d frame_count=%d ! ! \n , buf , buf_size , avctx - > frame_number ) ; dec_mode = ( buf[0] > > 3 ) & 0x000F ; packet_size = block_size[dec_mode] + 1 ; if ( packet_size > buf_size ) { av_log ( avctx , AV_LOG_ERROR , amr frame too short ( %u , should be %u ) \n , buf_size , packet_size ) ; return AVERROR_INVALIDDATA ; } av_dlog ( avctx , packet_size=%d buf= 0x%X %X %X %X\n , packet_size , buf[0] , buf[1] , buf[2] , buf[3] ) ; / * call decoder * / Decoder_Interface_Decode ( s - > dec_state , buf , data , 0 ) ; * data_size = 160 * 2 ; return packet_size ; }",0
"static int pps_range_extensions ( GetBitContext * gb , AVCodecContext * avctx , HEVCPPS * pps , HEVCSPS * sps ) { int i ; if ( pps - > transform_skip_enabled_flag ) { pps - > log2_max_transform_skip_block_size = get_ue_golomb_long ( gb ) + 2 ; } pps - > cross_component_prediction_enabled_flag = get_bits1 ( gb ) ; pps - > chroma_qp_offset_list_enabled_flag = get_bits1 ( gb ) ; if ( pps - > chroma_qp_offset_list_enabled_flag ) { pps - > diff_cu_chroma_qp_offset_depth = get_ue_golomb_long ( gb ) ; pps - > chroma_qp_offset_list_len_minus1 = get_ue_golomb_long ( gb ) ; if ( pps - > chroma_qp_offset_list_len_minus1 & & pps - > chroma_qp_offset_list_len_minus1 > = 5 ) { av_log ( avctx , AV_LOG_ERROR , chroma_qp_offset_list_len_minus1 shall be in the range [0 , 5] . \n ) ; return AVERROR_INVALIDDATA ; } for ( i = 0 ; i < = pps - > chroma_qp_offset_list_len_minus1 ; i + + ) { pps - > cb_qp_offset_list[i] = get_se_golomb_long ( gb ) ; if ( pps - > cb_qp_offset_list[i] ) { av_log ( avctx , AV_LOG_WARNING , cb_qp_offset_list not tested yet . \n ) ; } pps - > cr_qp_offset_list[i] = get_se_golomb_long ( gb ) ; if ( pps - > cr_qp_offset_list[i] ) { av_log ( avctx , AV_LOG_WARNING , cb_qp_offset_list not tested yet . \n ) ; } } } pps - > log2_sao_offset_scale_luma = get_ue_golomb_long ( gb ) ; pps - > log2_sao_offset_scale_chroma = get_ue_golomb_long ( gb ) ; return ( 0 ) ; }",0
"av_cold int ff_wma_init ( AVCodecContext * avctx , int flags2 ) { WMACodecContext * s = avctx - > priv_data ; int i ; float bps1 , high_freq ; volatile float bps ; int sample_rate1 ; int coef_vlc_table ; if ( avctx - > sample_rate < = 0 || avctx - > sample_rate > 50000 || avctx - > channels < = 0 || avctx - > channels > 2 || avctx - > bit_rate < = 0 ) return - 1 ; ff_fmt_convert_init ( & s - > fmt_conv , avctx ) ; avpriv_float_dsp_init ( & s - > fdsp , avctx - > flags & CODEC_FLAG_BITEXACT ) ; if ( avctx - > codec - > id == AV_CODEC_ID_WMAV1 ) s - > version = 1 ; else s - > version = 2 ; / * compute MDCT block size * / s - > frame_len_bits = ff_wma_get_frame_len_bits ( avctx - > sample_rate , s - > version , 0 ) ; s - > next_block_len_bits = s - > frame_len_bits ; s - > prev_block_len_bits = s - > frame_len_bits ; s - > block_len_bits = s - > frame_len_bits ; s - > frame_len = 1 < < s - > frame_len_bits ; if ( s - > use_variable_block_len ) { int nb_max , nb ; nb = ( ( flags2 > > 3 ) & 3 ) + 1 ; if ( ( avctx - > bit_rate / avctx - > channels ) > = 32000 ) nb + = 2 ; nb_max = s - > frame_len_bits - BLOCK_MIN_BITS ; if ( nb > nb_max ) nb = nb_max ; s - > nb_block_sizes = nb + 1 ; } else s - > nb_block_sizes = 1 ; / * init rate dependent parameters * / s - > use_noise_coding = 1 ; high_freq = avctx - > sample_rate * 0 . 5 ; / * if version 2 , then the rates are normalized * / sample_rate1 = avctx - > sample_rate ; if ( s - > version == 2 ) { if ( sample_rate1 > = 44100 ) sample_rate1 = 44100 ; else if ( sample_rate1 > = 22050 ) sample_rate1 = 22050 ; else if ( sample_rate1 > = 16000 ) sample_rate1 = 16000 ; else if ( sample_rate1 > = 11025 ) sample_rate1 = 11025 ; else if ( sample_rate1 > = 8000 ) sample_rate1 = 8000 ; } bps = ( float ) avctx - > bit_rate / ( float ) ( avctx - > channels * avctx - > sample_rate ) ; s - > byte_offset_bits = av_log2 ( ( int ) ( bps * s - > frame_len / 8 . 0 + 0 . 5 ) ) + 2 ; / * compute high frequency value and choose if noise coding should * be activated * / bps1 = bps ; if ( avctx - > channels == 2 ) bps1 = bps * 1 . 6 ; if ( sample_rate1 == 44100 ) { if ( bps1 > = 0 . 61 ) s - > use_noise_coding = 0 ; else high_freq = high_freq * 0 . 4 ; } else if ( sample_rate1 == 22050 ) { if ( bps1 > = 1 . 16 ) s - > use_noise_coding = 0 ; else if ( bps1 > = 0 . 72 ) high_freq = high_freq * 0 . 7 ; else high_freq = high_freq * 0 . 6 ; } else if ( sample_rate1 == 16000 ) { if ( bps > 0 . 5 ) high_freq = high_freq * 0 . 5 ; else high_freq = high_freq * 0 . 3 ; } else if ( sample_rate1 == 11025 ) high_freq = high_freq * 0 . 7 ; else if ( sample_rate1 == 8000 ) { if ( bps < = 0 . 625 ) high_freq = high_freq * 0 . 5 ; else if ( bps > 0 . 75 ) s - > use_noise_coding = 0 ; else high_freq = high_freq * 0 . 65 ; } else { if ( bps > = 0 . 8 ) high_freq = high_freq * 0 . 75 ; else if ( bps > = 0 . 6 ) high_freq = high_freq * 0 . 6 ; else high_freq = high_freq * 0 . 5 ; } av_dlog ( s - > avctx , flags2=0x%x\n , flags2 ) ; av_dlog ( s - > avctx , version=%d channels=%d sample_rate=%d bitrate=%d block_align=%d\n , s - > version , avctx - > channels , avctx - > sample_rate , avctx - > bit_rate , avctx - > block_align ) ; av_dlog ( s - > avctx , bps=%f bps1=%f high_freq=%f bitoffset=%d\n , bps , bps1 , high_freq , s - > byte_offset_bits ) ; av_dlog ( s - > avctx , use_noise_coding=%d use_exp_vlc=%d nb_block_sizes=%d\n , s - > use_noise_coding , s - > use_exp_vlc , s - > nb_block_sizes ) ; / * compute the scale factor band sizes for each MDCT block size * / { int a , b , pos , lpos , k , block_len , i , j , n ; const uint8_t * table ; if ( s - > version == 1 ) s - > coefs_start = 3 ; else s - > coefs_start = 0 ; for ( k = 0 ; k < s - > nb_block_sizes ; k + + ) { block_len = s - > frame_len > > k ; if ( s - > version == 1 ) { lpos = 0 ; for ( i = 0 ; i < 25 ; i + + ) { a = ff_wma_critical_freqs[i] ; b = avctx - > sample_rate ; pos = ( ( block_len * 2 * a ) + ( b > > 1 ) ) / b ; if ( pos > block_len ) pos = block_len ; s - > exponent_bands[0][i] = pos - lpos ; if ( pos > = block_len ) { i + + ; break ; } lpos = pos ; } s - > exponent_sizes[0] = i ; } else { / * hardcoded tables * / table = NULL ; a = s - > frame_len_bits - BLOCK_MIN_BITS - k ; if ( a < 3 ) { if ( avctx - > sample_rate > = 44100 ) table = exponent_band_44100[a] ; else if ( avctx - > sample_rate > = 32000 ) table = exponent_band_32000[a] ; else if ( avctx - > sample_rate > = 22050 ) table = exponent_band_22050[a] ; } if ( table ) { n = * table + + ; for ( i = 0 ; i < n ; i + + ) s - > exponent_bands[k][i] = table[i] ; s - > exponent_sizes[k] = n ; } else { j = 0 ; lpos = 0 ; for ( i = 0 ; i < 25 ; i + + ) { a = ff_wma_critical_freqs[i] ; b = avctx - > sample_rate ; pos = ( ( block_len * 2 * a )",0
"static void avc_h_loop_filter_chroma422_mbaff_msa ( uint8_t * src , int32_t stride , int32_t alpha_in , int32_t beta_in , int8_t * tc0 ) { int32_t col , tc_val ; int16_t out0 , out1 ; v16u8 alpha , beta , res ; alpha = ( v16u8 ) __msa_fill_b ( alpha_in ) ; beta = ( v16u8 ) __msa_fill_b ( beta_in ) ; for ( col = 0 ; col < 4 ; col + + ) { tc_val = ( tc0[col] - 1 ) + 1 ; if ( tc_val < = 0 ) { src + = 4 * stride ; continue ; } AVC_LPF_H_2BYTE_CHROMA_422 ( src , stride , tc_val , alpha , beta , res ) ; out0 = __msa_copy_s_h ( ( v8i16 ) res , 0 ) ; out1 = __msa_copy_s_h ( ( v8i16 ) res , 1 ) ; STORE_HWORD ( ( src - 1 ) , out0 ) ; src + = stride ; STORE_HWORD ( ( src - 1 ) , out1 ) ; src + = stride ; } }",0
"static void mdct_test ( AC3MDCTContext * mdct , AVLFG * lfg ) { int16_t input[MDCT_SAMPLES] ; int32_t output[AC3_MAX_COEFS] ; float input1[MDCT_SAMPLES] ; float output1[AC3_MAX_COEFS] ; float s , a , err , e , emax ; int i , k , n ; for ( i = 0 ; i < MDCT_SAMPLES ; i + + ) { input[i] = ( av_lfg_get ( lfg ) % 65535 - 32767 ) * 9 / 10 ; input1[i] = input[i] ; } mdct512 ( mdct , output , input ) ; / * do it by hand * / for ( k = 0 ; k < AC3_MAX_COEFS ; k + + ) { s = 0 ; for ( n = 0 ; n < MDCT_SAMPLES ; n + + ) { a = ( 2 * M_PI * ( 2 * n + 1 + MDCT_SAMPLES/2 ) * ( 2 * k + 1 ) / ( 4 * MDCT_SAMPLES ) ) ; s + = input1[n] * cos ( a ) ; } output1[k] = - 2 * s / MDCT_SAMPLES ; } err = 0 ; emax = 0 ; for ( i = 0 ; i < AC3_MAX_COEFS ; i + + ) { av_log ( NULL , AV_LOG_DEBUG , %3d : %7d %7 . 0f\n , i , output[i] , output1[i] ) ; e = output[i] - output1[i] ; if ( e > emax ) emax = e ; err + = e * e ; } av_log ( NULL , AV_LOG_DEBUG , err2=%f emax=%f\n , err / AC3_MAX_COEFS , emax ) ; }",0
"void ff_put_h264_qpel4_mc13_msa ( uint8_t * dst , const uint8_t * src , ptrdiff_t stride ) { avc_luma_hv_qrt_4w_msa ( src + stride - 2 , src - ( stride * 2 ) , stride , dst , stride , 4 ) ; }",0
"static void copy_cell ( Indeo3DecodeContext * ctx , Plane * plane , Cell * cell ) { int h , w , mv_x , mv_y , offset , offset_dst ; uint8_t * src , * dst ; / * setup output and reference pointers * / offset_dst = ( cell - > ypos < < 2 ) * plane - > pitch + ( cell - > xpos < < 2 ) ; dst = plane - > pixels[ctx - > buf_sel] + offset_dst ; mv_y = cell - > mv_ptr[0] ; mv_x = cell - > mv_ptr[1] ; offset = offset_dst + mv_y * plane - > pitch + mv_x ; src = plane - > pixels[ctx - > buf_sel 1] + offset ; h = cell - > height < < 2 ; for ( w = cell - > width ; w > 0 ; ) { / * copy using 16xH blocks * / if ( ! ( ( cell - > xpos < < 2 ) & 15 ) & & w > = 4 ) { for ( ; w > = 4 ; src + = 16 , dst + = 16 , w - = 4 ) ctx - > dsp . put_no_rnd_pixels_tab[0][0] ( dst , src , plane - > pitch , h ) ; } / * copy using 8xH blocks * / if ( ! ( ( cell - > xpos < < 2 ) & 7 ) & & w > = 2 ) { ctx - > dsp . put_no_rnd_pixels_tab[1][0] ( dst , src , plane - > pitch , h ) ; w - = 2 ; src + = 8 ; dst + = 8 ; } if ( w > = 1 ) { ctx - > dsp . put_no_rnd_pixels_tab[2][0] ( dst , src , plane - > pitch , h ) ; w - - ; src + = 4 ; dst + = 4 ; } } }",0
"static int flv_same_audio_codec ( AVCodecContext * acodec , int flags ) { int bits_per_coded_sample = ( flags & FLV_AUDIO_SAMPLESIZE_MASK ) ? 16 : 8 ; int flv_codecid = flags & FLV_AUDIO_CODECID_MASK ; int codec_id ; if ( ! acodec - > codec_id & & ! acodec - > codec_tag ) return 1 ; if ( acodec - > bits_per_coded_sample ! = bits_per_coded_sample ) return 0 ; switch ( flv_codecid ) { //no distinction between S16 and S8 PCM codec flags case FLV_CODECID_PCM : codec_id = bits_per_coded_sample == 8 ? AV_CODEC_ID_PCM_U8 : if HAVE_BIGENDIAN AV_CODEC_ID_PCM_S16BE ; else AV_CODEC_ID_PCM_S16LE ; endif return codec_id == acodec - > codec_id ; case FLV_CODECID_PCM_LE : codec_id = bits_per_coded_sample == 8 ? AV_CODEC_ID_PCM_U8 : AV_CODEC_ID_PCM_S16LE ; return codec_id == acodec - > codec_id ; case FLV_CODECID_AAC : return acodec - > codec_id == AV_CODEC_ID_AAC ; case FLV_CODECID_ADPCM : return acodec - > codec_id == AV_CODEC_ID_ADPCM_SWF ; case FLV_CODECID_SPEEX : return acodec - > codec_id == AV_CODEC_ID_SPEEX ; case FLV_CODECID_MP3 : return acodec - > codec_id == AV_CODEC_ID_MP3 ; case FLV_CODECID_NELLYMOSER_8KHZ_MONO : case FLV_CODECID_NELLYMOSER_16KHZ_MONO : case FLV_CODECID_NELLYMOSER : return acodec - > codec_id == AV_CODEC_ID_NELLYMOSER ; case FLV_CODECID_PCM_MULAW : return acodec - > sample_rate == 8000 & & acodec - > codec_id == AV_CODEC_ID_PCM_MULAW ; case FLV_CODECID_PCM_ALAW : return acodec - > sample_rate = 8000 & & acodec - > codec_id == AV_CODEC_ID_PCM_ALAW ; default : return acodec - > codec_tag == ( flv_codecid > > FLV_AUDIO_CODECID_OFFSET ) ; } }",0
"int avpriv_mpeg4audio_get_config ( MPEG4AudioConfig * c , const uint8_t * buf , int bit_size , int sync_extension ) { GetBitContext gb ; int specific_config_bitindex ; if ( bit_size < =0 ) return AVERROR_INVALIDDATA ; init_get_bits ( & gb , buf , bit_size ) ; c - > object_type = get_object_type ( & gb ) ; c - > sample_rate = get_sample_rate ( & gb , & c - > sampling_index ) ; c - > chan_config = get_bits ( & gb , 4 ) ; if ( c - > chan_config < FF_ARRAY_ELEMS ( ff_mpeg4audio_channels ) ) c - > channels = ff_mpeg4audio_channels[c - > chan_config] ; c - > sbr = - 1 ; c - > ps = - 1 ; if ( c - > object_type == AOT_SBR || ( c - > object_type == AOT_PS & & // check for W6132 Annex YYYY draft MP3onMP4 ! ( show_bits ( & gb , 3 ) & 0x03 & & ! ( show_bits ( & gb , 9 ) & 0x3F ) ) ) ) { if ( c - > object_type == AOT_PS ) c - > ps = 1 ; c - > ext_object_type = AOT_SBR ; c - > sbr = 1 ; c - > ext_sample_rate = get_sample_rate ( & gb , & c - > ext_sampling_index ) ; c - > object_type = get_object_type ( & gb ) ; if ( c - > object_type == AOT_ER_BSAC ) c - > ext_chan_config = get_bits ( & gb , 4 ) ; } else { c - > ext_object_type = AOT_NULL ; c - > ext_sample_rate = 0 ; } specific_config_bitindex = get_bits_count ( & gb ) ; if ( c - > object_type == AOT_ALS ) { skip_bits ( & gb , 5 ) ; if ( show_bits_long ( & gb , 24 ) ! = MKBETAG ( ' \0 ' , ' A ' , ' L ' , ' S ' ) ) skip_bits_long ( & gb , 24 ) ; specific_config_bitindex = get_bits_count ( & gb ) ; if ( parse_config_ALS ( & gb , c ) ) return - 1 ; } if ( c - > ext_object_type ! = AOT_SBR & & sync_extension ) { while ( get_bits_left ( & gb ) > 15 ) { if ( show_bits ( & gb , 11 ) == 0x2b7 ) { // sync extension get_bits ( & gb , 11 ) ; c - > ext_object_type = get_object_type ( & gb ) ; if ( c - > ext_object_type == AOT_SBR & & ( c - > sbr = get_bits1 ( & gb ) ) == 1 ) { c - > ext_sample_rate = get_sample_rate ( & gb , & c - > ext_sampling_index ) ; if ( c - > ext_sample_rate == c - > sample_rate ) c - > sbr = - 1 ; } if ( get_bits_left ( & gb ) > 11 & & get_bits ( & gb , 11 ) == 0x548 ) c - > ps = get_bits1 ( & gb ) ; break ; } else get_bits1 ( & gb ) ; // skip 1 bit } } //PS requires SBR if ( ! c - > sbr ) c - > ps = 0 ; //Limit implicit PS to the HE - AACv2 Profile if ( ( c - > ps == - 1 & & c - > object_type ! = AOT_AAC_LC ) || c - > channels & 0x01 ) c - > ps = 0 ; return specific_config_bitindex ; }",1
"static AVRational update_sar ( int old_w , int old_h , AVRational sar , int new_w , int new_h ) { // attempt to keep aspect during typical resolution switches if ( ! sar . num ) sar = ( AVRational ) { 1 , 1 } ; sar = av_mul_q ( sar , ( AVRational ) { new_h * old_w , new_w * old_h } ) ; return sar ; }",1
"vorbis_header ( AVFormatContext * s , int idx ) { ogg_t * ogg = s - > priv_data ; ogg_stream_t * os = ogg - > streams + idx ; AVStream * st = s - > streams[idx] ; oggvorbis_private_t * priv ; if ( os - > seq > 2 ) return 0 ; if ( os - > seq == 0 ) { os - > private = av_mallocz ( sizeof ( oggvorbis_private_t ) ) ; if ( ! os - > private ) return 0 ; } priv = os - > private ; priv - > len[os - > seq] = os - > psize ; priv - > packet[os - > seq] = av_mallocz ( os - > psize ) ; memcpy ( priv - > packet[os - > seq] , os - > buf + os - > pstart , os - > psize ) ; if ( os - > buf[os - > pstart] == 1 ) { uint8_t * p = os - > buf + os - > pstart + 11 ; //skip up to the audio channels st - > codec - > channels = * p + + ; st - > codec - > sample_rate = AV_RL32 ( p ) ; p + = 8 ; //skip maximum and and nominal bitrate st - > codec - > bit_rate = AV_RL32 ( p ) ; //Minimum bitrate st - > codec - > codec_type = CODEC_TYPE_AUDIO ; st - > codec - > codec_id = CODEC_ID_VORBIS ; st - > time_base . num = 1 ; st - > time_base . den = st - > codec - > sample_rate ; } else if ( os - > buf[os - > pstart] == 3 ) { vorbis_comment ( s , os - > buf + os - > pstart + 7 , os - > psize - 8 ) ; } else { st - > codec - > extradata_size = fixup_vorbis_headers ( s , priv , & st - > codec - > extradata ) ; } return os - > seq < 3 ; }",1
"static struct URLProtocol * url_find_protocol ( const char * filename ) { URLProtocol * up = NULL ; char proto_str[128] , proto_nested[128] , * ptr ; size_t proto_len = strspn ( filename , URL_SCHEME_CHARS ) ; if ( filename[proto_len] ! = ' : ' & & ( filename[proto_len] ! = ' , ' || ! strchr ( filename + proto_len + 1 , ' : ' ) ) || is_dos_path ( filename ) ) strcpy ( proto_str , file ) ; else av_strlcpy ( proto_str , filename , FFMIN ( proto_len + 1 , sizeof ( proto_str ) ) ) ; if ( ( ptr = strchr ( proto_str , ' , ' ) ) ) * ptr = ' \0 ' ; av_strlcpy ( proto_nested , proto_str , sizeof ( proto_nested ) ) ; if ( ( ptr = strchr ( proto_nested , ' + ' ) ) ) * ptr = ' \0 ' ; while ( up = ffurl_protocol_next ( up ) ) { if ( ! strcmp ( proto_str , up - > name ) ) break ; if ( up - > flags & URL_PROTOCOL_FLAG_NESTED_SCHEME & & ! strcmp ( proto_nested , up - > name ) ) break ; } return up ; }",1
"static av_cold int sonic_decode_init ( AVCodecContext * avctx ) { SonicContext * s = avctx - > priv_data ; GetBitContext gb ; int i ; s - > channels = avctx - > channels ; s - > samplerate = avctx - > sample_rate ; if ( ! avctx - > extradata ) { av_log ( avctx , AV_LOG_ERROR , No mandatory headers present\n ) ; return AVERROR_INVALIDDATA ; } init_get_bits8 ( & gb , avctx - > extradata , avctx - > extradata_size ) ; s - > version = get_bits ( & gb , 2 ) ; if ( s - > version > = 2 ) { s - > version = get_bits ( & gb , 8 ) ; s - > minor_version = get_bits ( & gb , 8 ) ; } if ( s - > version ! = 2 ) { av_log ( avctx , AV_LOG_ERROR , Unsupported Sonic version , please report\n ) ; return AVERROR_INVALIDDATA ; } if ( s - > version > = 1 ) { s - > channels = get_bits ( & gb , 2 ) ; s - > samplerate = samplerate_table[get_bits ( & gb , 4 ) ] ; av_log ( avctx , AV_LOG_INFO , Sonicv2 chans : %d samprate : %d\n , s - > channels , s - > samplerate ) ; } if ( s - > channels > MAX_CHANNELS ) { av_log ( avctx , AV_LOG_ERROR , Only mono and stereo streams are supported by now\n ) ; return AVERROR_INVALIDDATA ; } s - > lossless = get_bits1 ( & gb ) ; if ( ! s - > lossless ) skip_bits ( & gb , 3 ) ; // XXX FIXME s - > decorrelation = get_bits ( & gb , 2 ) ; if ( s - > decorrelation ! = 3 & & s - > channels ! = 2 ) { av_log ( avctx , AV_LOG_ERROR , invalid decorrelation %d\n , s - > decorrelation ) ; return AVERROR_INVALIDDATA ; } s - > downsampling = get_bits ( & gb , 2 ) ; if ( ! s - > downsampling ) { av_log ( avctx , AV_LOG_ERROR , invalid downsampling value\n ) ; return AVERROR_INVALIDDATA ; } s - > num_taps = ( get_bits ( & gb , 5 ) + 1 ) < < 5 ; if ( get_bits1 ( & gb ) ) // XXX FIXME av_log ( avctx , AV_LOG_INFO , Custom quant table\n ) ; s - > block_align = 2048LL * s - > samplerate/ ( 44100 * s - > downsampling ) ; s - > frame_size = s - > channels * s - > block_align * s - > downsampling ; // avctx - > frame_size = s - > block_align ; av_log ( avctx , AV_LOG_INFO , Sonic : ver : %d . %d ls : %d dr : %d taps : %d block : %d frame : %d downsamp : %d\n , s - > version , s - > minor_version , s - > lossless , s - > decorrelation , s - > num_taps , s - > block_align , s - > frame_size , s - > downsampling ) ; // generate taps s - > tap_quant = av_calloc ( s - > num_taps , sizeof ( * s - > tap_quant ) ) ; if ( ! s - > tap_quant ) return AVERROR ( ENOMEM ) ; for ( i = 0 ; i < s - > num_taps ; i + + ) s - > tap_quant[i] = ff_sqrt ( i + 1 ) ; s - > predictor_k = av_calloc ( s - > num_taps , sizeof ( * s - > predictor_k ) ) ; for ( i = 0 ; i < s - > channels ; i + + ) { s - > predictor_state[i] = av_calloc ( s - > num_taps , sizeof ( * * s - > predictor_state ) ) ; if ( ! s - > predictor_state[i] ) return AVERROR ( ENOMEM ) ; } for ( i = 0 ; i < s - > channels ; i + + ) { s - > coded_samples[i] = av_calloc ( s - > block_align , sizeof ( * * s - > coded_samples ) ) ; if ( ! s - > coded_samples[i] ) return AVERROR ( ENOMEM ) ; } s - > int_samples = av_calloc ( s - > frame_size , sizeof ( * s - > int_samples ) ) ; if ( ! s - > int_samples ) return AVERROR ( ENOMEM ) ; avctx - > sample_fmt = AV_SAMPLE_FMT_S16 ; return 0 ; }",0
"static int decode_block ( BinkAudioContext * s , float * * out , int use_dct ) { int ch , i , j , k ; float q , quant[25] ; int width , coeff ; GetBitContext * gb = & s - > gb ; if ( use_dct ) skip_bits ( gb , 2 ) ; for ( ch = 0 ; ch < s - > channels ; ch + + ) { FFTSample * coeffs = out[ch] ; if ( s - > version_b ) { if ( get_bits_left ( gb ) < 64 ) return AVERROR_INVALIDDATA ; coeffs[0] = av_int2float ( get_bits_long ( gb , 32 ) ) * s - > root ; coeffs[1] = av_int2float ( get_bits_long ( gb , 32 ) ) * s - > root ; } else { if ( get_bits_left ( gb ) < 58 ) return AVERROR_INVALIDDATA ; coeffs[0] = get_float ( gb ) * s - > root ; coeffs[1] = get_float ( gb ) * s - > root ; } if ( get_bits_left ( gb ) < s - > num_bands * 8 ) return AVERROR_INVALIDDATA ; for ( i = 0 ; i < s - > num_bands ; i + + ) { int value = get_bits ( gb , 8 ) ; quant[i] = quant_table[FFMIN ( value , 95 ) ] ; } k = 0 ; q = quant[0] ; // parse coefficients i = 2 ; while ( i < s - > frame_len ) { if ( s - > version_b ) { j = i + 16 ; } else { int v ; GET_BITS_SAFE ( v , 1 ) ; if ( v ) { GET_BITS_SAFE ( v , 4 ) ; j = i + rle_length_tab[v] * 8 ; } else { j = i + 8 ; } } j = FFMIN ( j , s - > frame_len ) ; GET_BITS_SAFE ( width , 4 ) ; if ( width == 0 ) { memset ( coeffs + i , 0 , ( j - i ) * sizeof ( * coeffs ) ) ; i = j ; while ( s - > bands[k] < i ) q = quant[k + + ] ; } else { while ( i < j ) { if ( s - > bands[k] == i ) q = quant[k + + ] ; GET_BITS_SAFE ( coeff , width ) ; if ( coeff ) { int v ; GET_BITS_SAFE ( v , 1 ) ; if ( v ) coeffs[i] = - q * coeff ; else coeffs[i] = q * coeff ; } else { coeffs[i] = 0 . 0f ; } i + + ; } } } if ( CONFIG_BINKAUDIO_DCT_DECODER & & use_dct ) { coeffs[0] /= 0 . 5 ; s - > trans . dct . dct_calc ( & s - > trans . dct , coeffs ) ; } else if ( CONFIG_BINKAUDIO_RDFT_DECODER ) s - > trans . rdft . rdft_calc ( & s - > trans . rdft , coeffs ) ; } for ( ch = 0 ; ch < s - > channels ; ch + + ) { int j ; int count = s - > overlap_len * s - > channels ; if ( ! s - > first ) { j = ch ; for ( i = 0 ; i < s - > overlap_len ; i + + , j + = s - > channels ) out[ch][i] = ( s - > previous[ch][i] * ( count - j ) + out[ch][i] * j ) / count ; } memcpy ( s - > previous[ch] , & out[ch][s - > frame_len - s - > overlap_len] , s - > overlap_len * sizeof ( * s - > previous[ch] ) ) ; } s - > first = 0 ; return 0 ; }",1
"static void flac_lpc_16_c ( int32_t * decoded , const int coeffs[32] , int pred_order , int qlevel , int len ) { int i , j ; for ( i = pred_order ; i < len - 1 ; i + = 2 , decoded + = 2 ) { int c = coeffs[0] ; int d = decoded[0] ; int s0 = 0 , s1 = 0 ; for ( j = 1 ; j < pred_order ; j + + ) { s0 + = c * d ; d = decoded[j] ; s1 + = c * d ; c = coeffs[j] ; } s0 + = c * d ; d = decoded[j] + = s0 > > qlevel ; s1 + = c * d ; decoded[j + 1] + = s1 > > qlevel ; } if ( i < len ) { int sum = 0 ; for ( j = 0 ; j < pred_order ; j + + ) sum + = coeffs[j] * decoded[j] ; decoded[j] + = sum > > qlevel ; } }",1
"static void hybrid_synthesis ( float out[2][38][64] , float in[91][32][2] , int is34 , int len ) { int i , n ; if ( is34 ) { for ( n = 0 ; n < len ; n + + ) { memset ( out[0][n] , 0 , 5 * sizeof ( out[0][n][0] ) ) ; memset ( out[1][n] , 0 , 5 * sizeof ( out[1][n][0] ) ) ; for ( i = 0 ; i < 12 ; i + + ) { out[0][n][0] + = in[ i][n][0] ; out[1][n][0] + = in[ i][n][1] ; } for ( i = 0 ; i < 8 ; i + + ) { out[0][n][1] + = in[12 + i][n][0] ; out[1][n][1] + = in[12 + i][n][1] ; } for ( i = 0 ; i < 4 ; i + + ) { out[0][n][2] + = in[20 + i][n][0] ; out[1][n][2] + = in[20 + i][n][1] ; out[0][n][3] + = in[24 + i][n][0] ; out[1][n][3] + = in[24 + i][n][1] ; out[0][n][4] + = in[28 + i][n][0] ; out[1][n][4] + = in[28 + i][n][1] ; } } for ( i = 0 ; i < 59 ; i + + ) { for ( n = 0 ; n < len ; n + + ) { out[0][n][i + 5] = in[i + 32][n][0] ; out[1][n][i + 5] = in[i + 32][n][1] ; } } } else { for ( n = 0 ; n < len ; n + + ) { out[0][n][0] = in[0][n][0] + in[1][n][0] + in[2][n][0] + in[3][n][0] + in[4][n][0] + in[5][n][0] ; out[1][n][0] = in[0][n][1] + in[1][n][1] + in[2][n][1] + in[3][n][1] + in[4][n][1] + in[5][n][1] ; out[0][n][1] = in[6][n][0] + in[7][n][0] ; out[1][n][1] = in[6][n][1] + in[7][n][1] ; out[0][n][2] = in[8][n][0] + in[9][n][0] ; out[1][n][2] = in[8][n][1] + in[9][n][1] ; } for ( i = 0 ; i < 61 ; i + + ) { for ( n = 0 ; n < len ; n + + ) { out[0][n][i + 3] = in[i + 10][n][0] ; out[1][n][i + 3] = in[i + 10][n][1] ; } } } }",0
"static int audio_get_buffer ( AVCodecContext * avctx , AVFrame * frame ) { AVCodecInternal * avci = avctx - > internal ; InternalBuffer * buf ; int buf_size , ret ; buf_size = av_samples_get_buffer_size ( NULL , avctx - > channels , frame - > nb_samples , avctx - > sample_fmt , 0 ) ; if ( buf_size < 0 ) return AVERROR ( EINVAL ) ; / * allocate InternalBuffer if needed * / if ( ! avci - > buffer ) { avci - > buffer = av_mallocz ( sizeof ( InternalBuffer ) ) ; if ( ! avci - > buffer ) return AVERROR ( ENOMEM ) ; } buf = avci - > buffer ; / * if there is a previously - used internal buffer , check its size and * channel count to see if we can reuse it * / if ( buf - > extended_data ) { / * if current buffer is too small , free it * / if ( buf - > extended_data[0] & & buf_size > buf - > audio_data_size ) { av_free ( buf - > extended_data[0] ) ; if ( buf - > extended_data ! = buf - > data ) av_free ( buf - > extended_data ) ; buf - > extended_data = NULL ; buf - > data[0] = NULL ; } / * if number of channels has changed , reset and/or free extended data * pointers but leave data buffer in buf - > data[0] for reuse * / if ( buf - > nb_channels ! = avctx - > channels ) { if ( buf - > extended_data ! = buf - > data ) av_free ( buf - > extended_data ) ; buf - > extended_data = NULL ; } } / * if there is no previous buffer or the previous buffer cannot be used * as - is , allocate a new buffer and/or rearrange the channel pointers * / if ( ! buf - > extended_data ) { if ( ! buf - > data[0] ) { if ( ! ( buf - > data[0] = av_mallocz ( buf_size ) ) ) return AVERROR ( ENOMEM ) ; buf - > audio_data_size = buf_size ; } if ( ( ret = avcodec_fill_audio_frame ( frame , avctx - > channels , avctx - > sample_fmt , buf - > data[0] , buf - > audio_data_size , 0 ) ) ) return ret ; if ( frame - > extended_data == frame - > data ) buf - > extended_data = buf - > data ; else buf - > extended_data = frame - > extended_data ; memcpy ( buf - > data , frame - > data , sizeof ( frame - > data ) ) ; buf - > linesize[0] = frame - > linesize[0] ; buf - > nb_channels = avctx - > channels ; } else { / * copy InternalBuffer info to the AVFrame * / frame - > extended_data = buf - > extended_data ; frame - > linesize[0] = buf - > linesize[0] ; memcpy ( frame - > data , buf - > data , sizeof ( frame - > data ) ) ; } frame - > type = FF_BUFFER_TYPE_INTERNAL ; ff_init_buffer_info ( avctx , frame ) ; if ( avctx - > debug & FF_DEBUG_BUFFERS ) av_log ( avctx , AV_LOG_DEBUG , default_get_buffer called on frame %p , internal audio buffer used\n , frame ) ; return 0 ; }",0
"static void luma_mc ( HEVCContext * s , int16_t * dst , ptrdiff_t dststride , AVFrame * ref , const Mv * mv , int x_off , int y_off , int block_w , int block_h ) { HEVCLocalContext * lc = & s - > HEVClc ; uint8_t * src = ref - > data[0] ; ptrdiff_t srcstride = ref - > linesize[0] ; int pic_width = s - > ps . sps - > width ; int pic_height = s - > ps . sps - > height ; int mx = mv - > x & 3 ; int my = mv - > y & 3 ; int extra_left = ff_hevc_qpel_extra_before[mx] ; int extra_top = ff_hevc_qpel_extra_before[my] ; x_off + = mv - > x > > 2 ; y_off + = mv - > y > > 2 ; src + = y_off * srcstride + ( x_off < < s - > ps . sps - > pixel_shift ) ; if ( x_off < extra_left || y_off < extra_top || x_off > = pic_width - block_w - ff_hevc_qpel_extra_after[mx] || y_off > = pic_height - block_h - ff_hevc_qpel_extra_after[my] ) { const int edge_emu_stride = EDGE_EMU_BUFFER_STRIDE < < s - > ps . sps - > pixel_shift ; int offset = extra_top * srcstride + ( extra_left < < s - > ps . sps - > pixel_shift ) ; int buf_offset = extra_top * edge_emu_stride + ( extra_left < < s - > ps . sps - > pixel_shift ) ; s - > vdsp . emulated_edge_mc ( lc - > edge_emu_buffer , src - offset , edge_emu_stride , srcstride , block_w + ff_hevc_qpel_extra[mx] , block_h + ff_hevc_qpel_extra[my] , x_off - extra_left , y_off - extra_top , pic_width , pic_height ) ; src = lc - > edge_emu_buffer + buf_offset ; srcstride = edge_emu_stride ; } s - > hevcdsp . put_hevc_qpel[my][mx] ( dst , dststride , src , srcstride , block_w , block_h , lc - > mc_buffer ) ; }",0
"static int init_image ( TiffContext * s , AVFrame * frame ) { int ret ; switch ( s - > planar * 1000 + s - > bpp * 10 + s - > bppcount ) { case 11 : s - > avctx - > pix_fmt = AV_PIX_FMT_MONOBLACK ; break ; case 81 : s - > avctx - > pix_fmt = s - > palette_is_set ? AV_PIX_FMT_PAL8 : AV_PIX_FMT_GRAY8 ; break ; case 243 : s - > avctx - > pix_fmt = AV_PIX_FMT_RGB24 ; break ; case 161 : s - > avctx - > pix_fmt = s - > le ? AV_PIX_FMT_GRAY16LE : AV_PIX_FMT_GRAY16BE ; break ; case 162 : s - > avctx - > pix_fmt = AV_PIX_FMT_YA8 ; break ; case 322 : s - > avctx - > pix_fmt = s - > le ? AV_PIX_FMT_YA16LE : AV_PIX_FMT_YA16BE ; break ; case 324 : s - > avctx - > pix_fmt = AV_PIX_FMT_RGBA ; break ; case 483 : s - > avctx - > pix_fmt = s - > le ? AV_PIX_FMT_RGB48LE : AV_PIX_FMT_RGB48BE ; break ; case 644 : s - > avctx - > pix_fmt = s - > le ? AV_PIX_FMT_RGBA64LE : AV_PIX_FMT_RGBA64BE ; break ; case 1243 : s - > avctx - > pix_fmt = AV_PIX_FMT_GBRP ; break ; case 1324 : s - > avctx - > pix_fmt = AV_PIX_FMT_GBRAP ; break ; case 1483 : s - > avctx - > pix_fmt = s - > le ? AV_PIX_FMT_GBRP16LE : AV_PIX_FMT_GBRP16BE ; break ; case 1644 : s - > avctx - > pix_fmt = s - > le ? AV_PIX_FMT_GBRAP16LE : AV_PIX_FMT_GBRAP16BE ; break ; default : This format is not supported ( bpp=%d , bppcount=%d ) \n , if ( s - > width ! = s - > avctx - > width || s - > height ! = s - > avctx - > height ) { ret = ff_set_dimensions ( s - > avctx , s - > width , s - > height ) ; if ( ret < 0 ) return ret ; if ( ( ret = ff_get_buffer ( s - > avctx , frame , 0 ) ) < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , get_buffer ( ) failed\n ) ; return ret ; if ( s - > avctx - > pix_fmt == AV_PIX_FMT_PAL8 ) { memcpy ( frame - > data[1] , s - > palette , sizeof ( s - > palette ) ) ; return 0 ;",1
"static int jpeg2000_decode_packet ( Jpeg2000DecoderContext * s , Jpeg2000Tile * tile , int * tp_index , Jpeg2000CodingStyle * codsty , Jpeg2000ResLevel * rlevel , int precno , int layno , uint8_t * expn , int numgbits ) { int bandno , cblkno , ret , nb_code_blocks ; int cwsno ; if ( bytestream2_get_bytes_left ( & s - > g ) == 0 & & s - > bit_index == 8 ) { if ( * tp_index < FF_ARRAY_ELEMS ( tile - > tile_part ) - 1 ) { s - > g = tile - > tile_part[ + + ( * tp_index ) ] . tpg ; } } if ( bytestream2_peek_be32 ( & s - > g ) == 0xFF910004 ) bytestream2_skip ( & s - > g , 6 ) ; if ( ! ( ret = get_bits ( s , 1 ) ) ) { jpeg2000_flush ( s ) ; return 0 ; } else if ( ret < 0 ) return ret ; for ( bandno = 0 ; bandno < rlevel - > nbands ; bandno + + ) { Jpeg2000Band * band = rlevel - > band + bandno ; Jpeg2000Prec * prec = band - > prec + precno ; if ( band - > coord[0][0] == band - > coord[0][1] || band - > coord[1][0] == band - > coord[1][1] ) continue ; nb_code_blocks = prec - > nb_codeblocks_height * prec - > nb_codeblocks_width ; for ( cblkno = 0 ; cblkno < nb_code_blocks ; cblkno + + ) { Jpeg2000Cblk * cblk = prec - > cblk + cblkno ; int incl , newpasses , llen ; if ( cblk - > npasses ) incl = get_bits ( s , 1 ) ; else incl = tag_tree_decode ( s , prec - > cblkincl + cblkno , layno + 1 ) == layno ; if ( ! incl ) continue ; else if ( incl < 0 ) return incl ; if ( ! cblk - > npasses ) { int v = expn[bandno] + numgbits - 1 - tag_tree_decode ( s , prec - > zerobits + cblkno , 100 ) ; if ( v < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , nonzerobits %d invalid\n , v ) ; return AVERROR_INVALIDDATA ; } cblk - > nonzerobits = v ; } if ( ( newpasses = getnpasses ( s ) ) < 0 ) return newpasses ; av_assert2 ( newpasses > 0 ) ; if ( cblk - > npasses + newpasses > = JPEG2000_MAX_PASSES ) { avpriv_request_sample ( s - > avctx , Too many passes\n ) ; return AVERROR_PATCHWELCOME ; } if ( ( llen = getlblockinc ( s ) ) < 0 ) return llen ; if ( cblk - > lblock + llen + av_log2 ( newpasses ) > 16 ) { avpriv_request_sample ( s - > avctx , Block with length beyond 16 bits\n ) ; return AVERROR_PATCHWELCOME ; } cblk - > lblock + = llen ; cblk - > nb_lengthinc = 0 ; cblk - > nb_terminationsinc = 0 ; do { int newpasses1 = 0 ; while ( newpasses1 < newpasses ) { newpasses1 + + ; if ( needs_termination ( codsty - > cblk_style , cblk - > npasses + newpasses1 - 1 ) ) { cblk - > nb_terminationsinc + + ; break ; } } if ( ( ret = get_bits ( s , av_log2 ( newpasses1 ) + cblk - > lblock ) ) < 0 ) return ret ; if ( ret > sizeof ( cblk - > data ) ) { avpriv_request_sample ( s - > avctx , Block with lengthinc greater than % SIZE_SPECIFIER , sizeof ( cblk - > data ) ) ; return AVERROR_PATCHWELCOME ; } cblk - > lengthinc[cblk - > nb_lengthinc + + ] = ret ; cblk - > npasses + = newpasses1 ; newpasses - = newpasses1 ; } while ( newpasses ) ; } } jpeg2000_flush ( s ) ; if ( codsty - > csty & JPEG2000_CSTY_EPH ) { if ( bytestream2_peek_be16 ( & s - > g ) == JPEG2000_EPH ) bytestream2_skip ( & s - > g , 2 ) ; else av_log ( s - > avctx , AV_LOG_ERROR , EPH marker not found . \n ) ; } for ( bandno = 0 ; bandno < rlevel - > nbands ; bandno + + ) { Jpeg2000Band * band = rlevel - > band + bandno ; Jpeg2000Prec * prec = band - > prec + precno ; nb_code_blocks = prec - > nb_codeblocks_height * prec - > nb_codeblocks_width ; for ( cblkno = 0 ; cblkno < nb_code_blocks ; cblkno + + ) { Jpeg2000Cblk * cblk = prec - > cblk + cblkno ; for ( cwsno = 0 ; cwsno < cblk - > nb_lengthinc ; cwsno + + ) { if ( bytestream2_get_bytes_left ( & s - > g ) < cblk - > lengthinc[cwsno] || sizeof ( cblk - > data ) < cblk - > length + cblk - > lengthinc[cwsno] + 4 ) { av_log ( s - > avctx , AV_LOG_ERROR , Block length % PRIu16 or lengthinc %d is too large , left %d\n , cblk - > length , cblk - > lengthinc[cwsno] , bytestream2_get_bytes_left ( & s - > g ) ) ; return AVERROR_INVALIDDATA ; } bytestream2_get_bufferu ( & s - > g , cblk - > data + cblk - > length , cblk - > lengthinc[cwsno] ) ; cblk - > length + = cblk - > lengthinc[cwsno] ; cblk - > lengthinc[cwsno] = 0 ; if ( cblk - > nb_terminationsinc ) { cblk - > nb_terminationsinc - - ; cblk - > nb_terminations + + ; cblk - > data[cblk - > length + + ] = 0xFF ; cblk - > data[cblk - > length + + ] = 0xFF ; cblk - > data_start[cblk - > nb_terminations] = cblk - > length ; } } } } return 0 ; }",0
"rdt_parse_sdp_line ( AVFormatContext * s , int st_index , PayloadContext * rdt , const char * line ) { AVStream * stream = s - > streams[st_index] ; const char * p = line ; if ( av_strstart ( p , OpaqueData : buffer ; , & p ) ) { rdt - > mlti_data = rdt_parse_b64buf ( & rdt - > mlti_data_size , p ) ; } else if ( av_strstart ( p , StartTime : integer ; , & p ) ) stream - > first_dts = atoi ( p ) ; else if ( av_strstart ( p , ASMRuleBook : string ; , & p ) ) { int n , first = - 1 ; for ( n = 0 ; n < s - > nb_streams ; n + + ) if ( s - > streams[n] - > id == stream - > id ) { int count = s - > streams[n] - > index + 1 ; if ( first == - 1 ) first = n ; if ( rdt - > nb_rmst < count ) { RMStream * * rmst= av_realloc ( rdt - > rmst , count * sizeof ( * rmst ) ) ; if ( ! rmst ) return AVERROR ( ENOMEM ) ; memset ( rmst + rdt - > nb_rmst , 0 , ( count - rdt - > nb_rmst ) * sizeof ( * rmst ) ) ; rdt - > rmst = rmst ; rdt - > nb_rmst = count ; } rdt - > rmst[s - > streams[n] - > index] = ff_rm_alloc_rmstream ( ) ; rdt_load_mdpr ( rdt , s - > streams[n] , ( n - first ) * 2 ) ; if ( s - > streams[n] - > codec - > codec_id == CODEC_ID_AAC ) s - > streams[n] - > codec - > frame_size = 1 ; // FIXME } } return 0 ; }",0
"static void psy_3gpp_analyze_channel ( FFPsyContext * ctx , int channel , const float * coefs , const FFPsyWindowInfo * wi ) { AacPsyContext * pctx = ( AacPsyContext * ) ctx - > model_priv_data ; AacPsyChannel * pch = & pctx - > ch[channel] ; int i , w , g ; float desired_bits , desired_pe , delta_pe , reduction= NAN , spread_en[128] = { 0 } ; float a = 0 . 0f , active_lines = 0 . 0f , norm_fac = 0 . 0f ; float pe = pctx - > chan_bitrate > 32000 ? 0 . 0f : FFMAX ( 50 . 0f , 100 . 0f - pctx - > chan_bitrate * 100 . 0f / 32000 . 0f ) ; const int num_bands = ctx - > num_bands[wi - > num_windows == 8] ; const uint8_t * band_sizes = ctx - > bands[wi - > num_windows == 8] ; AacPsyCoeffs * coeffs = pctx - > psy_coef[wi - > num_windows == 8] ; const float avoid_hole_thr = wi - > num_windows == 8 ? PSY_3GPP_AH_THR_SHORT : PSY_3GPP_AH_THR_LONG ; //calculate energies , initial thresholds and related values - 5 . 4 . 2 Threshold Calculation calc_thr_3gpp ( wi , num_bands , pch , band_sizes , coefs ) ; //modify thresholds and energies - spread , threshold in quiet , pre - echo control for ( w = 0 ; w < wi - > num_windows * 16 ; w + = 16 ) { AacPsyBand * bands = & pch - > band[w] ; / * 5 . 4 . 2 . 3 Spreading & 5 . 4 . 3 Spread Energy Calculation * / spread_en[0] = bands[0] . energy ; for ( g = 1 ; g < num_bands ; g + + ) { bands[g] . thr = FFMAX ( bands[g] . thr , bands[g - 1] . thr * coeffs[g] . spread_hi[0] ) ; spread_en[w + g] = FFMAX ( bands[g] . energy , spread_en[w + g - 1] * coeffs[g] . spread_hi[1] ) ; } for ( g = num_bands - 2 ; g > = 0 ; g - - ) { bands[g] . thr = FFMAX ( bands[g] . thr , bands[g + 1] . thr * coeffs[g] . spread_low[0] ) ; spread_en[w + g] = FFMAX ( spread_en[w + g] , spread_en[w + g + 1] * coeffs[g] . spread_low[1] ) ; } //5 . 4 . 2 . 4 Threshold in quiet for ( g = 0 ; g < num_bands ; g + + ) { AacPsyBand * band = & bands[g] ; band - > thr_quiet = band - > thr = FFMAX ( band - > thr , coeffs[g] . ath ) ; //5 . 4 . 2 . 5 Pre - echo control if ( ! ( wi - > window_type[0] == LONG_STOP_SEQUENCE || ( wi - > window_type[1] == LONG_START_SEQUENCE & & ! w ) ) ) band - > thr = FFMAX ( PSY_3GPP_RPEMIN * band - > thr , FFMIN ( band - > thr , PSY_3GPP_RPELEV * pch - > prev_band[w + g] . thr_quiet ) ) ; / * 5 . 6 . 1 . 3 . 1 Preparatory steps of the perceptual entropy calculation * / pe + = calc_pe_3gpp ( band ) ; a + = band - > pe_const ; active_lines + = band - > active_lines ; / * 5 . 6 . 1 . 3 . 3 Selection of the bands for avoidance of holes * / if ( spread_en[w + g] * avoid_hole_thr > band - > energy || coeffs[g] . min_snr > 1 . 0f ) band - > avoid_holes = PSY_3GPP_AH_NONE ; else band - > avoid_holes = PSY_3GPP_AH_INACTIVE ; } } / * 5 . 6 . 1 . 3 . 2 Calculation of the desired perceptual entropy * / ctx - > ch[channel] . entropy = pe ; desired_bits = calc_bit_demand ( pctx , pe , ctx - > bitres . bits , ctx - > bitres . size , wi - > num_windows == 8 ) ; desired_pe = PSY_3GPP_BITS_TO_PE ( desired_bits ) ; / * NOTE : PE correction is kept simple . During initial testing it had very * little effect on the final bitrate . Probably a good idea to come * back and do more testing later . * / if ( ctx - > bitres . bits > 0 ) desired_pe * = av_clipf ( pctx - > pe . previous / PSY_3GPP_BITS_TO_PE ( ctx - > bitres . bits ) , 0 . 85f , 1 . 15f ) ; pctx - > pe . previous = PSY_3GPP_BITS_TO_PE ( desired_bits ) ; if ( desired_pe < pe ) { / * 5 . 6 . 1 . 3 . 4 First Estimation of the reduction value * / for ( w = 0 ; w < wi - > num_windows * 16 ; w + = 16 ) { reduction = calc_reduction_3gpp ( a , desired_pe , pe , active_lines ) ; pe = 0 . 0f ; a = 0 . 0f ; active_lines = 0 . 0f ; for ( g = 0 ; g < num_bands ; g + + ) { AacPsyBand * band = & pch - > band[w + g] ; band - > thr = calc_reduced_thr_3gpp ( band , coeffs[g] . min_snr , reduction ) ; / * recalculate PE * / pe + = calc_pe_3gpp ( band ) ; a + = band - > pe_const ; active_lines + = band - > active_lines ; } } / * 5 . 6 . 1 . 3 . 5 Second Estimation of the reduction value * / for ( i = 0 ; i < 2 ; i + + ) { float pe_no_ah = 0 . 0f , desired_pe_no_ah ; active_lines = a = 0 . 0f ; for ( w = 0 ; w < wi - > num_windows * 16 ; w + = 16 ) { for ( g = 0 ; g < num_bands ; g + + ) { AacPsyBand * band = & pch - > band[w + g] ; if ( band - > avoid_holes ! = PSY_3GPP_AH_ACTIVE ) { pe_no_ah + = band - > pe ; a + = band - > pe_const ; active_lines + = band - > active_lines ; } } } desired_pe_no_ah = FFMAX ( desired_pe - ( pe - pe_no_ah ) , 0 . 0f ) ; if ( active_lines > 0 . 0f ) reduction + = calc_reduction_3gpp ( a , desired_pe_no_ah , pe_no_ah , active_lines ) ; pe = 0 . 0f ; for ( w = 0 ; w < wi - > num_windows * 16 ; w + = 16 ) { for ( g = 0 ; g < num_bands ; g + + ) { AacPsyBand * band = & pch - > band[w + g] ; if ( active_lines > 0 . 0f ) band - > thr = calc_reduced_thr_3gpp ( band , coeffs[g] . min_snr , reduction ) ; pe + =",0
"static int avi_write_ix ( AVFormatContext * s ) { AVIOContext * pb = s - > pb ; AVIContext * avi = s - > priv_data ; char tag[5] ; char ix_tag[] = ix00 ; int i , j ; assert ( pb - > seekable ) ; if ( avi - > riff_id > AVI_MASTER_INDEX_SIZE ) return - 1 ; for ( i = 0 ; i < s - > nb_streams ; i + + ) { AVIStream * avist = s - > streams[i] - > priv_data ; int64_t ix , pos ; avi_stream2fourcc ( tag , i , s - > streams[i] - > codecpar - > codec_type ) ; ix_tag[3] = ' 0 ' + i ; / * Writing AVI OpenDML leaf index chunk * / ix = avio_tell ( pb ) ; ffio_wfourcc ( pb , ix_tag ) ; / * ix ? ? * / avio_wl32 ( pb , avist - > indexes . entry * 8 + 24 ) ; / * chunk size * / avio_wl16 ( pb , 2 ) ; / * wLongsPerEntry * / avio_w8 ( pb , 0 ) ; / * bIndexSubType ( 0 == frame index ) * / avio_w8 ( pb , 1 ) ; / * bIndexType ( 1 == AVI_INDEX_OF_CHUNKS ) * / avio_wl32 ( pb , avist - > indexes . entry ) ; / * nEntriesInUse * / ffio_wfourcc ( pb , tag ) ; / * dwChunkId * / avio_wl64 ( pb , avi - > movi_list ) ; / * qwBaseOffset * / avio_wl32 ( pb , 0 ) ; / * dwReserved_3 ( must be 0 ) * / for ( j = 0 ; j < avist - > indexes . entry ; j + + ) { AVIIentry * ie = avi_get_ientry ( & avist - > indexes , j ) ; avio_wl32 ( pb , ie - > pos + 8 ) ; avio_wl32 ( pb , ( ( uint32_t ) ie - > len & 0x80000000 ) | ( ie - > flags & 0x10 ? 0 : 0x80000000 ) ) ; } avio_flush ( pb ) ; pos = avio_tell ( pb ) ; / * Updating one entry in the AVI OpenDML master index * / avio_seek ( pb , avist - > indexes . indx_start - 8 , SEEK_SET ) ; ffio_wfourcc ( pb , indx ) ; / * enabling this entry * / avio_skip ( pb , 8 ) ; avio_wl32 ( pb , avi - > riff_id ) ; / * nEntriesInUse * / avio_skip ( pb , 16 * avi - > riff_id ) ; avio_wl64 ( pb , ix ) ; / * qwOffset * / avio_wl32 ( pb , pos - ix ) ; / * dwSize * / avio_wl32 ( pb , avist - > indexes . entry ) ; / * dwDuration * / avio_seek ( pb , pos , SEEK_SET ) ; } return 0 ; }",0
"int ff_dxva2_decode_init ( AVCodecContext * avctx ) { FFDXVASharedContext * sctx = DXVA_SHARED_CONTEXT ( avctx ) ; AVHWFramesContext * frames_ctx = NULL ; int ret = 0 ; // Old API . if ( avctx - > hwaccel_context ) return 0 ; // ( avctx - > pix_fmt is not updated yet at this point ) sctx - > pix_fmt = avctx - > hwaccel - > pix_fmt ; if ( avctx - > codec_id == AV_CODEC_ID_H264 & & ( avctx - > profile & FF_PROFILE_H264_CONSTRAINED ) > FF_PROFILE_H264_HIGH ) { av_log ( avctx , AV_LOG_VERBOSE , Unsupported H . 264 profile for DXVA HWAccel : %d\n , avctx - > profile ) ; return AVERROR ( ENOTSUP ) ; } if ( avctx - > codec_id == AV_CODEC_ID_HEVC & & avctx - > profile ! = FF_PROFILE_HEVC_MAIN & & avctx - > profile ! = FF_PROFILE_HEVC_MAIN_10 ) { av_log ( avctx , AV_LOG_VERBOSE , Unsupported HEVC profile for DXVA HWAccel : %d\n , avctx - > profile ) ; return AVERROR ( ENOTSUP ) ; } if ( ! avctx - > hw_frames_ctx & & ! avctx - > hw_device_ctx ) { av_log ( avctx , AV_LOG_ERROR , Either a hw_frames_ctx or a hw_device_ctx needs to be set for hardware decoding . \n ) ; return AVERROR ( EINVAL ) ; } if ( avctx - > hw_frames_ctx ) { frames_ctx = ( AVHWFramesContext * ) avctx - > hw_frames_ctx - > data ; } else { avctx - > hw_frames_ctx = av_hwframe_ctx_alloc ( avctx - > hw_device_ctx ) ; if ( ! avctx - > hw_frames_ctx ) return AVERROR ( ENOMEM ) ; frames_ctx = ( AVHWFramesContext * ) avctx - > hw_frames_ctx - > data ; dxva_adjust_hwframes ( avctx , frames_ctx ) ; ret = av_hwframe_ctx_init ( avctx - > hw_frames_ctx ) ; if ( ret < 0 ) goto fail ; } sctx - > device_ctx = frames_ctx - > device_ctx ; if ( frames_ctx - > format ! = sctx - > pix_fmt || ! ( ( sctx - > pix_fmt == AV_PIX_FMT_D3D11 & & CONFIG_D3D11VA ) || ( sctx - > pix_fmt == AV_PIX_FMT_DXVA2_VLD & & CONFIG_DXVA2 ) ) ) { av_log ( avctx , AV_LOG_ERROR , Invalid pixfmt for hwaccel ! \n ) ; ret = AVERROR ( EINVAL ) ; goto fail ; } if CONFIG_D3D11VA if ( sctx - > pix_fmt == AV_PIX_FMT_D3D11 ) { AVD3D11VADeviceContext * device_hwctx = frames_ctx - > device_ctx - > hwctx ; AVD3D11VAContext * d3d11_ctx = & sctx - > ctx . d3d11va ; HRESULT hr ; ff_dxva2_lock ( avctx ) ; ret = d3d11va_create_decoder ( avctx ) ; ff_dxva2_unlock ( avctx ) ; if ( ret < 0 ) goto fail ; d3d11_ctx - > decoder = sctx - > d3d11_decoder ; d3d11_ctx - > video_context = device_hwctx - > video_context ; d3d11_ctx - > cfg = & sctx - > d3d11_config ; d3d11_ctx - > surface_count = sctx - > nb_d3d11_views ; d3d11_ctx - > surface = sctx - > d3d11_views ; d3d11_ctx - > workaround = sctx - > workaround ; d3d11_ctx - > context_mutex = INVALID_HANDLE_VALUE ; } endif if CONFIG_DXVA2 if ( sctx - > pix_fmt == AV_PIX_FMT_DXVA2_VLD ) { AVDXVA2FramesContext * frames_hwctx = frames_ctx - > hwctx ; struct dxva_context * dxva_ctx = & sctx - > ctx . dxva2 ; ff_dxva2_lock ( avctx ) ; ret = dxva2_create_decoder ( avctx ) ; ff_dxva2_unlock ( avctx ) ; if ( ret < 0 ) goto fail ; dxva_ctx - > decoder = sctx - > dxva2_decoder ; dxva_ctx - > cfg = & sctx - > dxva2_config ; dxva_ctx - > surface = frames_hwctx - > surfaces ; dxva_ctx - > surface_count = frames_hwctx - > nb_surfaces ; dxva_ctx - > workaround = sctx - > workaround ; } endif return 0 ; fail : ff_dxva2_decode_uninit ( avctx ) ; return ret ; }",0
"static av_cold int twolame_encode_init ( AVCodecContext * avctx ) { TWOLAMEContext * s = avctx - > priv_data ; int ret ; avctx - > frame_size = TWOLAME_SAMPLES_PER_FRAME ; avctx - > delay = 512 - 32 + 1 ; s - > glopts = twolame_init ( ) ; if ( ! s - > glopts ) return AVERROR ( ENOMEM ) ; twolame_set_verbosity ( s - > glopts , s - > verbosity ) ; twolame_set_mode ( s - > glopts , s - > mode ) ; twolame_set_psymodel ( s - > glopts , s - > psymodel ) ; twolame_set_energy_levels ( s - > glopts , s - > energy ) ; twolame_set_error_protection ( s - > glopts , s - > error_protection ) ; twolame_set_copyright ( s - > glopts , s - > copyright ) ; twolame_set_original ( s - > glopts , s - > original ) ; twolame_set_num_channels ( s - > glopts , avctx - > channels ) ; twolame_set_in_samplerate ( s - > glopts , avctx - > sample_rate ) ; twolame_set_out_samplerate ( s - > glopts , avctx - > sample_rate ) ; if ( avctx - > flags & CODEC_FLAG_QSCALE || ! avctx - > bit_rate ) { twolame_set_VBR ( s - > glopts , TRUE ) ; twolame_set_VBR_level ( s - > glopts , avctx - > global_quality / ( float ) FF_QP2LAMBDA ) ; av_log ( avctx , AV_LOG_WARNING , VBR in MP2 is a hack , use another codec that supports it . \n ) ; } else { twolame_set_bitrate ( s - > glopts , avctx - > bit_rate / 1000 ) ; } ret = twolame_init_params ( s - > glopts ) ; if ( ret ) { twolame_encode_close ( avctx ) ; return AVERROR_UNKNOWN ; } return 0 ; }",0
"static int decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { SheerVideoContext * s = avctx - > priv_data ; ThreadFrame frame = { . f = data } ; AVFrame * p = data ; GetBitContext gb ; unsigned format ; int ret ; if ( avpkt - > size < = 20 ) if ( AV_RL32 ( avpkt - > data ) ! = MKTAG ( ' S ' , ' h ' , ' i ' , ' r ' ) & & AV_RL32 ( avpkt - > data ) ! = MKTAG ( ' Z ' , ' w ' , ' a ' , ' k ' ) ) s - > alt = 0 ; format = AV_RL32 ( avpkt - > data + 16 ) ; av_log ( avctx , AV_LOG_DEBUG , format : %s\n , av_fourcc2str ( format ) ) ; switch ( format ) { case MKTAG ( ' ' , ' R ' , ' G ' , ' B ' ) : avctx - > pix_fmt = AV_PIX_FMT_RGB0 ; s - > decode_frame = decode_rgb ; if ( s - > format ! = format ) { ret = build_vlc ( & s - > vlc[0] , l_r_rgb , 256 ) ; ret |= build_vlc ( & s - > vlc[1] , l_g_rgb , 256 ) ; break ; case MKTAG ( ' ' , ' r ' , ' G ' , ' B ' ) : avctx - > pix_fmt = AV_PIX_FMT_RGB0 ; s - > decode_frame = decode_rgbi ; if ( s - > format ! = format ) { ret = build_vlc ( & s - > vlc[0] , l_r_rgbi , 256 ) ; ret |= build_vlc ( & s - > vlc[1] , l_g_rgbi , 256 ) ; break ; case MKTAG ( ' A ' , ' R ' , ' G ' , ' X ' ) : avctx - > pix_fmt = AV_PIX_FMT_GBRAP10 ; s - > decode_frame = decode_argx ; if ( s - > format ! = format ) { ret = build_vlc ( & s - > vlc[0] , l_r_rgbx , 1024 ) ; ret |= build_vlc ( & s - > vlc[1] , l_g_rgbx , 1024 ) ; break ; case MKTAG ( ' A ' , ' r ' , ' G ' , ' X ' ) : avctx - > pix_fmt = AV_PIX_FMT_GBRAP10 ; s - > decode_frame = decode_argxi ; if ( s - > format ! = format ) { ret = build_vlc ( & s - > vlc[0] , l_r_rgbxi , 1024 ) ; ret |= build_vlc ( & s - > vlc[1] , l_g_rgbxi , 1024 ) ; break ; case MKTAG ( ' R ' , ' G ' , ' B ' , ' X ' ) : avctx - > pix_fmt = AV_PIX_FMT_GBRP10 ; s - > decode_frame = decode_rgbx ; if ( s - > format ! = format ) { ret = build_vlc ( & s - > vlc[0] , l_r_rgbx , 1024 ) ; ret |= build_vlc ( & s - > vlc[1] , l_g_rgbx , 1024 ) ; break ; case MKTAG ( ' r ' , ' G ' , ' B ' , ' X ' ) : avctx - > pix_fmt = AV_PIX_FMT_GBRP10 ; s - > decode_frame = decode_rgbxi ; if ( s - > format ! = format ) { ret = build_vlc ( & s - > vlc[0] , l_r_rgbxi , 1024 ) ; ret |= build_vlc ( & s - > vlc[1] , l_g_rgbxi , 1024 ) ; break ; case MKTAG ( ' A ' , ' R ' , ' G ' , ' B ' ) : avctx - > pix_fmt = AV_PIX_FMT_ARGB ; s - > decode_frame = decode_argb ; if ( s - > format ! = format ) { ret = build_vlc ( & s - > vlc[0] , l_r_rgb , 256 ) ; ret |= build_vlc ( & s - > vlc[1] , l_g_rgb , 256 ) ; break ; case MKTAG ( ' A ' , ' r ' , ' G ' , ' B ' ) : avctx - > pix_fmt = AV_PIX_FMT_ARGB ; s - > decode_frame = decode_argbi ; if ( s - > format ! = format ) { ret = build_vlc ( & s - > vlc[0] , l_r_rgbi , 256 ) ; ret |= build_vlc ( & s - > vlc[1] , l_g_rgbi , 256 ) ; break ; case MKTAG ( ' A ' , ' Y ' , ' B ' , ' R ' ) : s - > alt = 1 ; case MKTAG ( ' A ' , ' Y ' , ' b ' , ' R ' ) : avctx - > pix_fmt = AV_PIX_FMT_YUVA444P ; s - > decode_frame = decode_aybr ; if ( s - > format ! = format ) { ret = build_vlc ( & s - > vlc[0] , l_y_ybr , 256 ) ; ret |= build_vlc ( & s - > vlc[1] , l_u_ybr , 256 ) ; break ; case MKTAG ( ' A ' , ' y ' , ' B ' , ' R ' ) : s - > alt = 1 ; case MKTAG ( ' A ' , ' y ' , ' b ' , ' R ' ) : avctx - > pix_fmt = AV_PIX_FMT_YUVA444P ; s - > decode_frame = decode_aybri ; if ( s - > format ! = format ) { ret = build_vlc ( & s - > vlc[0] , l_y_ybri , 256 ) ; ret |= build_vlc ( & s - > vlc[1] , l_u_ybri , 256 ) ; break ; case MKTAG ( ' ' , ' Y ' , ' B ' , ' R ' ) : s - > alt = 1 ; case MKTAG ( ' ' , ' Y ' , ' b ' , ' R ' ) : avctx - > pix_fmt = AV_PIX_FMT_YUV444P ; s - > decode_frame = decode_ybr ; if ( s - > format ! = format ) { ret = build_vlc ( & s - > vlc[0] , l_y_ybr , 256 ) ; ret |= build_vlc ( & s - > vlc[1] , l_u_ybr , 256 ) ; break ; case MKTAG ( ' ' , ' y ' , ' B ' , ' R ' ) : s - > alt = 1 ; case MKTAG ( ' ' , ' y ' , ' b ' , ' R ' ) : avctx - > pix_fmt = AV_PIX_FMT_YUV444P ; s - > decode_frame = decode_ybri ; if ( s - > format ! = format ) { ret = build_vlc ( & s - > vlc[0] , l_y_ybri , 256 ) ; ret |= build_vlc ( & s - > vlc[1] , l_u_ybri , 256 ) ; break ; case MKTAG ( ' Y ' , ' B '",1
"int ff_h264_decode_ref_pic_marking ( H264Context * h , GetBitContext * gb , int first_slice ) { MpegEncContext * const s = & h - > s ; int i , ret ; MMCO mmco_temp[MAX_MMCO_COUNT] , * mmco = first_slice ? h - > mmco : mmco_temp ; int mmco_index = 0 ; if ( h - > nal_unit_type == NAL_IDR_SLICE ) { // FIXME fields s - > broken_link = get_bits1 ( gb ) - 1 ; if ( get_bits1 ( gb ) ) { mmco[0] . opcode = MMCO_LONG ; mmco[0] . long_arg = 0 ; mmco_index = 1 ; } } else { if ( get_bits1 ( gb ) ) { // adaptive_ref_pic_marking_mode_flag for ( i = 0 ; i < MAX_MMCO_COUNT ; i + + ) { MMCOOpcode opcode = get_ue_golomb_31 ( gb ) ; mmco[i] . opcode = opcode ; if ( opcode == MMCO_SHORT2UNUSED || opcode == MMCO_SHORT2LONG ) { mmco[i] . short_pic_num = ( h - > curr_pic_num - get_ue_golomb ( gb ) - 1 ) & ( h - > max_pic_num - 1 ) ; if 0 if ( mmco[i] . short_pic_num > = h - > short_ref_count || h - > short_ref[ mmco[i] . short_pic_num ] == NULL ) { av_log ( s - > avctx , AV_LOG_ERROR , illegal short ref in memory management control operation %d\n , mmco ) ; return - 1 ; } endif } if ( opcode == MMCO_SHORT2LONG || opcode == MMCO_LONG2UNUSED || opcode == MMCO_LONG || opcode == MMCO_SET_MAX_LONG ) { unsigned int long_arg = get_ue_golomb_31 ( gb ) ; if ( long_arg > = 32 || ( long_arg > = 16 & & ! ( opcode == MMCO_SET_MAX_LONG & & long_arg == 16 ) & & ! ( opcode == MMCO_LONG2UNUSED & & FIELD_PICTURE ) ) ) { av_log ( h - > s . avctx , AV_LOG_ERROR , illegal long ref in memory management control operation %d\n , opcode ) ; return - 1 ; } mmco[i] . long_arg = long_arg ; } if ( opcode > ( unsigned ) MMCO_LONG ) { av_log ( h - > s . avctx , AV_LOG_ERROR , illegal memory management control operation %d\n , opcode ) ; return - 1 ; } if ( opcode == MMCO_END ) break ; } mmco_index = i ; } else { if ( first_slice ) { ret = ff_generate_sliding_window_mmcos ( h , first_slice ) ; if ( ret < 0 & & s - > avctx - > err_recognition & AV_EF_EXPLODE ) return ret ; } mmco_index = - 1 ; } } if ( first_slice & & mmco_index ! = - 1 ) { h - > mmco_index = mmco_index ; } else if ( ! first_slice & & mmco_index > = 0 & & ( mmco_index ! = h - > mmco_index || ( i = check_opcodes ( h - > mmco , mmco_temp , mmco_index ) ) ) ) { av_log ( h - > s . avctx , AV_LOG_ERROR , Inconsistent MMCO state between slices [%d , %d , %d]\n , mmco_index , h - > mmco_index , i ) ; return AVERROR_INVALIDDATA ; } return 0 ; }",1
"static int add_metadata_from_side_data ( AVCodecContext * avctx , AVFrame * frame ) { int size , ret = 0 ; const uint8_t * side_metadata ; const uint8_t * end ; side_metadata = av_packet_get_side_data ( avctx - > pkt , AV_PKT_DATA_STRINGS_METADATA , & size ) ; if ( ! side_metadata ) goto end ; end = side_metadata + size ; while ( side_metadata < end ) { const uint8_t * key = side_metadata ; const uint8_t * val = side_metadata + strlen ( key ) + 1 ; int ret = av_dict_set ( avpriv_frame_get_metadatap ( frame ) , key , val , 0 ) ; if ( ret < 0 ) break ; side_metadata = val + strlen ( val ) + 1 ; } end : return ret ; }",1
"static int decode_wdlt ( GetByteContext * gb , uint8_t * frame , int width , int height ) { const uint8_t * frame_end = frame + width * height ; uint8_t * line_ptr ; int count , i , v , lines , segments ; int y = 0 ; lines = bytestream2_get_le16 ( gb ) ; if ( lines > height ) return AVERROR_INVALIDDATA ; while ( lines - - ) { if ( bytestream2_get_bytes_left ( gb ) < 2 ) return AVERROR_INVALIDDATA ; segments = bytestream2_get_le16u ( gb ) ; while ( ( segments & 0xC000 ) == 0xC000 ) { unsigned skip_lines = - ( int16_t ) segments ; unsigned delta = - ( ( int16_t ) segments * width ) ; if ( frame_end - frame < = delta || y + lines + skip_lines > height ) return AVERROR_INVALIDDATA ; frame + = delta ; y + = skip_lines ; segments = bytestream2_get_le16 ( gb ) ; } if ( frame_end < = frame ) return AVERROR_INVALIDDATA ; if ( segments & 0x8000 ) { frame[width - 1] = segments & 0xFF ; segments = bytestream2_get_le16 ( gb ) ; } line_ptr = frame ; if ( frame_end - frame < width ) return AVERROR_INVALIDDATA ; frame + = width ; y + + ; while ( segments - - ) { if ( frame - line_ptr < = bytestream2_peek_byte ( gb ) ) return AVERROR_INVALIDDATA ; line_ptr + = bytestream2_get_byte ( gb ) ; count = ( int8_t ) bytestream2_get_byte ( gb ) ; if ( count > = 0 ) { if ( frame - line_ptr < count * 2 ) return AVERROR_INVALIDDATA ; if ( bytestream2_get_buffer ( gb , line_ptr , count * 2 ) ! = count * 2 ) return AVERROR_INVALIDDATA ; line_ptr + = count * 2 ; } else { count = - count ; if ( frame - line_ptr < count * 2 ) return AVERROR_INVALIDDATA ; v = bytestream2_get_le16 ( gb ) ; for ( i = 0 ; i < count ; i + + ) bytestream_put_le16 ( & line_ptr , v ) ; } } } return 0 ; }",1
"static int rprobe ( AVFormatContext * s , uint8_t * enc_header , const uint8_t * r_val ) { OMAContext * oc = s - > priv_data ; unsigned int pos ; struct AVDES av_des ; if ( ! enc_header || ! r_val ) return - 1 ; / * m_val * / av_des_init ( & av_des , r_val , 192 , 1 ) ; av_des_crypt ( & av_des , oc - > m_val , & enc_header[48] , 1 , NULL , 1 ) ; / * s_val * / av_des_init ( & av_des , oc - > m_val , 64 , 0 ) ; av_des_crypt ( & av_des , oc - > s_val , NULL , 1 , NULL , 0 ) ; / * sm_val * / pos = OMA_ENC_HEADER_SIZE + oc - > k_size + oc - > e_size ; av_des_init ( & av_des , oc - > s_val , 64 , 0 ) ; av_des_mac ( & av_des , oc - > sm_val , & enc_header[pos] , ( oc - > i_size > > 3 ) ) ; pos + = oc - > i_size ; return memcmp ( & enc_header[pos] , oc - > sm_val , 8 ) ? - 1 : 0 ; }",1
"static FFPsyWindowInfo psy_lame_window ( FFPsyContext * ctx , const int16_t * audio , const int16_t * la , int channel , int prev_type ) { AacPsyContext * pctx = ( AacPsyContext * ) ctx - > model_priv_data ; AacPsyChannel * pch = & pctx - > ch[channel] ; int grouping = 0 ; int uselongblock = 1 ; int attacks[AAC_NUM_BLOCKS_SHORT + 1] = { 0 } ; int i ; FFPsyWindowInfo wi ; memset ( & wi , 0 , sizeof ( wi ) ) ; if ( la ) { float hpfsmpl[AAC_BLOCK_SIZE_LONG] ; float const * pf = hpfsmpl ; float attack_intensity[ ( AAC_NUM_BLOCKS_SHORT + 1 ) * PSY_LAME_NUM_SUBBLOCKS] ; float energy_subshort[ ( AAC_NUM_BLOCKS_SHORT + 1 ) * PSY_LAME_NUM_SUBBLOCKS] ; float energy_short[AAC_NUM_BLOCKS_SHORT + 1] = { 0 } ; int chans = ctx - > avctx - > channels ; const int16_t * firbuf = la + ( AAC_BLOCK_SIZE_SHORT/4 - PSY_LAME_FIR_LEN ) * chans ; int j , att_sum = 0 ; / * LAME comment : apply high pass filter of fs/4 * / for ( i = 0 ; i < AAC_BLOCK_SIZE_LONG ; i + + ) { float sum1 , sum2 ; sum1 = firbuf[ ( i + ( ( PSY_LAME_FIR_LEN - 1 ) / 2 ) ) * chans] ; sum2 = 0 . 0 ; for ( j = 0 ; j < ( ( PSY_LAME_FIR_LEN - 1 ) / 2 ) - 1 ; j + = 2 ) { sum1 + = psy_fir_coeffs[j] * ( firbuf[ ( i + j ) * chans] + firbuf[ ( i + PSY_LAME_FIR_LEN - j ) * chans] ) ; sum2 + = psy_fir_coeffs[j + 1] * ( firbuf[ ( i + j + 1 ) * chans] + firbuf[ ( i + PSY_LAME_FIR_LEN - j - 1 ) * chans] ) ; } hpfsmpl[i] = sum1 + sum2 ; } / * Calculate the energies of each sub - shortblock * / for ( i = 0 ; i < PSY_LAME_NUM_SUBBLOCKS ; i + + ) { energy_subshort[i] = pch - > prev_energy_subshort[i + ( ( AAC_NUM_BLOCKS_SHORT - 1 ) * PSY_LAME_NUM_SUBBLOCKS ) ] ; assert ( pch - > prev_energy_subshort[i + ( ( AAC_NUM_BLOCKS_SHORT - 2 ) * PSY_LAME_NUM_SUBBLOCKS + 1 ) ] > 0 ) ; attack_intensity[i] = energy_subshort[i] / pch - > prev_energy_subshort[i + ( ( AAC_NUM_BLOCKS_SHORT - 2 ) * PSY_LAME_NUM_SUBBLOCKS + 1 ) ] ; energy_short[0] + = energy_subshort[i] ; } for ( i = 0 ; i < AAC_NUM_BLOCKS_SHORT * PSY_LAME_NUM_SUBBLOCKS ; i + + ) { float const * const pfe = pf + AAC_BLOCK_SIZE_LONG / ( AAC_NUM_BLOCKS_SHORT * PSY_LAME_NUM_SUBBLOCKS ) ; float p = 1 . 0f ; for ( ; pf < pfe ; pf + + ) if ( p < fabsf ( * pf ) ) p = fabsf ( * pf ) ; pch - > prev_energy_subshort[i] = energy_subshort[i + PSY_LAME_NUM_SUBBLOCKS] = p ; energy_short[1 + i / PSY_LAME_NUM_SUBBLOCKS] + = p ; / * FIXME : The indexes below are [i + 3 - 2] in the LAME source . * Obviously the 3 and 2 have some significance , or this would be just [i + 1] * ( which is what we use here ) . What the 3 stands for is ambigious , as it is both * number of short blocks , and the number of sub - short blocks . * It seems that LAME is comparing each sub - block to sub - block + 1 in the * previous block . * / if ( p > energy_subshort[i + 1] ) p = p / energy_subshort[i + 1] ; else if ( energy_subshort[i + 1] > p * 10 . 0f ) p = energy_subshort[i + 1] / ( p * 10 . 0f ) ; else p = 0 . 0 ; attack_intensity[i + PSY_LAME_NUM_SUBBLOCKS] = p ; } / * compare energy between sub - short blocks * / for ( i = 0 ; i < ( AAC_NUM_BLOCKS_SHORT + 1 ) * PSY_LAME_NUM_SUBBLOCKS ; i + + ) if ( ! attacks[i / PSY_LAME_NUM_SUBBLOCKS] ) if ( attack_intensity[i] > pch - > attack_threshold ) attacks[i / PSY_LAME_NUM_SUBBLOCKS] = ( i % PSY_LAME_NUM_SUBBLOCKS ) + 1 ; / * should have energy change between short blocks , in order to avoid periodic signals * / / * Good samples to show the effect are Trumpet test songs * / / * GB : tuned ( 1 ) to avoid too many short blocks for test sample TRUMPET * / / * RH : tuned ( 2 ) to let enough short blocks through for test sample FSOL and SNAPS * / for ( i = 1 ; i < AAC_NUM_BLOCKS_SHORT + 1 ; i + + ) { float const u = energy_short[i - 1] ; float const v = energy_short[i] ; float const m = FFMAX ( u , v ) ; if ( m < 40000 ) { / * ( 2 ) * / if ( u < 1 . 7f * v & & v < 1 . 7f * u ) { / * ( 1 ) * / if ( i == 1 & & attacks[0] < attacks[i] ) attacks[0] = 0 ; attacks[i] = 0 ; } } att_sum + = attacks[i] ; } if ( attacks[0] < = pch - > prev_attack ) attacks[0] = 0 ; att_sum + = attacks[0] ; / * 3 below indicates the previous attack happened in the last sub - block of the previous sequence * / if ( pch - > prev_attack == 3 || att_sum ) { uselongblock = 0 ; if ( attacks[1] & & attacks[0] ) attacks[1] = 0 ; if ( attacks[2] & & attacks[1] ) attacks[2] = 0 ; if ( attacks[3] & & attacks[2] ) attacks[3] = 0 ; if ( attacks[4] & & attacks[3] ) attacks[4] = 0 ; if ( attacks[5] & & attacks[4] ) attacks[5] = 0 ; if ( attacks[6] & & attacks[5] ) attacks[6] = 0 ; if ( attacks[7] & & attacks[6] ) attacks[7] = 0 ; if ( attacks[8] & & attacks[7] ) attacks[8] = 0 ; } } else { / * We have no lookahead info , so just use same type as the previous sequence . * / uselongblock = ! ( prev_type == EIGHT_SHORT_SEQUENCE ) ; } lame_apply_block_type ( pch , & wi , uselongblock ) ; wi . window_type[1] = prev_type ; if ( wi . window_type[0] ! = EIGHT_SHORT_SEQUENCE ) { wi . num_windows = 1 ; wi . grouping[0] = 1 ; if ( wi . window_type[0] == LONG_START_SEQUENCE ) wi . window_shape = 0 ; else wi . window_shape = 1 ; } else { int lastgrp = 0 ; wi . num_windows = 8 ; wi . window_shape = 0 ; for ( i = 0 ; i < 8 ; i + + ) { if ( ! ( ( pch - > next_grouping > > i ) & 1 ) ) lastgrp = i ; wi . grouping[lastgrp] + + ; } } /",0
"static void float_to_int16_stride_altivec ( int16_t * dst , const float * src , long len , int stride ) { int i , j ; vector signed short d , s ; for ( i = 0 ; i < len - 7 ; i + = 8 ) { d = float_to_int16_one_altivec ( src + i ) ; for ( j = 0 ; j < 8 ; j + + ) { s = vec_splat ( d , j ) ; vec_ste ( s , 0 , dst ) ; dst + = stride ; } } }",0
"static int check_opcodes ( MMCO * mmco1 , MMCO * mmco2 , int n_mmcos ) { int i ; for ( i = 0 ; i < n_mmcos ; i + + ) { if ( mmco1[i] . opcode ! = mmco2[i] . opcode ) return - 1 ; } return 0 ; }",0
"static void vp3_idct_dc_add_c ( uint8_t * dest / * align 8 * / , int line_size , const DCTELEM * block / * align 16 * / ) { int i , dc = ( block[0] + 15 ) > > 5 ; for ( i = 0 ; i < 8 ; i + + ) { dest[0] = av_clip_uint8 ( dest[0] + dc ) ; dest[1] = av_clip_uint8 ( dest[1] + dc ) ; dest[2] = av_clip_uint8 ( dest[2] + dc ) ; dest[3] = av_clip_uint8 ( dest[3] + dc ) ; dest[4] = av_clip_uint8 ( dest[4] + dc ) ; dest[5] = av_clip_uint8 ( dest[5] + dc ) ; dest[6] = av_clip_uint8 ( dest[6] + dc ) ; dest[7] = av_clip_uint8 ( dest[7] + dc ) ; dest + = line_size ; } }",0
static av_cold int libopenjpeg_encode_close ( AVCodecContext * avctx ) { LibOpenJPEGContext * ctx = avctx - > priv_data ; opj_cio_close ( ctx - > stream ) ; ctx - > stream = NULL ; opj_destroy_compress ( ctx - > compress ) ; ctx - > compress = NULL ; opj_image_destroy ( ctx - > image ) ; ctx - > image = NULL ; av_freep ( & avctx - > coded_frame ) ; return 0 ; },1
"FFAMediaFormat * ff_AMediaFormat_new ( void ) { JNIEnv * env = NULL ; FFAMediaFormat * format = NULL ; format = av_mallocz ( sizeof ( FFAMediaFormat ) ) ; if ( ! format ) { return NULL ; } format - > class = & amediaformat_class ; env = ff_jni_get_env ( format ) ; if ( ! env ) { av_freep ( & format ) ; return NULL ; } if ( ff_jni_init_jfields ( env , & format - > jfields , jni_amediaformat_mapping , 1 , format ) < 0 ) { goto fail ; } format - > object = ( * env ) - > NewObject ( env , format - > jfields . mediaformat_class , format - > jfields . init_id ) ; if ( ! format - > object ) { goto fail ; } format - > object = ( * env ) - > NewGlobalRef ( env , format - > object ) ; if ( ! format - > object ) { goto fail ; } return format ; fail : ff_jni_reset_jfields ( env , & format - > jfields , jni_amediaformat_mapping , 1 , format ) ; av_freep ( & format ) ; return NULL ; }",1
"static int deband_8_coupling_c ( AVFilterContext * ctx , void * arg , int jobnr , int nb_jobs ) { DebandContext * s = ctx - > priv ; ThreadData * td = arg ; AVFrame * in = td - > in ; AVFrame * out = td - > out ; const int start = ( s - > planeheight[0] * jobnr ) / nb_jobs ; const int end = ( s - > planeheight[0] * ( jobnr + 1 ) ) / nb_jobs ; int x , y , p ; for ( y = start ; y < end ; y + + ) { const int pos = y * s - > planewidth[0] ; for ( x = 0 ; x < s - > planewidth[p] ; x + + ) { const int x_pos = s - > x_pos[pos + x] ; const int y_pos = s - > y_pos[pos + x] ; int avg[4] , cmp[4] = { 0 } , src[4] ; for ( p = 0 ; p < s - > nb_components ; p + + ) { const uint8_t * src_ptr = ( const uint8_t * ) in - > data[p] ; const int src_linesize = in - > linesize[p] ; const int thr = s - > thr[p] ; const int w = s - > planewidth[p] - 1 ; const int h = s - > planeheight[p] - 1 ; const int ref0 = src_ptr[av_clip ( y + y_pos , 0 , h ) * src_linesize + av_clip ( x + x_pos , 0 , w ) ] ; const int ref1 = src_ptr[av_clip ( y + - y_pos , 0 , h ) * src_linesize + av_clip ( x + x_pos , 0 , w ) ] ; const int ref2 = src_ptr[av_clip ( y + - y_pos , 0 , h ) * src_linesize + av_clip ( x + - x_pos , 0 , w ) ] ; const int ref3 = src_ptr[av_clip ( y + y_pos , 0 , h ) * src_linesize + av_clip ( x + - x_pos , 0 , w ) ] ; const int src0 = src_ptr[y * src_linesize + x] ; src[p] = src0 ; avg[p] = get_avg ( ref0 , ref1 , ref2 , ref3 ) ; if ( s - > blur ) { cmp[p] = FFABS ( src0 - avg[p] ) < thr ; } else { cmp[p] = ( FFABS ( src0 - ref0 ) < thr ) & & ( FFABS ( src0 - ref1 ) < thr ) & & ( FFABS ( src0 - ref2 ) < thr ) & & ( FFABS ( src0 - ref3 ) < thr ) ; } } for ( p = 0 ; p < s - > nb_components ; p + + ) if ( ! cmp[p] ) break ; if ( p == s - > nb_components ) { for ( p = 0 ; p < s - > nb_components ; p + + ) { const int dst_linesize = out - > linesize[p] ; out - > data[p][y * dst_linesize + x] = avg[p] ; } } else { for ( p = 0 ; p < s - > nb_components ; p + + ) { const int dst_linesize = out - > linesize[p] ; out - > data[p][y * dst_linesize + x] = src[p] ; } } } } return 0 ; }",1
"int ff_MPV_frame_start ( MpegEncContext * s , AVCodecContext * avctx ) { int i , ret ; Picture * pic ; s - > mb_skipped = 0 ; if ( ! ff_thread_can_start_frame ( avctx ) ) { av_log ( avctx , AV_LOG_ERROR , Attempt to start a frame outside SETUP state\n ) ; return - 1 ; } / * mark & release old frames * / if ( s - > pict_type ! = AV_PICTURE_TYPE_B & & s - > last_picture_ptr & & s - > last_picture_ptr ! = s - > next_picture_ptr & & s - > last_picture_ptr - > f - > buf[0] ) { ff_mpeg_unref_picture ( s , s - > last_picture_ptr ) ; } / * release forgotten pictures * / / * if ( mpeg124/h263 ) * / for ( i = 0 ; i < MAX_PICTURE_COUNT ; i + + ) { if ( & s - > picture[i] ! = s - > last_picture_ptr & & & s - > picture[i] ! = s - > next_picture_ptr & & s - > picture[i] . reference & & ! s - > picture[i] . needs_realloc ) { if ( ! ( avctx - > active_thread_type & FF_THREAD_FRAME ) ) av_log ( avctx , AV_LOG_ERROR , releasing zombie picture\n ) ; ff_mpeg_unref_picture ( s , & s - > picture[i] ) ; } } ff_mpeg_unref_picture ( s , & s - > current_picture ) ; release_unused_pictures ( s ) ; if ( s - > current_picture_ptr & & s - > current_picture_ptr - > f - > buf[0] == NULL ) { // we already have a unused image // ( maybe it was set before reading the header ) pic = s - > current_picture_ptr ; } else { i = ff_find_unused_picture ( s , 0 ) ; if ( i < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , no frame buffer available\n ) ; return i ; } pic = & s - > picture[i] ; } pic - > reference = 0 ; if ( ! s - > droppable ) { if ( s - > pict_type ! = AV_PICTURE_TYPE_B ) pic - > reference = 3 ; } pic - > f - > coded_picture_number = s - > coded_picture_number + + ; if ( ff_alloc_picture ( s , pic , 0 ) < 0 ) return - 1 ; s - > current_picture_ptr = pic ; // FIXME use only the vars from current_pic s - > current_picture_ptr - > f - > top_field_first = s - > top_field_first ; if ( s - > codec_id == AV_CODEC_ID_MPEG1VIDEO || s - > codec_id == AV_CODEC_ID_MPEG2VIDEO ) { if ( s - > picture_structure ! = PICT_FRAME ) s - > current_picture_ptr - > f - > top_field_first = ( s - > picture_structure == PICT_TOP_FIELD ) == s - > first_field ; } s - > current_picture_ptr - > f - > interlaced_frame = ! s - > progressive_frame & & ! s - > progressive_sequence ; s - > current_picture_ptr - > field_picture = s - > picture_structure ! = PICT_FRAME ; s - > current_picture_ptr - > f - > pict_type = s - > pict_type ; // if ( s - > flags & & CODEC_FLAG_QSCALE ) // s - > current_picture_ptr - > quality = s - > new_picture_ptr - > quality ; s - > current_picture_ptr - > f - > key_frame = s - > pict_type == AV_PICTURE_TYPE_I ; if ( ( ret = ff_mpeg_ref_picture ( s , & s - > current_picture , s - > current_picture_ptr ) ) < 0 ) return ret ; if ( s - > pict_type ! = AV_PICTURE_TYPE_B ) { s - > last_picture_ptr = s - > next_picture_ptr ; if ( ! s - > droppable ) s - > next_picture_ptr = s - > current_picture_ptr ; } av_dlog ( s - > avctx , L%p N%p C%p L%p N%p C%p type : %d drop : %d\n , s - > last_picture_ptr , s - > next_picture_ptr , s - > current_picture_ptr , s - > last_picture_ptr ? s - > last_picture_ptr - > f - > data[0] : NULL , s - > next_picture_ptr ? s - > next_picture_ptr - > f - > data[0] : NULL , s - > current_picture_ptr ? s - > current_picture_ptr - > f - > data[0] : NULL , s - > pict_type , s - > droppable ) ; if ( ( s - > last_picture_ptr == NULL || s - > last_picture_ptr - > f - > buf[0] == NULL ) & & ( s - > pict_type ! = AV_PICTURE_TYPE_I || s - > picture_structure ! = PICT_FRAME ) ) { int h_chroma_shift , v_chroma_shift ; av_pix_fmt_get_chroma_sub_sample ( s - > avctx - > pix_fmt , & h_chroma_shift , & v_chroma_shift ) ; if ( s - > pict_type == AV_PICTURE_TYPE_B & & s - > next_picture_ptr & & s - > next_picture_ptr - > f - > buf[0] ) av_log ( avctx , AV_LOG_DEBUG , allocating dummy last picture for B frame\n ) ; else if ( s - > pict_type ! = AV_PICTURE_TYPE_I ) av_log ( avctx , AV_LOG_ERROR , warning : first frame is no keyframe\n ) ; else if ( s - > picture_structure ! = PICT_FRAME ) av_log ( avctx , AV_LOG_DEBUG , allocate dummy last picture for field based first keyframe\n ) ; / * Allocate a dummy frame * / i = ff_find_unused_picture ( s , 0 ) ; if ( i < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , no frame buffer available\n ) ; return i ; } s - > last_picture_ptr = & s - > picture[i] ; s - > last_picture_ptr - > reference = 3 ; s - > last_picture_ptr - > f - > key_frame = 0 ; s - > last_picture_ptr - > f - > pict_type = AV_PICTURE_TYPE_P ; if ( ff_alloc_picture ( s , s - > last_picture_ptr , 0 ) < 0 ) { s - > last_picture_ptr = NULL ; return - 1 ; } if ( ! avctx - > hwaccel ) { for ( i=0 ; i < avctx - > height ; i + + ) memset ( s - > last_picture_ptr - > f - > data[0] + s - > last_picture_ptr - > f - > linesize[0] * i , 0x80 , avctx - > width ) ; for ( i=0 ; i < FF_CEIL_RSHIFT ( avctx - > height , v_chroma_shift ) ; i + + ) { memset ( s - > last_picture_ptr - > f - > data[1] + s - > last_picture_ptr - > f - > linesize[1] * i , 0x80 , FF_CEIL_RSHIFT ( avctx - > width , h_chroma_shift ) ) ; memset ( s - > last_picture_ptr - > f - > data[2] + s - > last_picture_ptr - > f - > linesize[2] * i , 0x80 , FF_CEIL_RSHIFT ( avctx - > width , h_chroma_shift ) ) ; } if (",1
"static int decode_0 ( AVCodecContext * avctx , uint8_t code , uint8_t * pkt ) { PAFVideoDecContext * c = avctx - > priv_data ; uint32_t opcode_size , offset ; uint8_t * dst , * dend , mask = 0 , color = 0 , a , b , p ; const uint8_t * src , * send , * opcodes ; int i , j , x = 0 ; i = bytestream2_get_byte ( & c - > gb ) ; if ( i ) { if ( code & 0x10 ) { int align ; align = bytestream2_tell ( & c - > gb ) & 3 ; if ( align ) bytestream2_skip ( & c - > gb , 4 - align ) ; } do { a = bytestream2_get_byte ( & c - > gb ) ; b = bytestream2_get_byte ( & c - > gb ) ; p = ( a & 0xC0 ) > > 6 ; dst = c - > frame[p] + get_video_page_offset ( avctx , a , b ) ; dend = c - > frame[p] + c - > frame_size ; offset = ( b & 0x7F ) * 2 ; j = bytestream2_get_le16 ( & c - > gb ) + offset ; do { offset + + ; if ( dst + 3 * avctx - > width + 4 > dend ) return AVERROR_INVALIDDATA ; copy4h ( avctx , dst ) ; if ( ( offset & 0x3F ) == 0 ) dst + = avctx - > width * 3 ; dst + = 4 ; } while ( offset < j ) ; } while ( - - i ) ; } dst = c - > frame[c - > current_frame] ; do { a = bytestream2_get_byte ( & c - > gb ) ; b = bytestream2_get_byte ( & c - > gb ) ; p = ( a & 0xC0 ) > > 6 ; src = c - > frame[p] + get_video_page_offset ( avctx , a , b ) ; send = c - > frame[p] + c - > frame_size ; if ( src + 3 * avctx - > width + 4 > send ) return AVERROR_INVALIDDATA ; copy_block4 ( dst , src , avctx - > width , avctx - > width , 4 ) ; i + + ; if ( ( i & 0x3F ) == 0 ) dst + = avctx - > width * 3 ; dst + = 4 ; } while ( i < c - > video_size / 16 ) ; opcode_size = bytestream2_get_le16 ( & c - > gb ) ; bytestream2_skip ( & c - > gb , 2 ) ; if ( bytestream2_get_bytes_left ( & c - > gb ) < opcode_size ) return AVERROR_INVALIDDATA ; opcodes = pkt + bytestream2_tell ( & c - > gb ) ; bytestream2_skipu ( & c - > gb , opcode_size ) ; dst = c - > frame[c - > current_frame] ; for ( i = 0 ; i < avctx - > height ; i + = 4 , dst + = avctx - > width * 3 ) { for ( j = 0 ; j < avctx - > width ; j + = 4 , dst + = 4 ) { int opcode , k = 0 ; if ( x > opcode_size ) return AVERROR_INVALIDDATA ; if ( j & 4 ) { opcode = opcodes[x] & 15 ; x + + ; } else { opcode = opcodes[x] > > 4 ; } while ( block_sequences[opcode][k] ) { offset = avctx - > width * 2 ; code = block_sequences[opcode][k + + ] ; switch ( code ) { case 2 : offset = 0 ; case 3 : color = bytestream2_get_byte ( & c - > gb ) ; case 4 : mask = bytestream2_get_byte ( & c - > gb ) ; copy_color_mask ( avctx , mask , dst + offset , color ) ; break ; case 5 : offset = 0 ; case 6 : a = bytestream2_get_byte ( & c - > gb ) ; b = bytestream2_get_byte ( & c - > gb ) ; p = ( a & 0xC0 ) > > 6 ; src = c - > frame[p] + get_video_page_offset ( avctx , a , b ) ; send = c - > frame[p] + c - > frame_size ; case 7 : if ( src + offset + avctx - > width + 4 > send ) return AVERROR_INVALIDDATA ; mask = bytestream2_get_byte ( & c - > gb ) ; copy_src_mask ( avctx , mask , dst + offset , src + offset ) ; break ; } } } } return 0 ; }",1
"static int64_t ogg_read_timestamp ( AVFormatContext * s , int stream_index , int64_t * pos_arg , int64_t pos_limit ) { struct ogg * ogg = s - > priv_data ; struct ogg_stream * os = ogg - > streams + stream_index ; AVIOContext * bc = s - > pb ; int64_t pts = AV_NOPTS_VALUE ; int i ; avio_seek ( bc , * pos_arg , SEEK_SET ) ; ogg_reset ( ogg ) ; while ( avio_tell ( bc ) < pos_limit & & ! ogg_packet ( s , & i , NULL , NULL , pos_arg ) ) { if ( i == stream_index ) { pts = ogg_calc_pts ( s , i , NULL ) ; if ( os - > keyframe_seek & & ! ( os - > pflags & AV_PKT_FLAG_KEY ) ) pts = AV_NOPTS_VALUE ; } if ( pts ! = AV_NOPTS_VALUE ) break ; } ogg_reset ( ogg ) ; return pts ; }",1
"static int scaling_list_data ( GetBitContext * gb , AVCodecContext * avctx , ScalingList * sl , HEVCSPS * sps ) { uint8_t scaling_list_pred_mode_flag ; int32_t scaling_list_dc_coef[2][6] ; int size_id , matrix_id , pos ; int i ; for ( size_id = 0 ; size_id < 4 ; size_id + + ) for ( matrix_id = 0 ; matrix_id < 6 ; matrix_id + = ( ( size_id == 3 ) ? 3 : 1 ) ) { scaling_list_pred_mode_flag = get_bits1 ( gb ) ; if ( ! scaling_list_pred_mode_flag ) { unsigned int delta = get_ue_golomb_long ( gb ) ; / * Only need to handle non - zero delta . Zero means default , * which should already be in the arrays . * / if ( delta ) { // Copy from previous array . if ( matrix_id < delta ) { av_log ( avctx , AV_LOG_ERROR , Invalid delta in scaling list data : %d . \n , delta ) ; return AVERROR_INVALIDDATA ; } memcpy ( sl - > sl[size_id][matrix_id] , sl - > sl[size_id][matrix_id - delta] , size_id > 0 ? 64 : 16 ) ; if ( size_id > 1 ) sl - > sl_dc[size_id - 2][matrix_id] = sl - > sl_dc[size_id - 2][matrix_id - delta] ; } } else { int next_coef , coef_num ; int32_t scaling_list_delta_coef ; next_coef = 8 ; coef_num = FFMIN ( 64 , 1 < < ( 4 + ( size_id < < 1 ) ) ) ; if ( size_id > 1 ) { scaling_list_dc_coef[size_id - 2][matrix_id] = get_se_golomb ( gb ) + 8 ; next_coef = scaling_list_dc_coef[size_id - 2][matrix_id] ; sl - > sl_dc[size_id - 2][matrix_id] = next_coef ; } for ( i = 0 ; i < coef_num ; i + + ) { if ( size_id == 0 ) pos = 4 * ff_hevc_diag_scan4x4_y[i] + ff_hevc_diag_scan4x4_x[i] ; else pos = 8 * ff_hevc_diag_scan8x8_y[i] + ff_hevc_diag_scan8x8_x[i] ; scaling_list_delta_coef = get_se_golomb ( gb ) ; next_coef = ( next_coef + scaling_list_delta_coef + 256 ) % 256 ; sl - > sl[size_id][matrix_id][pos] = next_coef ; } } } if ( sps - > chroma_format_idc == 3 ) { for ( i = 0 ; i < 64 ; i + + ) { sl - > sl[3][1][i] = sl - > sl[2][1][i] ; sl - > sl[3][2][i] = sl - > sl[2][2][i] ; sl - > sl[3][4][i] = sl - > sl[2][4][i] ; sl - > sl[3][5][i] = sl - > sl[2][5][i] ; } sl - > sl_dc[1][1] = sl - > sl_dc[0][1] ; sl - > sl_dc[1][2] = sl - > sl_dc[0][2] ; sl - > sl_dc[1][4] = sl - > sl_dc[0][4] ; sl - > sl_dc[1][5] = sl - > sl_dc[0][5] ; } return 0 ; }",1
"static int recode_subtitle ( AVCodecContext * avctx , AVPacket * outpkt , const AVPacket * inpkt ) { if CONFIG_ICONV iconv_t cd = ( iconv_t ) - 1 ; int ret = 0 ; char * inb , * outb ; size_t inl , outl ; AVPacket tmp ; endif if ( avctx - > sub_charenc_mode ! = FF_SUB_CHARENC_MODE_PRE_DECODER ) return 0 ; if CONFIG_ICONV cd = iconv_open ( UTF - 8 , avctx - > sub_charenc ) ; av_assert0 ( cd ! = ( iconv_t ) - 1 ) ; inb = inpkt - > data ; inl = inpkt - > size ; if ( inl > = INT_MAX / UTF8_MAX_BYTES - FF_INPUT_BUFFER_PADDING_SIZE ) { av_log ( avctx , AV_LOG_ERROR , Subtitles packet is too big for recoding\n ) ; ret = AVERROR ( ENOMEM ) ; goto end ; } ret = av_new_packet ( & tmp , inl * UTF8_MAX_BYTES ) ; if ( ret < 0 ) goto end ; outpkt - > buf = tmp . buf ; outpkt - > data = tmp . data ; outpkt - > size = tmp . size ; outb = outpkt - > data ; outl = outpkt - > size ; if ( iconv ( cd , & inb , & inl , & outb , & outl ) == ( size_t ) - 1 || iconv ( cd , NULL , NULL , & outb , & outl ) == ( size_t ) - 1 || outl > = outpkt - > size || inl ! = 0 ) { av_log ( avctx , AV_LOG_ERROR , Unable to recode subtitle event \ %s\ from %s to UTF - 8\n , inpkt - > data , avctx - > sub_charenc ) ; av_free_packet ( & tmp ) ; ret = AVERROR ( errno ) ; goto end ; } outpkt - > size - = outl ; outpkt - > data[outpkt - > size - 1] = ' \0 ' ; end : if ( cd ! = ( iconv_t ) - 1 ) iconv_close ( cd ) ; return ret ; else av_assert0 ( ! requesting subtitles recoding without iconv ) ; endif }",1
"static int ffm_read_data ( AVFormatContext * s , uint8_t * buf , int size , int first ) { FFMContext * ffm = s - > priv_data ; ByteIOContext * pb = s - > pb ; int len , fill_size , size1 , frame_offset ; size1 = size ; while ( size > 0 ) { redo : len = ffm - > packet_end - ffm - > packet_ptr ; if ( len < 0 ) return - 1 ; if ( len > size ) len = size ; if ( len == 0 ) { if ( url_ftell ( pb ) == ffm - > file_size ) url_fseek ( pb , ffm - > packet_size , SEEK_SET ) ; retry_read : get_be16 ( pb ) ; / * PACKET_ID * / fill_size = get_be16 ( pb ) ; ffm - > pts = get_be64 ( pb ) ; ffm - > first_frame_in_packet = 1 ; frame_offset = get_be16 ( pb ) ; get_buffer ( pb , ffm - > packet , ffm - > packet_size - FFM_HEADER_SIZE ) ; ffm - > packet_end = ffm - > packet + ( ffm - > packet_size - FFM_HEADER_SIZE - fill_size ) ; if ( ffm - > packet_end < ffm - > packet ) return - 1 ; / * if first packet or resynchronization packet , we must handle it specifically * / if ( ffm - > first_packet || ( frame_offset & 0x8000 ) ) { if ( ! frame_offset ) { / * This packet has no frame headers in it * / if ( url_ftell ( pb ) > = ffm - > packet_size * 3 ) { url_fseek ( pb , - ffm - > packet_size * 2 , SEEK_CUR ) ; goto retry_read ; } / * This is bad , we cannot find a valid frame header * / return 0 ; } ffm - > first_packet = 0 ; if ( ( frame_offset & 0x7ffff ) < FFM_HEADER_SIZE ) return - 1 ; ffm - > packet_ptr = ffm - > packet + ( frame_offset & 0x7fff ) - FFM_HEADER_SIZE ; if ( ! first ) break ; } else { ffm - > packet_ptr = ffm - > packet ; } goto redo ; } memcpy ( buf , ffm - > packet_ptr , len ) ; buf + = len ; ffm - > packet_ptr + = len ; size - = len ; first = 0 ; } return size1 - size ; }",0
"static int mpegts_write_section1 ( MpegTSSection * s , int tid , int id , int version , int sec_num , int last_sec_num , uint8_t * buf , int len ) { uint8_t section[1024] , * q ; unsigned int tot_len ; / * reserved_future_use field must be set to 1 for SDT * / unsigned int flags = tid == SDT_TID ? 0xf000 : 0xb000 ; tot_len = 3 + 5 + len + 4 ; / * check if not too big * / if ( tot_len > 1024 ) return - 1 ; q = section ; * q + + = tid ; put16 ( & q , flags | ( len + 5 + 4 ) ) ; / * 5 byte header + 4 byte CRC * / put16 ( & q , id ) ; * q + + = 0xc1 | ( version < < 1 ) ; / * current_next_indicator = 1 * / * q + + = sec_num ; * q + + = last_sec_num ; memcpy ( q , buf , len ) ; mpegts_write_section ( s , section , tot_len ) ; return 0 ; }",0
"static int compare_doubles ( const double * a , const double * b , int len , double max_diff ) { int i ; for ( i = 0 ; i < len ; i + + ) { if ( fabs ( a[i] - b[i] ) > max_diff ) { av_log ( NULL , AV_LOG_ERROR , %d : % - . 12f - % - . 12f = % . 12g\n , i , a[i] , b[i] , a[i] - b[i] ) ; return - 1 ; } } return 0 ; }",0
"static int fourxm_read_header ( AVFormatContext * s , AVFormatParameters * ap ) { ByteIOContext * pb = s - > pb ; unsigned int fourcc_tag ; unsigned int size ; int header_size ; FourxmDemuxContext * fourxm = s - > priv_data ; unsigned char * header ; int i ; int current_track = - 1 ; AVStream * st ; fourxm - > track_count = 0 ; fourxm - > tracks = NULL ; fourxm - > selected_track = 0 ; fourxm - > fps = 1 . 0 ; / * skip the first 3 32 - bit numbers * / url_fseek ( pb , 12 , SEEK_CUR ) ; / * check for LIST - HEAD * / GET_LIST_HEADER ( ) ; header_size = size - 4 ; if ( fourcc_tag ! = HEAD_TAG || size < 4 ) return AVERROR_INVALIDDATA ; / * allocate space for the header and load the whole thing * / header = av_malloc ( header_size ) ; if ( ! header ) return AVERROR ( ENOMEM ) ; if ( get_buffer ( pb , header , header_size ) ! = header_size ) return AVERROR ( EIO ) ; / * take the lazy approach and search for any and all vtrk and strk chunks * / for ( i = 0 ; i < header_size - 8 ; i + + ) { fourcc_tag = AV_RL32 ( & header[i] ) ; size = AV_RL32 ( & header[i + 4] ) ; if ( fourcc_tag == std__TAG ) { fourxm - > fps = av_int2flt ( AV_RL32 ( & header[i + 12] ) ) ; } else if ( fourcc_tag == vtrk_TAG ) { / * check that there is enough data * / if ( size ! = vtrk_SIZE ) { av_free ( header ) ; return AVERROR_INVALIDDATA ; } fourxm - > width = AV_RL32 ( & header[i + 36] ) ; fourxm - > height = AV_RL32 ( & header[i + 40] ) ; / * allocate a new AVStream * / st = av_new_stream ( s , 0 ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; av_set_pts_info ( st , 60 , 1 , fourxm - > fps ) ; fourxm - > video_stream_index = st - > index ; st - > codec - > codec_type = CODEC_TYPE_VIDEO ; st - > codec - > codec_id = CODEC_ID_4XM ; st - > codec - > extradata_size = 4 ; st - > codec - > extradata = av_malloc ( 4 ) ; AV_WL32 ( st - > codec - > extradata , AV_RL32 ( & header[i + 16] ) ) ; st - > codec - > width = fourxm - > width ; st - > codec - > height = fourxm - > height ; i + = 8 + size ; } else if ( fourcc_tag == strk_TAG ) { / * check that there is enough data * / if ( size ! = strk_SIZE ) { av_free ( header ) ; return AVERROR_INVALIDDATA ; } current_track = AV_RL32 ( & header[i + 8] ) ; if ( current_track + 1 > fourxm - > track_count ) { fourxm - > track_count = current_track + 1 ; if ( ( unsigned ) fourxm - > track_count > = UINT_MAX / sizeof ( AudioTrack ) ) return - 1 ; fourxm - > tracks = av_realloc ( fourxm - > tracks , fourxm - > track_count * sizeof ( AudioTrack ) ) ; if ( ! fourxm - > tracks ) { av_free ( header ) ; return AVERROR ( ENOMEM ) ; } } fourxm - > tracks[current_track] . adpcm = AV_RL32 ( & header[i + 12] ) ; fourxm - > tracks[current_track] . channels = AV_RL32 ( & header[i + 36] ) ; fourxm - > tracks[current_track] . sample_rate = AV_RL32 ( & header[i + 40] ) ; fourxm - > tracks[current_track] . bits = AV_RL32 ( & header[i + 44] ) ; i + = 8 + size ; / * allocate a new AVStream * / st = av_new_stream ( s , current_track ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; av_set_pts_info ( st , 60 , 1 , fourxm - > tracks[current_track] . sample_rate ) ; fourxm - > tracks[current_track] . stream_index = st - > index ; st - > codec - > codec_type = CODEC_TYPE_AUDIO ; st - > codec - > codec_tag = 0 ; st - > codec - > channels = fourxm - > tracks[current_track] . channels ; st - > codec - > sample_rate = fourxm - > tracks[current_track] . sample_rate ; st - > codec - > bits_per_coded_sample = fourxm - > tracks[current_track] . bits ; st - > codec - > bit_rate = st - > codec - > channels * st - > codec - > sample_rate * st - > codec - > bits_per_coded_sample ; st - > codec - > block_align = st - > codec - > channels * st - > codec - > bits_per_coded_sample ; if ( fourxm - > tracks[current_track] . adpcm ) st - > codec - > codec_id = CODEC_ID_ADPCM_4XM ; else if ( st - > codec - > bits_per_coded_sample == 8 ) st - > codec - > codec_id = CODEC_ID_PCM_U8 ; else st - > codec - > codec_id = CODEC_ID_PCM_S16LE ; } } av_free ( header ) ; / * skip over the LIST - MOVI chunk ( which is where the stream should be * / GET_LIST_HEADER ( ) ; if ( fourcc_tag ! = MOVI_TAG ) return AVERROR_INVALIDDATA ; / * initialize context members * / fourxm - > video_pts = - 1 ; / * first frame will push to 0 * / fourxm - > audio_pts = 0 ; return 0 ; }",0
"static int flush_packet ( AVFormatContext * ctx , int stream_index , int64_t pts , int64_t dts , int64_t scr , int trailer_size ) { MpegMuxContext * s = ctx - > priv_data ; StreamInfo * stream = ctx - > streams[stream_index] - > priv_data ; uint8_t * buf_ptr ; int size , payload_size , startcode , id , stuffing_size , i , header_len ; int packet_size ; uint8_t buffer[128] ; int zero_trail_bytes = 0 ; int pad_packet_bytes = 0 ; int pes_flags ; int general_pack = 0 ; / * general pack without data specific to one stream ? * / int nb_frames ; id = stream - > id ; if 0 printf ( packet ID=%2x PTS=%0 . 3f\n , id , pts / 90000 . 0 ) ; endif buf_ptr = buffer ; if ( ( s - > packet_number % s - > pack_header_freq ) == 0 || s - > last_scr ! = scr ) { / * output pack and systems header if needed * / size = put_pack_header ( ctx , buf_ptr , scr ) ; buf_ptr + = size ; s - > last_scr= scr ; if ( s - > is_vcd ) { / * there is exactly one system header for each stream in a VCD MPEG , One in the very first video packet and one in the very first audio packet ( see VCD standard p . IV - 7 and IV - 8 ) . * / if ( stream - > packet_number==0 ) { size = put_system_header ( ctx , buf_ptr , id ) ; buf_ptr + = size ; } } else if ( s - > is_dvd ) { if ( stream - > align_iframe || s - > packet_number == 0 ) { int PES_bytes_to_fill = s - > packet_size - size - 10 ; if ( pts ! = AV_NOPTS_VALUE ) { if ( dts ! = pts ) PES_bytes_to_fill - = 5 + 5 ; else PES_bytes_to_fill - = 5 ; } if ( stream - > bytes_to_iframe == 0 || s - > packet_number == 0 ) { size = put_system_header ( ctx , buf_ptr , 0 ) ; buf_ptr + = size ; size = buf_ptr - buffer ; put_buffer ( ctx - > pb , buffer , size ) ; put_be32 ( ctx - > pb , PRIVATE_STREAM_2 ) ; put_be16 ( ctx - > pb , 0x03d4 ) ; // length put_byte ( ctx - > pb , 0x00 ) ; // substream ID , 00=PCI for ( i = 0 ; i < 979 ; i + + ) put_byte ( ctx - > pb , 0x00 ) ; put_be32 ( ctx - > pb , PRIVATE_STREAM_2 ) ; put_be16 ( ctx - > pb , 0x03fa ) ; // length put_byte ( ctx - > pb , 0x01 ) ; // substream ID , 01=DSI for ( i = 0 ; i < 1017 ; i + + ) put_byte ( ctx - > pb , 0x00 ) ; memset ( buffer , 0 , 128 ) ; buf_ptr = buffer ; s - > packet_number + + ; stream - > align_iframe = 0 ; scr + = s - > packet_size * 90000LL / ( s - > mux_rate * 50LL ) ; //FIXME rounding and first few bytes of each packet size = put_pack_header ( ctx , buf_ptr , scr ) ; s - > last_scr= scr ; buf_ptr + = size ; / * GOP Start * / } else if ( stream - > bytes_to_iframe < PES_bytes_to_fill ) { pad_packet_bytes = PES_bytes_to_fill - stream - > bytes_to_iframe ; } } } else { if ( ( s - > packet_number % s - > system_header_freq ) == 0 ) { size = put_system_header ( ctx , buf_ptr , 0 ) ; buf_ptr + = size ; } } } size = buf_ptr - buffer ; put_buffer ( ctx - > pb , buffer , size ) ; packet_size = s - > packet_size - size ; if ( s - > is_vcd & & id == AUDIO_ID ) / * The VCD standard demands that 20 zero bytes follow each audio pack ( see standard p . IV - 8 ) . * / zero_trail_bytes + = 20 ; if ( ( s - > is_vcd & & stream - > packet_number==0 ) || ( s - > is_svcd & & s - > packet_number==0 ) ) { / * for VCD the first pack of each stream contains only the pack header , the system header and lots of padding ( see VCD standard p . IV - 6 ) . In the case of an audio pack , 20 zero bytes are also added at the end . * / / * For SVCD we fill the very first pack to increase compatibility with some DVD players . Not mandated by the standard . * / if ( s - > is_svcd ) general_pack = 1 ; / * the system header refers to both streams and no stream data * / pad_packet_bytes = packet_size - zero_trail_bytes ; } packet_size - = pad_packet_bytes + zero_trail_bytes ; if ( packet_size > 0 ) { / * packet header size * / packet_size - = 6 ; / * packet header * / if ( s - > is_mpeg2 ) { header_len = 3 ; if ( stream - > packet_number==0 ) header_len + = 3 ; / * PES extension * / header_len + = 1 ; / * obligatory stuffing byte * / } else { header_len = 0 ; } if ( pts ! = AV_NOPTS_VALUE ) { if ( dts ! = pts ) header_len + = 5 + 5 ; else header_len + = 5 ; } else { if ( ! s - > is_mpeg2 ) header_len + + ; } payload_size = packet_size - header_len ; if ( id < 0xc0 ) { startcode = PRIVATE_STREAM_1 ; payload_size - = 1 ; if ( id > = 0x40 ) { payload_size - = 3 ; if ( id > = 0xa0 ) payload_size - = 3 ; } } else { startcode = 0x100 + id ; } stuffing_size = payload_size - av_fifo_size ( stream - > fifo ) ; // first byte does not fit - > reset pts/dts + stuffing if ( payload_size < = trailer_size & & pts ! = AV_NOPTS_VALUE ) { int timestamp_len=0 ; if ( dts ! = pts ) timestamp_len + = 5 ; if ( pts ! = AV_NOPTS_VALUE ) timestamp_len + = s - > is_mpeg2 ? 5 : 4 ; pts=dts= AV_NOPTS_VALUE ; header_len - = timestamp_len ; if ( s - > is_dvd & & stream - > align_iframe ) { pad_packet_bytes + = timestamp_len ; packet_size - = timestamp_len ; } else { payload_size + = timestamp_len ; } stuffing_size + = timestamp_len ; if ( payload_size > trailer_size ) stuffing_size + = payload_size - trailer_size ; } if ( pad_packet_bytes > 0 & & pad_packet_bytes < = 7 ) { //",0
"static int _decode_exponents ( int expstr , int ngrps , uint8_t absexp , uint8_t * gexps , uint8_t * dexps ) { int exps ; int i = 0 ; while ( ngrps - - ) { exps = gexps[i + + ] ; absexp + = exp_1[exps] ; assert ( absexp < = 24 ) ; switch ( expstr ) { case AC3_EXPSTR_D45 : * ( dexps + + ) = absexp ; * ( dexps + + ) = absexp ; case AC3_EXPSTR_D25 : * ( dexps + + ) = absexp ; case AC3_EXPSTR_D15 : * ( dexps + + ) = absexp ; } absexp + = exp_2[exps] ; assert ( absexp < = 24 ) ; switch ( expstr ) { case AC3_EXPSTR_D45 : * ( dexps + + ) = absexp ; * ( dexps + + ) = absexp ; case AC3_EXPSTR_D25 : * ( dexps + + ) = absexp ; case AC3_EXPSTR_D15 : * ( dexps + + ) = absexp ; } absexp + = exp_3[exps] ; assert ( absexp < = 24 ) ; switch ( expstr ) { case AC3_EXPSTR_D45 : * ( dexps + + ) = absexp ; * ( dexps + + ) = absexp ; case AC3_EXPSTR_D25 : * ( dexps + + ) = absexp ; case AC3_EXPSTR_D15 : * ( dexps + + ) = absexp ; } } return 0 ; }",0
"static void draw_axis_yuv ( AVFrame * out , AVFrame * axis , const ColorFloat * c , int off ) { int fmt = out - > format , x , y , yh , w = axis - > width , h = axis - > height ; int offh = ( fmt == AV_PIX_FMT_YUV420P ) ? off / 2 : off ; float a , rcp_255 = 1 . 0f / 255 . 0f ; uint8_t * vy = out - > data[0] , * vu = out - > data[1] , * vv = out - > data[2] ; uint8_t * vay = axis - > data[0] , * vau = axis - > data[1] , * vav = axis - > data[2] , * vaa = axis - > data[3] ; int lsy = out - > linesize[0] , lsu = out - > linesize[1] , lsv = out - > linesize[2] ; int lsay = axis - > linesize[0] , lsau = axis - > linesize[1] , lsav = axis - > linesize[2] , lsaa = axis - > linesize[3] ; uint8_t * lpy , * lpu , * lpv , * lpay , * lpau , * lpav , * lpaa ; for ( y = 0 ; y < h ; y + = 2 ) { yh = ( fmt == AV_PIX_FMT_YUV420P ) ? y / 2 : y ; lpy = vy + ( off + y ) * lsy ; lpu = vu + ( offh + yh ) * lsu ; lpv = vv + ( offh + yh ) * lsv ; lpay = vay + y * lsay ; lpau = vau + yh * lsau ; lpav = vav + yh * lsav ; lpaa = vaa + y * lsaa ; for ( x = 0 ; x < w ; x + = 2 ) { a = rcp_255 * ( * lpaa + + ) ; * lpy + + = a * ( * lpay + + ) + ( 1 . 0f - a ) * c[x] . yuv . y + 0 . 5f ; * lpu + + = a * ( * lpau + + ) + ( 1 . 0f - a ) * c[x] . yuv . u + 0 . 5f ; * lpv + + = a * ( * lpav + + ) + ( 1 . 0f - a ) * c[x] . yuv . v + 0 . 5f ; / * u and v are skipped on yuv422p and yuv420p * / a = rcp_255 * ( * lpaa + + ) ; * lpy + + = a * ( * lpay + + ) + ( 1 . 0f - a ) * c[x + 1] . yuv . y + 0 . 5f ; if ( fmt == AV_PIX_FMT_YUV444P ) { * lpu + + = a * ( * lpau + + ) + ( 1 . 0f - a ) * c[x + 1] . yuv . u + 0 . 5f ; * lpv + + = a * ( * lpav + + ) + ( 1 . 0f - a ) * c[x + 1] . yuv . v + 0 . 5f ; } } lpy = vy + ( off + y + 1 ) * lsy ; lpu = vu + ( off + y + 1 ) * lsu ; lpv = vv + ( off + y + 1 ) * lsv ; lpay = vay + ( y + 1 ) * lsay ; lpau = vau + ( y + 1 ) * lsau ; lpav = vav + ( y + 1 ) * lsav ; lpaa = vaa + ( y + 1 ) * lsaa ; for ( x = 0 ; x < out - > width ; x + = 2 ) { / * u and v are skipped on yuv420p * / a = rcp_255 * ( * lpaa + + ) ; * lpy + + = a * ( * lpay + + ) + ( 1 . 0f - a ) * c[x] . yuv . y + 0 . 5f ; if ( fmt ! = AV_PIX_FMT_YUV420P ) { * lpu + + = a * ( * lpau + + ) + ( 1 . 0f - a ) * c[x] . yuv . u + 0 . 5f ; * lpv + + = a * ( * lpav + + ) + ( 1 . 0f - a ) * c[x] . yuv . v + 0 . 5f ; } / * u and v are skipped on yuv422p and yuv420p * / a = rcp_255 * ( * lpaa + + ) ; * lpy + + = a * ( * lpay + + ) + ( 1 . 0f - a ) * c[x + 1] . yuv . y + 0 . 5f ; if ( fmt == AV_PIX_FMT_YUV444P ) { * lpu + + = a * ( * lpau + + ) + ( 1 . 0f - a ) * c[x + 1] . yuv . u + 0 . 5f ; * lpv + + = a * ( * lpav + + ) + ( 1 . 0f - a ) * c[x + 1] . yuv . v + 0 . 5f ; } } } }",0
"static int shift_data ( AVFormatContext * s ) { int ret = 0 , moov_size ; MOVMuxContext * mov = s - > priv_data ; int64_t pos , pos_end = avio_tell ( s - > pb ) ; uint8_t * buf , * read_buf[2] ; int read_buf_id = 0 ; int read_size[2] ; AVIOContext * read_pb ; if ( mov - > flags & FF_MOV_FLAG_FRAGMENT ) moov_size = compute_sidx_size ( s ) ; else moov_size = compute_moov_size ( s ) ; if ( moov_size < 0 ) return moov_size ; buf = av_malloc ( moov_size * 2 ) ; if ( ! buf ) return AVERROR ( ENOMEM ) ; read_buf[0] = buf ; read_buf[1] = buf + moov_size ; / * Shift the data : the AVIO context of the output can only be used for * writing , so we re - open the same output , but for reading . It also avoids * a read/seek/write/seek back and forth . * / avio_flush ( s - > pb ) ; ret = avio_open ( & read_pb , s - > filename , AVIO_FLAG_READ ) ; if ( ret < 0 ) { av_log ( s , AV_LOG_ERROR , Unable to re - open %s output file for the second pass ( faststart ) \n , s - > filename ) ; goto end ; } / * mark the end of the shift to up to the last data we wrote , and get ready * for writing * / pos_end = avio_tell ( s - > pb ) ; avio_seek ( s - > pb , mov - > reserved_header_pos + moov_size , SEEK_SET ) ; / * start reading at where the new moov will be placed * / avio_seek ( read_pb , mov - > reserved_header_pos , SEEK_SET ) ; pos = avio_tell ( read_pb ) ; define READ_BLOCK do { \ read_size[read_buf_id] = avio_read ( read_pb , read_buf[read_buf_id] , moov_size ) ; \ read_buf_id = 1 ; \ } while ( 0 ) / * shift data by chunk of at most moov_size * / READ_BLOCK ; do { int n ; READ_BLOCK ; n = read_size[read_buf_id] ; if ( n < = 0 ) break ; avio_write ( s - > pb , read_buf[read_buf_id] , n ) ; pos + = n ; } while ( pos < pos_end ) ; avio_close ( read_pb ) ; end : av_free ( buf ) ; return ret ; }",0
"void ff_do_elbg ( int * points , int dim , int numpoints , int * codebook , int numCB , int max_steps , int * closest_cb , AVLFG * rand_state ) { int dist ; elbg_data elbg_d ; elbg_data * elbg = & elbg_d ; int i , j , k , last_error , steps=0 ; int * dist_cb = av_malloc ( numpoints * sizeof ( int ) ) ; int * size_part = av_malloc ( numCB * sizeof ( int ) ) ; cell * list_buffer = av_malloc ( numpoints * sizeof ( cell ) ) ; cell * free_cells ; int best_dist , best_idx = 0 ; elbg - > error = INT_MAX ; elbg - > dim = dim ; elbg - > numCB = numCB ; elbg - > codebook = codebook ; elbg - > cells = av_malloc ( numCB * sizeof ( cell * ) ) ; elbg - > utility = av_malloc ( numCB * sizeof ( int ) ) ; elbg - > nearest_cb = closest_cb ; elbg - > points = points ; elbg - > utility_inc = av_malloc ( numCB * sizeof ( int ) ) ; elbg - > scratchbuf = av_malloc ( 5 * dim * sizeof ( int ) ) ; elbg - > rand_state = rand_state ; do { free_cells = list_buffer ; last_error = elbg - > error ; steps + + ; memset ( elbg - > utility , 0 , numCB * sizeof ( int ) ) ; memset ( elbg - > cells , 0 , numCB * sizeof ( cell * ) ) ; elbg - > error = 0 ; / * This loop evaluate the actual Voronoi partition . It is the most costly part of the algorithm . * / for ( i=0 ; i < numpoints ; i + + ) { best_dist = distance_limited ( elbg - > points + i * elbg - > dim , elbg - > codebook + best_idx * elbg - > dim , dim , INT_MAX ) ; for ( k=0 ; k < elbg - > numCB ; k + + ) { dist = distance_limited ( elbg - > points + i * elbg - > dim , elbg - > codebook + k * elbg - > dim , dim , best_dist ) ; if ( dist < best_dist ) { best_dist = dist ; best_idx = k ; } } elbg - > nearest_cb[i] = best_idx ; dist_cb[i] = best_dist ; elbg - > error + = dist_cb[i] ; elbg - > utility[elbg - > nearest_cb[i]] + = dist_cb[i] ; free_cells - > index = i ; free_cells - > next = elbg - > cells[elbg - > nearest_cb[i]] ; elbg - > cells[elbg - > nearest_cb[i]] = free_cells ; free_cells + + ; } do_shiftings ( elbg ) ; memset ( size_part , 0 , numCB * sizeof ( int ) ) ; memset ( elbg - > codebook , 0 , elbg - > numCB * dim * sizeof ( int ) ) ; for ( i=0 ; i < numpoints ; i + + ) { size_part[elbg - > nearest_cb[i]] + + ; for ( j=0 ; j < elbg - > dim ; j + + ) elbg - > codebook[elbg - > nearest_cb[i] * elbg - > dim + j] + = elbg - > points[i * elbg - > dim + j] ; } for ( i=0 ; i < elbg - > numCB ; i + + ) vect_division ( elbg - > codebook + i * elbg - > dim , elbg - > codebook + i * elbg - > dim , size_part[i] , elbg - > dim ) ; } while ( ( ( last_error - elbg - > error ) > DELTA_ERR_MAX * elbg - > error ) & & ( steps < max_steps ) ) ; av_free ( dist_cb ) ; av_free ( size_part ) ; av_free ( elbg - > utility ) ; av_free ( list_buffer ) ; av_free ( elbg - > cells ) ; av_free ( elbg - > utility_inc ) ; av_free ( elbg - > scratchbuf ) ; }",0
"int ff_h263_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , uint8_t * buf , int buf_size ) { MpegEncContext * s = avctx - > priv_data ; int ret ; AVFrame * pict = data ; ifdef PRINT_FRAME_TIME uint64_t time= rdtsc ( ) ; endif ifdef DEBUG printf ( * * * * * frame %d size=%d\n , avctx - > frame_number , buf_size ) ; printf ( bytes=%x %x %x %x\n , buf[0] , buf[1] , buf[2] , buf[3] ) ; endif s - > flags= avctx - > flags ; s - > flags2= avctx - > flags2 ; / * no supplementary picture * / if ( buf_size == 0 ) { / * special case for last picture * / if ( s - > low_delay==0 & & s - > next_picture_ptr ) { * pict= * ( AVFrame * ) s - > next_picture_ptr ; s - > next_picture_ptr= NULL ; * data_size = sizeof ( AVFrame ) ; } return 0 ; } if ( s - > flags & CODEC_FLAG_TRUNCATED ) { int next ; if ( s - > codec_id==CODEC_ID_MPEG4 ) { next= ff_mpeg4_find_frame_end ( & s - > parse_context , buf , buf_size ) ; } else if ( s - > codec_id==CODEC_ID_H263 ) { next= h263_find_frame_end ( & s - > parse_context , buf , buf_size ) ; } else { av_log ( s - > avctx , AV_LOG_ERROR , this codec doesnt support truncated bitstreams\n ) ; return - 1 ; } if ( ff_combine_frame ( & s - > parse_context , next , & buf , & buf_size ) < 0 ) return buf_size ; } retry : if ( s - > bitstream_buffer_size & & ( s - > divx_packed || buf_size < 20 ) ) { //divx 5 . 01 + /xvid frame reorder init_get_bits ( & s - > gb , s - > bitstream_buffer , s - > bitstream_buffer_size * 8 ) ; } else init_get_bits ( & s - > gb , buf , buf_size * 8 ) ; s - > bitstream_buffer_size=0 ; if ( ! s - > context_initialized ) { if ( MPV_common_init ( s ) < 0 ) //we need the idct permutaton for reading a custom matrix return - 1 ; } //we need to set current_picture_ptr before reading the header , otherwise we cant store anyting im there if ( s - > current_picture_ptr==NULL || s - > current_picture_ptr - > data[0] ) { int i= ff_find_unused_picture ( s , 0 ) ; s - > current_picture_ptr= & s - > picture[i] ; } / * let ' s go : - ) * / if ( s - > msmpeg4_version==5 ) { ret= ff_wmv2_decode_picture_header ( s ) ; } else if ( s - > msmpeg4_version ) { ret = msmpeg4_decode_picture_header ( s ) ; } else if ( s - > h263_pred ) { if ( s - > avctx - > extradata_size & & s - > picture_number==0 ) { GetBitContext gb ; init_get_bits ( & gb , s - > avctx - > extradata , s - > avctx - > extradata_size * 8 ) ; ret = ff_mpeg4_decode_picture_header ( s , & gb ) ; } ret = ff_mpeg4_decode_picture_header ( s , & s - > gb ) ; if ( s - > flags & CODEC_FLAG_LOW_DELAY ) s - > low_delay=1 ; } else if ( s - > codec_id == CODEC_ID_H263I ) { ret = intel_h263_decode_picture_header ( s ) ; } else if ( s - > h263_flv ) { ret = flv_h263_decode_picture_header ( s ) ; } else { ret = h263_decode_picture_header ( s ) ; } if ( ret==FRAME_SKIPED ) return get_consumed_bytes ( s , buf_size ) ; / * skip if the header was thrashed * / if ( ret < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , header damaged\n ) ; return - 1 ; } avctx - > has_b_frames= ! s - > low_delay ; if ( s - > xvid_build==0 & & s - > divx_version==0 & & s - > lavc_build==0 ) { if ( s - > avctx - > stream_codec_tag == ff_get_fourcc ( XVID ) || s - > avctx - > codec_tag == ff_get_fourcc ( XVID ) || s - > avctx - > codec_tag == ff_get_fourcc ( XVIX ) ) s - > xvid_build= - 1 ; if 0 if ( s - > avctx - > codec_tag == ff_get_fourcc ( DIVX ) & & s - > vo_type==0 & & s - > vol_control_parameters==1 & & s - > padding_bug_score > 0 & & s - > low_delay ) // XVID with modified fourcc s - > xvid_build= - 1 ; endif } if ( s - > xvid_build==0 & & s - > divx_version==0 & & s - > lavc_build==0 ) { if ( s - > avctx - > codec_tag == ff_get_fourcc ( DIVX ) & & s - > vo_type==0 & & s - > vol_control_parameters==0 ) s - > divx_version= 400 ; //divx 4 } if ( s - > workaround_bugs & FF_BUG_AUTODETECT ) { s - > workaround_bugs & = FF_BUG_NO_PADDING ; if ( s - > padding_bug_score > - 2 & & ! s - > data_partitioning & & ( s - > divx_version || ! s - > resync_marker ) ) s - > workaround_bugs |= FF_BUG_NO_PADDING ; if ( s - > avctx - > codec_tag == ff_get_fourcc ( XVIX ) ) s - > workaround_bugs|= FF_BUG_XVID_ILACE ; if ( s - > avctx - > codec_tag == ff_get_fourcc ( UMP4 ) ) { s - > workaround_bugs|= FF_BUG_UMP4 ; } if ( s - > divx_version > =500 ) { s - > workaround_bugs|= FF_BUG_QPEL_CHROMA ; } if ( s - > divx_version > 502 ) { s - > workaround_bugs|= FF_BUG_QPEL_CHROMA2 ; } if ( s - > xvid_build & & s - > xvid_build < =3 ) s - > padding_bug_score= 256 * 256 * 256 * 64 ; if ( s - > xvid_build & & s - > xvid_build < =1 ) s - > workaround_bugs|= FF_BUG_QPEL_CHROMA ; if ( s - > xvid_build & & s - > xvid_build < =12 ) s - > workaround_bugs|= FF_BUG_EDGE ; if ( s - > xvid_build & & s - > xvid_build < =32 ) s - > workaround_bugs|= FF_BUG_DC_CLIP ; define SET_QPEL_FUNC ( postfix1 , postfix2 ) \ s - > dsp . put_ postfix1 = ff_put_ postfix2 ; \ s - > dsp . put_no_rnd_ postfix1 = ff_put_no_rnd_ postfix2 ; \ s - > dsp . avg_ postfix1 = ff_avg_ postfix2 ; if ( s - > lavc_build & & s - > lavc_build < 4653 ) s - > workaround_bugs|= FF_BUG_STD_QPEL ; if ( s - > lavc_build & & s - > lavc_build < 4655 ) s - > workaround_bugs|= FF_BUG_DIRECT_BLOCKSIZE ; if ( s - > lavc_build & & s - > lavc_build < 4670 ) { s - > workaround_bugs|= FF_BUG_EDGE ; } if ( s - > lavc_build &",0
"static void FUNCC ( pred8x8_vertical ) ( uint8_t * _src , int _stride ) { int i ; pixel * src = ( pixel * ) _src ; int stride = _stride/sizeof ( pixel ) ; const pixel4 a= ( ( pixel4 * ) ( src - stride ) ) [0] ; const pixel4 b= ( ( pixel4 * ) ( src - stride ) ) [1] ; for ( i=0 ; i < 8 ; i + + ) { ( ( pixel4 * ) ( src + i * stride ) ) [0]= a ; ( ( pixel4 * ) ( src + i * stride ) ) [1]= b ; } }",1
"static int videotoolbox_buffer_create ( AVCodecContext * avctx , AVFrame * frame ) { VTContext * vtctx = avctx - > internal - > hwaccel_priv_data ; CVPixelBufferRef pixbuf = ( CVPixelBufferRef ) vtctx - > frame ; OSType pixel_format = CVPixelBufferGetPixelFormatType ( pixbuf ) ; enum AVPixelFormat sw_format = av_map_videotoolbox_format_to_pixfmt ( pixel_format ) ; int width = CVPixelBufferGetWidth ( pixbuf ) ; int height = CVPixelBufferGetHeight ( pixbuf ) ; AVHWFramesContext * cached_frames ; int ret ; ret = ff_videotoolbox_buffer_create ( vtctx , frame ) ; if ( ret < 0 ) return ret ; // Old API code path . if ( ! vtctx - > cached_hw_frames_ctx ) return 0 ; cached_frames = ( AVHWFramesContext * ) vtctx - > cached_hw_frames_ctx - > data ; if ( cached_frames - > sw_format ! = sw_format || cached_frames - > width ! = width || cached_frames - > height ! = height ) { AVBufferRef * hw_frames_ctx = av_hwframe_ctx_alloc ( cached_frames - > device_ref ) ; AVHWFramesContext * hw_frames ; if ( ! hw_frames_ctx ) return AVERROR ( ENOMEM ) ; hw_frames = ( AVHWFramesContext * ) hw_frames_ctx - > data ; hw_frames - > format = cached_frames - > format ; hw_frames - > sw_format = sw_format ; hw_frames - > width = width ; hw_frames - > height = height ; ret = av_hwframe_ctx_init ( hw_frames_ctx ) ; if ( ret < 0 ) { av_buffer_unref ( & hw_frames_ctx ) ; return ret ; } av_buffer_unref ( & vtctx - > cached_hw_frames_ctx ) ; vtctx - > cached_hw_frames_ctx = hw_frames_ctx ; } av_assert0 ( ! frame - > hw_frames_ctx ) ; frame - > hw_frames_ctx = av_buffer_ref ( vtctx - > cached_hw_frames_ctx ) ; if ( ! frame - > hw_frames_ctx ) return AVERROR ( ENOMEM ) ; return 0 ; }",1
"static void inner_add_yblock_bw_16_obmc_32_sse2 ( const uint8_t * obmc , const long obmc_stride , uint8_t * * block , int b_w , long b_h , int src_x , int src_y , long src_stride , slice_buffer * sb , int add , uint8_t * dst8 ) { snow_inner_add_yblock_sse2_header snow_inner_add_yblock_sse2_start_16 ( xmm1 , xmm5 , 3 , 0 ) snow_inner_add_yblock_sse2_accum_16 ( 2 , 16 ) snow_inner_add_yblock_sse2_accum_16 ( 1 , 512 ) snow_inner_add_yblock_sse2_accum_16 ( 0 , 528 ) mov %0 , %% REG_d \n\t movdqa %%xmm1 , %%xmm0 \n\t movdqa %%xmm5 , %%xmm4 \n\t punpcklwd %%xmm7 , %%xmm0 \n\t paddd ( %% REG_D ) , %%xmm0 \n\t punpckhwd %%xmm7 , %%xmm1 \n\t paddd 16 ( %% REG_D ) , %%xmm1 \n\t punpcklwd %%xmm7 , %%xmm4 \n\t paddd 32 ( %% REG_D ) , %%xmm4 \n\t punpckhwd %%xmm7 , %%xmm5 \n\t paddd 48 ( %% REG_D ) , %%xmm5 \n\t paddd %%xmm3 , %%xmm0 \n\t paddd %%xmm3 , %%xmm1 \n\t paddd %%xmm3 , %%xmm4 \n\t paddd %%xmm3 , %%xmm5 \n\t psrad 8 , %%xmm0 \n\t / * FRAC_BITS . * / psrad 8 , %%xmm1 \n\t / * FRAC_BITS . * / psrad 8 , %%xmm4 \n\t / * FRAC_BITS . * / psrad 8 , %%xmm5 \n\t / * FRAC_BITS . * / packssdw %%xmm1 , %%xmm0 \n\t packssdw %%xmm5 , %%xmm4 \n\t packuswb %%xmm4 , %%xmm0 \n\t movdqu %%xmm0 , ( %% REG_d ) \n\t snow_inner_add_yblock_sse2_end_16 }",1
"void ff_put_h264_qpel4_mc03_msa ( uint8_t * dst , const uint8_t * src , ptrdiff_t stride ) { avc_luma_vt_qrt_4w_msa ( src - ( stride * 2 ) , stride , dst , stride , 4 , 1 ) ; }",0
"static int ff_asf_get_packet ( AVFormatContext * s , AVIOContext * pb ) { ASFContext * asf = s - > priv_data ; uint32_t packet_length , padsize ; int rsize = 8 ; int c , d , e , off ; // if we do not know packet size , allow skipping up to 32 kB off= 32768 ; if ( s - > packet_size > 0 ) off= ( avio_tell ( pb ) - s - > data_offset ) % s - > packet_size + 3 ; c=d=e= - 1 ; while ( off - - > 0 ) { c=d ; d=e ; e= avio_r8 ( pb ) ; if ( c == 0x82 & & ! d & & ! e ) break ; } if ( c ! = 0x82 ) { / * * * This code allows handling of - EAGAIN at packet boundaries ( i . e . * if the packet sync code above triggers - EAGAIN ) . This does not * imply complete - EAGAIN handling support at random positions in * the stream . * / if ( pb - > error == AVERROR ( EAGAIN ) ) return AVERROR ( EAGAIN ) ; if ( ! url_feof ( pb ) ) av_log ( s , AV_LOG_ERROR , ff asf bad header %x at : % PRId64 \n , c , avio_tell ( pb ) ) ; } if ( ( c & 0x8f ) == 0x82 ) { if ( d || e ) { if ( ! url_feof ( pb ) ) av_log ( s , AV_LOG_ERROR , ff asf bad non zero\n ) ; return - 1 ; } c= avio_r8 ( pb ) ; d= avio_r8 ( pb ) ; rsize + =3 ; } else { avio_seek ( pb , - 1 , SEEK_CUR ) ; //FIXME } asf - > packet_flags = c ; asf - > packet_property = d ; DO_2BITS ( asf - > packet_flags > > 5 , packet_length , s - > packet_size ) ; DO_2BITS ( asf - > packet_flags > > 1 , padsize , 0 ) ; // sequence ignored DO_2BITS ( asf - > packet_flags > > 3 , padsize , 0 ) ; // padding length //the following checks prevent overflows and infinite loops if ( ! packet_length || packet_length > = ( 1U < < 29 ) ) { av_log ( s , AV_LOG_ERROR , invalid packet_length %d at : % PRId64 \n , packet_length , avio_tell ( pb ) ) ; return - 1 ; } if ( padsize > = packet_length ) { av_log ( s , AV_LOG_ERROR , invalid padsize %d at : % PRId64 \n , padsize , avio_tell ( pb ) ) ; return - 1 ; } asf - > packet_timestamp = avio_rl32 ( pb ) ; avio_rl16 ( pb ) ; / * duration * / // rsize has at least 11 bytes which have to be present if ( asf - > packet_flags & 0x01 ) { asf - > packet_segsizetype = avio_r8 ( pb ) ; rsize + + ; asf - > packet_segments = asf - > packet_segsizetype & 0x3f ; } else { asf - > packet_segments = 1 ; asf - > packet_segsizetype = 0x80 ; } asf - > packet_size_left = packet_length - padsize - rsize ; if ( packet_length < asf - > hdr . min_pktsize ) padsize + = asf - > hdr . min_pktsize - packet_length ; asf - > packet_padsize = padsize ; av_dlog ( s , packet : size=%d padsize=%d left=%d\n , s - > packet_size , asf - > packet_padsize , asf - > packet_size_left ) ; return 0 ; }",0
"void checkasm_check_blockdsp ( void ) { LOCAL_ALIGNED_16 ( uint16_t , buf0 , [6 * 8 * 8] ) ; LOCAL_ALIGNED_16 ( uint16_t , buf1 , [6 * 8 * 8] ) ; AVCodecContext avctx = { 0 } ; BlockDSPContext h ; ff_blockdsp_init ( & h , & avctx ) ; check_clear ( clear_block , 8 * 8 ) ; check_clear ( clear_blocks , 8 * 8 * 6 ) ; report ( blockdsp ) ; }",0
"static int mkv_write_chapters ( AVFormatContext * s ) { MatroskaMuxContext * mkv = s - > priv_data ; AVIOContext * pb = s - > pb ; ebml_master chapters , editionentry ; AVRational scale = { 1 , 1E9 } ; int i , ret ; if ( ! s - > nb_chapters || mkv - > wrote_chapters ) return 0 ; ret = mkv_add_seekhead_entry ( mkv - > main_seekhead , MATROSKA_ID_CHAPTERS , avio_tell ( pb ) ) ; if ( ret < 0 ) return ret ; chapters = start_ebml_master ( pb , MATROSKA_ID_CHAPTERS , 0 ) ; editionentry = start_ebml_master ( pb , MATROSKA_ID_EDITIONENTRY , 0 ) ; put_ebml_uint ( pb , MATROSKA_ID_EDITIONFLAGDEFAULT , 1 ) ; put_ebml_uint ( pb , MATROSKA_ID_EDITIONFLAGHIDDEN , 0 ) ; for ( i = 0 ; i < s - > nb_chapters ; i + + ) { ebml_master chapteratom , chapterdisplay ; AVChapter * c = s - > chapters[i] ; int chapterstart = av_rescale_q ( c - > start , c - > time_base , scale ) ; int chapterend = av_rescale_q ( c - > end , c - > time_base , scale ) ; AVDictionaryEntry * t = NULL ; if ( chapterstart < 0 || chapterstart > chapterend ) return AVERROR_INVALIDDATA ; chapteratom = start_ebml_master ( pb , MATROSKA_ID_CHAPTERATOM , 0 ) ; put_ebml_uint ( pb , MATROSKA_ID_CHAPTERUID , c - > id + mkv - > chapter_id_offset ) ; put_ebml_uint ( pb , MATROSKA_ID_CHAPTERTIMESTART , chapterstart ) ; put_ebml_uint ( pb , MATROSKA_ID_CHAPTERTIMEEND , chapterend ) ; put_ebml_uint ( pb , MATROSKA_ID_CHAPTERFLAGHIDDEN , 0 ) ; put_ebml_uint ( pb , MATROSKA_ID_CHAPTERFLAGENABLED , 1 ) ; if ( ( t = av_dict_get ( c - > metadata , title , NULL , 0 ) ) ) { chapterdisplay = start_ebml_master ( pb , MATROSKA_ID_CHAPTERDISPLAY , 0 ) ; put_ebml_string ( pb , MATROSKA_ID_CHAPSTRING , t - > value ) ; put_ebml_string ( pb , MATROSKA_ID_CHAPLANG , und ) ; end_ebml_master ( pb , chapterdisplay ) ; } end_ebml_master ( pb , chapteratom ) ; } end_ebml_master ( pb , editionentry ) ; end_ebml_master ( pb , chapters ) ; mkv - > wrote_chapters = 1 ; return 0 ; }",1
"void ff_er_frame_end ( ERContext * s ) { int * linesize = s - > cur_pic - > f . linesize ; int i , mb_x , mb_y , error , error_type , dc_error , mv_error , ac_error ; int distance ; int threshold_part[4] = { 100 , 100 , 100 } ; int threshold = 50 ; int is_intra_likely ; int size = s - > b8_stride * 2 * s - > mb_height ; / * We do not support ER of field pictures yet , * though it should not crash if enabled . * / if ( ! s - > avctx - > error_concealment || s - > error_count == 0 || s - > avctx - > lowres || s - > avctx - > hwaccel || s - > avctx - > codec - > capabilities & CODEC_CAP_HWACCEL_VDPAU || ! s - > cur_pic || s - > cur_pic - > field_picture || s - > error_count == 3 * s - > mb_width * ( s - > avctx - > skip_top + s - > avctx - > skip_bottom ) ) { return ; } for ( mb_x = 0 ; mb_x < s - > mb_width ; mb_x + + ) { int status = s - > error_status_table[mb_x + ( s - > mb_height - 1 ) * s - > mb_stride] ; if ( status ! = 0x7F ) break ; } if ( mb_x == s - > mb_width & & s - > avctx - > codec_id == AV_CODEC_ID_MPEG2VIDEO & & ( s - > avctx - > height & 16 ) & & s - > error_count == 3 * s - > mb_width * ( s - > avctx - > skip_top + s - > avctx - > skip_bottom + 1 ) ) { av_log ( s - > avctx , AV_LOG_DEBUG , ignoring last missing slice\n ) ; return ; } if ( s - > last_pic ) { if ( s - > last_pic - > f . width ! = s - > cur_pic - > f . width || s - > last_pic - > f . height ! = s - > cur_pic - > f . height || s - > last_pic - > f . format ! = s - > cur_pic - > f . format ) { av_log ( s - > avctx , AV_LOG_WARNING , Cannot use previous picture in error concealment\n ) ; s - > last_pic = NULL ; } } if ( s - > next_pic ) { if ( s - > next_pic - > f . width ! = s - > cur_pic - > f . width || s - > next_pic - > f . height ! = s - > cur_pic - > f . height || s - > next_pic - > f . format ! = s - > cur_pic - > f . format ) { av_log ( s - > avctx , AV_LOG_WARNING , Cannot use next picture in error concealment\n ) ; s - > next_pic = NULL ; } } if ( s - > cur_pic - > motion_val[0] == NULL ) { av_log ( s - > avctx , AV_LOG_ERROR , Warning MVs not available\n ) ; for ( i = 0 ; i < 2 ; i + + ) { s - > cur_pic - > ref_index_buf[i] = av_buffer_allocz ( s - > mb_stride * s - > mb_height * 4 * sizeof ( uint8_t ) ) ; s - > cur_pic - > motion_val_buf[i] = av_buffer_allocz ( ( size + 4 ) * 2 * sizeof ( uint16_t ) ) ; if ( ! s - > cur_pic - > ref_index_buf[i] || ! s - > cur_pic - > motion_val_buf[i] ) break ; s - > cur_pic - > ref_index[i] = s - > cur_pic - > ref_index_buf[i] - > data ; s - > cur_pic - > motion_val[i] = ( int16_t ( * ) [2] ) s - > cur_pic - > motion_val_buf[i] - > data + 4 ; } if ( i < 2 ) { for ( i = 0 ; i < 2 ; i + + ) { av_buffer_unref ( & s - > cur_pic - > ref_index_buf[i] ) ; av_buffer_unref ( & s - > cur_pic - > motion_val_buf[i] ) ; s - > cur_pic - > ref_index[i] = NULL ; s - > cur_pic - > motion_val[i] = NULL ; } return ; } } if ( s - > avctx - > debug & FF_DEBUG_ER ) { for ( mb_y = 0 ; mb_y < s - > mb_height ; mb_y + + ) { for ( mb_x = 0 ; mb_x < s - > mb_width ; mb_x + + ) { int status = s - > error_status_table[mb_x + mb_y * s - > mb_stride] ; av_log ( s - > avctx , AV_LOG_DEBUG , %2X , status ) ; } av_log ( s - > avctx , AV_LOG_DEBUG , \n ) ; } } if 1 / * handle overlapping slices * / for ( error_type = 1 ; error_type < = 3 ; error_type + + ) { int end_ok = 0 ; for ( i = s - > mb_num - 1 ; i > = 0 ; i - - ) { const int mb_xy = s - > mb_index2xy[i] ; int error = s - > error_status_table[mb_xy] ; if ( error & ( 1 < < error_type ) ) end_ok = 1 ; if ( error & ( 8 < < error_type ) ) end_ok = 1 ; if ( ! end_ok ) s - > error_status_table[mb_xy] |= 1 < < error_type ; if ( error & VP_START ) end_ok = 0 ; } } endif if 1 / * handle slices with partitions of different length * / if ( s - > partitioned_frame ) { int end_ok = 0 ; for ( i = s - > mb_num - 1 ; i > = 0 ; i - - ) { const int mb_xy = s - > mb_index2xy[i] ; int error = s - > error_status_table[mb_xy] ; if ( error & ER_AC_END ) end_ok = 0 ; if ( ( error & ER_MV_END ) || ( error & ER_DC_END ) || ( error & ER_AC_ERROR ) ) end_ok = 1 ; if ( ! end_ok ) s - > error_status_table[mb_xy]|= ER_AC_ERROR ; if ( error & VP_START ) end_ok = 0 ; } } endif / * handle missing slices * / if ( s - > avctx - > err_recognition & AV_EF_EXPLODE ) { int end_ok = 1 ; // FIXME + 100 hack for ( i = s - > mb_num - 2 ; i > = s - > mb_width + 100 ; i - - ) { const int mb_xy = s - > mb_index2xy[i] ; int error1 = s - > error_status_table[mb_xy] ; int error2 = s - > error_status_table[s - > mb_index2xy[i + 1]] ; if ( error1 & VP_START )",0
"static void create_default_qtables ( uint8_t * qtables , uint8_t q ) { int factor = q ; int i ; factor = av_clip ( q , 1 , 99 ) ; if ( q < 50 ) q = 5000 / factor ; else q = 200 - factor * 2 ; for ( i = 0 ; i < 128 ; i + + ) { int val = ( default_quantizers[i] * q + 50 ) / 100 ; / * Limit the quantizers to 1 < = q < = 255 . * / val = av_clip ( val , 1 , 255 ) ; qtables[i] = val ; } }",1
"void ff_acelp_weighted_filter ( int16_t * out , const int16_t * in , const int16_t * weight_pow , int filter_length ) { int n ; for ( n=0 ; n < filter_length ; n + + ) out[n] = ( in[n] * weight_pow[n] + 0x4000 ) > > 15 ; / * ( 3 . 12 ) = ( 0 . 15 ) * ( 3 . 12 ) with rounding * / }",0
"void ff_vp3_idct_c ( DCTELEM * block / * align 16 * / ) { idct ( NULL , 0 , block , 0 ) ; }",0
"static int seq_fill_buffer ( SeqDemuxContext * seq , ByteIOContext * pb , int buffer_num , unsigned int data_offs , int data_size ) { TiertexSeqFrameBuffer * seq_buffer ; if ( buffer_num > = SEQ_NUM_FRAME_BUFFERS ) return AVERROR_INVALIDDATA ; seq_buffer = & seq - > frame_buffers[buffer_num] ; if ( seq_buffer - > fill_size + data_size > seq_buffer - > data_size ) return AVERROR_INVALIDDATA ; url_fseek ( pb , seq - > current_frame_offs + data_offs , SEEK_SET ) ; if ( get_buffer ( pb , seq_buffer - > data + seq_buffer - > fill_size , data_size ) ! = data_size ) return AVERROR ( EIO ) ; seq_buffer - > fill_size + = data_size ; return 0 ; }",0
"void ff_af_queue_close ( AudioFrameQueue * afq ) { / * remove/free any remaining frames * / while ( afq - > frame_queue ) delete_next_frame ( afq ) ; memset ( afq , 0 , sizeof ( * afq ) ) ; }",0
"static av_always_inline av_flatten void h264_loop_filter_luma_c ( uint8_t * pix , int xstride , int ystride , int alpha , int beta , int8_t * tc0 ) { int i , d ; for ( i = 0 ; i < 4 ; i + + ) { if ( tc0[i] < 0 ) { pix + = 4 * ystride ; continue ; } for ( d = 0 ; d < 4 ; d + + ) { const int p0 = pix[ - 1 * xstride] ; const int p1 = pix[ - 2 * xstride] ; const int p2 = pix[ - 3 * xstride] ; const int q0 = pix[0] ; const int q1 = pix[1 * xstride] ; const int q2 = pix[2 * xstride] ; if ( FFABS ( p0 - q0 ) < alpha & & FFABS ( p1 - p0 ) < beta & & FFABS ( q1 - q0 ) < beta ) { int tc = tc0[i] ; int i_delta ; if ( FFABS ( p2 - p0 ) < beta ) { if ( tc0[i] ) pix[ - 2 * xstride] = p1 + av_clip ( ( ( p2 + ( ( p0 + q0 + 1 ) > > 1 ) ) > > 1 ) - p1 , - tc0[i] , tc0[i] ) ; tc + + ; } if ( FFABS ( q2 - q0 ) < beta ) { if ( tc0[i] ) pix[ xstride] = q1 + av_clip ( ( ( q2 + ( ( p0 + q0 + 1 ) > > 1 ) ) > > 1 ) - q1 , - tc0[i] , tc0[i] ) ; tc + + ; } i_delta = av_clip ( ( ( ( q0 - p0 ) < < 2 ) + ( p1 - q1 ) + 4 ) > > 3 , - tc , tc ) ; pix[ - xstride] = av_clip_uint8 ( p0 + i_delta ) ; / * p0 ' * / pix[0] = av_clip_uint8 ( q0 - i_delta ) ; / * q0 ' * / } pix + = ystride ; } } }",0
"static int io_open_default ( AVFormatContext * s , AVIOContext * * pb , const char * url , int flags , AVDictionary * * options ) { return avio_open2 ( pb , url , flags , & s - > interrupt_callback , options ) ; }",1
"static int read_huffman_tables ( HYuvContext * s , const uint8_t * src , int length ) { GetBitContext gb ; int i ; init_get_bits ( & gb , src , length * 8 ) ; for ( i = 0 ; i < 3 ; i + + ) { if ( read_len_table ( s - > len[i] , & gb ) < 0 ) return - 1 ; if ( ff_huffyuv_generate_bits_table ( s - > bits[i] , s - > len[i] ) < 0 ) return - 1 ; ff_free_vlc ( & s - > vlc[i] ) ; init_vlc ( & s - > vlc[i] , VLC_BITS , 256 , s - > len[i] , 1 , 1 , s - > bits[i] , 4 , 4 , 0 ) ; } generate_joint_tables ( s ) ; return ( get_bits_count ( & gb ) + 7 ) / 8 ; }",1
"int ff_pnm_decode_header ( AVCodecContext * avctx , PNMContext * const s ) { char buf1[32] , tuple_type[32] ; int h , w , depth , maxval ; pnm_get ( s , buf1 , sizeof ( buf1 ) ) ; s - > type= buf1[1] - ' 0 ' ; if ( buf1[0] ! = ' P ' ) return - 1 ; if ( s - > type==1 || s - > type==4 ) { avctx - > pix_fmt = PIX_FMT_MONOWHITE ; } else if ( s - > type==2 || s - > type==5 ) { if ( avctx - > codec_id == CODEC_ID_PGMYUV ) avctx - > pix_fmt = PIX_FMT_YUV420P ; else avctx - > pix_fmt = PIX_FMT_GRAY8 ; } else if ( s - > type==3 || s - > type==6 ) { avctx - > pix_fmt = PIX_FMT_RGB24 ; } else if ( s - > type==7 ) { w = - 1 ; h = - 1 ; maxval = - 1 ; depth = - 1 ; tuple_type[0] = ' \0 ' ; for ( ; ; ) { pnm_get ( s , buf1 , sizeof ( buf1 ) ) ; if ( ! strcmp ( buf1 , WIDTH ) ) { pnm_get ( s , buf1 , sizeof ( buf1 ) ) ; w = strtol ( buf1 , NULL , 10 ) ; } else if ( ! strcmp ( buf1 , HEIGHT ) ) { pnm_get ( s , buf1 , sizeof ( buf1 ) ) ; h = strtol ( buf1 , NULL , 10 ) ; } else if ( ! strcmp ( buf1 , DEPTH ) ) { pnm_get ( s , buf1 , sizeof ( buf1 ) ) ; depth = strtol ( buf1 , NULL , 10 ) ; } else if ( ! strcmp ( buf1 , MAXVAL ) ) { pnm_get ( s , buf1 , sizeof ( buf1 ) ) ; maxval = strtol ( buf1 , NULL , 10 ) ; } else if ( ! strcmp ( buf1 , TUPLTYPE ) || // FFmpeg used to write invalid files ! strcmp ( buf1 , TUPLETYPE ) ) { pnm_get ( s , tuple_type , sizeof ( tuple_type ) ) ; } else if ( ! strcmp ( buf1 , ENDHDR ) ) { break ; } else { return - 1 ; } } / * check that all tags are present * / if ( w < = 0 || h < = 0 || maxval < = 0 || depth < = 0 || tuple_type[0] == ' \0 ' || av_image_check_size ( w , h , 0 , avctx ) ) return - 1 ; avctx - > width = w ; avctx - > height = h ; if ( depth == 1 ) { if ( maxval == 1 ) avctx - > pix_fmt = PIX_FMT_MONOWHITE ; else avctx - > pix_fmt = PIX_FMT_GRAY8 ; } else if ( depth == 3 ) { if ( maxval < 256 ) { avctx - > pix_fmt = PIX_FMT_RGB24 ; } else { av_log ( avctx , AV_LOG_ERROR , 16 - bit components are only supported for grayscale\n ) ; avctx - > pix_fmt = PIX_FMT_NONE ; return - 1 ; } } else if ( depth == 4 ) { avctx - > pix_fmt = PIX_FMT_RGB32 ; } else { return - 1 ; } return 0 ; } else { return - 1 ; } pnm_get ( s , buf1 , sizeof ( buf1 ) ) ; avctx - > width = atoi ( buf1 ) ; if ( avctx - > width < = 0 ) return - 1 ; pnm_get ( s , buf1 , sizeof ( buf1 ) ) ; avctx - > height = atoi ( buf1 ) ; if ( avctx - > height < = 0 || av_image_check_size ( avctx - > width , avctx - > height , 0 , avctx ) ) return - 1 ; if ( avctx - > pix_fmt ! = PIX_FMT_MONOWHITE ) { pnm_get ( s , buf1 , sizeof ( buf1 ) ) ; s - > maxval = atoi ( buf1 ) ; if ( s - > maxval < = 0 ) { av_log ( avctx , AV_LOG_ERROR , Invalid maxval : %d\n , s - > maxval ) ; s - > maxval = 255 ; } if ( s - > maxval > = 256 ) { if ( avctx - > pix_fmt == PIX_FMT_GRAY8 ) { avctx - > pix_fmt = PIX_FMT_GRAY16BE ; if ( s - > maxval ! = 65535 ) avctx - > pix_fmt = PIX_FMT_GRAY16 ; } else if ( avctx - > pix_fmt == PIX_FMT_RGB24 ) { if ( s - > maxval > 255 ) avctx - > pix_fmt = PIX_FMT_RGB48BE ; } else { av_log ( avctx , AV_LOG_ERROR , Unsupported pixel format\n ) ; avctx - > pix_fmt = PIX_FMT_NONE ; return - 1 ; } } } else s - > maxval=1 ; / * more check if YUV420 * / if ( avctx - > pix_fmt == PIX_FMT_YUV420P ) { if ( ( avctx - > width & 1 ) ! = 0 ) return - 1 ; h = ( avctx - > height * 2 ) ; if ( ( h % 3 ) ! = 0 ) return - 1 ; h /= 3 ; avctx - > height = h ; } return 0 ; }",1
"static void lumRangeToJpeg16_c ( int16_t * _dst , int width ) { int i ; int32_t * dst = ( int32_t * ) _dst ; for ( i = 0 ; i < width ; i + + ) dst[i] = ( FFMIN ( dst[i] , 30189 < < 4 ) * 19077 - ( 39057361 < < 4 ) ) > > 14 ; }",1
"static void fill_coding_method_array ( sb_int8_array tone_level_idx , sb_int8_array tone_level_idx_temp , sb_int8_array coding_method , int nb_channels , int c , int superblocktype_2_3 , int cm_table_select ) { int ch , sb , j ; int tmp , acc , esp_40 , comp ; int add1 , add2 , add3 , add4 ; int64_t multres ; if ( ! superblocktype_2_3 ) { / * This case is untested , no samples available * / SAMPLES_NEEDED for ( ch = 0 ; ch < nb_channels ; ch + + ) for ( sb = 0 ; sb < 30 ; sb + + ) { for ( j = 1 ; j < 63 ; j + + ) { // The loop only iterates to 63 so the code doesn ' t overflow the buffer add1 = tone_level_idx[ch][sb][j] - 10 ; if ( add1 < 0 ) add1 = 0 ; add2 = add3 = add4 = 0 ; if ( sb > 1 ) { add2 = tone_level_idx[ch][sb - 2][j] + tone_level_idx_offset_table[sb][0] - 6 ; if ( add2 < 0 ) add2 = 0 ; } if ( sb > 0 ) { add3 = tone_level_idx[ch][sb - 1][j] + tone_level_idx_offset_table[sb][1] - 6 ; if ( add3 < 0 ) add3 = 0 ; } if ( sb < 29 ) { add4 = tone_level_idx[ch][sb + 1][j] + tone_level_idx_offset_table[sb][3] - 6 ; if ( add4 < 0 ) add4 = 0 ; } tmp = tone_level_idx[ch][sb][j + 1] * 2 - add4 - add3 - add2 - add1 ; if ( tmp < 0 ) tmp = 0 ; tone_level_idx_temp[ch][sb][j + 1] = tmp & 0xff ; } tone_level_idx_temp[ch][sb][0] = tone_level_idx_temp[ch][sb][1] ; } acc = 0 ; for ( ch = 0 ; ch < nb_channels ; ch + + ) for ( sb = 0 ; sb < 30 ; sb + + ) for ( j = 0 ; j < 64 ; j + + ) acc + = tone_level_idx_temp[ch][sb][j] ; multres = 0x66666667 * ( acc * 10 ) ; esp_40 = ( multres > > 32 ) / 8 + ( ( multres & 0xffffffff ) > > 31 ) ; for ( ch = 0 ; ch < nb_channels ; ch + + ) for ( sb = 0 ; sb < 30 ; sb + + ) for ( j = 0 ; j < 64 ; j + + ) { comp = tone_level_idx_temp[ch][sb][j] * esp_40 * 10 ; if ( comp < 0 ) comp + = 0xff ; comp /= 256 ; // signed shift switch ( sb ) { case 0 : if ( comp < 30 ) comp = 30 ; comp + = 15 ; break ; case 1 : if ( comp < 24 ) comp = 24 ; comp + = 10 ; break ; case 2 : case 3 : case 4 : if ( comp < 16 ) comp = 16 ; } if ( comp < = 5 ) tmp = 0 ; else if ( comp < = 10 ) tmp = 10 ; else if ( comp < = 16 ) tmp = 16 ; else if ( comp < = 24 ) tmp = - 1 ; else tmp = 0 ; coding_method[ch][sb][j] = ( ( tmp & 0xfffa ) + 30 ) & 0xff ; } for ( sb = 0 ; sb < 30 ; sb + + ) fix_coding_method_array ( sb , nb_channels , coding_method ) ; for ( ch = 0 ; ch < nb_channels ; ch + + ) for ( sb = 0 ; sb < 30 ; sb + + ) for ( j = 0 ; j < 64 ; j + + ) if ( sb > = 10 ) { if ( coding_method[ch][sb][j] < 10 ) coding_method[ch][sb][j] = 10 ; } else { if ( sb > = 2 ) { if ( coding_method[ch][sb][j] < 16 ) coding_method[ch][sb][j] = 16 ; } else { if ( coding_method[ch][sb][j] < 30 ) coding_method[ch][sb][j] = 30 ; } } } else { // superblocktype_2_3 ! = 0 for ( ch = 0 ; ch < nb_channels ; ch + + ) for ( sb = 0 ; sb < 30 ; sb + + ) for ( j = 0 ; j < 64 ; j + + ) coding_method[ch][sb][j] = coding_method_table[cm_table_select][sb] ; } }",1
"static int tak_parse ( AVCodecParserContext * s , AVCodecContext * avctx , const uint8_t * * poutbuf , int * poutbuf_size , const uint8_t * buf , int buf_size ) { TAKParseContext * t = s - > priv_data ; ParseContext * pc = & t - > pc ; int next = END_NOT_FOUND ; GetBitContext gb ; int consumed = 0 ; int needed = buf_size ? TAK_MAX_FRAME_HEADER_BYTES : 8 ; if ( s - > flags & PARSER_FLAG_COMPLETE_FRAMES ) { TAKStreamInfo ti ; init_get_bits ( & gb , buf , buf_size ) ; if ( ! ff_tak_decode_frame_header ( avctx , & gb , & ti , 127 ) ) s - > duration = t - > ti . last_frame_samples ? t - > ti . last_frame_samples : t - > ti . frame_samples ; * poutbuf = buf ; * poutbuf_size = buf_size ; return buf_size ; } while ( buf_size || t - > index + needed < = pc - > index ) { if ( buf_size & & t - > index + TAK_MAX_FRAME_HEADER_BYTES > pc - > index ) { int tmp_buf_size = FFMIN ( 2 * TAK_MAX_FRAME_HEADER_BYTES , buf_size ) ; const uint8_t * tmp_buf = buf ; ff_combine_frame ( pc , END_NOT_FOUND , & tmp_buf , & tmp_buf_size ) ; consumed + = tmp_buf_size ; buf + = tmp_buf_size ; buf_size - = tmp_buf_size ; } for ( ; t - > index + needed < = pc - > index ; t - > index + + ) { if ( pc - > buffer[ t - > index ] == 0xFF & & pc - > buffer[ t - > index + 1 ] == 0xA0 ) { TAKStreamInfo ti ; init_get_bits ( & gb , pc - > buffer + t - > index , 8 * ( pc - > index - t - > index ) ) ; if ( ! ff_tak_decode_frame_header ( avctx , & gb , pc - > frame_start_found ? & ti : & t - > ti , 127 ) & & ! ff_tak_check_crc ( pc - > buffer + t - > index , get_bits_count ( & gb ) / 8 ) ) { if ( ! pc - > frame_start_found ) { pc - > frame_start_found = 1 ; s - > duration = t - > ti . last_frame_samples ? t - > ti . last_frame_samples : t - > ti . frame_samples ; } else { pc - > frame_start_found = 0 ; next = t - > index - pc - > index ; t - > index = 0 ; goto found ; } } } } } found : if ( consumed & & ! buf_size & & next == END_NOT_FOUND || ff_combine_frame ( pc , next , & buf , & buf_size ) < 0 ) { * poutbuf = NULL ; * poutbuf_size = 0 ; return buf_size + consumed ; } if ( next ! = END_NOT_FOUND ) { next + = consumed ; pc - > overread = FFMAX ( 0 , - next ) ; } * poutbuf = buf ; * poutbuf_size = buf_size ; return next ; }",0
"static void find_motion ( DeshakeContext * deshake , uint8_t * src1 , uint8_t * src2 , int width , int height , int stride , Transform * t ) { int x , y ; IntMotionVector mv = { 0 , 0 } ; int counts[128][128] ; int count_max_value = 0 ; int contrast ; int pos ; double * angles = av_malloc ( sizeof ( * angles ) * width * height / ( 16 * deshake - > blocksize ) ) ; int center_x = 0 , center_y = 0 ; double p_x , p_y ; // Reset counts to zero for ( x = 0 ; x < deshake - > rx * 2 + 1 ; x + + ) { for ( y = 0 ; y < deshake - > ry * 2 + 1 ; y + + ) { counts[x][y] = 0 ; } } pos = 0 ; // Find motion for every block and store the motion vector in the counts for ( y = deshake - > ry ; y < height - deshake - > ry - ( deshake - > blocksize * 2 ) ; y + = deshake - > blocksize * 2 ) { // We use a width of 16 here to match the libavcodec sad functions for ( x = deshake - > rx ; x < width - deshake - > rx - 16 ; x + = 16 ) { // If the contrast is too low , just skip this block as it probably // won ' t be very useful to us . contrast = block_contrast ( src2 , x , y , stride , deshake - > blocksize ) ; if ( contrast > deshake - > contrast ) { //av_log ( NULL , AV_LOG_ERROR , %d\n , contrast ) ; find_block_motion ( deshake , src1 , src2 , x , y , stride , & mv ) ; if ( mv . x ! = - 1 & & mv . y ! = - 1 ) { counts[mv . x + deshake - > rx][mv . y + deshake - > ry] + = 1 ; if ( x > deshake - > rx & & y > deshake - > ry ) angles[pos + + ] = block_angle ( x , y , 0 , 0 , & mv ) ; center_x + = mv . x ; center_y + = mv . y ; } } } } pos = FFMAX ( 1 , pos ) ; center_x /= pos ; center_y /= pos ; t - > angle = clean_mean ( angles , pos ) ; if ( t - > angle < 0 . 001 ) t - > angle = 0 ; // Find the most common motion vector in the frame and use it as the gmv for ( y = deshake - > ry * 2 ; y > = 0 ; y - - ) { for ( x = 0 ; x < deshake - > rx * 2 + 1 ; x + + ) { //av_log ( NULL , AV_LOG_ERROR , %5d , counts[x][y] ) ; if ( counts[x][y] > count_max_value ) { t - > vector . x = x - deshake - > rx ; t - > vector . y = y - deshake - > ry ; count_max_value = counts[x][y] ; } } //av_log ( NULL , AV_LOG_ERROR , \n ) ; } p_x = ( center_x - width / 2 ) ; p_y = ( center_y - height / 2 ) ; t - > vector . x + = ( cos ( t - > angle ) - 1 ) * p_x - sin ( t - > angle ) * p_y ; t - > vector . y + = sin ( t - > angle ) * p_x + ( cos ( t - > angle ) - 1 ) * p_y ; // Clamp max shift & rotation ? t - > vector . x = av_clipf ( t - > vector . x , - deshake - > rx * 2 , deshake - > rx * 2 ) ; t - > vector . y = av_clipf ( t - > vector . y , - deshake - > ry * 2 , deshake - > ry * 2 ) ; t - > angle = av_clipf ( t - > angle , - 0 . 1 , 0 . 1 ) ; //av_log ( NULL , AV_LOG_ERROR , %d x %d\n , avg - > x , avg - > y ) ; av_free ( angles ) ; }",1
"static int decode_ref_pic_list_reordering ( H264Context * h ) { MpegEncContext * const s = & h - > s ; int list , index , pic_structure ; print_short_term ( h ) ; print_long_term ( h ) ; if ( h - > slice_type==FF_I_TYPE || h - > slice_type==FF_SI_TYPE ) return 0 ; //FIXME move before func for ( list=0 ; list < h - > list_count ; list + + ) { memcpy ( h - > ref_list[list] , h - > default_ref_list[list] , sizeof ( Picture ) * h - > ref_count[list] ) ; if ( get_bits1 ( & s - > gb ) ) { int pred= h - > curr_pic_num ; for ( index=0 ; ; index + + ) { unsigned int reordering_of_pic_nums_idc= get_ue_golomb ( & s - > gb ) ; unsigned int pic_id ; int i ; Picture * ref = NULL ; if ( reordering_of_pic_nums_idc==3 ) break ; if ( index > = h - > ref_count[list] ) { av_log ( h - > s . avctx , AV_LOG_ERROR , reference count overflow\n ) ; return - 1 ; } if ( reordering_of_pic_nums_idc < 3 ) { if ( reordering_of_pic_nums_idc < 2 ) { const unsigned int abs_diff_pic_num= get_ue_golomb ( & s - > gb ) + 1 ; int frame_num ; if ( abs_diff_pic_num > h - > max_pic_num ) { av_log ( h - > s . avctx , AV_LOG_ERROR , abs_diff_pic_num overflow\n ) ; return - 1 ; } if ( reordering_of_pic_nums_idc == 0 ) pred - = abs_diff_pic_num ; else pred + = abs_diff_pic_num ; pred & = h - > max_pic_num - 1 ; frame_num = pic_num_extract ( h , pred , & pic_structure ) ; for ( i= h - > short_ref_count - 1 ; i > =0 ; i - - ) { ref = h - > short_ref[i] ; assert ( ref - > reference ) ; assert ( ! ref - > long_ref ) ; if ( ref - > data[0] ! = NULL & & ref - > frame_num == frame_num & & ( ref - > reference & pic_structure ) & & ref - > long_ref == 0 ) // ignore non existing pictures by testing data[0] pointer break ; } if ( i > =0 ) ref - > pic_id= pred ; } else { int long_idx ; pic_id= get_ue_golomb ( & s - > gb ) ; //long_term_pic_idx long_idx= pic_num_extract ( h , pic_id , & pic_structure ) ; if ( long_idx > 31 ) { av_log ( h - > s . avctx , AV_LOG_ERROR , long_term_pic_idx overflow\n ) ; return - 1 ; } ref = h - > long_ref[long_idx] ; assert ( ! ( ref & & ! ref - > reference ) ) ; if ( ref & & ( ref - > reference & pic_structure ) ) { ref - > pic_id= pic_id ; assert ( ref - > long_ref ) ; i=0 ; } else { i= - 1 ; } } if ( i < 0 ) { av_log ( h - > s . avctx , AV_LOG_ERROR , reference picture missing during reorder\n ) ; memset ( & h - > ref_list[list][index] , 0 , sizeof ( Picture ) ) ; //FIXME } else { for ( i=index ; i + 1 < h - > ref_count[list] ; i + + ) { if ( ref - > long_ref == h - > ref_list[list][i] . long_ref & & ref - > pic_id == h - > ref_list[list][i] . pic_id ) break ; } for ( ; i > index ; i - - ) { h - > ref_list[list][i]= h - > ref_list[list][i - 1] ; } h - > ref_list[list][index]= * ref ; if ( FIELD_PICTURE ) { pic_as_field ( & h - > ref_list[list][index] , pic_structure ) ; } } } else { av_log ( h - > s . avctx , AV_LOG_ERROR , illegal reordering_of_pic_nums_idc\n ) ; return - 1 ; } } } } for ( list=0 ; list < h - > list_count ; list + + ) { for ( index= 0 ; index < h - > ref_count[list] ; index + + ) { if ( ! h - > ref_list[list][index] . data[0] ) h - > ref_list[list][index]= s - > current_picture ; } } if ( h - > slice_type==FF_B_TYPE & & ! h - > direct_spatial_mv_pred ) direct_dist_scale_factor ( h ) ; direct_ref_list_init ( h ) ; return 0 ; }",0
static av_cold int X264_close ( AVCodecContext * avctx ) { X264Context * x4 = avctx - > priv_data ; av_freep ( & avctx - > extradata ) ; av_freep ( & x4 - > sei ) ; if ( x4 - > enc ) { x264_encoder_close ( x4 - > enc ) ; x4 - > enc = NULL ; } av_frame_free ( & avctx - > coded_frame ) ; return 0 ; },0
"static int dirac_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * pkt ) { DiracContext * s = avctx - > priv_data ; AVFrame * picture = data ; uint8_t * buf = pkt - > data ; int buf_size = pkt - > size ; int i , data_unit_size , buf_idx = 0 ; int ret ; / * release unused frames * / for ( i = 0 ; i < MAX_FRAMES ; i + + ) if ( s - > all_frames[i] . avframe - > data[0] & & ! s - > all_frames[i] . avframe - > reference ) { av_frame_unref ( s - > all_frames[i] . avframe ) ; memset ( s - > all_frames[i] . interpolated , 0 , sizeof ( s - > all_frames[i] . interpolated ) ) ; } s - > current_picture = NULL ; * got_frame = 0 ; / * end of stream , so flush delayed pics * / if ( buf_size == 0 ) return get_delayed_pic ( s , ( AVFrame * ) data , got_frame ) ; for ( ; ; ) { / * [DIRAC_STD] Here starts the code from parse_info ( ) defined in 9 . 6 [DIRAC_STD] PARSE_INFO_PREFIX = BBCD as defined in ISO/IEC 646 BBCD start code search * / for ( ; buf_idx + DATA_UNIT_HEADER_SIZE < buf_size ; buf_idx + + ) { if ( buf[buf_idx ] == ' B ' & & buf[buf_idx + 1] == ' B ' & & buf[buf_idx + 2] == ' C ' & & buf[buf_idx + 3] == ' D ' ) break ; } / * BBCD found or end of data * / if ( buf_idx + DATA_UNIT_HEADER_SIZE > = buf_size ) break ; data_unit_size = AV_RB32 ( buf + buf_idx + 5 ) ; if ( buf_idx + data_unit_size > buf_size || ! data_unit_size ) { if ( buf_idx + data_unit_size > buf_size ) av_log ( s - > avctx , AV_LOG_ERROR , Data unit with size %d is larger than input buffer , discarding\n , data_unit_size ) ; buf_idx + = 4 ; continue ; } / * [DIRAC_STD] dirac_decode_data_unit makes reference to the while defined in 9 . 3 inside the function parse_sequence ( ) * / if ( dirac_decode_data_unit ( avctx , buf + buf_idx , data_unit_size ) ) { av_log ( s - > avctx , AV_LOG_ERROR , Error in dirac_decode_data_unit\n ) ; return - 1 ; } buf_idx + = data_unit_size ; } if ( ! s - > current_picture ) return buf_size ; if ( s - > current_picture - > avframe - > display_picture_number > s - > frame_number ) { DiracFrame * delayed_frame = remove_frame ( s - > delay_frames , s - > frame_number ) ; s - > current_picture - > avframe - > reference |= DELAYED_PIC_REF ; if ( add_frame ( s - > delay_frames , MAX_DELAY , s - > current_picture ) ) { int min_num = s - > delay_frames[0] - > avframe - > display_picture_number ; / * Too many delayed frames , so we display the frame with the lowest pts * / av_log ( avctx , AV_LOG_ERROR , Delay frame overflow\n ) ; for ( i = 1 ; s - > delay_frames[i] ; i + + ) if ( s - > delay_frames[i] - > avframe - > display_picture_number < min_num ) min_num = s - > delay_frames[i] - > avframe - > display_picture_number ; delayed_frame = remove_frame ( s - > delay_frames , min_num ) ; add_frame ( s - > delay_frames , MAX_DELAY , s - > current_picture ) ; } if ( delayed_frame ) { delayed_frame - > avframe - > reference = DELAYED_PIC_REF ; if ( ( ret=av_frame_ref ( data , delayed_frame - > avframe ) ) < 0 ) return ret ; * got_frame = 1 ; } } else if ( s - > current_picture - > avframe - > display_picture_number == s - > frame_number ) { / * The right frame at the right time : - ) * / if ( ( ret=av_frame_ref ( data , s - > current_picture - > avframe ) ) < 0 ) return ret ; * got_frame = 1 ; } if ( * got_frame ) s - > frame_number = picture - > display_picture_number + 1 ; return buf_idx ; }",1
"static void unpack_vectors ( Vp3DecodeContext * s , GetBitContext * gb ) { int i , j , k ; int coding_mode ; int motion_x[6] ; int motion_y[6] ; int last_motion_x = 0 ; int last_motion_y = 0 ; int prior_last_motion_x = 0 ; int prior_last_motion_y = 0 ; int current_macroblock ; int current_fragment ; debug_vp3 ( vp3 : unpacking motion vectors\n ) ; if ( s - > keyframe ) { debug_vp3 ( keyframe - - there are no motion vectors\n ) ; } else { memset ( motion_x , 0 , 6 * sizeof ( int ) ) ; memset ( motion_y , 0 , 6 * sizeof ( int ) ) ; / * coding mode 0 is the VLC scheme ; 1 is the fixed code scheme * / coding_mode = get_bits ( gb , 1 ) ; debug_vectors ( using %s scheme for unpacking motion vectors\n , ( coding_mode == 0 ) ? VLC : fixed - length ) ; / * iterate through all of the macroblocks that contain 1 or more * coded fragments * / for ( i = 0 ; i < s - > u_superblock_start ; i + + ) { for ( j = 0 ; j < 4 ; j + + ) { current_macroblock = s - > superblock_macroblocks[i * 4 + j] ; if ( ( current_macroblock == - 1 ) || ( ! s - > macroblock_coded[current_macroblock] ) ) continue ; current_fragment = s - > macroblock_fragments[current_macroblock * 6] ; switch ( s - > all_fragments[current_fragment] . coding_method ) { case MODE_INTER_PLUS_MV : case MODE_GOLDEN_MV : / * all 6 fragments use the same motion vector * / if ( coding_mode == 0 ) { motion_x[0] = get_motion_vector_vlc ( gb ) ; motion_y[0] = get_motion_vector_vlc ( gb ) ; } else { motion_x[0] = get_motion_vector_fixed ( gb ) ; motion_y[0] = get_motion_vector_fixed ( gb ) ; } for ( k = 1 ; k < 6 ; k + + ) { motion_x[k] = motion_x[0] ; motion_y[k] = motion_y[0] ; } / * vector maintenance , only on MODE_INTER_PLUS_MV * / if ( s - > all_fragments[current_fragment] . coding_method == MODE_INTER_PLUS_MV ) { prior_last_motion_x = last_motion_x ; prior_last_motion_y = last_motion_y ; last_motion_x = motion_x[0] ; last_motion_y = motion_y[0] ; } break ; case MODE_INTER_FOURMV : / * fetch 4 vectors from the bitstream , one for each * Y fragment , then average for the C fragment vectors * / motion_x[4] = motion_y[4] = 0 ; for ( k = 0 ; k < 4 ; k + + ) { if ( coding_mode == 0 ) { motion_x[k] = get_motion_vector_vlc ( gb ) ; motion_y[k] = get_motion_vector_vlc ( gb ) ; } else { motion_x[k] = get_motion_vector_fixed ( gb ) ; motion_y[k] = get_motion_vector_fixed ( gb ) ; } motion_x[4] + = motion_x[k] ; motion_y[4] + = motion_y[k] ; } if ( motion_x[4] > = 0 ) motion_x[4] = ( motion_x[4] + 2 ) / 4 ; else motion_x[4] = ( motion_x[4] - 2 ) / 4 ; motion_x[5] = motion_x[4] ; if ( motion_y[4] > = 0 ) motion_y[4] = ( motion_y[4] + 2 ) / 4 ; else motion_y[4] = ( motion_y[4] - 2 ) / 4 ; motion_y[5] = motion_y[4] ; / * vector maintenance ; vector[3] is treated as the * last vector in this case * / prior_last_motion_x = last_motion_x ; prior_last_motion_y = last_motion_y ; last_motion_x = motion_x[3] ; last_motion_y = motion_y[3] ; break ; case MODE_INTER_LAST_MV : / * all 6 fragments use the last motion vector * / motion_x[0] = last_motion_x ; motion_y[0] = last_motion_y ; for ( k = 1 ; k < 6 ; k + + ) { motion_x[k] = motion_x[0] ; motion_y[k] = motion_y[0] ; } / * no vector maintenance ( last vector remains the * last vector ) * / break ; case MODE_INTER_PRIOR_LAST : / * all 6 fragments use the motion vector prior to the * last motion vector * / motion_x[0] = prior_last_motion_x ; motion_y[0] = prior_last_motion_y ; for ( k = 1 ; k < 6 ; k + + ) { motion_x[k] = motion_x[0] ; motion_y[k] = motion_y[0] ; } / * vector maintenance * / prior_last_motion_x = last_motion_x ; prior_last_motion_y = last_motion_y ; last_motion_x = motion_x[0] ; last_motion_y = motion_y[0] ; break ; } / * assign the motion vectors to the correct fragments * / debug_vectors ( vectors for macroblock starting fragment %d ( coding method %d ) : \n , current_fragment , s - > all_fragments[current_fragment] . coding_method ) ; for ( k = 0 ; k < 6 ; k + + ) { current_fragment = s - > macroblock_fragments[current_macroblock * 6 + k] ; s - > all_fragments[current_fragment] . motion_x = motion_x[k] ; s - > all_fragments[current_fragment] . motion_x = motion_y[k] ; debug_vectors ( vector %d : fragment %d = ( %d , %d ) \n , k , current_fragment , motion_x[k] , motion_y[k] ) ; } } } } }",1
"static int imc_decode_block ( AVCodecContext * avctx , IMCContext * q , int ch ) { int stream_format_code ; int imc_hdr , i , j , ret ; int flag ; int bits , summer ; int counter , bitscount ; IMCChannel * chctx = q - > chctx + ch ; / * Check the frame header * / imc_hdr = get_bits ( & q - > gb , 9 ) ; if ( imc_hdr & 0x18 ) { av_log ( avctx , AV_LOG_ERROR , frame header check failed ! \n ) ; av_log ( avctx , AV_LOG_ERROR , got %X . \n , imc_hdr ) ; stream_format_code = get_bits ( & q - > gb , 3 ) ; if ( stream_format_code & 1 ) { av_log_ask_for_sample ( avctx , Stream format %X is not supported\n , stream_format_code ) ; return AVERROR_PATCHWELCOME ; if ( stream_format_code & 0x04 ) chctx - > decoder_reset = 1 ; if ( chctx - > decoder_reset ) { for ( i = 0 ; i < BANDS ; i + + ) chctx - > old_floor[i] = 1 . 0 ; for ( i = 0 ; i < COEFFS ; i + + ) chctx - > CWdecoded[i] = 0 ; chctx - > decoder_reset = 0 ; flag = get_bits1 ( & q - > gb ) ; imc_read_level_coeffs ( q , stream_format_code , chctx - > levlCoeffBuf ) ; if ( stream_format_code & 0x4 ) imc_decode_level_coefficients ( q , chctx - > levlCoeffBuf , chctx - > flcoeffs1 , chctx - > flcoeffs2 ) ; else imc_decode_level_coefficients2 ( q , chctx - > levlCoeffBuf , chctx - > old_floor , chctx - > flcoeffs1 , chctx - > flcoeffs2 ) ; memcpy ( chctx - > old_floor , chctx - > flcoeffs1 , 32 * sizeof ( float ) ) ; counter = 0 ; for ( i = 0 ; i < BANDS ; i + + ) { if ( chctx - > levlCoeffBuf[i] == 16 ) { chctx - > bandWidthT[i] = 0 ; counter + + ; } else chctx - > bandWidthT[i] = band_tab[i + 1] - band_tab[i] ; memset ( chctx - > bandFlagsBuf , 0 , BANDS * sizeof ( int ) ) ; for ( i = 0 ; i < BANDS - 1 ; i + + ) { if ( chctx - > bandWidthT[i] ) chctx - > bandFlagsBuf[i] = get_bits1 ( & q - > gb ) ; imc_calculate_coeffs ( q , chctx - > flcoeffs1 , chctx - > flcoeffs2 , chctx - > bandWidthT , chctx - > flcoeffs3 , chctx - > flcoeffs5 ) ; bitscount = 0 ; / * first 4 bands will be assigned 5 bits per coefficient * / if ( stream_format_code & 0x2 ) { bitscount + = 15 ; chctx - > bitsBandT[0] = 5 ; chctx - > CWlengthT[0] = 5 ; chctx - > CWlengthT[1] = 5 ; chctx - > CWlengthT[2] = 5 ; for ( i = 1 ; i < 4 ; i + + ) { bits = ( chctx - > levlCoeffBuf[i] == 16 ) ? 0 : 5 ; chctx - > bitsBandT[i] = bits ; for ( j = band_tab[i] ; j < band_tab[i + 1] ; j + + ) { chctx - > CWlengthT[j] = bits ; bitscount + = bits ; if ( avctx - > codec_id == AV_CODEC_ID_IAC ) { bitscount + = ! ! chctx - > bandWidthT[BANDS - 1] ; if ( ! ( stream_format_code & 0x2 ) ) bitscount + = 16 ; if ( ( ret = bit_allocation ( q , chctx , stream_format_code , 512 - bitscount - get_bits_count ( & q - > gb ) , flag ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , Bit allocations failed\n ) ; chctx - > decoder_reset = 1 ; return ret ; for ( i = 0 ; i < BANDS ; i + + ) { chctx - > sumLenArr[i] = 0 ; chctx - > skipFlagRaw[i] = 0 ; for ( j = band_tab[i] ; j < band_tab[i + 1] ; j + + ) chctx - > sumLenArr[i] + = chctx - > CWlengthT[j] ; if ( chctx - > bandFlagsBuf[i] ) if ( ( ( ( band_tab[i + 1] - band_tab[i] ) * 1 . 5 ) > chctx - > sumLenArr[i] ) & & ( chctx - > sumLenArr[i] > 0 ) ) chctx - > skipFlagRaw[i] = 1 ; imc_get_skip_coeff ( q , chctx ) ; for ( i = 0 ; i < BANDS ; i + + ) { chctx - > flcoeffs6[i] = chctx - > flcoeffs1[i] ; / * band has flag set and at least one coded coefficient * / if ( chctx - > bandFlagsBuf[i] & & ( band_tab[i + 1] - band_tab[i] ) ! = chctx - > skipFlagCount[i] ) { chctx - > flcoeffs6[i] * = q - > sqrt_tab[ band_tab[i + 1] - band_tab[i]] / q - > sqrt_tab[ ( band_tab[i + 1] - band_tab[i] - chctx - > skipFlagCount[i] ) ] ; / * calculate bits left , bits needed and adjust bit allocation * / bits = summer = 0 ; for ( i = 0 ; i < BANDS ; i + + ) { if ( chctx - > bandFlagsBuf[i] ) { for ( j = band_tab[i] ; j < band_tab[i + 1] ; j + + ) { if ( chctx - > skipFlags[j] ) { summer + = chctx - > CWlengthT[j] ; chctx - > CWlengthT[j] = 0 ; bits + = chctx - > skipFlagBits[i] ; summer - = chctx - > skipFlagBits[i] ; imc_adjust_bit_allocation ( q , chctx , summer ) ; for ( i = 0 ; i < BANDS ; i + + ) { chctx - > sumLenArr[i] = 0 ; for ( j = band_tab[i] ; j < band_tab[i + 1] ; j + + ) if ( ! chctx - > skipFlags[j] ) chctx - > sumLenArr[i] + = chctx - > CWlengthT[j] ; memset ( chctx - > codewords , 0 , sizeof ( chctx - > codewords ) ) ; if ( imc_get_coeffs ( q , chctx ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , Read coefficients failed\n ) ; chctx - > decoder_reset = 1 ; if ( inverse_quant_coeff ( q , chctx , stream_format_code ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , Inverse quantization of coefficients failed\n ) ; chctx - > decoder_reset = 1 ; memset ( chctx - > skipFlags , 0 , sizeof ( chctx - > skipFlags ) ) ; imc_imdct256 ( q , chctx , avctx - > channels ) ; return 0 ;",1
static av_cold void nvenc_setup_rate_control ( AVCodecContext * avctx ) { NvencContext * ctx = avctx - > priv_data ; if ( avctx - > bit_rate > 0 ) { ctx - > encode_config . rcParams . averageBitRate = avctx - > bit_rate ; } else if ( ctx - > encode_config . rcParams . averageBitRate > 0 ) { ctx - > encode_config . rcParams . maxBitRate = ctx - > encode_config . rcParams . averageBitRate ; } if ( avctx - > rc_max_rate > 0 ) ctx - > encode_config . rcParams . maxBitRate = avctx - > rc_max_rate ; if ( ctx - > rc < 0 ) { if ( ctx - > flags & NVENC_ONE_PASS ) ctx - > twopass = 0 ; if ( ctx - > flags & NVENC_TWO_PASSES ) ctx - > twopass = 1 ; if ( ctx - > twopass < 0 ) ctx - > twopass = ( ctx - > flags & NVENC_LOWLATENCY ) ! = 0 ; if ( ctx - > cbr ) { if ( ctx - > twopass ) { ctx - > rc = NV_ENC_PARAMS_RC_2_PASS_QUALITY ; } else { ctx - > rc = NV_ENC_PARAMS_RC_CBR ; } } else if ( avctx - > global_quality > 0 ) { ctx - > rc = NV_ENC_PARAMS_RC_CONSTQP ; } else if ( ctx - > twopass ) { ctx - > rc = NV_ENC_PARAMS_RC_2_PASS_VBR ; } else if ( avctx - > qmin > = 0 & & avctx - > qmax > = 0 ) { ctx - > rc = NV_ENC_PARAMS_RC_VBR_MINQP ; } } if ( ctx - > flags & NVENC_LOSSLESS ) { set_lossless ( avctx ) ; } else if ( ctx - > rc > 0 ) { nvenc_override_rate_control ( avctx ) ; } else { ctx - > encode_config . rcParams . rateControlMode = NV_ENC_PARAMS_RC_VBR ; set_vbr ( avctx ) ; } if ( avctx - > rc_buffer_size > 0 ) { ctx - > encode_config . rcParams . vbvBufferSize = avctx - > rc_buffer_size ; } else if ( ctx - > encode_config . rcParams . averageBitRate > 0 ) { ctx - > encode_config . rcParams . vbvBufferSize = 2 * ctx - > encode_config . rcParams . averageBitRate ; } },1
"static int get_audio_frame_size ( AVCodecContext * enc , int size ) { int frame_size ; if ( enc - > codec_id == CODEC_ID_VORBIS ) return - 1 ; if ( enc - > frame_size < = 1 ) { int bits_per_sample = av_get_bits_per_sample ( enc - > codec_id ) ; if ( bits_per_sample ) { if ( enc - > channels == 0 ) return - 1 ; frame_size = ( size < < 3 ) / ( bits_per_sample * enc - > channels ) ; } else { / * used for example by ADPCM codecs * / if ( enc - > bit_rate == 0 ) return - 1 ; frame_size = ( size * 8 * enc - > sample_rate ) / enc - > bit_rate ; } } else { frame_size = enc - > frame_size ; } return frame_size ; }",1
"static void apply_dependent_coupling_fixed ( AACContext * ac , SingleChannelElement * target , ChannelElement * cce , int index ) { IndividualChannelStream * ics = & cce - > ch[0] . ics ; const uint16_t * offsets = ics - > swb_offset ; int * dest = target - > coeffs ; const int * src = cce - > ch[0] . coeffs ; int g , i , group , k , idx = 0 ; if ( ac - > oc[1] . m4ac . object_type == AOT_AAC_LTP ) { av_log ( ac - > avctx , AV_LOG_ERROR , Dependent coupling is not supported together with LTP\n ) ; return ; } for ( g = 0 ; g < ics - > num_window_groups ; g + + ) { for ( i = 0 ; i < ics - > max_sfb ; i + + , idx + + ) { if ( cce - > ch[0] . band_type[idx] ! = ZERO_BT ) { const int gain = cce - > coup . gain[index][idx] ; int shift , round , c , tmp ; if ( gain < 0 ) { c = - cce_scale_fixed[ - gain & 7] ; shift = ( - gain - 1024 ) > > 3 ; } else { c = cce_scale_fixed[gain & 7] ; shift = ( gain - 1024 ) > > 3 ; } if ( shift < - 31 ) { // Nothing to do } else if ( shift < 0 ) { shift = - shift ; round = 1 < < ( shift - 1 ) ; for ( group = 0 ; group < ics - > group_len[g] ; group + + ) { for ( k = offsets[i] ; k < offsets[i + 1] ; k + + ) { tmp = ( int ) ( ( ( int64_t ) src[group * 128 + k] * c + \ ( int64_t ) 0x1000000000 ) > > 37 ) ; dest[group * 128 + k] + = ( tmp + round ) > > shift ; } } } else { for ( group = 0 ; group < ics - > group_len[g] ; group + + ) { for ( k = offsets[i] ; k < offsets[i + 1] ; k + + ) { tmp = ( int ) ( ( ( int64_t ) src[group * 128 + k] * c + \ ( int64_t ) 0x1000000000 ) > > 37 ) ; dest[group * 128 + k] + = tmp < < shift ; } } } } } dest + = ics - > group_len[g] * 128 ; src + = ics - > group_len[g] * 128 ; } }",1
"static int copy_metadata ( char * outspec , char * inspec , AVFormatContext * oc , AVFormatContext * ic , OptionsContext * o ) { AVDictionary * * meta_in = NULL ; AVDictionary * * meta_out ; int i , ret = 0 ; char type_in , type_out ; const char * istream_spec = NULL , * ostream_spec = NULL ; int idx_in = 0 , idx_out = 0 ; parse_meta_type ( inspec , & type_in , & idx_in , & istream_spec ) ; parse_meta_type ( outspec , & type_out , & idx_out , & ostream_spec ) ; if ( type_in == ' g ' || type_out == ' g ' ) o - > metadata_global_manual = 1 ; if ( type_in == ' s ' || type_out == ' s ' ) o - > metadata_streams_manual = 1 ; if ( type_in == ' c ' || type_out == ' c ' ) o - > metadata_chapters_manual = 1 ; define METADATA_CHECK_INDEX ( index , nb_elems , desc ) \ if ( ( index ) < 0 || ( index ) > = ( nb_elems ) ) { \ av_log ( NULL , AV_LOG_FATAL , Invalid %s index %d while processing metadata maps . \n , \ ( desc ) , ( index ) ) ; \ exit_program ( 1 ) ; \ } define SET_DICT ( type , meta , context , index ) \ switch ( type ) { \ case ' g ' : \ meta = & context - > metadata ; \ break ; \ case ' c ' : \ METADATA_CHECK_INDEX ( index , context - > nb_chapters , chapter ) \ meta = & context - > chapters[index] - > metadata ; \ break ; \ case ' p ' : \ METADATA_CHECK_INDEX ( index , context - > nb_programs , program ) \ meta = & context - > programs[index] - > metadata ; \ break ; \ } \ SET_DICT ( type_in , meta_in , ic , idx_in ) ; SET_DICT ( type_out , meta_out , oc , idx_out ) ; / * for input streams choose first matching stream * / if ( type_in == ' s ' ) { for ( i = 0 ; i < ic - > nb_streams ; i + + ) { if ( ( ret = check_stream_specifier ( ic , ic - > streams[i] , istream_spec ) ) > 0 ) { meta_in = & ic - > streams[i] - > metadata ; break ; } else if ( ret < 0 ) exit_program ( 1 ) ; } if ( ! meta_in ) { av_log ( NULL , AV_LOG_FATAL , Stream specifier %s does not match any streams . \n , istream_spec ) ; exit_program ( 1 ) ; } } if ( type_out == ' s ' ) { for ( i = 0 ; i < oc - > nb_streams ; i + + ) { if ( ( ret = check_stream_specifier ( oc , oc - > streams[i] , ostream_spec ) ) > 0 ) { meta_out = & oc - > streams[i] - > metadata ; av_dict_copy ( meta_out , * meta_in , AV_DICT_DONT_OVERWRITE ) ; } else if ( ret < 0 ) exit_program ( 1 ) ; } } else av_dict_copy ( meta_out , * meta_in , AV_DICT_DONT_OVERWRITE ) ; return 0 ; }",1
"static av_cold int vp3_decode_end ( AVCodecContext * avctx ) { Vp3DecodeContext * s = avctx - > priv_data ; int i ; if ( avctx - > is_copy & & ! s - > current_frame . data[0] ) return 0 ; av_free ( s - > superblock_coding ) ; av_free ( s - > all_fragments ) ; av_free ( s - > coded_fragment_list[0] ) ; av_free ( s - > dct_tokens_base ) ; av_free ( s - > superblock_fragments ) ; av_free ( s - > macroblock_coding ) ; av_free ( s - > motion_val[0] ) ; av_free ( s - > motion_val[1] ) ; av_free ( s - > edge_emu_buffer ) ; if ( avctx - > is_copy ) return 0 ; for ( i = 0 ; i < 16 ; i + + ) { free_vlc ( & s - > dc_vlc[i] ) ; free_vlc ( & s - > ac_vlc_1[i] ) ; free_vlc ( & s - > ac_vlc_2[i] ) ; free_vlc ( & s - > ac_vlc_3[i] ) ; free_vlc ( & s - > ac_vlc_4[i] ) ; } free_vlc ( & s - > superblock_run_length_vlc ) ; free_vlc ( & s - > fragment_run_length_vlc ) ; free_vlc ( & s - > mode_code_vlc ) ; free_vlc ( & s - > motion_vector_vlc ) ; / * release all frames * / if ( s - > golden_frame . data[0] ) ff_thread_release_buffer ( avctx , & s - > golden_frame ) ; if ( s - > last_frame . data[0] & & s - > last_frame . type ! = FF_BUFFER_TYPE_COPY ) ff_thread_release_buffer ( avctx , & s - > last_frame ) ; / * no need to release the current_frame since it will always be pointing * to the same frame as either the golden or last frame * / return 0 ; }",1
"static av_always_inline void paint_raw ( uint8_t * dst , int w , int h , const uint8_t * src , int bpp , int be , int stride ) { int i , j , p ; for ( j = 0 ; j < h ; j + + ) { for ( i = 0 ; i < w ; i + + ) { p = vmnc_get_pixel ( src , bpp , be ) ; src + = bpp ; switch ( bpp ) { case 1 : dst[i] = p ; break ; case 2 : ( ( uint16_t * ) dst ) [i] = p ; break ; case 4 : ( ( uint32_t * ) dst ) [i] = p ; break ; } } dst + = stride ; } }",1
"static int gif_read_header ( AVFormatContext * s1 , AVFormatParameters * ap ) { GifState * s = s1 - > priv_data ; ByteIOContext * f = s1 - > pb ; AVStream * st ; s - > f = f ; if ( gif_read_header1 ( s ) < 0 ) return - 1 ; / * allocate image buffer * / s - > image_linesize = s - > screen_width * 3 ; s - > image_buf = av_malloc ( s - > screen_height * s - > image_linesize ) ; if ( ! s - > image_buf ) return AVERROR ( ENOMEM ) ; s - > pix_fmt = PIX_FMT_RGB24 ; / * now we are ready : build format streams * / st = av_new_stream ( s1 , 0 ) ; if ( ! st ) return - 1 ; st - > codec - > codec_type = CODEC_TYPE_VIDEO ; st - > codec - > codec_id = CODEC_ID_RAWVIDEO ; st - > codec - > time_base . den = 5 ; st - > codec - > time_base . num = 1 ; / * XXX : check if screen size is always valid * / st - > codec - > width = s - > screen_width ; st - > codec - > height = s - > screen_height ; st - > codec - > pix_fmt = PIX_FMT_RGB24 ; return 0 ; }",1
"static int decorrelate ( TAKDecContext * s , int c1 , int c2 , int length ) { GetBitContext * gb = & s - > gb ; int32_t * p1 = s - > decoded[c1] + 1 ; int32_t * p2 = s - > decoded[c2] + 1 ; int i ; int dshift , dfactor ; switch ( s - > dmode ) { case 1 : / * left/side * / for ( i = 0 ; i < length ; i + + ) { int32_t a = p1[i] ; int32_t b = p2[i] ; p2[i] = a + b ; } break ; case 2 : / * side/right * / for ( i = 0 ; i < length ; i + + ) { int32_t a = p1[i] ; int32_t b = p2[i] ; p1[i] = b - a ; } break ; case 3 : / * side/mid * / for ( i = 0 ; i < length ; i + + ) { int32_t a = p1[i] ; int32_t b = p2[i] ; a - = b > > 1 ; p1[i] = a ; p2[i] = a + b ; } break ; case 4 : / * side/left with scale factor * / FFSWAP ( int32_t * , p1 , p2 ) ; case 5 : / * side/right with scale factor * / dshift = get_bits_esc4 ( gb ) ; dfactor = get_sbits ( gb , 10 ) ; for ( i = 0 ; i < length ; i + + ) { int32_t a = p1[i] ; int32_t b = p2[i] ; b = dfactor * ( b > > dshift ) + 128 > > 8 < < dshift ; p1[i] = b - a ; } break ; case 6 : FFSWAP ( int32_t * , p1 , p2 ) ; case 7 : { int length2 , order_half , filter_order , dval1 , dval2 ; int tmp , x , code_size ; if ( length < 256 ) return AVERROR_INVALIDDATA ; dshift = get_bits_esc4 ( gb ) ; filter_order = 8 < < get_bits1 ( gb ) ; dval1 = get_bits1 ( gb ) ; dval2 = get_bits1 ( gb ) ; AV_ZERO128 ( s - > filter + 8 ) ; for ( i = 0 ; i < filter_order ; i + + ) { if ( ! ( i & 3 ) ) code_size = 14 - get_bits ( gb , 3 ) ; s - > filter[i] = get_sbits ( gb , code_size ) ; } order_half = filter_order / 2 ; length2 = length - ( filter_order - 1 ) ; / * decorrelate beginning samples * / if ( dval1 ) { for ( i = 0 ; i < order_half ; i + + ) { int32_t a = p1[i] ; int32_t b = p2[i] ; p1[i] = a + b ; } } / * decorrelate ending samples * / if ( dval2 ) { for ( i = length2 + order_half ; i < length ; i + + ) { int32_t a = p1[i] ; int32_t b = p2[i] ; p1[i] = a + b ; } } for ( i = 0 ; i < filter_order ; i + + ) s - > residues[i] = * p2 + + > > dshift ; p1 + = order_half ; x = FF_ARRAY_ELEMS ( s - > residues ) - filter_order ; for ( ; length2 > 0 ; length2 - = tmp ) { tmp = FFMIN ( length2 , x ) ; for ( i = 0 ; i < tmp ; i + + ) s - > residues[filter_order + i] = * p2 + + > > dshift ; for ( i = 0 ; i < tmp ; i + + ) { int v = 1 < < 9 ; v + = s - > adsp . scalarproduct_int16 ( & s - > residues[i] , s - > filter , 16 ) ; v = ( av_clip_intp2 ( v > > 10 , 13 ) < < dshift ) - * p1 ; * p1 + + = v ; } memcpy ( s - > residues , & s - > residues[tmp] , 2 * filter_order ) ; } emms_c ( ) ; break ; } } return 0 ; }",1
"static void show_format ( WriterContext * w , AVFormatContext * fmt_ctx ) { char val_str[128] ; int64_t size = fmt_ctx - > pb ? avio_size ( fmt_ctx - > pb ) : - 1 ; print_section_header ( format ) ; print_str ( filename , fmt_ctx - > filename ) ; print_int ( nb_streams , fmt_ctx - > nb_streams ) ; print_str ( format_name , fmt_ctx - > iformat - > name ) ; print_str ( format_long_name , fmt_ctx - > iformat - > long_name ) ; print_time ( start_time , fmt_ctx - > start_time , & AV_TIME_BASE_Q ) ; print_time ( duration , fmt_ctx - > duration , & AV_TIME_BASE_Q ) ; if ( size > = 0 ) print_val ( size , size , unit_byte_str ) ; else print_str_opt ( size , N/A ) ; if ( fmt_ctx - > bit_rate > 0 ) print_val ( bit_rate , fmt_ctx - > bit_rate , unit_bit_per_second_str ) ; else print_str_opt ( bit_rate , N/A ) ; show_tags ( fmt_ctx - > metadata ) ; print_section_footer ( format ) ; fflush ( stdout ) ; }",1
"static SchroFrame * libschroedinger_frame_from_data ( AVCodecContext * avctx , const AVFrame * frame ) { SchroEncoderParams * p_schro_params = avctx - > priv_data ; SchroFrame * in_frame = ff_create_schro_frame ( avctx , p_schro_params - > frame_format ) ; if ( in_frame ) { / * Copy input data to SchroFrame buffers ( they match the ones * referenced by the AVFrame stored in priv ) * / if ( av_frame_copy ( in_frame - > priv , frame ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , Failed to copy input data\n ) ; return NULL ; } } return in_frame ; }",1
"int ff_h264_update_thread_context ( AVCodecContext * dst , const AVCodecContext * src ) { H264Context * h = dst - > priv_data , * h1 = src - > priv_data ; int inited = h - > context_initialized , err = 0 ; int context_reinitialized = 0 ; int i , ret ; if ( dst == src ) return 0 ; if ( inited & & ( h - > width ! = h1 - > width || h - > height ! = h1 - > height || h - > mb_width ! = h1 - > mb_width || h - > mb_height ! = h1 - > mb_height || h - > sps . bit_depth_luma ! = h1 - > sps . bit_depth_luma || h - > sps . chroma_format_idc ! = h1 - > sps . chroma_format_idc || h - > sps . colorspace ! = h1 - > sps . colorspace ) ) { / * set bits_per_raw_sample to the previous value . the check for changed * bit depth in h264_set_parameter_from_sps ( ) uses it and sets it to * the current value * / h - > avctx - > bits_per_raw_sample = h - > sps . bit_depth_luma ; h - > width = h1 - > width ; h - > height = h1 - > height ; h - > mb_height = h1 - > mb_height ; h - > mb_width = h1 - > mb_width ; h - > mb_num = h1 - > mb_num ; h - > mb_stride = h1 - > mb_stride ; h - > b_stride = h1 - > b_stride ; // SPS/PPS if ( ( ret = copy_parameter_set ( ( void * * ) h - > sps_buffers , ( void * * ) h1 - > sps_buffers , MAX_SPS_COUNT , sizeof ( SPS ) ) ) < 0 ) return ret ; h - > sps = h1 - > sps ; if ( ( ret = copy_parameter_set ( ( void * * ) h - > pps_buffers , ( void * * ) h1 - > pps_buffers , MAX_PPS_COUNT , sizeof ( PPS ) ) ) < 0 ) return ret ; h - > pps = h1 - > pps ; if ( ( err = h264_slice_header_init ( h , 1 ) ) < 0 ) { av_log ( h - > avctx , AV_LOG_ERROR , h264_slice_header_init ( ) failed\n ) ; return err ; } context_reinitialized = 1 ; if 0 h264_set_parameter_from_sps ( h ) ; //Note we set context_reinitialized which will cause h264_set_parameter_from_sps to be reexecuted h - > cur_chroma_format_idc = h1 - > cur_chroma_format_idc ; endif } / * copy block_offset since frame_start may not be called * / memcpy ( h - > block_offset , h1 - > block_offset , sizeof ( h - > block_offset ) ) ; if ( ! inited ) { H264SliceContext * orig_slice_ctx = h - > slice_ctx ; for ( i = 0 ; i < MAX_SPS_COUNT ; i + + ) av_freep ( h - > sps_buffers + i ) ; for ( i = 0 ; i < MAX_PPS_COUNT ; i + + ) av_freep ( h - > pps_buffers + i ) ; ff_h264_unref_picture ( h , & h - > last_pic_for_ec ) ; memcpy ( h , h1 , sizeof ( H264Context ) ) ; memset ( h - > sps_buffers , 0 , sizeof ( h - > sps_buffers ) ) ; memset ( h - > pps_buffers , 0 , sizeof ( h - > pps_buffers ) ) ; memset ( & h - > cur_pic , 0 , sizeof ( h - > cur_pic ) ) ; memset ( & h - > last_pic_for_ec , 0 , sizeof ( h - > last_pic_for_ec ) ) ; h - > slice_ctx = orig_slice_ctx ; memset ( & h - > slice_ctx[0] . er , 0 , sizeof ( h - > slice_ctx[0] . er ) ) ; memset ( & h - > slice_ctx[0] . mb , 0 , sizeof ( h - > slice_ctx[0] . mb ) ) ; memset ( & h - > slice_ctx[0] . mb_luma_dc , 0 , sizeof ( h - > slice_ctx[0] . mb_luma_dc ) ) ; memset ( & h - > slice_ctx[0] . mb_padding , 0 , sizeof ( h - > slice_ctx[0] . mb_padding ) ) ; h - > avctx = dst ; h - > DPB = NULL ; h - > qscale_table_pool = NULL ; h - > mb_type_pool = NULL ; h - > ref_index_pool = NULL ; h - > motion_val_pool = NULL ; h - > intra4x4_pred_mode= NULL ; h - > non_zero_count = NULL ; h - > slice_table_base = NULL ; h - > slice_table = NULL ; h - > cbp_table = NULL ; h - > chroma_pred_mode_table = NULL ; memset ( h - > mvd_table , 0 , sizeof ( h - > mvd_table ) ) ; h - > direct_table = NULL ; h - > list_counts = NULL ; h - > mb2b_xy = NULL ; h - > mb2br_xy = NULL ; if ( h1 - > context_initialized ) { h - > context_initialized = 0 ; memset ( & h - > cur_pic , 0 , sizeof ( h - > cur_pic ) ) ; av_frame_unref ( & h - > cur_pic . f ) ; h - > cur_pic . tf . f = & h - > cur_pic . f ; ret = ff_h264_alloc_tables ( h ) ; if ( ret < 0 ) { av_log ( dst , AV_LOG_ERROR , Could not allocate memory\n ) ; return ret ; } ret = ff_h264_slice_context_init ( h , & h - > slice_ctx[0] ) ; if ( ret < 0 ) { av_log ( dst , AV_LOG_ERROR , context_init ( ) failed . \n ) ; return ret ; } } h - > context_initialized = h1 - > context_initialized ; } h - > avctx - > coded_height = h1 - > avctx - > coded_height ; h - > avctx - > coded_width = h1 - > avctx - > coded_width ; h - > avctx - > width = h1 - > avctx - > width ; h - > avctx - > height = h1 - > avctx - > height ; h - > coded_picture_number = h1 - > coded_picture_number ; h - > first_field = h1 - > first_field ; h - > picture_structure = h1 - > picture_structure ; h - > droppable = h1 - > droppable ; h - > low_delay = h1 - > low_delay ; for ( i = 0 ; h - > DPB & & i < H264_MAX_PICTURE_COUNT ; i + + ) { ff_h264_unref_picture ( h , & h - > DPB[i] ) ; if ( h1 - > DPB & & h1 - > DPB[i] . f . buf[0] & & ( ret = ff_h264_ref_picture ( h , & h - > DPB[i] , & h1 - > DPB[i] ) ) < 0 ) return ret",1
static av_cold int g722_encode_close ( AVCodecContext * avctx ) { G722Context * c = avctx - > priv_data ; int i ; for ( i = 0 ; i < 2 ; i + + ) { av_freep ( & c - > paths[i] ) ; av_freep ( & c - > node_buf[i] ) ; av_freep ( & c - > nodep_buf[i] ) ; } return 0 ; },0
"static int asf_get_packet ( AVFormatContext * s ) { ASFContext * asf = s - > priv_data ; ByteIOContext * pb = & s - > pb ; uint32_t packet_length , padsize ; int rsize = 9 ; int c ; c = get_byte ( pb ) ; if ( c ! = 0x82 ) { if ( ! url_feof ( pb ) ) av_log ( s , AV_LOG_ERROR , ff asf bad header %x at : % PRId64 \n , c , url_ftell ( pb ) ) ; } if ( ( c & 0x0f ) == 2 ) { // always true for now if ( get_le16 ( pb ) ! = 0 ) { if ( ! url_feof ( pb ) ) av_log ( s , AV_LOG_ERROR , ff asf bad non zero\n ) ; return AVERROR_IO ; } rsize + =2 ; / * } else { if ( ! url_feof ( pb ) ) printf ( ff asf bad header %x at : % PRId64 \n , c , url_ftell ( pb ) ) ; return AVERROR_IO ; * / } asf - > packet_flags = get_byte ( pb ) ; asf - > packet_property = get_byte ( pb ) ; DO_2BITS ( asf - > packet_flags > > 5 , packet_length , asf - > packet_size ) ; DO_2BITS ( asf - > packet_flags > > 1 , padsize , 0 ) ; // sequence ignored DO_2BITS ( asf - > packet_flags > > 3 , padsize , 0 ) ; // padding length //the following checks prevent overflows and infinite loops if ( packet_length > = ( 1U < < 29 ) ) { av_log ( s , AV_LOG_ERROR , invalid packet_length %d at : % PRId64 \n , packet_length , url_ftell ( pb ) ) ; return - 1 ; } if ( padsize > = ( 1U < < 29 ) ) { av_log ( s , AV_LOG_ERROR , invalid padsize %d at : % PRId64 \n , padsize , url_ftell ( pb ) ) ; return - 1 ; } asf - > packet_timestamp = get_le32 ( pb ) ; get_le16 ( pb ) ; / * duration * / // rsize has at least 11 bytes which have to be present if ( asf - > packet_flags & 0x01 ) { asf - > packet_segsizetype = get_byte ( pb ) ; rsize + + ; asf - > packet_segments = asf - > packet_segsizetype & 0x3f ; } else { asf - > packet_segments = 1 ; asf - > packet_segsizetype = 0x80 ; } asf - > packet_size_left = packet_length - padsize - rsize ; if ( packet_length < asf - > hdr . min_pktsize ) padsize + = asf - > hdr . min_pktsize - packet_length ; asf - > packet_padsize = padsize ; ifdef DEBUG printf ( packet : size=%d padsize=%d left=%d\n , asf - > packet_size , asf - > packet_padsize , asf - > packet_size_left ) ; endif return 0 ; }",0
"static void new_video_stream ( AVFormatContext * oc , int file_idx ) { AVStream * st ; OutputStream * ost ; AVCodecContext * video_enc ; enum CodecID codec_id = CODEC_ID_NONE ; AVCodec * codec= NULL ; if ( ! video_stream_copy ) { if ( video_codec_name ) { codec_id = find_codec_or_die ( video_codec_name , AVMEDIA_TYPE_VIDEO , 1 , avcodec_opts[AVMEDIA_TYPE_VIDEO] - > strict_std_compliance ) ; codec = avcodec_find_encoder_by_name ( video_codec_name ) ; } else { codec_id = av_guess_codec ( oc - > oformat , NULL , oc - > filename , NULL , AVMEDIA_TYPE_VIDEO ) ; codec = avcodec_find_encoder ( codec_id ) ; } } ost = new_output_stream ( oc , file_idx , codec ) ; st = ost - > st ; if ( ! video_stream_copy ) { ost - > frame_aspect_ratio = frame_aspect_ratio ; frame_aspect_ratio = 0 ; if CONFIG_AVFILTER ost - > avfilter= vfilters ; vfilters = NULL ; endif } ost - > bitstream_filters = video_bitstream_filters ; video_bitstream_filters= NULL ; st - > codec - > thread_count= thread_count ; video_enc = st - > codec ; if ( video_codec_tag ) video_enc - > codec_tag= video_codec_tag ; if ( oc - > oformat - > flags & AVFMT_GLOBALHEADER ) { video_enc - > flags |= CODEC_FLAG_GLOBAL_HEADER ; } if ( video_stream_copy ) { st - > stream_copy = 1 ; video_enc - > codec_type = AVMEDIA_TYPE_VIDEO ; video_enc - > sample_aspect_ratio = st - > sample_aspect_ratio = av_d2q ( frame_aspect_ratio * frame_height/frame_width , 255 ) ; } else { const char * p ; int i ; if ( frame_rate . num ) ost - > frame_rate = frame_rate ; video_enc - > codec_id = codec_id ; set_context_opts ( video_enc , avcodec_opts[AVMEDIA_TYPE_VIDEO] , AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM , codec ) ; video_enc - > width = frame_width ; video_enc - > height = frame_height ; video_enc - > pix_fmt = frame_pix_fmt ; st - > sample_aspect_ratio = video_enc - > sample_aspect_ratio ; if ( intra_only ) video_enc - > gop_size = 0 ; if ( video_qscale || same_quality ) { video_enc - > flags |= CODEC_FLAG_QSCALE ; video_enc - > global_quality = FF_QP2LAMBDA * video_qscale ; } if ( intra_matrix ) video_enc - > intra_matrix = intra_matrix ; if ( inter_matrix ) video_enc - > inter_matrix = inter_matrix ; p= video_rc_override_string ; for ( i=0 ; p ; i + + ) { int start , end , q ; int e=sscanf ( p , %d , %d , %d , & start , & end , & q ) ; if ( e ! =3 ) { fprintf ( stderr , error parsing rc_override\n ) ; ffmpeg_exit ( 1 ) ; } video_enc - > rc_override= av_realloc ( video_enc - > rc_override , sizeof ( RcOverride ) * ( i + 1 ) ) ; video_enc - > rc_override[i] . start_frame= start ; video_enc - > rc_override[i] . end_frame = end ; if ( q > 0 ) { video_enc - > rc_override[i] . qscale= q ; video_enc - > rc_override[i] . quality_factor= 1 . 0 ; } else { video_enc - > rc_override[i] . qscale= 0 ; video_enc - > rc_override[i] . quality_factor= - q/100 . 0 ; } p= strchr ( p , ' / ' ) ; if ( p ) p + + ; } video_enc - > rc_override_count=i ; if ( ! video_enc - > rc_initial_buffer_occupancy ) video_enc - > rc_initial_buffer_occupancy = video_enc - > rc_buffer_size * 3/4 ; video_enc - > me_threshold= me_threshold ; video_enc - > intra_dc_precision= intra_dc_precision - 8 ; if ( do_psnr ) video_enc - > flags|= CODEC_FLAG_PSNR ; / * two pass mode * / if ( do_pass ) { if ( do_pass == 1 ) { video_enc - > flags |= CODEC_FLAG_PASS1 ; } else { video_enc - > flags |= CODEC_FLAG_PASS2 ; } } if ( forced_key_frames ) parse_forced_key_frames ( forced_key_frames , ost , video_enc ) ; } if ( video_language ) { av_dict_set ( & st - > metadata , language , video_language , 0 ) ; av_freep ( & video_language ) ; } / * reset some key parameters * / video_disable = 0 ; av_freep ( & video_codec_name ) ; av_freep ( & forced_key_frames ) ; video_stream_copy = 0 ; frame_pix_fmt = PIX_FMT_NONE ; }",0
"void ff_check_pixfmt_descriptors ( void ) { int i , j ; for ( i=0 ; i < FF_ARRAY_ELEMS ( av_pix_fmt_descriptors ) ; i + + ) { const AVPixFmtDescriptor * d = & av_pix_fmt_descriptors[i] ; if ( ! d - > name & & ! d - > nb_components & & ! d - > log2_chroma_w & & ! d - > log2_chroma_h & & ! d - > flags ) continue ; // av_log ( NULL , AV_LOG_DEBUG , Checking : %s\n , d - > name ) ; av_assert0 ( d - > log2_chroma_w < = 3 ) ; av_assert0 ( d - > log2_chroma_h < = 3 ) ; av_assert0 ( d - > nb_components < = 4 ) ; av_assert0 ( d - > name & & d - > name[0] ) ; av_assert0 ( ( d - > nb_components==4 || d - > nb_components==2 ) == ! ! ( d - > flags & PIX_FMT_ALPHA ) ) ; av_assert2 ( av_get_pix_fmt ( d - > name ) == i ) ; for ( j=0 ; j < FF_ARRAY_ELEMS ( d - > comp ) ; j + + ) { const AVComponentDescriptor * c = & d - > comp[j] ; if ( j > =d - > nb_components ) av_assert0 ( ! c - > plane & & ! c - > step_minus1 & & ! c - > offset_plus1 & & ! c - > shift & & ! c - > depth_minus1 ) ; } } }",0
"static void mxf_write_generic_desc ( ByteIOContext * pb , const MXFDescriptorWriteTableEntry * desc_tbl , AVStream * st ) { const MXFCodecUL * codec_ul ; put_buffer ( pb , desc_tbl - > key , 16 ) ; klv_encode_ber_length ( pb , 108 ) ; mxf_write_local_tag ( pb , 16 , 0x3C0A ) ; mxf_write_uuid ( pb , SubDescriptor , st - > index ) ; mxf_write_local_tag ( pb , 4 , 0x3006 ) ; put_be32 ( pb , st - > index ) ; mxf_write_local_tag ( pb , 8 , 0x3001 ) ; put_be32 ( pb , st - > time_base . den ) ; put_be32 ( pb , st - > time_base . num ) ; codec_ul = mxf_get_essence_container_ul ( st - > codec - > codec_id ) ; mxf_write_local_tag ( pb , 16 , 0x3004 ) ; put_buffer ( pb , codec_ul - > uid , 16 ) ; }",0
"static int decode_frame_common ( AVCodecContext * avctx , PNGDecContext * s , AVFrame * p , AVPacket * avpkt ) { AVDictionary * * metadatap = NULL ; uint32_t tag , length ; int decode_next_dat = 0 ; int ret ; for ( ; ; ) { length = bytestream2_get_bytes_left ( & s - > gb ) ; if ( length < = 0 ) { if ( avctx - > codec_id == AV_CODEC_ID_PNG & & avctx - > skip_frame == AVDISCARD_ALL ) { return 0 ; } if ( CONFIG_APNG_DECODER & & avctx - > codec_id == AV_CODEC_ID_APNG & & length == 0 ) { if ( ! ( s - > pic_state & PNG_IDAT ) ) return 0 ; else goto exit_loop ; } av_log ( avctx , AV_LOG_ERROR , %d bytes left\n , length ) ; if ( s - > pic_state & PNG_ALLIMAGE & & avctx - > strict_std_compliance < = FF_COMPLIANCE_NORMAL ) goto exit_loop ; ret = AVERROR_INVALIDDATA ; goto fail ; } length = bytestream2_get_be32 ( & s - > gb ) ; if ( length > 0x7fffffff || length > bytestream2_get_bytes_left ( & s - > gb ) ) { av_log ( avctx , AV_LOG_ERROR , chunk too big\n ) ; ret = AVERROR_INVALIDDATA ; goto fail ; } tag = bytestream2_get_le32 ( & s - > gb ) ; if ( avctx - > debug & FF_DEBUG_STARTCODE ) av_log ( avctx , AV_LOG_DEBUG , png : tag=%s length=%u\n , av_fourcc2str ( tag ) , length ) ; if ( avctx - > codec_id == AV_CODEC_ID_PNG & & avctx - > skip_frame == AVDISCARD_ALL ) { switch ( tag ) { case MKTAG ( ' I ' , ' H ' , ' D ' , ' R ' ) : case MKTAG ( ' p ' , ' H ' , ' Y ' , ' s ' ) : case MKTAG ( ' t ' , ' E ' , ' X ' , ' t ' ) : case MKTAG ( ' I ' , ' D ' , ' A ' , ' T ' ) : case MKTAG ( ' t ' , ' R ' , ' N ' , ' S ' ) : break ; default : goto skip_tag ; } } metadatap = & p - > metadata ; switch ( tag ) { case MKTAG ( ' I ' , ' H ' , ' D ' , ' R ' ) : if ( ( ret = decode_ihdr_chunk ( avctx , s , length ) ) < 0 ) goto fail ; break ; case MKTAG ( ' p ' , ' H ' , ' Y ' , ' s ' ) : if ( ( ret = decode_phys_chunk ( avctx , s ) ) < 0 ) goto fail ; break ; case MKTAG ( ' f ' , ' c ' , ' T ' , ' L ' ) : if ( ! CONFIG_APNG_DECODER || avctx - > codec_id ! = AV_CODEC_ID_APNG ) goto skip_tag ; if ( ( ret = decode_fctl_chunk ( avctx , s , length ) ) < 0 ) goto fail ; decode_next_dat = 1 ; break ; case MKTAG ( ' f ' , ' d ' , ' A ' , ' T ' ) : if ( ! CONFIG_APNG_DECODER || avctx - > codec_id ! = AV_CODEC_ID_APNG ) goto skip_tag ; if ( ! decode_next_dat ) { ret = AVERROR_INVALIDDATA ; goto fail ; } bytestream2_get_be32 ( & s - > gb ) ; length - = 4 ; / * fallthrough * / case MKTAG ( ' I ' , ' D ' , ' A ' , ' T ' ) : if ( CONFIG_APNG_DECODER & & avctx - > codec_id == AV_CODEC_ID_APNG & & ! decode_next_dat ) goto skip_tag ; if ( ( ret = decode_idat_chunk ( avctx , s , length , p ) ) < 0 ) goto fail ; break ; case MKTAG ( ' P ' , ' L ' , ' T ' , ' E ' ) : if ( decode_plte_chunk ( avctx , s , length ) < 0 ) goto skip_tag ; break ; case MKTAG ( ' t ' , ' R ' , ' N ' , ' S ' ) : if ( decode_trns_chunk ( avctx , s , length ) < 0 ) goto skip_tag ; break ; case MKTAG ( ' t ' , ' E ' , ' X ' , ' t ' ) : if ( decode_text_chunk ( s , length , 0 , metadatap ) < 0 ) av_log ( avctx , AV_LOG_WARNING , Broken tEXt chunk\n ) ; bytestream2_skip ( & s - > gb , length + 4 ) ; break ; case MKTAG ( ' z ' , ' T ' , ' X ' , ' t ' ) : if ( decode_text_chunk ( s , length , 1 , metadatap ) < 0 ) av_log ( avctx , AV_LOG_WARNING , Broken zTXt chunk\n ) ; bytestream2_skip ( & s - > gb , length + 4 ) ; break ; case MKTAG ( ' s ' , ' T ' , ' E ' , ' R ' ) : { int mode = bytestream2_get_byte ( & s - > gb ) ; AVStereo3D * stereo3d = av_stereo3d_create_side_data ( p ) ; if ( ! stereo3d ) goto fail ; if ( mode == 0 || mode == 1 ) { stereo3d - > type = AV_STEREO3D_SIDEBYSIDE ; stereo3d - > flags = mode ? 0 : AV_STEREO3D_FLAG_INVERT ; } else { av_log ( avctx , AV_LOG_WARNING , Unknown value in sTER chunk ( %d ) \n , mode ) ; } bytestream2_skip ( & s - > gb , 4 ) ; / * crc * / break ; } case MKTAG ( ' i ' , ' C ' , ' C ' , ' P ' ) : { if ( decode_iccp_chunk ( s , length , p ) < 0 ) goto fail ; break ; } case MKTAG ( ' I ' , ' E ' , ' N ' , ' D ' ) : if ( ! ( s - > pic_state & PNG_ALLIMAGE ) ) av_log ( avctx , AV_LOG_ERROR , IEND without all image\n ) ; if ( ! ( s - > pic_state & ( PNG_ALLIMAGE|PNG_IDAT ) ) ) { ret = AVERROR_INVALIDDATA ; goto fail ; } bytestream2_skip ( & s - > gb , 4 ) ; / * crc * / goto exit_loop ; default : / * skip tag * / skip_tag : bytestream2_skip ( & s - > gb , length + 4 ) ; break ; } } exit_loop : if ( avctx - > codec_id == AV_CODEC_ID_PNG & & avctx - > skip_frame == AVDISCARD_ALL ) { return 0 ; } if ( s - > bits_per_pixel < = 4 ) handle_small_bpp ( s , p ) ; / * apply transparency if needed * / if ( s",0
"static void init_demo ( const char * filename ) { int i , j ; int h ; int radian ; char line[3 * W] ; FILE * fichier ; fichier = fopen ( filename , rb ) ; if ( ! fichier ) { perror ( filename ) ; exit ( 1 ) ; } fread ( line , 1 , 15 , fichier ) ; for ( i = 0 ; i < H ; i + + ) { fread ( line , 1 , 3 * W , fichier ) ; for ( j = 0 ; j < W ; j + + ) { tab_r[W * i + j] = line[3 * j ] ; tab_g[W * i + j] = line[3 * j + 1] ; tab_b[W * i + j] = line[3 * j + 2] ; } } fclose ( fichier ) ; / * tables sin/cos * / for ( i = 0 ; i < 360 ; i + + ) { radian = 2 * i * MY_PI / 360 ; h = 2 * FIXP + int_sin ( radian ) ; h_cos[i] = h * int_sin ( radian + MY_PI / 2 ) / 2 / FIXP ; h_sin[i] = h * int_sin ( radian ) / 2 / FIXP ; } }",0
"static int sync ( AVFormatContext * s , int64_t * timestamp , int * flags , int * stream_index , int64_t * pos ) { RMDemuxContext * rm = s - > priv_data ; ByteIOContext * pb = s - > pb ; int len , num , res , i ; AVStream * st ; uint32_t state=0xFFFFFFFF ; while ( ! url_feof ( pb ) ) { * pos= url_ftell ( pb ) - 3 ; if ( rm - > remaining_len > 0 ) { num= rm - > current_stream ; len= rm - > remaining_len ; * timestamp = AV_NOPTS_VALUE ; * flags= 0 ; } else { state= ( state < < 8 ) + get_byte ( pb ) ; if ( state == MKBETAG ( ' I ' , ' N ' , ' D ' , ' X ' ) ) { int n_pkts , expected_len ; len = get_be32 ( pb ) ; url_fskip ( pb , 2 ) ; n_pkts = get_be32 ( pb ) ; expected_len = 20 + n_pkts * 14 ; if ( len == 20 ) / * some files don ' t add index entries to chunk size . . . * / len = expected_len ; else if ( len ! = expected_len ) av_log ( s , AV_LOG_WARNING , Index size %d ( %d pkts ) is wrong , should be %d . \n , len , n_pkts , expected_len ) ; len - = 14 ; // we already read part of the index header if ( len < 0 ) continue ; goto skip ; } if ( state > ( unsigned ) 0xFFFF || state < 12 ) continue ; len=state ; state= 0xFFFFFFFF ; num = get_be16 ( pb ) ; * timestamp = get_be32 ( pb ) ; res= get_byte ( pb ) ; / * reserved * / * flags = get_byte ( pb ) ; / * flags * / len - = 12 ; } for ( i=0 ; i < s - > nb_streams ; i + + ) { st = s - > streams[i] ; if ( num == st - > id ) break ; } if ( i == s - > nb_streams ) { skip : / * skip packet if unknown number * / url_fskip ( pb , len ) ; rm - > remaining_len = 0 ; continue ; } * stream_index= i ; return len ; } return - 1 ; }",0
"static int qsv_get_buffer ( AVCodecContext * s , AVFrame * frame , int flags ) { InputStream * ist = s - > opaque ; QSVContext * qsv = ist - > hwaccel_ctx ; int i ; for ( i = 0 ; i < qsv - > nb_surfaces ; i + + ) { if ( qsv - > surface_used[i] ) continue ; frame - > buf[0] = av_buffer_create ( ( uint8_t * ) qsv - > surface_ptrs[i] , sizeof ( * qsv - > surface_ptrs[i] ) , buffer_release , & qsv - > surface_used[i] , 0 ) ; if ( ! frame - > buf[0] ) return AVERROR ( ENOMEM ) ; frame - > data[3] = ( uint8_t * ) qsv - > surface_ptrs[i] ; qsv - > surface_used[i] = 1 ; return 0 ; } return AVERROR ( ENOMEM ) ; }",0
"static int vid_read_packet ( AVFormatContext * s , AVPacket * pkt ) { BVID_DemuxContext * vid = s - > priv_data ; AVIOContext * pb = s - > pb ; unsigned char block_type ; int audio_length ; int ret_value ; if ( vid - > is_finished || pb - > eof_reached ) return AVERROR ( EIO ) ; block_type = avio_r8 ( pb ) ; switch ( block_type ) { case PALETTE_BLOCK : avio_seek ( pb , - 1 , SEEK_CUR ) ; // include block type ret_value = av_get_packet ( pb , pkt , 3 * 256 + 1 ) ; if ( ret_value ! = 3 * 256 + 1 ) { av_free_packet ( pkt ) ; return AVERROR ( EIO ) ; } pkt - > stream_index = 0 ; return ret_value ; case FIRST_AUDIO_BLOCK : avio_rl16 ( pb ) ; // soundblaster DAC used for sample rate , as on specification page ( link above ) s - > streams[1] - > codec - > sample_rate = 1000000 / ( 256 - avio_r8 ( pb ) ) ; s - > streams[1] - > codec - > bit_rate = s - > streams[1] - > codec - > channels * s - > streams[1] - > codec - > sample_rate * s - > streams[1] - > codec - > bits_per_coded_sample ; case AUDIO_BLOCK : audio_length = avio_rl16 ( pb ) ; ret_value = av_get_packet ( pb , pkt , audio_length ) ; pkt - > stream_index = 1 ; return ret_value ! = audio_length ? AVERROR ( EIO ) : ret_value ; case VIDEO_P_FRAME : case VIDEO_YOFF_P_FRAME : case VIDEO_I_FRAME : return read_frame ( vid , pb , pkt , block_type , s , s - > streams[0] - > codec - > width * s - > streams[0] - > codec - > height ) ; case EOF_BLOCK : if ( vid - > nframes ! = 0 ) av_log ( s , AV_LOG_VERBOSE , reached terminating character but not all frames read . \n ) ; vid - > is_finished = 1 ; return AVERROR ( EIO ) ; default : av_log ( s , AV_LOG_ERROR , unknown block ( character = %c , decimal = %d , hex = %x ) ! ! ! \n , block_type , block_type , block_type ) ; return - 1 ; } }",0
"static int config_props ( AVFilterLink * link ) { UnsharpContext * unsharp = link - > dst - > priv ; const AVPixFmtDescriptor * desc = av_pix_fmt_desc_get ( link - > format ) ; unsharp - > hsub = desc - > log2_chroma_w ; unsharp - > vsub = desc - > log2_chroma_h ; init_filter_param ( link - > dst , & unsharp - > luma , luma , link - > w ) ; init_filter_param ( link - > dst , & unsharp - > chroma , chroma , SHIFTUP ( link - > w , unsharp - > hsub ) ) ; return 0 ; }",0
"void avpriv_solve_lls ( LLSModel * m , double threshold , unsigned short min_order ) { int i , j , k ; double ( * factor ) [MAX_VARS_ALIGN] = ( void * ) & m - > covariance[1][0] ; double ( * covar ) [MAX_VARS_ALIGN] = ( void * ) & m - > covariance[1][1] ; double * covar_y = m - > covariance[0] ; int count = m - > indep_count ; for ( i = 0 ; i < count ; i + + ) { for ( j = i ; j < count ; j + + ) { double sum = covar[i][j] ; for ( k = i - 1 ; k > = 0 ; k - - ) sum - = factor[i][k] * factor[j][k] ; if ( i == j ) { if ( sum < threshold ) sum = 1 . 0 ; factor[i][i] = sqrt ( sum ) ; } else { factor[j][i] = sum / factor[i][i] ; } } } for ( i = 0 ; i < count ; i + + ) { double sum = covar_y[i + 1] ; for ( k = i - 1 ; k > = 0 ; k - - ) sum - = factor[i][k] * m - > coeff[0][k] ; m - > coeff[0][i] = sum / factor[i][i] ; } for ( j = count - 1 ; j > = min_order ; j - - ) { for ( i = j ; i > = 0 ; i - - ) { double sum = m - > coeff[0][i] ; for ( k = i + 1 ; k < = j ; k + + ) sum - = factor[k][i] * m - > coeff[j][k] ; m - > coeff[j][i] = sum / factor[i][i] ; } m - > variance[j] = covar_y[0] ; for ( i = 0 ; i < = j ; i + + ) { double sum = m - > coeff[j][i] * covar[i][i] - 2 * covar_y[i + 1] ; for ( k = 0 ; k < i ; k + + ) sum + = 2 * m - > coeff[j][k] * covar[k][i] ; m - > variance[j] + = m - > coeff[j][i] * sum ; } } }",0
"static int hap_encode ( AVCodecContext * avctx , AVPacket * pkt , const AVFrame * frame , int * got_packet ) { HapContext * ctx = avctx - > priv_data ; int header_length = hap_header_length ( ctx ) ; int final_data_size , ret ; int pktsize = FFMAX ( ctx - > tex_size , ctx - > max_snappy * ctx - > chunk_count ) + header_length ; / * Allocate maximum size packet , shrink later . * / ret = ff_alloc_packet2 ( avctx , pkt , pktsize , header_length ) ; if ( ret < 0 ) return ret ; / * DXTC compression . * / ret = compress_texture ( avctx , ctx - > tex_buf , ctx - > tex_size , frame ) ; if ( ret < 0 ) return ret ; / * Compress ( using Snappy ) the frame * / final_data_size = hap_compress_frame ( avctx , pkt - > data + header_length ) ; if ( final_data_size < 0 ) return final_data_size ; / * Write header at the start . * / hap_write_frame_header ( ctx , pkt - > data , final_data_size + header_length ) ; av_shrink_packet ( pkt , final_data_size + header_length ) ; pkt - > flags |= AV_PKT_FLAG_KEY ; * got_packet = 1 ; return 0 ; }",0
"static void add_pid_to_pmt ( MpegTSContext * ts , unsigned int programid , unsigned int pid ) { int i ; struct Program * p = NULL ; for ( i=0 ; i < ts - > nb_prg ; i + + ) { if ( ts - > prg[i] . id == programid ) { p = & ts - > prg[i] ; break ; } } if ( ! p ) return ; if ( p - > nb_pids > = MAX_PIDS_PER_PROGRAM ) return ; p - > pids[p - > nb_pids + + ] = pid ; }",0
"void ff_h261_loop_filter ( H261Context * h ) { MpegEncContext * const s = & h - > s ; int i ; const int linesize = s - > linesize ; const int uvlinesize= s - > uvlinesize ; uint8_t * dest_y = s - > dest[0] ; uint8_t * dest_cb= s - > dest[1] ; uint8_t * dest_cr= s - > dest[2] ; uint8_t * src ; CHECKED_ALLOCZ ( ( src ) , sizeof ( uint8_t ) * 64 ) ; for ( i=0 ; i < 8 ; i + + ) memcpy ( src + i * 8 , dest_y + i * linesize , sizeof ( uint8_t ) * 8 ) ; s - > dsp . h261_v_loop_filter ( dest_y , src , linesize ) ; s - > dsp . h261_h_loop_filter ( dest_y , src , linesize ) ; for ( i=0 ; i < 8 ; i + + ) memcpy ( src + i * 8 , dest_y + i * linesize + 8 , sizeof ( uint8_t ) * 8 ) ; s - > dsp . h261_v_loop_filter ( dest_y + 8 , src , linesize ) ; s - > dsp . h261_h_loop_filter ( dest_y + 8 , src , linesize ) ; for ( i=0 ; i < 8 ; i + + ) memcpy ( src + i * 8 , dest_y + ( i + 8 ) * linesize , sizeof ( uint8_t ) * 8 ) ; s - > dsp . h261_v_loop_filter ( dest_y + 8 * linesize , src , linesize ) ; s - > dsp . h261_h_loop_filter ( dest_y + 8 * linesize , src , linesize ) ; for ( i=0 ; i < 8 ; i + + ) memcpy ( src + i * 8 , dest_y + ( i + 8 ) * linesize + 8 , sizeof ( uint8_t ) * 8 ) ; s - > dsp . h261_v_loop_filter ( dest_y + 8 * linesize + 8 , src , linesize ) ; s - > dsp . h261_h_loop_filter ( dest_y + 8 * linesize + 8 , src , linesize ) ; for ( i=0 ; i < 8 ; i + + ) memcpy ( src + i * 8 , dest_cb + i * uvlinesize , sizeof ( uint8_t ) * 8 ) ; s - > dsp . h261_v_loop_filter ( dest_cb , src , uvlinesize ) ; s - > dsp . h261_h_loop_filter ( dest_cb , src , uvlinesize ) ; for ( i=0 ; i < 8 ; i + + ) memcpy ( src + i * 8 , dest_cr + i * uvlinesize , sizeof ( uint8_t ) * 8 ) ; s - > dsp . h261_v_loop_filter ( dest_cr , src , uvlinesize ) ; s - > dsp . h261_h_loop_filter ( dest_cr , src , uvlinesize ) ; fail : av_free ( src ) ; return ; }",0
"static int64_t wav_seek_tag ( AVIOContext * s , int64_t offset , int whence ) { offset + = offset < INT64_MAX & & offset & 1 ; return avio_seek ( s , offset , whence ) ; }",0
"void ff_put_h264_qpel8_mc32_msa ( uint8_t * dst , const uint8_t * src , ptrdiff_t stride ) { avc_luma_midh_qrt_8w_msa ( src - ( 2 * stride ) - 2 , stride , dst , stride , 8 , 1 ) ; }",0
"x11grab_read_header ( AVFormatContext * s1 , AVFormatParameters * ap ) { struct x11_grab * x11grab = s1 - > priv_data ; Display * dpy ; AVStream * st = NULL ; enum PixelFormat input_pixfmt ; XImage * image ; int x_off = 0 ; int y_off = 0 ; int use_shm ; char * param , * offset ; int ret = 0 ; AVRational framerate ; param = av_strdup ( s1 - > filename ) ; offset = strchr ( param , ' + ' ) ; if ( offset ) { sscanf ( offset , %d , %d , & x_off , & y_off ) ; x11grab - > nomouse= strstr ( offset , nomouse ) ; * offset= 0 ; } if ( ( ret = av_parse_video_size ( & x11grab - > width , & x11grab - > height , x11grab - > video_size ) ) < 0 ) { av_log ( s1 , AV_LOG_ERROR , Couldn ' t parse video size . \n ) ; goto out ; } if ( ( ret = av_parse_video_rate ( & framerate , x11grab - > framerate ) ) < 0 ) { av_log ( s1 , AV_LOG_ERROR , Could not parse framerate : %s . \n , x11grab - > framerate ) ; goto out ; } if FF_API_FORMAT_PARAMETERS if ( ap - > width > 0 ) x11grab - > width = ap - > width ; if ( ap - > height > 0 ) x11grab - > height = ap - > height ; if ( ap - > time_base . num ) framerate = ( AVRational ) { ap - > time_base . den , ap - > time_base . num } ; endif av_log ( s1 , AV_LOG_INFO , device : %s - > display : %s x : %d y : %d width : %d height : %d\n , s1 - > filename , param , x_off , y_off , x11grab - > width , x11grab - > height ) ; dpy = XOpenDisplay ( param ) ; if ( ! dpy ) { av_log ( s1 , AV_LOG_ERROR , Could not open X display . \n ) ; ret = AVERROR ( EIO ) ; goto out ; } st = av_new_stream ( s1 , 0 ) ; if ( ! st ) { ret = AVERROR ( ENOMEM ) ; goto out ; } av_set_pts_info ( st , 64 , 1 , 1000000 ) ; / * 64 bits pts in us * / use_shm = XShmQueryExtension ( dpy ) ; av_log ( s1 , AV_LOG_INFO , shared memory extension %s found\n , use_shm ? : not ) ; if ( use_shm ) { int scr = XDefaultScreen ( dpy ) ; image = XShmCreateImage ( dpy , DefaultVisual ( dpy , scr ) , DefaultDepth ( dpy , scr ) , ZPixmap , NULL , & x11grab - > shminfo , x11grab - > width , x11grab - > height ) ; x11grab - > shminfo . shmid = shmget ( IPC_PRIVATE , image - > bytes_per_line * image - > height , IPC_CREAT|0777 ) ; if ( x11grab - > shminfo . shmid == - 1 ) { av_log ( s1 , AV_LOG_ERROR , Fatal : Can ' t get shared memory ! \n ) ; ret = AVERROR ( ENOMEM ) ; goto out ; } x11grab - > shminfo . shmaddr = image - > data = shmat ( x11grab - > shminfo . shmid , 0 , 0 ) ; x11grab - > shminfo . readOnly = False ; if ( ! XShmAttach ( dpy , & x11grab - > shminfo ) ) { av_log ( s1 , AV_LOG_ERROR , Fatal : Failed to attach shared memory ! \n ) ; / * needs some better error subroutine : ) * / ret = AVERROR ( EIO ) ; goto out ; } } else { image = XGetImage ( dpy , RootWindow ( dpy , DefaultScreen ( dpy ) ) , x_off , y_off , x11grab - > width , x11grab - > height , AllPlanes , ZPixmap ) ; } switch ( image - > bits_per_pixel ) { case 8 : av_log ( s1 , AV_LOG_DEBUG , 8 bit palette\n ) ; input_pixfmt = PIX_FMT_PAL8 ; break ; case 16 : if ( image - > red_mask == 0xf800 & & image - > green_mask == 0x07e0 & & image - > blue_mask == 0x001f ) { av_log ( s1 , AV_LOG_DEBUG , 16 bit RGB565\n ) ; input_pixfmt = PIX_FMT_RGB565 ; } else if ( image - > red_mask == 0x7c00 & & image - > green_mask == 0x03e0 & & image - > blue_mask == 0x001f ) { av_log ( s1 , AV_LOG_DEBUG , 16 bit RGB555\n ) ; input_pixfmt = PIX_FMT_RGB555 ; } else { av_log ( s1 , AV_LOG_ERROR , RGB ordering at image depth %i not supported . . . aborting\n , image - > bits_per_pixel ) ; av_log ( s1 , AV_LOG_ERROR , color masks : r 0x% . 6lx g 0x% . 6lx b 0x% . 6lx\n , image - > red_mask , image - > green_mask , image - > blue_mask ) ; ret = AVERROR ( EIO ) ; goto out ; } break ; case 24 : if ( image - > red_mask == 0xff0000 & & image - > green_mask == 0x00ff00 & & image - > blue_mask == 0x0000ff ) { input_pixfmt = PIX_FMT_BGR24 ; } else if ( image - > red_mask == 0x0000ff & & image - > green_mask == 0x00ff00 & & image - > blue_mask == 0xff0000 ) { input_pixfmt = PIX_FMT_RGB24 ; } else { av_log ( s1 , AV_LOG_ERROR , rgb ordering at image depth %i not supported . . . aborting\n , image - > bits_per_pixel ) ; av_log ( s1 , AV_LOG_ERROR , color masks : r 0x% . 6lx g 0x% . 6lx b 0x% . 6lx\n , image - > red_mask , image - > green_mask , image - > blue_mask ) ; ret = AVERROR ( EIO ) ; goto out ; } break ; case 32 : input_pixfmt = PIX_FMT_RGB32 ; break ; default : av_log ( s1 , AV_LOG_ERROR , image depth %i not supported . . . aborting\n , image - > bits_per_pixel ) ; ret = AVERROR ( EINVAL ) ; goto out ; } x11grab - > frame_size = x11grab - > width * x11grab - > height * image - > bits_per_pixel/8 ; x11grab - > dpy = dpy ; x11grab - > time_base = ( AVRational ) { framerate . den , framerate . num } ; x11grab - > time_frame = av_gettime ( ) / av_q2d ( x11grab - > time_base ) ; x11grab - > x_off = x_off ; x11grab - > y_off = y_off ; x11grab - > image = image ; x11grab - > use_shm = use_shm ; st - > codec - > codec_type = AVMEDIA_TYPE_VIDEO ; st - > codec - > codec_id = CODEC_ID_RAWVIDEO ; st - > codec - > width = x11grab - > width",0
"static inline void RENAME ( yuv2yuyv422_1 ) ( SwsContext * c , const uint16_t * buf0 , const uint16_t * ubuf0 , const uint16_t * ubuf1 , const uint16_t * vbuf0 , const uint16_t * vbuf1 , const uint16_t * abuf0 , uint8_t * dest , int dstW , int uvalpha , enum PixelFormat dstFormat , int flags , int y ) { x86_reg uv_off = c - > uv_off < < 1 ; const uint16_t * buf1= buf0 ; //FIXME needed for RGB1/BGR1 if ( uvalpha < 2048 ) { // note this is not correct ( shifts chrominance by 0 . 5 pixels ) but it is a bit faster __asm__ volatile ( mov %% REG_b , ESP_OFFSET ( %5 ) \n\t mov %4 , %% REG_b \n\t push %% REG_BP \n\t YSCALEYUV2PACKED1 ( %%REGBP , %5 , %6 ) WRITEYUY2 ( %%REGb , 8280 ( %5 ) , %%REGBP ) pop %% REG_BP \n\t mov ESP_OFFSET ( %5 ) , %% REG_b \n\t : : c ( buf0 ) , d ( buf1 ) , S ( ubuf0 ) , D ( ubuf1 ) , m ( dest ) , a ( & c - > redDither ) , m ( uv_off ) ) ; } else { __asm__ volatile ( mov %% REG_b , ESP_OFFSET ( %5 ) \n\t mov %4 , %% REG_b \n\t push %% REG_BP \n\t YSCALEYUV2PACKED1b ( %%REGBP , %5 , %6 ) WRITEYUY2 ( %%REGb , 8280 ( %5 ) , %%REGBP ) pop %% REG_BP \n\t mov ESP_OFFSET ( %5 ) , %% REG_b \n\t : : c ( buf0 ) , d ( buf1 ) , S ( ubuf0 ) , D ( ubuf1 ) , m ( dest ) , a ( & c - > redDither ) , m ( uv_off ) ) ; } }",1
"static int ipvideo_decode_block_opcode_0x4 ( IpvideoContext * s ) { int x , y ; unsigned char B , BL , BH ; / * copy a block from the previous frame ; need 1 more byte * / CHECK_STREAM_PTR ( 1 ) ; B = * s - > stream_ptr + + ; BL = B & 0x0F ; BH = ( B > > 4 ) & 0x0F ; x = - 8 + BL ; y = - 8 + BH ; debug_interplay ( motion byte = %d , ( x , y ) = ( %d , %d ) \n , B , x , y ) ; return copy_from ( s , & s - > last_frame , x , y ) ; }",0
"static int open_input_stream ( HTTPContext * c , const char * info ) { char buf[128] ; char input_filename[1024] ; AVFormatContext * s ; int buf_size , i , ret ; int64_t stream_pos ; / * find file name * / if ( c - > stream - > feed ) { strcpy ( input_filename , c - > stream - > feed - > feed_filename ) ; buf_size = FFM_PACKET_SIZE ; / * compute position ( absolute time ) * / if ( find_info_tag ( buf , sizeof ( buf ) , date , info ) ) { stream_pos = parse_date ( buf , 0 ) ; if ( stream_pos == INT64_MIN ) return - 1 ; } else if ( find_info_tag ( buf , sizeof ( buf ) , buffer , info ) ) { int prebuffer = strtol ( buf , 0 , 10 ) ; stream_pos = av_gettime ( ) - prebuffer * ( int64_t ) 1000000 ; } else stream_pos = av_gettime ( ) - c - > stream - > prebuffer * ( int64_t ) 1000 ; } else { strcpy ( input_filename , c - > stream - > feed_filename ) ; buf_size = 0 ; / * compute position ( relative time ) * / if ( find_info_tag ( buf , sizeof ( buf ) , date , info ) ) { stream_pos = parse_date ( buf , 1 ) ; if ( stream_pos == INT64_MIN ) return - 1 ; } else stream_pos = 0 ; } if ( input_filename[0] == ' \0 ' ) return - 1 ; if 0 { time_t when = stream_pos / 1000000 ; http_log ( Stream pos = % PRId64 , time=%s , stream_pos , ctime ( & when ) ) ; } endif / * open stream * / if ( ( ret = av_open_input_file ( & s , input_filename , c - > stream - > ifmt , buf_size , c - > stream - > ap_in ) ) < 0 ) { http_log ( could not open %s : %d\n , input_filename , ret ) ; return - 1 ; } s - > flags |= AVFMT_FLAG_GENPTS ; c - > fmt_in = s ; av_find_stream_info ( c - > fmt_in ) ; / * open each parser * / for ( i=0 ; i < s - > nb_streams ; i + + ) open_parser ( s , i ) ; / * choose stream as clock source ( we favorize video stream if present ) for packet sending * / c - > pts_stream_index = 0 ; for ( i=0 ; i < c - > stream - > nb_streams ; i + + ) { if ( c - > pts_stream_index == 0 & & c - > stream - > streams[i] - > codec - > codec_type == CODEC_TYPE_VIDEO ) { c - > pts_stream_index = i ; } } if 1 if ( c - > fmt_in - > iformat - > read_seek ) av_seek_frame ( c - > fmt_in , - 1 , stream_pos , 0 ) ; endif / * set the start time ( needed for maxtime and RTP packet timing ) * / c - > start_time = cur_time ; c - > first_pts = AV_NOPTS_VALUE ; return 0 ; }",0
"static int rtcp_parse_packet ( RTPDemuxContext * s , const unsigned char * buf , int len ) { int payload_len ; while ( len > = 4 ) { payload_len = FFMIN ( len , ( AV_RB16 ( buf + 2 ) + 1 ) * 4 ) ; switch ( buf[1] ) { case RTCP_SR : if ( payload_len < 20 ) { av_log ( NULL , AV_LOG_ERROR , Invalid length for RTCP SR packet\n ) ; return AVERROR_INVALIDDATA ; } s - > last_rtcp_reception_time = av_gettime_relative ( ) ; s - > last_rtcp_ntp_time = AV_RB64 ( buf + 8 ) ; s - > last_rtcp_timestamp = AV_RB32 ( buf + 16 ) ; if ( s - > first_rtcp_ntp_time == AV_NOPTS_VALUE ) { s - > first_rtcp_ntp_time = s - > last_rtcp_ntp_time ; if ( ! s - > base_timestamp ) s - > base_timestamp = s - > last_rtcp_timestamp ; s - > rtcp_ts_offset = s - > last_rtcp_timestamp - s - > base_timestamp ; } break ; case RTCP_BYE : return - RTCP_BYE ; } buf + = payload_len ; len - = payload_len ; } return - 1 ; }",0
"void idct_add_altivec ( uint8_t * dest , int stride , vector_s16_t * block ) { POWERPC_TBL_DECLARE ( altivec_idct_add_num , 1 ) ; ifdef ALTIVEC_USE_REFERENCE_C_CODE POWERPC_TBL_START_COUNT ( altivec_idct_add_num , 1 ) ; void simple_idct_add ( uint8_t * dest , int line_size , int16_t * block ) ; simple_idct_add ( dest , stride , ( int16_t * ) block ) ; POWERPC_TBL_STOP_COUNT ( altivec_idct_add_num , 1 ) ; else / * ALTIVEC_USE_REFERENCE_C_CODE * / vector_u8_t tmp ; vector_s16_t tmp2 , tmp3 ; vector_u8_t perm0 ; vector_u8_t perm1 ; vector_u8_t p0 , p1 , p ; POWERPC_TBL_START_COUNT ( altivec_idct_add_num , 1 ) ; IDCT p0 = vec_lvsl ( 0 , dest ) ; p1 = vec_lvsl ( stride , dest ) ; p = vec_splat_u8 ( - 1 ) ; perm0 = vec_mergeh ( p , p0 ) ; perm1 = vec_mergeh ( p , p1 ) ; define ADD ( dest , src , perm ) \ / * * ( uint64_t * ) & tmp = * ( uint64_t * ) dest ; * / \ tmp = vec_ld ( 0 , dest ) ; \ tmp2 = ( vector_s16_t ) vec_perm ( tmp , ( vector_u8_t ) zero , perm ) ; \ tmp3 = vec_adds ( tmp2 , src ) ; \ tmp = vec_packsu ( tmp3 , tmp3 ) ; \ vec_ste ( ( vector_u32_t ) tmp , 0 , ( unsigned int * ) dest ) ; \ vec_ste ( ( vector_u32_t ) tmp , 4 , ( unsigned int * ) dest ) ; ADD ( dest , vx0 , perm0 ) dest + = stride ; ADD ( dest , vx1 , perm1 ) dest + = stride ; ADD ( dest , vx2 , perm0 ) dest + = stride ; ADD ( dest , vx3 , perm1 ) dest + = stride ; ADD ( dest , vx4 , perm0 ) dest + = stride ; ADD ( dest , vx5 , perm1 ) dest + = stride ; ADD ( dest , vx6 , perm0 ) dest + = stride ; ADD ( dest , vx7 , perm1 ) POWERPC_TBL_STOP_COUNT ( altivec_idct_add_num , 1 ) ; endif / * ALTIVEC_USE_REFERENCE_C_CODE * / }",0
"AVBufferRef * av_buffer_alloc ( int size ) { AVBufferRef * ret = NULL ; uint8_t * data = NULL ; data = av_malloc ( size ) ; if ( ! data ) return NULL ; if ( CONFIG_MEMORY_POISONING ) memset ( data , 0x2a , size ) ; ret = av_buffer_create ( data , size , av_buffer_default_free , NULL , 0 ) ; if ( ! ret ) av_freep ( & data ) ; return ret ; }",0
"static int gxf_write_header ( AVFormatContext * s ) { AVIOContext * pb = s - > pb ; GXFContext * gxf = s - > priv_data ; GXFStreamContext * vsc = NULL ; uint8_t tracks[255] = { 0 } ; int i , media_info = 0 ; if ( ! pb - > seekable ) { av_log ( s , AV_LOG_ERROR , gxf muxer does not support streamed output , patch welcome ) ; return - 1 ; } gxf - > flags |= 0x00080000 ; / * material is simple clip * / for ( i = 0 ; i < s - > nb_streams ; + + i ) { AVStream * st = s - > streams[i] ; GXFStreamContext * sc = av_mallocz ( sizeof ( * sc ) ) ; if ( ! sc ) return AVERROR ( ENOMEM ) ; st - > priv_data = sc ; sc - > media_type = ff_codec_get_tag ( gxf_media_types , st - > codecpar - > codec_id ) ; if ( st - > codecpar - > codec_type == AVMEDIA_TYPE_AUDIO ) { if ( st - > codecpar - > codec_id ! = AV_CODEC_ID_PCM_S16LE ) { av_log ( s , AV_LOG_ERROR , only 16 BIT PCM LE allowed for now\n ) ; return - 1 ; } if ( st - > codecpar - > sample_rate ! = 48000 ) { av_log ( s , AV_LOG_ERROR , only 48000hz sampling rate is allowed\n ) ; return - 1 ; } if ( st - > codecpar - > channels ! = 1 ) { av_log ( s , AV_LOG_ERROR , only mono tracks are allowed\n ) ; return - 1 ; } sc - > track_type = 2 ; sc - > sample_rate = st - > codecpar - > sample_rate ; avpriv_set_pts_info ( st , 64 , 1 , sc - > sample_rate ) ; sc - > sample_size = 16 ; sc - > frame_rate_index = - 2 ; sc - > lines_index = - 2 ; sc - > fields = - 2 ; gxf - > audio_tracks + + ; gxf - > flags |= 0x04000000 ; / * audio is 16 bit pcm * / media_info = ' A ' ; } else if ( st - > codecpar - > codec_type == AVMEDIA_TYPE_VIDEO ) { if ( i ! = 0 ) { av_log ( s , AV_LOG_ERROR , video stream must be the first track\n ) ; return - 1 ; } / * FIXME check from time_base ? * / if ( st - > codecpar - > height == 480 || st - > codecpar - > height == 512 ) { / * NTSC or NTSC + VBI * / sc - > frame_rate_index = 5 ; sc - > sample_rate = 60 ; gxf - > flags |= 0x00000080 ; gxf - > time_base = ( AVRational ) { 1001 , 60000 } ; } else if ( st - > codecpar - > height == 576 || st - > codecpar - > height == 608 ) { / * PAL or PAL + VBI * / sc - > frame_rate_index = 6 ; sc - > media_type + + ; sc - > sample_rate = 50 ; gxf - > flags |= 0x00000040 ; gxf - > time_base = ( AVRational ) { 1 , 50 } ; } else { av_log ( s , AV_LOG_ERROR , unsupported video resolution , gxf muxer only accepts PAL or NTSC resolutions currently\n ) ; return - 1 ; } avpriv_set_pts_info ( st , 64 , gxf - > time_base . num , gxf - > time_base . den ) ; if ( gxf_find_lines_index ( st ) < 0 ) sc - > lines_index = - 1 ; sc - > sample_size = st - > codecpar - > bit_rate ; sc - > fields = 2 ; / * interlaced * / vsc = sc ; switch ( st - > codecpar - > codec_id ) { case AV_CODEC_ID_MJPEG : sc - > track_type = 1 ; gxf - > flags |= 0x00004000 ; media_info = ' J ' ; break ; case AV_CODEC_ID_MPEG1VIDEO : sc - > track_type = 9 ; gxf - > mpeg_tracks + + ; media_info = ' L ' ; break ; case AV_CODEC_ID_MPEG2VIDEO : sc - > first_gop_closed = - 1 ; sc - > track_type = 4 ; gxf - > mpeg_tracks + + ; gxf - > flags |= 0x00008000 ; media_info = ' M ' ; break ; case AV_CODEC_ID_DVVIDEO : if ( st - > codecpar - > format == AV_PIX_FMT_YUV422P ) { sc - > media_type + = 2 ; sc - > track_type = 6 ; gxf - > flags |= 0x00002000 ; media_info = ' E ' ; } else { sc - > track_type = 5 ; gxf - > flags |= 0x00001000 ; media_info = ' D ' ; } break ; default : av_log ( s , AV_LOG_ERROR , video codec not supported\n ) ; return - 1 ; } } / * FIXME first 10 audio tracks are 0 to 9 next 22 are A to V * / sc - > media_info = media_info < < 8 | ( ' 0 ' + tracks[media_info] + + ) ; sc - > order = s - > nb_streams - st - > index ; } if ( ff_audio_interleave_init ( s , GXF_samples_per_frame , ( AVRational ) { 1 , 48000 } ) < 0 ) return - 1 ; gxf_init_timecode_track ( & gxf - > timecode_track , vsc ) ; gxf - > flags |= 0x200000 ; // time code track is non - drop frame gxf_write_map_packet ( s , 0 ) ; gxf_write_flt_packet ( s ) ; gxf_write_umf_packet ( s ) ; gxf - > packet_count = 3 ; avio_flush ( pb ) ; return 0 ; }",0
"static unsigned tget ( const uint8_t * * p , int type , int le ) { switch ( type ) { case TIFF_BYTE : return * ( * p ) + + ; case TIFF_SHORT : return tget_short ( p , le ) ; case TIFF_LONG : return tget_long ( p , le ) ; default : return UINT_MAX ; } }",0
"static int mpeg4_decode_partitioned_mb ( MpegEncContext * s , DCTELEM block[6][64] ) { int cbp , mb_type ; const int xy= s - > mb_x + s - > mb_y * s - > mb_width ; mb_type= s - > mb_type[xy] ; cbp = s - > cbp_table[xy] ; if ( s - > current_picture . qscale_table[xy] ! = s - > qscale ) { s - > qscale= s - > current_picture . qscale_table[xy] ; s - > y_dc_scale= s - > y_dc_scale_table[ s - > qscale ] ; s - > c_dc_scale= s - > c_dc_scale_table[ s - > qscale ] ; } if ( s - > pict_type == P_TYPE || s - > pict_type==S_TYPE ) { int i ; for ( i=0 ; i < 4 ; i + + ) { s - > mv[0][i][0] = s - > motion_val[ s - > block_index[i] ][0] ; s - > mv[0][i][1] = s - > motion_val[ s - > block_index[i] ][1] ; } s - > mb_intra = mb_type & MB_TYPE_INTRA ; if ( mb_type & MB_TYPE_SKIPED ) { / * skip mb * / for ( i=0 ; i < 6 ; i + + ) s - > block_last_index[i] = - 1 ; s - > mv_dir = MV_DIR_FORWARD ; s - > mv_type = MV_TYPE_16X16 ; if ( s - > pict_type==S_TYPE & & s - > vol_sprite_usage==GMC_SPRITE ) { s - > mcsel=1 ; s - > mb_skiped = 0 ; } else { s - > mcsel=0 ; s - > mb_skiped = 1 ; } } else if ( s - > mb_intra ) { s - > ac_pred = s - > pred_dir_table[xy] > > 7 ; / * decode each block * / for ( i = 0 ; i < 6 ; i + + ) { if ( mpeg4_decode_block ( s , block[i] , i , cbp & 32 , 1 ) < 0 ) { fprintf ( stderr , texture corrupted at %d %d\n , s - > mb_x , s - > mb_y ) ; return - 1 ; } cbp + =cbp ; } } else if ( ! s - > mb_intra ) { // s - > mcsel= 0 ; //FIXME do we need to init that s - > mv_dir = MV_DIR_FORWARD ; if ( mb_type & MB_TYPE_INTER4V ) { s - > mv_type = MV_TYPE_8X8 ; } else { s - > mv_type = MV_TYPE_16X16 ; } / * decode each block * / for ( i = 0 ; i < 6 ; i + + ) { if ( mpeg4_decode_block ( s , block[i] , i , cbp & 32 , 0 ) < 0 ) { fprintf ( stderr , texture corrupted at %d %d ( trying to continue with mc/dc only ) \n , s - > mb_x , s - > mb_y ) ; return - 1 ; } cbp + =cbp ; } } } else { / * I - Frame * / int i ; s - > mb_intra = 1 ; s - > ac_pred = s - > pred_dir_table[xy] > > 7 ; / * decode each block * / for ( i = 0 ; i < 6 ; i + + ) { if ( mpeg4_decode_block ( s , block[i] , i , cbp & 32 , 1 ) < 0 ) { fprintf ( stderr , texture corrupted at %d %d ( trying to continue with dc only ) \n , s - > mb_x , s - > mb_y ) ; return - 1 ; } cbp + =cbp ; } } s - > error_status_table[xy] & = AC_ERROR ; / * per - MB end of slice check * / if ( - - s - > mb_num_left < = 0 ) { //printf ( %06X %d\n , show_bits ( & s - > gb , 24 ) , s - > gb . size * 8 - get_bits_count ( & s - > gb ) ) ; if ( mpeg4_is_resync ( s ) ) return SLICE_END ; else return SLICE_NOEND ; } else { if ( s - > cbp_table[xy + 1] & & mpeg4_is_resync ( s ) ) return SLICE_END ; else return SLICE_OK ; } }",0
"static int roq_decode_init ( AVCodecContext * avctx ) { RoqContext * s = avctx - > priv_data ; s - > avctx = avctx ; s - > width = avctx - > width ; s - > height = avctx - > height ; s - > last_frame = & s - > frames[0] ; s - > current_frame = & s - > frames[1] ; avctx - > pix_fmt = PIX_FMT_YUV444P ; dsputil_init ( & s - > dsp , avctx ) ; return 0 ; }",0
"static void opt_format ( const char * arg ) { / * compatibility stuff for pgmyuv * / if ( ! strcmp ( arg , pgmyuv ) ) { opt_image_format ( arg ) ; arg = image ; } file_iformat = av_find_input_format ( arg ) ; file_oformat = guess_format ( arg , NULL , NULL ) ; if ( ! file_iformat & & ! file_oformat ) { fprintf ( stderr , Unknown input or output format : %s\n , arg ) ; exit ( 1 ) ; } }",0
"void init_vlc_rl ( RLTable * rl ) { int i , q ; init_vlc ( & rl - > vlc , 9 , rl - > n + 1 , & rl - > table_vlc[0][1] , 4 , 2 , & rl - > table_vlc[0][0] , 4 , 2 ) ; for ( q=0 ; q < 32 ; q + + ) { int qmul= q * 2 ; int qadd= ( q - 1 ) |1 ; if ( q==0 ) { qmul=1 ; qadd=0 ; } rl - > rl_vlc[q]= av_malloc ( rl - > vlc . table_size * sizeof ( RL_VLC_ELEM ) ) ; for ( i=0 ; i < rl - > vlc . table_size ; i + + ) { int code= rl - > vlc . table[i][0] ; int len = rl - > vlc . table[i][1] ; int level , run ; if ( len==0 ) { // illegal code run= 66 ; level= MAX_LEVEL ; } else if ( len < 0 ) { //more bits needed run= 0 ; level= code ; } else { if ( code==rl - > n ) { //esc run= 66 ; level= 0 ; } else { run= rl - > table_run [code] + 1 ; level= rl - > table_level[code] * qmul + qadd ; if ( code > = rl - > last ) run + =192 ; } } rl - > rl_vlc[q][i] . len= len ; rl - > rl_vlc[q][i] . level= level ; rl - > rl_vlc[q][i] . run= run ; } } }",1
"static int mxf_read_material_package ( MXFPackage * package , ByteIOContext * pb , int tag ) { switch ( tag ) { case 0x4403 : package - > tracks_count = get_be32 ( pb ) ; if ( package - > tracks_count > = UINT_MAX / sizeof ( UID ) ) return - 1 ; package - > tracks_refs = av_malloc ( package - > tracks_count * sizeof ( UID ) ) ; if ( ! package - > tracks_refs ) return - 1 ; url_fskip ( pb , 4 ) ; / * useless size of objects , always 16 according to specs * / get_buffer ( pb , ( uint8_t * ) package - > tracks_refs , package - > tracks_count * sizeof ( UID ) ) ; break ; } return 0 ; }",1
"static int select_rc_mode ( AVCodecContext * avctx , QSVEncContext * q ) { const char * rc_desc ; mfxU16 rc_mode ; int want_la = q - > la_depth > = 0 ; int want_qscale = ! ! ( avctx - > flags & AV_CODEC_FLAG_QSCALE ) ; int want_vcm = q - > vcm ; if ( want_la & & ! QSV_HAVE_LA ) { av_log ( avctx , AV_LOG_ERROR , Lookahead ratecontrol mode requested , but is not supported by this SDK version\n ) ; return AVERROR ( ENOSYS ) ; } if ( want_vcm & & ! QSV_HAVE_VCM ) { av_log ( avctx , AV_LOG_ERROR , VCM ratecontrol mode requested , but is not supported by this SDK version\n ) ; return AVERROR ( ENOSYS ) ; } if ( want_la + want_qscale + want_vcm > 1 ) { av_log ( avctx , AV_LOG_ERROR , More than one of : { constant qscale , lookahead , VCM } requested , only one of them can be used at a time . \n ) ; return AVERROR ( EINVAL ) ; } if ( want_qscale ) { rc_mode = MFX_RATECONTROL_CQP ; rc_desc = constant quantization parameter ( CQP ) ; } if QSV_HAVE_VCM else if ( want_vcm ) { rc_mode = MFX_RATECONTROL_VCM ; rc_desc = video conferencing mode ( VCM ) ; } endif if QSV_HAVE_LA else if ( want_la ) { rc_mode = MFX_RATECONTROL_LA ; rc_desc = VBR with lookahead ( LA ) ; if QSV_HAVE_ICQ if ( avctx - > global_quality > 0 ) { rc_mode = MFX_RATECONTROL_LA_ICQ ; rc_desc = intelligent constant quality with lookahead ( LA_ICQ ) ; } endif } endif if QSV_HAVE_ICQ else if ( avctx - > global_quality > 0 ) { rc_mode = MFX_RATECONTROL_ICQ ; rc_desc = intelligent constant quality ( ICQ ) ; } endif else if ( avctx - > rc_max_rate == avctx - > bit_rate ) { rc_mode = MFX_RATECONTROL_CBR ; rc_desc = constant bitrate ( CBR ) ; } else if ( ! avctx - > rc_max_rate ) { rc_mode = MFX_RATECONTROL_AVBR ; rc_desc = average variable bitrate ( AVBR ) ; } else { rc_mode = MFX_RATECONTROL_VBR ; rc_desc = variable bitrate ( VBR ) ; } q - > param . mfx . RateControlMethod = rc_mode ; av_log ( avctx , AV_LOG_VERBOSE , Using the %s ratecontrol method\n , rc_desc ) ; return 0 ; }",0
"void ff_avg_h264_qpel4_mc00_msa ( uint8_t * dst , const uint8_t * src , ptrdiff_t stride ) { avg_width4_msa ( src , stride , dst , stride , 4 ) ; }",0
"static void put_pixels_y2_mmx ( UINT8 * block , const UINT8 * pixels , int line_size , int h ) { if 0 UINT8 * p ; const UINT8 * pix ; p = block ; pix = pixels ; MOVQ_ZERO ( mm7 ) ; MOVQ_WONE ( mm4 ) ; JUMPALIGN ( ) ; do { __asm __volatile ( movq %1 , %%mm0\n\t movq %2 , %%mm1\n\t movq %%mm0 , %%mm2\n\t movq %%mm1 , %%mm3\n\t punpcklbw %%mm7 , %%mm0\n\t punpcklbw %%mm7 , %%mm1\n\t punpckhbw %%mm7 , %%mm2\n\t punpckhbw %%mm7 , %%mm3\n\t paddusw %%mm1 , %%mm0\n\t paddusw %%mm3 , %%mm2\n\t paddusw %%mm4 , %%mm0\n\t paddusw %%mm4 , %%mm2\n\t psrlw 1 , %%mm0\n\t psrlw 1 , %%mm2\n\t packuswb %%mm2 , %%mm0\n\t movq %%mm0 , %0\n\t : =m ( * p ) : m ( * pix ) , m ( * ( pix + line_size ) ) : memory ) ; pix + = line_size ; p + = line_size ; } while ( - - h ) ; else __asm __volatile ( MOVQ_BFE ( %%mm7 ) lea ( %3 , %3 ) , %%eax \n\t movq ( %1 ) , %%mm0 \n\t . balign 8 \n\t 1 : \n\t movq ( %1 , %3 ) , %%mm1 \n\t movq ( %1 , %%eax ) , %%mm2 \n\t PAVG_MMX ( %%mm1 , %%mm0 ) movq %%mm6 , ( %2 ) \n\t PAVG_MMX ( %%mm2 , %%mm1 ) movq %%mm6 , ( %2 , %3 ) \n\t addl %%eax , %1 \n\t addl %%eax , %2 \n\t ifdef LONG_UNROLL movq ( %1 , %3 ) , %%mm1 \n\t movq ( %1 , %%eax ) , %%mm0 \n\t PAVG_MMX ( %%mm1 , %%mm2 ) movq %%mm6 , ( %2 ) \n\t PAVG_MMX ( %%mm0 , %%mm1 ) movq %%mm6 , ( %2 , %3 ) \n\t addl %%eax , %1 \n\t addl %%eax , %2 \n\t subl 4 , %0 \n\t else subl 2 , %0 \n\t endif jnz 1b \n\t : + g ( h ) , + S ( pixels ) , + D ( block ) : r ( line_size ) : eax , memory ) ; endif }",0
"static int mpeg4_decode_gop_header ( MpegEncContext * s , GetBitContext * gb ) { int hours , minutes , seconds ; if ( ! show_bits ( gb , 23 ) ) { av_log ( s - > avctx , AV_LOG_WARNING , GOP header invalid\n ) ; return - 1 ; } hours = get_bits ( gb , 5 ) ; minutes = get_bits ( gb , 6 ) ; skip_bits1 ( gb ) ; seconds = get_bits ( gb , 6 ) ; s - > time_base = seconds + 60 * ( minutes + 60 * hours ) ; skip_bits1 ( gb ) ; skip_bits1 ( gb ) ; return 0 ; }",0
"static av_cold int decode_close ( AVCodecContext * avctx ) { IVI5DecContext * ctx = avctx - > priv_data ; ff_ivi_free_buffers ( & ctx - > planes[0] ) ; if ( ctx - > frame . data[0] ) avctx - > release_buffer ( avctx , & ctx - > frame ) ; return 0 ; }",1
"static int input_get_buffer ( AVCodecContext * codec , AVFrame * pic ) { AVFilterContext * ctx = codec - > opaque ; AVFilterBufferRef * ref ; int perms = AV_PERM_WRITE ; int i , w , h , stride[4] ; unsigned edge ; int pixel_size ; av_assert0 ( codec - > flags & CODEC_FLAG_EMU_EDGE ) ; if ( codec - > codec - > capabilities & CODEC_CAP_NEG_LINESIZES ) perms |= AV_PERM_NEG_LINESIZES ; if ( pic - > buffer_hints & FF_BUFFER_HINTS_VALID ) { if ( pic - > buffer_hints & FF_BUFFER_HINTS_READABLE ) perms |= AV_PERM_READ ; if ( pic - > buffer_hints & FF_BUFFER_HINTS_PRESERVE ) perms |= AV_PERM_PRESERVE ; if ( pic - > buffer_hints & FF_BUFFER_HINTS_REUSABLE ) perms |= AV_PERM_REUSE2 ; } if ( pic - > reference ) perms |= AV_PERM_READ | AV_PERM_PRESERVE ; w = codec - > width ; h = codec - > height ; if ( av_image_check_size ( w , h , 0 , codec ) ) return - 1 ; avcodec_align_dimensions2 ( codec , & w , & h , stride ) ; edge = codec - > flags & CODEC_FLAG_EMU_EDGE ? 0 : avcodec_get_edge_width ( ) ; w + = edge < < 1 ; h + = edge < < 1 ; if ( ! ( ref = avfilter_get_video_buffer ( ctx - > outputs[0] , perms , w , h ) ) ) return - 1 ; pixel_size = av_pix_fmt_descriptors[ref - > format] . comp[0] . step_minus1 + 1 ; ref - > video - > w = codec - > width ; ref - > video - > h = codec - > height ; for ( i = 0 ; i < 4 ; i + + ) { unsigned hshift = ( i == 1 || i == 2 ) ? av_pix_fmt_descriptors[ref - > format] . log2_chroma_w : 0 ; unsigned vshift = ( i == 1 || i == 2 ) ? av_pix_fmt_descriptors[ref - > format] . log2_chroma_h : 0 ; if ( ref - > data[i] ) { ref - > data[i] + = ( ( edge * pixel_size ) > > hshift ) + ( ( edge * ref - > linesize[i] ) > > vshift ) ; } pic - > data[i] = ref - > data[i] ; pic - > linesize[i] = ref - > linesize[i] ; } pic - > opaque = ref ; pic - > age = INT_MAX ; pic - > type = FF_BUFFER_TYPE_USER ; pic - > reordered_opaque = codec - > reordered_opaque ; if ( codec - > pkt ) pic - > pkt_pts = codec - > pkt - > pts ; else pic - > pkt_pts = AV_NOPTS_VALUE ; return 0 ; }",1
"static int ftp_restart ( FTPContext * s , int64_t pos ) { char command[CONTROL_BUFFER_SIZE] ; const int rest_codes[] = { 350 , 0 } ; snprintf ( command , sizeof ( command ) , REST % PRId64 \r\n , pos ) ; if ( ! ftp_send_command ( s , command , rest_codes , NULL ) ) return AVERROR ( EIO ) ; return 0 ; }",0
"static int idcin_probe ( AVProbeData * p ) { unsigned int number ; / * * This is what you could call a probabilistic file check : Id CIN * files don ' t have a definite file signature . In lieu of such a marker , * perform sanity checks on the 5 32 - bit header fields : * width , height : greater than 0 , less than or equal to 1024 * audio sample rate : greater than or equal to 8000 , less than or * equal to 48000 , or 0 for no audio * audio sample width ( bytes/sample ) : 0 for no audio , or 1 or 2 * audio channels : 0 for no audio , or 1 or 2 * / / * cannot proceed without 20 bytes * / if ( p - > buf_size < 20 ) return 0 ; / * check the video width * / number = AV_RL32 ( & p - > buf[0] ) ; if ( ( number == 0 ) || ( number > 1024 ) ) return 0 ; / * check the video height * / number = AV_RL32 ( & p - > buf[4] ) ; if ( ( number == 0 ) || ( number > 1024 ) ) return 0 ; / * check the audio sample rate * / number = AV_RL32 ( & p - > buf[8] ) ; if ( ( number ! = 0 ) & & ( ( number < 8000 ) | ( number > 48000 ) ) ) return 0 ; / * check the audio bytes/sample * / number = AV_RL32 ( & p - > buf[12] ) ; if ( number > 2 ) return 0 ; / * check the audio channels * / number = AV_RL32 ( & p - > buf[16] ) ; if ( number > 2 ) return 0 ; / * return half certainly since this check is a bit sketchy * / return AVPROBE_SCORE_MAX / 2 ; }",0
"static int av_seek_frame_generic ( AVFormatContext * s , int stream_index , int64_t timestamp ) { int index ; AVStream * st ; AVIndexEntry * ie ; if ( ! s - > index_built ) { if ( is_raw_stream ( s ) ) { av_build_index_raw ( s ) ; } else { return - 1 ; } s - > index_built = 1 ; } if ( stream_index < 0 ) stream_index = 0 ; st = s - > streams[stream_index] ; index = index_search_timestamp ( st - > index_entries , st - > nb_index_entries , timestamp ) ; if ( index < 0 ) return - 1 ; / * now we have found the index , we can seek * / ie = & st - > index_entries[index] ; av_read_frame_flush ( s ) ; url_fseek ( & s - > pb , ie - > pos , SEEK_SET ) ; st - > cur_dts = ie - > timestamp ; return 0 ; }",0
"static int read_key ( void ) { if defined ( HAVE_CONIO_H ) if ( kbhit ( ) ) return ( getch ( ) ) ; elif defined ( HAVE_TERMIOS_H ) int n = 1 ; unsigned char ch ; ifndef CONFIG_BEOS_NETSERVER struct timeval tv ; fd_set rfds ; FD_ZERO ( & rfds ) ; FD_SET ( 0 , & rfds ) ; tv . tv_sec = 0 ; tv . tv_usec = 0 ; n = select ( 1 , & rfds , NULL , NULL , & tv ) ; endif if ( n > 0 ) { n = read ( 0 , & ch , 1 ) ; if ( n == 1 ) return ch ; return n ; } endif return - 1 ; }",0
"theora_gptopts ( AVFormatContext * ctx , int idx , uint64_t gp , int64_t * dts ) { struct ogg * ogg = ctx - > priv_data ; struct ogg_stream * os = ogg - > streams + idx ; struct theora_params * thp = os - > private ; uint64_t iframe = gp > > thp - > gpshift ; uint64_t pframe = gp & thp - > gpmask ; if ( thp - > version < 0x030201 ) iframe + + ; if ( ! pframe ) os - > pflags |= AV_PKT_FLAG_KEY ; if ( dts ) * dts = iframe + pframe ; return iframe + pframe ; }",0
"static int mxf_read_index_table_segment ( void * arg , AVIOContext * pb , int tag , int size , UID uid ) { MXFIndexTableSegment * segment = arg ; switch ( tag ) { case 0x3F05 : segment - > edit_unit_byte_count = avio_rb32 ( pb ) ; av_dlog ( NULL , EditUnitByteCount %d\n , segment - > edit_unit_byte_count ) ; break ; case 0x3F06 : segment - > index_sid = avio_rb32 ( pb ) ; av_dlog ( NULL , IndexSID %d\n , segment - > index_sid ) ; break ; case 0x3F07 : segment - > body_sid = avio_rb32 ( pb ) ; av_dlog ( NULL , BodySID %d\n , segment - > body_sid ) ; break ; case 0x3F08 : segment - > slice_count = avio_r8 ( pb ) ; av_dlog ( NULL , SliceCount %d\n , segment - > slice_count ) ; break ; case 0x3F09 : av_dlog ( NULL , DeltaEntryArray found\n ) ; return mxf_read_delta_entry_array ( pb , segment ) ; case 0x3F0A : av_dlog ( NULL , IndexEntryArray found\n ) ; return mxf_read_index_entry_array ( pb , segment ) ; case 0x3F0B : segment - > index_edit_rate . num = avio_rb32 ( pb ) ; segment - > index_edit_rate . den = avio_rb32 ( pb ) ; av_dlog ( NULL , IndexEditRate %d/%d\n , segment - > index_edit_rate . num , segment - > index_edit_rate . den ) ; break ; case 0x3F0C : segment - > index_start_position = avio_rb64 ( pb ) ; av_dlog ( NULL , IndexStartPosition % PRId64 \n , segment - > index_start_position ) ; break ; case 0x3F0D : segment - > index_duration = avio_rb64 ( pb ) ; av_dlog ( NULL , IndexDuration % PRId64 \n , segment - > index_duration ) ; break ; } return 0 ; }",1
"static void av_build_index_raw ( AVFormatContext * s ) { AVPacket pkt1 , * pkt = & pkt1 ; int ret ; AVStream * st ; st = s - > streams[0] ; av_read_frame_flush ( s ) ; url_fseek ( & s - > pb , s - > data_offset , SEEK_SET ) ; for ( ; ; ) { ret = av_read_frame ( s , pkt ) ; if ( ret < 0 ) break ; if ( pkt - > stream_index == 0 & & st - > parser & & ( pkt - > flags & PKT_FLAG_KEY ) ) { add_index_entry ( st , st - > parser - > frame_offset , pkt - > dts , AVINDEX_KEYFRAME ) ; } av_free_packet ( pkt ) ; } }",0
"SwsContext * sws_getContext ( int srcW , int srcH , enum PixelFormat srcFormat , int dstW , int dstH , enum PixelFormat dstFormat , int flags , SwsFilter * srcFilter , SwsFilter * dstFilter , const double * param ) { SwsContext * c ; int i ; int usesVFilter , usesHFilter ; int unscaled ; int srcRange , dstRange ; SwsFilter dummyFilter= { NULL , NULL , NULL , NULL } ; if ARCH_X86 if ( flags & SWS_CPU_CAPS_MMX ) __asm__ volatile ( emms\n\t : : : memory ) ; endif if ! CONFIG_RUNTIME_CPUDETECT //ensure that the flags match the compiled variant if cpudetect is off flags & = ( SWS_CPU_CAPS_MMX|SWS_CPU_CAPS_MMX2|SWS_CPU_CAPS_3DNOW|SWS_CPU_CAPS_ALTIVEC|SWS_CPU_CAPS_BFIN ) ; flags |= ff_hardcodedcpuflags ( ) ; endif / * CONFIG_RUNTIME_CPUDETECT * / if ( ! rgb15to16 ) sws_rgb2rgb_init ( flags ) ; unscaled = ( srcW == dstW & & srcH == dstH ) ; srcRange = handle_jpeg ( & srcFormat ) ; dstRange = handle_jpeg ( & dstFormat ) ; if ( ! isSupportedIn ( srcFormat ) ) { av_log ( NULL , AV_LOG_ERROR , swScaler : %s is not supported as input pixel format\n , sws_format_name ( srcFormat ) ) ; return NULL ; } if ( ! isSupportedOut ( dstFormat ) ) { av_log ( NULL , AV_LOG_ERROR , swScaler : %s is not supported as output pixel format\n , sws_format_name ( dstFormat ) ) ; return NULL ; } i= flags & ( SWS_POINT |SWS_AREA |SWS_BILINEAR |SWS_FAST_BILINEAR |SWS_BICUBIC |SWS_X |SWS_GAUSS |SWS_LANCZOS |SWS_SINC |SWS_SPLINE |SWS_BICUBLIN ) ; if ( ! i || ( i & ( i - 1 ) ) ) { av_log ( NULL , AV_LOG_ERROR , swScaler : Exactly one scaler algorithm must be chosen\n ) ; return NULL ; } / * sanity check * / if ( srcW < 4 || srcH < 1 || dstW < 8 || dstH < 1 ) { //FIXME check if these are enough and try to lowwer them after fixing the relevant parts of the code av_log ( NULL , AV_LOG_ERROR , swScaler : %dx%d - > %dx%d is invalid scaling dimension\n , srcW , srcH , dstW , dstH ) ; return NULL ; } if ( srcW > VOFW || dstW > VOFW ) { av_log ( NULL , AV_LOG_ERROR , swScaler : Compile - time maximum width is AV_STRINGIFY ( VOFW ) change VOF/VOFW and recompile\n ) ; return NULL ; } if ( ! dstFilter ) dstFilter= & dummyFilter ; if ( ! srcFilter ) srcFilter= & dummyFilter ; FF_ALLOCZ_OR_GOTO ( NULL , c , sizeof ( SwsContext ) , fail ) ; c - > av_class = & sws_context_class ; c - > srcW= srcW ; c - > srcH= srcH ; c - > dstW= dstW ; c - > dstH= dstH ; c - > lumXInc= ( ( srcW < < 16 ) + ( dstW > > 1 ) ) /dstW ; c - > lumYInc= ( ( srcH < < 16 ) + ( dstH > > 1 ) ) /dstH ; c - > flags= flags ; c - > dstFormat= dstFormat ; c - > srcFormat= srcFormat ; c - > dstFormatBpp = av_get_bits_per_pixel ( & av_pix_fmt_descriptors[dstFormat] ) ; c - > srcFormatBpp = av_get_bits_per_pixel ( & av_pix_fmt_descriptors[srcFormat] ) ; c - > vRounder= 4 * 0x0001000100010001ULL ; usesVFilter = ( srcFilter - > lumV & & srcFilter - > lumV - > length > 1 ) || ( srcFilter - > chrV & & srcFilter - > chrV - > length > 1 ) || ( dstFilter - > lumV & & dstFilter - > lumV - > length > 1 ) || ( dstFilter - > chrV & & dstFilter - > chrV - > length > 1 ) ; usesHFilter = ( srcFilter - > lumH & & srcFilter - > lumH - > length > 1 ) || ( srcFilter - > chrH & & srcFilter - > chrH - > length > 1 ) || ( dstFilter - > lumH & & dstFilter - > lumH - > length > 1 ) || ( dstFilter - > chrH & & dstFilter - > chrH - > length > 1 ) ; getSubSampleFactors ( & c - > chrSrcHSubSample , & c - > chrSrcVSubSample , srcFormat ) ; getSubSampleFactors ( & c - > chrDstHSubSample , & c - > chrDstVSubSample , dstFormat ) ; // reuse chroma for 2 pixels RGB/BGR unless user wants full chroma interpolation if ( isAnyRGB ( dstFormat ) & & ! ( flags & SWS_FULL_CHR_H_INT ) ) c - > chrDstHSubSample=1 ; // drop some chroma lines if the user wants it c - > vChrDrop= ( flags & SWS_SRC_V_CHR_DROP_MASK ) > > SWS_SRC_V_CHR_DROP_SHIFT ; c - > chrSrcVSubSample + = c - > vChrDrop ; // drop every other pixel for chroma calculation unless user wants full chroma if ( isAnyRGB ( srcFormat ) & & ! ( flags & SWS_FULL_CHR_H_INP ) & & srcFormat ! =PIX_FMT_RGB8 & & srcFormat ! =PIX_FMT_BGR8 & & srcFormat ! =PIX_FMT_RGB4 & & srcFormat ! =PIX_FMT_BGR4 & & srcFormat ! =PIX_FMT_RGB4_BYTE & & srcFormat ! =PIX_FMT_BGR4_BYTE & & ( ( dstW > > c - > chrDstHSubSample ) < = ( srcW > > 1 ) || ( flags & ( SWS_FAST_BILINEAR|SWS_POINT ) ) ) ) c - > chrSrcHSubSample=1 ; if ( param ) { c - > param[0] = param[0] ; c - > param[1] = param[1] ; } else { c - > param[0] = c - > param[1] = SWS_PARAM_DEFAULT ; } // Note the - ( ( - x ) > > y ) is so that we always round toward + inf . c - > chrSrcW= - ( ( - srcW ) > > c - > chrSrcHSubSample ) ; c - > chrSrcH= - ( ( - srcH ) > > c - > chrSrcVSubSample ) ; c - > chrDstW= - ( ( - dstW ) > > c - > chrDstHSubSample ) ; c - > chrDstH= - ( ( - dstH ) > > c - > chrDstVSubSample ) ; sws_setColorspaceDetails ( c , ff_yuv2rgb_coeffs[SWS_CS_DEFAULT] , srcRange , ff_yuv2rgb_coeffs[SWS_CS_DEFAULT] / * FIXME * / , dstRange , 0 , 1 < < 16 , 1 < < 16 ) ; / * unscaled special cases * / if ( unscaled & & ! usesHFilter & & ! usesVFilter & & ( srcRange == dstRange || isAnyRGB ( dstFormat ) ) ) { ff_get_unscaled_swscale ( c ) ; if ( c - > swScale ) { if ( flags & SWS_PRINT_INFO ) av_log ( c , AV_LOG_INFO , using unscaled %s - > %s special converter\n , sws_format_name ( srcFormat ) , sws_format_name ( dstFormat ) ) ; return c ; } } if ( flags & SWS_CPU_CAPS_MMX2 ) { c - > canMMX2BeUsed= ( dstW > =srcW & & ( dstW & 31 ) ==0 & & ( srcW & 15 ) ==0 ) ? 1 : 0 ; if ( ! c - > canMMX2BeUsed & & dstW > =srcW & & ( srcW & 15 ) ==0 & &",0
"void FUNC ( ff_emulated_edge_mc ) ( uint8_t * buf , const uint8_t * src , int linesize , int block_w , int block_h , int src_x , int src_y , int w , int h ) { int x , y ; int start_y , start_x , end_y , end_x ; if ( src_y > = h ) { src + = ( h - 1 - src_y ) * linesize ; src_y=h - 1 ; } else if ( src_y < = - block_h ) { src + = ( 1 - block_h - src_y ) * linesize ; src_y=1 - block_h ; } if ( src_x > = w ) { src + = ( w - 1 - src_x ) * sizeof ( pixel ) ; src_x=w - 1 ; } else if ( src_x < = - block_w ) { src + = ( 1 - block_w - src_x ) * sizeof ( pixel ) ; src_x=1 - block_w ; } start_y= FFMAX ( 0 , - src_y ) ; start_x= FFMAX ( 0 , - src_x ) ; end_y= FFMIN ( block_h , h - src_y ) ; end_x= FFMIN ( block_w , w - src_x ) ; av_assert2 ( start_y < end_y & & block_h ) ; av_assert2 ( start_x < end_x & & block_w ) ; w = end_x - start_x ; src + = start_y * linesize + start_x * sizeof ( pixel ) ; buf + = start_x * sizeof ( pixel ) ; //top for ( y=0 ; y < start_y ; y + + ) { memcpy ( buf , src , w * sizeof ( pixel ) ) ; buf + = linesize ; } // copy existing part for ( ; y < end_y ; y + + ) { memcpy ( buf , src , w * sizeof ( pixel ) ) ; src + = linesize ; buf + = linesize ; } //bottom src - = linesize ; for ( ; y < block_h ; y + + ) { memcpy ( buf , src , w * sizeof ( pixel ) ) ; buf + = linesize ; } buf - = block_h * linesize + start_x * sizeof ( pixel ) ; while ( block_h - - ) { pixel * bufp = ( pixel * ) buf ; //left for ( x=0 ; x < start_x ; x + + ) { bufp[x] = bufp[start_x] ; } //right for ( x=end_x ; x < block_w ; x + + ) { bufp[x] = bufp[end_x - 1] ; } buf + = linesize ; } }",0
"static void test_separators ( const AVDictionary * m , const char pair , const char val ) { AVDictionary * dict = NULL ; char pairs[] = { pair , ' \0 ' } ; char vals[] = { val , ' \0 ' } ; char * buffer = NULL ; av_dict_copy ( & dict , m , 0 ) ; print_dict ( dict ) ; av_dict_get_string ( dict , & buffer , val , pair ) ; printf ( %s\n , buffer ) ; av_dict_free ( & dict ) ; av_dict_parse_string ( & dict , buffer , vals , pairs , 0 ) ; av_freep ( & buffer ) ; print_dict ( dict ) ; av_dict_free ( & dict ) ; }",0
"static inline int decode_ac_coeffs ( GetBitContext * gb , int16_t * out , int blocks_per_slice , int plane_size_factor , const uint8_t * scan ) { int pos , block_mask , run , level , sign , run_cb_index , lev_cb_index ; int max_coeffs , bits_left ; / * set initial prediction values * / run = 4 ; level = 2 ; max_coeffs = blocks_per_slice < < 6 ; block_mask = blocks_per_slice - 1 ; for ( pos = blocks_per_slice - 1 ; pos < max_coeffs ; ) { run_cb_index = ff_prores_run_to_cb_index[FFMIN ( run , 15 ) ] ; lev_cb_index = ff_prores_lev_to_cb_index[FFMIN ( level , 9 ) ] ; bits_left = get_bits_left ( gb ) ; if ( bits_left < = 0 || ( bits_left < = 8 & & ! show_bits ( gb , bits_left ) ) ) return 0 ; run = decode_vlc_codeword ( gb , ff_prores_ac_codebook[run_cb_index] ) ; if ( run < 0 ) return AVERROR_INVALIDDATA ; bits_left = get_bits_left ( gb ) ; if ( bits_left < = 0 || ( bits_left < = 8 & & ! show_bits ( gb , bits_left ) ) ) return AVERROR_INVALIDDATA ; level = decode_vlc_codeword ( gb , ff_prores_ac_codebook[lev_cb_index] ) + 1 ; if ( level < 0 ) return AVERROR_INVALIDDATA ; pos + = run + 1 ; if ( pos > = max_coeffs ) break ; sign = get_sbits ( gb , 1 ) ; out[ ( ( pos & block_mask ) < < 6 ) + scan[pos > > plane_size_factor]] = ( level sign ) - sign ; } return 0 ; }",0
"static int flac_read_header ( AVFormatContext * s ) { int ret , metadata_last=0 , metadata_type , metadata_size , found_streaminfo=0 ; uint8_t header[4] ; uint8_t * buffer=NULL ; FLACDecContext * flac = s - > priv_data ; AVStream * st = avformat_new_stream ( s , NULL ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; st - > codecpar - > codec_type = AVMEDIA_TYPE_AUDIO ; st - > codecpar - > codec_id = AV_CODEC_ID_FLAC ; st - > need_parsing = AVSTREAM_PARSE_FULL_RAW ; / * the parameters will be extracted from the compressed bitstream * / / * if fLaC marker is not found , assume there is no header * / if ( avio_rl32 ( s - > pb ) ! = MKTAG ( ' f ' , ' L ' , ' a ' , ' C ' ) ) { avio_seek ( s - > pb , - 4 , SEEK_CUR ) ; return 0 ; } / * process metadata blocks * / while ( ! avio_feof ( s - > pb ) & & ! metadata_last ) { avio_read ( s - > pb , header , 4 ) ; flac_parse_block_header ( header , & metadata_last , & metadata_type , & metadata_size ) ; switch ( metadata_type ) { / * allocate and read metadata block for supported types * / case FLAC_METADATA_TYPE_STREAMINFO : case FLAC_METADATA_TYPE_CUESHEET : case FLAC_METADATA_TYPE_PICTURE : case FLAC_METADATA_TYPE_VORBIS_COMMENT : case FLAC_METADATA_TYPE_SEEKTABLE : buffer = av_mallocz ( metadata_size + AV_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! buffer ) { return AVERROR ( ENOMEM ) ; } if ( avio_read ( s - > pb , buffer , metadata_size ) ! = metadata_size ) { RETURN_ERROR ( AVERROR ( EIO ) ) ; } break ; / * skip metadata block for unsupported types * / default : ret = avio_skip ( s - > pb , metadata_size ) ; if ( ret < 0 ) return ret ; } if ( metadata_type == FLAC_METADATA_TYPE_STREAMINFO ) { uint32_t samplerate ; uint64_t samples ; / * STREAMINFO can only occur once * / if ( found_streaminfo ) { RETURN_ERROR ( AVERROR_INVALIDDATA ) ; } if ( metadata_size ! = FLAC_STREAMINFO_SIZE ) { RETURN_ERROR ( AVERROR_INVALIDDATA ) ; } found_streaminfo = 1 ; st - > codecpar - > extradata = buffer ; st - > codecpar - > extradata_size = metadata_size ; buffer = NULL ; / * get sample rate and sample count from STREAMINFO header ; * other parameters will be extracted by the parser * / samplerate = AV_RB24 ( st - > codecpar - > extradata + 10 ) > > 4 ; samples = ( AV_RB64 ( st - > codecpar - > extradata + 13 ) > > 24 ) & ( ( 1ULL < < 36 ) - 1 ) ; / * set time base and duration * / if ( samplerate > 0 ) { avpriv_set_pts_info ( st , 64 , 1 , samplerate ) ; if ( samples > 0 ) st - > duration = samples ; } } else if ( metadata_type == FLAC_METADATA_TYPE_CUESHEET ) { uint8_t isrc[13] ; uint64_t start ; const uint8_t * offset ; int i , chapters , track , ti ; if ( metadata_size < 431 ) RETURN_ERROR ( AVERROR_INVALIDDATA ) ; offset = buffer + 395 ; chapters = bytestream_get_byte ( & offset ) - 1 ; if ( chapters < = 0 ) RETURN_ERROR ( AVERROR_INVALIDDATA ) ; for ( i = 0 ; i < chapters ; i + + ) { if ( offset + 36 - buffer > metadata_size ) RETURN_ERROR ( AVERROR_INVALIDDATA ) ; start = bytestream_get_be64 ( & offset ) ; track = bytestream_get_byte ( & offset ) ; bytestream_get_buffer ( & offset , isrc , 12 ) ; isrc[12] = 0 ; offset + = 14 ; ti = bytestream_get_byte ( & offset ) ; if ( ti < = 0 ) RETURN_ERROR ( AVERROR_INVALIDDATA ) ; offset + = ti * 12 ; avpriv_new_chapter ( s , track , st - > time_base , start , AV_NOPTS_VALUE , isrc ) ; } av_freep ( & buffer ) ; } else if ( metadata_type == FLAC_METADATA_TYPE_PICTURE ) { ret = ff_flac_parse_picture ( s , buffer , metadata_size ) ; av_freep ( & buffer ) ; if ( ret < 0 ) { av_log ( s , AV_LOG_ERROR , Error parsing attached picture . \n ) ; return ret ; } } else if ( metadata_type == FLAC_METADATA_TYPE_SEEKTABLE ) { const uint8_t * seekpoint = buffer ; int i , seek_point_count = metadata_size/SEEKPOINT_SIZE ; flac - > found_seektable = 1 ; if ( ( s - > flags & AVFMT_FLAG_FAST_SEEK ) ) { for ( i=0 ; i < seek_point_count ; i + + ) { int64_t timestamp = bytestream_get_be64 ( & seekpoint ) ; int64_t pos = bytestream_get_be64 ( & seekpoint ) ; / * skip number of samples * / bytestream_get_be16 ( & seekpoint ) ; av_add_index_entry ( st , pos , timestamp , 0 , 0 , AVINDEX_KEYFRAME ) ; } } av_freep ( & buffer ) ; } else { / * STREAMINFO must be the first block * / if ( ! found_streaminfo ) { RETURN_ERROR ( AVERROR_INVALIDDATA ) ; } / * process supported blocks other than STREAMINFO * / if ( metadata_type == FLAC_METADATA_TYPE_VORBIS_COMMENT ) { AVDictionaryEntry * chmask ; ret = ff_vorbis_comment ( s , & s - > metadata , buffer , metadata_size , 1 ) ; if ( ret < 0 ) { av_log ( s , AV_LOG_WARNING , error parsing VorbisComment metadata\n ) ; } else if ( ret > 0 ) { s - > event_flags |= AVFMT_EVENT_FLAG_METADATA_UPDATED ; } / * parse the channels mask if present * / chmask = av_dict_get ( s - > metadata , WAVEFORMATEXTENSIBLE_CHANNEL_MASK , NULL , 0 ) ; if ( chmask ) { uint64_t mask = strtol ( chmask - > value , NULL , 0 ) ; if ( ! mask || mask & 0x3ffffULL ) { av_log ( s , AV_LOG_WARNING , Invalid value of WAVEFORMATEXTENSIBLE_CHANNEL_MASK\n ) ; } else { st - > codecpar - > channel_layout = mask ; av_dict_set ( & s - > metadata , WAVEFORMATEXTENSIBLE_CHANNEL_MASK , NULL , 0 ) ; } } } av_freep ( & buffer ) ; } } ret = ff_replaygain_export ( st , s - > metadata ) ; if ( ret < 0 ) return ret ; reset_index_position ( avio_tell ( s - > pb ) , st ) ; return 0 ; fail : av_free ( buffer ) ; return ret ; }",0
"static int mov_write_video_tag ( AVIOContext * pb , MOVMuxContext * mov , MOVTrack * track ) { int64_t pos = avio_tell ( pb ) ; char compressor_name[32] = { 0 } ; avio_wb32 ( pb , 0 ) ; / * size * / avio_wl32 ( pb , track - > tag ) ; // store it byteswapped avio_wb32 ( pb , 0 ) ; / * Reserved * / avio_wb16 ( pb , 0 ) ; / * Reserved * / avio_wb16 ( pb , 1 ) ; / * Data - reference index * / avio_wb16 ( pb , 0 ) ; / * Codec stream version * / avio_wb16 ( pb , 0 ) ; / * Codec stream revision ( =0 ) * / if ( track - > mode == MODE_MOV ) { ffio_wfourcc ( pb , FFMP ) ; / * Vendor * / if ( track - > enc - > codec_id == AV_CODEC_ID_RAWVIDEO ) { avio_wb32 ( pb , 0 ) ; / * Temporal Quality * / avio_wb32 ( pb , 0x400 ) ; / * Spatial Quality = lossless * / } else { avio_wb32 ( pb , 0x200 ) ; / * Temporal Quality = normal * / avio_wb32 ( pb , 0x200 ) ; / * Spatial Quality = normal * / } } else { avio_wb32 ( pb , 0 ) ; / * Reserved * / avio_wb32 ( pb , 0 ) ; / * Reserved * / avio_wb32 ( pb , 0 ) ; / * Reserved * / } avio_wb16 ( pb , track - > enc - > width ) ; / * Video width * / avio_wb16 ( pb , track - > height ) ; / * Video height * / avio_wb32 ( pb , 0x00480000 ) ; / * Horizontal resolution 72dpi * / avio_wb32 ( pb , 0x00480000 ) ; / * Vertical resolution 72dpi * / avio_wb32 ( pb , 0 ) ; / * Data size ( = 0 ) * / avio_wb16 ( pb , 1 ) ; / * Frame count ( = 1 ) * / / * FIXME not sure , ISO 14496 - 1 draft where it shall be set to 0 * / find_compressor ( compressor_name , 32 , track ) ; avio_w8 ( pb , strlen ( compressor_name ) ) ; avio_write ( pb , compressor_name , 31 ) ; if ( track - > mode == MODE_MOV & & track - > enc - > bits_per_coded_sample ) avio_wb16 ( pb , track - > enc - > bits_per_coded_sample ) ; else avio_wb16 ( pb , 0x18 ) ; / * Reserved * / avio_wb16 ( pb , 0xffff ) ; / * Reserved * / if ( track - > tag == MKTAG ( ' m ' , ' p ' , ' 4 ' , ' v ' ) ) mov_write_esds_tag ( pb , track ) ; else if ( track - > enc - > codec_id == AV_CODEC_ID_H263 ) mov_write_d263_tag ( pb ) ; else if ( track - > enc - > codec_id == AV_CODEC_ID_AVUI || track - > enc - > codec_id == AV_CODEC_ID_SVQ3 ) { mov_write_extradata_tag ( pb , track ) ; avio_wb32 ( pb , 0 ) ; } else if ( track - > enc - > codec_id == AV_CODEC_ID_DNXHD ) mov_write_avid_tag ( pb , track ) ; else if ( track - > enc - > codec_id == AV_CODEC_ID_HEVC ) mov_write_hvcc_tag ( pb , track ) ; else if ( track - > enc - > codec_id == AV_CODEC_ID_H264 & & ! TAG_IS_AVCI ( track - > tag ) ) { mov_write_avcc_tag ( pb , track ) ; if ( track - > mode == MODE_IPOD ) mov_write_uuid_tag_ipod ( pb ) ; } else if ( track - > enc - > codec_id == AV_CODEC_ID_VC1 & & track - > vos_len > 0 ) mov_write_dvc1_tag ( pb , track ) ; else if ( track - > enc - > codec_id == AV_CODEC_ID_VP6F || track - > enc - > codec_id == AV_CODEC_ID_VP6A ) { / * Don ' t write any potential extradata here - the cropping * is signalled via the normal width/height fields . * / } else if ( track - > enc - > codec_id == AV_CODEC_ID_R10K ) { if ( track - > enc - > codec_tag == MKTAG ( ' R ' , ' 1 ' , ' 0 ' , ' k ' ) ) mov_write_dpxe_tag ( pb , track ) ; } else if ( track - > vos_len > 0 ) mov_write_glbl_tag ( pb , track ) ; if ( track - > enc - > codec_id ! = AV_CODEC_ID_H264 & & track - > enc - > codec_id ! = AV_CODEC_ID_MPEG4 & & track - > enc - > codec_id ! = AV_CODEC_ID_DNXHD ) if ( track - > enc - > field_order ! = AV_FIELD_UNKNOWN ) mov_write_fiel_tag ( pb , track ) ; if ( mov - > flags & FF_MOV_FLAG_WRITE_COLR ) mov_write_colr_tag ( pb , track ) ; if ( track - > enc - > sample_aspect_ratio . den & & track - > enc - > sample_aspect_ratio . num & & track - > enc - > sample_aspect_ratio . den ! = track - > enc - > sample_aspect_ratio . num ) { mov_write_pasp_tag ( pb , track ) ; } return update_size ( pb , pos ) ; }",1
"static int ogg_write_packet ( AVFormatContext * avfcontext , int stream_index , const uint8_t * buf , int size , int64_t pts ) { OggContext * context = avfcontext - > priv_data ; AVCodecContext * avctx= & avfcontext - > streams[stream_index] - > codec ; ogg_packet * op= & context - > op ; ogg_page og ; pts= av_rescale ( pts , avctx - > sample_rate , AV_TIME_BASE ) ; if ( ! size ) { // av_log ( avfcontext , AV_LOG_DEBUG , zero packet\n ) ; return 0 ; } // av_log ( avfcontext , AV_LOG_DEBUG , M%d\n , size ) ; / * flush header packets so audio starts on a new page * / if ( ! context - > header_handled ) { while ( ogg_stream_flush ( & context - > os , & og ) ) { put_buffer ( & avfcontext - > pb , og . header , og . header_len ) ; put_buffer ( & avfcontext - > pb , og . body , og . body_len ) ; put_flush_packet ( & avfcontext - > pb ) ; } context - > header_handled = 1 ; } op - > packet = ( uint8_t * ) buf ; op - > bytes = size ; op - > b_o_s = op - > packetno == 0 ; op - > granulepos= pts ; / * correct the fields in the packet - - essential for streaming * / ogg_stream_packetin ( & context - > os , op ) ; while ( ogg_stream_pageout ( & context - > os , & og ) ) { put_buffer ( & avfcontext - > pb , og . header , og . header_len ) ; put_buffer ( & avfcontext - > pb , og . body , og . body_len ) ; put_flush_packet ( & avfcontext - > pb ) ; } op - > packetno + + ; return 0 ; }",0
"static int mpeg_mux_init ( AVFormatContext * ctx ) { MpegMuxContext * s = ctx - > priv_data ; int bitrate , i , mpa_id , mpv_id , ac3_id ; AVStream * st ; StreamInfo * stream ; s - > packet_number = 0 ; s - > is_vcd = ( ctx - > oformat == & mpeg1vcd_mux ) ; s - > is_mpeg2 = ( ctx - > oformat == & mpeg2vob_mux ) ; if ( s - > is_vcd ) s - > packet_size = 2324 ; / * VCD packet size * / else s - > packet_size = 2048 ; / * startcode ( 4 ) + length ( 2 ) + flags ( 1 ) * / s - > packet_data_max_size = s - > packet_size - 7 ; if ( s - > is_mpeg2 ) s - > packet_data_max_size - = 2 ; s - > audio_bound = 0 ; s - > video_bound = 0 ; mpa_id = AUDIO_ID ; ac3_id = 0x80 ; mpv_id = VIDEO_ID ; s - > scr_stream_index = - 1 ; for ( i=0 ; i < ctx - > nb_streams ; i + + ) { st = ctx - > streams[i] ; stream = av_mallocz ( sizeof ( StreamInfo ) ) ; if ( ! stream ) goto fail ; st - > priv_data = stream ; switch ( st - > codec . codec_type ) { case CODEC_TYPE_AUDIO : if ( st - > codec . codec_id == CODEC_ID_AC3 ) stream - > id = ac3_id + + ; else stream - > id = mpa_id + + ; stream - > max_buffer_size = 4 * 1024 ; s - > audio_bound + + ; break ; case CODEC_TYPE_VIDEO : / * by default , video is used for the SCR computation * / if ( s - > scr_stream_index == - 1 ) s - > scr_stream_index = i ; stream - > id = mpv_id + + ; stream - > max_buffer_size = 46 * 1024 ; s - > video_bound + + ; break ; default : av_abort ( ) ; } } / * if no SCR , use first stream ( audio ) * / if ( s - > scr_stream_index == - 1 ) s - > scr_stream_index = 0 ; / * we increase slightly the bitrate to take into account the headers . XXX : compute it exactly * / bitrate = 2000 ; for ( i=0 ; i < ctx - > nb_streams ; i + + ) { st = ctx - > streams[i] ; bitrate + = st - > codec . bit_rate ; } s - > mux_rate = ( bitrate + ( 8 * 50 ) - 1 ) / ( 8 * 50 ) ; if ( s - > is_vcd || s - > is_mpeg2 ) / * every packet * / s - > pack_header_freq = 1 ; else / * every 2 seconds * / s - > pack_header_freq = 2 * bitrate / s - > packet_size / 8 ; / * the above seems to make pack_header_freq zero sometimes * / if ( s - > pack_header_freq == 0 ) s - > pack_header_freq = 1 ; if ( s - > is_mpeg2 ) / * every 200 packets . Need to look at the spec . * / s - > system_header_freq = s - > pack_header_freq * 40 ; else if ( s - > is_vcd ) / * every 40 packets , this is my invention * / s - > system_header_freq = s - > pack_header_freq * 40 ; else s - > system_header_freq = s - > pack_header_freq * 5 ; for ( i=0 ; i < ctx - > nb_streams ; i + + ) { stream = ctx - > streams[i] - > priv_data ; stream - > buffer_ptr = 0 ; stream - > packet_number = 0 ; stream - > start_pts = AV_NOPTS_VALUE ; stream - > start_dts = AV_NOPTS_VALUE ; } s - > last_scr = 0 ; return 0 ; fail : for ( i=0 ; i < ctx - > nb_streams ; i + + ) { av_free ( ctx - > streams[i] - > priv_data ) ; } return - ENOMEM ; }",1
"void * av_malloc ( size_t size ) { void * ptr = NULL ; if CONFIG_MEMALIGN_HACK long diff ; endif / * let ' s disallow possible ambiguous cases * / if ( size > ( INT_MAX - 32 ) ) return NULL ; if CONFIG_MEMALIGN_HACK ptr = malloc ( size + 32 ) ; if ( ! ptr ) return ptr ; diff= ( ( - ( long ) ptr - 1 ) & 31 ) + 1 ; ptr = ( char * ) ptr + diff ; ( ( char * ) ptr ) [ - 1]= diff ; elif HAVE_POSIX_MEMALIGN if ( posix_memalign ( & ptr , 32 , size ) ) ptr = NULL ; elif HAVE_MEMALIGN ptr = memalign ( 32 , size ) ; / * Why 64 ? Indeed , we should align it : on 4 for 386 on 16 for 486 on 32 for 586 , PPro - K6 - III on 64 for K7 ( maybe for P3 too ) . Because L1 and L2 caches are aligned on those values . But I don ' t want to code such logic here ! * / / * Why 32 ? For AVX ASM . SSE / NEON needs only 16 . Why not larger ? Because I did not see a difference in benchmarks . . . * / / * benchmarks with P3 memalign ( 64 ) + 1 3071 , 3051 , 3032 memalign ( 64 ) + 2 3051 , 3032 , 3041 memalign ( 64 ) + 4 2911 , 2896 , 2915 memalign ( 64 ) + 8 2545 , 2554 , 2550 memalign ( 64 ) + 16 2543 , 2572 , 2563 memalign ( 64 ) + 32 2546 , 2545 , 2571 memalign ( 64 ) + 64 2570 , 2533 , 2558 BTW , malloc seems to do 8 - byte alignment by default here . * / else ptr = malloc ( size ) ; endif return ptr ; }",1
"static void decor_c ( int32_t * dst , const int32_t * src , int coeff , ptrdiff_t len ) { int i ; for ( i = 0 ; i < len ; i + + ) dst[i] + = ( int ) ( src[i] * ( SUINT ) coeff + ( 1 < < 2 ) ) > > 3 ; }",1
"static inline void RENAME ( rgb32to16 ) ( const uint8_t * src , uint8_t * dst , unsigned src_size ) { const uint8_t * s = src ; const uint8_t * end ; ifdef HAVE_MMX const uint8_t * mm_end ; endif uint16_t * d = ( uint16_t * ) dst ; end = s + src_size ; ifdef HAVE_MMX mm_end = end - 15 ; if 1 //is faster only if multiplies are reasonable fast ( FIXME figure out on which cpus this is faster , on Athlon its slightly faster ) asm volatile ( movq %3 , %%mm5 \n\t movq %4 , %%mm6 \n\t movq %5 , %%mm7 \n\t . balign 16 \n\t 1 : \n\t PREFETCH 32 ( %1 ) \n\t movd ( %1 ) , %%mm0 \n\t movd 4 ( %1 ) , %%mm3 \n\t punpckldq 8 ( %1 ) , %%mm0 \n\t punpckldq 12 ( %1 ) , %%mm3 \n\t movq %%mm0 , %%mm1 \n\t movq %%mm3 , %%mm4 \n\t pand %%mm6 , %%mm0 \n\t pand %%mm6 , %%mm3 \n\t pmaddwd %%mm7 , %%mm0 \n\t pmaddwd %%mm7 , %%mm3 \n\t pand %%mm5 , %%mm1 \n\t pand %%mm5 , %%mm4 \n\t por %%mm1 , %%mm0 \n\t por %%mm4 , %%mm3 \n\t psrld 5 , %%mm0 \n\t pslld 11 , %%mm3 \n\t por %%mm3 , %%mm0 \n\t MOVNTQ %%mm0 , ( %0 ) \n\t add 16 , %1 \n\t add 8 , %0 \n\t cmp %2 , %1 \n\t jb 1b \n\t : + r ( d ) , + r ( s ) : r ( mm_end ) , m ( mask3216g ) , m ( mask3216br ) , m ( mul3216 ) ) ; else __asm __volatile ( PREFETCH %0 : : m ( * src ) : memory ) ; __asm __volatile ( movq %0 , %%mm7\n\t movq %1 , %%mm6\n\t : : m ( red_16mask ) , m ( green_16mask ) ) ; while ( s < mm_end ) { __asm __volatile ( PREFETCH 32%1\n\t movd %1 , %%mm0\n\t movd 4%1 , %%mm3\n\t punpckldq 8%1 , %%mm0\n\t punpckldq 12%1 , %%mm3\n\t movq %%mm0 , %%mm1\n\t movq %%mm0 , %%mm2\n\t movq %%mm3 , %%mm4\n\t movq %%mm3 , %%mm5\n\t psrlq 3 , %%mm0\n\t psrlq 3 , %%mm3\n\t pand %2 , %%mm0\n\t pand %2 , %%mm3\n\t psrlq 5 , %%mm1\n\t psrlq 5 , %%mm4\n\t pand %%mm6 , %%mm1\n\t pand %%mm6 , %%mm4\n\t psrlq 8 , %%mm2\n\t psrlq 8 , %%mm5\n\t pand %%mm7 , %%mm2\n\t pand %%mm7 , %%mm5\n\t por %%mm1 , %%mm0\n\t por %%mm4 , %%mm3\n\t por %%mm2 , %%mm0\n\t por %%mm5 , %%mm3\n\t psllq 16 , %%mm3\n\t por %%mm3 , %%mm0\n\t MOVNTQ %%mm0 , %0\n\t : =m ( * d ) : m ( * s ) , m ( blue_16mask ) : memory ) ; d + = 4 ; s + = 16 ; } endif __asm __volatile ( SFENCE : : : memory ) ; __asm __volatile ( EMMS : : : memory ) ; endif while ( s < end ) { register int rgb = * ( uint32_t * ) s ; s + = 4 ; * d + + = ( ( rgb & 0xFF ) > > 3 ) + ( ( rgb & 0xFC00 ) > > 5 ) + ( ( rgb & 0xF80000 ) > > 8 ) ; } }",1
"static int mxf_read_header ( AVFormatContext * s ) { MXFContext * mxf = s - > priv_data ; KLVPacket klv ; int64_t essence_offset = 0 ; int ret ; mxf - > last_forward_tell = INT64_MAX ; mxf - > edit_units_per_packet = 1 ; if ( ! mxf_read_sync ( s - > pb , mxf_header_partition_pack_key , 14 ) ) { av_log ( s , AV_LOG_ERROR , could not find header partition pack key\n ) ; return AVERROR_INVALIDDATA ; } avio_seek ( s - > pb , - 14 , SEEK_CUR ) ; mxf - > fc = s ; mxf - > run_in = avio_tell ( s - > pb ) ; while ( ! url_feof ( s - > pb ) ) { const MXFMetadataReadTableEntry * metadata ; if ( klv_read_packet ( & klv , s - > pb ) < 0 ) { / * EOF - seek to previous partition or stop * / if ( mxf_parse_handle_partition_or_eof ( mxf ) < = 0 ) break ; else continue ; } PRINT_KEY ( s , read header , klv . key ) ; av_dlog ( s , size % PRIu64 offset % PRIx64 \n , klv . length , klv . offset ) ; if ( IS_KLV_KEY ( klv . key , mxf_encrypted_triplet_key ) || IS_KLV_KEY ( klv . key , mxf_essence_element_key ) || IS_KLV_KEY ( klv . key , mxf_avid_essence_element_key ) || IS_KLV_KEY ( klv . key , mxf_system_item_key ) ) { if ( ! mxf - > current_partition ) { av_log ( mxf - > fc , AV_LOG_ERROR , found essence prior to first PartitionPack\n ) ; return AVERROR_INVALIDDATA ; } if ( ! mxf - > current_partition - > essence_offset ) { / * for OP1a we compute essence_offset * for OPAtom we point essence_offset after the KL ( usually op1a_essence_offset + 20 or 25 ) * TODO : for OP1a we could eliminate this entire if statement , always stopping parsing at op1a_essence_offset * for OPAtom we still need the actual essence_offset though ( the KL ' s length can vary ) * / int64_t op1a_essence_offset = round_to_kag ( mxf - > current_partition - > this_partition + mxf - > current_partition - > pack_length , mxf - > current_partition - > kag_size ) + round_to_kag ( mxf - > current_partition - > header_byte_count , mxf - > current_partition - > kag_size ) + round_to_kag ( mxf - > current_partition - > index_byte_count , mxf - > current_partition - > kag_size ) ; if ( mxf - > op == OPAtom ) { / * point essence_offset to the actual data * OPAtom has all the essence in one big KLV * / mxf - > current_partition - > essence_offset = avio_tell ( s - > pb ) ; mxf - > current_partition - > essence_length = klv . length ; } else { / * NOTE : op1a_essence_offset may be less than to klv . offset ( C0023S01 . mxf ) * / mxf - > current_partition - > essence_offset = op1a_essence_offset ; } } if ( ! essence_offset ) essence_offset = klv . offset ; / * seek to footer , previous partition or stop * / if ( mxf_parse_handle_essence ( mxf ) < = 0 ) break ; continue ; } else if ( ! memcmp ( klv . key , mxf_header_partition_pack_key , 13 ) & & klv . key[13] > = 2 & & klv . key[13] < = 4 & & mxf - > current_partition ) { / * next partition pack - keep going , seek to previous partition or stop * / if ( mxf_parse_handle_partition_or_eof ( mxf ) < = 0 ) break ; else if ( mxf - > parsing_backward ) continue ; / * we ' re still parsing forward . proceed to parsing this partition pack * / } for ( metadata = mxf_metadata_read_table ; metadata - > read ; metadata + + ) { if ( IS_KLV_KEY ( klv . key , metadata - > key ) ) { int res ; if ( klv . key[5] == 0x53 ) { res = mxf_read_local_tags ( mxf , & klv , metadata - > read , metadata - > ctx_size , metadata - > type ) ; } else { uint64_t next = avio_tell ( s - > pb ) + klv . length ; res = metadata - > read ( mxf , s - > pb , 0 , klv . length , klv . key , klv . offset ) ; / * only seek forward , else this can loop for a long time * / if ( avio_tell ( s - > pb ) > next ) { av_log ( s , AV_LOG_ERROR , read past end of KLV % PRIx64 \n , klv . offset ) ; return AVERROR_INVALIDDATA ; } avio_seek ( s - > pb , next , SEEK_SET ) ; } if ( res < 0 ) { av_log ( s , AV_LOG_ERROR , error reading header metadata\n ) ; return res ; } break ; } } if ( ! metadata - > read ) avio_skip ( s - > pb , klv . length ) ; } / * FIXME avoid seek * / if ( ! essence_offset ) { av_log ( s , AV_LOG_ERROR , no essence\n ) ; return AVERROR_INVALIDDATA ; } avio_seek ( s - > pb , essence_offset , SEEK_SET ) ; mxf_compute_essence_containers ( mxf ) ; / * we need to do this before computing the index tables * to be able to fill in zero IndexDurations with st - > duration * / if ( ( ret = mxf_parse_structural_metadata ( mxf ) ) < 0 ) return ret ; if ( ( ret = mxf_compute_index_tables ( mxf ) ) < 0 ) return ret ; if ( mxf - > nb_index_tables > 1 ) { / * TODO : look up which IndexSID to use via EssenceContainerData * / av_log ( mxf - > fc , AV_LOG_INFO , got %i index tables - only the first one ( IndexSID %i ) will be used\n , mxf - > nb_index_tables , mxf - > index_tables[0] . index_sid ) ; } else if ( mxf - > nb_index_tables == 0 & & mxf - > op == OPAtom ) { av_log ( mxf - > fc , AV_LOG_ERROR , cannot demux OPAtom without an index\n ) ; return AVERROR_INVALIDDATA ; } mxf_handle_small_eubc ( s ) ; return 0 ; }",1
"static av_cold int pulse_write_header ( AVFormatContext * h ) { PulseData * s = h - > priv_data ; AVStream * st = NULL ; int ret ; unsigned int i ; pa_sample_spec ss ; pa_buffer_attr attr = { - 1 , - 1 , - 1 , - 1 , - 1 } ; const char * stream_name = s - > stream_name ; for ( i = 0 ; i < h - > nb_streams ; i + + ) { if ( h - > streams[i] - > codec - > codec_type == AVMEDIA_TYPE_AUDIO ) { st = h - > streams[i] ; s - > stream_index = i ; break ; } } if ( ! st ) { av_log ( s , AV_LOG_ERROR , No audio stream found . \n ) ; return AVERROR ( EINVAL ) ; } if ( ! stream_name ) { if ( h - > filename[0] ) stream_name = h - > filename ; else stream_name = Playback ; } ss . format = codec_id_to_pulse_format ( st - > codec - > codec_id ) ; ss . rate = st - > codec - > sample_rate ; ss . channels = st - > codec - > channels ; s - > pa = pa_simple_new ( s - > server , // Server s - > name , // Application name PA_STREAM_PLAYBACK , s - > device , // Device stream_name , // Description of a stream & ss , // Sample format NULL , // Use default channel map & attr , // Buffering attributes & ret ) ; // Result if ( ! s - > pa ) { av_log ( s , AV_LOG_ERROR , pa_simple_new failed : %s\n , pa_strerror ( ret ) ) ; return AVERROR ( EIO ) ; } avpriv_set_pts_info ( st , 64 , 1 , 1000000 ) ; / * 64 bits pts in us * / return 0 ; }",0
"static int seg_write_packet ( AVFormatContext * s , AVPacket * pkt ) { SegmentContext * seg = s - > priv_data ; AVFormatContext * oc = seg - > avf ; AVStream * st = s - > streams[pkt - > stream_index] ; int64_t end_pts = seg - > recording_time * seg - > number ; int ret , can_split = 1 ; if ( ! oc ) return AVERROR ( EINVAL ) ; if ( seg - > has_video ) { can_split = st - > codec - > codec_type == AVMEDIA_TYPE_VIDEO & & pkt - > flags & AV_PKT_FLAG_KEY ; } if ( can_split & & av_compare_ts ( pkt - > pts , st - > time_base , end_pts , AV_TIME_BASE_Q ) > = 0 ) { av_log ( s , AV_LOG_DEBUG , Next segment starts at %d % PRId64 \n , pkt - > stream_index , pkt - > pts ) ; ret = segment_end ( oc , seg - > individual_header_trailer ) ; if ( ! ret ) ret = segment_start ( s , seg - > individual_header_trailer ) ; if ( ret ) goto fail ; oc = seg - > avf ; if ( seg - > list ) { if ( seg - > list_type == LIST_HLS ) { if ( ( ret = segment_hls_window ( s , 0 ) ) < 0 ) goto fail ; } else { avio_printf ( seg - > pb , %s\n , oc - > filename ) ; avio_flush ( seg - > pb ) ; if ( seg - > size & & ! ( seg - > number % seg - > size ) ) { avio_closep ( & seg - > pb ) ; if ( ( ret = avio_open2 ( & seg - > pb , seg - > list , AVIO_FLAG_WRITE , & s - > interrupt_callback , NULL ) ) < 0 ) goto fail ; } } } } ret = ff_write_chained ( oc , pkt - > stream_index , pkt , s ) ; fail : if ( ret < 0 ) seg_free_context ( seg ) ; return ret ; }",0
"avs_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; const uint8_t * buf_end = avpkt - > data + avpkt - > size ; int buf_size = avpkt - > size ; AvsContext * const avs = avctx - > priv_data ; AVFrame * picture = data ; AVFrame * const p = & avs - > picture ; const uint8_t * table , * vect ; uint8_t * out ; int i , j , x , y , stride , vect_w = 3 , vect_h = 3 ; AvsVideoSubType sub_type ; AvsBlockType type ; GetBitContext change_map ; if ( avctx - > reget_buffer ( avctx , p ) ) { av_log ( avctx , AV_LOG_ERROR , reget_buffer ( ) failed\n ) ; return - 1 ; } p - > reference = 3 ; p - > pict_type = AV_PICTURE_TYPE_P ; p - > key_frame = 0 ; out = avs - > picture . data[0] ; stride = avs - > picture . linesize[0] ; if ( buf_end - buf < 4 ) return AVERROR_INVALIDDATA ; sub_type = buf[0] ; type = buf[1] ; buf + = 4 ; if ( type == AVS_PALETTE ) { int first , last ; uint32_t * pal = ( uint32_t * ) avs - > picture . data[1] ; first = AV_RL16 ( buf ) ; last = first + AV_RL16 ( buf + 2 ) ; if ( first > = 256 || last > 256 || buf_end - buf < 4 + 4 + 3 * ( last - first ) ) return AVERROR_INVALIDDATA ; buf + = 4 ; for ( i=first ; i < last ; i + + , buf + =3 ) { pal[i] = ( buf[0] < < 18 ) | ( buf[1] < < 10 ) | ( buf[2] < < 2 ) ; pal[i] |= 0xFFU < < 24 | ( pal[i] > > 6 ) & 0x30303 ; } sub_type = buf[0] ; type = buf[1] ; buf + = 4 ; } if ( type ! = AVS_VIDEO ) return - 1 ; switch ( sub_type ) { case AVS_I_FRAME : p - > pict_type = AV_PICTURE_TYPE_I ; p - > key_frame = 1 ; case AVS_P_FRAME_3X3 : vect_w = 3 ; vect_h = 3 ; break ; case AVS_P_FRAME_2X2 : vect_w = 2 ; vect_h = 2 ; break ; case AVS_P_FRAME_2X3 : vect_w = 2 ; vect_h = 3 ; break ; default : return - 1 ; } if ( buf_end - buf < 256 * vect_w * vect_h ) return AVERROR_INVALIDDATA ; table = buf + ( 256 * vect_w * vect_h ) ; if ( sub_type ! = AVS_I_FRAME ) { int map_size = ( ( 318 / vect_w + 7 ) / 8 ) * ( 198 / vect_h ) ; if ( buf_end - table < map_size ) return AVERROR_INVALIDDATA ; init_get_bits ( & change_map , table , map_size * 8 ) ; table + = map_size ; } for ( y=0 ; y < 198 ; y + =vect_h ) { for ( x=0 ; x < 318 ; x + =vect_w ) { if ( sub_type == AVS_I_FRAME || get_bits1 ( & change_map ) ) { if ( buf_end - table < 1 ) return AVERROR_INVALIDDATA ; vect = & buf[ * table + + * ( vect_w * vect_h ) ] ; for ( j=0 ; j < vect_w ; j + + ) { out[ ( y + 0 ) * stride + x + j] = vect[ ( 0 * vect_w ) + j] ; out[ ( y + 1 ) * stride + x + j] = vect[ ( 1 * vect_w ) + j] ; if ( vect_h == 3 ) out[ ( y + 2 ) * stride + x + j] = vect[ ( 2 * vect_w ) + j] ; } } } if ( sub_type ! = AVS_I_FRAME ) align_get_bits ( & change_map ) ; } * picture = avs - > picture ; * got_frame = 1 ; return buf_size ; }",1
"int av_asrc_buffer_add_buffer ( AVFilterContext * ctx , uint8_t * buf , int buf_size , int sample_rate , int sample_fmt , int64_t channel_layout , int planar , int64_t pts , int av_unused flags ) { uint8_t * data[8] ; int linesize[8] ; int nb_channels = av_get_channel_layout_nb_channels ( channel_layout ) , nb_samples = buf_size / nb_channels / av_get_bytes_per_sample ( sample_fmt ) ; av_samples_fill_arrays ( data , linesize , buf , nb_channels , nb_samples , sample_fmt , 16 ) ; return av_asrc_buffer_add_samples ( ctx , data , linesize , nb_samples , sample_rate , sample_fmt , channel_layout , planar , pts , flags ) ; }",1
"static int vmdaudio_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; VmdAudioContext * s = avctx - > priv_data ; int block_type , silent_chunks ; unsigned char * output_samples = ( unsigned char * ) data ; if ( buf_size < 16 ) { av_log ( avctx , AV_LOG_WARNING , skipping small junk packet\n ) ; * data_size = 0 ; return buf_size ; } block_type = buf[6] ; if ( block_type < BLOCK_TYPE_AUDIO || block_type > BLOCK_TYPE_SILENCE ) { av_log ( avctx , AV_LOG_ERROR , unknown block type : %d\n , block_type ) ; return AVERROR ( EINVAL ) ; } buf + = 16 ; buf_size - = 16 ; silent_chunks = 0 ; if ( block_type == BLOCK_TYPE_INITIAL ) { uint32_t flags = AV_RB32 ( buf ) ; silent_chunks = av_popcount ( flags ) ; buf + = 4 ; buf_size - = 4 ; } else if ( block_type == BLOCK_TYPE_SILENCE ) { silent_chunks = 1 ; buf_size = 0 ; // should already be zero but set it just to be sure } / * ensure output buffer is large enough * / if ( * data_size < ( avctx - > block_align * silent_chunks + buf_size ) * s - > out_bps ) return - 1 ; * data_size = vmdaudio_loadsound ( s , output_samples , buf , silent_chunks , buf_size ) ; return avpkt - > size ; }",1
"static void ps_decorrelate_c ( INTFLOAT ( * out ) [2] , INTFLOAT ( * delay ) [2] , INTFLOAT ( * ap_delay ) [PS_QMF_TIME_SLOTS + PS_MAX_AP_DELAY][2] , const INTFLOAT phi_fract[2] , const INTFLOAT ( * Q_fract ) [2] , const INTFLOAT * transient_gain , INTFLOAT g_decay_slope , int len ) { static const INTFLOAT a[] = { Q31 ( 0 . 65143905753106f ) , Q31 ( 0 . 56471812200776f ) , Q31 ( 0 . 48954165955695f ) } ; INTFLOAT ag[PS_AP_LINKS] ; int m , n ; for ( m = 0 ; m < PS_AP_LINKS ; m + + ) ag[m] = AAC_MUL30 ( a[m] , g_decay_slope ) ; for ( n = 0 ; n < len ; n + + ) { INTFLOAT in_re = AAC_MSUB30 ( delay[n][0] , phi_fract[0] , delay[n][1] , phi_fract[1] ) ; INTFLOAT in_im = AAC_MADD30 ( delay[n][0] , phi_fract[1] , delay[n][1] , phi_fract[0] ) ; for ( m = 0 ; m < PS_AP_LINKS ; m + + ) { INTFLOAT a_re = AAC_MUL31 ( ag[m] , in_re ) ; INTFLOAT a_im = AAC_MUL31 ( ag[m] , in_im ) ; INTFLOAT link_delay_re = ap_delay[m][n + 2 - m][0] ; INTFLOAT link_delay_im = ap_delay[m][n + 2 - m][1] ; INTFLOAT fractional_delay_re = Q_fract[m][0] ; INTFLOAT fractional_delay_im = Q_fract[m][1] ; INTFLOAT apd_re = in_re ; INTFLOAT apd_im = in_im ; in_re = AAC_MSUB30 ( link_delay_re , fractional_delay_re , link_delay_im , fractional_delay_im ) ; in_re - = a_re ; in_im = AAC_MADD30 ( link_delay_re , fractional_delay_im , link_delay_im , fractional_delay_re ) ; in_im - = a_im ; ap_delay[m][n + 5][0] = apd_re + AAC_MUL31 ( ag[m] , in_re ) ; ap_delay[m][n + 5][1] = apd_im + AAC_MUL31 ( ag[m] , in_im ) ; } out[n][0] = AAC_MUL16 ( transient_gain[n] , in_re ) ; out[n][1] = AAC_MUL16 ( transient_gain[n] , in_im ) ; } }",1
"static int parse_presentation_segment ( AVCodecContext * avctx , const uint8_t * buf , int buf_size , int64_t pts ) { PGSSubContext * ctx = avctx - > priv_data ; int i , state , ret ; const uint8_t * buf_end = buf + buf_size ; // Video descriptor int w = bytestream_get_be16 ( & buf ) ; int h = bytestream_get_be16 ( & buf ) ; uint16_t object_index ; ctx - > presentation . pts = pts ; av_dlog ( avctx , Video Dimensions %dx%d\n , w , h ) ; ret = ff_set_dimensions ( avctx , w , h ) ; if ( ret < 0 ) return ret ; / * Skip 1 bytes of unknown , frame rate * / buf + + ; // Composition descriptor ctx - > presentation . id_number = bytestream_get_be16 ( & buf ) ; / * * state is a 2 bit field that defines pgs epoch boundaries * 00 - Normal , previously defined objects and palettes are still valid * 01 - Acquisition point , previous objects and palettes can be released * 10 - Epoch start , previous objects and palettes can be released * 11 - Epoch continue , previous objects and palettes can be released * * reserved 6 bits discarded * / state = bytestream_get_byte ( & buf ) > > 6 ; if ( state ! = 0 ) { flush_cache ( avctx ) ; / * * skip palette_update_flag ( 0x80 ) , * / buf + = 1 ; ctx - > presentation . palette_id = bytestream_get_byte ( & buf ) ; ctx - > presentation . object_count = bytestream_get_byte ( & buf ) ; if ( ctx - > presentation . object_count > MAX_OBJECT_REFS ) { av_log ( avctx , AV_LOG_ERROR , Invalid number of presentation objects %d\n , ctx - > presentation . object_count ) ; ctx - > presentation . object_count = 2 ; if ( avctx - > err_recognition & AV_EF_EXPLODE ) { for ( i = 0 ; i < ctx - > presentation . object_count ; i + + ) { ctx - > presentation . objects[i] . id = bytestream_get_be16 ( & buf ) ; ctx - > presentation . objects[i] . window_id = bytestream_get_byte ( & buf ) ; ctx - > presentation . objects[i] . composition_flag = bytestream_get_byte ( & buf ) ; ctx - > presentation . objects[i] . x = bytestream_get_be16 ( & buf ) ; ctx - > presentation . objects[i] . y = bytestream_get_be16 ( & buf ) ; // If cropping if ( ctx - > presentation . objects[i] . composition_flag & 0x80 ) { ctx - > presentation . objects[i] . crop_x = bytestream_get_be16 ( & buf ) ; ctx - > presentation . objects[i] . crop_y = bytestream_get_be16 ( & buf ) ; ctx - > presentation . objects[i] . crop_w = bytestream_get_be16 ( & buf ) ; ctx - > presentation . objects[i] . crop_h = bytestream_get_be16 ( & buf ) ; av_dlog ( avctx , Subtitle Placement x=%d , y=%d\n , ctx - > presentation . objects[i] . x , ctx - > presentation . objects[i] . y ) ; if ( ctx - > presentation . objects[i] . x > avctx - > width || ctx - > presentation . objects[i] . y > avctx - > height ) { av_log ( avctx , AV_LOG_ERROR , Subtitle out of video bounds . x = %d , y = %d , video width = %d , video height = %d . \n , ctx - > presentation . objects[i] . x , ctx - > presentation . objects[i] . y , avctx - > width , avctx - > height ) ; ctx - > presentation . objects[i] . x = 0 ; ctx - > presentation . objects[i] . y = 0 ; if ( avctx - > err_recognition & AV_EF_EXPLODE ) { return 0 ;",1
"PROTO4 ( _pack_2ch_ ) PROTO4 ( _pack_6ch_ ) PROTO4 ( _unpack_2ch_ ) av_cold void swri_audio_convert_init_x86 ( struct AudioConvert * ac , enum AVSampleFormat out_fmt , enum AVSampleFormat in_fmt , int channels ) { int mm_flags = av_get_cpu_flags ( ) ; ac - > simd_f= NULL ; //FIXME add memcpy case define MULTI_CAPS_FUNC ( flag , cap ) \ if ( mm_flags & flag ) { \ if ( out_fmt == AV_SAMPLE_FMT_S32 & & in_fmt == AV_SAMPLE_FMT_S16 || out_fmt == AV_SAMPLE_FMT_S32P & & in_fmt == AV_SAMPLE_FMT_S16P ) \ ac - > simd_f = ff_int16_to_int32_a_ cap ; \ if ( out_fmt == AV_SAMPLE_FMT_S16 & & in_fmt == AV_SAMPLE_FMT_S32 || out_fmt == AV_SAMPLE_FMT_S16P & & in_fmt == AV_SAMPLE_FMT_S32P ) \ ac - > simd_f = ff_int32_to_int16_a_ cap ; \ } MULTI_CAPS_FUNC ( AV_CPU_FLAG_MMX , mmx ) MULTI_CAPS_FUNC ( AV_CPU_FLAG_SSE2 , sse2 ) if ( mm_flags & AV_CPU_FLAG_MMX ) { if ( channels == 6 ) { if ( out_fmt == AV_SAMPLE_FMT_FLT & & in_fmt == AV_SAMPLE_FMT_FLTP || out_fmt == AV_SAMPLE_FMT_S32 & & in_fmt == AV_SAMPLE_FMT_S32P ) ac - > simd_f = ff_pack_6ch_float_to_float_a_mmx ; } } if ( mm_flags & AV_CPU_FLAG_SSE2 ) { if ( out_fmt == AV_SAMPLE_FMT_FLT & & in_fmt == AV_SAMPLE_FMT_S32 || out_fmt == AV_SAMPLE_FMT_FLTP & & in_fmt == AV_SAMPLE_FMT_S32P ) ac - > simd_f = ff_int32_to_float_a_sse2 ; if ( out_fmt == AV_SAMPLE_FMT_FLT & & in_fmt == AV_SAMPLE_FMT_S16 || out_fmt == AV_SAMPLE_FMT_FLTP & & in_fmt == AV_SAMPLE_FMT_S16P ) ac - > simd_f = ff_int16_to_float_a_sse2 ; if ( out_fmt == AV_SAMPLE_FMT_S32 & & in_fmt == AV_SAMPLE_FMT_FLT || out_fmt == AV_SAMPLE_FMT_S32P & & in_fmt == AV_SAMPLE_FMT_FLTP ) ac - > simd_f = ff_float_to_int32_a_sse2 ; if ( out_fmt == AV_SAMPLE_FMT_S16 & & in_fmt == AV_SAMPLE_FMT_FLT || out_fmt == AV_SAMPLE_FMT_S16P & & in_fmt == AV_SAMPLE_FMT_FLTP ) ac - > simd_f = ff_float_to_int16_a_sse2 ; if ( channels == 2 ) { if ( out_fmt == AV_SAMPLE_FMT_FLT & & in_fmt == AV_SAMPLE_FMT_FLTP || out_fmt == AV_SAMPLE_FMT_S32 & & in_fmt == AV_SAMPLE_FMT_S32P ) ac - > simd_f = ff_pack_2ch_int32_to_int32_a_sse2 ; if ( out_fmt == AV_SAMPLE_FMT_S16 & & in_fmt == AV_SAMPLE_FMT_S16P ) ac - > simd_f = ff_pack_2ch_int16_to_int16_a_sse2 ; if ( out_fmt == AV_SAMPLE_FMT_S32 & & in_fmt == AV_SAMPLE_FMT_S16P ) ac - > simd_f = ff_pack_2ch_int16_to_int32_a_sse2 ; if ( out_fmt == AV_SAMPLE_FMT_S16 & & in_fmt == AV_SAMPLE_FMT_S32P ) ac - > simd_f = ff_pack_2ch_int32_to_int16_a_sse2 ; if ( out_fmt == AV_SAMPLE_FMT_FLTP & & in_fmt == AV_SAMPLE_FMT_FLT || out_fmt == AV_SAMPLE_FMT_S32P & & in_fmt == AV_SAMPLE_FMT_S32 ) ac - > simd_f = ff_unpack_2ch_int32_to_int32_a_sse2 ; if ( out_fmt == AV_SAMPLE_FMT_S16P & & in_fmt == AV_SAMPLE_FMT_S16 ) ac - > simd_f = ff_unpack_2ch_int16_to_int16_a_sse2 ; if ( out_fmt == AV_SAMPLE_FMT_S32P & & in_fmt == AV_SAMPLE_FMT_S16 ) ac - > simd_f = ff_unpack_2ch_int16_to_int32_a_sse2 ; if ( out_fmt == AV_SAMPLE_FMT_S16P & & in_fmt == AV_SAMPLE_FMT_S32 ) ac - > simd_f = ff_unpack_2ch_int32_to_int16_a_sse2 ; if ( out_fmt == AV_SAMPLE_FMT_FLT & & in_fmt == AV_SAMPLE_FMT_S32P ) ac - > simd_f = ff_pack_2ch_int32_to_float_a_sse2 ; if ( out_fmt == AV_SAMPLE_FMT_S32 & & in_fmt == AV_SAMPLE_FMT_FLTP ) ac - > simd_f = ff_pack_2ch_float_to_int32_a_sse2 ; if ( out_fmt == AV_SAMPLE_FMT_FLT & & in_fmt == AV_SAMPLE_FMT_S16P ) ac - > simd_f = ff_pack_2ch_int16_to_float_a_sse2 ; if ( out_fmt == AV_SAMPLE_FMT_S16 & & in_fmt == AV_SAMPLE_FMT_FLTP ) ac - > simd_f = ff_pack_2ch_float_to_int16_a_sse2 ; if ( out_fmt == AV_SAMPLE_FMT_FLTP & & in_fmt == AV_SAMPLE_FMT_S32 ) ac - > simd_f = ff_unpack_2ch_int32_to_float_a_sse2 ; if ( out_fmt == AV_SAMPLE_FMT_S32P & & in_fmt == AV_SAMPLE_FMT_FLT ) ac - > simd_f = ff_unpack_2ch_float_to_int32_a_sse2 ; if ( out_fmt == AV_SAMPLE_FMT_FLTP & & in_fmt == AV_SAMPLE_FMT_S16 ) ac - > simd_f = ff_unpack_2ch_int16_to_float_a_sse2 ; if ( out_fmt == AV_SAMPLE_FMT_S16P & & in_fmt == AV_SAMPLE_FMT_FLT ) ac - > simd_f = ff_unpack_2ch_float_to_int16_a_sse2 ; } } if ( mm_flags & AV_CPU_FLAG_SSSE3 ) { if ( channels == 2 ) { if ( out_fmt == AV_SAMPLE_FMT_S16P & & in_fmt == AV_SAMPLE_FMT_S16 ) ac - > simd_f = ff_unpack_2ch_int16_to_int16_a_ssse3 ; if ( out_fmt == AV_SAMPLE_FMT_S32P & & in_fmt == AV_SAMPLE_FMT_S16 ) ac - > simd_f = ff_unpack_2ch_int16_to_int32_a_ssse3 ; if ( out_fmt == AV_SAMPLE_FMT_FLTP & & in_fmt == AV_SAMPLE_FMT_S16 ) ac - > simd_f = ff_unpack_2ch_int16_to_float_a_ssse3 ; } } if ( mm_flags & AV_CPU_FLAG_SSE4 ) { if ( channels == 6 ) { if ( out_fmt == AV_SAMPLE_FMT_FLT & & in_fmt == AV_SAMPLE_FMT_FLTP || out_fmt == AV_SAMPLE_FMT_S32 & & in_fmt == AV_SAMPLE_FMT_S32P ) ac - > simd_f = ff_pack_6ch_float_to_float_a_sse4 ; if ( out_fmt == AV_SAMPLE_FMT_FLT & & in_fmt == AV_SAMPLE_FMT_S32P ) ac - > simd_f = ff_pack_6ch_int32_to_float_a_sse4 ; if ( out_fmt == AV_SAMPLE_FMT_S32 & & in_fmt == AV_SAMPLE_FMT_FLTP ) ac - > simd_f = ff_pack_6ch_float_to_int32_a_sse4 ; } } if ( HAVE_AVX_EXTERNAL & & mm_flags & AV_CPU_FLAG_AVX ) { if ( out_fmt == AV_SAMPLE_FMT_FLT & & in_fmt == AV_SAMPLE_FMT_S32 || out_fmt == AV_SAMPLE_FMT_FLTP & & in_fmt == AV_SAMPLE_FMT_S32P ) ac - > simd_f = ff_int32_to_float_a_avx ; if ( channels == 6 ) { if ( out_fmt == AV_SAMPLE_FMT_FLT & & in_fmt == AV_SAMPLE_FMT_FLTP || out_fmt == AV_SAMPLE_FMT_S32 & & in_fmt == AV_SAMPLE_FMT_S32P ) ac - > simd_f = ff_pack_6ch_float_to_float_a_avx ; if ( out_fmt == AV_SAMPLE_FMT_FLT & & in_fmt == AV_SAMPLE_FMT_S32P ) ac - > simd_f = ff_pack_6ch_int32_to_float_a_avx ; if ( out_fmt == AV_SAMPLE_FMT_S32 & & in_fmt == AV_SAMPLE_FMT_FLTP ) ac - > simd_f = ff_pack_6ch_float_to_int32_a_avx ; } } }",0
"static av_cold int dnxhd_init_rc ( DNXHDEncContext * ctx ) { FF_ALLOCZ_OR_GOTO ( ctx - > m . avctx , ctx - > mb_rc , 8160 * ctx - > m . avctx - > qmax * sizeof ( RCEntry ) , fail ) ; if ( ctx - > m . avctx - > mb_decision ! = FF_MB_DECISION_RD ) FF_ALLOCZ_OR_GOTO ( ctx - > m . avctx , ctx - > mb_cmp , ctx - > m . mb_num * sizeof ( RCCMPEntry ) , fail ) ; ctx - > frame_bits = ( ctx - > cid_table - > coding_unit_size - 640 - 4 - ctx - > min_padding ) * 8 ; ctx - > qscale = 1 ; ctx - > lambda = 2 < < LAMBDA_FRAC_BITS ; // qscale 2 return 0 ; fail : return - 1 ; }",0
"static int dirac_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * pkt ) { DiracContext * s = avctx - > priv_data ; DiracFrame * picture = data ; uint8_t * buf = pkt - > data ; int buf_size = pkt - > size ; int i , data_unit_size , buf_idx = 0 ; / * release unused frames * / for ( i = 0 ; i < MAX_FRAMES ; i + + ) if ( s - > all_frames[i] . avframe . data[0] & & ! s - > all_frames[i] . avframe . reference ) { avctx - > release_buffer ( avctx , & s - > all_frames[i] . avframe ) ; memset ( s - > all_frames[i] . interpolated , 0 , sizeof ( s - > all_frames[i] . interpolated ) ) ; } s - > current_picture = NULL ; * data_size = 0 ; / * end of stream , so flush delayed pics * / if ( buf_size == 0 ) return get_delayed_pic ( s , ( AVFrame * ) data , data_size ) ; for ( ; ; ) { / * [DIRAC_STD] Here starts the code from parse_info ( ) defined in 9 . 6 [DIRAC_STD] PARSE_INFO_PREFIX = BBCD as defined in ISO/IEC 646 BBCD start code search * / for ( ; buf_idx + DATA_UNIT_HEADER_SIZE < buf_size ; buf_idx + + ) { if ( buf[buf_idx ] == ' B ' & & buf[buf_idx + 1] == ' B ' & & buf[buf_idx + 2] == ' C ' & & buf[buf_idx + 3] == ' D ' ) break ; } / * BBCD found or end of data * / if ( buf_idx + DATA_UNIT_HEADER_SIZE > = buf_size ) break ; data_unit_size = AV_RB32 ( buf + buf_idx + 5 ) ; if ( buf_idx + data_unit_size > buf_size || ! data_unit_size ) { if ( buf_idx + data_unit_size > buf_size ) av_log ( s - > avctx , AV_LOG_ERROR , Data unit with size %d is larger than input buffer , discarding\n , data_unit_size ) ; buf_idx + = 4 ; continue ; } / * [DIRAC_STD] dirac_decode_data_unit makes reference to the while defined in 9 . 3 inside the function parse_sequence ( ) * / if ( dirac_decode_data_unit ( avctx , buf + buf_idx , data_unit_size ) ) { av_log ( s - > avctx , AV_LOG_ERROR , Error in dirac_decode_data_unit\n ) ; return - 1 ; } buf_idx + = data_unit_size ; } if ( ! s - > current_picture ) return 0 ; if ( s - > current_picture - > avframe . display_picture_number > s - > frame_number ) { DiracFrame * delayed_frame = remove_frame ( s - > delay_frames , s - > frame_number ) ; s - > current_picture - > avframe . reference |= DELAYED_PIC_REF ; if ( add_frame ( s - > delay_frames , MAX_DELAY , s - > current_picture ) ) { int min_num = s - > delay_frames[0] - > avframe . display_picture_number ; / * Too many delayed frames , so we display the frame with the lowest pts * / av_log ( avctx , AV_LOG_ERROR , Delay frame overflow\n ) ; delayed_frame = s - > delay_frames[0] ; for ( i = 1 ; s - > delay_frames[i] ; i + + ) if ( s - > delay_frames[i] - > avframe . display_picture_number < min_num ) min_num = s - > delay_frames[i] - > avframe . display_picture_number ; delayed_frame = remove_frame ( s - > delay_frames , min_num ) ; add_frame ( s - > delay_frames , MAX_DELAY , s - > current_picture ) ; } if ( delayed_frame ) { delayed_frame - > avframe . reference = DELAYED_PIC_REF ; * ( AVFrame * ) data = delayed_frame - > avframe ; * data_size = sizeof ( AVFrame ) ; } } else if ( s - > current_picture - > avframe . display_picture_number == s - > frame_number ) { / * The right frame at the right time : - ) * / * ( AVFrame * ) data = s - > current_picture - > avframe ; * data_size = sizeof ( AVFrame ) ; } if ( * data_size ) s - > frame_number = picture - > avframe . display_picture_number + 1 ; return buf_idx ; }",0
"static int opt_default ( const char * opt , const char * arg ) { int type ; const AVOption * o= NULL ; int opt_types[]= { AV_OPT_FLAG_VIDEO_PARAM , AV_OPT_FLAG_AUDIO_PARAM , 0 , AV_OPT_FLAG_SUBTITLE_PARAM , 0 } ; for ( type=0 ; type < CODEC_TYPE_NB ; type + + ) { const AVOption * o2 = av_find_opt ( avctx_opts[0] , opt , NULL , opt_types[type] , opt_types[type] ) ; if ( o2 ) o = av_set_string ( avctx_opts[type] , opt , arg ) ; } if ( ! o ) o = av_set_string ( avformat_opts , opt , arg ) ; if ( ! o ) o = av_set_string ( sws_opts , opt , arg ) ; if ( ! o ) { if ( opt[0] == ' a ' ) o = av_set_string ( avctx_opts[CODEC_TYPE_AUDIO] , opt + 1 , arg ) ; else if ( opt[0] == ' v ' ) o = av_set_string ( avctx_opts[CODEC_TYPE_VIDEO] , opt + 1 , arg ) ; else if ( opt[0] == ' s ' ) o = av_set_string ( avctx_opts[CODEC_TYPE_SUBTITLE] , opt + 1 , arg ) ; } if ( ! o ) return - 1 ; // av_log ( NULL , AV_LOG_ERROR , %s : %s : %f 0x%0X\n , opt , arg , av_get_double ( avctx_opts , opt , NULL ) , ( int ) av_get_int ( avctx_opts , opt , NULL ) ) ; //FIXME we should always use avctx_opts , . . . for storing options so there wont be any need to keep track of whats set over this opt_names= av_realloc ( opt_names , sizeof ( void * ) * ( opt_name_count + 1 ) ) ; opt_names[opt_name_count + + ]= o - > name ; ifdef CONFIG_FFM_MUXER / * disable generate of real time pts in ffm ( need to be supressed anyway ) * / if ( avctx_opts[0] - > flags & CODEC_FLAG_BITEXACT ) ffm_nopts = 1 ; endif if ( avctx_opts[0] - > debug ) av_log_set_level ( AV_LOG_DEBUG ) ; return 0 ; }",0
"static int null_draw_slice ( AVFilterLink * link , int y , int h , int slice_dir ) { return 0 ; }",0
"static inline void RENAME ( yuv422ptoyuy2 ) ( const uint8_t * ysrc , const uint8_t * usrc , const uint8_t * vsrc , uint8_t * dst , long width , long height , long lumStride , long chromStride , long dstStride ) { RENAME ( yuvPlanartoyuy2 ) ( ysrc , usrc , vsrc , dst , width , height , lumStride , chromStride , dstStride , 1 ) ; }",0
"D ( float , sse ) D ( float , avx ) D ( int16 , mmx ) D ( int16 , sse2 ) av_cold int swri_rematrix_init_x86 ( struct SwrContext * s ) { if HAVE_YASM int mm_flags = av_get_cpu_flags ( ) ; int nb_in = av_get_channel_layout_nb_channels ( s - > in_ch_layout ) ; int nb_out = av_get_channel_layout_nb_channels ( s - > out_ch_layout ) ; int num = nb_in * nb_out ; int i , j ; s - > mix_1_1_simd = NULL ; s - > mix_2_1_simd = NULL ; if ( s - > midbuf . fmt == AV_SAMPLE_FMT_S16P ) { if ( EXTERNAL_MMX ( mm_flags ) ) { s - > mix_1_1_simd = ff_mix_1_1_a_int16_mmx ; s - > mix_2_1_simd = ff_mix_2_1_a_int16_mmx ; } if ( EXTERNAL_SSE2 ( mm_flags ) ) { s - > mix_1_1_simd = ff_mix_1_1_a_int16_sse2 ; s - > mix_2_1_simd = ff_mix_2_1_a_int16_sse2 ; } s - > native_simd_matrix = av_mallocz_array ( num , 2 * sizeof ( int16_t ) ) ; s - > native_simd_one = av_mallocz ( 2 * sizeof ( int16_t ) ) ; if ( ! s - > native_simd_matrix || ! s - > native_simd_one ) return AVERROR ( ENOMEM ) ; for ( i=0 ; i < nb_out ; i + + ) { int sh = 0 ; for ( j=0 ; j < nb_in ; j + + ) sh = FFMAX ( sh , FFABS ( ( ( int * ) s - > native_matrix ) [i * nb_in + j] ) ) ; sh = FFMAX ( av_log2 ( sh ) - 14 , 0 ) ; for ( j=0 ; j < nb_in ; j + + ) { ( ( int16_t * ) s - > native_simd_matrix ) [2 * ( i * nb_in + j ) + 1] = 15 - sh ; ( ( int16_t * ) s - > native_simd_matrix ) [2 * ( i * nb_in + j ) ] = ( ( ( ( int * ) s - > native_matrix ) [i * nb_in + j] ) + ( 1 < < sh > > 1 ) ) > > sh ; } } ( ( int16_t * ) s - > native_simd_one ) [1] = 14 ; ( ( int16_t * ) s - > native_simd_one ) [0] = 16384 ; } else if ( s - > midbuf . fmt == AV_SAMPLE_FMT_FLTP ) { if ( EXTERNAL_SSE ( mm_flags ) ) { s - > mix_1_1_simd = ff_mix_1_1_a_float_sse ; s - > mix_2_1_simd = ff_mix_2_1_a_float_sse ; } if ( EXTERNAL_AVX ( mm_flags ) ) { s - > mix_1_1_simd = ff_mix_1_1_a_float_avx ; s - > mix_2_1_simd = ff_mix_2_1_a_float_avx ; } s - > native_simd_matrix = av_mallocz_array ( num , sizeof ( float ) ) ; s - > native_simd_one = av_mallocz ( sizeof ( float ) ) ; if ( ! s - > native_simd_matrix || ! s - > native_simd_one ) return AVERROR ( ENOMEM ) ; memcpy ( s - > native_simd_matrix , s - > native_matrix , num * sizeof ( float ) ) ; memcpy ( s - > native_simd_one , s - > native_one , sizeof ( float ) ) ; } endif return 0 ; }",0
"static int configure_output_video_filter ( FilterGraph * fg , OutputFilter * ofilter , AVFilterInOut * out ) { char * pix_fmts ; OutputStream * ost = ofilter - > ost ; OutputFile * of = output_files[ost - > file_index] ; AVFilterContext * last_filter = out - > filter_ctx ; int pad_idx = out - > pad_idx ; int ret ; char name[255] ; snprintf ( name , sizeof ( name ) , output stream %d : %d , ost - > file_index , ost - > index ) ; ret = avfilter_graph_create_filter ( & ofilter - > filter , avfilter_get_by_name ( buffersink ) , name , NULL , NULL , fg - > graph ) ; if ( ret < 0 ) return ret ; if ( ! hw_device_ctx & & ( ofilter - > width || ofilter - > height ) ) { char args[255] ; AVFilterContext * filter ; snprintf ( args , sizeof ( args ) , %d : %d : 0x%X , ofilter - > width , ofilter - > height , ( unsigned ) ost - > sws_flags ) ; snprintf ( name , sizeof ( name ) , scaler for output stream %d : %d , ost - > file_index , ost - > index ) ; if ( ( ret = avfilter_graph_create_filter ( & filter , avfilter_get_by_name ( scale ) , name , args , NULL , fg - > graph ) ) < 0 ) return ret ; if ( ( ret = avfilter_link ( last_filter , pad_idx , filter , 0 ) ) < 0 ) return ret ; last_filter = filter ; pad_idx = 0 ; } if ( ( pix_fmts = choose_pix_fmts ( ofilter ) ) ) { AVFilterContext * filter ; snprintf ( name , sizeof ( name ) , pixel format for output stream %d : %d , ost - > file_index , ost - > index ) ; ret = avfilter_graph_create_filter ( & filter , avfilter_get_by_name ( format ) , format , pix_fmts , NULL , fg - > graph ) ; av_freep ( & pix_fmts ) ; if ( ret < 0 ) return ret ; if ( ( ret = avfilter_link ( last_filter , pad_idx , filter , 0 ) ) < 0 ) return ret ; last_filter = filter ; pad_idx = 0 ; } if ( ost - > frame_rate . num ) { AVFilterContext * fps ; char args[255] ; snprintf ( args , sizeof ( args ) , fps=%d/%d , ost - > frame_rate . num , ost - > frame_rate . den ) ; snprintf ( name , sizeof ( name ) , fps for output stream %d : %d , ost - > file_index , ost - > index ) ; ret = avfilter_graph_create_filter ( & fps , avfilter_get_by_name ( fps ) , name , args , NULL , fg - > graph ) ; if ( ret < 0 ) return ret ; ret = avfilter_link ( last_filter , pad_idx , fps , 0 ) ; if ( ret < 0 ) return ret ; last_filter = fps ; pad_idx = 0 ; } snprintf ( name , sizeof ( name ) , trim for output stream %d : %d , ost - > file_index , ost - > index ) ; ret = insert_trim ( of - > start_time , of - > recording_time , & last_filter , & pad_idx , name ) ; if ( ret < 0 ) return ret ; if ( ( ret = avfilter_link ( last_filter , pad_idx , ofilter - > filter , 0 ) ) < 0 ) return ret ; return 0 ; }",0
"static void FUNCC ( pred4x4_left_dc ) ( uint8_t * _src , const uint8_t * topright , int _stride ) { pixel * src = ( pixel * ) _src ; int stride = _stride/sizeof ( pixel ) ; const int dc= ( src[ - 1 + 0 * stride] + src[ - 1 + 1 * stride] + src[ - 1 + 2 * stride] + src[ - 1 + 3 * stride] + 2 ) > > 2 ; ( ( pixel4 * ) ( src + 0 * stride ) ) [0]= ( ( pixel4 * ) ( src + 1 * stride ) ) [0]= ( ( pixel4 * ) ( src + 2 * stride ) ) [0]= ( ( pixel4 * ) ( src + 3 * stride ) ) [0]= PIXEL_SPLAT_X4 ( dc ) ; }",1
"static void decode_nal_sei_decoded_picture_hash ( HEVCContext * s ) { int cIdx , i ; uint8_t hash_type ; //uint16_t picture_crc ; //uint32_t picture_checksum ; GetBitContext * gb = & s - > HEVClc - > gb ; hash_type = get_bits ( gb , 8 ) ; for ( cIdx = 0 ; cIdx < 3 / * ( ( s - > sps - > chroma_format_idc == 0 ) ? 1 : 3 ) * / ; cIdx + + ) { if ( hash_type == 0 ) { s - > is_md5 = 1 ; for ( i = 0 ; i < 16 ; i + + ) s - > md5[cIdx][i] = get_bits ( gb , 8 ) ; } else if ( hash_type == 1 ) { // picture_crc = get_bits ( gb , 16 ) ; skip_bits ( gb , 16 ) ; } else if ( hash_type == 2 ) { // picture_checksum = get_bits ( gb , 32 ) ; skip_bits ( gb , 32 ) ; } } }",1
"int ff_h263_decode_mb ( MpegEncContext * s , int16_t block[6][64] ) { int cbpc , cbpy , i , cbp , pred_x , pred_y , mx , my , dquant ; int16_t * mot_val ; const int xy= s - > mb_x + s - > mb_y * s - > mb_stride ; int cbpb = 0 , pb_mv_count = 0 ; av_assert2 ( ! s - > h263_pred ) ; if ( s - > pict_type == AV_PICTURE_TYPE_P ) { do { if ( get_bits1 ( & s - > gb ) ) { / * skip mb * / s - > mb_intra = 0 ; for ( i=0 ; i < 6 ; i + + ) s - > block_last_index[i] = - 1 ; s - > mv_dir = MV_DIR_FORWARD ; s - > mv_type = MV_TYPE_16X16 ; s - > current_picture . mb_type[xy] = MB_TYPE_SKIP | MB_TYPE_16x16 | MB_TYPE_L0 ; s - > mv[0][0][0] = 0 ; s - > mv[0][0][1] = 0 ; s - > mb_skipped = ! ( s - > obmc | s - > loop_filter ) ; goto end ; cbpc = get_vlc2 ( & s - > gb , ff_h263_inter_MCBPC_vlc . table , INTER_MCBPC_VLC_BITS , 2 ) ; if ( cbpc < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , cbpc damaged at %d %d\n , s - > mb_x , s - > mb_y ) ; } while ( cbpc == 20 ) ; s - > bdsp . clear_blocks ( s - > block[0] ) ; dquant = cbpc & 8 ; s - > mb_intra = ( ( cbpc & 4 ) ! = 0 ) ; if ( s - > mb_intra ) goto intra ; if ( s - > pb_frame & & get_bits1 ( & s - > gb ) ) pb_mv_count = h263_get_modb ( & s - > gb , s - > pb_frame , & cbpb ) ; cbpy = get_vlc2 ( & s - > gb , ff_h263_cbpy_vlc . table , CBPY_VLC_BITS , 1 ) ; if ( s - > alt_inter_vlc==0 || ( cbpc & 3 ) ! =3 ) cbpy = 0xF ; cbp = ( cbpc & 3 ) | ( cbpy < < 2 ) ; if ( dquant ) { h263_decode_dquant ( s ) ; s - > mv_dir = MV_DIR_FORWARD ; if ( ( cbpc & 16 ) == 0 ) { s - > current_picture . mb_type[xy] = MB_TYPE_16x16 | MB_TYPE_L0 ; / * 16x16 motion prediction * / s - > mv_type = MV_TYPE_16X16 ; ff_h263_pred_motion ( s , 0 , 0 , & pred_x , & pred_y ) ; if ( s - > umvplus ) mx = h263p_decode_umotion ( s , pred_x ) ; else mx = ff_h263_decode_motion ( s , pred_x , 1 ) ; if ( mx > = 0xffff ) if ( s - > umvplus ) my = h263p_decode_umotion ( s , pred_y ) ; else my = ff_h263_decode_motion ( s , pred_y , 1 ) ; if ( my > = 0xffff ) s - > mv[0][0][0] = mx ; s - > mv[0][0][1] = my ; if ( s - > umvplus & & ( mx - pred_x ) == 1 & & ( my - pred_y ) == 1 ) skip_bits1 ( & s - > gb ) ; / * Bit stuffing to prevent PSC * / } else { s - > current_picture . mb_type[xy] = MB_TYPE_8x8 | MB_TYPE_L0 ; s - > mv_type = MV_TYPE_8X8 ; for ( i=0 ; i < 4 ; i + + ) { mot_val = ff_h263_pred_motion ( s , i , 0 , & pred_x , & pred_y ) ; if ( s - > umvplus ) mx = h263p_decode_umotion ( s , pred_x ) ; else mx = ff_h263_decode_motion ( s , pred_x , 1 ) ; if ( mx > = 0xffff ) if ( s - > umvplus ) my = h263p_decode_umotion ( s , pred_y ) ; else my = ff_h263_decode_motion ( s , pred_y , 1 ) ; if ( my > = 0xffff ) s - > mv[0][i][0] = mx ; s - > mv[0][i][1] = my ; if ( s - > umvplus & & ( mx - pred_x ) == 1 & & ( my - pred_y ) == 1 ) skip_bits1 ( & s - > gb ) ; / * Bit stuffing to prevent PSC * / mot_val[0] = mx ; mot_val[1] = my ; } else if ( s - > pict_type==AV_PICTURE_TYPE_B ) { int mb_type ; const int stride= s - > b8_stride ; int16_t * mot_val0 = s - > current_picture . motion_val[0][2 * ( s - > mb_x + s - > mb_y * stride ) ] ; int16_t * mot_val1 = s - > current_picture . motion_val[1][2 * ( s - > mb_x + s - > mb_y * stride ) ] ; // const int mv_xy= s - > mb_x + 1 + s - > mb_y * s - > mb_stride ; //FIXME ugly mot_val0[0 ]= mot_val0[2 ]= mot_val0[0 + 2 * stride]= mot_val0[2 + 2 * stride]= mot_val0[1 ]= mot_val0[3 ]= mot_val0[1 + 2 * stride]= mot_val0[3 + 2 * stride]= mot_val1[0 ]= mot_val1[2 ]= mot_val1[0 + 2 * stride]= mot_val1[2 + 2 * stride]= mot_val1[1 ]= mot_val1[3 ]= mot_val1[1 + 2 * stride]= mot_val1[3 + 2 * stride]= 0 ; do { mb_type= get_vlc2 ( & s - > gb , h263_mbtype_b_vlc . table , H263_MBTYPE_B_VLC_BITS , 2 ) ; if ( mb_type < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , b mb_type damaged at %d %d\n , s - > mb_x , s - > mb_y ) ; mb_type= h263_mb_type_b_map[ mb_type ] ; } while ( ! mb_type ) ; s - > mb_intra = IS_INTRA ( mb_type ) ; if ( HAS_CBP ( mb_type ) ) { s - > bdsp . clear_blocks ( s - > block[0] ) ; cbpc = get_vlc2 ( & s - > gb , cbpc_b_vlc . table , CBPC_B_VLC_BITS , 1 ) ; if ( s - > mb_intra ) { dquant = IS_QUANT ( mb_type ) ; goto intra ; cbpy = get_vlc2 ( & s - > gb , ff_h263_cbpy_vlc . table , CBPY_VLC_BITS , 1 ) ; if ( cbpy < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , b cbpy damaged at %d %d\n , s - > mb_x , s - > mb_y ) ; if ( s - > alt_inter_vlc==0 || ( cbpc & 3 ) ! =3 ) cbpy = 0xF ; cbp = ( cbpc & 3 ) | ( cbpy < < 2 ) ; } else cbp=0 ; av_assert2 ( ! s - > mb_intra ) ; if ( IS_QUANT ( mb_type ) ) { h263_decode_dquant ( s ) ; if ( IS_DIRECT ( mb_type ) ) { s - > mv_dir = MV_DIR_FORWARD | MV_DIR_BACKWARD | MV_DIRECT ; mb_type |= set_direct_mv ( s ) ; } else { s - > mv_dir = 0",1
static av_cold void dcadec_flush ( AVCodecContext * avctx ) { DCAContext * s = avctx - > priv_data ; ff_dca_core_flush ( & s - > core ) ; ff_dca_xll_flush ( & s - > xll ) ; ff_dca_lbr_flush ( & s - > lbr ) ; s - > core_residual_valid = 0 ; },0
"static int amf_parse_object ( AVFormatContext * s , AVStream * astream , AVStream * vstream , const char * key , int64_t max_pos , int depth ) { AVCodecContext * acodec , * vcodec ; FLVContext * flv = s - > priv_data ; AVIOContext * ioc ; AMFDataType amf_type ; char str_val[256] ; double num_val ; num_val = 0 ; ioc = s - > pb ; amf_type = avio_r8 ( ioc ) ; switch ( amf_type ) { case AMF_DATA_TYPE_NUMBER : num_val = av_int2double ( avio_rb64 ( ioc ) ) ; break ; case AMF_DATA_TYPE_BOOL : num_val = avio_r8 ( ioc ) ; break ; case AMF_DATA_TYPE_STRING : if ( amf_get_string ( ioc , str_val , sizeof ( str_val ) ) < 0 ) return - 1 ; break ; case AMF_DATA_TYPE_OBJECT : if ( ( vstream || astream ) & & key & & ! strcmp ( KEYFRAMES_TAG , key ) & & depth == 1 ) if ( parse_keyframes_index ( s , ioc , vstream ? vstream : astream , max_pos ) < 0 ) return - 1 ; while ( avio_tell ( ioc ) < max_pos - 2 & & amf_get_string ( ioc , str_val , sizeof ( str_val ) ) > 0 ) if ( amf_parse_object ( s , astream , vstream , str_val , max_pos , depth + 1 ) < 0 ) return - 1 ; // if we couldn ' t skip , bomb out . if ( avio_r8 ( ioc ) ! = AMF_END_OF_OBJECT ) return - 1 ; break ; case AMF_DATA_TYPE_NULL : case AMF_DATA_TYPE_UNDEFINED : case AMF_DATA_TYPE_UNSUPPORTED : break ; // these take up no additional space case AMF_DATA_TYPE_MIXEDARRAY : avio_skip ( ioc , 4 ) ; // skip 32 - bit max array index while ( avio_tell ( ioc ) < max_pos - 2 & & amf_get_string ( ioc , str_val , sizeof ( str_val ) ) > 0 ) // this is the only case in which we would want a nested // parse to not skip over the object if ( amf_parse_object ( s , astream , vstream , str_val , max_pos , depth + 1 ) < 0 ) return - 1 ; if ( avio_r8 ( ioc ) ! = AMF_END_OF_OBJECT ) return - 1 ; break ; case AMF_DATA_TYPE_ARRAY : { unsigned int arraylen , i ; arraylen = avio_rb32 ( ioc ) ; for ( i = 0 ; i < arraylen & & avio_tell ( ioc ) < max_pos - 1 ; i + + ) if ( amf_parse_object ( s , NULL , NULL , NULL , max_pos , depth + 1 ) < 0 ) return - 1 ; // if we couldn ' t skip , bomb out . } break ; case AMF_DATA_TYPE_DATE : avio_skip ( ioc , 8 + 2 ) ; // timestamp ( double ) and UTC offset ( int16 ) break ; default : // unsupported type , we couldn ' t skip return - 1 ; } // only look for metadata values when we are not nested and key ! = NULL if ( depth == 1 & & key ) { acodec = astream ? astream - > codec : NULL ; vcodec = vstream ? vstream - > codec : NULL ; if ( amf_type == AMF_DATA_TYPE_NUMBER || amf_type == AMF_DATA_TYPE_BOOL ) { if ( ! strcmp ( key , duration ) ) s - > duration = num_val * AV_TIME_BASE ; else if ( ! strcmp ( key , videodatarate ) & & vcodec & & 0 < = ( int ) ( num_val * 1024 . 0 ) ) vcodec - > bit_rate = num_val * 1024 . 0 ; else if ( ! strcmp ( key , audiodatarate ) & & acodec & & 0 < = ( int ) ( num_val * 1024 . 0 ) ) acodec - > bit_rate = num_val * 1024 . 0 ; else if ( ! strcmp ( key , datastream ) ) { AVStream * st = create_stream ( s , AVMEDIA_TYPE_DATA ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; st - > codec - > codec_id = AV_CODEC_ID_TEXT ; } else if ( flv - > trust_metadata ) { if ( ! strcmp ( key , videocodecid ) & & vcodec ) { flv_set_video_codec ( s , vstream , num_val , 0 ) ; } else if ( ! strcmp ( key , audiocodecid ) & & acodec ) { int id = ( ( int ) num_val ) < < FLV_AUDIO_CODECID_OFFSET ; flv_set_audio_codec ( s , astream , acodec , id ) ; } else if ( ! strcmp ( key , audiosamplerate ) & & acodec ) { acodec - > sample_rate = num_val ; } else if ( ! strcmp ( key , audiosamplesize ) & & acodec ) { acodec - > bits_per_coded_sample = num_val ; } else if ( ! strcmp ( key , stereo ) & & acodec ) { acodec - > channels = num_val + 1 ; acodec - > channel_layout = acodec - > channels == 2 ? AV_CH_LAYOUT_STEREO : AV_CH_LAYOUT_MONO ; } else if ( ! strcmp ( key , width ) & & vcodec ) { vcodec - > width = num_val ; } else if ( ! strcmp ( key , height ) & & vcodec ) { vcodec - > height = num_val ; } } } if ( ! strcmp ( key , duration ) || ! strcmp ( key , filesize ) || ! strcmp ( key , width ) || ! strcmp ( key , height ) || ! strcmp ( key , videodatarate ) || ! strcmp ( key , framerate ) || ! strcmp ( key , videocodecid ) || ! strcmp ( key , audiodatarate ) || ! strcmp ( key , audiosamplerate ) || ! strcmp ( key , audiosamplesize ) || ! strcmp ( key , stereo ) || ! strcmp ( key , audiocodecid ) || ! strcmp ( key , datastream ) ) return 0 ; if ( amf_type == AMF_DATA_TYPE_BOOL ) { av_strlcpy ( str_val , num_val > 0 ? true : false , sizeof ( str_val ) ) ; av_dict_set ( & s - > metadata , key , str_val , 0 ) ; } else if ( amf_type == AMF_DATA_TYPE_NUMBER ) { snprintf ( str_val , sizeof ( str_val ) , % . f , num_val ) ; av_dict_set ( & s - > metadata , key , str_val , 0 ) ; } else if ( amf_type == AMF_DATA_TYPE_STRING ) av_dict_set ( & s - > metadata , key , str_val , 0 ) ; } return 0 ; }",0
"static void DEF ( put , pixels16_x2 ) ( uint8_t * block , const uint8_t * pixels , ptrdiff_t line_size , int h ) { MOVQ_BFE ( mm6 ) ; __asm__ volatile ( lea ( %3 , %3 ) , %% REG_a \n\t . p2align 3 \n\t 1 : \n\t movq ( %1 ) , %%mm0 \n\t movq 1 ( %1 ) , %%mm1 \n\t movq ( %1 , %3 ) , %%mm2 \n\t movq 1 ( %1 , %3 ) , %%mm3 \n\t PAVGBP ( %%mm0 , %%mm1 , %%mm4 , %%mm2 , %%mm3 , %%mm5 ) movq %%mm4 , ( %2 ) \n\t movq %%mm5 , ( %2 , %3 ) \n\t movq 8 ( %1 ) , %%mm0 \n\t movq 9 ( %1 ) , %%mm1 \n\t movq 8 ( %1 , %3 ) , %%mm2 \n\t movq 9 ( %1 , %3 ) , %%mm3 \n\t PAVGBP ( %%mm0 , %%mm1 , %%mm4 , %%mm2 , %%mm3 , %%mm5 ) movq %%mm4 , 8 ( %2 ) \n\t movq %%mm5 , 8 ( %2 , %3 ) \n\t add %% REG_a , %1 \n\t add %% REG_a , %2 \n\t movq ( %1 ) , %%mm0 \n\t movq 1 ( %1 ) , %%mm1 \n\t movq ( %1 , %3 ) , %%mm2 \n\t movq 1 ( %1 , %3 ) , %%mm3 \n\t PAVGBP ( %%mm0 , %%mm1 , %%mm4 , %%mm2 , %%mm3 , %%mm5 ) movq %%mm4 , ( %2 ) \n\t movq %%mm5 , ( %2 , %3 ) \n\t movq 8 ( %1 ) , %%mm0 \n\t movq 9 ( %1 ) , %%mm1 \n\t movq 8 ( %1 , %3 ) , %%mm2 \n\t movq 9 ( %1 , %3 ) , %%mm3 \n\t PAVGBP ( %%mm0 , %%mm1 , %%mm4 , %%mm2 , %%mm3 , %%mm5 ) movq %%mm4 , 8 ( %2 ) \n\t movq %%mm5 , 8 ( %2 , %3 ) \n\t add %% REG_a , %1 \n\t add %% REG_a , %2 \n\t subl 4 , %0 \n\t jnz 1b \n\t : + g ( h ) , + S ( pixels ) , + D ( block ) : r ( ( x86_reg ) line_size ) : REG_a , memory ) ; }",0
"static int av_transcode ( AVFormatContext * * output_files , int nb_output_files , AVFormatContext * * input_files , int nb_input_files , AVStreamMap * stream_maps , int nb_stream_maps ) { int ret = 0 , i , j , k , n , nb_istreams = 0 , nb_ostreams = 0 ; AVFormatContext * is , * os ; AVCodecContext * codec , * icodec ; AVOutputStream * ost , * * ost_table = NULL ; AVInputStream * ist , * * ist_table = NULL ; AVInputFile * file_table ; char error[1024] ; int key ; int want_sdp = 1 ; uint8_t no_packet[MAX_FILES]= { 0 } ; int no_packet_count=0 ; file_table= av_mallocz ( nb_input_files * sizeof ( AVInputFile ) ) ; if ( ! file_table ) goto fail ; / * input stream init * / j = 0 ; for ( i=0 ; i < nb_input_files ; i + + ) { is = input_files[i] ; file_table[i] . ist_index = j ; file_table[i] . nb_streams = is - > nb_streams ; j + = is - > nb_streams ; } nb_istreams = j ; ist_table = av_mallocz ( nb_istreams * sizeof ( AVInputStream * ) ) ; if ( ! ist_table ) goto fail ; for ( i=0 ; i < nb_istreams ; i + + ) { ist = av_mallocz ( sizeof ( AVInputStream ) ) ; if ( ! ist ) goto fail ; ist_table[i] = ist ; } j = 0 ; for ( i=0 ; i < nb_input_files ; i + + ) { is = input_files[i] ; for ( k=0 ; k < is - > nb_streams ; k + + ) { ist = ist_table[j + + ] ; ist - > st = is - > streams[k] ; ist - > file_index = i ; ist - > index = k ; ist - > discard = 1 ; / * the stream is discarded by default ( changed later ) * / if ( rate_emu ) { ist - > start = av_gettime ( ) ; } } } / * output stream init * / nb_ostreams = 0 ; for ( i=0 ; i < nb_output_files ; i + + ) { os = output_files[i] ; if ( ! os - > nb_streams ) { dump_format ( output_files[i] , i , output_files[i] - > filename , 1 ) ; fprintf ( stderr , Output file %d does not contain any stream\n , i ) ; av_exit ( 1 ) ; } nb_ostreams + = os - > nb_streams ; } if ( nb_stream_maps > 0 & & nb_stream_maps ! = nb_ostreams ) { fprintf ( stderr , Number of stream maps must match number of output streams\n ) ; av_exit ( 1 ) ; } / * Sanity check the mapping args - - do the input files & streams exist ? * / for ( i=0 ; i < nb_stream_maps ; i + + ) { int fi = stream_maps[i] . file_index ; int si = stream_maps[i] . stream_index ; if ( fi < 0 || fi > nb_input_files - 1 || si < 0 || si > file_table[fi] . nb_streams - 1 ) { fprintf ( stderr , Could not find input stream %d . %d\n , fi , si ) ; av_exit ( 1 ) ; } fi = stream_maps[i] . sync_file_index ; si = stream_maps[i] . sync_stream_index ; if ( fi < 0 || fi > nb_input_files - 1 || si < 0 || si > file_table[fi] . nb_streams - 1 ) { fprintf ( stderr , Could not find sync stream %d . %d\n , fi , si ) ; av_exit ( 1 ) ; } } ost_table = av_mallocz ( sizeof ( AVOutputStream * ) * nb_ostreams ) ; if ( ! ost_table ) goto fail ; for ( i=0 ; i < nb_ostreams ; i + + ) { ost = av_mallocz ( sizeof ( AVOutputStream ) ) ; if ( ! ost ) goto fail ; ost_table[i] = ost ; } n = 0 ; for ( k=0 ; k < nb_output_files ; k + + ) { os = output_files[k] ; for ( i=0 ; i < os - > nb_streams ; i + + , n + + ) { int found ; ost = ost_table[n] ; ost - > file_index = k ; ost - > index = i ; ost - > st = os - > streams[i] ; if ( nb_stream_maps > 0 ) { ost - > source_index = file_table[stream_maps[n] . file_index] . ist_index + stream_maps[n] . stream_index ; / * Sanity check that the stream types match * / if ( ist_table[ost - > source_index] - > st - > codec - > codec_type ! = ost - > st - > codec - > codec_type ) { int i= ost - > file_index ; dump_format ( output_files[i] , i , output_files[i] - > filename , 1 ) ; fprintf ( stderr , Codec type mismatch for mapping %d . %d - > %d . %d\n , stream_maps[n] . file_index , stream_maps[n] . stream_index , ost - > file_index , ost - > index ) ; av_exit ( 1 ) ; } } else { int best_nb_frames= - 1 ; / * get corresponding input stream index : we select the first one with the right type * / found = 0 ; for ( j=0 ; j < nb_istreams ; j + + ) { int skip=0 ; ist = ist_table[j] ; if ( opt_programid ) { int pi , si ; AVFormatContext * f= input_files[ ist - > file_index ] ; skip=1 ; for ( pi=0 ; pi < f - > nb_programs ; pi + + ) { AVProgram * p= f - > programs[pi] ; if ( p - > id == opt_programid ) for ( si=0 ; si < p - > nb_stream_indexes ; si + + ) { if ( f - > streams[ p - > stream_index[si] ] == ist - > st ) skip=0 ; } } } if ( ist - > discard & & ist - > st - > discard ! = AVDISCARD_ALL & & ! skip & & ist - > st - > codec - > codec_type == ost - > st - > codec - > codec_type ) { if ( best_nb_frames < ist - > st - > codec_info_nb_frames ) { best_nb_frames= ist - > st - > codec_info_nb_frames ; ost - > source_index = j ; found = 1 ; } } } if ( ! found ) { if ( ! opt_programid ) { / * try again and reuse existing stream * / for ( j=0 ; j < nb_istreams ; j + + ) { ist = ist_table[j] ; if ( ist - > st - > codec - > codec_type == ost - > st - > codec - > codec_type & & ist - > st - > discard ! = AVDISCARD_ALL ) { ost - > source_index = j ; found = 1 ; } } } if ( ! found ) { int i= ost",0
"static int check ( AVIOContext * pb , int64_t pos , int64_t * out_pos ) { MPADecodeHeader mh = { 0 } ; int i ; uint32_t header ; int64_t off = 0 ; for ( i = 0 ; i < SEEK_PACKETS ; i + + ) { off = avio_seek ( pb , pos + mh . frame_size , SEEK_SET ) ; if ( off < 0 ) break ; header = avio_rb32 ( pb ) ; if ( ff_mpa_check_header ( header ) < 0 || avpriv_mpegaudio_decode_header ( & mh , header ) ) break ; out_pos[i] = off ; } return i ; }",0
"int av_read_play ( AVFormatContext * s ) { if ( s - > iformat - > read_play ) return s - > iformat - > read_play ( s ) ; if ( s - > pb & & s - > pb - > read_pause ) return av_url_read_fpause ( s - > pb , 0 ) ; return AVERROR ( ENOSYS ) ; }",0
"static int mpegts_write_packet ( AVFormatContext * s , AVPacket * pkt ) { AVStream * st = s - > streams[pkt - > stream_index] ; int size= pkt - > size ; uint8_t * buf= pkt - > data ; MpegTSWriteStream * ts_st = st - > priv_data ; int len , max_payload_size ; const uint8_t * access_unit_index = NULL ; if ( st - > codec - > codec_type == CODEC_TYPE_SUBTITLE ) { / * for subtitle , a single PES packet must be generated * / mpegts_write_pes ( s , st , buf , size , pkt - > pts , AV_NOPTS_VALUE ) ; return 0 ; } if ( st - > codec - > codec_id == CODEC_ID_DIRAC ) { / * for Dirac , a single PES packet must be generated * / mpegts_write_pes ( s , st , buf , size , pkt - > pts , pkt - > dts ) ; return 0 ; } max_payload_size = DEFAULT_PES_PAYLOAD_SIZE ; if ( st - > codec - > codec_id == CODEC_ID_MPEG2VIDEO || st - > codec - > codec_id == CODEC_ID_MPEG1VIDEO ) { const uint8_t * p = pkt - > data ; const uint8_t * end = pkt - > data + pkt - > size ; uint32_t state = - 1 ; while ( p < end ) { p = ff_find_start_code ( p , end , & state ) ; if ( state == PICTURE_START_CODE ) { access_unit_index = p - 4 ; break ; } } } else if ( st - > codec - > codec_type == CODEC_TYPE_AUDIO ) { access_unit_index = pkt - > data ; } if ( ! access_unit_index ) { av_log ( s , AV_LOG_ERROR , error , could not find access unit start\n ) ; return - 1 ; } while ( size > 0 ) { len = max_payload_size - ts_st - > payload_index ; if ( len > size ) len = size ; memcpy ( ts_st - > payload + ts_st - > payload_index , buf , len ) ; buf + = len ; size - = len ; ts_st - > payload_index + = len ; if ( access_unit_index & & access_unit_index < buf & & ts_st - > payload_pts == AV_NOPTS_VALUE & & ts_st - > payload_dts == AV_NOPTS_VALUE ) { ts_st - > payload_dts = pkt - > dts ; ts_st - > payload_pts = pkt - > pts ; } if ( ts_st - > payload_index > = max_payload_size ) { mpegts_write_pes ( s , st , ts_st - > payload , ts_st - > payload_index , ts_st - > payload_pts , ts_st - > payload_dts ) ; ts_st - > payload_pts = AV_NOPTS_VALUE ; ts_st - > payload_dts = AV_NOPTS_VALUE ; ts_st - > payload_index = 0 ; access_unit_index = NULL ; // unset access unit to avoid setting pts/dts again } } return 0 ; }",0
"int ff_hevc_extract_rbsp ( HEVCContext * s , const uint8_t * src , int length , HEVCNAL * nal ) { int i , si , di ; uint8_t * dst ; if ( s ) nal - > skipped_bytes = 0 ; define STARTCODE_TEST \ if ( i + 2 < length & & src[i + 1] == 0 & & src[i + 2] < = 3 ) { \ if ( src[i + 2] ! = 3 ) { \ / * startcode , so we must be past the end * / \ length = i ; \ } \ break ; \ } if HAVE_FAST_UNALIGNED define FIND_FIRST_ZERO \ if ( i > 0 & & ! src[i] ) \ i - - ; \ while ( src[i] ) \ i + + if HAVE_FAST_64BIT for ( i = 0 ; i + 1 < length ; i + = 9 ) { if ( ! ( ( AV_RN64A ( src + i ) & ( AV_RN64A ( src + i ) - 0x0100010001000101ULL ) ) & 0x8000800080008080ULL ) ) continue ; FIND_FIRST_ZERO ; STARTCODE_TEST ; i - = 7 ; } else for ( i = 0 ; i + 1 < length ; i + = 5 ) { if ( ! ( ( AV_RN32A ( src + i ) & ( AV_RN32A ( src + i ) - 0x01000101U ) ) & 0x80008080U ) ) continue ; FIND_FIRST_ZERO ; STARTCODE_TEST ; i - = 3 ; } endif / * HAVE_FAST_64BIT * / else for ( i = 0 ; i + 1 < length ; i + = 2 ) { if ( src[i] ) continue ; if ( i > 0 & & src[i - 1] == 0 ) i - - ; STARTCODE_TEST ; } endif / * HAVE_FAST_UNALIGNED * / if ( i > = length - 1 ) { // no escaped 0 nal - > data = nal - > raw_data = src ; nal - > size = nal - > raw_size = length ; return length ; } av_fast_malloc ( & nal - > rbsp_buffer , & nal - > rbsp_buffer_size , length + AV_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! nal - > rbsp_buffer ) return AVERROR ( ENOMEM ) ; dst = nal - > rbsp_buffer ; memcpy ( dst , src , i ) ; si = di = i ; while ( si + 2 < length ) { // remove escapes ( very rare 1 : 2 22 ) if ( src[si + 2] > 3 ) { dst[di + + ] = src[si + + ] ; dst[di + + ] = src[si + + ] ; } else if ( src[si] == 0 & & src[si + 1] == 0 ) { if ( src[si + 2] == 3 ) { // escape dst[di + + ] = 0 ; dst[di + + ] = 0 ; si + = 3 ; if ( s & & nal - > skipped_bytes_pos ) { nal - > skipped_bytes + + ; if ( nal - > skipped_bytes_pos_size < nal - > skipped_bytes ) { nal - > skipped_bytes_pos_size * = 2 ; av_assert0 ( nal - > skipped_bytes_pos_size > = nal - > skipped_bytes ) ; av_reallocp_array ( & nal - > skipped_bytes_pos , nal - > skipped_bytes_pos_size , sizeof ( * nal - > skipped_bytes_pos ) ) ; if ( ! nal - > skipped_bytes_pos ) { nal - > skipped_bytes_pos_size = 0 ; return AVERROR ( ENOMEM ) ; } } if ( nal - > skipped_bytes_pos ) nal - > skipped_bytes_pos[nal - > skipped_bytes - 1] = di - 1 ; } continue ; } else // next start code goto nsc ; } dst[di + + ] = src[si + + ] ; } while ( si < length ) dst[di + + ] = src[si + + ] ; nsc : memset ( dst + di , 0 , AV_INPUT_BUFFER_PADDING_SIZE ) ; nal - > data = dst ; nal - > size = di ; nal - > raw_data = src ; nal - > raw_size = si ; return si ; }",0
"static int tiff_decode_tag ( TiffContext * s , const uint8_t * start , const uint8_t * buf , const uint8_t * end_buf ) { unsigned tag , type , count , off , value = 0 ; int i , j ; int ret ; uint32_t * pal ; const uint8_t * rp , * gp , * bp ; double * dp ; if ( end_buf - buf < 12 ) return - 1 ; tag = tget_short ( & buf , s - > le ) ; type = tget_short ( & buf , s - > le ) ; count = tget_long ( & buf , s - > le ) ; off = tget_long ( & buf , s - > le ) ; if ( type == 0 || type > = FF_ARRAY_ELEMS ( type_sizes ) ) { av_log ( s - > avctx , AV_LOG_DEBUG , Unknown tiff type ( %u ) encountered\n , type ) ; return 0 ; } if ( count == 1 ) { switch ( type ) { case TIFF_BYTE : case TIFF_SHORT : buf - = 4 ; value = tget ( & buf , type , s - > le ) ; buf = NULL ; break ; case TIFF_LONG : value = off ; buf = NULL ; break ; case TIFF_STRING : if ( count < = 4 ) { buf - = 4 ; break ; } default : value = UINT_MAX ; buf = start + off ; } } else { if ( count < = 4 & & type_sizes[type] * count < = 4 ) { buf - = 4 ; } else { buf = start + off ; } } if ( buf & & ( buf < start || buf > end_buf ) ) { av_log ( s - > avctx , AV_LOG_ERROR , Tag referencing position outside the image\n ) ; return - 1 ; } switch ( tag ) { case TIFF_WIDTH : s - > width = value ; break ; case TIFF_HEIGHT : s - > height = value ; break ; case TIFF_BPP : s - > bppcount = count ; if ( count > 4 ) { av_log ( s - > avctx , AV_LOG_ERROR , This format is not supported ( bpp=%d , %d components ) \n , s - > bpp , count ) ; return - 1 ; } if ( count == 1 ) s - > bpp = value ; else { switch ( type ) { case TIFF_BYTE : s - > bpp = ( off & 0xFF ) + ( ( off > > 8 ) & 0xFF ) + ( ( off > > 16 ) & 0xFF ) + ( ( off > > 24 ) & 0xFF ) ; break ; case TIFF_SHORT : case TIFF_LONG : s - > bpp = 0 ; for ( i = 0 ; i < count & & buf < end_buf ; i + + ) s - > bpp + = tget ( & buf , type , s - > le ) ; break ; default : s - > bpp = - 1 ; } } break ; case TIFF_SAMPLES_PER_PIXEL : if ( count ! = 1 ) { av_log ( s - > avctx , AV_LOG_ERROR , Samples per pixel requires a single value , many provided\n ) ; return AVERROR_INVALIDDATA ; } if ( s - > bppcount == 1 ) s - > bpp * = value ; s - > bppcount = value ; break ; case TIFF_COMPR : s - > compr = value ; s - > predictor = 0 ; switch ( s - > compr ) { case TIFF_RAW : case TIFF_PACKBITS : case TIFF_LZW : case TIFF_CCITT_RLE : break ; case TIFF_G3 : case TIFF_G4 : s - > fax_opts = 0 ; break ; case TIFF_DEFLATE : case TIFF_ADOBE_DEFLATE : if CONFIG_ZLIB break ; else av_log ( s - > avctx , AV_LOG_ERROR , Deflate : ZLib not compiled in\n ) ; return - 1 ; endif case TIFF_JPEG : case TIFF_NEWJPEG : av_log ( s - > avctx , AV_LOG_ERROR , JPEG compression is not supported\n ) ; return - 1 ; default : av_log ( s - > avctx , AV_LOG_ERROR , Unknown compression method %i\n , s - > compr ) ; return - 1 ; } break ; case TIFF_ROWSPERSTRIP : if ( type == TIFF_LONG & & value == UINT_MAX ) value = s - > avctx - > height ; if ( value < 1 ) { av_log ( s - > avctx , AV_LOG_ERROR , Incorrect value of rows per strip\n ) ; return - 1 ; } s - > rps = value ; break ; case TIFF_STRIP_OFFS : if ( count == 1 ) { s - > stripdata = NULL ; s - > stripoff = value ; } else s - > stripdata = start + off ; s - > strips = count ; if ( s - > strips == 1 ) s - > rps = s - > height ; s - > sot = type ; if ( s - > stripdata > end_buf ) { av_log ( s - > avctx , AV_LOG_ERROR , Tag referencing position outside the image\n ) ; return - 1 ; } break ; case TIFF_STRIP_SIZE : if ( count == 1 ) { s - > stripsizes = NULL ; s - > stripsize = value ; s - > strips = 1 ; } else { s - > stripsizes = start + off ; } s - > strips = count ; s - > sstype = type ; if ( s - > stripsizes > end_buf ) { av_log ( s - > avctx , AV_LOG_ERROR , Tag referencing position outside the image\n ) ; return - 1 ; } break ; case TIFF_TILE_BYTE_COUNTS : case TIFF_TILE_LENGTH : case TIFF_TILE_OFFSETS : case TIFF_TILE_WIDTH : av_log ( s - > avctx , AV_LOG_ERROR , Tiled images are not supported\n ) ; return AVERROR_PATCHWELCOME ; break ; case TIFF_PREDICTOR : s - > predictor = value ; break ; case TIFF_INVERT : switch ( value ) { case 0 : s - > invert = 1 ; break ; case 1 : s - > invert = 0 ; break ; case 2 : case 3 : break ; default : av_log ( s - > avctx , AV_LOG_ERROR , Color mode %d is not supported\n , value ) ; return - 1 ; } break ; case TIFF_FILL_ORDER : if ( value < 1 || value > 2 ) { av_log ( s - > avctx , AV_LOG_ERROR , Unknown FillOrder value %d , trying default one\n , value ) ; value = 1 ; } s - > fill_order = value - 1 ; break ; case TIFF_PAL : pal = ( uint32_t * ) s - > palette ; off = type_sizes[type] ; if ( count / 3 > 256 || end_buf - buf <",0
"static int bit_allocation ( IMCContext * q , IMCChannel * chctx , int stream_format_code , int freebits , int flag ) { int i , j ; const float limit = - 1 . e20 ; float highest = 0 . 0 ; int indx ; int t1 = 0 ; int t2 = 1 ; float summa = 0 . 0 ; int iacc = 0 ; int summer = 0 ; int rres , cwlen ; float lowest = 1 . e10 ; int low_indx = 0 ; float workT[32] ; int flg ; int found_indx = 0 ; for ( i = 0 ; i < BANDS ; i + + ) highest = FFMAX ( highest , chctx - > flcoeffs1[i] ) ; for ( i = 0 ; i < BANDS - 1 ; i + + ) chctx - > flcoeffs4[i] = chctx - > flcoeffs3[i] - log2f ( chctx - > flcoeffs5[i] ) ; chctx - > flcoeffs4[BANDS - 1] = limit ; highest = highest * 0 . 25 ; for ( i = 0 ; i < BANDS ; i + + ) { indx = - 1 ; if ( ( band_tab[i + 1] - band_tab[i] ) == chctx - > bandWidthT[i] ) indx = 0 ; if ( ( band_tab[i + 1] - band_tab[i] ) > chctx - > bandWidthT[i] ) indx = 1 ; if ( ( ( band_tab[i + 1] - band_tab[i] ) / 2 ) > = chctx - > bandWidthT[i] ) indx = 2 ; if ( indx == - 1 ) return AVERROR_INVALIDDATA ; chctx - > flcoeffs4[i] + = xTab[ ( indx * 2 + ( chctx - > flcoeffs1[i] < highest ) ) * 2 + flag] ; } if ( stream_format_code & 0x2 ) { chctx - > flcoeffs4[0] = limit ; chctx - > flcoeffs4[1] = limit ; chctx - > flcoeffs4[2] = limit ; chctx - > flcoeffs4[3] = limit ; } for ( i = ( stream_format_code & 0x2 ) ? 4 : 0 ; i < BANDS - 1 ; i + + ) { iacc + = chctx - > bandWidthT[i] ; summa + = chctx - > bandWidthT[i] * chctx - > flcoeffs4[i] ; } if ( ! iacc ) return AVERROR_INVALIDDATA ; chctx - > bandWidthT[BANDS - 1] = 0 ; summa = ( summa * 0 . 5 - freebits ) / iacc ; for ( i = 0 ; i < BANDS / 2 ; i + + ) { rres = summer - freebits ; if ( ( rres > = - 8 ) & & ( rres < = 8 ) ) break ; summer = 0 ; iacc = 0 ; for ( j = ( stream_format_code & 0x2 ) ? 4 : 0 ; j < BANDS ; j + + ) { cwlen = av_clipf ( ( ( chctx - > flcoeffs4[j] * 0 . 5 ) - summa + 0 . 5 ) , 0 , 6 ) ; chctx - > bitsBandT[j] = cwlen ; summer + = chctx - > bandWidthT[j] * cwlen ; if ( cwlen > 0 ) iacc + = chctx - > bandWidthT[j] ; } flg = t2 ; t2 = 1 ; if ( freebits < summer ) t2 = - 1 ; if ( i == 0 ) flg = t2 ; if ( flg ! = t2 ) t1 + + ; summa = ( float ) ( summer - freebits ) / ( ( t1 + 1 ) * iacc ) + summa ; } for ( i = ( stream_format_code & 0x2 ) ? 4 : 0 ; i < BANDS ; i + + ) { for ( j = band_tab[i] ; j < band_tab[i + 1] ; j + + ) chctx - > CWlengthT[j] = chctx - > bitsBandT[i] ; } if ( freebits > summer ) { for ( i = 0 ; i < BANDS ; i + + ) { workT[i] = ( chctx - > bitsBandT[i] == 6 ) ? - 1 . e20 : ( chctx - > bitsBandT[i] * - 2 + chctx - > flcoeffs4[i] - 0 . 415 ) ; } highest = 0 . 0 ; do { if ( highest < = - 1 . e20 ) break ; found_indx = 0 ; highest = - 1 . e20 ; for ( i = 0 ; i < BANDS ; i + + ) { if ( workT[i] > highest ) { highest = workT[i] ; found_indx = i ; } } if ( highest > - 1 . e20 ) { workT[found_indx] - = 2 . 0 ; if ( + + chctx - > bitsBandT[found_indx] == 6 ) workT[found_indx] = - 1 . e20 ; for ( j = band_tab[found_indx] ; j < band_tab[found_indx + 1] & & ( freebits > summer ) ; j + + ) { chctx - > CWlengthT[j] + + ; summer + + ; } } } while ( freebits > summer ) ; } if ( freebits < summer ) { for ( i = 0 ; i < BANDS ; i + + ) { workT[i] = chctx - > bitsBandT[i] ? ( chctx - > bitsBandT[i] * - 2 + chctx - > flcoeffs4[i] + 1 . 585 ) : 1 . e20 ; } if ( stream_format_code & 0x2 ) { workT[0] = 1 . e20 ; workT[1] = 1 . e20 ; workT[2] = 1 . e20 ; workT[3] = 1 . e20 ; } while ( freebits < summer ) { lowest = 1 . e10 ; low_indx = 0 ; for ( i = 0 ; i < BANDS ; i + + ) { if ( workT[i] < lowest ) { lowest = workT[i] ; low_indx = i ; } } // if ( lowest > = 1 . e10 ) // break ; workT[low_indx] = lowest + 2 . 0 ; if ( ! - - chctx - > bitsBandT[low_indx] ) workT[low_indx] = 1 . e20 ; for ( j = band_tab[low_indx] ; j < band_tab[low_indx + 1] & & ( freebits < summer ) ; j + + ) { if ( chctx - > CWlengthT[j] > 0 ) { chctx - > CWlengthT[j] - - ; summer - - ; } } } } return 0 ; }",0
"static av_cold int g722_decode_init ( AVCodecContext * avctx ) { G722Context * c = avctx - > priv_data ; if ( avctx - > channels ! = 1 ) { av_log ( avctx , AV_LOG_ERROR , Only mono tracks are allowed . \n ) ; return AVERROR_INVALIDDATA ; } avctx - > sample_fmt = AV_SAMPLE_FMT_S16 ; c - > band[0] . scale_factor = 8 ; c - > band[1] . scale_factor = 2 ; c - > prev_samples_pos = 22 ; avcodec_get_frame_defaults ( & c - > frame ) ; avctx - > coded_frame = & c - > frame ; return 0 ; }",0
"static int handle_packet ( MpegTSContext * ts , const uint8_t * packet ) { AVFormatContext * s = ts - > stream ; MpegTSFilter * tss ; int len , pid , cc , cc_ok , afc , is_start ; const uint8_t * p , * p_end ; int64_t pos ; pid = AV_RB16 ( packet + 1 ) & 0x1fff ; if ( pid & & discard_pid ( ts , pid ) ) return 0 ; is_start = packet[1] & 0x40 ; tss = ts - > pids[pid] ; if ( ts - > auto_guess & & tss == NULL & & is_start ) { add_pes_stream ( ts , pid , - 1 , 0 ) ; tss = ts - > pids[pid] ; } if ( ! tss ) return 0 ; / * continuity check ( currently not used ) * / cc = ( packet[3] & 0xf ) ; cc_ok = ( tss - > last_cc < 0 ) || ( ( ( ( tss - > last_cc + 1 ) & 0x0f ) == cc ) ) ; tss - > last_cc = cc ; / * skip adaptation field * / afc = ( packet[3] > > 4 ) & 3 ; p = packet + 4 ; if ( afc == 0 ) / * reserved value * / return 0 ; if ( afc == 2 ) / * adaptation field only * / return 0 ; if ( afc == 3 ) { / * skip adapation field * / p + = p[0] + 1 ; } / * if past the end of packet , ignore * / p_end = packet + TS_PACKET_SIZE ; if ( p > = p_end ) return 0 ; pos = url_ftell ( ts - > stream - > pb ) ; ts - > pos47= pos % ts - > raw_packet_size ; if ( tss - > type == MPEGTS_SECTION ) { if ( is_start ) { / * pointer field present * / len = * p + + ; if ( p + len > p_end ) return 0 ; if ( len & & cc_ok ) { / * write remaining section bytes * / write_section_data ( s , tss , p , len , 0 ) ; / * check whether filter has been closed * / if ( ! ts - > pids[pid] ) return 0 ; } p + = len ; if ( p < p_end ) { write_section_data ( s , tss , p , p_end - p , 1 ) ; } } else { if ( cc_ok ) { write_section_data ( s , tss , p , p_end - p , 0 ) ; } } } else { int ret ; // Note : The position here points actually behind the current packet . if ( ( ret = tss - > u . pes_filter . pes_cb ( tss , p , p_end - p , is_start , pos - ts - > raw_packet_size ) ) < 0 ) return ret ; } return 0 ; }",0
"static void buffer_release ( void * opaque , uint8_t * data ) { * ( uint8_t * ) opaque = 0 ; }",0
"static void float_to_int16_3dnow ( int16_t * dst , const float * src , int len ) { // not bit - exact : pf2id uses different rounding than C and SSE int i ; for ( i=0 ; i < len ; i + =4 ) { asm volatile ( pf2id %1 , %%mm0 \n\t pf2id %2 , %%mm1 \n\t packssdw %%mm1 , %%mm0 \n\t movq %%mm0 , %0 \n\t : =m ( dst[i] ) : m ( src[i] ) , m ( src[i + 2] ) ) ; } asm volatile ( femms ) ; }",0
"static int add_shorts_metadata ( const uint8_t * * buf , int count , const char * name , const char * sep , TiffContext * s ) { char * ap ; int i ; int * sp = av_malloc ( count * sizeof ( int ) ) ; if ( ! sp ) return AVERROR ( ENOMEM ) ; for ( i = 0 ; i < count ; i + + ) sp[i] = tget_short ( buf , s - > le ) ; ap = shorts2str ( sp , count , sep ) ; av_freep ( & sp ) ; if ( ! ap ) return AVERROR ( ENOMEM ) ; av_dict_set ( & s - > picture . metadata , name , ap , AV_DICT_DONT_STRDUP_VAL ) ; return 0 ; }",0
"int ff_mjpeg_decode_sos ( MJpegDecodeContext * s , const uint8_t * mb_bitmask , const AVFrame * reference ) { int len , nb_components , i , h , v , predictor , point_transform ; int index , id ; const int block_size= s - > lossless ? 1 : 8 ; int ilv , prev_shift ; / * XXX : verify len field validity * / len = get_bits ( & s - > gb , 16 ) ; nb_components = get_bits ( & s - > gb , 8 ) ; if ( nb_components == 0 || nb_components > MAX_COMPONENTS ) { av_log ( s - > avctx , AV_LOG_ERROR , decode_sos : nb_components ( %d ) unsupported\n , nb_components ) ; return - 1 ; } if ( len ! = 6 + 2 * nb_components ) { av_log ( s - > avctx , AV_LOG_ERROR , decode_sos : invalid len ( %d ) \n , len ) ; return - 1 ; } for ( i=0 ; i < nb_components ; i + + ) { id = get_bits ( & s - > gb , 8 ) - 1 ; av_log ( s - > avctx , AV_LOG_DEBUG , component : %d\n , id ) ; / * find component index * / for ( index=0 ; index < s - > nb_components ; index + + ) if ( id == s - > component_id[index] ) break ; if ( index == s - > nb_components ) { av_log ( s - > avctx , AV_LOG_ERROR , decode_sos : index ( %d ) out of components\n , index ) ; return - 1 ; } / * Metasoft MJPEG codec has Cb and Cr swapped * / if ( s - > avctx - > codec_tag == MKTAG ( ' M ' , ' T ' , ' S ' , ' J ' ) & & nb_components == 3 & & s - > nb_components == 3 & & i ) index = 3 - i ; if ( nb_components == 3 & & s - > nb_components == 3 & & s - > avctx - > pix_fmt == PIX_FMT_GBR24P ) index = ( i + 2 ) %3 ; s - > comp_index[i] = index ; s - > nb_blocks[i] = s - > h_count[index] * s - > v_count[index] ; s - > h_scount[i] = s - > h_count[index] ; s - > v_scount[i] = s - > v_count[index] ; s - > dc_index[i] = get_bits ( & s - > gb , 4 ) ; s - > ac_index[i] = get_bits ( & s - > gb , 4 ) ; if ( s - > dc_index[i] < 0 || s - > ac_index[i] < 0 || s - > dc_index[i] > = 4 || s - > ac_index[i] > = 4 ) goto out_of_range ; if ( ! s - > vlcs[0][s - > dc_index[i]] . table || ! s - > vlcs[1][s - > ac_index[i]] . table ) goto out_of_range ; } predictor= get_bits ( & s - > gb , 8 ) ; / * JPEG Ss / lossless JPEG predictor /JPEG - LS NEAR * / ilv= get_bits ( & s - > gb , 8 ) ; / * JPEG Se / JPEG - LS ILV * / if ( s - > avctx - > codec_tag ! = AV_RL32 ( CJPG ) ) { prev_shift = get_bits ( & s - > gb , 4 ) ; / * Ah * / point_transform= get_bits ( & s - > gb , 4 ) ; / * Al * / } else prev_shift= point_transform= 0 ; for ( i=0 ; i < nb_components ; i + + ) s - > last_dc[i] = 1024 ; if ( nb_components > 1 ) { / * interleaved stream * / s - > mb_width = ( s - > width + s - > h_max * block_size - 1 ) / ( s - > h_max * block_size ) ; s - > mb_height = ( s - > height + s - > v_max * block_size - 1 ) / ( s - > v_max * block_size ) ; } else if ( ! s - > ls ) { / * skip this for JPEG - LS * / h = s - > h_max / s - > h_scount[0] ; v = s - > v_max / s - > v_scount[0] ; s - > mb_width = ( s - > width + h * block_size - 1 ) / ( h * block_size ) ; s - > mb_height = ( s - > height + v * block_size - 1 ) / ( v * block_size ) ; s - > nb_blocks[0] = 1 ; s - > h_scount[0] = 1 ; s - > v_scount[0] = 1 ; } if ( s - > avctx - > debug & FF_DEBUG_PICT_INFO ) av_log ( s - > avctx , AV_LOG_DEBUG , %s %s p : %d > > : %d ilv : %d bits : %d skip : %d %s comp : %d\n , s - > lossless ? lossless : sequential DCT , s - > rgb ? RGB : , predictor , point_transform , ilv , s - > bits , s - > mjpb_skiptosod , s - > pegasus_rct ? PRCT : ( s - > rct ? RCT : ) , nb_components ) ; / * mjpeg - b can have padding bytes between sos and image data , skip them * / for ( i = s - > mjpb_skiptosod ; i > 0 ; i - - ) skip_bits ( & s - > gb , 8 ) ; if ( s - > lossless ) { av_assert0 ( s - > picture_ptr == & s - > picture ) ; if ( CONFIG_JPEGLS_DECODER & & s - > ls ) { // for ( ) { // reset_ls_coding_parameters ( s , 0 ) ; if ( ff_jpegls_decode_picture ( s , predictor , point_transform , ilv ) < 0 ) return - 1 ; } else { if ( s - > rgb ) { if ( ljpeg_decode_rgb_scan ( s , nb_components , predictor , point_transform ) < 0 ) return - 1 ; } else { if ( ljpeg_decode_yuv_scan ( s , predictor , point_transform ) < 0 ) return - 1 ; } } } else { if ( s - > progressive & & predictor ) { av_assert0 ( s - > picture_ptr == & s - > picture ) ; if ( mjpeg_decode_scan_progressive_ac ( s , predictor , ilv , prev_shift , point_transform ) < 0 ) return - 1 ; } else { if ( mjpeg_decode_scan ( s , nb_components , prev_shift , point_transform , mb_bitmask , reference ) < 0 ) return - 1 ; } } if ( s - > yuv421 ) { uint8_t * line = s - > picture_ptr - > data[2] ; for ( i = 0 ; i < s - > height / 2",0
"static int is_intra_more_likely ( MpegEncContext * s ) { int is_intra_likely , i , j , undamaged_count , skip_amount , mb_x , mb_y ; if ( ! s - > last_picture_ptr || ! s - > last_picture_ptr - > f . data[0] ) return 1 ; //no previous frame available - > use spatial prediction undamaged_count=0 ; for ( i=0 ; i < s - > mb_num ; i + + ) { const int mb_xy= s - > mb_index2xy[i] ; const int error= s - > error_status_table[mb_xy] ; if ( ! ( ( error & DC_ERROR ) & & ( error & MV_ERROR ) ) ) undamaged_count + + ; } if ( s - > codec_id == CODEC_ID_H264 ) { H264Context * h= ( void * ) s ; if ( h - > ref_count[0] < = 0 || ! h - > ref_list[0][0] . f . data[0] ) return 1 ; } if ( undamaged_count < 5 ) return 0 ; //almost all MBs damaged - > use temporal prediction //prevent dsp . sad ( ) check , that requires access to the image if ( CONFIG_MPEG_XVMC_DECODER & & s - > avctx - > xvmc_acceleration & & s - > pict_type == AV_PICTURE_TYPE_I ) return 1 ; skip_amount= FFMAX ( undamaged_count/50 , 1 ) ; //check only upto 50 MBs is_intra_likely=0 ; j=0 ; for ( mb_y= 0 ; mb_y < s - > mb_height - 1 ; mb_y + + ) { for ( mb_x= 0 ; mb_x < s - > mb_width ; mb_x + + ) { int error ; const int mb_xy= mb_x + mb_y * s - > mb_stride ; error= s - > error_status_table[mb_xy] ; if ( ( error & DC_ERROR ) & & ( error & MV_ERROR ) ) continue ; //skip damaged j + + ; if ( ( j%skip_amount ) ! = 0 ) continue ; //skip a few to speed things up if ( s - > pict_type==AV_PICTURE_TYPE_I ) { uint8_t * mb_ptr = s - > current_picture . f . data[0] + mb_x * 16 + mb_y * 16 * s - > linesize ; uint8_t * last_mb_ptr= s - > last_picture . f . data [0] + mb_x * 16 + mb_y * 16 * s - > linesize ; if ( s - > avctx - > codec_id == CODEC_ID_H264 ) { // FIXME } else { ff_thread_await_progress ( ( AVFrame * ) s - > last_picture_ptr , mb_y , 0 ) ; } is_intra_likely + = s - > dsp . sad[0] ( NULL , last_mb_ptr , mb_ptr , s - > linesize , 16 ) ; // FIXME need await_progress ( ) here is_intra_likely - = s - > dsp . sad[0] ( NULL , last_mb_ptr , last_mb_ptr + s - > linesize * 16 , s - > linesize , 16 ) ; } else { if ( IS_INTRA ( s - > current_picture . f . mb_type[mb_xy] ) ) is_intra_likely + + ; else is_intra_likely - - ; } } } //printf ( is_intra_likely : %d type : %d\n , is_intra_likely , s - > pict_type ) ; return is_intra_likely > 0 ; }",0
"void ff_hevc_luma_mv_mvp_mode ( HEVCContext * s , int x0 , int y0 , int nPbW , int nPbH , int log2_cb_size , int part_idx , int merge_idx , MvField * mv , int mvp_lx_flag , int LX ) { HEVCLocalContext * lc = s - > HEVClc ; MvField * tab_mvf = s - > ref - > tab_mvf ; int isScaledFlag_L0 = 0 ; int availableFlagLXA0 = 1 ; int availableFlagLXB0 = 1 ; int numMVPCandLX = 0 ; int min_pu_width = s - > sps - > min_pu_width ; int xA0 , yA0 ; int is_available_a0 ; int xA1 , yA1 ; int is_available_a1 ; int xB0 , yB0 ; int is_available_b0 ; int xB1 , yB1 ; int is_available_b1 ; int xB2 , yB2 ; int is_available_b2 ; Mv mvpcand_list[2] = { { 0 } } ; Mv mxA ; Mv mxB ; int ref_idx_curr = 0 ; int ref_idx = 0 ; int pred_flag_index_l0 ; int pred_flag_index_l1 ; const int cand_bottom_left = lc - > na . cand_bottom_left ; const int cand_left = lc - > na . cand_left ; const int cand_up_left = lc - > na . cand_up_left ; const int cand_up = lc - > na . cand_up ; const int cand_up_right = lc - > na . cand_up_right_sap ; ref_idx_curr = LX ; ref_idx = mv - > ref_idx[LX] ; pred_flag_index_l0 = LX ; pred_flag_index_l1 = ! LX ; // left bottom spatial candidate xA0 = x0 - 1 ; yA0 = y0 + nPbH ; is_available_a0 = AVAILABLE ( cand_bottom_left , A0 ) & & yA0 < s - > sps - > height & & PRED_BLOCK_AVAILABLE ( A0 ) ; //left spatial merge candidate xA1 = x0 - 1 ; yA1 = y0 + nPbH - 1 ; is_available_a1 = AVAILABLE ( cand_left , A1 ) ; if ( is_available_a0 || is_available_a1 ) isScaledFlag_L0 = 1 ; if ( is_available_a0 ) { if ( MP_MX ( A0 , pred_flag_index_l0 , mxA ) ) { goto b_candidates ; } if ( MP_MX ( A0 , pred_flag_index_l1 , mxA ) ) { goto b_candidates ; } } if ( is_available_a1 ) { if ( MP_MX ( A1 , pred_flag_index_l0 , mxA ) ) { goto b_candidates ; } if ( MP_MX ( A1 , pred_flag_index_l1 , mxA ) ) { goto b_candidates ; } } if ( is_available_a0 ) { if ( MP_MX_LT ( A0 , pred_flag_index_l0 , mxA ) ) { goto b_candidates ; } if ( MP_MX_LT ( A0 , pred_flag_index_l1 , mxA ) ) { goto b_candidates ; } } if ( is_available_a1 ) { if ( MP_MX_LT ( A1 , pred_flag_index_l0 , mxA ) ) { goto b_candidates ; } if ( MP_MX_LT ( A1 , pred_flag_index_l1 , mxA ) ) { goto b_candidates ; } } availableFlagLXA0 = 0 ; b_candidates : // B candidates // above right spatial merge candidate xB0 = x0 + nPbW ; yB0 = y0 - 1 ; is_available_b0 = AVAILABLE ( cand_up_right , B0 ) & & xB0 < s - > sps - > width & & PRED_BLOCK_AVAILABLE ( B0 ) ; if ( is_available_b0 ) { if ( MP_MX ( B0 , pred_flag_index_l0 , mxB ) ) { goto scalef ; } if ( MP_MX ( B0 , pred_flag_index_l1 , mxB ) ) { goto scalef ; } } // above spatial merge candidate xB1 = x0 + nPbW - 1 ; yB1 = y0 - 1 ; is_available_b1 = AVAILABLE ( cand_up , B1 ) ; if ( is_available_b1 ) { if ( MP_MX ( B1 , pred_flag_index_l0 , mxB ) ) { goto scalef ; } if ( MP_MX ( B1 , pred_flag_index_l1 , mxB ) ) { goto scalef ; } } // above left spatial merge candidate xB2 = x0 - 1 ; yB2 = y0 - 1 ; is_available_b2 = AVAILABLE ( cand_up_left , B2 ) ; if ( is_available_b2 ) { if ( MP_MX ( B2 , pred_flag_index_l0 , mxB ) ) { goto scalef ; } if ( MP_MX ( B2 , pred_flag_index_l1 , mxB ) ) { goto scalef ; } } availableFlagLXB0 = 0 ; scalef : if ( ! isScaledFlag_L0 ) { if ( availableFlagLXB0 ) { availableFlagLXA0 = 1 ; mxA = mxB ; } availableFlagLXB0 = 0 ; // XB0 and L1 if ( is_available_b0 ) { availableFlagLXB0 = MP_MX_LT ( B0 , pred_flag_index_l0 , mxB ) ; if ( ! availableFlagLXB0 ) availableFlagLXB0 = MP_MX_LT ( B0 , pred_flag_index_l1 , mxB ) ; } if ( is_available_b1 & & ! availableFlagLXB0 ) { availableFlagLXB0 = MP_MX_LT ( B1 , pred_flag_index_l0 , mxB ) ; if ( ! availableFlagLXB0 ) availableFlagLXB0 = MP_MX_LT ( B1 , pred_flag_index_l1 , mxB ) ; } if ( is_available_b2 & & ! availableFlagLXB0 ) { availableFlagLXB0 = MP_MX_LT ( B2 , pred_flag_index_l0 , mxB ) ; if ( ! availableFlagLXB0 ) availableFlagLXB0 = MP_MX_LT ( B2 , pred_flag_index_l1 , mxB ) ; } } if ( availableFlagLXA0 ) mvpcand_list[numMVPCandLX + + ] = mxA ; if ( availableFlagLXB0 & & ( ! availableFlagLXA0 || mxA . x ! = mxB . x || mxA . y ! = mxB . y ) ) mvpcand_list[numMVPCandLX + + ] = mxB ; //temporal motion vector prediction candidate if ( numMVPCandLX < 2 & & s - > sh . slice_temporal_mvp_enabled_flag & & mvp_lx_flag == numMVPCandLX ) { Mv mv_col ; int available_col = temporal_luma_motion_vector ( s , x0 , y0 , nPbW , nPbH , ref_idx , & mv_col , LX ) ; if ( available_col ) mvpcand_list[numMVPCandLX + + ] = mv_col ; } mv - > mv[LX] = mvpcand_list[mvp_lx_flag] ; }",1
"static inline void RENAME ( yuv2packedX ) ( SwsContext * c , const int16_t * lumFilter , const int16_t * * lumSrc , int lumFilterSize , const int16_t * chrFilter , const int16_t * * chrSrc , int chrFilterSize , const int16_t * * alpSrc , uint8_t * dest , int dstW , int dstY ) { if COMPILE_TEMPLATE_MMX x86_reg dummy=0 ; if ( ! ( c - > flags & SWS_BITEXACT ) ) { if ( c - > flags & SWS_ACCURATE_RND ) { switch ( c - > dstFormat ) { case PIX_FMT_RGB32 : if ( CONFIG_SWSCALE_ALPHA & & c - > alpPixBuf ) { YSCALEYUV2PACKEDX_ACCURATE YSCALEYUV2RGBX movq %%mm2 , U_TEMP ( %0 ) \n\t movq %%mm4 , V_TEMP ( %0 ) \n\t movq %%mm5 , Y_TEMP ( %0 ) \n\t YSCALEYUV2PACKEDX_ACCURATE_YA ( ALP_MMX_FILTER_OFFSET ) movq Y_TEMP ( %0 ) , %%mm5 \n\t psraw 3 , %%mm1 \n\t psraw 3 , %%mm7 \n\t packuswb %%mm7 , %%mm1 \n\t WRITEBGR32 ( %4 , %5 , %%REGa , %%mm3 , %%mm4 , %%mm5 , %%mm1 , %%mm0 , %%mm7 , %%mm2 , %%mm6 ) YSCALEYUV2PACKEDX_END } else { YSCALEYUV2PACKEDX_ACCURATE YSCALEYUV2RGBX pcmpeqd %%mm7 , %%mm7 \n\t WRITEBGR32 ( %4 , %5 , %%REGa , %%mm2 , %%mm4 , %%mm5 , %%mm7 , %%mm0 , %%mm1 , %%mm3 , %%mm6 ) YSCALEYUV2PACKEDX_END } return ; case PIX_FMT_BGR24 : YSCALEYUV2PACKEDX_ACCURATE YSCALEYUV2RGBX pxor %%mm7 , %%mm7 \n\t lea ( %% REG_a , %% REG_a , 2 ) , %% REG_c \n\t //FIXME optimize add %4 , %% REG_c \n\t WRITEBGR24 ( %%REGc , %5 , %%REGa ) : : r ( & c - > redDither ) , m ( dummy ) , m ( dummy ) , m ( dummy ) , r ( dest ) , m ( dstW ) : % REG_a , % REG_c , % REG_d , % REG_S ) ; return ; case PIX_FMT_RGB555 : YSCALEYUV2PACKEDX_ACCURATE YSCALEYUV2RGBX pxor %%mm7 , %%mm7 \n\t / * mm2=B , %%mm4=G , %%mm5=R , %%mm7=0 * / ifdef DITHER1XBPP paddusb BLUE_DITHER ( %0 ) , %%mm2\n\t paddusb GREEN_DITHER ( %0 ) , %%mm4\n\t paddusb RED_DITHER ( %0 ) , %%mm5\n\t endif WRITERGB15 ( %4 , %5 , %%REGa ) YSCALEYUV2PACKEDX_END return ; case PIX_FMT_RGB565 : YSCALEYUV2PACKEDX_ACCURATE YSCALEYUV2RGBX pxor %%mm7 , %%mm7 \n\t / * mm2=B , %%mm4=G , %%mm5=R , %%mm7=0 * / ifdef DITHER1XBPP paddusb BLUE_DITHER ( %0 ) , %%mm2\n\t paddusb GREEN_DITHER ( %0 ) , %%mm4\n\t paddusb RED_DITHER ( %0 ) , %%mm5\n\t endif WRITERGB16 ( %4 , %5 , %%REGa ) YSCALEYUV2PACKEDX_END return ; case PIX_FMT_YUYV422 : YSCALEYUV2PACKEDX_ACCURATE / * mm2=B , %%mm4=G , %%mm5=R , %%mm7=0 * / psraw 3 , %%mm3 \n\t psraw 3 , %%mm4 \n\t psraw 3 , %%mm1 \n\t psraw 3 , %%mm7 \n\t WRITEYUY2 ( %4 , %5 , %%REGa ) YSCALEYUV2PACKEDX_END return ; } } else { switch ( c - > dstFormat ) { case PIX_FMT_RGB32 : if ( CONFIG_SWSCALE_ALPHA & & c - > alpPixBuf ) { YSCALEYUV2PACKEDX YSCALEYUV2RGBX YSCALEYUV2PACKEDX_YA ( ALP_MMX_FILTER_OFFSET , %%mm0 , %%mm3 , %%mm6 , %%mm1 , %%mm7 ) psraw 3 , %%mm1 \n\t psraw 3 , %%mm7 \n\t packuswb %%mm7 , %%mm1 \n\t WRITEBGR32 ( %4 , %5 , %%REGa , %%mm2 , %%mm4 , %%mm5 , %%mm1 , %%mm0 , %%mm7 , %%mm3 , %%mm6 ) YSCALEYUV2PACKEDX_END } else { YSCALEYUV2PACKEDX YSCALEYUV2RGBX pcmpeqd %%mm7 , %%mm7 \n\t WRITEBGR32 ( %4 , %5 , %%REGa , %%mm2 , %%mm4 , %%mm5 , %%mm7 , %%mm0 , %%mm1 , %%mm3 , %%mm6 ) YSCALEYUV2PACKEDX_END } return ; case PIX_FMT_BGR24 : YSCALEYUV2PACKEDX YSCALEYUV2RGBX pxor %%mm7 , %%mm7 \n\t lea ( %% REG_a , %% REG_a , 2 ) , %% REG_c \n\t //FIXME optimize add %4 , %% REG_c \n\t WRITEBGR24 ( %%REGc , %5 , %%REGa ) : : r ( & c - > redDither ) , m ( dummy ) , m ( dummy ) , m ( dummy ) , r ( dest ) , m ( dstW ) : % REG_a , % REG_c , % REG_d , % REG_S ) ; return ; case PIX_FMT_RGB555 : YSCALEYUV2PACKEDX YSCALEYUV2RGBX pxor %%mm7 , %%mm7 \n\t / * mm2=B , %%mm4=G , %%mm5=R , %%mm7=0 * / ifdef DITHER1XBPP paddusb BLUE_DITHER ( %0 ) , %%mm2 \n\t paddusb GREEN_DITHER ( %0 ) , %%mm4 \n\t paddusb RED_DITHER ( %0 ) , %%mm5 \n\t endif WRITERGB15 ( %4 , %5 , %%REGa ) YSCALEYUV2PACKEDX_END return ; case PIX_FMT_RGB565 : YSCALEYUV2PACKEDX YSCALEYUV2RGBX pxor %%mm7 , %%mm7 \n\t / * mm2=B , %%mm4=G , %%mm5=R , %%mm7=0 * / ifdef DITHER1XBPP paddusb BLUE_DITHER ( %0 ) , %%mm2 \n\t paddusb GREEN_DITHER ( %0 ) , %%mm4 \n\t paddusb RED_DITHER ( %0 ) , %%mm5 \n\t endif WRITERGB16 ( %4 , %5 , %%REGa ) YSCALEYUV2PACKEDX_END return ; case PIX_FMT_YUYV422 : YSCALEYUV2PACKEDX / * mm2=B , %%mm4=G , %%mm5=R , %%mm7=0 * / psraw 3 , %%mm3 \n\t psraw 3 , %%mm4 \n\t psraw 3 , %%mm1 \n\t psraw 3 , %%mm7 \n\t WRITEYUY2 ( %4 , %5 , %%REGa ) YSCALEYUV2PACKEDX_END return ; } } } endif / * COMPILE_TEMPLATE_MMX * / if COMPILE_TEMPLATE_ALTIVEC / * The following list of supported dstFormat values should match what ' s found in the body of ff_yuv2packedX_altivec ( ) * / if ( ! ( c - > flags & SWS_BITEXACT ) & & ! c - > alpPixBuf & & ( c - > dstFormat==PIX_FMT_ABGR || c - > dstFormat==PIX_FMT_BGRA || c - > dstFormat==PIX_FMT_BGR24 || c - > dstFormat==PIX_FMT_RGB24 || c - > dstFormat==PIX_FMT_RGBA || c - > dstFormat==PIX_FMT_ARGB ) ) ff_yuv2packedX_altivec ( c , lumFilter , lumSrc , lumFilterSize , chrFilter , chrSrc , chrFilterSize , dest , dstW , dstY ) ; else endif yuv2packedXinC ( c , lumFilter , lumSrc , lumFilterSize , chrFilter , chrSrc , chrFilterSize , alpSrc , dest , dstW , dstY ) ; }",1
"static int vqa_decode_chunk ( VqaContext * s ) { unsigned int chunk_type ; unsigned int chunk_size ; int byte_skip ; unsigned int index = 0 ; int i ; unsigned char r , g , b ; int index_shift ; int res ; int cbf0_chunk = - 1 ; int cbfz_chunk = - 1 ; int cbp0_chunk = - 1 ; int cbpz_chunk = - 1 ; int cpl0_chunk = - 1 ; int cplz_chunk = - 1 ; int vptz_chunk = - 1 ; int x , y ; int lines = 0 ; int pixel_ptr ; int vector_index = 0 ; int lobyte = 0 ; int hibyte = 0 ; int lobytes = 0 ; int hibytes = s - > decode_buffer_size / 2 ; / * first , traverse through the frame and find the subchunks * / while ( bytestream2_get_bytes_left ( & s - > gb ) > = 8 ) { chunk_type = bytestream2_get_be32u ( & s - > gb ) ; index = bytestream2_tell ( & s - > gb ) ; chunk_size = bytestream2_get_be32u ( & s - > gb ) ; switch ( chunk_type ) { case CBF0_TAG : cbf0_chunk = index ; break ; case CBFZ_TAG : cbfz_chunk = index ; break ; case CBP0_TAG : cbp0_chunk = index ; break ; case CBPZ_TAG : cbpz_chunk = index ; break ; case CPL0_TAG : cpl0_chunk = index ; break ; case CPLZ_TAG : cplz_chunk = index ; break ; case VPTZ_TAG : vptz_chunk = index ; break ; default : av_log ( s - > avctx , AV_LOG_ERROR , Found unknown chunk type : %c%c%c%c ( %08X ) \n , ( chunk_type > > 24 ) & 0xFF , ( chunk_type > > 16 ) & 0xFF , ( chunk_type > > 8 ) & 0xFF , ( chunk_type > > 0 ) & 0xFF , chunk_type ) ; break ; } byte_skip = chunk_size & 0x01 ; bytestream2_skip ( & s - > gb , chunk_size + byte_skip ) ; } / * next , deal with the palette * / if ( ( cpl0_chunk ! = - 1 ) & & ( cplz_chunk ! = - 1 ) ) { / * a chunk should not have both chunk types * / av_log ( s - > avctx , AV_LOG_ERROR , problem : found both CPL0 and CPLZ chunks\n ) ; return AVERROR_INVALIDDATA ; } / * decompress the palette chunk * / if ( cplz_chunk ! = - 1 ) { / * yet to be handled * / } / * convert the RGB palette into the machine ' s endian format * / if ( cpl0_chunk ! = - 1 ) { bytestream2_seek ( & s - > gb , cpl0_chunk , SEEK_SET ) ; chunk_size = bytestream2_get_be32 ( & s - > gb ) ; / * sanity check the palette size * / if ( chunk_size / 3 > 256 || chunk_size > bytestream2_get_bytes_left ( & s - > gb ) ) { av_log ( s - > avctx , AV_LOG_ERROR , problem : found a palette chunk with %d colors\n , chunk_size / 3 ) ; return AVERROR_INVALIDDATA ; } for ( i = 0 ; i < chunk_size / 3 ; i + + ) { / * scale by 4 to transform 6 - bit palette - > 8 - bit * / r = bytestream2_get_byteu ( & s - > gb ) * 4 ; g = bytestream2_get_byteu ( & s - > gb ) * 4 ; b = bytestream2_get_byteu ( & s - > gb ) * 4 ; s - > palette[i] = 0xFF < < 24 | r < < 16 | g < < 8 | b ; s - > palette[i] |= s - > palette[i] > > 6 & 0x30303 ; } } / * next , look for a full codebook * / if ( ( cbf0_chunk ! = - 1 ) & & ( cbfz_chunk ! = - 1 ) ) { / * a chunk should not have both chunk types * / av_log ( s - > avctx , AV_LOG_ERROR , problem : found both CBF0 and CBFZ chunks\n ) ; return AVERROR_INVALIDDATA ; } / * decompress the full codebook chunk * / if ( cbfz_chunk ! = - 1 ) { bytestream2_seek ( & s - > gb , cbfz_chunk , SEEK_SET ) ; chunk_size = bytestream2_get_be32 ( & s - > gb ) ; if ( ( res = decode_format80 ( s , chunk_size , s - > codebook , s - > codebook_size , 0 ) ) < 0 ) return res ; } / * copy a full codebook * / if ( cbf0_chunk ! = - 1 ) { bytestream2_seek ( & s - > gb , cbf0_chunk , SEEK_SET ) ; chunk_size = bytestream2_get_be32 ( & s - > gb ) ; / * sanity check the full codebook size * / if ( chunk_size > MAX_CODEBOOK_SIZE ) { av_log ( s - > avctx , AV_LOG_ERROR , problem : CBF0 chunk too large ( 0x%X bytes ) \n , chunk_size ) ; return AVERROR_INVALIDDATA ; } bytestream2_get_buffer ( & s - > gb , s - > codebook , chunk_size ) ; } / * decode the frame * / if ( vptz_chunk == - 1 ) { / * something is wrong if there is no VPTZ chunk * / av_log ( s - > avctx , AV_LOG_ERROR , problem : no VPTZ chunk found\n ) ; return AVERROR_INVALIDDATA ; } bytestream2_seek ( & s - > gb , vptz_chunk , SEEK_SET ) ; chunk_size = bytestream2_get_be32 ( & s - > gb ) ; if ( ( res = decode_format80 ( s , chunk_size , s - > decode_buffer , s - > decode_buffer_size , 1 ) ) < 0 ) return res ; / * render the final PAL8 frame * / if ( s - > vector_height == 4 ) index_shift = 4 ; else index_shift = 3 ; for ( y = 0 ; y < s - > height ; y + = s - > vector_height ) { for ( x = 0 ; x < s - > width ; x + = 4 , lobytes + + , hibytes + + ) { pixel_ptr = y * s - > frame . linesize[0] + x ; / * get the vector index , the method for which varies according to * VQA file version * / switch ( s - > vqa_version ) { case 1 : lobyte = s - > decode_buffer[lobytes * 2] ; hibyte = s - > decode_buffer[ ( lobytes * 2 ) + 1] ; vector_index = ( ( hibyte < < 8 ) | lobyte ) > > 3 ; vector_index < < = index_shift ; lines = s - > vector_height ; / * uniform color fill - a quick hack * / if ( hibyte == 0xFF ) { while ( lines - - ) { s - > frame . data[0][pixel_ptr +",1
"static int hls_read ( URLContext * h , uint8_t * buf , int size ) { HLSContext * s = h - > priv_data ; const char * url ; int ret ; int64_t reload_interval ; start : if ( s - > seg_hd ) { ret = ffurl_read ( s - > seg_hd , buf , size ) ; if ( ret > 0 ) return ret ; } if ( s - > seg_hd ) { ffurl_close ( s - > seg_hd ) ; s - > seg_hd = NULL ; s - > cur_seq_no + + ; } reload_interval = s - > n_segments > 0 ? s - > segments[s - > n_segments - 1] - > duration : s - > target_duration ; reload_interval * = 1000000 ; retry : if ( ! s - > finished ) { int64_t now = av_gettime ( ) ; if ( now - s - > last_load_time > = reload_interval ) { if ( ( ret = parse_playlist ( h , s - > playlisturl ) ) < 0 ) return ret ; / * If we need to reload the playlist again below ( if * there ' s still no more segments ) , switch to a reload * interval of half the target duration . * / reload_interval = s - > target_duration * 500000 ; } } if ( s - > cur_seq_no < s - > start_seq_no ) { av_log ( h , AV_LOG_WARNING , skipping %d segments ahead , expired from playlist\n , s - > start_seq_no - s - > cur_seq_no ) ; s - > cur_seq_no = s - > start_seq_no ; } if ( s - > cur_seq_no - s - > start_seq_no > = s - > n_segments ) { if ( s - > finished ) return AVERROR_EOF ; while ( av_gettime ( ) - s - > last_load_time < reload_interval ) { if ( ff_check_interrupt ( & h - > interrupt_callback ) ) return AVERROR_EXIT ; av_usleep ( 100 * 1000 ) ; } goto retry ; } url = s - > segments[s - > cur_seq_no - s - > start_seq_no] - > url , av_log ( h , AV_LOG_DEBUG , opening %s\n , url ) ; ret = ffurl_open ( & s - > seg_hd , url , AVIO_FLAG_READ , & h - > interrupt_callback , NULL ) ; if ( ret < 0 ) { if ( ff_check_interrupt ( & h - > interrupt_callback ) ) return AVERROR_EXIT ; av_log ( h , AV_LOG_WARNING , Unable to open %s\n , url ) ; s - > cur_seq_no + + ; goto retry ; } goto start ; }",1
"static inline void ff_h264_biweight_WxH_mmx2 ( uint8_t * dst , uint8_t * src , int stride , int log2_denom , int weightd , int weights , int offsetd , int offsets , int w , int h ) { int x , y ; int offset = ( ( offsets + offsetd + 1 ) | 1 ) < < log2_denom ; asm volatile ( movd %0 , %%mm3 \n\t movd %1 , %%mm4 \n\t movd %2 , %%mm5 \n\t movd %3 , %%mm6 \n\t pshufw 0 , %%mm3 , %%mm3 \n\t pshufw 0 , %%mm4 , %%mm4 \n\t pshufw 0 , %%mm5 , %%mm5 \n\t pxor %%mm7 , %%mm7 \n\t : : g ( weightd ) , g ( weights ) , g ( offset ) , g ( log2_denom + 1 ) ) ; for ( y=0 ; y < h ; y + + ) { for ( x=0 ; x < w ; x + =4 ) { asm volatile ( movd %0 , %%mm0 \n\t movd %1 , %%mm1 \n\t punpcklbw %%mm7 , %%mm0 \n\t punpcklbw %%mm7 , %%mm1 \n\t pmullw %%mm3 , %%mm0 \n\t pmullw %%mm4 , %%mm1 \n\t paddw %%mm5 , %%mm0 \n\t paddw %%mm1 , %%mm0 \n\t psraw %%mm6 , %%mm0 \n\t packuswb %%mm0 , %%mm0 \n\t movd %%mm0 , %0 \n\t : + m ( * ( uint32_t * ) ( dst + x ) ) : m ( * ( uint32_t * ) ( src + x ) ) ) ; } src + = stride ; dst + = stride ; } }",1
static int dpx_probe ( AVProbeData * p ) { const uint8_t * b = p - > buf ; if ( AV_RN32 ( b ) == AV_RN32 ( SDPX ) || AV_RN32 ( b ) == AV_RN32 ( XPDS ) ) return AVPROBE_SCORE_EXTENSION + 1 ; return 0 ; },1
"static int yop_read_seek ( AVFormatContext * s , int stream_index , int64_t timestamp , int flags ) { YopDecContext * yop = s - > priv_data ; int64_t frame_pos , pos_min , pos_max ; int frame_count ; av_free_packet ( & yop - > video_packet ) ; if ( ! stream_index ) return - 1 ; pos_min = s - > data_offset ; pos_max = avio_size ( s - > pb ) - yop - > frame_size ; frame_count = ( pos_max - pos_min ) / yop - > frame_size ; timestamp = FFMAX ( 0 , FFMIN ( frame_count , timestamp ) ) ; frame_pos = timestamp * yop - > frame_size + pos_min ; yop - > odd_frame = timestamp & 1 ; avio_seek ( s - > pb , frame_pos , SEEK_SET ) ; return 0 ; }",1
"static av_cold int frei0r_init ( AVFilterContext * ctx , const char * dl_name , int type ) { Frei0rContext * frei0r = ctx - > priv ; f0r_init_f f0r_init ; f0r_get_plugin_info_f f0r_get_plugin_info ; f0r_plugin_info_t * pi ; char * path ; int ret = 0 ; / * see : http : //frei0r . dyne . org/codedoc/html/group__pluglocations . html * / if ( ( path = av_strdup ( getenv ( FREI0R_PATH ) ) ) ) { ifdef _WIN32 const char * separator = ; ; else const char * separator = : ; endif char * p , * ptr = NULL ; for ( p = path ; p = av_strtok ( p , separator , & ptr ) ; p = NULL ) { / * add additional trailing slash in case it is missing * / char * p1 = av_asprintf ( %s/ , p ) ; if ( ! p1 ) { av_free ( path ) ; return AVERROR ( ENOMEM ) ; } ret = load_path ( ctx , & frei0r - > dl_handle , p1 , dl_name ) ; av_free ( p1 ) ; if ( ret < 0 ) { av_free ( path ) ; return ret ; } if ( frei0r - > dl_handle ) break ; } av_free ( path ) ; } if ( ! frei0r - > dl_handle & & ( path = getenv ( HOME ) ) ) { char * prefix = av_asprintf ( %s/ . frei0r - 1/lib/ , path ) ; if ( ! prefix ) return AVERROR ( ENOMEM ) ; ret = load_path ( ctx , & frei0r - > dl_handle , prefix , dl_name ) ; av_free ( prefix ) ; if ( ret < 0 ) return ret ; } if ( ! frei0r - > dl_handle ) { ret = load_path ( ctx , & frei0r - > dl_handle , /usr/local/lib/frei0r - 1/ , dl_name ) ; if ( ret < 0 ) return ret ; } if ( ! frei0r - > dl_handle ) { ret = load_path ( ctx , & frei0r - > dl_handle , /usr/lib/frei0r - 1/ , dl_name ) ; if ( ret < 0 ) return ret ; } if ( ! frei0r - > dl_handle ) { av_log ( ctx , AV_LOG_ERROR , Could not find module ' %s ' \n , dl_name ) ; return AVERROR ( EINVAL ) ; } if ( ! ( f0r_init = load_sym ( ctx , f0r_init ) ) || ! ( f0r_get_plugin_info = load_sym ( ctx , f0r_get_plugin_info ) ) || ! ( frei0r - > get_param_info = load_sym ( ctx , f0r_get_param_info ) ) || ! ( frei0r - > get_param_value = load_sym ( ctx , f0r_get_param_value ) ) || ! ( frei0r - > set_param_value = load_sym ( ctx , f0r_set_param_value ) ) || ! ( frei0r - > update = load_sym ( ctx , f0r_update ) ) || ! ( frei0r - > construct = load_sym ( ctx , f0r_construct ) ) || ! ( frei0r - > destruct = load_sym ( ctx , f0r_destruct ) ) || ! ( frei0r - > deinit = load_sym ( ctx , f0r_deinit ) ) ) return AVERROR ( EINVAL ) ; if ( f0r_init ( ) < 0 ) { av_log ( ctx , AV_LOG_ERROR , Could not init the frei0r module\n ) ; return AVERROR ( EINVAL ) ; } f0r_get_plugin_info ( & frei0r - > plugin_info ) ; pi = & frei0r - > plugin_info ; if ( pi - > plugin_type ! = type ) { av_log ( ctx , AV_LOG_ERROR , Invalid type ' %s ' for the plugin\n , pi - > plugin_type == F0R_PLUGIN_TYPE_FILTER ? filter : pi - > plugin_type == F0R_PLUGIN_TYPE_SOURCE ? source : pi - > plugin_type == F0R_PLUGIN_TYPE_MIXER2 ? mixer2 : pi - > plugin_type == F0R_PLUGIN_TYPE_MIXER3 ? mixer3 : unknown ) ; return AVERROR ( EINVAL ) ; } av_log ( ctx , AV_LOG_VERBOSE , name : %s author : ' %s ' explanation : ' %s ' color_model : %s frei0r_version : %d version : %d . %d num_params : %d\n , pi - > name , pi - > author , pi - > explanation , pi - > color_model == F0R_COLOR_MODEL_BGRA8888 ? bgra8888 : pi - > color_model == F0R_COLOR_MODEL_RGBA8888 ? rgba8888 : pi - > color_model == F0R_COLOR_MODEL_PACKED32 ? packed32 : unknown , pi - > frei0r_version , pi - > major_version , pi - > minor_version , pi - > num_params ) ; return 0 ; }",0
"static int film_read_packet ( AVFormatContext * s , AVPacket * pkt ) { FilmDemuxContext * film = s - > priv_data ; AVIOContext * pb = s - > pb ; film_sample * sample ; int ret = 0 ; int i ; int left , right ; if ( film - > current_sample > = film - > sample_count ) return AVERROR ( EIO ) ; sample = & film - > sample_table[film - > current_sample] ; / * position the stream ( will probably be there anyway ) * / avio_seek ( pb , sample - > sample_offset , SEEK_SET ) ; / * do a special song and dance when loading FILM Cinepak chunks * / if ( ( sample - > stream == film - > video_stream_index ) & & ( film - > video_type == AV_CODEC_ID_CINEPAK ) ) { pkt - > pos= avio_tell ( pb ) ; if ( av_new_packet ( pkt , sample - > sample_size ) ) return AVERROR ( ENOMEM ) ; avio_read ( pb , pkt - > data , sample - > sample_size ) ; } else if ( ( sample - > stream == film - > audio_stream_index ) & & ( film - > audio_channels == 2 ) & & ( film - > audio_type ! = AV_CODEC_ID_ADPCM_ADX ) ) { / * stereo PCM needs to be interleaved * / if ( av_new_packet ( pkt , sample - > sample_size ) ) return AVERROR ( ENOMEM ) ; / * make sure the interleave buffer is large enough * / if ( sample - > sample_size > film - > stereo_buffer_size ) { av_free ( film - > stereo_buffer ) ; film - > stereo_buffer_size = sample - > sample_size ; film - > stereo_buffer = av_malloc ( film - > stereo_buffer_size ) ; if ( ! film - > stereo_buffer ) { film - > stereo_buffer_size = 0 ; return AVERROR ( ENOMEM ) ; } } pkt - > pos= avio_tell ( pb ) ; ret = avio_read ( pb , film - > stereo_buffer , sample - > sample_size ) ; if ( ret ! = sample - > sample_size ) ret = AVERROR ( EIO ) ; left = 0 ; right = sample - > sample_size / 2 ; for ( i = 0 ; i < sample - > sample_size ; ) { if ( film - > audio_bits == 8 ) { pkt - > data[i + + ] = film - > stereo_buffer[left + + ] ; pkt - > data[i + + ] = film - > stereo_buffer[right + + ] ; } else { pkt - > data[i + + ] = film - > stereo_buffer[left + + ] ; pkt - > data[i + + ] = film - > stereo_buffer[left + + ] ; pkt - > data[i + + ] = film - > stereo_buffer[right + + ] ; pkt - > data[i + + ] = film - > stereo_buffer[right + + ] ; } } } else { ret= av_get_packet ( pb , pkt , sample - > sample_size ) ; if ( ret ! = sample - > sample_size ) ret = AVERROR ( EIO ) ; } pkt - > stream_index = sample - > stream ; pkt - > pts = sample - > pts ; film - > current_sample + + ; return ret ; }",0
"static inline void RENAME ( hcscale_fast ) ( SwsContext * c , int16_t * dst , int dstWidth , const uint8_t * src1 , const uint8_t * src2 , int srcW , int xInc ) { if ARCH_X86 if COMPILE_TEMPLATE_MMX2 int32_t * filterPos = c - > hChrFilterPos ; int16_t * filter = c - > hChrFilter ; int canMMX2BeUsed = c - > canMMX2BeUsed ; void * mmx2FilterCode= c - > chrMmx2FilterCode ; int i ; if defined ( PIC ) DECLARE_ALIGNED ( 8 , uint64_t , ebxsave ) ; endif if ( canMMX2BeUsed ) { __asm__ volatile ( if defined ( PIC ) mov %% REG_b , %6 \n\t endif pxor %%mm7 , %%mm7 \n\t mov %0 , %% REG_c \n\t mov %1 , %% REG_D \n\t mov %2 , %% REG_d \n\t mov %3 , %% REG_b \n\t xor %% REG_a , %% REG_a \n\t // i PREFETCH ( %% REG_c ) \n\t PREFETCH 32 ( %% REG_c ) \n\t PREFETCH 64 ( %% REG_c ) \n\t CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE xor %% REG_a , %% REG_a \n\t // i mov %5 , %% REG_c \n\t // src mov %1 , %% REG_D \n\t // buf1 add AV_STRINGIFY ( VOF ) , %% REG_D \n\t PREFETCH ( %% REG_c ) \n\t PREFETCH 32 ( %% REG_c ) \n\t PREFETCH 64 ( %% REG_c ) \n\t CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE CALL_MMX2_FILTER_CODE if defined ( PIC ) mov %6 , %% REG_b \n\t endif : : m ( src1 ) , m ( dst ) , m ( filter ) , m ( filterPos ) , m ( mmx2FilterCode ) , m ( src2 ) if defined ( PIC ) , m ( ebxsave ) endif : % REG_a , % REG_c , % REG_d , % REG_S , % REG_D if ! defined ( PIC ) , % REG_b endif ) ; for ( i=dstWidth - 1 ; ( i * xInc ) > > 16 > =srcW - 1 ; i - - ) { //printf ( %d %d %d\n , dstWidth , i , srcW ) ; dst[i] = src1[srcW - 1] * 128 ; dst[i + VOFW] = src2[srcW - 1] * 128 ; } } else { endif / * COMPILE_TEMPLATE_MMX2 * / x86_reg dstWidth_reg = dstWidth ; x86_reg xInc_shr16 = ( x86_reg ) ( xInc > > 16 ) ; uint16_t xInc_mask = xInc & 0xffff ; __asm__ volatile ( xor %% REG_a , %% REG_a \n\t // i xor %% REG_d , %% REG_d \n\t // xx xorl %%ecx , %%ecx \n\t // xalpha ASMALIGN ( 4 ) 1 : \n\t mov %0 , %% REG_S \n\t movzbl ( %% REG_S , %% REG_d ) , %%edi \n\t //src[xx] movzbl 1 ( %% REG_S , %% REG_d ) , %%esi \n\t //src[xx + 1] FAST_BILINEAR_X86 movw %%si , ( %% REG_D , %% REG_a , 2 ) \n\t movzbl ( %5 , %% REG_d ) , %%edi \n\t //src[xx] movzbl 1 ( %5 , %% REG_d ) , %%esi \n\t //src[xx + 1] FAST_BILINEAR_X86 movw %%si , AV_STRINGIFY ( VOF ) ( %% REG_D , %% REG_a , 2 ) \n\t addw %4 , %%cx \n\t //xalpha + = xInc & 0xFFFF adc %3 , %% REG_d \n\t //xx + = xInc > > 16 + carry add 1 , %% REG_a \n\t cmp %2 , %% REG_a \n\t jb 1b \n\t / * GCC 3 . 3 makes MPlayer crash on IA - 32 machines when using g operand here , which is needed to support GCC 4 . 0 . * / if ARCH_X86_64 & & AV_GCC_VERSION_AT_LEAST ( 3 , 4 ) : : m ( src1 ) , m ( dst ) , g ( dstWidth_reg ) , m ( xInc_shr16 ) , m ( xInc_mask ) , else : : m ( src1 ) , m ( dst ) , m ( dstWidth_reg ) , m ( xInc_shr16 ) , m ( xInc_mask ) , endif r ( src2 ) : % REG_a , % REG_d , %ecx , % REG_D , %esi ) ; if COMPILE_TEMPLATE_MMX2 } //if MMX2 can ' t be used endif else int i ; unsigned int xpos=0 ; for ( i=0 ; i < dstWidth ; i + + ) { register unsigned int xx=xpos > > 16 ; register unsigned int xalpha= ( xpos & 0xFFFF ) > > 9 ; dst[i]= ( src1[xx] * ( xalpha 127 ) + src1[xx + 1] * xalpha ) ; dst[i + VOFW]= ( src2[xx] * ( xalpha 127 ) + src2[xx + 1] * xalpha ) ; / * slower dst[i]= ( src1[xx] < < 7 ) + ( src1[xx + 1] - src1[xx] ) * xalpha ; dst[i + VOFW]= ( src2[xx] < < 7 ) + ( src2[xx + 1] - src2[xx] ) * xalpha ; * / xpos + =xInc ; } endif / * ARCH_X86 * / }",1
"static int decode_mb_info ( IVI45DecContext * ctx , IVIBandDesc * band , IVITile * tile , AVCodecContext * avctx ) { int x , y , mv_x , mv_y , mv_delta , offs , mb_offset , mv_scale , blks_per_mb ; IVIMbInfo * mb , * ref_mb ; int row_offset = band - > mb_size * band - > pitch ; mb = tile - > mbs ; ref_mb = tile - > ref_mbs ; offs = tile - > ypos * band - > pitch + tile - > xpos ; if ( ! ref_mb & & ( ( band - > qdelta_present & & band - > inherit_qdelta ) || band - > inherit_mv ) ) / * scale factor for motion vectors * / mv_scale = ( ctx - > planes[0] . bands[0] . mb_size > > 3 ) - ( band - > mb_size > > 3 ) ; mv_x = mv_y = 0 ; for ( y = tile - > ypos ; y < ( tile - > ypos + tile - > height ) ; y + = band - > mb_size ) { mb_offset = offs ; for ( x = tile - > xpos ; x < ( tile - > xpos + tile - > width ) ; x + = band - > mb_size ) { mb - > xpos = x ; mb - > ypos = y ; mb - > buf_offs = mb_offset ; if ( get_bits1 ( & ctx - > gb ) ) { if ( ctx - > frame_type == FRAMETYPE_INTRA ) { av_log ( avctx , AV_LOG_ERROR , Empty macroblock in an INTRA picture ! \n ) ; return - 1 ; mb - > type = 1 ; / * empty macroblocks are always INTER * / mb - > cbp = 0 ; / * all blocks are empty * / mb - > q_delta = 0 ; if ( ! band - > plane & & ! band - > band_num & & ( ctx - > frame_flags & 8 ) ) { mb - > q_delta = get_vlc2 ( & ctx - > gb , ctx - > mb_vlc . tab - > table , IVI_VLC_BITS , 1 ) ; mb - > q_delta = IVI_TOSIGNED ( mb - > q_delta ) ; mb - > mv_x = mb - > mv_y = 0 ; / * no motion vector coded * / if ( band - > inherit_mv ) { / * motion vector inheritance * / if ( mv_scale ) { mb - > mv_x = ivi_scale_mv ( ref_mb - > mv_x , mv_scale ) ; mb - > mv_y = ivi_scale_mv ( ref_mb - > mv_y , mv_scale ) ; } else { mb - > mv_x = ref_mb - > mv_x ; mb - > mv_y = ref_mb - > mv_y ; } else { if ( band - > inherit_mv ) { mb - > type = ref_mb - > type ; / * copy mb_type from corresponding reference mb * / } else if ( ctx - > frame_type == FRAMETYPE_INTRA ) { mb - > type = 0 ; / * mb_type is always INTRA for intra - frames * / } else { mb - > type = get_bits1 ( & ctx - > gb ) ; blks_per_mb = band - > mb_size ! = band - > blk_size ? 4 : 1 ; mb - > cbp = get_bits ( & ctx - > gb , blks_per_mb ) ; mb - > q_delta = 0 ; if ( band - > qdelta_present ) { if ( band - > inherit_qdelta ) { if ( ref_mb ) mb - > q_delta = ref_mb - > q_delta ; } else if ( mb - > cbp || ( ! band - > plane & & ! band - > band_num & & ( ctx - > frame_flags & 8 ) ) ) { mb - > q_delta = get_vlc2 ( & ctx - > gb , ctx - > mb_vlc . tab - > table , IVI_VLC_BITS , 1 ) ; mb - > q_delta = IVI_TOSIGNED ( mb - > q_delta ) ; if ( ! mb - > type ) { mb - > mv_x = mb - > mv_y = 0 ; / * there is no motion vector in intra - macroblocks * / } else { if ( band - > inherit_mv ) { / * motion vector inheritance * / if ( mv_scale ) { mb - > mv_x = ivi_scale_mv ( ref_mb - > mv_x , mv_scale ) ; mb - > mv_y = ivi_scale_mv ( ref_mb - > mv_y , mv_scale ) ; } else { mb - > mv_x = ref_mb - > mv_x ; mb - > mv_y = ref_mb - > mv_y ; } else { / * decode motion vector deltas * / mv_delta = get_vlc2 ( & ctx - > gb , ctx - > mb_vlc . tab - > table , IVI_VLC_BITS , 1 ) ; mv_y + = IVI_TOSIGNED ( mv_delta ) ; mv_delta = get_vlc2 ( & ctx - > gb , ctx - > mb_vlc . tab - > table , IVI_VLC_BITS , 1 ) ; mv_x + = IVI_TOSIGNED ( mv_delta ) ; mb - > mv_x = mv_x ; mb - > mv_y = mv_y ; mb + + ; if ( ref_mb ) ref_mb + + ; mb_offset + = band - > mb_size ; offs + = row_offset ; align_get_bits ( & ctx - > gb ) ; return 0 ;",1
"static void decode_nal_sei_frame_packing_arrangement ( HEVCContext * s ) { GetBitContext * gb = & s - > HEVClc - > gb ; int cancel , type , quincunx , content ; get_ue_golomb ( gb ) ; // frame_packing_arrangement_id cancel = get_bits1 ( gb ) ; // frame_packing_cancel_flag if ( cancel == 0 ) { type = get_bits ( gb , 7 ) ; // frame_packing_arrangement_type quincunx = get_bits1 ( gb ) ; // quincunx_sampling_flag content = get_bits ( gb , 6 ) ; // content_interpretation_type // the following skips spatial_flipping_flag frame0_flipped_flag // field_views_flag current_frame_is_frame0_flag // frame0_self_contained_flag frame1_self_contained_flag skip_bits ( gb , 6 ) ; if ( quincunx == 0 & & type ! = 5 ) skip_bits ( gb , 16 ) ; // frame[01]_grid_position_[xy] skip_bits ( gb , 8 ) ; // frame_packing_arrangement_reserved_byte skip_bits1 ( gb ) ; // frame_packing_arrangement_persistance_flag } skip_bits1 ( gb ) ; // upsampled_aspect_ratio_flag s - > sei_frame_packing_present = ( cancel == 0 ) ; s - > frame_packing_arrangement_type = type ; s - > content_interpretation_type = content ; s - > quincunx_subsampling = quincunx ; }",1
"static int decode_mb_cavlc ( H264Context * h ) { MpegEncContext * const s = & h - > s ; const int mb_xy= s - > mb_x + s - > mb_y * s - > mb_stride ; int partition_count ; unsigned int mb_type , cbp ; int dct8x8_allowed= h - > pps . transform_8x8_mode ; s - > dsp . clear_blocks ( h - > mb ) ; //FIXME avoid if already clear ( move after skip handlong ? tprintf ( s - > avctx , pic : %d mb : %d/%d\n , h - > frame_num , s - > mb_x , s - > mb_y ) ; cbp = 0 ; / * avoid warning . FIXME : find a solution without slowing down the code * / if ( h - > slice_type ! = I_TYPE & & h - > slice_type ! = SI_TYPE ) { if ( s - > mb_skip_run== - 1 ) s - > mb_skip_run= get_ue_golomb ( & s - > gb ) ; if ( s - > mb_skip_run - - ) { if ( FRAME_MBAFF & & ( s - > mb_y & 1 ) == 0 ) { if ( s - > mb_skip_run==0 ) h - > mb_mbaff = h - > mb_field_decoding_flag = get_bits1 ( & s - > gb ) ; else predict_field_decoding_flag ( h ) ; } decode_mb_skip ( h ) ; return 0 ; } } if ( FRAME_MBAFF ) { if ( ( s - > mb_y & 1 ) == 0 ) h - > mb_mbaff = h - > mb_field_decoding_flag = get_bits1 ( & s - > gb ) ; } else h - > mb_field_decoding_flag= ( s - > picture_structure ! =PICT_FRAME ) ; h - > prev_mb_skipped= 0 ; mb_type= get_ue_golomb ( & s - > gb ) ; if ( h - > slice_type == B_TYPE ) { if ( mb_type < 23 ) { partition_count= b_mb_type_info[mb_type] . partition_count ; mb_type= b_mb_type_info[mb_type] . type ; } else { mb_type - = 23 ; goto decode_intra_mb ; } } else if ( h - > slice_type == P_TYPE / * || h - > slice_type == SP_TYPE * / ) { if ( mb_type < 5 ) { partition_count= p_mb_type_info[mb_type] . partition_count ; mb_type= p_mb_type_info[mb_type] . type ; } else { mb_type - = 5 ; goto decode_intra_mb ; } } else { assert ( h - > slice_type == I_TYPE ) ; decode_intra_mb : if ( mb_type > 25 ) { av_log ( h - > s . avctx , AV_LOG_ERROR , mb_type %d in %c slice too large at %d %d\n , mb_type , av_get_pict_type_char ( h - > slice_type ) , s - > mb_x , s - > mb_y ) ; return - 1 ; } partition_count=0 ; cbp= i_mb_type_info[mb_type] . cbp ; h - > intra16x16_pred_mode= i_mb_type_info[mb_type] . pred_mode ; mb_type= i_mb_type_info[mb_type] . type ; } if ( MB_FIELD ) mb_type |= MB_TYPE_INTERLACED ; h - > slice_table[ mb_xy ]= h - > slice_num ; if ( IS_INTRA_PCM ( mb_type ) ) { unsigned int x , y ; // We assume these blocks are very rare so we do not optimize it . align_get_bits ( & s - > gb ) ; // The pixels are stored in the same order as levels in h - > mb array . for ( y=0 ; y < 16 ; y + + ) { const int index= 4 * ( y & 3 ) + 32 * ( ( y > > 2 ) & 1 ) + 128 * ( y > > 3 ) ; for ( x=0 ; x < 16 ; x + + ) { tprintf ( s - > avctx , LUMA ICPM LEVEL ( %3d ) \n , show_bits ( & s - > gb , 8 ) ) ; h - > mb[index + ( x & 3 ) + 16 * ( ( x > > 2 ) & 1 ) + 64 * ( x > > 3 ) ]= get_bits ( & s - > gb , 8 ) ; } } for ( y=0 ; y < 8 ; y + + ) { const int index= 256 + 4 * ( y & 3 ) + 32 * ( y > > 2 ) ; for ( x=0 ; x < 8 ; x + + ) { tprintf ( s - > avctx , CHROMA U ICPM LEVEL ( %3d ) \n , show_bits ( & s - > gb , 8 ) ) ; h - > mb[index + ( x & 3 ) + 16 * ( x > > 2 ) ]= get_bits ( & s - > gb , 8 ) ; } } for ( y=0 ; y < 8 ; y + + ) { const int index= 256 + 64 + 4 * ( y & 3 ) + 32 * ( y > > 2 ) ; for ( x=0 ; x < 8 ; x + + ) { tprintf ( s - > avctx , CHROMA V ICPM LEVEL ( %3d ) \n , show_bits ( & s - > gb , 8 ) ) ; h - > mb[index + ( x & 3 ) + 16 * ( x > > 2 ) ]= get_bits ( & s - > gb , 8 ) ; } } // In deblocking , the quantizer is 0 s - > current_picture . qscale_table[mb_xy]= 0 ; h - > chroma_qp = get_chroma_qp ( h - > pps . chroma_qp_index_offset , 0 ) ; // All coeffs are present memset ( h - > non_zero_count[mb_xy] , 16 , 16 ) ; s - > current_picture . mb_type[mb_xy]= mb_type ; return 0 ; } if ( MB_MBAFF ) { h - > ref_count[0] < < = 1 ; h - > ref_count[1] < < = 1 ; } fill_caches ( h , mb_type , 0 ) ; //mb_pred if ( IS_INTRA ( mb_type ) ) { int pred_mode ; // init_top_left_availability ( h ) ; if ( IS_INTRA4x4 ( mb_type ) ) { int i ; int di = 1 ; if ( dct8x8_allowed & & get_bits1 ( & s - > gb ) ) { mb_type |= MB_TYPE_8x8DCT ; di = 4 ; } // fill_intra4x4_pred_table ( h ) ; for ( i=0 ; i < 16 ; i + =di ) { int mode= pred_intra_mode ( h , i ) ; if ( ! get_bits1 ( & s - > gb ) ) { const int rem_mode= get_bits ( & s - > gb , 3 ) ; mode = rem_mode + ( rem_mode > = mode ) ; } if ( di==4 ) fill_rectangle ( & h - > intra4x4_pred_mode_cache[ scan8[i] ] , 2 , 2 , 8 , mode , 1 ) ; else h - > intra4x4_pred_mode_cache[ scan8[i] ] = mode ; } write_back_intra_pred_mode ( h ) ; if ( check_intra4x4_pred_mode ( h ) < 0 ) return - 1 ; } else { h - >",1
void avfilter_free ( AVFilterContext * filter ) { int i ; AVFilterLink * link ; if ( filter - > filter - > uninit ) filter - > filter - > uninit ( filter ) ; for ( i = 0 ; i < filter - > input_count ; i + + ) { if ( ( link = filter - > inputs[i] ) ) { if ( link - > src ) link - > src - > outputs[link - > srcpad - link - > src - > output_pads] = NULL ; avfilter_formats_unref ( & link - > in_formats ) ; avfilter_formats_unref ( & link - > out_formats ) ; } av_freep ( & link ) ; } for ( i = 0 ; i < filter - > output_count ; i + + ) { if ( ( link = filter - > outputs[i] ) ) { if ( link - > dst ) link - > dst - > inputs[link - > dstpad - link - > dst - > input_pads] = NULL ; avfilter_formats_unref ( & link - > in_formats ) ; avfilter_formats_unref ( & link - > out_formats ) ; } av_freep ( & link ) ; } av_freep ( & filter - > name ) ; av_freep ( & filter - > input_pads ) ; av_freep ( & filter - > output_pads ) ; av_freep ( & filter - > inputs ) ; av_freep ( & filter - > outputs ) ; av_freep ( & filter - > priv ) ; av_free ( filter ) ; },1
"static int mpegts_handle_packet ( AVFormatContext * ctx , PayloadContext * data , AVStream * st , AVPacket * pkt , uint32_t * timestamp , const uint8_t * buf , int len , uint16_t seq , int flags ) { int ret ; // We don ' t want to use the RTP timestamps at all . If the mpegts demuxer // doesn ' t set any pts/dts , the generic rtpdec code shouldn ' t try to // fill it in either , since the mpegts and RTP timestamps are in totally // different ranges . * timestamp = RTP_NOTS_VALUE ; if ( ! data - > ts ) return AVERROR ( EINVAL ) ; if ( ! buf ) { if ( data - > read_buf_index > = data - > read_buf_size ) return AVERROR ( EAGAIN ) ; ret = ff_mpegts_parse_packet ( data - > ts , pkt , data - > buf + data - > read_buf_index , data - > read_buf_size - data - > read_buf_index ) ; if ( ret < 0 ) return AVERROR ( EAGAIN ) ; data - > read_buf_index + = ret ; if ( data - > read_buf_index < data - > read_buf_size ) return 1 ; else return 0 ; } ret = ff_mpegts_parse_packet ( data - > ts , pkt , buf , len ) ; / * The only error that can be returned from ff_mpegts_parse_packet * is no more data to return from the provided buffer , so return * AVERROR ( EAGAIN ) for all errors * / if ( ret < 0 ) return AVERROR ( EAGAIN ) ; if ( ret < len ) { data - > read_buf_size = FFMIN ( len - ret , sizeof ( data - > buf ) ) ; memcpy ( data - > buf , buf + ret , data - > read_buf_size ) ; data - > read_buf_index = 0 ; return 1 ; } return 0 ; }",1
"static inline int wv_unpack_stereo ( WavpackFrameContext * s , GetBitContext * gb , void * dst_l , void * dst_r , const int type ) { int i , j , count = 0 ; int last , t ; int A , B , L , L2 , R , R2 ; int pos = s - > pos ; uint32_t crc = s - > sc . crc ; uint32_t crc_extra_bits = s - > extra_sc . crc ; int16_t * dst16_l = dst_l ; int16_t * dst16_r = dst_r ; int32_t * dst32_l = dst_l ; int32_t * dst32_r = dst_r ; float * dstfl_l = dst_l ; float * dstfl_r = dst_r ; s - > one = s - > zero = s - > zeroes = 0 ; do { L = wv_get_value ( s , gb , 0 , & last ) ; if ( last ) break ; R = wv_get_value ( s , gb , 1 , & last ) ; if ( last ) break ; for ( i = 0 ; i < s - > terms ; i + + ) { t = s - > decorr[i] . value ; if ( t > 0 ) { if ( t > 8 ) { if ( t & 1 ) { A = 2U * s - > decorr[i] . samplesA[0] - s - > decorr[i] . samplesA[1] ; B = 2U * s - > decorr[i] . samplesB[0] - s - > decorr[i] . samplesB[1] ; } else { A = ( int ) ( 3U * s - > decorr[i] . samplesA[0] - s - > decorr[i] . samplesA[1] ) > > 1 ; B = ( int ) ( 3U * s - > decorr[i] . samplesB[0] - s - > decorr[i] . samplesB[1] ) > > 1 ; } s - > decorr[i] . samplesA[1] = s - > decorr[i] . samplesA[0] ; s - > decorr[i] . samplesB[1] = s - > decorr[i] . samplesB[0] ; j = 0 ; } else { A = s - > decorr[i] . samplesA[pos] ; B = s - > decorr[i] . samplesB[pos] ; j = ( pos + t ) & 7 ; } if ( type ! = AV_SAMPLE_FMT_S16P ) { L2 = L + ( ( s - > decorr[i] . weightA * ( int64_t ) A + 512 ) > > 10 ) ; R2 = R + ( ( s - > decorr[i] . weightB * ( int64_t ) B + 512 ) > > 10 ) ; } else { L2 = L + ( ( int ) ( s - > decorr[i] . weightA * ( unsigned ) A + 512 ) > > 10 ) ; R2 = R + ( ( int ) ( s - > decorr[i] . weightB * ( unsigned ) B + 512 ) > > 10 ) ; } if ( A & & L ) s - > decorr[i] . weightA - = ( ( ( ( L A ) > > 30 ) & 2 ) - 1 ) * s - > decorr[i] . delta ; if ( B & & R ) s - > decorr[i] . weightB - = ( ( ( ( R B ) > > 30 ) & 2 ) - 1 ) * s - > decorr[i] . delta ; s - > decorr[i] . samplesA[j] = L = L2 ; s - > decorr[i] . samplesB[j] = R = R2 ; } else if ( t == - 1 ) { if ( type ! = AV_SAMPLE_FMT_S16P ) L2 = L + ( ( s - > decorr[i] . weightA * ( int64_t ) s - > decorr[i] . samplesA[0] + 512 ) > > 10 ) ; else L2 = L + ( ( int ) ( s - > decorr[i] . weightA * ( unsigned ) s - > decorr[i] . samplesA[0] + 512 ) > > 10 ) ; UPDATE_WEIGHT_CLIP ( s - > decorr[i] . weightA , s - > decorr[i] . delta , s - > decorr[i] . samplesA[0] , L ) ; L = L2 ; if ( type ! = AV_SAMPLE_FMT_S16P ) R2 = R + ( ( s - > decorr[i] . weightB * ( int64_t ) L2 + 512 ) > > 10 ) ; else R2 = R + ( ( int ) ( s - > decorr[i] . weightB * ( unsigned ) L2 + 512 ) > > 10 ) ; UPDATE_WEIGHT_CLIP ( s - > decorr[i] . weightB , s - > decorr[i] . delta , L2 , R ) ; R = R2 ; s - > decorr[i] . samplesA[0] = R ; } else { if ( type ! = AV_SAMPLE_FMT_S16P ) R2 = R + ( ( s - > decorr[i] . weightB * ( int64_t ) s - > decorr[i] . samplesB[0] + 512 ) > > 10 ) ; else R2 = R + ( ( int ) ( s - > decorr[i] . weightB * ( unsigned ) s - > decorr[i] . samplesB[0] + 512 ) > > 10 ) ; UPDATE_WEIGHT_CLIP ( s - > decorr[i] . weightB , s - > decorr[i] . delta , s - > decorr[i] . samplesB[0] , R ) ; R = R2 ; if ( t == - 3 ) { R2 = s - > decorr[i] . samplesA[0] ; s - > decorr[i] . samplesA[0] = R ; } if ( type ! = AV_SAMPLE_FMT_S16P ) L2 = L + ( ( s - > decorr[i] . weightA * ( int64_t ) R2 + 512 ) > > 10 ) ; else L2 = L + ( ( int ) ( s - > decorr[i] . weightA * ( unsigned ) R2 + 512 ) > > 10 ) ; UPDATE_WEIGHT_CLIP ( s - > decorr[i] . weightA , s - > decorr[i] . delta , R2 , L ) ; L = L2 ; s - > decorr[i] . samplesB[0] = L ; } } if ( type == AV_SAMPLE_FMT_S16P ) { if ( FFABS ( L ) + ( unsigned ) FFABS ( R ) > ( 1 < < 19 ) ) { av_log ( s - > avctx , AV_LOG_ERROR , sample %d %d too large\n , L , R ) ; return AVERROR_INVALIDDATA ; } } pos = ( pos + 1 ) & 7 ; if ( s - > joint ) L + = ( unsigned ) ( R - = ( unsigned ) ( L > > 1 ) ) ; crc = ( crc * 3 + L ) * 3 + R ; if ( type == AV_SAMPLE_FMT_FLTP ) { * dstfl_l + + = wv_get_value_float ( s , & crc_extra_bits , L ) ; * dstfl_r + + = wv_get_value_float ( s , & crc_extra_bits , R ) ; } else if ( type == AV_SAMPLE_FMT_S32P ) { * dst32_l + + = wv_get_value_integer ( s , & crc_extra_bits , L",1
"static int decode_trns_chunk ( AVCodecContext * avctx , PNGDecContext * s , uint32_t length ) { int v , i ; if ( s - > color_type == PNG_COLOR_TYPE_PALETTE ) { if ( length > 256 || ! ( s - > state & PNG_PLTE ) ) return AVERROR_INVALIDDATA ; for ( i = 0 ; i < length ; i + + ) { v = bytestream2_get_byte ( & s - > gb ) ; s - > palette[i] = ( s - > palette[i] & 0x00ffffff ) | ( v < < 24 ) ; } } else if ( s - > color_type == PNG_COLOR_TYPE_GRAY || s - > color_type == PNG_COLOR_TYPE_RGB ) { if ( ( s - > color_type == PNG_COLOR_TYPE_GRAY & & length ! = 2 ) || ( s - > color_type == PNG_COLOR_TYPE_RGB & & length ! = 6 ) ) return AVERROR_INVALIDDATA ; for ( i = 0 ; i < length / 2 ; i + + ) { / * only use the least significant bits * / v = av_mod_uintp2 ( bytestream2_get_be16 ( & s - > gb ) , s - > bit_depth ) ; if ( s - > bit_depth > 8 ) AV_WB16 ( & s - > transparent_color_be[2 * i] , v ) ; else s - > transparent_color_be[i] = v ; } } else { return AVERROR_INVALIDDATA ; } bytestream2_skip ( & s - > gb , 4 ) ; / * crc * / s - > has_trns = 1 ; return 0 ; }",1
"static void compute_default_clut ( AVSubtitleRect * rect , int w , int h ) { uint8_t list[256] = { 0 } ; uint8_t list_inv[256] ; int counttab[256] = { 0 } ; int count , i , x , y ; define V ( x , y ) rect - > data[0][ ( x ) + ( y ) * rect - > linesize[0]] for ( y = 0 ; y < h ; y + + ) { for ( x = 0 ; x < w ; x + + ) { int v = V ( x , y ) + 1 ; int vl = x ? V ( x - 1 , y ) + 1 : 0 ; int vr = x + 1 < w ? V ( x + 1 , y ) + 1 : 0 ; int vt = y ? V ( x , y - 1 ) + 1 : 0 ; int vb = y + 1 < h ? V ( x , y + 1 ) + 1 : 0 ; counttab[v - 1] + = ! ! ( ( v ! =vl ) + ( v ! =vr ) + ( v ! =vt ) + ( v ! =vb ) ) ; } } define L ( x , y ) list[ rect - > data[0][ ( x ) + ( y ) * rect - > linesize[0]] ] for ( i = 0 ; i < 256 ; i + + ) { int scoretab[256] = { 0 } ; int bestscore = 0 ; int bestv = 0 ; for ( y = 0 ; y < h ; y + + ) { for ( x = 0 ; x < w ; x + + ) { int v = rect - > data[0][x + y * rect - > linesize[0]] ; int l_m = list[v] ; int l_l = x ? L ( x - 1 , y ) : 1 ; int l_r = x + 1 < w ? L ( x + 1 , y ) : 1 ; int l_t = y ? L ( x , y - 1 ) : 1 ; int l_b = y + 1 < h ? L ( x , y + 1 ) : 1 ; int score ; if ( l_m ) continue ; scoretab[v] + = l_l + l_r + l_t + l_b ; score = 1024LL * scoretab[v] / counttab[v] ; if ( score > bestscore ) { bestscore = score ; bestv = v ; } } } if ( ! bestscore ) break ; list [ bestv ] = 1 ; list_inv[ i ] = bestv ; } count = i - 1 ; for ( i - - ; i > =0 ; i - - ) { int v = i * 255/count ; AV_WN32 ( rect - > data[1] + 4 * list_inv[i] , RGBA ( v/2 , v , v/2 , v ) ) ; } }",1
"static int pvf_read_header ( AVFormatContext * s ) { char buffer[32] ; AVStream * st ; int bps , channels , sample_rate ; avio_skip ( s - > pb , 5 ) ; ff_get_line ( s - > pb , buffer , sizeof ( buffer ) ) ; if ( sscanf ( buffer , %d %d %d , & channels , & sample_rate , & bps ) ! = 3 ) return AVERROR_INVALIDDATA ; if ( channels < = 0 || bps < = 0 || sample_rate < = 0 ) return AVERROR_INVALIDDATA ; st = avformat_new_stream ( s , NULL ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; st - > codecpar - > codec_type = AVMEDIA_TYPE_AUDIO ; st - > codecpar - > channels = channels ; st - > codecpar - > sample_rate = sample_rate ; st - > codecpar - > codec_id = ff_get_pcm_codec_id ( bps , 0 , 1 , 0xFFFF ) ; st - > codecpar - > bits_per_coded_sample = bps ; st - > codecpar - > block_align = bps * st - > codecpar - > channels / 8 ; avpriv_set_pts_info ( st , 64 , 1 , st - > codecpar - > sample_rate ) ; return 0 ; }",1
"static inline int signed_shift ( int i , int shift ) { if ( shift > 0 ) return i < < shift ; return i > > - shift ; }",1
"static int doTest ( uint8_t * ref[4] , int refStride[4] , int w , int h , enum AVPixelFormat srcFormat , enum AVPixelFormat dstFormat , int srcW , int srcH , int dstW , int dstH , int flags , struct Results * r ) { static enum AVPixelFormat cur_srcFormat ; static int cur_srcW , cur_srcH ; static uint8_t * src[4] ; static int srcStride[4] ; uint8_t * dst[4] = { 0 } ; uint8_t * out[4] = { 0 } ; int dstStride[4] ; int i ; uint64_t ssdY , ssdU = 0 , ssdV = 0 , ssdA = 0 ; struct SwsContext * dstContext = NULL , * outContext = NULL ; uint32_t crc = 0 ; int res = 0 ; if ( cur_srcFormat ! = srcFormat || cur_srcW ! = srcW || cur_srcH ! = srcH ) { struct SwsContext * srcContext = NULL ; int p ; for ( p = 0 ; p < 4 ; p + + ) av_freep ( & src[p] ) ; av_image_fill_linesizes ( srcStride , srcFormat , srcW ) ; for ( p = 0 ; p < 4 ; p + + ) { srcStride[p] = FFALIGN ( srcStride[p] , 16 ) ; if ( srcStride[p] ) src[p] = av_mallocz ( srcStride[p] * srcH + 16 ) ; if ( srcStride[p] & & ! src[p] ) { perror ( Malloc ) ; res = - 1 ; goto end ; } } srcContext = sws_getContext ( w , h , AV_PIX_FMT_YUVA420P , srcW , srcH , srcFormat , SWS_BILINEAR , NULL , NULL , NULL ) ; if ( ! srcContext ) { fprintf ( stderr , Failed to get %s - - - > %s\n , av_pix_fmt_descriptors[AV_PIX_FMT_YUVA420P] . name , av_pix_fmt_descriptors[srcFormat] . name ) ; res = - 1 ; goto end ; } sws_scale ( srcContext , ref , refStride , 0 , h , src , srcStride ) ; sws_freeContext ( srcContext ) ; cur_srcFormat = srcFormat ; cur_srcW = srcW ; cur_srcH = srcH ; } av_image_fill_linesizes ( dstStride , dstFormat , dstW ) ; for ( i = 0 ; i < 4 ; i + + ) { / * Image buffers passed into libswscale can be allocated any way you * prefer , as long as they ' re aligned enough for the architecture , and * they ' re freed appropriately ( such as using av_free for buffers * allocated with av_malloc ) . * / / * An extra 16 bytes is being allocated because some scalers may write * out of bounds . * / dstStride[i] = FFALIGN ( dstStride[i] , 16 ) ; if ( dstStride[i] ) dst[i] = av_mallocz ( dstStride[i] * dstH + 16 ) ; if ( dstStride[i] & & ! dst[i] ) { perror ( Malloc ) ; res = - 1 ; goto end ; } } dstContext = sws_getContext ( srcW , srcH , srcFormat , dstW , dstH , dstFormat , flags , NULL , NULL , NULL ) ; if ( ! dstContext ) { fprintf ( stderr , Failed to get %s - - - > %s\n , av_pix_fmt_descriptors[srcFormat] . name , av_pix_fmt_descriptors[dstFormat] . name ) ; res = - 1 ; goto end ; } printf ( %s %dx%d - > %s %3dx%3d flags=%2d , av_pix_fmt_descriptors[srcFormat] . name , srcW , srcH , av_pix_fmt_descriptors[dstFormat] . name , dstW , dstH , flags ) ; fflush ( stdout ) ; sws_scale ( dstContext , src , srcStride , 0 , srcH , dst , dstStride ) ; for ( i = 0 ; i < 4 & & dstStride[i] ; i + + ) crc = av_crc ( av_crc_get_table ( AV_CRC_32_IEEE ) , crc , dst[i] , dstStride[i] * dstH ) ; if ( r & & crc == r - > crc ) { ssdY = r - > ssdY ; ssdU = r - > ssdU ; ssdV = r - > ssdV ; ssdA = r - > ssdA ; } else { for ( i = 0 ; i < 4 ; i + + ) { refStride[i] = FFALIGN ( refStride[i] , 16 ) ; if ( refStride[i] ) out[i] = av_mallocz ( refStride[i] * h ) ; if ( refStride[i] & & ! out[i] ) { perror ( Malloc ) ; res = - 1 ; goto end ; } } outContext = sws_getContext ( dstW , dstH , dstFormat , w , h , AV_PIX_FMT_YUVA420P , SWS_BILINEAR , NULL , NULL , NULL ) ; if ( ! outContext ) { fprintf ( stderr , Failed to get %s - - - > %s\n , av_pix_fmt_descriptors[dstFormat] . name , av_pix_fmt_descriptors[AV_PIX_FMT_YUVA420P] . name ) ; res = - 1 ; goto end ; } sws_scale ( outContext , dst , dstStride , 0 , dstH , out , refStride ) ; ssdY = getSSD ( ref[0] , out[0] , refStride[0] , refStride[0] , w , h ) ; if ( hasChroma ( srcFormat ) & & hasChroma ( dstFormat ) ) { //FIXME check that output is really gray ssdU = getSSD ( ref[1] , out[1] , refStride[1] , refStride[1] , ( w + 1 ) > > 1 , ( h + 1 ) > > 1 ) ; ssdV = getSSD ( ref[2] , out[2] , refStride[2] , refStride[2] , ( w + 1 ) > > 1 , ( h + 1 ) > > 1 ) ; } if ( isALPHA ( srcFormat ) & & isALPHA ( dstFormat ) ) ssdA = getSSD ( ref[3] , out[3] , refStride[3] , refStride[3] , w , h ) ; ssdY /= w * h ; ssdU /= w * h / 4 ; ssdV /= w * h / 4 ; ssdA /= w * h ; sws_freeContext ( outContext ) ; for ( i = 0 ; i < 4 ; i + + ) if ( refStride[i] ) av_free ( out[i] ) ; } printf ( CRC=%08x SSD=%5 PRId64 , %5 PRId64 , %5 PRId64 , %5 PRId64 \n , crc , ssdY , ssdU , ssdV , ssdA ) ; end : sws_freeContext ( dstContext ) ; for ( i = 0 ; i < 4 ; i + + ) if ( dstStride[i] ) av_free ( dst[i] ) ; return res ; }",1
"static inline void RENAME ( yuv2yuv1 ) ( int16_t * lumSrc , int16_t * chrSrc , uint8_t * dest , uint8_t * uDest , uint8_t * vDest , int dstW , int chrDstW ) { ifdef HAVE_MMX if ( uDest ! = NULL ) { asm volatile ( YSCALEYUV2YV121 : : r ( chrSrc + chrDstW ) , r ( uDest + chrDstW ) , g ( ( long ) - chrDstW ) : % REG_a ) ; asm volatile ( YSCALEYUV2YV121 : : r ( chrSrc + 2048 + chrDstW ) , r ( vDest + chrDstW ) , g ( ( long ) - chrDstW ) : % REG_a ) ; } asm volatile ( YSCALEYUV2YV121 : : r ( lumSrc + dstW ) , r ( dest + dstW ) , g ( ( long ) - dstW ) : % REG_a ) ; else int i ; for ( i=0 ; i < dstW ; i + + ) { int val= lumSrc[i] > > 7 ; if ( val & 256 ) { if ( val < 0 ) val=0 ; else val=255 ; } dest[i]= val ; } if ( uDest ! = NULL ) for ( i=0 ; i < chrDstW ; i + + ) { int u=chrSrc[i] > > 7 ; int v=chrSrc[i + 2048] > > 7 ; if ( ( u|v ) & 256 ) { if ( u < 0 ) u=0 ; else if ( u > 255 ) u=255 ; if ( v < 0 ) v=0 ; else if ( v > 255 ) v=255 ; } uDest[i]= u ; vDest[i]= v ; } endif }",1
"static int read_dialogue ( ASSContext * ass , AVBPrint * dst , const uint8_t * p , int64_t * start , int * duration ) { int pos ; int64_t end ; int hh1 , mm1 , ss1 , ms1 ; int hh2 , mm2 , ss2 , ms2 ; if ( sscanf ( p , Dialogue : % * [ , ] , %d : %d : %d% * c%d , %d : %d : %d% * c%d , %n , & hh1 , & mm1 , & ss1 , & ms1 , & hh2 , & mm2 , & ss2 , & ms2 , & pos ) > = 8 ) { / * This is not part of the sscanf itself in order to handle an actual * number ( which would be the Layer ) or the form Marked=N ( which is * the old SSA field , now replaced by Layer , and will be lead to Layer * being 0 here ) . * / const int layer = atoi ( p + 10 ) ; end = ( hh2 * 3600LL + mm2 * 60LL + ss2 ) * 100LL + ms2 ; * start = ( hh1 * 3600LL + mm1 * 60LL + ss1 ) * 100LL + ms1 ; * duration = end - * start ; av_bprint_clear ( dst ) ; av_bprintf ( dst , %u , %d , %s , ass - > readorder + + , layer , p + pos ) ; / * right strip the buffer * / while ( dst - > len > 0 & & dst - > str[dst - > len - 1] == ' \r ' || dst - > str[dst - > len - 1] == ' \n ' ) dst - > str[ - - dst - > len] = 0 ; return 0 ; } return - 1 ; }",1
"static inline int wv_get_value_integer ( WavpackFrameContext * s , uint32_t * crc , int S ) { unsigned bit ; if ( s - > extra_bits ) { S < < = s - > extra_bits ; if ( s - > got_extra_bits & & get_bits_left ( & s - > gb_extra_bits ) > = s - > extra_bits ) { S |= get_bits_long ( & s - > gb_extra_bits , s - > extra_bits ) ; * crc = * crc * 9 + ( S & 0xffff ) * 3 + ( ( unsigned ) S > > 16 ) ; } } bit = ( S & s - > and ) | s - > or ; bit = ( ( S + bit ) < < s - > shift ) - bit ; if ( s - > hybrid ) bit = av_clip ( bit , s - > hybrid_minclip , s - > hybrid_maxclip ) ; return bit < < s - > post_shift ; }",1
"static void quantize_bands ( int ( * out ) [2] , const float * in , const float * scaled , int size , float Q34 , int is_signed , int maxval ) { int i ; double qc ; for ( i = 0 ; i < size ; i + + ) { qc = scaled[i] * Q34 ; out[i][0] = ( int ) FFMIN ( ( int ) qc , maxval ) ; out[i][1] = ( int ) FFMIN ( ( int ) ( qc + 0 . 4054 ) , maxval ) ; if ( is_signed & & in[i] < 0 . 0f ) { out[i][0] = - out[i][0] ; out[i][1] = - out[i][1] ; } } }",1
"av_cold int vaapi_device_init ( const char * device ) { int err ; err = av_hwdevice_ctx_create ( & hw_device_ctx , AV_HWDEVICE_TYPE_VAAPI , device , NULL , 0 ) ; if ( err < 0 ) { av_log ( & vaapi_log , AV_LOG_ERROR , Failed to create a VAAPI device\n ) ; return err ; } return 0 ; }",1
"static int smvjpeg_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const AVPixFmtDescriptor * desc ; SMVJpegDecodeContext * s = avctx - > priv_data ; AVFrame * mjpeg_data = s - > picture[0] ; int i , cur_frame = 0 , ret = 0 ; cur_frame = avpkt - > pts % s - > frames_per_jpeg ; / * Are we at the start of a block ? * / if ( ! cur_frame ) { av_frame_unref ( mjpeg_data ) ; ret = avcodec_decode_video2 ( s - > avctx , mjpeg_data , & s - > mjpeg_data_size , avpkt ) ; if ( ret < 0 ) { s - > mjpeg_data_size = 0 ; return ret ; } } else if ( ! s - > mjpeg_data_size ) return AVERROR ( EINVAL ) ; desc = av_pix_fmt_desc_get ( s - > avctx - > pix_fmt ) ; if ( desc & & mjpeg_data - > height % ( s - > frames_per_jpeg < < desc - > log2_chroma_h ) ) { av_log ( avctx , AV_LOG_ERROR , Invalid height\n ) ; return AVERROR_INVALIDDATA ; } / * use the last lot . . . * / * data_size = s - > mjpeg_data_size ; avctx - > pix_fmt = s - > avctx - > pix_fmt ; / * We shouldn ' t get here if frames_per_jpeg < = 0 because this was rejected in init * / ret = ff_set_dimensions ( avctx , mjpeg_data - > width , mjpeg_data - > height / s - > frames_per_jpeg ) ; if ( ret < 0 ) { av_log ( s , AV_LOG_ERROR , Failed to set dimensions\n ) ; return ret ; } if ( * data_size ) { s - > picture[1] - > extended_data = NULL ; s - > picture[1] - > width = avctx - > width ; s - > picture[1] - > height = avctx - > height ; s - > picture[1] - > format = avctx - > pix_fmt ; / * ff_init_buffer_info ( avctx , & s - > picture[1] ) ; * / smv_img_pnt ( s - > picture[1] - > data , mjpeg_data - > data , mjpeg_data - > linesize , avctx - > pix_fmt , avctx - > width , avctx - > height , cur_frame ) ; for ( i = 0 ; i < AV_NUM_DATA_POINTERS ; i + + ) s - > picture[1] - > linesize[i] = mjpeg_data - > linesize[i] ; ret = av_frame_ref ( data , s - > picture[1] ) ; } return ret ; }",1
"static void rtsp_parse_rtp_info ( RTSPState * rt , const char * p ) { int read = 0 ; char key[20] , value[1024] , url[1024] = ; uint32_t seq = 0 , rtptime = 0 ; for ( ; ; ) { p + = strspn ( p , SPACE_CHARS ) ; if ( ! * p ) break ; get_word_sep ( key , sizeof ( key ) , = , & p ) ; if ( * p ! = ' = ' ) break ; p + + ; get_word_sep ( value , sizeof ( value ) , ; , , & p ) ; read + + ; if ( ! strcmp ( key , url ) ) av_strlcpy ( url , value , sizeof ( url ) ) ; else if ( ! strcmp ( key , seq ) ) seq = strtol ( value , NULL , 10 ) ; else if ( ! strcmp ( key , rtptime ) ) rtptime = strtol ( value , NULL , 10 ) ; if ( * p == ' , ' ) { handle_rtp_info ( rt , url , seq , rtptime ) ; url[0] = ' \0 ' ; seq = rtptime = 0 ; read = 0 ; } if ( * p ) p + + ; } if ( read > 0 ) handle_rtp_info ( rt , url , seq , rtptime ) ; }",0
"static int bink_decode_plane ( BinkContext * c , AVFrame * frame , BitstreamContext * bc , int plane_idx , int is_chroma ) { int blk , ret ; int i , j , bx , by ; uint8_t * dst , * prev , * ref_start , * ref_end ; int v , col[2] ; const uint8_t * scan ; LOCAL_ALIGNED_16 ( int16_t , block , [64] ) ; LOCAL_ALIGNED_16 ( uint8_t , ublock , [64] ) ; LOCAL_ALIGNED_16 ( int32_t , dctblock , [64] ) ; int coordmap[64] ; const int stride = frame - > linesize[plane_idx] ; int bw = is_chroma ? ( c - > avctx - > width + 15 ) > > 4 : ( c - > avctx - > width + 7 ) > > 3 ; int bh = is_chroma ? ( c - > avctx - > height + 15 ) > > 4 : ( c - > avctx - > height + 7 ) > > 3 ; int width = c - > avctx - > width > > is_chroma ; init_lengths ( c , FFMAX ( width , 8 ) , bw ) ; for ( i = 0 ; i < BINK_NB_SRC ; i + + ) read_bundle ( bc , c , i ) ; ref_start = c - > last - > data[plane_idx] ? c - > last - > data[plane_idx] : frame - > data[plane_idx] ; ref_end = ref_start + ( bw - 1 + c - > last - > linesize[plane_idx] * ( bh - 1 ) ) * 8 ; for ( i = 0 ; i < 64 ; i + + ) coordmap[i] = ( i & 7 ) + ( i > > 3 ) * stride ; for ( by = 0 ; by < bh ; by + + ) { if ( ( ret = read_block_types ( c - > avctx , bc , & c - > bundle[BINK_SRC_BLOCK_TYPES] ) ) < 0 ) return ret ; if ( ( ret = read_block_types ( c - > avctx , bc , & c - > bundle[BINK_SRC_SUB_BLOCK_TYPES] ) ) < 0 ) return ret ; if ( ( ret = read_colors ( bc , & c - > bundle[BINK_SRC_COLORS] , c ) ) < 0 ) return ret ; if ( ( ret = read_patterns ( c - > avctx , bc , & c - > bundle[BINK_SRC_PATTERN] ) ) < 0 ) return ret ; if ( ( ret = read_motion_values ( c - > avctx , bc , & c - > bundle[BINK_SRC_X_OFF] ) ) < 0 ) return ret ; if ( ( ret = read_motion_values ( c - > avctx , bc , & c - > bundle[BINK_SRC_Y_OFF] ) ) < 0 ) return ret ; if ( ( ret = read_dcs ( c - > avctx , bc , & c - > bundle[BINK_SRC_INTRA_DC] , DC_START_BITS , 0 ) ) < 0 ) return ret ; if ( ( ret = read_dcs ( c - > avctx , bc , & c - > bundle[BINK_SRC_INTER_DC] , DC_START_BITS , 1 ) ) < 0 ) return ret ; if ( ( ret = read_runs ( c - > avctx , bc , & c - > bundle[BINK_SRC_RUN] ) ) < 0 ) return ret ; if ( by == bh ) break ; dst = frame - > data[plane_idx] + 8 * by * stride ; prev = ( c - > last - > data[plane_idx] ? c - > last - > data[plane_idx] : frame - > data[plane_idx] ) + 8 * by * stride ; for ( bx = 0 ; bx < bw ; bx + + , dst + = 8 , prev + = 8 ) { blk = get_value ( c , BINK_SRC_BLOCK_TYPES ) ; // 16x16 block type on odd line means part of the already decoded block , so skip it if ( ( by & 1 ) & & blk == SCALED_BLOCK ) { bx + + ; dst + = 8 ; prev + = 8 ; continue ; } switch ( blk ) { case SKIP_BLOCK : c - > hdsp . put_pixels_tab[1][0] ( dst , prev , stride , 8 ) ; break ; case SCALED_BLOCK : blk = get_value ( c , BINK_SRC_SUB_BLOCK_TYPES ) ; switch ( blk ) { case RUN_BLOCK : scan = bink_patterns[bitstream_read ( bc , 4 ) ] ; i = 0 ; do { int run = get_value ( c , BINK_SRC_RUN ) + 1 ; i + = run ; if ( i > 64 ) { av_log ( c - > avctx , AV_LOG_ERROR , Run went out of bounds\n ) ; return AVERROR_INVALIDDATA ; } if ( bitstream_read_bit ( bc ) ) { v = get_value ( c , BINK_SRC_COLORS ) ; for ( j = 0 ; j < run ; j + + ) ublock[ * scan + + ] = v ; } else { for ( j = 0 ; j < run ; j + + ) ublock[ * scan + + ] = get_value ( c , BINK_SRC_COLORS ) ; } } while ( i < 63 ) ; if ( i == 63 ) ublock[ * scan + + ] = get_value ( c , BINK_SRC_COLORS ) ; break ; case INTRA_BLOCK : memset ( dctblock , 0 , sizeof ( * dctblock ) * 64 ) ; dctblock[0] = get_value ( c , BINK_SRC_INTRA_DC ) ; read_dct_coeffs ( bc , dctblock , bink_scan , bink_intra_quant , - 1 ) ; c - > binkdsp . idct_put ( ublock , 8 , dctblock ) ; break ; case FILL_BLOCK : v = get_value ( c , BINK_SRC_COLORS ) ; c - > bdsp . fill_block_tab[0] ( dst , v , stride , 16 ) ; break ; case PATTERN_BLOCK : for ( i = 0 ; i < 2 ; i + + ) col[i] = get_value ( c , BINK_SRC_COLORS ) ; for ( j = 0 ; j < 8 ; j + + ) { v = get_value ( c , BINK_SRC_PATTERN ) ; for ( i = 0 ; i < 8 ; i + + , v > > = 1 ) ublock[i + j * 8] = col[v & 1] ; } break ; case RAW_BLOCK : for ( j = 0 ; j < 8 ; j + + ) for ( i = 0 ; i < 8 ; i + + ) ublock[i + j * 8] = get_value ( c , BINK_SRC_COLORS ) ; break ; default : av_log ( c - > avctx , AV_LOG_ERROR , Incorrect 16x16 block type %d\n , blk ) ; return AVERROR_INVALIDDATA ; } if ( blk ! = FILL_BLOCK ) c - > binkdsp . scale_block ( ublock , dst , stride ) ; bx + + ; dst + = 8 ; prev + = 8 ; break ; case MOTION_BLOCK : ret = bink_put_pixels ( c , dst , prev , stride , ref_start ,",0
"static void opt_frame_pad_right ( const char * arg ) { frame_padright = atoi ( arg ) ; if ( frame_padright < 0 ) { fprintf ( stderr , Incorrect right pad size\n ) ; av_exit ( 1 ) ; } }",0
"static int dcadec_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame_ptr , AVPacket * avpkt ) { DCAContext * s = avctx - > priv_data ; AVFrame * frame = data ; uint8_t * input = avpkt - > data ; int input_size = avpkt - > size ; int i , ret , prev_packet = s - > packet ; if ( input_size < MIN_PACKET_SIZE || input_size > MAX_PACKET_SIZE ) { av_log ( avctx , AV_LOG_ERROR , Invalid packet size\n ) ; return AVERROR_INVALIDDATA ; } av_fast_malloc ( & s - > buffer , & s - > buffer_size , FFALIGN ( input_size , 4096 ) + DCA_BUFFER_PADDING_SIZE ) ; if ( ! s - > buffer ) return AVERROR ( ENOMEM ) ; for ( i = 0 , ret = AVERROR_INVALIDDATA ; i < input_size - MIN_PACKET_SIZE + 1 & & ret < 0 ; i + + ) ret = convert_bitstream ( input + i , input_size - i , s - > buffer , s - > buffer_size ) ; if ( ret < 0 ) { av_log ( avctx , AV_LOG_ERROR , Not a valid DCA frame\n ) ; return ret ; } input = s - > buffer ; input_size = ret ; s - > packet = 0 ; // Parse backward compatible core sub - stream if ( AV_RB32 ( input ) == DCA_SYNCWORD_CORE_BE ) { int frame_size ; if ( ( ret = ff_dca_core_parse ( & s - > core , input , input_size ) ) < 0 ) return ret ; s - > packet |= DCA_PACKET_CORE ; // EXXS data must be aligned on 4 - byte boundary frame_size = FFALIGN ( s - > core . frame_size , 4 ) ; if ( input_size - 4 > frame_size ) { input + = frame_size ; input_size - = frame_size ; } } if ( ! s - > core_only ) { DCAExssAsset * asset = NULL ; // Parse extension sub - stream ( EXSS ) if ( AV_RB32 ( input ) == DCA_SYNCWORD_SUBSTREAM ) { if ( ( ret = ff_dca_exss_parse ( & s - > exss , input , input_size ) ) < 0 ) { if ( avctx - > err_recognition & AV_EF_EXPLODE ) return ret ; } else { s - > packet |= DCA_PACKET_EXSS ; asset = & s - > exss . assets[0] ; } } // Parse XLL component in EXSS if ( asset & & ( asset - > extension_mask & DCA_EXSS_XLL ) ) { if ( ( ret = ff_dca_xll_parse ( & s - > xll , input , asset ) ) < 0 ) { // Conceal XLL synchronization error if ( ret == AVERROR ( EAGAIN ) & & ( prev_packet & DCA_PACKET_XLL ) & & ( s - > packet & DCA_PACKET_CORE ) ) s - > packet |= DCA_PACKET_XLL | DCA_PACKET_RECOVERY ; else if ( ret == AVERROR ( ENOMEM ) || ( avctx - > err_recognition & AV_EF_EXPLODE ) ) return ret ; } else { s - > packet |= DCA_PACKET_XLL ; } } // Parse LBR component in EXSS if ( asset & & ( asset - > extension_mask & DCA_EXSS_LBR ) ) { if ( ( ret = ff_dca_lbr_parse ( & s - > lbr , input , asset ) ) < 0 ) { if ( ret == AVERROR ( ENOMEM ) || ( avctx - > err_recognition & AV_EF_EXPLODE ) ) return ret ; } else { s - > packet |= DCA_PACKET_LBR ; } } // Parse core extensions in EXSS or backward compatible core sub - stream if ( ( s - > packet & DCA_PACKET_CORE ) & & ( ret = ff_dca_core_parse_exss ( & s - > core , input , asset ) ) < 0 ) return ret ; } // Filter the frame if ( s - > packet & DCA_PACKET_LBR ) { if ( ( ret = ff_dca_lbr_filter_frame ( & s - > lbr , frame ) ) < 0 ) return ret ; } else if ( s - > packet & DCA_PACKET_XLL ) { if ( s - > packet & DCA_PACKET_CORE ) { int x96_synth = - 1 ; // Enable X96 synthesis if needed if ( s - > xll . chset[0] . freq == 96000 & & s - > core . sample_rate == 48000 ) x96_synth = 1 ; if ( ( ret = ff_dca_core_filter_fixed ( & s - > core , x96_synth ) ) < 0 ) return ret ; // Force lossy downmixed output on the first core frame filtered . // This prevents audible clicks when seeking and is consistent with // what reference decoder does when there are multiple channel sets . if ( ! ( prev_packet & DCA_PACKET_RESIDUAL ) & & s - > xll . nreschsets > 0 & & s - > xll . nchsets > 1 ) { av_log ( avctx , AV_LOG_VERBOSE , Forcing XLL recovery mode\n ) ; s - > packet |= DCA_PACKET_RECOVERY ; } // Set ' residual ok ' flag for the next frame s - > packet |= DCA_PACKET_RESIDUAL ; } if ( ( ret = ff_dca_xll_filter_frame ( & s - > xll , frame ) ) < 0 ) { // Fall back to core unless hard error if ( ! ( s - > packet & DCA_PACKET_CORE ) ) return ret ; if ( ret ! = AVERROR_INVALIDDATA || ( avctx - > err_recognition & AV_EF_EXPLODE ) ) return ret ; if ( ( ret = ff_dca_core_filter_frame ( & s - > core , frame ) ) < 0 ) return ret ; } } else if ( s - > packet & DCA_PACKET_CORE ) { if ( ( ret = ff_dca_core_filter_frame ( & s - > core , frame ) ) < 0 ) return ret ; if ( s - > core . filter_mode & DCA_FILTER_MODE_FIXED ) s - > packet |= DCA_PACKET_RESIDUAL ; } else { av_log ( avctx , AV_LOG_ERROR , No valid DCA sub - stream found\n ) ; if ( s - > core_only ) av_log ( avctx , AV_LOG_WARNING , Consider disabling ' core_only ' option\n ) ; return AVERROR_INVALIDDATA ; } * got_frame_ptr = 1 ; return avpkt - > size ; }",0
"static int iszero ( const int16_t * c , int sz ) { int n ; for ( n = 0 ; n < sz ; n + = 4 ) if ( AV_RN32A ( & c[n] ) ) return 0 ; return 1 ; }",0
"void avpriv_set_pts_info ( AVStream * s , int pts_wrap_bits , unsigned int pts_num , unsigned int pts_den ) { AVRational new_tb ; if ( av_reduce ( & new_tb . num , & new_tb . den , pts_num , pts_den , INT_MAX ) ) { if ( new_tb . num ! = pts_num ) av_log ( NULL , AV_LOG_DEBUG , st : %d removing common factor %d from timebase\n , s - > index , pts_num/new_tb . num ) ; } else av_log ( NULL , AV_LOG_WARNING , st : %d has too large timebase , reducing\n , s - > index ) ; if ( new_tb . num < = 0 || new_tb . den < = 0 ) { av_log ( NULL , AV_LOG_ERROR , Ignoring attempt to set invalid timebase for st : %d\n , s - > index ) ; return ; } s - > time_base = new_tb ; s - > pts_wrap_bits = pts_wrap_bits ; }",0
"static void RENAME ( interleaveBytes ) ( const uint8_t * src1 , const uint8_t * src2 , uint8_t * dest , int width , int height , int src1Stride , int src2Stride , int dstStride ) { int h ; for ( h=0 ; h < height ; h + + ) { int w ; if ( width > = 16 ) if COMPILE_TEMPLATE_SSE2 __asm__ ( xor %% REG_a , %% REG_a \n\t 1 : \n\t PREFETCH 64 ( %1 , %% REG_a ) \n\t PREFETCH 64 ( %2 , %% REG_a ) \n\t movdqa ( %1 , %% REG_a ) , %%xmm0 \n\t movdqa ( %1 , %% REG_a ) , %%xmm1 \n\t movdqa ( %2 , %% REG_a ) , %%xmm2 \n\t punpcklbw %%xmm2 , %%xmm0 \n\t punpckhbw %%xmm2 , %%xmm1 \n\t movntdq %%xmm0 , ( %0 , %% REG_a , 2 ) \n\t movntdq %%xmm1 , 16 ( %0 , %% REG_a , 2 ) \n\t add 16 , %% REG_a \n\t cmp %3 , %% REG_a \n\t jb 1b \n\t : : r ( dest ) , r ( src1 ) , r ( src2 ) , r ( ( x86_reg ) width - 15 ) : memory , XMM_CLOBBERS ( xmm0 , xmm1 , xmm2 , ) % REG_a ) ; else __asm__ ( xor %% REG_a , %% REG_a \n\t 1 : \n\t PREFETCH 64 ( %1 , %% REG_a ) \n\t PREFETCH 64 ( %2 , %% REG_a ) \n\t movq ( %1 , %% REG_a ) , %%mm0 \n\t movq 8 ( %1 , %% REG_a ) , %%mm2 \n\t movq %%mm0 , %%mm1 \n\t movq %%mm2 , %%mm3 \n\t movq ( %2 , %% REG_a ) , %%mm4 \n\t movq 8 ( %2 , %% REG_a ) , %%mm5 \n\t punpcklbw %%mm4 , %%mm0 \n\t punpckhbw %%mm4 , %%mm1 \n\t punpcklbw %%mm5 , %%mm2 \n\t punpckhbw %%mm5 , %%mm3 \n\t MOVNTQ %%mm0 , ( %0 , %% REG_a , 2 ) \n\t MOVNTQ %%mm1 , 8 ( %0 , %% REG_a , 2 ) \n\t MOVNTQ %%mm2 , 16 ( %0 , %% REG_a , 2 ) \n\t MOVNTQ %%mm3 , 24 ( %0 , %% REG_a , 2 ) \n\t add 16 , %% REG_a \n\t cmp %3 , %% REG_a \n\t jb 1b \n\t : : r ( dest ) , r ( src1 ) , r ( src2 ) , r ( ( x86_reg ) width - 15 ) : memory , % REG_a ) ; endif for ( w= ( width & ( 15 ) ) ; w < width ; w + + ) { dest[2 * w + 0] = src1[w] ; dest[2 * w + 1] = src2[w] ; } dest + = dstStride ; src1 + = src1Stride ; src2 + = src2Stride ; } __asm__ ( if ! COMPILE_TEMPLATE_SSE2 EMMS \n\t endif SFENCE \n\t : : : memory ) ; }",1
"static int dvbsub_parse_page_segment ( AVCodecContext * avctx , const uint8_t * buf , int buf_size , AVSubtitle * sub , int * got_output ) { DVBSubContext * ctx = avctx - > priv_data ; DVBSubRegionDisplay * display ; DVBSubRegionDisplay * tmp_display_list , * * tmp_ptr ; const uint8_t * buf_end = buf + buf_size ; int region_id ; int page_state ; int timeout ; int version ; if ( buf_size < 1 ) return AVERROR_INVALIDDATA ; timeout = * buf + + ; version = ( ( * buf ) > > 4 ) & 15 ; page_state = ( ( * buf + + ) > > 2 ) & 3 ; if ( ctx - > version == version ) { return 0 ; ctx - > time_out = timeout ; ctx - > version = version ; ff_dlog ( avctx , Page time out %ds , state %d\n , ctx - > time_out , page_state ) ; if ( ctx - > compute_edt == 1 ) save_subtitle_set ( avctx , sub , got_output ) ; if ( page_state == 1 || page_state == 2 ) { delete_regions ( ctx ) ; delete_objects ( ctx ) ; delete_cluts ( ctx ) ; tmp_display_list = ctx - > display_list ; ctx - > display_list = NULL ; while ( buf + 5 < buf_end ) { region_id = * buf + + ; buf + = 1 ; display = tmp_display_list ; tmp_ptr = & tmp_display_list ; tmp_ptr = & display - > next ; if ( ! display ) { display = av_mallocz ( sizeof ( DVBSubRegionDisplay ) ) ; if ( ! display ) return AVERROR ( ENOMEM ) ; display - > region_id = region_id ; display - > x_pos = AV_RB16 ( buf ) ; buf + = 2 ; display - > y_pos = AV_RB16 ( buf ) ; buf + = 2 ; * tmp_ptr = display - > next ; display - > next = ctx - > display_list ; ctx - > display_list = display ; ff_dlog ( avctx , Region %d , ( %d , %d ) \n , region_id , display - > x_pos , display - > y_pos ) ; while ( tmp_display_list ) { display = tmp_display_list ; tmp_display_list = display - > next ; av_freep ( & display ) ; return 0 ;",1
"static inline void ls_decode_line ( JLSState * state , MJpegDecodeContext * s , void * last , void * dst , int last2 , int w , int stride , int comp , int bits ) { int i , x = 0 ; int Ra , Rb , Rc , Rd ; int D0 , D1 , D2 ; while ( x < w ) { int err , pred ; / * compute gradients * / Ra = x ? R ( dst , x - stride ) : R ( last , x ) ; Rb = R ( last , x ) ; Rc = x ? R ( last , x - stride ) : last2 ; Rd = ( x > = w - stride ) ? R ( last , x ) : R ( last , x + stride ) ; D0 = Rd - Rb ; D1 = Rb - Rc ; D2 = Rc - Ra ; / * run mode * / if ( ( FFABS ( D0 ) < = state - > near ) & & ( FFABS ( D1 ) < = state - > near ) & & ( FFABS ( D2 ) < = state - > near ) ) { int r ; int RItype ; / * decode full runs while available * / while ( get_bits1 ( & s - > gb ) ) { int r ; r = 1 < < ff_log2_run[state - > run_index[comp]] ; if ( x + r * stride > w ) r = ( w - x ) / stride ; for ( i = 0 ; i < r ; i + + ) { W ( dst , x , Ra ) ; x + = stride ; } / * if EOL reached , we stop decoding * / if ( r ! = 1 < < ff_log2_run[state - > run_index[comp]] ) if ( state - > run_index[comp] < 31 ) state - > run_index[comp] + + ; if ( x + stride > w ) } / * decode aborted run * / r = ff_log2_run[state - > run_index[comp]] ; if ( r ) r = get_bits_long ( & s - > gb , r ) ; if ( x + r * stride > w ) { r = ( w - x ) / stride ; } for ( i = 0 ; i < r ; i + + ) { W ( dst , x , Ra ) ; x + = stride ; } if ( x > = w ) { av_log ( NULL , AV_LOG_ERROR , run overflow\n ) ; av_assert0 ( x < = w ) ; } / * decode run termination value * / Rb = R ( last , x ) ; RItype = ( FFABS ( Ra - Rb ) < = state - > near ) ? 1 : 0 ; err = ls_get_code_runterm ( & s - > gb , state , RItype , ff_log2_run[state - > run_index[comp]] ) ; if ( state - > run_index[comp] ) state - > run_index[comp] - - ; if ( state - > near & & RItype ) { pred = Ra + err ; } else { if ( Rb < Ra ) pred = Rb - err ; else pred = Rb + err ; } } else { / * regular mode * / int context , sign ; context = ff_jpegls_quantize ( state , D0 ) * 81 + ff_jpegls_quantize ( state , D1 ) * 9 + ff_jpegls_quantize ( state , D2 ) ; pred = mid_pred ( Ra , Ra + Rb - Rc , Rb ) ; if ( context < 0 ) { context = - context ; sign = 1 ; } else { sign = 0 ; } if ( sign ) { pred = av_clip ( pred - state - > C[context] , 0 , state - > maxval ) ; err = - ls_get_code_regular ( & s - > gb , state , context ) ; } else { pred = av_clip ( pred + state - > C[context] , 0 , state - > maxval ) ; err = ls_get_code_regular ( & s - > gb , state , context ) ; } / * we have to do something more for near - lossless coding * / pred + = err ; } if ( state - > near ) { if ( pred < - state - > near ) pred + = state - > range * state - > twonear ; else if ( pred > state - > maxval + state - > near ) pred - = state - > range * state - > twonear ; pred = av_clip ( pred , 0 , state - > maxval ) ; } pred & = state - > maxval ; W ( dst , x , pred ) ; x + = stride ; } }",1
"static int finish_frame ( AVCodecContext * avctx , AVFrame * pict ) { RV34DecContext * r = avctx - > priv_data ; MpegEncContext * s = & r - > s ; int got_picture = 0 ; ff_er_frame_end ( s ) ; ff_MPV_frame_end ( s ) ; if ( HAVE_THREADS & & ( s - > avctx - > active_thread_type & FF_THREAD_FRAME ) ) ff_thread_report_progress ( & s - > current_picture_ptr - > f , INT_MAX , 0 ) ; if ( s - > pict_type == AV_PICTURE_TYPE_B || s - > low_delay ) { * pict = s - > current_picture_ptr - > f ; got_picture = 1 ; } else if ( s - > last_picture_ptr ! = NULL ) { * pict = s - > last_picture_ptr - > f ; got_picture = 1 ; } if ( got_picture ) ff_print_debug_info ( s , pict ) ; return got_picture ; }",1
"static int load_matrix ( MpegEncContext * s , uint16_t matrix0[64] , uint16_t matrix1[64] , int intra ) { int i ; for ( i = 0 ; i < 64 ; i + + ) { int j = s - > dsp . idct_permutation[ff_zigzag_direct[i]] ; int v = get_bits ( & s - > gb , 8 ) ; if ( v == 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , matrix damaged\n ) ; return - 1 ; } if ( intra & & i == 0 & & v ! = 8 ) { av_log ( s - > avctx , AV_LOG_ERROR , intra matrix specifies invalid DC quantizer %d , ignoring\n , v ) ; v = 8 ; // needed by pink . mpg / issue1046 } matrix0[j] = v ; if ( matrix1 ) matrix1[j] = v ; } return 0 ; }",0
"static int s337m_probe ( AVProbeData * p ) { uint64_t state = 0 ; int markers[3] = { 0 } ; int i , sum , max , data_type , data_size , offset ; uint8_t * buf ; for ( buf = p - > buf ; buf < p - > buf + p - > buf_size ; buf + + ) { state = ( state < < 8 ) | * buf ; if ( ! IS_LE_MARKER ( state ) ) continue ; if ( IS_16LE_MARKER ( state ) ) { data_type = AV_RL16 ( buf + 1 ) ; data_size = AV_RL16 ( buf + 3 ) ; buf + = 4 ; } else { data_type = AV_RL24 ( buf + 1 ) ; data_size = AV_RL24 ( buf + 4 ) ; buf + = 6 ; } if ( s337m_get_offset_and_codec ( NULL , state , data_type , data_size , & offset , NULL ) ) continue ; i = IS_16LE_MARKER ( state ) ? 0 : IS_20LE_MARKER ( state ) ? 1 : 2 ; markers[i] + + ; buf + = offset ; state = 0 ; } sum = max = 0 ; for ( i = 0 ; i < FF_ARRAY_ELEMS ( markers ) ; i + + ) { sum + = markers[i] ; if ( markers[max] < markers[i] ) max = i ; } if ( markers[max] > 3 & & markers[max] * 4 > sum * 3 ) return AVPROBE_SCORE_EXTENSION + 1 ; return 0 ; }",0
"static inline void RENAME ( yuv2nv12X ) ( SwsContext * c , const int16_t * lumFilter , const int16_t * * lumSrc , int lumFilterSize , const int16_t * chrFilter , const int16_t * * chrSrc , int chrFilterSize , uint8_t * dest , uint8_t * uDest , int dstW , int chrDstW , enum PixelFormat dstFormat ) { yuv2nv12XinC ( lumFilter , lumSrc , lumFilterSize , chrFilter , chrSrc , chrFilterSize , dest , uDest , dstW , chrDstW , dstFormat ) ; }",0
"int get_filtered_video_frame ( AVFilterContext * ctx , AVFrame * frame , AVFilterBufferRef * * picref_ptr , AVRational * tb ) { int ret ; AVFilterBufferRef * picref ; if ( ( ret = avfilter_request_frame ( ctx - > inputs[0] ) ) < 0 ) return ret ; if ( ! ( picref = ctx - > inputs[0] - > cur_buf ) ) return AVERROR ( ENOENT ) ; * picref_ptr = picref ; ctx - > inputs[0] - > cur_buf = NULL ; * tb = ctx - > inputs[0] - > time_base ; memcpy ( frame - > data , picref - > data , sizeof ( frame - > data ) ) ; memcpy ( frame - > linesize , picref - > linesize , sizeof ( frame - > linesize ) ) ; frame - > pkt_pos = picref - > pos ; frame - > interlaced_frame = picref - > video - > interlaced ; frame - > top_field_first = picref - > video - > top_field_first ; frame - > key_frame = picref - > video - > key_frame ; frame - > pict_type = picref - > video - > pict_type ; frame - > sample_aspect_ratio = picref - > video - > sample_aspect_ratio ; return 1 ; }",1
"static int hq_decode_block ( HQContext * c , GetBitContext * gb , int16_t block[64] , int qsel , int is_chroma , int is_hqa ) { const int32_t * q ; int val , pos = 1 ; memset ( block , 0 , 64 * sizeof ( * block ) ) ; if ( ! is_hqa ) { block[0] = get_sbits ( gb , 9 ) * 64 ; q = ff_hq_quants[qsel][is_chroma][get_bits ( gb , 2 ) ] ; } else { q = ff_hq_quants[qsel][is_chroma][get_bits ( gb , 2 ) ] ; block[0] = get_sbits ( gb , 9 ) * 64 ; } for ( ; ; ) { val = get_vlc2 ( gb , c - > hq_ac_vlc . table , 9 , 2 ) ; if ( val < 0 ) return AVERROR_INVALIDDATA ; pos + = ff_hq_ac_skips[val] ; if ( pos > = 64 ) break ; block[ff_zigzag_direct[pos]] = ( ff_hq_ac_syms[val] * q[pos] ) > > 12 ; pos + + ; } return 0 ; }",1
void dsputil_init_alpha ( void ) { put_pixels_tab[0][0] = put_pixels16_axp_asm ; put_pixels_tab[0][1] = put_pixels16_x2_axp ; put_pixels_tab[0][2] = put_pixels16_y2_axp ; put_pixels_tab[0][3] = put_pixels16_xy2_axp ; put_no_rnd_pixels_tab[0][0] = put_pixels16_axp_asm ; put_no_rnd_pixels_tab[0][1] = put_no_rnd_pixels16_x2_axp ; put_no_rnd_pixels_tab[0][2] = put_no_rnd_pixels16_y2_axp ; put_no_rnd_pixels_tab[0][3] = put_no_rnd_pixels16_xy2_axp ; avg_pixels_tab[0][0] = avg_pixels16_axp ; avg_pixels_tab[0][1] = avg_pixels16_x2_axp ; avg_pixels_tab[0][2] = avg_pixels16_y2_axp ; avg_pixels_tab[0][3] = avg_pixels16_xy2_axp ; avg_no_rnd_pixels_tab[0][0] = avg_no_rnd_pixels16_axp ; avg_no_rnd_pixels_tab[0][1] = avg_no_rnd_pixels16_x2_axp ; avg_no_rnd_pixels_tab[0][2] = avg_no_rnd_pixels16_y2_axp ; avg_no_rnd_pixels_tab[0][3] = avg_no_rnd_pixels16_xy2_axp ; put_pixels_tab[1][0] = put_pixels_axp_asm ; put_pixels_tab[1][1] = put_pixels_x2_axp ; put_pixels_tab[1][2] = put_pixels_y2_axp ; put_pixels_tab[1][3] = put_pixels_xy2_axp ; put_no_rnd_pixels_tab[1][0] = put_pixels_axp_asm ; put_no_rnd_pixels_tab[1][1] = put_no_rnd_pixels_x2_axp ; put_no_rnd_pixels_tab[1][2] = put_no_rnd_pixels_y2_axp ; put_no_rnd_pixels_tab[1][3] = put_no_rnd_pixels_xy2_axp ; avg_pixels_tab[1][0] = avg_pixels_axp ; avg_pixels_tab[1][1] = avg_pixels_x2_axp ; avg_pixels_tab[1][2] = avg_pixels_y2_axp ; avg_pixels_tab[1][3] = avg_pixels_xy2_axp ; avg_no_rnd_pixels_tab[1][0] = avg_no_rnd_pixels_axp ; avg_no_rnd_pixels_tab[1][1] = avg_no_rnd_pixels_x2_axp ; avg_no_rnd_pixels_tab[1][2] = avg_no_rnd_pixels_y2_axp ; avg_no_rnd_pixels_tab[1][3] = avg_no_rnd_pixels_xy2_axp ; clear_blocks = clear_blocks_axp ; / * amask clears all bits that correspond to present features . * / if ( amask ( AMASK_MVI ) == 0 ) { put_pixels_clamped = put_pixels_clamped_mvi_asm ; add_pixels_clamped = add_pixels_clamped_mvi_asm ; get_pixels = get_pixels_mvi ; diff_pixels = diff_pixels_mvi ; pix_abs8x8 = pix_abs8x8_mvi ; pix_abs16x16 = pix_abs16x16_mvi_asm ; pix_abs16x16_x2 = pix_abs16x16_x2_mvi ; pix_abs16x16_y2 = pix_abs16x16_y2_mvi ; pix_abs16x16_xy2 = pix_abs16x16_xy2_mvi ; } },0
"AVFrame * ff_framequeue_take ( FFFrameQueue * fq ) { FFFrameBucket * b ; check_consistency ( fq ) ; av_assert1 ( fq - > queued ) ; b = bucket ( fq , 0 ) ; fq - > queued - - ; fq - > tail + + ; fq - > tail & = fq - > allocated - 1 ; fq - > total_frames_tail + + ; fq - > total_samples_tail + = b - > frame - > nb_samples ; check_consistency ( fq ) ; return b - > frame ; }",1
"static int copy_from ( IpvideoContext * s , AVFrame * src , AVFrame * dst , int delta_x , int delta_y ) { int current_offset = s - > pixel_ptr - dst - > data[0] ; int motion_offset = current_offset + delta_y * dst - > linesize[0] + delta_x * ( 1 + s - > is_16bpp ) ; if ( motion_offset < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , Interplay video : motion offset < 0 ( %d ) \n , motion_offset ) ; return AVERROR_INVALIDDATA ; } else if ( motion_offset > s - > upper_motion_limit_offset ) { av_log ( s - > avctx , AV_LOG_ERROR , Interplay video : motion offset above limit ( %d > = %d ) \n , motion_offset , s - > upper_motion_limit_offset ) ; return AVERROR_INVALIDDATA ; } if ( src - > data[0] == NULL ) { av_log ( s - > avctx , AV_LOG_ERROR , Invalid decode type , corrupted header ? \n ) ; return AVERROR ( EINVAL ) ; } s - > hdsp . put_pixels_tab[ ! s - > is_16bpp][0] ( s - > pixel_ptr , src - > data[0] + motion_offset , dst - > linesize[0] , 8 ) ; return 0 ; }",0
"void av_log_format_line ( void * ptr , int level , const char * fmt , va_list vl , char * line , int line_size , int * print_prefix ) { AVBPrint part[4] ; format_line ( ptr , level , fmt , vl , part , print_prefix , NULL ) ; snprintf ( line , line_size , %s%s%s%s , part[0] . str , part[1] . str , part[2] . str , part[3] . str ) ; av_bprint_finalize ( part + 3 , NULL ) ; }",0
"int ff_j2k_init_component ( Jpeg2000Component * comp , Jpeg2000CodingStyle * codsty , Jpeg2000QuantStyle * qntsty , int cbps , int dx , int dy , AVCodecContext * avctx ) { uint8_t log2_band_prec_width , log2_band_prec_height ; int reslevelno , bandno , gbandno = 0 , ret , i , j , csize = 1 ; if ( ret=ff_jpeg2000_dwt_init ( & comp - > dwt , comp - > coord , codsty - > nreslevels2decode - 1 , codsty - > transform == FF_DWT53 ? FF_DWT53 : FF_DWT97_INT ) ) return ret ; for ( i = 0 ; i < 2 ; i + + ) csize * = comp - > coord[i][1] - comp - > coord[i][0] ; comp - > data = av_malloc_array ( csize , sizeof ( * comp - > data ) ) ; if ( ! comp - > data ) return AVERROR ( ENOMEM ) ; comp - > reslevel = av_malloc_array ( codsty - > nreslevels , sizeof ( * comp - > reslevel ) ) ; if ( ! comp - > reslevel ) return AVERROR ( ENOMEM ) ; / * LOOP on resolution levels * / for ( reslevelno = 0 ; reslevelno < codsty - > nreslevels ; reslevelno + + ) { int declvl = codsty - > nreslevels - reslevelno ; // N_L - r see ISO/IEC 15444 - 1 : 2002 B . 5 Jpeg2000ResLevel * reslevel = comp - > reslevel + reslevelno ; / * Compute borders for each resolution level . * Computation of trx_0 , trx_1 , try_0 and try_1 . * see ISO/IEC 15444 - 1 : 2002 eq . B . 5 and B - 14 * / for ( i = 0 ; i < 2 ; i + + ) for ( j = 0 ; j < 2 ; j + + ) reslevel - > coord[i][j] = ff_jpeg2000_ceildivpow2 ( comp - > coord_o[i][j] , declvl - 1 ) ; // update precincts size : 2 n value reslevel - > log2_prec_width = codsty - > log2_prec_widths[reslevelno] ; reslevel - > log2_prec_height = codsty - > log2_prec_heights[reslevelno] ; / * Number of bands for each resolution level * / if ( reslevelno == 0 ) reslevel - > nbands = 1 ; else reslevel - > nbands = 3 ; / * Number of precincts wich span the tile for resolution level reslevelno * see B . 6 in ISO/IEC 15444 - 1 : 2002 eq . B - 16 * num_precincts_x = | - trx_1 / 2 log2_prec_width ) - | - ( trx_0 / 2 log2_prec_width ) * num_precincts_y = | - try_1 / 2 log2_prec_width ) - | - ( try_0 / 2 log2_prec_width ) * for Dcinema profiles in JPEG 2000 * num_precincts_x = | - trx_1 / 2 log2_prec_width ) - | * num_precincts_y = | - try_1 / 2 log2_prec_width ) - | * / if ( reslevel - > coord[0][1] == reslevel - > coord[0][0] ) reslevel - > num_precincts_x = 0 ; else reslevel - > num_precincts_x = ff_jpeg2000_ceildivpow2 ( reslevel - > coord[0][1] , reslevel - > log2_prec_width ) - ( reslevel - > coord[0][0] > > reslevel - > log2_prec_width ) ; if ( reslevel - > coord[1][1] == reslevel - > coord[1][0] ) reslevel - > num_precincts_y = 0 ; else reslevel - > num_precincts_y = ff_jpeg2000_ceildivpow2 ( reslevel - > coord[1][1] , reslevel - > log2_prec_height ) - ( reslevel - > coord[1][0] > > reslevel - > log2_prec_height ) ; reslevel - > band = av_malloc_array ( reslevel - > nbands , sizeof ( * reslevel - > band ) ) ; if ( ! reslevel - > band ) return AVERROR ( ENOMEM ) ; for ( bandno = 0 ; bandno < reslevel - > nbands ; bandno + + , gbandno + + ) { Jpeg2000Band * band = reslevel - > band + bandno ; int cblkno , precno ; int nb_precincts ; / * TODO : Implementation of quantization step not finished , * see ISO/IEC 15444 - 1 : 2002 E . 1 and A . 6 . 4 . * / switch ( qntsty - > quantsty ) { uint8_t gain ; int numbps ; case JPEG2000_QSTY_NONE : / * TODO : to verify . No quantization in this case * / band - > f_stepsize = 1 ; break ; case JPEG2000_QSTY_SI : / * TODO : Compute formula to implement . * / numbps = cbps + lut_gain[codsty - > transform][bandno + ( reslevelno > 0 ) ] ; band - > f_stepsize = SHL ( 2048 + qntsty - > mant[gbandno] , 2 + numbps - qntsty - > expn[gbandno] ) ; break ; case JPEG2000_QSTY_SE : / * Exponent quantization step . * Formula : * delta_b = 2 ( R_b - expn_b ) * ( 1 + ( mant_b / 2 11 ) ) * R_b = R_I + log2 ( gain_b ) * see ISO/IEC 15444 - 1 : 2002 E . 1 . 1 eqn . E - 3 and E - 4 * / / * TODO/WARN : value of log2 ( gain_b ) not taken into account * but it works ( compared to OpenJPEG ) . Why ? * Further investigation needed . * / gain = cbps ; band - > f_stepsize = pow ( 2 . 0 , gain - qntsty - > expn[gbandno] ) ; band - > f_stepsize * = ( qntsty - > mant[gbandno] / 2048 . 0 + 1 . 0 ) ; break ; default : band - > f_stepsize = 0 ; av_log ( avctx , AV_LOG_ERROR , Unknown quantization format\n ) ; break ; } / * FIXME : In openjepg code stespize = stepsize * 0 . 5 . Why ? * If not set output of entropic decoder is not correct . * / if ( ! av_codec_is_encoder ( avctx - > codec ) ) band - > f_stepsize * = 0 . 5 ; band - > i_stepsize = band - > f_stepsize * ( 1 < < 16 ) ; / * computation of tbx_0 , tbx_1 , tby_0 , tby_1 * see ISO/IEC 15444 - 1 : 2002 B . 5 eq . B - 15 and tbl B . 1 * codeblock width and height is computed for * DCI JPEG 2000 codeblock_width = codeblock_width = 32 = 2 5 * / if ( reslevelno == 0 ) { / * for reslevelno = 0 , only one band , x0_b = y0_b = 0 * / for ( i = 0 ; i < 2 ; i + + ) for ( j = 0 ; j < 2 ; j + + ) band - > coord[i][j] = ff_jpeg2000_ceildivpow2 ( comp - > coord_o[i][j] - comp - > coord_o[i][0] , declvl - 1 ) ; log2_band_prec_width = reslevel - > log2_prec_width ; log2_band_prec_height = reslevel - > log2_prec_height ; / * see ISO/IEC 15444 - 1 : 2002 eq . B - 17 and eq . B - 15 * / band",0
"static int r3d_read_redv ( AVFormatContext * s , AVPacket * pkt , Atom * atom ) { AVStream * st = s - > streams[0] ; int tmp , tmp2 ; uint64_t pos = url_ftell ( s - > pb ) ; unsigned dts ; dts = get_be32 ( s - > pb ) ; tmp = get_be32 ( s - > pb ) ; dprintf ( s , frame num %d\n , tmp ) ; tmp = get_byte ( s - > pb ) ; // major version tmp2 = get_byte ( s - > pb ) ; // minor version dprintf ( s , version %d . %d\n , tmp , tmp2 ) ; tmp = get_be16 ( s - > pb ) ; // unknown dprintf ( s , unknown %d\n , tmp ) ; if ( tmp > 4 ) { tmp = get_be16 ( s - > pb ) ; // unknown dprintf ( s , unknown %d\n , tmp ) ; tmp = get_be16 ( s - > pb ) ; // unknown dprintf ( s , unknown %d\n , tmp ) ; tmp = get_be32 ( s - > pb ) ; dprintf ( s , width %d\n , tmp ) ; tmp = get_be32 ( s - > pb ) ; dprintf ( s , height %d\n , tmp ) ; tmp = get_be32 ( s - > pb ) ; dprintf ( s , metadata len %d\n , tmp ) ; } tmp = atom - > size - 8 - ( url_ftell ( s - > pb ) - pos ) ; if ( tmp < 0 ) return - 1 ; if ( av_get_packet ( s - > pb , pkt , tmp ) ! = tmp ) { av_log ( s , AV_LOG_ERROR , error reading video packet\n ) ; return - 1 ; } pkt - > stream_index = 0 ; pkt - > dts = dts ; if ( st - > codec - > time_base . den ) pkt - > duration = ( uint64_t ) st - > time_base . den * st - > codec - > time_base . num/st - > codec - > time_base . den ; dprintf ( s , pkt dts %lld duration %d\n , pkt - > dts , pkt - > duration ) ; return 0 ; }",1
"static av_always_inline void blend_image_packed_rgb ( AVFilterContext * ctx , AVFrame * dst , const AVFrame * src , int main_has_alpha , int x , int y , int is_straight ) { OverlayContext * s = ctx - > priv ; int i , imax , j , jmax ; const int src_w = src - > width ; const int src_h = src - > height ; const int dst_w = dst - > width ; const int dst_h = dst - > height ; uint8_t alpha ; /// < the amount of overlay to blend on to main const int dr = s - > main_rgba_map[R] ; const int dg = s - > main_rgba_map[G] ; const int db = s - > main_rgba_map[B] ; const int da = s - > main_rgba_map[A] ; const int dstep = s - > main_pix_step[0] ; const int sr = s - > overlay_rgba_map[R] ; const int sg = s - > overlay_rgba_map[G] ; const int sb = s - > overlay_rgba_map[B] ; const int sa = s - > overlay_rgba_map[A] ; const int sstep = s - > overlay_pix_step[0] ; uint8_t * S , * sp , * d , * dp ; i = FFMAX ( - y , 0 ) ; sp = src - > data[0] + i * src - > linesize[0] ; dp = dst - > data[0] + ( y + i ) * dst - > linesize[0] ; for ( imax = FFMIN ( - y + dst_h , src_h ) ; i < imax ; i + + ) { j = FFMAX ( - x , 0 ) ; S = sp + j * sstep ; d = dp + ( x + j ) * dstep ; for ( jmax = FFMIN ( - x + dst_w , src_w ) ; j < jmax ; j + + ) { alpha = S[sa] ; // if the main channel has an alpha channel , alpha has to be calculated // to create an un - premultiplied ( straight ) alpha value if ( main_has_alpha & & alpha ! = 0 & & alpha ! = 255 ) { uint8_t alpha_d = d[da] ; alpha = UNPREMULTIPLY_ALPHA ( alpha , alpha_d ) ; } switch ( alpha ) { case 0 : break ; case 255 : d[dr] = S[sr] ; d[dg] = S[sg] ; d[db] = S[sb] ; break ; default : // main_value = main_value * ( 1 - alpha ) + overlay_value * alpha // since alpha is in the range 0 - 255 , the result must divided by 255 d[dr] = is_straight ? FAST_DIV255 ( d[dr] * ( 255 - alpha ) + S[sr] * alpha ) : FAST_DIV255 ( d[dr] * ( 255 - alpha ) + S[sr] ) ; d[dg] = is_straight ? FAST_DIV255 ( d[dg] * ( 255 - alpha ) + S[sg] * alpha ) : FAST_DIV255 ( d[dr] * ( 255 - alpha ) + S[sr] ) ; d[db] = is_straight ? FAST_DIV255 ( d[db] * ( 255 - alpha ) + S[sb] * alpha ) : FAST_DIV255 ( d[dr] * ( 255 - alpha ) + S[sr] ) ; } if ( main_has_alpha ) { switch ( alpha ) { case 0 : break ; case 255 : d[da] = S[sa] ; break ; default : // apply alpha compositing : main_alpha + = ( 1 - main_alpha ) * overlay_alpha d[da] + = FAST_DIV255 ( ( 255 - d[da] ) * S[sa] ) ; } } d + = dstep ; S + = sstep ; } dp + = dst - > linesize[0] ; sp + = src - > linesize[0] ; } }",0
"static int decode_block_refinement ( MJpegDecodeContext * s , int16_t * block , uint8_t * last_nnz , int ac_index , int16_t * quant_matrix , int ss , int se , int Al , int * EOBRUN ) { int code , i = ss , j , sign , val , run ; int last = FFMIN ( se , * last_nnz ) ; OPEN_READER ( re , & s - > gb ) ; if ( * EOBRUN ) { ( * EOBRUN ) - - ; } else { for ( ; ; i + + ) { UPDATE_CACHE ( re , & s - > gb ) ; GET_VLC ( code , re , & s - > gb , s - > vlcs[2][ac_index] . table , 9 , 2 ) ; if ( code & 0xF ) { run = ( ( unsigned ) code ) > > 4 ; UPDATE_CACHE ( re , & s - > gb ) ; val = SHOW_UBITS ( re , & s - > gb , 1 ) ; LAST_SKIP_BITS ( re , & s - > gb , 1 ) ; ZERO_RUN ; j = s - > scantable . permutated[i] ; val - - ; block[j] = ( ( quant_matrix[j] val ) - val ) < < Al ; if ( i == se ) { if ( i > * last_nnz ) * last_nnz = i ; CLOSE_READER ( re , & s - > gb ) ; return 0 ; } } else { run = ( ( unsigned ) code ) > > 4 ; if ( run == 0xF ) { ZERO_RUN ; } else { val = run ; run = ( 1 < < run ) ; if ( val ) { UPDATE_CACHE ( re , & s - > gb ) ; run + = SHOW_UBITS ( re , & s - > gb , val ) ; LAST_SKIP_BITS ( re , & s - > gb , val ) ; } * EOBRUN = run - 1 ; break ; } } } if ( i > * last_nnz ) * last_nnz = i ; } for ( ; i < = last ; i + + ) { j = s - > scantable . permutated[i] ; if ( block[j] ) REFINE_BIT ( j ) } CLOSE_READER ( re , & s - > gb ) ; return 0 ; }",1
"int ff_mov_lang_to_iso639 ( int code , char * to ) { int i ; / * is it the mangled iso code ? * / / * see http : //www . geocities . com/xhelmboyx/quicktime/formats/mp4 - layout . txt * / if ( code > 138 ) { for ( i = 2 ; i > = 0 ; i - - ) { to[i] = 0x60 + ( code & 0x1f ) ; code > > = 5 ; } return 1 ; } / * old fashion apple lang code * / if ( code > = FF_ARRAY_ELEMS ( mov_mdhd_language_map ) ) return 0 ; if ( ! mov_mdhd_language_map[code] ) return 0 ; strncpy ( to , mov_mdhd_language_map[code] , 4 ) ; return 1 ; }",1
"av_cold void ff_vp3dsp_init_x86 ( VP3DSPContext * c , int flags ) { if HAVE_YASM int cpuflags = av_get_cpu_flags ( ) ; if ARCH_X86_32 if ( HAVE_MMX & & cpuflags & AV_CPU_FLAG_MMX ) { c - > idct_put = ff_vp3_idct_put_mmx ; c - > idct_add = ff_vp3_idct_add_mmx ; c - > idct_perm = FF_PARTTRANS_IDCT_PERM ; } endif if ( HAVE_MMXEXT & & cpuflags & AV_CPU_FLAG_MMXEXT ) { c - > idct_dc_add = ff_vp3_idct_dc_add_mmx2 ; if ( ! ( flags & CODEC_FLAG_BITEXACT ) ) { c - > v_loop_filter = ff_vp3_v_loop_filter_mmx2 ; c - > h_loop_filter = ff_vp3_h_loop_filter_mmx2 ; } } if ( cpuflags & AV_CPU_FLAG_SSE2 ) { c - > idct_put = ff_vp3_idct_put_sse2 ; c - > idct_add = ff_vp3_idct_add_sse2 ; c - > idct_perm = FF_TRANSPOSE_IDCT_PERM ; } endif }",0
"static int decode_hrd ( VC9Context * v , GetBitContext * gb ) { int i , num ; num = get_bits ( gb , 5 ) ; if ( v - > hrd_rate || num ! = v - > hrd_num_leaky_buckets ) { av_freep ( & v - > hrd_rate ) ; } if ( ! v - > hrd_rate ) v - > hrd_rate = av_malloc ( num ) ; if ( ! v - > hrd_rate ) return - 1 ; if ( v - > hrd_buffer || num ! = v - > hrd_num_leaky_buckets ) { av_freep ( & v - > hrd_buffer ) ; } if ( ! v - > hrd_buffer ) v - > hrd_buffer = av_malloc ( num ) ; if ( ! v - > hrd_buffer ) return - 1 ; v - > hrd_num_leaky_buckets = num ; //exponent in base - 2 for rate v - > bit_rate_exponent = get_bits ( gb , 4 ) ; //exponent in base - 2 for buffer_size v - > buffer_size_exponent = get_bits ( gb , 4 ) ; for ( i=0 ; i < num ; i + + ) { //mantissae , ordered ( if not , use a function ? v - > hrd_rate[i] = get_bits ( gb , 16 ) ; if ( i & & v - > hrd_rate[i - 1] > =v - > hrd_rate[i] ) { av_log ( v , AV_LOG_ERROR , HDR Rates aren ' t strictly increasing : %i vs %i\n , v - > hrd_rate[i - 1] , v - > hrd_rate[i] ) ; return - 1 ; } v - > hrd_buffer[i] = get_bits ( gb , 16 ) ; if ( i & & v - > hrd_buffer[i - 1] < v - > hrd_buffer[i] ) { av_log ( v , AV_LOG_ERROR , HDR Buffers aren ' t decreasing : %i vs %i\n , v - > hrd_buffer[i - 1] , v - > hrd_buffer[i] ) ; return - 1 ; } } return 0 ; }",0
"static int wav_write_trailer ( AVFormatContext * s ) { AVIOContext * pb = s - > pb ; WAVMuxContext * wav = s - > priv_data ; int64_t file_size , data_size ; int64_t number_of_samples = 0 ; int rf64 = 0 ; avio_flush ( pb ) ; if ( s - > pb - > seekable ) { if ( wav - > write_peak ! = 2 ) { ff_end_tag ( pb , wav - > data ) ; avio_flush ( pb ) ; } if ( wav - > write_peak & & wav - > peak_output ) { peak_write_chunk ( s ) ; avio_flush ( pb ) ; } / * update file size * / file_size = avio_tell ( pb ) ; data_size = file_size - wav - > data ; if ( wav - > rf64 == RF64_ALWAYS || ( wav - > rf64 == RF64_AUTO & & file_size - 8 > UINT32_MAX ) ) { rf64 = 1 ; } else { avio_seek ( pb , 4 , SEEK_SET ) ; avio_wl32 ( pb , ( uint32_t ) ( file_size - 8 ) ) ; avio_seek ( pb , file_size , SEEK_SET ) ; avio_flush ( pb ) ; } number_of_samples = av_rescale ( wav - > maxpts - wav - > minpts + wav - > last_duration , s - > streams[0] - > codec - > sample_rate * ( int64_t ) s - > streams[0] - > time_base . num , s - > streams[0] - > time_base . den ) ; if ( s - > streams[0] - > codec - > codec_tag ! = 0x01 ) { / * Update num_samps in fact chunk * / avio_seek ( pb , wav - > fact_pos , SEEK_SET ) ; if ( rf64 || ( wav - > rf64 == RF64_AUTO & & number_of_samples > UINT32_MAX ) ) { rf64 = 1 ; avio_wl32 ( pb , - 1 ) ; } else { avio_wl32 ( pb , number_of_samples ) ; avio_seek ( pb , file_size , SEEK_SET ) ; avio_flush ( pb ) ; } } if ( rf64 ) { / * overwrite RIFF with RF64 * / avio_seek ( pb , 0 , SEEK_SET ) ; ffio_wfourcc ( pb , RF64 ) ; avio_wl32 ( pb , - 1 ) ; / * write ds64 chunk ( overwrite JUNK if rf64 == RF64_AUTO ) * / avio_seek ( pb , wav - > ds64 - 8 , SEEK_SET ) ; ffio_wfourcc ( pb , ds64 ) ; avio_wl32 ( pb , 28 ) ; / * ds64 chunk size * / avio_wl64 ( pb , file_size - 8 ) ; / * RF64 chunk size * / avio_wl64 ( pb , data_size ) ; / * data chunk size * / avio_wl64 ( pb , number_of_samples ) ; / * fact chunk number of samples * / avio_wl32 ( pb , 0 ) ; / * number of table entries for non - ' data ' chunks * / / * write - 1 in data chunk size * / avio_seek ( pb , wav - > data - 4 , SEEK_SET ) ; avio_wl32 ( pb , - 1 ) ; avio_seek ( pb , file_size , SEEK_SET ) ; avio_flush ( pb ) ; } } if ( wav - > write_peak ) peak_free_buffers ( s ) ; return 0 ; }",0
"static av_cold int oggvorbis_encode_close ( AVCodecContext * avccontext ) { OggVorbisContext * context = avccontext - > priv_data ; / * ogg_packet op ; * / vorbis_analysis_wrote ( & context - > vd , 0 ) ; / * notify vorbisenc this is EOF * / vorbis_block_clear ( & context - > vb ) ; vorbis_dsp_clear ( & context - > vd ) ; vorbis_info_clear ( & context - > vi ) ; av_freep ( & avccontext - > coded_frame ) ; av_freep ( & avccontext - > extradata ) ; return 0 ; }",0
"static PESContext * add_pes_stream ( MpegTSContext * ts , int pid , int pcr_pid , int stream_type ) { MpegTSFilter * tss ; PESContext * pes ; / * if no pid found , then add a pid context * / pes = av_mallocz ( sizeof ( PESContext ) ) ; if ( ! pes ) return 0 ; pes - > ts = ts ; pes - > stream = ts - > stream ; pes - > pid = pid ; pes - > pcr_pid = pcr_pid ; pes - > stream_type = stream_type ; pes - > state = MPEGTS_SKIP ; pes - > pts = AV_NOPTS_VALUE ; pes - > dts = AV_NOPTS_VALUE ; tss = mpegts_open_pes_filter ( ts , pid , mpegts_push_data , pes ) ; if ( ! tss ) { av_free ( pes ) ; return 0 ; } return pes ; }",0
"av_cold int swr_init ( struct SwrContext * s ) { int ret ; clear_context ( s ) ; if ( s - > in_sample_fmt > = AV_SAMPLE_FMT_NB ) { av_log ( s , AV_LOG_ERROR , Requested input sample format %d is invalid\n , s - > in_sample_fmt ) ; return AVERROR ( EINVAL ) ; } if ( s - > out_sample_fmt > = AV_SAMPLE_FMT_NB ) { av_log ( s , AV_LOG_ERROR , Requested output sample format %d is invalid\n , s - > out_sample_fmt ) ; return AVERROR ( EINVAL ) ; } s - > out . ch_count = s - > user_out_ch_count ; s - > in . ch_count = s - > user_in_ch_count ; s - > used_ch_count = s - > user_used_ch_count ; s - > in_ch_layout = s - > user_in_ch_layout ; s - > out_ch_layout = s - > user_out_ch_layout ; if ( av_get_channel_layout_nb_channels ( s - > in_ch_layout ) > SWR_CH_MAX ) { av_log ( s , AV_LOG_WARNING , Input channel layout 0x% PRIx64 is invalid or unsupported . \n , s - > in_ch_layout ) ; s - > in_ch_layout = 0 ; } if ( av_get_channel_layout_nb_channels ( s - > out_ch_layout ) > SWR_CH_MAX ) { av_log ( s , AV_LOG_WARNING , Output channel layout 0x% PRIx64 is invalid or unsupported . \n , s - > out_ch_layout ) ; s - > out_ch_layout = 0 ; } switch ( s - > engine ) { if CONFIG_LIBSOXR case SWR_ENGINE_SOXR : s - > resampler = & swri_soxr_resampler ; break ; endif case SWR_ENGINE_SWR : s - > resampler = & swri_resampler ; break ; default : av_log ( s , AV_LOG_ERROR , Requested resampling engine is unavailable\n ) ; return AVERROR ( EINVAL ) ; } if ( ! s - > used_ch_count ) s - > used_ch_count= s - > in . ch_count ; if ( s - > used_ch_count & & s - > in_ch_layout & & s - > used_ch_count ! = av_get_channel_layout_nb_channels ( s - > in_ch_layout ) ) { av_log ( s , AV_LOG_WARNING , Input channel layout has a different number of channels than the number of used channels , ignoring layout\n ) ; s - > in_ch_layout= 0 ; } if ( ! s - > in_ch_layout ) s - > in_ch_layout= av_get_default_channel_layout ( s - > used_ch_count ) ; if ( ! s - > out_ch_layout ) s - > out_ch_layout= av_get_default_channel_layout ( s - > out . ch_count ) ; s - > rematrix= s - > out_ch_layout ! =s - > in_ch_layout || s - > rematrix_volume ! =1 . 0 || s - > rematrix_custom ; if ( s - > int_sample_fmt == AV_SAMPLE_FMT_NONE ) { if ( av_get_planar_sample_fmt ( s - > in_sample_fmt ) < = AV_SAMPLE_FMT_S16P ) { s - > int_sample_fmt= AV_SAMPLE_FMT_S16P ; } else if ( av_get_planar_sample_fmt ( s - > in_sample_fmt ) == AV_SAMPLE_FMT_S32P & & av_get_planar_sample_fmt ( s - > out_sample_fmt ) == AV_SAMPLE_FMT_S32P & & ! s - > rematrix & & s - > engine ! = SWR_ENGINE_SOXR ) { s - > int_sample_fmt= AV_SAMPLE_FMT_S32P ; } else if ( av_get_planar_sample_fmt ( s - > in_sample_fmt ) < = AV_SAMPLE_FMT_FLTP ) { s - > int_sample_fmt= AV_SAMPLE_FMT_FLTP ; } else { av_log ( s , AV_LOG_DEBUG , Using double precision mode\n ) ; s - > int_sample_fmt= AV_SAMPLE_FMT_DBLP ; } } if ( s - > int_sample_fmt ! = AV_SAMPLE_FMT_S16P & & s - > int_sample_fmt ! = AV_SAMPLE_FMT_S32P & & s - > int_sample_fmt ! = AV_SAMPLE_FMT_FLTP & & s - > int_sample_fmt ! = AV_SAMPLE_FMT_DBLP ) { av_log ( s , AV_LOG_ERROR , Requested sample format %s is not supported internally , S16/S32/FLT/DBL is supported\n , av_get_sample_fmt_name ( s - > int_sample_fmt ) ) ; return AVERROR ( EINVAL ) ; } set_audiodata_fmt ( & s - > in , s - > in_sample_fmt ) ; set_audiodata_fmt ( & s - > out , s - > out_sample_fmt ) ; if ( s - > firstpts_in_samples ! = AV_NOPTS_VALUE ) { if ( ! s - > async & & s - > min_compensation > = FLT_MAX/2 ) s - > async = 1 ; s - > firstpts = s - > outpts = s - > firstpts_in_samples * s - > out_sample_rate ; } else s - > firstpts = AV_NOPTS_VALUE ; if ( s - > async ) { if ( s - > min_compensation > = FLT_MAX/2 ) s - > min_compensation = 0 . 001 ; if ( s - > async > 1 . 0001 ) { s - > max_soft_compensation = s - > async / ( double ) s - > in_sample_rate ; } } if ( s - > out_sample_rate ! =s - > in_sample_rate || ( s - > flags & SWR_FLAG_RESAMPLE ) ) { s - > resample = s - > resampler - > init ( s - > resample , s - > out_sample_rate , s - > in_sample_rate , s - > filter_size , s - > phase_shift , s - > linear_interp , s - > cutoff , s - > int_sample_fmt , s - > filter_type , s - > kaiser_beta , s - > precision , s - > cheby ) ; } else s - > resampler - > free ( & s - > resample ) ; if ( s - > int_sample_fmt ! = AV_SAMPLE_FMT_S16P & & s - > int_sample_fmt ! = AV_SAMPLE_FMT_S32P & & s - > int_sample_fmt ! = AV_SAMPLE_FMT_FLTP & & s - > int_sample_fmt ! = AV_SAMPLE_FMT_DBLP & & s - > resample ) { av_log ( s , AV_LOG_ERROR , Resampling only supported with internal s16/s32/flt/dbl\n ) ; return - 1 ; } define RSC 1 //FIXME finetune if ( ! s - > in . ch_count ) s - > in . ch_count= av_get_channel_layout_nb_channels ( s - > in_ch_layout ) ; if ( ! s - > used_ch_count ) s - > used_ch_count= s - > in . ch_count ; if ( ! s - > out . ch_count ) s - > out . ch_count= av_get_channel_layout_nb_channels ( s - > out_ch_layout ) ; if ( ! s - > in . ch_count ) { av_assert0 ( ! s - > in_ch_layout ) ; av_log ( s , AV_LOG_ERROR , Input channel count and layout are unset\n ) ; return - 1 ; } if ( ( ! s - > out_ch_layout || ! s - > in_ch_layout ) & & s - > used_ch_count ! = s - > out . ch_count & & ! s - > rematrix_custom ) { char l1[1024] , l2[1024] ; av_get_channel_layout_string ( l1 , sizeof ( l1 ) , s - > in . ch_count , s - > in_ch_layout ) ; av_get_channel_layout_string ( l2 , sizeof ( l2 ) , s - > out . ch_count , s - > out_ch_layout ) ; av_log ( s , AV_LOG_ERROR , Rematrix is needed between %s and %s but there is not enough information to do it\n , l1 , l2 ) ; return -",0
"static int dxtory_decode_v2_565 ( AVCodecContext * avctx , AVFrame * pic , const uint8_t * src , int src_size , int is_565 ) { GetByteContext gb ; GetBitContext gb2 ; int nslices , slice , slice_height ; uint32_t off , slice_size ; uint8_t * dst ; int ret ; bytestream2_init ( & gb , src , src_size ) ; nslices = bytestream2_get_le16 ( & gb ) ; off = FFALIGN ( nslices * 4 + 2 , 16 ) ; if ( src_size < off ) { av_log ( avctx , AV_LOG_ERROR , no slice data\n ) ; return AVERROR_INVALIDDATA ; } if ( ! nslices || avctx - > height % nslices ) { avpriv_request_sample ( avctx , %d slices for %dx%d , nslices , avctx - > width , avctx - > height ) ; return AVERROR_PATCHWELCOME ; } slice_height = avctx - > height / nslices ; avctx - > pix_fmt = AV_PIX_FMT_RGB24 ; if ( ( ret = ff_get_buffer ( avctx , pic , 0 ) ) < 0 ) return ret ; dst = pic - > data[0] ; for ( slice = 0 ; slice < nslices ; slice + + ) { slice_size = bytestream2_get_le32 ( & gb ) ; ret = check_slice_size ( avctx , src , src_size , slice_size , off ) ; if ( ret < 0 ) return ret ; init_get_bits ( & gb2 , src + off + 16 , ( slice_size - 16 ) * 8 ) ; dx2_decode_slice_565 ( & gb2 , avctx - > width , slice_height , dst , pic - > linesize[0] , is_565 ) ; dst + = pic - > linesize[0] * slice_height ; off + = slice_size ; } return 0 ; }",0
"void mpeg_motion_internal ( MpegEncContext * s , uint8_t * dest_y , uint8_t * dest_cb , uint8_t * dest_cr , int field_based , int bottom_field , int field_select , uint8_t * * ref_picture , op_pixels_func ( * pix_op ) [4] , int motion_x , int motion_y , int h , int is_mpeg12 , int mb_y ) { uint8_t * ptr_y , * ptr_cb , * ptr_cr ; int dxy , uvdxy , mx , my , src_x , src_y , uvsrc_x , uvsrc_y , v_edge_pos ; emuedge_linesize_type uvlinesize , linesize ; if 0 if ( s - > quarter_sample ) { motion_x > > =1 ; motion_y > > =1 ; } endif v_edge_pos = s - > v_edge_pos > > field_based ; linesize = s - > current_picture . f . linesize[0] < < field_based ; uvlinesize = s - > current_picture . f . linesize[1] < < field_based ; dxy = ( ( motion_y & 1 ) < < 1 ) | ( motion_x & 1 ) ; src_x = s - > mb_x * 16 + ( motion_x > > 1 ) ; src_y = ( mb_y < < ( 4 - field_based ) ) + ( motion_y > > 1 ) ; if ( ! is_mpeg12 & & s - > out_format == FMT_H263 ) { if ( ( s - > workaround_bugs & FF_BUG_HPEL_CHROMA ) & & field_based ) { mx = ( motion_x > > 1 ) | ( motion_x & 1 ) ; my = motion_y > > 1 ; uvdxy = ( ( my & 1 ) < < 1 ) | ( mx & 1 ) ; uvsrc_x = s - > mb_x * 8 + ( mx > > 1 ) ; uvsrc_y = ( mb_y < < ( 3 - field_based ) ) + ( my > > 1 ) ; } else { uvdxy = dxy | ( motion_y & 2 ) | ( ( motion_x & 2 ) > > 1 ) ; uvsrc_x = src_x > > 1 ; uvsrc_y = src_y > > 1 ; } } else if ( ! is_mpeg12 & & s - > out_format == FMT_H261 ) { //even chroma mv ' s are full pel in H261 mx = motion_x / 4 ; my = motion_y / 4 ; uvdxy = 0 ; uvsrc_x = s - > mb_x * 8 + mx ; uvsrc_y = mb_y * 8 + my ; } else { if ( s - > chroma_y_shift ) { mx = motion_x / 2 ; my = motion_y / 2 ; uvdxy = ( ( my & 1 ) < < 1 ) | ( mx & 1 ) ; uvsrc_x = s - > mb_x * 8 + ( mx > > 1 ) ; uvsrc_y = ( mb_y < < ( 3 - field_based ) ) + ( my > > 1 ) ; } else { if ( s - > chroma_x_shift ) { //Chroma422 mx = motion_x / 2 ; uvdxy = ( ( motion_y & 1 ) < < 1 ) | ( mx & 1 ) ; uvsrc_x = s - > mb_x * 8 + ( mx > > 1 ) ; uvsrc_y = src_y ; } else { //Chroma444 uvdxy = dxy ; uvsrc_x = src_x ; uvsrc_y = src_y ; } } } ptr_y = ref_picture[0] + src_y * linesize + src_x ; ptr_cb = ref_picture[1] + uvsrc_y * uvlinesize + uvsrc_x ; ptr_cr = ref_picture[2] + uvsrc_y * uvlinesize + uvsrc_x ; if ( ( unsigned ) src_x > FFMAX ( s - > h_edge_pos - ( motion_x & 1 ) - 16 , 0 ) || ( unsigned ) src_y > FFMAX ( v_edge_pos - ( motion_y & 1 ) - h , 0 ) ) { if ( is_mpeg12 || s - > codec_id == AV_CODEC_ID_MPEG2VIDEO || s - > codec_id == AV_CODEC_ID_MPEG1VIDEO ) { av_log ( s - > avctx , AV_LOG_DEBUG , MPEG motion vector out of boundary ( %d %d ) \n , src_x , src_y ) ; return ; } s - > vdsp . emulated_edge_mc ( s - > edge_emu_buffer , ptr_y , s - > linesize , 17 , 17 + field_based , src_x , src_y < < field_based , s - > h_edge_pos , s - > v_edge_pos ) ; ptr_y = s - > edge_emu_buffer ; if ( ! CONFIG_GRAY || ! ( s - > flags & CODEC_FLAG_GRAY ) ) { uint8_t * uvbuf= s - > edge_emu_buffer + 18 * s - > linesize ; s - > vdsp . emulated_edge_mc ( uvbuf , ptr_cb , s - > uvlinesize , 9 , 9 + field_based , uvsrc_x , uvsrc_y < < field_based , s - > h_edge_pos > > 1 , s - > v_edge_pos > > 1 ) ; s - > vdsp . emulated_edge_mc ( uvbuf + 16 , ptr_cr , s - > uvlinesize , 9 , 9 + field_based , uvsrc_x , uvsrc_y < < field_based , s - > h_edge_pos > > 1 , s - > v_edge_pos > > 1 ) ; ptr_cb= uvbuf ; ptr_cr= uvbuf + 16 ; } } if ( bottom_field ) { //FIXME use this for field pix too instead of the obnoxious hack which changes picture . data dest_y + = s - > linesize ; dest_cb + = s - > uvlinesize ; dest_cr + = s - > uvlinesize ; } if ( field_select ) { ptr_y + = s - > linesize ; ptr_cb + = s - > uvlinesize ; ptr_cr + = s - > uvlinesize ; } pix_op[0][dxy] ( dest_y , ptr_y , linesize , h ) ; if ( ! CONFIG_GRAY || ! ( s - > flags & CODEC_FLAG_GRAY ) ) { pix_op[s - > chroma_x_shift][uvdxy] ( dest_cb , ptr_cb , uvlinesize , h > > s - > chroma_y_shift ) ; pix_op[s - > chroma_x_shift][uvdxy] ( dest_cr , ptr_cr , uvlinesize , h > > s - > chroma_y_shift ) ; } if ( ! is_mpeg12 & & ( CONFIG_H261_ENCODER || CONFIG_H261_DECODER ) & & s - > out_format == FMT_H261 ) { ff_h261_loop_filter ( s ) ; } }",1
"void rgb16tobgr32 ( const uint8_t * src , uint8_t * dst , unsigned int src_size ) { const uint16_t * end ; uint8_t * d = ( uint8_t * ) dst ; const uint16_t * s = ( uint16_t * ) src ; end = s + src_size/2 ; while ( s < end ) { register uint16_t bgr ; bgr = * s + + ; * d + + = ( bgr & 0xF800 ) > > 8 ; * d + + = ( bgr & 0x7E0 ) > > 3 ; * d + + = ( bgr & 0x1F ) < < 3 ; * d + + = 0 ; } }",1
"static int decode_audio_block ( AC3DecodeContext * s , int blk ) { int fbw_channels = s - > fbw_channels ; int channel_mode = s - > channel_mode ; int i , bnd , seg , ch , ret ; int different_transforms ; int downmix_output ; int cpl_in_use ; GetBitContext * gbc = & s - > gbc ; uint8_t bit_alloc_stages[AC3_MAX_CHANNELS] = { 0 } ; / * block switch flags * / different_transforms = 0 ; if ( s - > block_switch_syntax ) { for ( ch = 1 ; ch < = fbw_channels ; ch + + ) { s - > block_switch[ch] = get_bits1 ( gbc ) ; if ( ch > 1 & & s - > block_switch[ch] ! = s - > block_switch[1] ) different_transforms = 1 ; } } / * dithering flags * / if ( s - > dither_flag_syntax ) { for ( ch = 1 ; ch < = fbw_channels ; ch + + ) { s - > dither_flag[ch] = get_bits1 ( gbc ) ; } } / * dynamic range * / i = ! s - > channel_mode ; do { if ( get_bits1 ( gbc ) ) { / * Allow asymmetric application of DRC when drc_scale > 1 . Amplification of quiet sounds is enhanced * / int range_bits = get_bits ( gbc , 8 ) ; INTFLOAT range = AC3_RANGE ( range_bits ) ; if ( range_bits < = 127 || s - > drc_scale < = 1 . 0 ) s - > dynamic_range[i] = AC3_DYNAMIC_RANGE ( range ) ; else s - > dynamic_range[i] = range ; } else if ( blk == 0 ) { s - > dynamic_range[i] = AC3_DYNAMIC_RANGE1 ; } } while ( i - - ) ; / * spectral extension strategy * / if ( s - > eac3 & & ( ! blk || get_bits1 ( gbc ) ) ) { s - > spx_in_use = get_bits1 ( gbc ) ; if ( s - > spx_in_use ) { if ( ( ret = spx_strategy ( s , blk ) ) < 0 ) return ret ; } } if ( ! s - > eac3 || ! s - > spx_in_use ) { s - > spx_in_use = 0 ; for ( ch = 1 ; ch < = fbw_channels ; ch + + ) { s - > channel_uses_spx[ch] = 0 ; s - > first_spx_coords[ch] = 1 ; } } / * spectral extension coordinates * / if ( s - > spx_in_use ) spx_coordinates ( s ) ; / * coupling strategy * / if ( s - > eac3 ? s - > cpl_strategy_exists[blk] : get_bits1 ( gbc ) ) { if ( ( ret = coupling_strategy ( s , blk , bit_alloc_stages ) ) < 0 ) return ret ; } else if ( ! s - > eac3 ) { if ( ! blk ) { av_log ( s - > avctx , AV_LOG_ERROR , new coupling strategy must be present in block 0\n ) ; return AVERROR_INVALIDDATA ; } else { s - > cpl_in_use[blk] = s - > cpl_in_use[blk - 1] ; } } cpl_in_use = s - > cpl_in_use[blk] ; / * coupling coordinates * / if ( cpl_in_use ) { if ( ( ret = coupling_coordinates ( s , blk ) ) < 0 ) return ret ; } / * stereo rematrixing strategy and band structure * / if ( channel_mode == AC3_CHMODE_STEREO ) { if ( ( s - > eac3 & & ! blk ) || get_bits1 ( gbc ) ) { s - > num_rematrixing_bands = 4 ; if ( cpl_in_use & & s - > start_freq[CPL_CH] < = 61 ) { s - > num_rematrixing_bands - = 1 + ( s - > start_freq[CPL_CH] == 37 ) ; } else if ( s - > spx_in_use & & s - > spx_src_start_freq < = 61 ) { s - > num_rematrixing_bands - - ; } for ( bnd = 0 ; bnd < s - > num_rematrixing_bands ; bnd + + ) s - > rematrixing_flags[bnd] = get_bits1 ( gbc ) ; } else if ( ! blk ) { av_log ( s - > avctx , AV_LOG_WARNING , Warning : new rematrixing strategy not present in block 0\n ) ; s - > num_rematrixing_bands = 0 ; } } / * exponent strategies for each channel * / for ( ch = ! cpl_in_use ; ch < = s - > channels ; ch + + ) { if ( ! s - > eac3 ) s - > exp_strategy[blk][ch] = get_bits ( gbc , 2 - ( ch == s - > lfe_ch ) ) ; if ( s - > exp_strategy[blk][ch] ! = EXP_REUSE ) bit_alloc_stages[ch] = 3 ; } / * channel bandwidth * / for ( ch = 1 ; ch < = fbw_channels ; ch + + ) { s - > start_freq[ch] = 0 ; if ( s - > exp_strategy[blk][ch] ! = EXP_REUSE ) { int group_size ; int prev = s - > end_freq[ch] ; if ( s - > channel_in_cpl[ch] ) s - > end_freq[ch] = s - > start_freq[CPL_CH] ; else if ( s - > channel_uses_spx[ch] ) s - > end_freq[ch] = s - > spx_src_start_freq ; else { int bandwidth_code = get_bits ( gbc , 6 ) ; if ( bandwidth_code > 60 ) { av_log ( s - > avctx , AV_LOG_ERROR , bandwidth code = %d > 60\n , bandwidth_code ) ; return AVERROR_INVALIDDATA ; } s - > end_freq[ch] = bandwidth_code * 3 + 73 ; } group_size = 3 < < ( s - > exp_strategy[blk][ch] - 1 ) ; s - > num_exp_groups[ch] = ( s - > end_freq[ch] + group_size - 4 ) / group_size ; if ( blk > 0 & & s - > end_freq[ch] ! = prev ) memset ( bit_alloc_stages , 3 , AC3_MAX_CHANNELS ) ; } } if ( cpl_in_use & & s - > exp_strategy[blk][CPL_CH] ! = EXP_REUSE ) { s - > num_exp_groups[CPL_CH] = ( s - > end_freq[CPL_CH] - s - > start_freq[CPL_CH] ) / ( 3 < < ( s - > exp_strategy[blk][CPL_CH] - 1 ) ) ; } / * decode exponents for each channel * / for ( ch = ! cpl_in_use ; ch < = s - > channels ; ch + + ) { if ( s - > exp_strategy[blk][ch] ! = EXP_REUSE ) { s - > dexps[ch][0] = get_bits ( gbc , 4 ) < < ! ch ; if ( decode_exponents ( s , gbc , s - > exp_strategy[blk][ch] , s - > num_exp_groups[ch] , s - > dexps[ch][0] , & s - > dexps[ch][s - > start_freq[ch] + ! ! ch] ) ) { return AVERROR_INVALIDDATA ; } if ( ch ! = CPL_CH & & ch ! = s - > lfe_ch ) skip_bits ( gbc , 2 ) ; / * skip gainrng * / } } / * bit allocation information * / if ( s - > bit_allocation_syntax ) {",1
"static inline void RENAME ( rgb32to16 ) ( const uint8_t * src , uint8_t * dst , long src_size ) { const uint8_t * s = src ; const uint8_t * end ; ifdef HAVE_MMX const uint8_t * mm_end ; endif uint16_t * d = ( uint16_t * ) dst ; end = s + src_size ; ifdef HAVE_MMX mm_end = end - 15 ; if 1 //is faster only if multiplies are reasonable fast ( FIXME figure out on which cpus this is faster , on Athlon its slightly faster ) asm volatile ( movq %3 , %%mm5 \n\t movq %4 , %%mm6 \n\t movq %5 , %%mm7 \n\t jmp 2f \n\t ASMALIGN ( 4 ) 1 : \n\t PREFETCH 32 ( %1 ) \n\t movd ( %1 ) , %%mm0 \n\t movd 4 ( %1 ) , %%mm3 \n\t punpckldq 8 ( %1 ) , %%mm0 \n\t punpckldq 12 ( %1 ) , %%mm3 \n\t movq %%mm0 , %%mm1 \n\t movq %%mm3 , %%mm4 \n\t pand %%mm6 , %%mm0 \n\t pand %%mm6 , %%mm3 \n\t pmaddwd %%mm7 , %%mm0 \n\t pmaddwd %%mm7 , %%mm3 \n\t pand %%mm5 , %%mm1 \n\t pand %%mm5 , %%mm4 \n\t por %%mm1 , %%mm0 \n\t por %%mm4 , %%mm3 \n\t psrld 5 , %%mm0 \n\t pslld 11 , %%mm3 \n\t por %%mm3 , %%mm0 \n\t MOVNTQ %%mm0 , ( %0 ) \n\t add 16 , %1 \n\t add 8 , %0 \n\t 2 : \n\t cmp %2 , %1 \n\t jb 1b \n\t : + r ( d ) , + r ( s ) : r ( mm_end ) , m ( mask3216g ) , m ( mask3216br ) , m ( mul3216 ) ) ; else __asm __volatile ( PREFETCH %0 : : m ( * src ) : memory ) ; __asm __volatile ( movq %0 , %%mm7\n\t movq %1 , %%mm6\n\t : : m ( red_16mask ) , m ( green_16mask ) ) ; while ( s < mm_end ) { __asm __volatile ( PREFETCH 32%1\n\t movd %1 , %%mm0\n\t movd 4%1 , %%mm3\n\t punpckldq 8%1 , %%mm0\n\t punpckldq 12%1 , %%mm3\n\t movq %%mm0 , %%mm1\n\t movq %%mm0 , %%mm2\n\t movq %%mm3 , %%mm4\n\t movq %%mm3 , %%mm5\n\t psrlq 3 , %%mm0\n\t psrlq 3 , %%mm3\n\t pand %2 , %%mm0\n\t pand %2 , %%mm3\n\t psrlq 5 , %%mm1\n\t psrlq 5 , %%mm4\n\t pand %%mm6 , %%mm1\n\t pand %%mm6 , %%mm4\n\t psrlq 8 , %%mm2\n\t psrlq 8 , %%mm5\n\t pand %%mm7 , %%mm2\n\t pand %%mm7 , %%mm5\n\t por %%mm1 , %%mm0\n\t por %%mm4 , %%mm3\n\t por %%mm2 , %%mm0\n\t por %%mm5 , %%mm3\n\t psllq 16 , %%mm3\n\t por %%mm3 , %%mm0\n\t MOVNTQ %%mm0 , %0\n\t : =m ( * d ) : m ( * s ) , m ( blue_16mask ) : memory ) ; d + = 4 ; s + = 16 ; } endif __asm __volatile ( SFENCE : : : memory ) ; __asm __volatile ( EMMS : : : memory ) ; endif while ( s < end ) { register int rgb = * ( uint32_t * ) s ; s + = 4 ; * d + + = ( ( rgb & 0xFF ) > > 3 ) + ( ( rgb & 0xFC00 ) > > 5 ) + ( ( rgb & 0xF80000 ) > > 8 ) ; } }",1
"static void write_header ( AVFormatContext * s ) { double min_buffer_time = 1 . 0 ; avio_printf ( s - > pb , < ? xml version=\ 1 . 0\ encoding=\ UTF - 8\ ? > \n ) ; avio_printf ( s - > pb , < MPD\n ) ; avio_printf ( s - > pb , xmlns : xsi=\ http : //www . w3 . org/2001/XMLSchema - instance\ \n ) ; avio_printf ( s - > pb , xmlns=\ urn : mpeg : DASH : schema : MPD : 2011\ \n ) ; avio_printf ( s - > pb , xsi : schemaLocation=\ urn : mpeg : DASH : schema : MPD : 2011\ \n ) ; avio_printf ( s - > pb , type=\ static\ \n ) ; avio_printf ( s - > pb , mediaPresentationDuration=\ PT%gS\ \n , get_duration ( s ) ) ; avio_printf ( s - > pb , minBufferTime=\ PT%gS\ \n , min_buffer_time ) ; avio_printf ( s - > pb , profiles=\ urn : webm : dash : profile : webm - on - demand : 2012\ ) ; avio_printf ( s - > pb , > \n ) ; }",1
"static void print_formats ( AVFilterContext * filter_ctx ) { int i , j ; define PRINT_FMTS ( inout , outin , INOUT ) \ for ( i = 0 ; i < filter_ctx - > nb_ inout puts ; i + + ) { \ if ( filter_ctx - > inout puts[i] - > type == AVMEDIA_TYPE_VIDEO ) { \ AVFilterFormats * fmts = \ filter_ctx - > inout puts[i] - > outin _formats ; \ for ( j = 0 ; j < fmts - > nb_formats ; j + + ) \ if ( av_get_pix_fmt_name ( fmts - > formats[j] ) ) \ printf ( INOUT PUT[%d] %s : fmt : %s\n , \ i , filter_ctx - > filter - > inout puts[i] . name , \ av_get_pix_fmt_name ( fmts - > formats[j] ) ) ; \ } else if ( filter_ctx - > inout puts[i] - > type == AVMEDIA_TYPE_AUDIO ) { \ AVFilterFormats * fmts ; \ AVFilterChannelLayouts * layouts ; \ \ fmts = filter_ctx - > inout puts[i] - > outin _formats ; \ for ( j = 0 ; j < fmts - > nb_formats ; j + + ) \ printf ( INOUT PUT[%d] %s : fmt : %s\n , \ i , filter_ctx - > filter - > inout puts[i] . name , \ av_get_sample_fmt_name ( fmts - > formats[j] ) ) ; \ \ layouts = filter_ctx - > inout puts[i] - > outin _channel_layouts ; \ for ( j = 0 ; j < layouts - > nb_channel_layouts ; j + + ) { \ char buf[256] ; \ av_get_channel_layout_string ( buf , sizeof ( buf ) , - 1 , \ layouts - > channel_layouts[j] ) ; \ printf ( INOUT PUT[%d] %s : chlayout : %s\n , \ i , filter_ctx - > filter - > inout puts[i] . name , buf ) ; \ } \ } \ } \ PRINT_FMTS ( in , out , IN ) ; PRINT_FMTS ( out , in , OUT ) ; }",1
"static int hls_slice_data_wpp ( HEVCContext * s , const uint8_t * nal , int length ) { HEVCLocalContext * lc = s - > HEVClc ; int * ret = av_malloc_array ( s - > sh . num_entry_point_offsets + 1 , sizeof ( int ) ) ; int * arg = av_malloc_array ( s - > sh . num_entry_point_offsets + 1 , sizeof ( int ) ) ; int offset ; int startheader , cmpt = 0 ; int i , j , res = 0 ; if ( ! s - > sList[1] ) { ff_alloc_entries ( s - > avctx , s - > sh . num_entry_point_offsets + 1 ) ; for ( i = 1 ; i < s - > threads_number ; i + + ) { s - > sList[i] = av_malloc ( sizeof ( HEVCContext ) ) ; memcpy ( s - > sList[i] , s , sizeof ( HEVCContext ) ) ; s - > HEVClcList[i] = av_mallocz ( sizeof ( HEVCLocalContext ) ) ; s - > sList[i] - > HEVClc = s - > HEVClcList[i] ; offset = ( lc - > gb . index > > 3 ) ; for ( j = 0 , cmpt = 0 , startheader = offset + s - > sh . entry_point_offset[0] ; j < s - > skipped_bytes ; j + + ) { if ( s - > skipped_bytes_pos[j] > = offset & & s - > skipped_bytes_pos[j] < startheader ) { startheader - - ; cmpt + + ; for ( i = 1 ; i < s - > sh . num_entry_point_offsets ; i + + ) { offset + = ( s - > sh . entry_point_offset[i - 1] - cmpt ) ; for ( j = 0 , cmpt = 0 , startheader = offset + s - > sh . entry_point_offset[i] ; j < s - > skipped_bytes ; j + + ) { if ( s - > skipped_bytes_pos[j] > = offset & & s - > skipped_bytes_pos[j] < startheader ) { startheader - - ; cmpt + + ; s - > sh . size[i - 1] = s - > sh . entry_point_offset[i] - cmpt ; s - > sh . offset[i - 1] = offset ; if ( s - > sh . num_entry_point_offsets ! = 0 ) { offset + = s - > sh . entry_point_offset[s - > sh . num_entry_point_offsets - 1] - cmpt ; s - > sh . size[s - > sh . num_entry_point_offsets - 1] = length - offset ; s - > sh . offset[s - > sh . num_entry_point_offsets - 1] = offset ; s - > data = nal ; for ( i = 1 ; i < s - > threads_number ; i + + ) { s - > sList[i] - > HEVClc - > first_qp_group = 1 ; s - > sList[i] - > HEVClc - > qp_y = s - > sList[0] - > HEVClc - > qp_y ; memcpy ( s - > sList[i] , s , sizeof ( HEVCContext ) ) ; s - > sList[i] - > HEVClc = s - > HEVClcList[i] ; avpriv_atomic_int_set ( & s - > wpp_err , 0 ) ; ff_reset_entries ( s - > avctx ) ; for ( i = 0 ; i < = s - > sh . num_entry_point_offsets ; i + + ) { arg[i] = i ; ret[i] = 0 ; if ( s - > pps - > entropy_coding_sync_enabled_flag ) s - > avctx - > execute2 ( s - > avctx , ( void * ) hls_decode_entry_wpp , arg , ret , s - > sh . num_entry_point_offsets + 1 ) ; for ( i = 0 ; i < = s - > sh . num_entry_point_offsets ; i + + ) res + = ret[i] ; return res ;",1
"static void opt_input_file ( void * optctx , const char * arg ) { if ( input_filename ) { fprintf ( stderr , Argument ' %s ' provided as input filename , but ' %s ' was already specified . \n , arg , input_filename ) ; exit ( 1 ) ; } if ( ! strcmp ( arg , - ) ) arg = pipe : ; input_filename = arg ; }",1
"static void decode_p_block ( FourXContext * f , uint16_t * dst , uint16_t * src , int log2w , int log2h , int stride ) { const int index = size2index[log2h][log2w] ; const int h = 1 < < log2h ; int code = get_vlc2 ( & f - > gb , block_type_vlc[1 - ( f - > version > 1 ) ][index] . table , BLOCK_TYPE_VLC_BITS , 1 ) ; uint16_t * start = ( uint16_t * ) f - > last_picture . data[0] ; uint16_t * end = start + stride * ( f - > avctx - > height - h + 1 ) - ( 1 < < log2w ) ; av_assert2 ( code > = 0 & & code < = 6 ) ; if ( code == 0 ) { if ( bytestream2_get_bytes_left ( & f - > g ) < 1 ) { av_log ( f - > avctx , AV_LOG_ERROR , bytestream overread\n ) ; return ; } src + = f - > mv[bytestream2_get_byteu ( & f - > g ) ] ; if ( start > src || src > end ) { av_log ( f - > avctx , AV_LOG_ERROR , mv out of pic\n ) ; return ; } mcdc ( dst , src , log2w , h , stride , 1 , 0 ) ; } else if ( code == 1 ) { log2h - - ; decode_p_block ( f , dst , src , log2w , log2h , stride ) ; decode_p_block ( f , dst + ( stride < < log2h ) , src + ( stride < < log2h ) , log2w , log2h , stride ) ; } else if ( code == 2 ) { log2w - - ; decode_p_block ( f , dst , src , log2w , log2h , stride ) ; decode_p_block ( f , dst + ( 1 < < log2w ) , src + ( 1 < < log2w ) , log2w , log2h , stride ) ; } else if ( code == 3 & & f - > version < 2 ) { mcdc ( dst , src , log2w , h , stride , 1 , 0 ) ; } else if ( code == 4 ) { if ( bytestream2_get_bytes_left ( & f - > g ) < 1 ) { av_log ( f - > avctx , AV_LOG_ERROR , bytestream overread\n ) ; return ; } src + = f - > mv[bytestream2_get_byteu ( & f - > g ) ] ; if ( start > src || src > end ) { av_log ( f - > avctx , AV_LOG_ERROR , mv out of pic\n ) ; return ; } if ( bytestream2_get_bytes_left ( & f - > g ) < 2 ) { av_log ( f - > avctx , AV_LOG_ERROR , wordstream overread\n ) ; return ; } mcdc ( dst , src , log2w , h , stride , 1 , bytestream2_get_le16u ( & f - > g2 ) ) ; } else if ( code == 5 ) { if ( bytestream2_get_bytes_left ( & f - > g ) < 2 ) { av_log ( f - > avctx , AV_LOG_ERROR , wordstream overread\n ) ; return ; } mcdc ( dst , src , log2w , h , stride , 0 , bytestream2_get_le16u ( & f - > g2 ) ) ; } else if ( code == 6 ) { if ( bytestream2_get_bytes_left ( & f - > g ) < 4 ) { av_log ( f - > avctx , AV_LOG_ERROR , wordstream overread\n ) ; return ; } if ( log2w ) { dst[0] = bytestream2_get_le16u ( & f - > g2 ) ; dst[1] = bytestream2_get_le16u ( & f - > g2 ) ; } else { dst[0] = bytestream2_get_le16u ( & f - > g2 ) ; dst[stride] = bytestream2_get_le16u ( & f - > g2 ) ; } } }",0
"static void generate_coupling_coordinates ( AC3DecodeContext * ctx ) { ac3_audio_block * ab = & ctx - > audio_block ; uint8_t exp , mstrcplco ; int16_t mant ; uint32_t cplbndstrc = ( 1 < < ab - > ncplsubnd ) > > 1 ; int ch , bnd , sbnd ; float cplco ; if ( ab - > cplcoe ) for ( ch = 0 ; ch < ctx - > bsi . nfchans ; ch + + ) if ( ab - > cplcoe & ( 1 < < ch ) ) { mstrcplco = 3 * ab - > mstrcplco[ch] ; sbnd = ab - > cplbegf ; for ( bnd = 0 ; bnd < ab - > ncplbnd ; bnd + + ) { exp = ab - > cplcoexp[ch][bnd] ; if ( exp == 15 ) mant = ab - > cplcomant[ch][bnd] < < = 14 ; else mant = ( ab - > cplcomant[ch][bnd] | 0x10 ) < < 13 ; cplco = to_float ( exp + mstrcplco , mant ) ; if ( ctx - > bsi . acmod == 0x02 & & ( ab - > flags & AC3_AB_PHSFLGINU ) & & ch == 1 & & ( ab - > phsflg & ( 1 < < bnd ) ) ) cplco = - cplco ; / * invert the right channel * / ab - > cplco[ch][sbnd + + ] = cplco ; while ( cplbndstrc & ab - > cplbndstrc ) { cplbndstrc > > = 1 ; ab - > cplco[ch][sbnd + + ] = cplco ; } cplbndstrc > > = 1 ; } } }",0
"static int update_streams_from_subdemuxer ( AVFormatContext * s , struct playlist * pls ) { while ( pls - > n_main_streams < pls - > ctx - > nb_streams ) { int ist_idx = pls - > n_main_streams ; AVStream * st = avformat_new_stream ( s , NULL ) ; AVStream * ist = pls - > ctx - > streams[ist_idx] ; if ( ! st ) return AVERROR ( ENOMEM ) ; st - > id = pls - > index ; set_stream_info_from_input_stream ( st , pls , ist ) ; dynarray_add ( & pls - > main_streams , & pls - > n_main_streams , st ) ; add_stream_to_programs ( s , pls , st ) ; } return 0 ; }",0
"static inline void h264_loop_filter_luma_c ( uint8_t * pix , int xstride , int ystride , int alpha , int beta , int8_t * tc0 ) { int i , d ; for ( i = 0 ; i < 4 ; i + + ) { if ( tc0[i] < 0 ) { pix + = 4 * ystride ; continue ; } for ( d = 0 ; d < 4 ; d + + ) { const int p0 = pix[ - 1 * xstride] ; const int p1 = pix[ - 2 * xstride] ; const int p2 = pix[ - 3 * xstride] ; const int q0 = pix[0] ; const int q1 = pix[1 * xstride] ; const int q2 = pix[2 * xstride] ; if ( FFABS ( p0 - q0 ) < alpha & & FFABS ( p1 - p0 ) < beta & & FFABS ( q1 - q0 ) < beta ) { int tc = tc0[i] ; int i_delta ; if ( FFABS ( p2 - p0 ) < beta ) { if ( tc0[i] ) pix[ - 2 * xstride] = p1 + av_clip ( ( ( p2 + ( ( p0 + q0 + 1 ) > > 1 ) ) > > 1 ) - p1 , - tc0[i] , tc0[i] ) ; tc + + ; } if ( FFABS ( q2 - q0 ) < beta ) { if ( tc0[i] ) pix[ xstride] = q1 + av_clip ( ( ( q2 + ( ( p0 + q0 + 1 ) > > 1 ) ) > > 1 ) - q1 , - tc0[i] , tc0[i] ) ; tc + + ; } i_delta = av_clip ( ( ( ( q0 - p0 ) < < 2 ) + ( p1 - q1 ) + 4 ) > > 3 , - tc , tc ) ; pix[ - xstride] = av_clip_uint8 ( p0 + i_delta ) ; / * p0 ' * / pix[0] = av_clip_uint8 ( q0 - i_delta ) ; / * q0 ' * / } pix + = ystride ; } } }",0
"static int mov_write_udta_tag ( ByteIOContext * pb , MOVContext * mov , AVFormatContext * s ) { offset_t pos = url_ftell ( pb ) ; int i ; put_be32 ( pb , 0 ) ; / * size * / put_tag ( pb , udta ) ; / * iTunes meta data * / mov_write_meta_tag ( pb , mov , s ) ; if ( mov - > mode == MODE_MOV ) { // the title field breaks gtkpod with mp4 and my suspicion is that stuff isnt valid in mp4 / * Requirements * / for ( i=0 ; i < MAX_STREAMS ; i + + ) { if ( mov - > tracks[i] . entry < = 0 ) continue ; if ( mov - > tracks[i] . enc - > codec_id == CODEC_ID_AAC || mov - > tracks[i] . enc - > codec_id == CODEC_ID_MPEG4 ) { mov_write_string_tag ( pb , \251req , QuickTime 6 . 0 or greater , 0 ) ; break ; } } mov_write_string_tag ( pb , \251nam , s - > title , 0 ) ; mov_write_string_tag ( pb , \251aut , s - > author , 0 ) ; mov_write_string_tag ( pb , \251alb , s - > album , 0 ) ; mov_write_day_tag ( pb , s - > year , 0 ) ; if ( mov - > tracks[0] . enc & & ! ( mov - > tracks[0] . enc - > flags & CODEC_FLAG_BITEXACT ) ) mov_write_string_tag ( pb , \251enc , LIBAVFORMAT_IDENT , 0 ) ; mov_write_string_tag ( pb , \251des , s - > comment , 0 ) ; mov_write_string_tag ( pb , \251gen , s - > genre , 0 ) ; } return updateSize ( pb , pos ) ; }",0
"static int vble_unpack ( VBLEContext * ctx , GetBitContext * gb ) { int i ; static const uint8_t LUT[256] = { 8 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 3 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 4 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 3 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 5 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 3 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 4 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 3 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 6 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 3 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 4 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 3 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 5 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 3 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 4 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 3 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 7 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 3 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 4 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 3 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 5 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 3 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 4 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 3 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 6 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 3 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 4 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 3 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 5 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 3 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 4 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , 3 , 0 , 1 , 0 , 2 , 0 , 1 , 0 , } ; / * Read all the lengths in first * / for ( i = 0 ; i < ctx - > size ; i + + ) { / * At most we need to read 9 bits total to get indices up to 8 * / int val = show_bits ( gb , 8 ) ; // read reverse unary if ( val ) { val = LUT[val] ; skip_bits ( gb , val + 1 ) ; ctx - > len[i] = val ; } else { skip_bits ( gb , 8 ) ; if ( ! get_bits1 ( gb ) ) return - 1 ; ctx - > len[i] = 8 ; } } / * For any values that have length 0 * / memset ( ctx - > val , 0 , ctx - > size ) ; for ( i = 0 ; i < ctx - > size ; i + + ) { / * Check we have enough bits left * / if ( get_bits_left ( gb ) < ctx - > len[i] ) return - 1 ; / * get_bits can ' t take a length of 0 * / if ( ctx - > len[i] ) ctx - > val[i] = ( 1 < < ctx - > len[i] ) + get_bits ( gb , ctx - > len[i] ) - 1 ; } return 0 ; }",0
"static void selfTest ( uint8_t * ref[4] , int refStride[4] , int w , int h ) { const int flags[] = { SWS_FAST_BILINEAR , SWS_BILINEAR , SWS_BICUBIC , SWS_X , SWS_POINT , SWS_AREA , 0 } ; const int srcW = w ; const int srcH = h ; const int dstW[] = { srcW - srcW/3 , srcW , srcW + srcW/3 , 0 } ; const int dstH[] = { srcH - srcH/3 , srcH , srcH + srcH/3 , 0 } ; enum PixelFormat srcFormat , dstFormat ; for ( srcFormat = 0 ; srcFormat < PIX_FMT_NB ; srcFormat + + ) { for ( dstFormat = 0 ; dstFormat < PIX_FMT_NB ; dstFormat + + ) { int i , j , k ; int res = 0 ; printf ( %s - > %s\n , sws_format_name ( srcFormat ) , sws_format_name ( dstFormat ) ) ; fflush ( stdout ) ; for ( i = 0 ; dstW[i] & & ! res ; i + + ) for ( j = 0 ; dstH[j] & & ! res ; j + + ) for ( k = 0 ; flags[k] & & ! res ; k + + ) res = doTest ( ref , refStride , w , h , srcFormat , dstFormat , srcW , srcH , dstW[i] , dstH[j] , flags[k] ) ; } } }",0
"static void avc_biwgt_4width_msa ( uint8_t * src , int32_t src_stride , uint8_t * dst , int32_t dst_stride , int32_t height , int32_t log2_denom , int32_t src_weight , int32_t dst_weight , int32_t offset_in ) { if ( 2 == height ) { avc_biwgt_4x2_msa ( src , src_stride , dst , dst_stride , log2_denom , src_weight , dst_weight , offset_in ) ; } else { avc_biwgt_4x4multiple_msa ( src , src_stride , dst , dst_stride , height , log2_denom , src_weight , dst_weight , offset_in ) ; } }",0
"static inline int decode_vui_parameters ( GetBitContext * gb , AVCodecContext * avctx , SPS * sps ) { int aspect_ratio_info_present_flag ; unsigned int aspect_ratio_idc ; aspect_ratio_info_present_flag = get_bits1 ( gb ) ; if ( aspect_ratio_info_present_flag ) { aspect_ratio_idc = get_bits ( gb , 8 ) ; if ( aspect_ratio_idc == EXTENDED_SAR ) { sps - > sar . num = get_bits ( gb , 16 ) ; sps - > sar . den = get_bits ( gb , 16 ) ; } else if ( aspect_ratio_idc < FF_ARRAY_ELEMS ( pixel_aspect ) ) { sps - > sar = pixel_aspect[aspect_ratio_idc] ; } else { av_log ( avctx , AV_LOG_ERROR , illegal aspect ratio\n ) ; return AVERROR_INVALIDDATA ; } } else { sps - > sar . num = sps - > sar . den = 0 ; } if ( get_bits1 ( gb ) ) / * overscan_info_present_flag * / get_bits1 ( gb ) ; / * overscan_appropriate_flag * / sps - > video_signal_type_present_flag = get_bits1 ( gb ) ; if ( sps - > video_signal_type_present_flag ) { get_bits ( gb , 3 ) ; / * video_format * / sps - > full_range = get_bits1 ( gb ) ; / * video_full_range_flag * / sps - > colour_description_present_flag = get_bits1 ( gb ) ; if ( sps - > colour_description_present_flag ) { sps - > color_primaries = get_bits ( gb , 8 ) ; / * colour_primaries * / sps - > color_trc = get_bits ( gb , 8 ) ; / * transfer_characteristics * / sps - > colorspace = get_bits ( gb , 8 ) ; / * matrix_coefficients * / if ( sps - > color_primaries > = AVCOL_PRI_NB ) sps - > color_primaries = AVCOL_PRI_UNSPECIFIED ; if ( sps - > color_trc > = AVCOL_TRC_NB ) sps - > color_trc = AVCOL_TRC_UNSPECIFIED ; if ( sps - > colorspace > = AVCOL_SPC_NB ) sps - > colorspace = AVCOL_SPC_UNSPECIFIED ; } } / * chroma_location_info_present_flag * / if ( get_bits1 ( gb ) ) { / * chroma_sample_location_type_top_field * / avctx - > chroma_sample_location = get_ue_golomb ( gb ) + 1 ; get_ue_golomb ( gb ) ; / * chroma_sample_location_type_bottom_field * / } sps - > timing_info_present_flag = get_bits1 ( gb ) ; if ( sps - > timing_info_present_flag ) { sps - > num_units_in_tick = get_bits_long ( gb , 32 ) ; sps - > time_scale = get_bits_long ( gb , 32 ) ; if ( ! sps - > num_units_in_tick || ! sps - > time_scale ) { av_log ( avctx , AV_LOG_ERROR , time_scale/num_units_in_tick invalid or unsupported ( % PRIu32 /% PRIu32 ) \n , sps - > time_scale , sps - > num_units_in_tick ) ; return AVERROR_INVALIDDATA ; } sps - > fixed_frame_rate_flag = get_bits1 ( gb ) ; } sps - > nal_hrd_parameters_present_flag = get_bits1 ( gb ) ; if ( sps - > nal_hrd_parameters_present_flag ) if ( decode_hrd_parameters ( gb , avctx , sps ) < 0 ) return AVERROR_INVALIDDATA ; sps - > vcl_hrd_parameters_present_flag = get_bits1 ( gb ) ; if ( sps - > vcl_hrd_parameters_present_flag ) if ( decode_hrd_parameters ( gb , avctx , sps ) < 0 ) return AVERROR_INVALIDDATA ; if ( sps - > nal_hrd_parameters_present_flag || sps - > vcl_hrd_parameters_present_flag ) get_bits1 ( gb ) ; / * low_delay_hrd_flag * / sps - > pic_struct_present_flag = get_bits1 ( gb ) ; sps - > bitstream_restriction_flag = get_bits1 ( gb ) ; if ( sps - > bitstream_restriction_flag ) { get_bits1 ( gb ) ; / * motion_vectors_over_pic_boundaries_flag * / get_ue_golomb ( gb ) ; / * max_bytes_per_pic_denom * / get_ue_golomb ( gb ) ; / * max_bits_per_mb_denom * / get_ue_golomb ( gb ) ; / * log2_max_mv_length_horizontal * / get_ue_golomb ( gb ) ; / * log2_max_mv_length_vertical * / sps - > num_reorder_frames = get_ue_golomb ( gb ) ; get_ue_golomb ( gb ) ; / * max_dec_frame_buffering * / if ( get_bits_left ( gb ) < 0 ) { sps - > num_reorder_frames = 0 ; sps - > bitstream_restriction_flag = 0 ; } if ( sps - > num_reorder_frames > 16U / * max_dec_frame_buffering || max_dec_frame_buffering > 16 * / ) { av_log ( avctx , AV_LOG_ERROR , Clipping illegal num_reorder_frames %d\n , sps - > num_reorder_frames ) ; sps - > num_reorder_frames = 16 ; return AVERROR_INVALIDDATA ; } } if ( get_bits_left ( gb ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , Overread VUI by %d bits\n , - get_bits_left ( gb ) ) ; return AVERROR_INVALIDDATA ; } return 0 ; }",0
"static int buffer_needs_copy ( PadContext * s , AVFrame * frame , AVBufferRef * buf ) { int planes[4] = { - 1 , - 1 , - 1 , - 1 } , * p = planes ; int i , j ; / * get all planes in this buffer * / for ( i = 0 ; i < FF_ARRAY_ELEMS ( planes ) & & frame - > data[i] ; i + + ) { if ( av_frame_get_plane_buffer ( frame , i ) == buf ) * p + + = i ; } / * for each plane in this buffer , check that it can be padded without * going over buffer bounds or other planes * / for ( i = 0 ; i < FF_ARRAY_ELEMS ( planes ) & & planes[i] > = 0 ; i + + ) { int hsub = s - > draw . hsub[planes[i]] ; int vsub = s - > draw . vsub[planes[i]] ; uint8_t * start = frame - > data[planes[i]] ; uint8_t * end = start + ( frame - > height > > vsub ) * frame - > linesize[planes[i]] ; / * amount of free space needed before the start and after the end * of the plane * / ptrdiff_t req_start = ( s - > x > > hsub ) * s - > draw . pixelstep[planes[i]] + ( s - > y > > vsub ) * frame - > linesize[planes[i]] ; ptrdiff_t req_end = ( ( s - > w - s - > x - frame - > width ) > > hsub ) * s - > draw . pixelstep[planes[i]] + ( s - > y > > vsub ) * frame - > linesize[planes[i]] ; if ( frame - > linesize[planes[i]] < ( s - > w > > hsub ) * s - > draw . pixelstep[planes[i]] ) return 1 ; if ( start - buf - > data < req_start || ( buf - > data + buf - > size ) - end < req_end ) return 1 ; for ( j = 0 ; j < FF_ARRAY_ELEMS ( planes ) & & planes[j] > = 0 ; j + + ) { int vsub1 = s - > draw . vsub[planes[j]] ; uint8_t * start1 = frame - > data[planes[j]] ; uint8_t * end1 = start1 + ( frame - > height > > vsub1 ) * frame - > linesize[planes[j]] ; if ( i == j ) continue ; if ( FFSIGN ( start - end1 ) ! = FFSIGN ( start - end1 - req_start ) || FFSIGN ( end - start1 ) ! = FFSIGN ( end - start1 + req_end ) ) return 1 ; } } return 0 ; }",0
"int ffurl_alloc ( URLContext * * puc , const char * filename , int flags , const AVIOInterruptCB * int_cb ) { URLProtocol * up = NULL ; char proto_str[128] , proto_nested[128] , * ptr ; size_t proto_len = strspn ( filename , URL_SCHEME_CHARS ) ; if ( filename[proto_len] ! = ' : ' || is_dos_path ( filename ) ) strcpy ( proto_str , file ) ; else av_strlcpy ( proto_str , filename , FFMIN ( proto_len + 1 , sizeof ( proto_str ) ) ) ; av_strlcpy ( proto_nested , proto_str , sizeof ( proto_nested ) ) ; if ( ( ptr = strchr ( proto_nested , ' + ' ) ) ) * ptr = ' \0 ' ; while ( up = ffurl_protocol_next ( up ) ) { if ( ! strcmp ( proto_str , up - > name ) ) return url_alloc_for_protocol ( puc , up , filename , flags , int_cb ) ; if ( up - > flags & URL_PROTOCOL_FLAG_NESTED_SCHEME & & ! strcmp ( proto_nested , up - > name ) ) return url_alloc_for_protocol ( puc , up , filename , flags , int_cb ) ; } * puc = NULL ; return AVERROR_PROTOCOL_NOT_FOUND ; }",0
"static int transcode_subtitles ( InputStream * ist , AVPacket * pkt , int * got_output ) { AVSubtitle subtitle ; int i , ret = avcodec_decode_subtitle2 ( ist - > dec_ctx , & subtitle , got_output , pkt ) ; if ( ret < 0 ) return ret ; if ( ! * got_output ) return ret ; ist - > frames_decoded + + ; for ( i = 0 ; i < nb_output_streams ; i + + ) { OutputStream * ost = output_streams[i] ; if ( ! check_output_constraints ( ist , ost ) || ! ost - > encoding_needed ) continue ; do_subtitle_out ( output_files[ost - > file_index] - > ctx , ost , ist , & subtitle , pkt - > pts ) ; } avsubtitle_free ( & subtitle ) ; return ret ; }",0
"static void decode_pitch_lag_high ( int * lag_int , int * lag_frac , int pitch_index , uint8_t * base_lag_int , int subframe ) { if ( subframe == 0 || subframe == 2 ) { if ( pitch_index < 376 ) { * lag_int = ( pitch_index + 137 ) > > 2 ; * lag_frac = pitch_index - ( * lag_int < < 2 ) + 136 ; } else if ( pitch_index < 440 ) { * lag_int = ( pitch_index + 257 - 376 ) > > 1 ; * lag_frac = ( pitch_index - ( * lag_int < < 1 ) + 256 - 376 ) < < 1 ; / * the actual resolution is 1/2 but expressed as 1/4 * / } else { * lag_int = pitch_index - 280 ; * lag_frac = 0 ; } / * minimum lag for next subframe * / * base_lag_int = av_clip ( * lag_int - 8 - ( * lag_frac < 0 ) , AMRWB_P_DELAY_MIN , AMRWB_P_DELAY_MAX - 15 ) ; // XXX : the spec states clearly that * base_lag_int should be // the nearest integer to * lag_int ( minus 8 ) , but the ref code // actually always uses its floor , I ' m following the latter } else { * lag_int = ( pitch_index + 1 ) > > 2 ; * lag_frac = pitch_index - ( * lag_int < < 2 ) ; * lag_int + = * base_lag_int ; } }",1
"static int transcode ( AVFormatContext * * output_files , int nb_output_files , InputFile * input_files , int nb_input_files , StreamMap * stream_maps , int nb_stream_maps ) { int ret = 0 , i , j , k , n , nb_ostreams = 0 , step ; AVFormatContext * is , * os ; AVCodecContext * codec , * icodec ; OutputStream * ost , * * ost_table = NULL ; InputStream * ist ; char error[1024] ; int key ; int want_sdp = 1 ; uint8_t no_packet[MAX_FILES]= { 0 } ; int no_packet_count=0 ; int nb_frame_threshold[AVMEDIA_TYPE_NB]= { 0 } ; int nb_streams[AVMEDIA_TYPE_NB]= { 0 } ; if ( rate_emu ) for ( i = 0 ; i < nb_input_streams ; i + + ) input_streams[i] . start = av_gettime ( ) ; / * output stream init * / nb_ostreams = 0 ; for ( i=0 ; i < nb_output_files ; i + + ) { os = output_files[i] ; if ( ! os - > nb_streams & & ! ( os - > oformat - > flags & AVFMT_NOSTREAMS ) ) { av_dump_format ( output_files[i] , i , output_files[i] - > filename , 1 ) ; fprintf ( stderr , Output file %d does not contain any stream\n , i ) ; ret = AVERROR ( EINVAL ) ; goto fail ; } nb_ostreams + = os - > nb_streams ; } if ( nb_stream_maps > 0 & & nb_stream_maps ! = nb_ostreams ) { fprintf ( stderr , Number of stream maps must match number of output streams\n ) ; ret = AVERROR ( EINVAL ) ; goto fail ; } / * Sanity check the mapping args - - do the input files & streams exist ? * / for ( i=0 ; i < nb_stream_maps ; i + + ) { int fi = stream_maps[i] . file_index ; int si = stream_maps[i] . stream_index ; if ( fi < 0 || fi > nb_input_files - 1 || si < 0 || si > input_files[fi] . ctx - > nb_streams - 1 ) { fprintf ( stderr , Could not find input stream %d . %d\n , fi , si ) ; ret = AVERROR ( EINVAL ) ; goto fail ; } fi = stream_maps[i] . sync_file_index ; si = stream_maps[i] . sync_stream_index ; if ( fi < 0 || fi > nb_input_files - 1 || si < 0 || si > input_files[fi] . ctx - > nb_streams - 1 ) { fprintf ( stderr , Could not find sync stream %d . %d\n , fi , si ) ; ret = AVERROR ( EINVAL ) ; goto fail ; } } ost_table = av_mallocz ( sizeof ( OutputStream * ) * nb_ostreams ) ; if ( ! ost_table ) goto fail ; for ( k=0 ; k < nb_output_files ; k + + ) { os = output_files[k] ; for ( i=0 ; i < os - > nb_streams ; i + + , n + + ) { nb_streams[os - > streams[i] - > codec - > codec_type] + + ; } } for ( step=1 < < 30 ; step ; step > > =1 ) { int found_streams[AVMEDIA_TYPE_NB]= { 0 } ; for ( j=0 ; j < AVMEDIA_TYPE_NB ; j + + ) nb_frame_threshold[j] + = step ; for ( j=0 ; j < nb_input_streams ; j + + ) { int skip=0 ; ist = & input_streams[j] ; if ( opt_programid ) { int pi , si ; AVFormatContext * f= input_files[ ist - > file_index ] . ctx ; skip=1 ; for ( pi=0 ; pi < f - > nb_programs ; pi + + ) { AVProgram * p= f - > programs[pi] ; if ( p - > id == opt_programid ) for ( si=0 ; si < p - > nb_stream_indexes ; si + + ) { if ( f - > streams[ p - > stream_index[si] ] == ist - > st ) skip=0 ; } } } if ( ist - > discard & & ist - > st - > discard ! = AVDISCARD_ALL & & ! skip & & nb_frame_threshold[ist - > st - > codec - > codec_type] < = ist - > st - > codec_info_nb_frames ) { found_streams[ist - > st - > codec - > codec_type] + + ; } } for ( j=0 ; j < AVMEDIA_TYPE_NB ; j + + ) if ( found_streams[j] < nb_streams[j] ) nb_frame_threshold[j] - = step ; } n = 0 ; for ( k=0 ; k < nb_output_files ; k + + ) { os = output_files[k] ; for ( i=0 ; i < os - > nb_streams ; i + + , n + + ) { int found ; ost = ost_table[n] = output_streams_for_file[k][i] ; if ( nb_stream_maps > 0 ) { ost - > source_index = input_files[stream_maps[n] . file_index] . ist_index + stream_maps[n] . stream_index ; / * Sanity check that the stream types match * / if ( input_streams[ost - > source_index] . st - > codec - > codec_type ! = ost - > st - > codec - > codec_type ) { int i= ost - > file_index ; av_dump_format ( output_files[i] , i , output_files[i] - > filename , 1 ) ; fprintf ( stderr , Codec type mismatch for mapping %d . %d - > %d . %d\n , stream_maps[n] . file_index , stream_maps[n] . stream_index , ost - > file_index , ost - > index ) ; ffmpeg_exit ( 1 ) ; } } else { / * get corresponding input stream index : we select the first one with the right type * / found = 0 ; for ( j = 0 ; j < nb_input_streams ; j + + ) { int skip=0 ; ist = & input_streams[j] ; if ( opt_programid ) { int pi , si ; AVFormatContext * f = input_files[ist - > file_index] . ctx ; skip=1 ; for ( pi=0 ; pi < f - > nb_programs ; pi + + ) { AVProgram * p= f - > programs[pi] ; if ( p - > id == opt_programid ) for ( si=0 ; si < p - > nb_stream_indexes ; si + + ) { if ( f - > streams[ p - > stream_index[si] ] == ist - > st ) skip=0 ; } } } if ( ist - > discard & & ist - > st - > discard ! = AVDISCARD_ALL & & ! skip & & ist - > st - > codec - > codec_type == ost - > st - > codec - > codec_type & & nb_frame_threshold[ist - > st - > codec - > codec_type] < = ist - > st - > codec_info_nb_frames ) { ost - > source_index = j ; found = 1 ; break ; } } if ( ! found ) { if ( ! opt_programid ) { / * try again and reuse existing stream * / for ( j = 0 ; j < nb_input_streams ; j + + ) { ist = & input_streams[j] ;",1
"static int amv_encode_picture ( AVCodecContext * avctx , AVPacket * pkt , const AVFrame * pic_arg , int * got_packet ) { MpegEncContext * s = avctx - > priv_data ; AVFrame * pic ; int i , ret ; int chroma_h_shift , chroma_v_shift ; av_pix_fmt_get_chroma_sub_sample ( avctx - > pix_fmt , & chroma_h_shift , & chroma_v_shift ) ; //CODEC_FLAG_EMU_EDGE have to be cleared if ( s - > avctx - > flags & CODEC_FLAG_EMU_EDGE ) return AVERROR ( EINVAL ) ; if ( avctx - > height & 15 ) { av_log ( avctx , AV_LOG_ERROR , Height must be a multiple of 16 , also note , if you have a AMV sample thats mod 16 ! = 0 , please contact us\n ) ; return AVERROR ( EINVAL ) ; } pic = av_frame_clone ( pic_arg ) ; if ( ! pic ) return AVERROR ( ENOMEM ) ; //picture should be flipped upside - down for ( i=0 ; i < 3 ; i + + ) { int vsample = i ? 2 > > chroma_v_shift : 2 ; pic - > data[i] + = ( pic - > linesize[i] * ( vsample * ( 8 * s - > mb_height - ( ( s - > height/V_MAX ) & 7 ) ) - 1 ) ) ; pic - > linesize[i] * = - 1 ; } ret = ff_MPV_encode_picture ( avctx , pkt , pic , got_packet ) ; av_frame_free ( & pic ) ; return ret ; }",1
"static inline void halfpel_motion_search4 ( MpegEncContext * s , int * mx_ptr , int * my_ptr , int dmin , int xmin , int ymin , int xmax , int ymax , int pred_x , int pred_y , int block_x , int block_y , uint8_t * ref_picture ) { UINT16 * mv_penalty= s - > mv_penalty[s - > f_code] + MAX_MV ; // f_code of the prev frame const int quant= s - > qscale ; int pen_x , pen_y ; int mx , my , mx1 , my1 , d , xx , yy , dminh ; UINT8 * pix , * ptr ; xx = 8 * block_x ; yy = 8 * block_y ; pix = s - > new_picture[0] + ( yy * s - > linesize ) + xx ; mx = * mx_ptr ; my = * my_ptr ; ptr = ref_picture + ( ( yy + my ) * s - > linesize ) + xx + mx ; dminh = dmin ; if ( mx > xmin & & mx < xmax & & my > ymin & & my < ymax ) { mx= mx1= 2 * mx ; my= my1= 2 * my ; if ( dmin < Z_THRESHOLD & & mx==0 & & my==0 ) { * mx_ptr = 0 ; * my_ptr = 0 ; return ; } pen_x= pred_x + mx ; pen_y= pred_y + my ; ptr - = s - > linesize ; CHECK_HALF_MV4 ( xy2 , - 1 , - 1 ) CHECK_HALF_MV4 ( y2 , 0 , - 1 ) CHECK_HALF_MV4 ( xy2 , + 1 , - 1 ) ptr + = s - > linesize ; CHECK_HALF_MV4 ( x2 , - 1 , 0 ) CHECK_HALF_MV4 ( x2 , + 1 , 0 ) CHECK_HALF_MV4 ( xy2 , - 1 , + 1 ) CHECK_HALF_MV4 ( y2 , 0 , + 1 ) CHECK_HALF_MV4 ( xy2 , + 1 , + 1 ) } else { mx * =2 ; my * =2 ; } * mx_ptr = mx ; * my_ptr = my ; }",0
"static void ff_h264_idct8_add4_mmx ( uint8_t * dst , const int * block_offset , DCTELEM * block , int stride , const uint8_t nnzc[6 * 8] ) { int i ; for ( i=0 ; i < 16 ; i + =4 ) { if ( nnzc[ scan8[i] ] ) ff_h264_idct8_add_mmx ( dst + block_offset[i] , block + i * 16 , stride ) ; } }",0
"static int mpegts_raw_read_packet ( AVFormatContext * s , AVPacket * pkt ) { MpegTSContext * ts = s - > priv_data ; int ret , i ; int64_t pcr_h , next_pcr_h , pos ; int pcr_l , next_pcr_l ; uint8_t pcr_buf[12] ; if ( av_new_packet ( pkt , TS_PACKET_SIZE ) < 0 ) return AVERROR ( ENOMEM ) ; pkt - > pos= url_ftell ( s - > pb ) ; ret = read_packet ( s - > pb , pkt - > data , ts - > raw_packet_size ) ; if ( ret < 0 ) { av_free_packet ( pkt ) ; return ret ; } if ( ts - > mpeg2ts_compute_pcr ) { / * compute exact PCR for each packet * / if ( parse_pcr ( & pcr_h , & pcr_l , pkt - > data ) == 0 ) { / * we read the next PCR ( XXX : optimize it by using a bigger buffer * / pos = url_ftell ( s - > pb ) ; for ( i = 0 ; i < MAX_PACKET_READAHEAD ; i + + ) { url_fseek ( s - > pb , pos + i * ts - > raw_packet_size , SEEK_SET ) ; get_buffer ( s - > pb , pcr_buf , 12 ) ; if ( parse_pcr ( & next_pcr_h , & next_pcr_l , pcr_buf ) == 0 ) { / * XXX : not precise enough * / ts - > pcr_incr = ( ( next_pcr_h - pcr_h ) * 300 + ( next_pcr_l - pcr_l ) ) / ( i + 1 ) ; break ; } } url_fseek ( s - > pb , pos , SEEK_SET ) ; / * no next PCR found : we use previous increment * / ts - > cur_pcr = pcr_h * 300 + pcr_l ; } pkt - > pts = ts - > cur_pcr ; pkt - > duration = ts - > pcr_incr ; ts - > cur_pcr + = ts - > pcr_incr ; } pkt - > stream_index = 0 ; return 0 ; }",0
"int avio_open2 ( AVIOContext * * s , const char * filename , int flags , const AVIOInterruptCB * int_cb , AVDictionary * * options ) { URLContext * h ; int err ; err = ffurl_open ( & h , filename , flags , int_cb , options ) ; if ( err < 0 ) return err ; err = ffio_fdopen ( s , h ) ; if ( err < 0 ) { ffurl_close ( h ) ; return err ; } return 0 ; }",0
"static void sbr_hf_inverse_filter ( float ( * alpha0 ) [2] , float ( * alpha1 ) [2] , const float X_low[32][40][2] , int k0 ) { int k ; for ( k = 0 ; k < k0 ; k + + ) { float phi[3][2][2] , dk ; autocorrelate ( X_low[k] , phi , 0 ) ; autocorrelate ( X_low[k] , phi , 1 ) ; autocorrelate ( X_low[k] , phi , 2 ) ; dk = phi[2][1][0] * phi[1][0][0] - ( phi[1][1][0] * phi[1][1][0] + phi[1][1][1] * phi[1][1][1] ) / 1 . 000001f ; if ( ! dk ) { alpha1[k][0] = 0 ; alpha1[k][1] = 0 ; } else { float temp_real , temp_im ; temp_real = phi[0][0][0] * phi[1][1][0] - phi[0][0][1] * phi[1][1][1] - phi[0][1][0] * phi[1][0][0] ; temp_im = phi[0][0][0] * phi[1][1][1] + phi[0][0][1] * phi[1][1][0] - phi[0][1][1] * phi[1][0][0] ; alpha1[k][0] = temp_real / dk ; alpha1[k][1] = temp_im / dk ; } if ( ! phi[1][0][0] ) { alpha0[k][0] = 0 ; alpha0[k][1] = 0 ; } else { float temp_real , temp_im ; temp_real = phi[0][0][0] + alpha1[k][0] * phi[1][1][0] + alpha1[k][1] * phi[1][1][1] ; temp_im = phi[0][0][1] + alpha1[k][1] * phi[1][1][0] - alpha1[k][0] * phi[1][1][1] ; alpha0[k][0] = - temp_real / phi[1][0][0] ; alpha0[k][1] = - temp_im / phi[1][0][0] ; } if ( alpha1[k][0] * alpha1[k][0] + alpha1[k][1] * alpha1[k][1] > = 16 . 0f || alpha0[k][0] * alpha0[k][0] + alpha0[k][1] * alpha0[k][1] > = 16 . 0f ) { alpha1[k][0] = 0 ; alpha1[k][1] = 0 ; alpha0[k][0] = 0 ; alpha0[k][1] = 0 ; } } }",0
"static int avi_write_trailer ( AVFormatContext * s ) { AVIContext * avi = s - > priv_data ; AVIOContext * pb = s - > pb ; int res = 0 ; int i , j , n , nb_frames ; int64_t file_size ; if ( pb - > seekable ) { if ( avi - > riff_id == 1 ) { ff_end_tag ( pb , avi - > movi_list ) ; res = avi_write_idx1 ( s ) ; ff_end_tag ( pb , avi - > riff_start ) ; } else { avi_write_ix ( s ) ; ff_end_tag ( pb , avi - > movi_list ) ; ff_end_tag ( pb , avi - > riff_start ) ; file_size = avio_tell ( pb ) ; avio_seek ( pb , avi - > odml_list - 8 , SEEK_SET ) ; ffio_wfourcc ( pb , LIST ) ; / * Making this AVI OpenDML one * / avio_skip ( pb , 16 ) ; for ( n = nb_frames = 0 ; n < s - > nb_streams ; n + + ) { AVCodecParameters * par = s - > streams[n] - > codecpar ; AVIStream * avist = s - > streams[n] - > priv_data ; if ( par - > codec_type == AVMEDIA_TYPE_VIDEO ) { if ( nb_frames < avist - > packet_count ) nb_frames = avist - > packet_count ; } else { if ( par - > codec_id == AV_CODEC_ID_MP2 || par - > codec_id == AV_CODEC_ID_MP3 ) nb_frames + = avist - > packet_count ; } } avio_wl32 ( pb , nb_frames ) ; avio_seek ( pb , file_size , SEEK_SET ) ; avi_write_counters ( s , avi - > riff_id ) ; } } for ( i = 0 ; i < s - > nb_streams ; i + + ) { AVIStream * avist = s - > streams[i] - > priv_data ; for ( j = 0 ; j < avist - > indexes . ents_allocated / AVI_INDEX_CLUSTER_SIZE ; j + + ) av_free ( avist - > indexes . cluster[j] ) ; av_freep ( & avist - > indexes . cluster ) ; avist - > indexes . ents_allocated = avist - > indexes . entry = 0 ; } return res ; }",0
"static int mov_read_udta_string ( MOVContext * c , AVIOContext * pb , MOVAtom atom ) { char tmp_key[5] ; char str[1024] , key2[32] , language[4] = { 0 } ; const char * key = NULL ; uint16_t langcode = 0 ; uint32_t data_type = 0 , str_size ; int ( * parse ) ( MOVContext * , AVIOContext * , unsigned , const char * ) = NULL ; switch ( atom . type ) { case MKTAG ( 0xa9 , ' n ' , ' a ' , ' m ' ) : key = title ; break ; case MKTAG ( 0xa9 , ' a ' , ' u ' , ' t ' ) : case MKTAG ( 0xa9 , ' A ' , ' R ' , ' T ' ) : key = artist ; break ; case MKTAG ( ' a ' , ' A ' , ' R ' , ' T ' ) : key = album_artist ; break ; case MKTAG ( 0xa9 , ' w ' , ' r ' , ' t ' ) : key = composer ; break ; case MKTAG ( ' c ' , ' p ' , ' r ' , ' t ' ) : case MKTAG ( 0xa9 , ' c ' , ' p ' , ' y ' ) : key = copyright ; break ; case MKTAG ( 0xa9 , ' c ' , ' m ' , ' t ' ) : case MKTAG ( 0xa9 , ' i ' , ' n ' , ' f ' ) : key = comment ; break ; case MKTAG ( 0xa9 , ' a ' , ' l ' , ' b ' ) : key = album ; break ; case MKTAG ( 0xa9 , ' d ' , ' a ' , ' y ' ) : key = date ; break ; case MKTAG ( 0xa9 , ' g ' , ' e ' , ' n ' ) : key = genre ; break ; case MKTAG ( ' g ' , ' n ' , ' r ' , ' e ' ) : key = genre ; parse = mov_metadata_gnre ; break ; case MKTAG ( 0xa9 , ' t ' , ' o ' , ' o ' ) : case MKTAG ( 0xa9 , ' s ' , ' w ' , ' r ' ) : key = encoder ; break ; case MKTAG ( 0xa9 , ' e ' , ' n ' , ' c ' ) : key = encoder ; break ; case MKTAG ( 0xa9 , ' x ' , ' y ' , ' z ' ) : key = location ; break ; case MKTAG ( ' d ' , ' e ' , ' s ' , ' c ' ) : key = description ; break ; case MKTAG ( ' l ' , ' d ' , ' e ' , ' s ' ) : key = synopsis ; break ; case MKTAG ( ' t ' , ' v ' , ' s ' , ' h ' ) : key = show ; break ; case MKTAG ( ' t ' , ' v ' , ' e ' , ' n ' ) : key = episode_id ; break ; case MKTAG ( ' t ' , ' v ' , ' n ' , ' n ' ) : key = network ; break ; case MKTAG ( ' t ' , ' r ' , ' k ' , ' n ' ) : key = track ; parse = mov_metadata_track_or_disc_number ; break ; case MKTAG ( ' d ' , ' i ' , ' s ' , ' k ' ) : key = disc ; parse = mov_metadata_track_or_disc_number ; break ; case MKTAG ( ' t ' , ' v ' , ' e ' , ' s ' ) : key = episode_sort ; parse = mov_metadata_int8_bypass_padding ; break ; case MKTAG ( ' t ' , ' v ' , ' s ' , ' n ' ) : key = season_number ; parse = mov_metadata_int8_bypass_padding ; break ; case MKTAG ( ' s ' , ' t ' , ' i ' , ' k ' ) : key = media_type ; parse = mov_metadata_int8_no_padding ; break ; case MKTAG ( ' h ' , ' d ' , ' v ' , ' d ' ) : key = hd_video ; parse = mov_metadata_int8_no_padding ; break ; case MKTAG ( ' p ' , ' g ' , ' a ' , ' p ' ) : key = gapless_playback ; parse = mov_metadata_int8_no_padding ; break ; case MKTAG ( ' l ' , ' o ' , ' c ' , ' i ' ) : return mov_metadata_loci ( c , pb , atom . size ) ; } if ( c - > itunes_metadata & & atom . size > 8 ) { int data_size = avio_rb32 ( pb ) ; int tag = avio_rl32 ( pb ) ; if ( tag == MKTAG ( ' d ' , ' a ' , ' t ' , ' a ' ) ) { data_type = avio_rb32 ( pb ) ; // type avio_rb32 ( pb ) ; // unknown str_size = data_size - 16 ; atom . size - = 16 ; if ( atom . type == MKTAG ( ' c ' , ' o ' , ' v ' , ' r ' ) ) { int ret = mov_read_covr ( c , pb , data_type , str_size ) ; if ( ret < 0 ) { av_log ( c - > fc , AV_LOG_ERROR , Error parsing cover art . \n ) ; return ret ; } } } else return 0 ; } else if ( atom . size > 4 & & key & & ! c - > itunes_metadata ) { str_size = avio_rb16 ( pb ) ; // string length langcode = avio_rb16 ( pb ) ; ff_mov_lang_to_iso639 ( langcode , language ) ; atom . size - = 4 ; } else str_size = atom . size ; if ( c - > export_all & & ! key ) { snprintf ( tmp_key , 5 , % . 4s , ( char * ) & atom . type ) ; key = tmp_key ; } if ( ! key ) return 0 ; if ( atom . size < 0 ) return AVERROR_INVALIDDATA ; str_size = FFMIN3 ( sizeof ( str ) - 1 , str_size , atom . size ) ; if ( parse ) parse ( c , pb , str_size , key ) ; else { if ( data_type == 3 || ( data_type == 0 & & ( langcode < 0x400 || langcode == 0x7fff ) ) ) { // MAC Encoded mov_read_mac_string ( c , pb , str_size , str , sizeof ( str ) ) ; } else { avio_read",0
"static AVFilterBufferRef * get_video_buffer ( AVFilterLink * link , int perms , int w , int h ) { FlipContext * flip = link - > dst - > priv ; int i ; AVFilterBufferRef * picref = avfilter_get_video_buffer ( link - > dst - > outputs[0] , perms , w , h ) ; for ( i = 0 ; i < 4 ; i + + ) { int vsub = i == 1 || i == 2 ? flip - > vsub : 0 ; if ( picref - > data[i] ) { picref - > data[i] + = ( ( h > > vsub ) - 1 ) * picref - > linesize[i] ; picref - > linesize[i] = - picref - > linesize[i] ; } } return picref ; }",0
"static int set_pix_fmt ( AVCodecContext * avctx , vpx_codec_caps_t codec_caps , struct vpx_codec_enc_cfg * enccfg , vpx_codec_flags_t * flags , vpx_img_fmt_t * img_fmt ) { VPxContext av_unused * ctx = avctx - > priv_data ; ifdef VPX_IMG_FMT_HIGHBITDEPTH enccfg - > g_bit_depth = enccfg - > g_input_bit_depth = 8 ; endif switch ( avctx - > pix_fmt ) { case AV_PIX_FMT_YUV420P : case AV_PIX_FMT_YUVA420P : enccfg - > g_profile = 0 ; * img_fmt = VPX_IMG_FMT_I420 ; return 0 ; case AV_PIX_FMT_YUV422P : enccfg - > g_profile = 1 ; * img_fmt = VPX_IMG_FMT_I422 ; return 0 ; if VPX_IMAGE_ABI_VERSION > = 3 case AV_PIX_FMT_YUV440P : enccfg - > g_profile = 1 ; * img_fmt = VPX_IMG_FMT_I440 ; return 0 ; case AV_PIX_FMT_GBRP : ctx - > vpx_cs = VPX_CS_SRGB ; endif case AV_PIX_FMT_YUV444P : enccfg - > g_profile = 1 ; * img_fmt = VPX_IMG_FMT_I444 ; return 0 ; ifdef VPX_IMG_FMT_HIGHBITDEPTH case AV_PIX_FMT_YUV420P10 : case AV_PIX_FMT_YUV420P12 : if ( codec_caps & VPX_CODEC_CAP_HIGHBITDEPTH ) { enccfg - > g_bit_depth = enccfg - > g_input_bit_depth = avctx - > pix_fmt == AV_PIX_FMT_YUV420P10 ? 10 : 12 ; enccfg - > g_profile = 2 ; * img_fmt = VPX_IMG_FMT_I42016 ; * flags |= VPX_CODEC_USE_HIGHBITDEPTH ; return 0 ; } break ; case AV_PIX_FMT_YUV422P10 : case AV_PIX_FMT_YUV422P12 : if ( codec_caps & VPX_CODEC_CAP_HIGHBITDEPTH ) { enccfg - > g_bit_depth = enccfg - > g_input_bit_depth = avctx - > pix_fmt == AV_PIX_FMT_YUV422P10 ? 10 : 12 ; enccfg - > g_profile = 3 ; * img_fmt = VPX_IMG_FMT_I42216 ; * flags |= VPX_CODEC_USE_HIGHBITDEPTH ; return 0 ; } break ; if VPX_IMAGE_ABI_VERSION > = 3 case AV_PIX_FMT_YUV440P10 : case AV_PIX_FMT_YUV440P12 : if ( codec_caps & VPX_CODEC_CAP_HIGHBITDEPTH ) { enccfg - > g_bit_depth = enccfg - > g_input_bit_depth = avctx - > pix_fmt == AV_PIX_FMT_YUV440P10 ? 10 : 12 ; enccfg - > g_profile = 3 ; * img_fmt = VPX_IMG_FMT_I44016 ; * flags |= VPX_CODEC_USE_HIGHBITDEPTH ; return 0 ; } break ; case AV_PIX_FMT_GBRP10 : case AV_PIX_FMT_GBRP12 : ctx - > vpx_cs = VPX_CS_SRGB ; endif case AV_PIX_FMT_YUV444P10 : case AV_PIX_FMT_YUV444P12 : if ( codec_caps & VPX_CODEC_CAP_HIGHBITDEPTH ) { enccfg - > g_bit_depth = enccfg - > g_input_bit_depth = avctx - > pix_fmt == AV_PIX_FMT_YUV444P10 || avctx - > pix_fmt == AV_PIX_FMT_GBRP10 ? 10 : 12 ; enccfg - > g_profile = 3 ; * img_fmt = VPX_IMG_FMT_I44416 ; * flags |= VPX_CODEC_USE_HIGHBITDEPTH ; return 0 ; } break ; endif default : break ; } av_log ( avctx , AV_LOG_ERROR , Unsupported pixel format . \n ) ; return AVERROR_INVALIDDATA ; }",0
"static inline void RENAME ( rgb24to16 ) ( const uint8_t * src , uint8_t * dst , long src_size ) { const uint8_t * s = src ; const uint8_t * end ; if COMPILE_TEMPLATE_MMX const uint8_t * mm_end ; endif uint16_t * d = ( uint16_t * ) dst ; end = s + src_size ; if COMPILE_TEMPLATE_MMX __asm__ volatile ( PREFETCH %0 : : m ( * src ) : memory ) ; __asm__ volatile ( movq %0 , %%mm7 \n\t movq %1 , %%mm6 \n\t : : m ( red_16mask ) , m ( green_16mask ) ) ; mm_end = end - 15 ; while ( s < mm_end ) { __asm__ volatile ( PREFETCH 32%1 \n\t movd %1 , %%mm0 \n\t movd 3%1 , %%mm3 \n\t punpckldq 6%1 , %%mm0 \n\t punpckldq 9%1 , %%mm3 \n\t movq %%mm0 , %%mm1 \n\t movq %%mm0 , %%mm2 \n\t movq %%mm3 , %%mm4 \n\t movq %%mm3 , %%mm5 \n\t psllq 8 , %%mm0 \n\t psllq 8 , %%mm3 \n\t pand %%mm7 , %%mm0 \n\t pand %%mm7 , %%mm3 \n\t psrlq 5 , %%mm1 \n\t psrlq 5 , %%mm4 \n\t pand %%mm6 , %%mm1 \n\t pand %%mm6 , %%mm4 \n\t psrlq 19 , %%mm2 \n\t psrlq 19 , %%mm5 \n\t pand %2 , %%mm2 \n\t pand %2 , %%mm5 \n\t por %%mm1 , %%mm0 \n\t por %%mm4 , %%mm3 \n\t por %%mm2 , %%mm0 \n\t por %%mm5 , %%mm3 \n\t psllq 16 , %%mm3 \n\t por %%mm3 , %%mm0 \n\t MOVNTQ %%mm0 , %0 \n\t : =m ( * d ) : m ( * s ) , m ( blue_16mask ) : memory ) ; d + = 4 ; s + = 12 ; } __asm__ volatile ( SFENCE : : : memory ) ; __asm__ volatile ( EMMS : : : memory ) ; endif while ( s < end ) { const int r = * s + + ; const int g = * s + + ; const int b = * s + + ; * d + + = ( b > > 3 ) | ( ( g & 0xFC ) < < 3 ) | ( ( r & 0xF8 ) < < 8 ) ; } }",0
"static inline void RENAME ( yuv2packed2 ) ( SwsContext * c , const uint16_t * buf0 , const uint16_t * buf1 , const uint16_t * uvbuf0 , const uint16_t * uvbuf1 , const uint16_t * abuf0 , const uint16_t * abuf1 , uint8_t * dest , int dstW , int yalpha , int uvalpha , int y ) { int yalpha1=4095 - yalpha ; int uvalpha1=4095 - uvalpha ; int i ; if COMPILE_TEMPLATE_MMX if ( ! ( c - > flags & SWS_BITEXACT ) ) { switch ( c - > dstFormat ) { //Note 8280 == DSTW_OFFSET but the preprocessor can ' t handle that there : ( case PIX_FMT_RGB32 : if ( CONFIG_SWSCALE_ALPHA & & c - > alpPixBuf ) { if ARCH_X86_64 __asm__ volatile ( YSCALEYUV2RGB ( %%r8 , %5 ) YSCALEYUV2RGB_YA ( %%r8 , %5 , %6 , %7 ) psraw 3 , %%mm1 \n\t / * abuf0[eax] - abuf1[eax] > > 7 * / psraw 3 , %%mm7 \n\t / * abuf0[eax] - abuf1[eax] > > 7 * / packuswb %%mm7 , %%mm1 \n\t WRITEBGR32 ( %4 , 8280 ( %5 ) , %%r8 , %%mm2 , %%mm4 , %%mm5 , %%mm1 , %%mm0 , %%mm7 , %%mm3 , %%mm6 ) : : c ( buf0 ) , d ( buf1 ) , S ( uvbuf0 ) , D ( uvbuf1 ) , r ( dest ) , a ( & c - > redDither ) , r ( abuf0 ) , r ( abuf1 ) : %r8 ) ; else c - > u_temp= ( intptr_t ) abuf0 ; c - > v_temp= ( intptr_t ) abuf1 ; __asm__ volatile ( mov %% REG_b , ESP_OFFSET ( %5 ) \n\t mov %4 , %% REG_b \n\t push %% REG_BP \n\t YSCALEYUV2RGB ( %%REGBP , %5 ) push %0 \n\t push %1 \n\t mov U_TEMP ( %5 ) , %0 \n\t mov V_TEMP ( %5 ) , %1 \n\t YSCALEYUV2RGB_YA ( %%REGBP , %5 , %0 , %1 ) psraw 3 , %%mm1 \n\t / * abuf0[eax] - abuf1[eax] > > 7 * / psraw 3 , %%mm7 \n\t / * abuf0[eax] - abuf1[eax] > > 7 * / packuswb %%mm7 , %%mm1 \n\t pop %1 \n\t pop %0 \n\t WRITEBGR32 ( %%REGb , 8280 ( %5 ) , %%REGBP , %%mm2 , %%mm4 , %%mm5 , %%mm1 , %%mm0 , %%mm7 , %%mm3 , %%mm6 ) pop %% REG_BP \n\t mov ESP_OFFSET ( %5 ) , %% REG_b \n\t : : c ( buf0 ) , d ( buf1 ) , S ( uvbuf0 ) , D ( uvbuf1 ) , m ( dest ) , a ( & c - > redDither ) ) ; endif } else { __asm__ volatile ( mov %% REG_b , ESP_OFFSET ( %5 ) \n\t mov %4 , %% REG_b \n\t push %% REG_BP \n\t YSCALEYUV2RGB ( %%REGBP , %5 ) pcmpeqd %%mm7 , %%mm7 \n\t WRITEBGR32 ( %%REGb , 8280 ( %5 ) , %%REGBP , %%mm2 , %%mm4 , %%mm5 , %%mm7 , %%mm0 , %%mm1 , %%mm3 , %%mm6 ) pop %% REG_BP \n\t mov ESP_OFFSET ( %5 ) , %% REG_b \n\t : : c ( buf0 ) , d ( buf1 ) , S ( uvbuf0 ) , D ( uvbuf1 ) , m ( dest ) , a ( & c - > redDither ) ) ; } return ; case PIX_FMT_BGR24 : __asm__ volatile ( mov %% REG_b , ESP_OFFSET ( %5 ) \n\t mov %4 , %% REG_b \n\t push %% REG_BP \n\t YSCALEYUV2RGB ( %%REGBP , %5 ) pxor %%mm7 , %%mm7 \n\t WRITEBGR24 ( %%REGb , 8280 ( %5 ) , %%REGBP ) pop %% REG_BP \n\t mov ESP_OFFSET ( %5 ) , %% REG_b \n\t : : c ( buf0 ) , d ( buf1 ) , S ( uvbuf0 ) , D ( uvbuf1 ) , m ( dest ) , a ( & c - > redDither ) ) ; return ; case PIX_FMT_RGB555 : __asm__ volatile ( mov %% REG_b , ESP_OFFSET ( %5 ) \n\t mov %4 , %% REG_b \n\t push %% REG_BP \n\t YSCALEYUV2RGB ( %%REGBP , %5 ) pxor %%mm7 , %%mm7 \n\t / * mm2=B , %%mm4=G , %%mm5=R , %%mm7=0 * / ifdef DITHER1XBPP paddusb BLUE_DITHER ( %5 ) , %%mm2 \n\t paddusb GREEN_DITHER ( %5 ) , %%mm4 \n\t paddusb RED_DITHER ( %5 ) , %%mm5 \n\t endif WRITERGB15 ( %%REGb , 8280 ( %5 ) , %%REGBP ) pop %% REG_BP \n\t mov ESP_OFFSET ( %5 ) , %% REG_b \n\t : : c ( buf0 ) , d ( buf1 ) , S ( uvbuf0 ) , D ( uvbuf1 ) , m ( dest ) , a ( & c - > redDither ) ) ; return ; case PIX_FMT_RGB565 : __asm__ volatile ( mov %% REG_b , ESP_OFFSET ( %5 ) \n\t mov %4 , %% REG_b \n\t push %% REG_BP \n\t YSCALEYUV2RGB ( %%REGBP , %5 ) pxor %%mm7 , %%mm7 \n\t / * mm2=B , %%mm4=G , %%mm5=R , %%mm7=0 * / ifdef DITHER1XBPP paddusb BLUE_DITHER ( %5 ) , %%mm2 \n\t paddusb GREEN_DITHER ( %5 ) , %%mm4 \n\t paddusb RED_DITHER ( %5 ) , %%mm5 \n\t endif WRITERGB16 ( %%REGb , 8280 ( %5 ) , %%REGBP ) pop %% REG_BP \n\t mov ESP_OFFSET ( %5 ) , %% REG_b \n\t : : c ( buf0 ) , d ( buf1 ) , S ( uvbuf0 ) , D ( uvbuf1 ) , m ( dest ) , a ( & c - > redDither ) ) ; return ; case PIX_FMT_YUYV422 : __asm__ volatile ( mov %% REG_b , ESP_OFFSET ( %5 ) \n\t mov %4 , %% REG_b \n\t push %% REG_BP \n\t YSCALEYUV2PACKED ( %%REGBP , %5 ) WRITEYUY2 ( %%REGb , 8280 ( %5 ) , %%REGBP ) pop %% REG_BP \n\t mov ESP_OFFSET ( %5 ) , %% REG_b \n\t : : c ( buf0 ) , d ( buf1 ) , S ( uvbuf0 ) , D ( uvbuf1 ) , m ( dest ) , a ( & c - > redDither ) ) ; return ; default : break ; } } endif //COMPILE_TEMPLATE_MMX YSCALE_YUV_2_ANYRGB_C ( YSCALE_YUV_2_RGB2_C , YSCALE_YUV_2_PACKED2_C ( void , 0 ) , YSCALE_YUV_2_GRAY16_2_C , YSCALE_YUV_2_MONO2_C ) }",0
"void put_no_rnd_pixels16_xy2_altivec ( uint8_t * block , const uint8_t * pixels , int line_size , int h ) { POWERPC_TBL_DECLARE ( altivec_put_no_rnd_pixels16_xy2_num , 1 ) ; ifdef ALTIVEC_USE_REFERENCE_C_CODE int j ; POWERPC_TBL_START_COUNT ( altivec_put_no_rnd_pixels16_xy2_num , 1 ) ; for ( j = 0 ; j < 4 ; j + + ) { int i ; const uint32_t a = ( ( ( const struct unaligned_32 * ) ( pixels ) ) - > l ) ; const uint32_t b = ( ( ( const struct unaligned_32 * ) ( pixels + 1 ) ) - > l ) ; uint32_t l0 = ( a & 0x03030303UL ) + ( b & 0x03030303UL ) + 0x01010101UL ; uint32_t h0 = ( ( a & 0xFCFCFCFCUL ) > > 2 ) + ( ( b & 0xFCFCFCFCUL ) > > 2 ) ; uint32_t l1 , h1 ; pixels + = line_size ; for ( i = 0 ; i < h ; i + = 2 ) { uint32_t a = ( ( ( const struct unaligned_32 * ) ( pixels ) ) - > l ) ; uint32_t b = ( ( ( const struct unaligned_32 * ) ( pixels + 1 ) ) - > l ) ; l1 = ( a & 0x03030303UL ) + ( b & 0x03030303UL ) ; h1 = ( ( a & 0xFCFCFCFCUL ) > > 2 ) + ( ( b & 0xFCFCFCFCUL ) > > 2 ) ; * ( ( uint32_t * ) block ) = h0 + h1 + ( ( ( l0 + l1 ) > > 2 ) & 0x0F0F0F0FUL ) ; pixels + = line_size ; block + = line_size ; a = ( ( ( const struct unaligned_32 * ) ( pixels ) ) - > l ) ; b = ( ( ( const struct unaligned_32 * ) ( pixels + 1 ) ) - > l ) ; l0 = ( a & 0x03030303UL ) + ( b & 0x03030303UL ) + 0x01010101UL ; h0 = ( ( a & 0xFCFCFCFCUL ) > > 2 ) + ( ( b & 0xFCFCFCFCUL ) > > 2 ) ; * ( ( uint32_t * ) block ) = h0 + h1 + ( ( ( l0 + l1 ) > > 2 ) & 0x0F0F0F0FUL ) ; pixels + = line_size ; block + = line_size ; } pixels + = 4 - line_size * ( h + 1 ) ; block + = 4 - line_size * h ; } POWERPC_TBL_STOP_COUNT ( altivec_put_no_rnd_pixels16_xy2_num , 1 ) ; else / * ALTIVEC_USE_REFERENCE_C_CODE * / register int i ; register vector unsigned char pixelsv1 , pixelsv2 , pixelsv3 , pixelsv4 ; register vector unsigned char blockv , temp1 , temp2 ; register vector unsigned short pixelssum1 , pixelssum2 , temp3 , pixelssum3 , pixelssum4 , temp4 ; register const vector unsigned char vczero = ( const vector unsigned char ) vec_splat_u8 ( 0 ) ; register const vector unsigned short vcone = ( const vector unsigned short ) vec_splat_u16 ( 1 ) ; register const vector unsigned short vctwo = ( const vector unsigned short ) vec_splat_u16 ( 2 ) ; POWERPC_TBL_START_COUNT ( altivec_put_no_rnd_pixels16_xy2_num , 1 ) ; temp1 = vec_ld ( 0 , pixels ) ; temp2 = vec_ld ( 16 , pixels ) ; pixelsv1 = vec_perm ( temp1 , temp2 , vec_lvsl ( 0 , pixels ) ) ; if ( ( ( ( unsigned long ) pixels ) & 0x0000000F ) == 0x0000000F ) { pixelsv2 = temp2 ; } else { pixelsv2 = vec_perm ( temp1 , temp2 , vec_lvsl ( 1 , pixels ) ) ; } pixelsv3 = vec_mergel ( vczero , pixelsv1 ) ; pixelsv4 = vec_mergel ( vczero , pixelsv2 ) ; pixelsv1 = vec_mergeh ( vczero , pixelsv1 ) ; pixelsv2 = vec_mergeh ( vczero , pixelsv2 ) ; pixelssum3 = vec_add ( ( vector unsigned short ) pixelsv3 , ( vector unsigned short ) pixelsv4 ) ; pixelssum3 = vec_add ( pixelssum3 , vcone ) ; pixelssum1 = vec_add ( ( vector unsigned short ) pixelsv1 , ( vector unsigned short ) pixelsv2 ) ; pixelssum1 = vec_add ( pixelssum1 , vcone ) ; for ( i = 0 ; i < h ; i + + ) { blockv = vec_ld ( 0 , block ) ; temp1 = vec_ld ( line_size , pixels ) ; temp2 = vec_ld ( line_size + 16 , pixels ) ; pixelsv1 = vec_perm ( temp1 , temp2 , vec_lvsl ( line_size , pixels ) ) ; if ( ( ( ( ( unsigned long ) pixels ) + line_size ) & 0x0000000F ) == 0x0000000F ) { pixelsv2 = temp2 ; } else { pixelsv2 = vec_perm ( temp1 , temp2 , vec_lvsl ( line_size + 1 , pixels ) ) ; } pixelsv3 = vec_mergel ( vczero , pixelsv1 ) ; pixelsv4 = vec_mergel ( vczero , pixelsv2 ) ; pixelsv1 = vec_mergeh ( vczero , pixelsv1 ) ; pixelsv2 = vec_mergeh ( vczero , pixelsv2 ) ; pixelssum4 = vec_add ( ( vector unsigned short ) pixelsv3 , ( vector unsigned short ) pixelsv4 ) ; pixelssum2 = vec_add ( ( vector unsigned short ) pixelsv1 , ( vector unsigned short ) pixelsv2 ) ; temp4 = vec_add ( pixelssum3 , pixelssum4 ) ; temp4 = vec_sra ( temp4 , vctwo ) ; temp3 = vec_add ( pixelssum1 , pixelssum2 ) ; temp3 = vec_sra ( temp3 , vctwo ) ; pixelssum3 = vec_add ( pixelssum4 , vcone ) ; pixelssum1 = vec_add ( pixelssum2 , vcone ) ; blockv = vec_packsu ( temp3 , temp4 ) ; vec_st ( blockv , 0 , block ) ; block + = line_size ; pixels + = line_size ; } POWERPC_TBL_STOP_COUNT ( altivec_put_no_rnd_pixels16_xy2_num , 1 ) ; endif / * ALTIVEC_USE_REFERENCE_C_CODE * / }",0
"static inline void rv34_mc ( RV34DecContext * r , const int block_type , const int xoff , const int yoff , int mv_off , const int width , const int height , int dir , const int thirdpel , int weighted , qpel_mc_func ( * qpel_mc ) [16] , h264_chroma_mc_func ( * chroma_mc ) ) { MpegEncContext * s = & r - > s ; uint8_t * Y , * U , * V , * srcY , * srcU , * srcV ; int dxy , mx , my , umx , umy , lx , ly , uvmx , uvmy , src_x , src_y , uvsrc_x , uvsrc_y ; int mv_pos = s - > mb_x * 2 + s - > mb_y * 2 * s - > b8_stride + mv_off ; int is16x16 = 1 ; if ( thirdpel ) { int chroma_mx , chroma_my ; mx = ( s - > current_picture_ptr - > f . motion_val[dir][mv_pos][0] + ( 3 < < 24 ) ) / 3 - ( 1 < < 24 ) ; my = ( s - > current_picture_ptr - > f . motion_val[dir][mv_pos][1] + ( 3 < < 24 ) ) / 3 - ( 1 < < 24 ) ; lx = ( s - > current_picture_ptr - > f . motion_val[dir][mv_pos][0] + ( 3 < < 24 ) ) % 3 ; ly = ( s - > current_picture_ptr - > f . motion_val[dir][mv_pos][1] + ( 3 < < 24 ) ) % 3 ; chroma_mx = s - > current_picture_ptr - > f . motion_val[dir][mv_pos][0] / 2 ; chroma_my = s - > current_picture_ptr - > f . motion_val[dir][mv_pos][1] / 2 ; umx = ( chroma_mx + ( 3 < < 24 ) ) / 3 - ( 1 < < 24 ) ; umy = ( chroma_my + ( 3 < < 24 ) ) / 3 - ( 1 < < 24 ) ; uvmx = chroma_coeffs[ ( chroma_mx + ( 3 < < 24 ) ) % 3] ; uvmy = chroma_coeffs[ ( chroma_my + ( 3 < < 24 ) ) % 3] ; } else { int cx , cy ; mx = s - > current_picture_ptr - > f . motion_val[dir][mv_pos][0] > > 2 ; my = s - > current_picture_ptr - > f . motion_val[dir][mv_pos][1] > > 2 ; lx = s - > current_picture_ptr - > f . motion_val[dir][mv_pos][0] & 3 ; ly = s - > current_picture_ptr - > f . motion_val[dir][mv_pos][1] & 3 ; cx = s - > current_picture_ptr - > f . motion_val[dir][mv_pos][0] / 2 ; cy = s - > current_picture_ptr - > f . motion_val[dir][mv_pos][1] / 2 ; umx = cx > > 2 ; umy = cy > > 2 ; uvmx = ( cx & 3 ) < < 1 ; uvmy = ( cy & 3 ) < < 1 ; //due to some flaw RV40 uses the same MC compensation routine for H2V2 and H3V3 if ( uvmx == 6 & & uvmy == 6 ) uvmx = uvmy = 4 ; } if ( HAVE_THREADS & & ( s - > avctx - > active_thread_type & FF_THREAD_FRAME ) ) { / * wait for the referenced mb row to be finished * / int mb_row = FFMIN ( s - > mb_height - 1 , s - > mb_y + ( ( yoff + my + 21 ) > > 4 ) ) ; AVFrame * f = dir ? & s - > next_picture_ptr - > f : & s - > last_picture_ptr - > f ; ff_thread_await_progress ( f , mb_row , 0 ) ; } dxy = ly * 4 + lx ; srcY = dir ? s - > next_picture_ptr - > f . data[0] : s - > last_picture_ptr - > f . data[0] ; srcU = dir ? s - > next_picture_ptr - > f . data[1] : s - > last_picture_ptr - > f . data[1] ; srcV = dir ? s - > next_picture_ptr - > f . data[2] : s - > last_picture_ptr - > f . data[2] ; src_x = s - > mb_x * 16 + xoff + mx ; src_y = s - > mb_y * 16 + yoff + my ; uvsrc_x = s - > mb_x * 8 + ( xoff > > 1 ) + umx ; uvsrc_y = s - > mb_y * 8 + ( yoff > > 1 ) + umy ; srcY + = src_y * s - > linesize + src_x ; srcU + = uvsrc_y * s - > uvlinesize + uvsrc_x ; srcV + = uvsrc_y * s - > uvlinesize + uvsrc_x ; if ( s - > h_edge_pos - ( width < < 3 ) < 6 || s - > v_edge_pos - ( height < < 3 ) < 6 || ( unsigned ) ( src_x - ! ! lx * 2 ) > s - > h_edge_pos - ! ! lx * 2 - ( width < < 3 ) - 4 || ( unsigned ) ( src_y - ! ! ly * 2 ) > s - > v_edge_pos - ! ! ly * 2 - ( height < < 3 ) - 4 ) { uint8_t * uvbuf = s - > edge_emu_buffer + 22 * s - > linesize ; srcY - = 2 + 2 * s - > linesize ; s - > dsp . emulated_edge_mc ( s - > edge_emu_buffer , srcY , s - > linesize , ( width < < 3 ) + 6 , ( height < < 3 ) + 6 , src_x - 2 , src_y - 2 , s - > h_edge_pos , s - > v_edge_pos ) ; srcY = s - > edge_emu_buffer + 2 + 2 * s - > linesize ; s - > dsp . emulated_edge_mc ( uvbuf , srcU , s - > uvlinesize , ( width < < 2 ) + 1 , ( height < < 2 ) + 1 , uvsrc_x , uvsrc_y , s - > h_edge_pos > > 1 , s - > v_edge_pos > > 1 ) ; s - > dsp . emulated_edge_mc ( uvbuf + 16 , srcV , s - > uvlinesize , ( width < < 2 ) + 1 , ( height < < 2 ) + 1 , uvsrc_x , uvsrc_y , s - > h_edge_pos > > 1 , s - > v_edge_pos > > 1 ) ; srcU = uvbuf ; srcV = uvbuf + 16 ; } if ( ! weighted ) { Y = s - > dest[0] + xoff + yoff * s - > linesize ; U = s - > dest[1] + ( xoff > > 1 ) + ( yoff > > 1 ) * s - > uvlinesize ; V = s - > dest[2] + ( xoff > > 1 ) + ( yoff > > 1 ) * s - > uvlinesize ; } else { Y = r - >",0
"static int ftp_retrieve ( FTPContext * s ) { char command[CONTROL_BUFFER_SIZE] ; const int retr_codes[] = { 150 , 550 , 0 } ; / * 550 is incorrect code * / snprintf ( command , sizeof ( command ) , RETR %s\r\n , s - > path ) ; if ( ftp_send_command ( s , command , retr_codes , NULL ) ! = 150 ) return AVERROR ( EIO ) ; s - > state = DOWNLOADING ; return 0 ; }",0
"void dct_unquantize_h263_altivec ( MpegEncContext * s , DCTELEM * block , int n , int qscale ) { POWERPC_TBL_DECLARE ( altivec_dct_unquantize_h263_num , 1 ) ; int i , level , qmul , qadd ; int nCoeffs ; assert ( s - > block_last_index[n] > =0 ) ; POWERPC_TBL_START_COUNT ( altivec_dct_unquantize_h263_num , 1 ) ; qadd = ( qscale - 1 ) | 1 ; qmul = qscale < < 1 ; if ( s - > mb_intra ) { if ( ! s - > h263_aic ) { if ( n < 4 ) block[0] = block[0] * s - > y_dc_scale ; else block[0] = block[0] * s - > c_dc_scale ; } else qadd = 0 ; i = 1 ; nCoeffs= 63 ; //does not allways use zigzag table } else { i = 0 ; nCoeffs= s - > intra_scantable . raster_end[ s - > block_last_index[n] ] ; } ifdef ALTIVEC_USE_REFERENCE_C_CODE for ( ; i < =nCoeffs ; i + + ) { level = block[i] ; if ( level ) { if ( level < 0 ) { level = level * qmul - qadd ; } else { level = level * qmul + qadd ; } block[i] = level ; } } else / * ALTIVEC_USE_REFERENCE_C_CODE * / { register const vector short vczero = ( const vector short ) vec_splat_s16 ( 0 ) ; short __attribute__ ( ( aligned ( 16 ) ) ) qmul8[] = { qmul , qmul , qmul , qmul , qmul , qmul , qmul , qmul } ; short __attribute__ ( ( aligned ( 16 ) ) ) qadd8[] = { qadd , qadd , qadd , qadd , qadd , qadd , qadd , qadd } ; short __attribute__ ( ( aligned ( 16 ) ) ) nqadd8[] = { - qadd , - qadd , - qadd , - qadd , - qadd , - qadd , - qadd , - qadd } ; register vector short blockv , qmulv , qaddv , nqaddv , temp1 ; register vector bool short blockv_null , blockv_neg ; register short backup_0 = block[0] ; register int j = 0 ; qmulv = vec_ld ( 0 , qmul8 ) ; qaddv = vec_ld ( 0 , qadd8 ) ; nqaddv = vec_ld ( 0 , nqadd8 ) ; if 0 // block * is * 16 bytes - aligned , it seems . // first make sure block[j] is 16 bytes - aligned for ( j = 0 ; ( j < = nCoeffs ) & & ( ( ( ( unsigned long ) block ) + ( j < < 1 ) ) & 0x0000000F ) ; j + + ) { level = block[j] ; if ( level ) { if ( level < 0 ) { level = level * qmul - qadd ; } else { level = level * qmul + qadd ; } block[j] = level ; } } endif // vectorize all the 16 bytes - aligned blocks // of 8 elements for ( ; ( j + 7 ) < = nCoeffs ; j + =8 ) { blockv = vec_ld ( j < < 1 , block ) ; blockv_neg = vec_cmplt ( blockv , vczero ) ; blockv_null = vec_cmpeq ( blockv , vczero ) ; // choose between + qadd or - qadd as the third operand temp1 = vec_sel ( qaddv , nqaddv , blockv_neg ) ; // multiply & add ( block { i , i + 7 } * qmul [ + - ] qadd ) temp1 = vec_mladd ( blockv , qmulv , temp1 ) ; // put 0 where block[ { i , i + 7 } used to have 0 blockv = vec_sel ( temp1 , blockv , blockv_null ) ; vec_st ( blockv , j < < 1 , block ) ; } // if nCoeffs isn ' t a multiple of 8 , finish the job // using good old scalar units . // ( we could do it using a truncated vector , // but I ' m not sure it ' s worth the hassle ) for ( ; j < = nCoeffs ; j + + ) { level = block[j] ; if ( level ) { if ( level < 0 ) { level = level * qmul - qadd ; } else { level = level * qmul + qadd ; } block[j] = level ; } } if ( i == 1 ) { // cheat . this avoid special - casing the first iteration block[0] = backup_0 ; } } endif / * ALTIVEC_USE_REFERENCE_C_CODE * / POWERPC_TBL_STOP_COUNT ( altivec_dct_unquantize_h263_num , nCoeffs == 63 ) ; }",0
"static int dxva2_get_buffer ( AVCodecContext * s , AVFrame * frame , int flags ) { InputStream * ist = s - > opaque ; DXVA2Context * ctx = ist - > hwaccel_ctx ; return av_hwframe_get_buffer ( ctx - > hw_frames_ctx , frame , 0 ) ; }",0
"DECL_IMDCT_BLOCKS ( sse , sse ) DECL_IMDCT_BLOCKS ( sse2 , sse ) DECL_IMDCT_BLOCKS ( sse3 , sse ) DECL_IMDCT_BLOCKS ( ssse3 , sse ) DECL_IMDCT_BLOCKS ( avx , avx ) endif / * HAVE_YASM * / void ff_mpadsp_init_mmx ( MPADSPContext * s ) { int mm_flags = av_get_cpu_flags ( ) ; int i , j ; for ( j = 0 ; j < 4 ; j + + ) { for ( i = 0 ; i < 40 ; i + + ) { mdct_win_sse[0][j][4 * i ] = ff_mdct_win_float[j ][i] ; mdct_win_sse[0][j][4 * i + 1] = ff_mdct_win_float[j + 4][i] ; mdct_win_sse[0][j][4 * i + 2] = ff_mdct_win_float[j ][i] ; mdct_win_sse[0][j][4 * i + 3] = ff_mdct_win_float[j + 4][i] ; mdct_win_sse[1][j][4 * i ] = ff_mdct_win_float[0 ][i] ; mdct_win_sse[1][j][4 * i + 1] = ff_mdct_win_float[4 ][i] ; mdct_win_sse[1][j][4 * i + 2] = ff_mdct_win_float[j ][i] ; mdct_win_sse[1][j][4 * i + 3] = ff_mdct_win_float[j + 4][i] ; } } if HAVE_SSE2_INLINE if ( mm_flags & AV_CPU_FLAG_SSE2 ) { s - > apply_window_float = apply_window_mp3 ; } endif / * HAVE_SSE2_INLINE * / if HAVE_YASM if ( mm_flags & AV_CPU_FLAG_AVX & & HAVE_AVX ) { s - > imdct36_blocks_float = imdct36_blocks_avx ; if HAVE_SSE } else if ( mm_flags & AV_CPU_FLAG_SSSE3 ) { s - > imdct36_blocks_float = imdct36_blocks_ssse3 ; } else if ( mm_flags & AV_CPU_FLAG_SSE3 ) { s - > imdct36_blocks_float = imdct36_blocks_sse3 ; } else if ( mm_flags & AV_CPU_FLAG_SSE2 ) { s - > imdct36_blocks_float = imdct36_blocks_sse2 ; } else if ( mm_flags & AV_CPU_FLAG_SSE ) { s - > imdct36_blocks_float = imdct36_blocks_sse ; endif / * HAVE_SSE * / } endif / * HAVE_YASM * / }",0
"static inline int sub_left_prediction ( HYuvContext * s , uint8_t * dst , const uint8_t * src , int w , int left ) { int i ; if ( s - > bps < = 8 ) { if ( w < 32 ) { for ( i = 0 ; i < w ; i + + ) { const int temp = src[i] ; dst[i] = temp - left ; left = temp ; } return left ; } else { for ( i = 0 ; i < 32 ; i + + ) { const int temp = src[i] ; dst[i] = temp - left ; left = temp ; } s - > llvidencdsp . diff_bytes ( dst + 32 , src + 32 , src + 31 , w - 32 ) ; return src[w - 1] ; } } else { const uint16_t * src16 = ( const uint16_t * ) src ; uint16_t * dst16 = ( uint16_t * ) dst ; if ( w < 32 ) { for ( i = 0 ; i < w ; i + + ) { const int temp = src16[i] ; dst16[i] = temp - left ; left = temp ; } return left ; } else { for ( i = 0 ; i < 16 ; i + + ) { const int temp = src16[i] ; dst16[i] = temp - left ; left = temp ; } s - > hencdsp . diff_int16 ( dst16 + 16 , src16 + 16 , src16 + 15 , s - > n - 1 , w - 16 ) ; return src16[w - 1] ; } } }",0
"int ffurl_register_protocol ( URLProtocol * protocol , int size ) { URLProtocol * * p ; if ( size < sizeof ( URLProtocol ) ) { URLProtocol * temp = av_mallocz ( sizeof ( URLProtocol ) ) ; memcpy ( temp , protocol , size ) ; protocol = temp ; } p = & first_protocol ; while ( * p ! = NULL ) p = & ( * p ) - > next ; * p = protocol ; protocol - > next = NULL ; return 0 ; }",1
"static void rv34_idct_add_c ( uint8_t * dst , int stride , DCTELEM * block ) { int temp[16] ; uint8_t * cm = ff_cropTbl + MAX_NEG_CROP ; int i ; rv34_row_transform ( temp , block ) ; memset ( block , 0 , 16 * sizeof ( DCTELEM ) ) ; for ( i = 0 ; i < 4 ; i + + ) { const int z0 = 13 * ( temp[4 * 0 + i] + temp[4 * 2 + i] ) + 0x200 ; const int z1 = 13 * ( temp[4 * 0 + i] - temp[4 * 2 + i] ) + 0x200 ; const int z2 = 7 * temp[4 * 1 + i] - 17 * temp[4 * 3 + i] ; const int z3 = 17 * temp[4 * 1 + i] + 7 * temp[4 * 3 + i] ; dst[0] = cm[ dst[0] + ( ( z0 + z3 ) > > 10 ) ] ; dst[1] = cm[ dst[1] + ( ( z1 + z2 ) > > 10 ) ] ; dst[2] = cm[ dst[2] + ( ( z1 - z2 ) > > 10 ) ] ; dst[3] = cm[ dst[3] + ( ( z0 - z3 ) > > 10 ) ] ; dst + = stride ; } }",1
"int av_reallocp ( void * ptr , size_t size ) { void * * ptrptr = ptr ; void * ret ; ret = av_realloc ( * ptrptr , size ) ; if ( ! ret ) { return AVERROR ( ENOMEM ) ; * ptrptr = ret ;",1
"static int alac_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame_ptr , AVPacket * avpkt ) { const uint8_t * inbuffer = avpkt - > data ; int input_buffer_size = avpkt - > size ; ALACContext * alac = avctx - > priv_data ; int channels ; unsigned int outputsamples ; int hassize ; unsigned int readsamplesize ; int isnotcompressed ; uint8_t interlacing_shift ; uint8_t interlacing_leftweight ; int i , ch , ret ; init_get_bits ( & alac - > gb , inbuffer , input_buffer_size * 8 ) ; channels = get_bits ( & alac - > gb , 3 ) + 1 ; if ( channels ! = avctx - > channels ) { av_log ( avctx , AV_LOG_ERROR , frame header channel count mismatch\n ) ; return AVERROR_INVALIDDATA ; } / * 2 result = something to do with output waiting . * perhaps matters if we read > 1 frame in a pass ? * / skip_bits ( & alac - > gb , 4 ) ; skip_bits ( & alac - > gb , 12 ) ; / * unknown , skip 12 bits * / / * the output sample size is stored soon * / hassize = get_bits1 ( & alac - > gb ) ; alac - > extra_bits = get_bits ( & alac - > gb , 2 ) < < 3 ; / * whether the frame is compressed * / isnotcompressed = get_bits1 ( & alac - > gb ) ; if ( hassize ) { / * now read the number of samples as a 32bit integer * / outputsamples = get_bits_long ( & alac - > gb , 32 ) ; if ( outputsamples > alac - > setinfo_max_samples_per_frame ) { av_log ( avctx , AV_LOG_ERROR , outputsamples %d > %d\n , outputsamples , alac - > setinfo_max_samples_per_frame ) ; return - 1 ; } } else outputsamples = alac - > setinfo_max_samples_per_frame ; / * get output buffer * / if ( outputsamples > INT32_MAX ) { av_log ( avctx , AV_LOG_ERROR , unsupported block size : %u\n , outputsamples ) ; return AVERROR_INVALIDDATA ; } alac - > frame . nb_samples = outputsamples ; if ( ( ret = avctx - > get_buffer ( avctx , & alac - > frame ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed\n ) ; return ret ; } readsamplesize = alac - > setinfo_sample_size - alac - > extra_bits + channels - 1 ; if ( readsamplesize > MIN_CACHE_BITS ) { av_log ( avctx , AV_LOG_ERROR , readsamplesize too big ( %d ) \n , readsamplesize ) ; return - 1 ; } if ( ! isnotcompressed ) { / * so it is compressed * / int16_t predictor_coef_table[MAX_CHANNELS][32] ; int predictor_coef_num[MAX_CHANNELS] ; int prediction_type[MAX_CHANNELS] ; int prediction_quantitization[MAX_CHANNELS] ; int ricemodifier[MAX_CHANNELS] ; interlacing_shift = get_bits ( & alac - > gb , 8 ) ; interlacing_leftweight = get_bits ( & alac - > gb , 8 ) ; for ( ch = 0 ; ch < channels ; ch + + ) { prediction_type[ch] = get_bits ( & alac - > gb , 4 ) ; prediction_quantitization[ch] = get_bits ( & alac - > gb , 4 ) ; ricemodifier[ch] = get_bits ( & alac - > gb , 3 ) ; predictor_coef_num[ch] = get_bits ( & alac - > gb , 5 ) ; / * read the predictor table * / for ( i = 0 ; i < predictor_coef_num[ch] ; i + + ) predictor_coef_table[ch][i] = ( int16_t ) get_bits ( & alac - > gb , 16 ) ; } if ( alac - > extra_bits ) { for ( i = 0 ; i < outputsamples ; i + + ) { for ( ch = 0 ; ch < channels ; ch + + ) alac - > extra_bits_buffer[ch][i] = get_bits ( & alac - > gb , alac - > extra_bits ) ; } } for ( ch = 0 ; ch < channels ; ch + + ) { bastardized_rice_decompress ( alac , alac - > predicterror_buffer[ch] , outputsamples , readsamplesize , alac - > setinfo_rice_initialhistory , alac - > setinfo_rice_kmodifier , ricemodifier[ch] * alac - > setinfo_rice_historymult / 4 , ( 1 < < alac - > setinfo_rice_kmodifier ) - 1 ) ; if ( prediction_type[ch] == 0 ) { / * adaptive fir * / predictor_decompress_fir_adapt ( alac - > predicterror_buffer[ch] , alac - > outputsamples_buffer[ch] , outputsamples , readsamplesize , predictor_coef_table[ch] , predictor_coef_num[ch] , prediction_quantitization[ch] ) ; } else { av_log ( avctx , AV_LOG_ERROR , FIXME : unhandled prediction type : %i\n , prediction_type[ch] ) ; / * I think the only other prediction type ( or perhaps this is * just a boolean ? ) runs adaptive fir twice . . like : * predictor_decompress_fir_adapt ( predictor_error , tempout , . . . ) * predictor_decompress_fir_adapt ( predictor_error , outputsamples . . . ) * little strange . . * / } } } else { / * not compressed , easy case * / for ( i = 0 ; i < outputsamples ; i + + ) { for ( ch = 0 ; ch < channels ; ch + + ) { alac - > outputsamples_buffer[ch][i] = get_sbits_long ( & alac - > gb , alac - > setinfo_sample_size ) ; } } alac - > extra_bits = 0 ; interlacing_shift = 0 ; interlacing_leftweight = 0 ; } if ( get_bits ( & alac - > gb , 3 ) ! = 7 ) av_log ( avctx , AV_LOG_ERROR , Error : Wrong End Of Frame\n ) ; if ( channels == 2 & & interlacing_leftweight ) { decorrelate_stereo ( alac - > outputsamples_buffer , outputsamples , interlacing_shift , interlacing_leftweight ) ; } if ( alac - > extra_bits ) { append_extra_bits ( alac - > outputsamples_buffer , alac - > extra_bits_buffer , alac - > extra_bits , alac - > numchannels , outputsamples ) ; } switch ( alac - > setinfo_sample_size ) { case 16 : if ( channels == 2 ) { interleave_stereo_16 ( alac - > outputsamples_buffer , ( int16_t * ) alac - > frame . data[0] , outputsamples ) ; } else { int16_t * outbuffer = ( int16_t * ) alac - > frame . data[0] ; for ( i = 0 ; i < outputsamples ; i + + ) { outbuffer[i] = alac - > outputsamples_buffer[0][i] ; } } break ; case 24 : if ( channels == 2 ) { interleave_stereo_24 ( alac - > outputsamples_buffer , ( int32_t * ) alac - > frame . data[0] , outputsamples ) ; } else { int32_t * outbuffer = ( int32_t * ) alac - > frame . data[0] ; for ( i = 0 ; i < outputsamples ; i + + ) outbuffer[i] = alac - > outputsamples_buffer[0][i] < < 8 ; } break ; } if ( input_buffer_size * 8 - get_bits_count ( & alac - > gb ) > 8 ) av_log ( avctx , AV_LOG_ERROR ,",1
static int avi_probe ( AVProbeData * p ) { / * check file header * / if ( p - > buf_size < = 32 ) return 0 ; if ( p - > buf[0] == ' R ' & & p - > buf[1] == ' I ' & & p - > buf[2] == ' F ' & & p - > buf[3] == ' F ' & & p - > buf[8] == ' A ' & & p - > buf[9] == ' V ' & & p - > buf[10] == ' I ' & & ( p - > buf[11] == ' ' || p - > buf[11] == 0x19 ) ) return AVPROBE_SCORE_MAX ; else return 0 ; },0
"static int decode_user_data ( MpegEncContext * s , GetBitContext * gb ) { char buf[256] ; int i ; int e ; int ver = 0 , build = 0 , ver2 = 0 , ver3 = 0 ; char last ; for ( i=0 ; i < 255 & & get_bits_count ( gb ) < gb - > size_in_bits ; i + + ) { if ( show_bits ( gb , 23 ) == 0 ) break ; buf[i]= get_bits ( gb , 8 ) ; } buf[i]=0 ; / * divx detection * / e=sscanf ( buf , DivX%dBuild%d%c , & ver , & build , & last ) ; if ( e < 2 ) e=sscanf ( buf , DivX%db%d%c , & ver , & build , & last ) ; if ( e > =2 ) { s - > divx_version= ver ; s - > divx_build= build ; s - > divx_packed= e==3 & & last== ' p ' ; if ( s - > divx_packed ) av_log ( s - > avctx , AV_LOG_WARNING , Invalid and inefficient vfw - avi packed B frames detected\n ) ; } / * ffmpeg detection * / e=sscanf ( buf , FFmpe% * [ b]b%d , & build ) + 3 ; if ( e ! =4 ) e=sscanf ( buf , FFmpeg v%d . %d . %d / libavcodec build : %d , & ver , & ver2 , & ver3 , & build ) ; if ( e ! =4 ) { e=sscanf ( buf , Lavc%d . %d . %d , & ver , & ver2 , & ver3 ) + 1 ; if ( e > 1 ) build= ( ver < < 16 ) + ( ver2 < < 8 ) + ver3 ; } if ( e ! =4 ) { if ( strcmp ( buf , ffmpeg ) ==0 ) { s - > lavc_build= 4600 ; } } if ( e==4 ) { s - > lavc_build= build ; } / * Xvid detection * / e=sscanf ( buf , XviD%d , & build ) ; if ( e==1 ) { s - > xvid_build= build ; } //printf ( User Data : %s\n , buf ) ; return 0 ; }",0
"static void RENAME ( yuv2yuv1_ar ) ( SwsContext * c , const int16_t * lumSrc , const int16_t * chrUSrc , const int16_t * chrVSrc , const int16_t * alpSrc , uint8_t * dest , uint8_t * uDest , uint8_t * vDest , uint8_t * aDest , int dstW , int chrDstW ) { int p= 4 ; const int16_t * src[4]= { alpSrc + dstW , lumSrc + dstW , chrUSrc + chrDstW , chrVSrc + chrDstW } ; uint8_t * dst[4]= { aDest , dest , uDest , vDest } ; x86_reg counter[4]= { dstW , dstW , chrDstW , chrDstW } ; while ( p - - ) { if ( dst[p] ) { __asm__ volatile ( mov %2 , %% REG_a \n\t pcmpeqw %%mm7 , %%mm7 \n\t psrlw 15 , %%mm7 \n\t psllw 6 , %%mm7 \n\t . p2align 4 \n\t / * FIXME Unroll ? * / 1 : \n\t movq ( %0 , %% REG_a , 2 ) , %%mm0 \n\t movq 8 ( %0 , %% REG_a , 2 ) , %%mm1 \n\t paddsw %%mm7 , %%mm0 \n\t paddsw %%mm7 , %%mm1 \n\t psraw 7 , %%mm0 \n\t psraw 7 , %%mm1 \n\t packuswb %%mm1 , %%mm0 \n\t MOVNTQ ( %%mm0 , ( %1 , %%REGa ) ) add 8 , %% REG_a \n\t jnc 1b \n\t : : r ( src[p] ) , r ( dst[p] + counter[p] ) , g ( - counter[p] ) : % REG_a ) ; } } }",0
"static int nvdec_h264_decode_init ( AVCodecContext * avctx ) { const H264Context * h = avctx - > priv_data ; const SPS * sps = h - > ps . sps ; return ff_nvdec_decode_init ( avctx , sps - > ref_frame_count + sps - > num_reorder_frames ) ; }",0
"void ff_h264_idct8_add_c ( uint8_t * dst , DCTELEM * block , int stride ) { int i ; uint8_t * cm = ff_cropTbl + MAX_NEG_CROP ; block[0] + = 32 ; for ( i = 0 ; i < 8 ; i + + ) { const int a0 = block[0 + i * 8] + block[4 + i * 8] ; const int a2 = block[0 + i * 8] - block[4 + i * 8] ; const int a4 = ( block[2 + i * 8] > > 1 ) - block[6 + i * 8] ; const int a6 = ( block[6 + i * 8] > > 1 ) + block[2 + i * 8] ; const int b0 = a0 + a6 ; const int b2 = a2 + a4 ; const int b4 = a2 - a4 ; const int b6 = a0 - a6 ; const int a1 = - block[3 + i * 8] + block[5 + i * 8] - block[7 + i * 8] - ( block[7 + i * 8] > > 1 ) ; const int a3 = block[1 + i * 8] + block[7 + i * 8] - block[3 + i * 8] - ( block[3 + i * 8] > > 1 ) ; const int a5 = - block[1 + i * 8] + block[7 + i * 8] + block[5 + i * 8] + ( block[5 + i * 8] > > 1 ) ; const int a7 = block[3 + i * 8] + block[5 + i * 8] + block[1 + i * 8] + ( block[1 + i * 8] > > 1 ) ; const int b1 = ( a7 > > 2 ) + a1 ; const int b3 = a3 + ( a5 > > 2 ) ; const int b5 = ( a3 > > 2 ) - a5 ; const int b7 = a7 - ( a1 > > 2 ) ; block[0 + i * 8] = b0 + b7 ; block[7 + i * 8] = b0 - b7 ; block[1 + i * 8] = b2 + b5 ; block[6 + i * 8] = b2 - b5 ; block[2 + i * 8] = b4 + b3 ; block[5 + i * 8] = b4 - b3 ; block[3 + i * 8] = b6 + b1 ; block[4 + i * 8] = b6 - b1 ; } for ( i = 0 ; i < 8 ; i + + ) { const int a0 = block[i + 0 * 8] + block[i + 4 * 8] ; const int a2 = block[i + 0 * 8] - block[i + 4 * 8] ; const int a4 = ( block[i + 2 * 8] > > 1 ) - block[i + 6 * 8] ; const int a6 = ( block[i + 6 * 8] > > 1 ) + block[i + 2 * 8] ; const int b0 = a0 + a6 ; const int b2 = a2 + a4 ; const int b4 = a2 - a4 ; const int b6 = a0 - a6 ; const int a1 = - block[i + 3 * 8] + block[i + 5 * 8] - block[i + 7 * 8] - ( block[i + 7 * 8] > > 1 ) ; const int a3 = block[i + 1 * 8] + block[i + 7 * 8] - block[i + 3 * 8] - ( block[i + 3 * 8] > > 1 ) ; const int a5 = - block[i + 1 * 8] + block[i + 7 * 8] + block[i + 5 * 8] + ( block[i + 5 * 8] > > 1 ) ; const int a7 = block[i + 3 * 8] + block[i + 5 * 8] + block[i + 1 * 8] + ( block[i + 1 * 8] > > 1 ) ; const int b1 = ( a7 > > 2 ) + a1 ; const int b3 = a3 + ( a5 > > 2 ) ; const int b5 = ( a3 > > 2 ) - a5 ; const int b7 = a7 - ( a1 > > 2 ) ; dst[i + 0 * stride] = cm[ dst[i + 0 * stride] + ( ( b0 + b7 ) > > 6 ) ] ; dst[i + 1 * stride] = cm[ dst[i + 1 * stride] + ( ( b2 + b5 ) > > 6 ) ] ; dst[i + 2 * stride] = cm[ dst[i + 2 * stride] + ( ( b4 + b3 ) > > 6 ) ] ; dst[i + 3 * stride] = cm[ dst[i + 3 * stride] + ( ( b6 + b1 ) > > 6 ) ] ; dst[i + 4 * stride] = cm[ dst[i + 4 * stride] + ( ( b6 - b1 ) > > 6 ) ] ; dst[i + 5 * stride] = cm[ dst[i + 5 * stride] + ( ( b4 - b3 ) > > 6 ) ] ; dst[i + 6 * stride] = cm[ dst[i + 6 * stride] + ( ( b2 - b5 ) > > 6 ) ] ; dst[i + 7 * stride] = cm[ dst[i + 7 * stride] + ( ( b0 - b7 ) > > 6 ) ] ; } }",0
"void ff_put_h264_qpel8_mc02_msa ( uint8_t * dst , const uint8_t * src , ptrdiff_t stride ) { avc_luma_vt_8w_msa ( src - ( stride * 2 ) , stride , dst , stride , 8 ) ; }",0
"static int read_pakt_chunk ( AVFormatContext * s , int64_t size ) { AVIOContext * pb = s - > pb ; AVStream * st = s - > streams[0] ; CaffContext * caf = s - > priv_data ; int64_t pos = 0 , ccount ; int num_packets , i ; ccount = avio_tell ( pb ) ; num_packets = avio_rb64 ( pb ) ; if ( num_packets < 0 || INT32_MAX / sizeof ( AVIndexEntry ) < num_packets ) return AVERROR_INVALIDDATA ; st - > nb_frames = avio_rb64 ( pb ) ; / * valid frames * / st - > nb_frames + = avio_rb32 ( pb ) ; / * priming frames * / st - > nb_frames + = avio_rb32 ( pb ) ; / * remainder frames * / st - > duration = 0 ; for ( i = 0 ; i < num_packets ; i + + ) { av_add_index_entry ( s - > streams[0] , pos , st - > duration , 0 , 0 , AVINDEX_KEYFRAME ) ; pos + = caf - > bytes_per_packet ? caf - > bytes_per_packet : ff_mp4_read_descr_len ( pb ) ; st - > duration + = caf - > frames_per_packet ? caf - > frames_per_packet : ff_mp4_read_descr_len ( pb ) ; } if ( avio_tell ( pb ) - ccount ! = size ) { av_log ( s , AV_LOG_ERROR , error reading packet table\n ) ; return - 1 ; } caf - > num_bytes = pos ; return 0 ; }",0
"static void vp8_decode_mb_row_no_filter ( AVCodecContext * avctx , void * tdata , int jobnr , int threadnr ) { decode_mb_row_no_filter ( avctx , tdata , jobnr , threadnr , 0 ) ; }",1
"static void mxf_free_metadataset ( MXFMetadataSet * * ctx , int freectx ) { MXFIndexTableSegment * seg ; switch ( ( * ctx ) - > type ) { case Descriptor : av_freep ( & ( ( MXFDescriptor * ) * ctx ) - > extradata ) ; break ; case MultipleDescriptor : av_freep ( & ( ( MXFDescriptor * ) * ctx ) - > sub_descriptors_refs ) ; break ; case Sequence : av_freep ( & ( ( MXFSequence * ) * ctx ) - > structural_components_refs ) ; break ; case EssenceGroup : av_freep ( & ( ( MXFEssenceGroup * ) * ctx ) - > structural_components_refs ) ; break ; case SourcePackage : case MaterialPackage : av_freep ( & ( ( MXFPackage * ) * ctx ) - > tracks_refs ) ; av_freep ( & ( ( MXFPackage * ) * ctx ) - > name ) ; break ; case TaggedValue : av_freep ( & ( ( MXFTaggedValue * ) * ctx ) - > name ) ; av_freep ( & ( ( MXFTaggedValue * ) * ctx ) - > value ) ; break ; case IndexTableSegment : seg = ( MXFIndexTableSegment * ) * ctx ; av_freep ( & seg - > temporal_offset_entries ) ; av_freep ( & seg - > flag_entries ) ; av_freep ( & seg - > stream_offset_entries ) ; default : break ; } if ( freectx ) av_freep ( ctx ) ; }",1
"static av_cold int qdm2_decode_init ( AVCodecContext * avctx ) { QDM2Context * s = avctx - > priv_data ; uint8_t * extradata ; int extradata_size ; int tmp_val , tmp , size ; / * extradata parsing Structure : wave { frma ( QDM2 ) QDCA QDCP } 32 size ( including this field ) 32 tag ( =frma ) 32 type ( =QDM2 or QDMC ) 32 size ( including this field , in bytes ) 32 tag ( =QDCA ) // maybe mandatory parameters 32 unknown ( =1 ) 32 channels ( =2 ) 32 samplerate ( =44100 ) 32 bitrate ( =96000 ) 32 block size ( =4096 ) 32 frame size ( =256 ) ( for one channel ) 32 packet size ( =1300 ) 32 size ( including this field , in bytes ) 32 tag ( =QDCP ) // maybe some tuneable parameters 32 float1 ( =1 . 0 ) 32 zero ? 32 float2 ( =1 . 0 ) 32 float3 ( =1 . 0 ) 32 unknown ( 27 ) 32 unknown ( 8 ) 32 zero ? * / if ( ! avctx - > extradata || ( avctx - > extradata_size < 48 ) ) { av_log ( avctx , AV_LOG_ERROR , extradata missing or truncated\n ) ; return - 1 ; } extradata = avctx - > extradata ; extradata_size = avctx - > extradata_size ; while ( extradata_size > 7 ) { if ( ! memcmp ( extradata , frmaQDM , 7 ) ) break ; extradata + + ; extradata_size - - ; } if ( extradata_size < 12 ) { av_log ( avctx , AV_LOG_ERROR , not enough extradata ( %i ) \n , extradata_size ) ; return - 1 ; } if ( memcmp ( extradata , frmaQDM , 7 ) ) { av_log ( avctx , AV_LOG_ERROR , invalid headers , QDM ? not found\n ) ; return - 1 ; } if ( extradata[7] == ' C ' ) { // s - > is_qdmc = 1 ; av_log ( avctx , AV_LOG_ERROR , stream is QDMC version 1 , which is not supported\n ) ; return - 1 ; } extradata + = 8 ; extradata_size - = 8 ; size = AV_RB32 ( extradata ) ; if ( size > extradata_size ) { av_log ( avctx , AV_LOG_ERROR , extradata size too small , %i < %i\n , extradata_size , size ) ; return - 1 ; } extradata + = 4 ; av_log ( avctx , AV_LOG_DEBUG , size : %d\n , size ) ; if ( AV_RB32 ( extradata ) ! = MKBETAG ( ' Q ' , ' D ' , ' C ' , ' A ' ) ) { av_log ( avctx , AV_LOG_ERROR , invalid extradata , expecting QDCA\n ) ; return - 1 ; } extradata + = 8 ; avctx - > channels = s - > nb_channels = s - > channels = AV_RB32 ( extradata ) ; extradata + = 4 ; if ( s - > channels > MPA_MAX_CHANNELS ) avctx - > sample_rate = AV_RB32 ( extradata ) ; extradata + = 4 ; avctx - > bit_rate = AV_RB32 ( extradata ) ; extradata + = 4 ; s - > group_size = AV_RB32 ( extradata ) ; extradata + = 4 ; s - > fft_size = AV_RB32 ( extradata ) ; extradata + = 4 ; s - > checksum_size = AV_RB32 ( extradata ) ; s - > fft_order = av_log2 ( s - > fft_size ) + 1 ; s - > fft_frame_size = 2 * s - > fft_size ; // complex has two floats // something like max decodable tones s - > group_order = av_log2 ( s - > group_size ) + 1 ; s - > frame_size = s - > group_size / 16 ; // 16 iterations per super block s - > sub_sampling = s - > fft_order - 7 ; s - > frequency_range = 255 / ( 1 < < ( 2 - s - > sub_sampling ) ) ; switch ( ( s - > sub_sampling * 2 + s - > channels - 1 ) ) { case 0 : tmp = 40 ; break ; case 1 : tmp = 48 ; break ; case 2 : tmp = 56 ; break ; case 3 : tmp = 72 ; break ; case 4 : tmp = 80 ; break ; case 5 : tmp = 100 ; break ; default : tmp=s - > sub_sampling ; break ; } tmp_val = 0 ; if ( ( tmp * 1000 ) < avctx - > bit_rate ) tmp_val = 1 ; if ( ( tmp * 1440 ) < avctx - > bit_rate ) tmp_val = 2 ; if ( ( tmp * 1760 ) < avctx - > bit_rate ) tmp_val = 3 ; if ( ( tmp * 2240 ) < avctx - > bit_rate ) tmp_val = 4 ; s - > cm_table_select = tmp_val ; if ( s - > sub_sampling == 0 ) tmp = 7999 ; else tmp = ( ( - ( s - > sub_sampling - 1 ) ) & 8000 ) + 20000 ; / * 0 : 7999 - > 0 1 : 20000 - > 2 2 : 28000 - > 2 * / if ( tmp < 8000 ) s - > coeff_per_sb_select = 0 ; else if ( tmp < = 16000 ) s - > coeff_per_sb_select = 1 ; else s - > coeff_per_sb_select = 2 ; // Fail on unknown fft order if ( ( s - > fft_order < 7 ) || ( s - > fft_order > 9 ) ) { av_log ( avctx , AV_LOG_ERROR , Unknown FFT order ( %d ) , contact the developers ! \n , s - > fft_order ) ; return - 1 ; } ff_rdft_init ( & s - > rdft_ctx , s - > fft_order , IDFT_C2R ) ; ff_mpadsp_init ( & s - > mpadsp ) ; qdm2_init ( s ) ; avctx - > sample_fmt = AV_SAMPLE_FMT_S16 ; // dump_context ( s ) ; return 0 ; }",1
"static int roq_decode_end ( AVCodecContext * avctx ) { RoqContext * s = avctx - > priv_data ; / * release the last frame * / avctx - > release_buffer ( avctx , & s - > last_frame ) ; return 0 ; }",0
"static int vfw_read_header ( AVFormatContext * s , AVFormatParameters * ap ) { struct vfw_ctx * ctx = s - > priv_data ; AVCodecContext * codec ; AVStream * st ; int devnum ; int bisize ; BITMAPINFO * bi ; CAPTUREPARMS cparms ; DWORD biCompression ; WORD biBitCount ; int width ; int height ; int ret ; if ( ! ap - > time_base . den ) { av_log ( s , AV_LOG_ERROR , A time base must be specified . \n ) ; return AVERROR_IO ; } ctx - > s = s ; ctx - > hwnd = capCreateCaptureWindow ( NULL , 0 , 0 , 0 , 0 , 0 , HWND_MESSAGE , 0 ) ; if ( ! ctx - > hwnd ) { av_log ( s , AV_LOG_ERROR , Could not create capture window . \n ) ; return AVERROR_IO ; } / * If atoi fails , devnum==0 and the default device is used * / devnum = atoi ( s - > filename ) ; ret = SendMessage ( ctx - > hwnd , WM_CAP_DRIVER_CONNECT , devnum , 0 ) ; if ( ! ret ) { av_log ( s , AV_LOG_ERROR , Could not connect to device . \n ) ; DestroyWindow ( ctx - > hwnd ) ; return AVERROR ( ENODEV ) ; } SendMessage ( ctx - > hwnd , WM_CAP_SET_OVERLAY , 0 , 0 ) ; SendMessage ( ctx - > hwnd , WM_CAP_SET_PREVIEW , 0 , 0 ) ; ret = SendMessage ( ctx - > hwnd , WM_CAP_SET_CALLBACK_VIDEOSTREAM , 0 , ( LPARAM ) videostream_cb ) ; if ( ! ret ) { av_log ( s , AV_LOG_ERROR , Could not set video stream callback . \n ) ; goto fail_io ; } SetWindowLongPtr ( ctx - > hwnd , GWLP_USERDATA , ( LONG_PTR ) ctx ) ; st = av_new_stream ( s , 0 ) ; if ( ! st ) { vfw_read_close ( s ) ; return AVERROR_NOMEM ; } / * Set video format * / bisize = SendMessage ( ctx - > hwnd , WM_CAP_GET_VIDEOFORMAT , 0 , 0 ) ; if ( ! bisize ) goto fail_io ; bi = av_malloc ( bisize ) ; if ( ! bi ) { vfw_read_close ( s ) ; return AVERROR_NOMEM ; } ret = SendMessage ( ctx - > hwnd , WM_CAP_GET_VIDEOFORMAT , bisize , ( LPARAM ) bi ) ; if ( ! ret ) goto fail_bi ; dump_bih ( s , & bi - > bmiHeader ) ; width = ap - > width ? ap - > width : bi - > bmiHeader . biWidth ; height = ap - > height ? ap - > height : bi - > bmiHeader . biHeight ; bi - > bmiHeader . biWidth = width ; bi - > bmiHeader . biHeight = height ; if 0 / * For testing yet unsupported compressions * Copy these values from user - supplied verbose information * / bi - > bmiHeader . biWidth = 320 ; bi - > bmiHeader . biHeight = 240 ; bi - > bmiHeader . biPlanes = 1 ; bi - > bmiHeader . biBitCount = 12 ; bi - > bmiHeader . biCompression = MKTAG ( ' I ' , ' 4 ' , ' 2 ' , ' 0 ' ) ; bi - > bmiHeader . biSizeImage = 115200 ; dump_bih ( s , & bi - > bmiHeader ) ; endif ret = SendMessage ( ctx - > hwnd , WM_CAP_SET_VIDEOFORMAT , bisize , ( LPARAM ) bi ) ; if ( ! ret ) { av_log ( s , AV_LOG_ERROR , Could not set Video Format . \n ) ; goto fail_bi ; } biCompression = bi - > bmiHeader . biCompression ; biBitCount = bi - > bmiHeader . biBitCount ; av_free ( bi ) ; / * Set sequence setup * / ret = SendMessage ( ctx - > hwnd , WM_CAP_GET_SEQUENCE_SETUP , sizeof ( cparms ) , ( LPARAM ) & cparms ) ; if ( ! ret ) goto fail_io ; dump_captureparms ( s , & cparms ) ; cparms . fYield = 1 ; // Spawn a background thread cparms . dwRequestMicroSecPerFrame = ( ap - > time_base . num * 1000000 ) / ap - > time_base . den ; cparms . fAbortLeftMouse = 0 ; cparms . fAbortRightMouse = 0 ; cparms . fCaptureAudio = 0 ; cparms . vKeyAbort = 0 ; ret = SendMessage ( ctx - > hwnd , WM_CAP_SET_SEQUENCE_SETUP , sizeof ( cparms ) , ( LPARAM ) & cparms ) ; if ( ! ret ) goto fail_io ; codec = st - > codec ; codec - > time_base = ap - > time_base ; codec - > codec_type = CODEC_TYPE_VIDEO ; codec - > width = width ; codec - > height = height ; codec - > pix_fmt = vfw_pixfmt ( biCompression , biBitCount ) ; if ( codec - > pix_fmt == PIX_FMT_NONE ) { codec - > codec_id = vfw_codecid ( biCompression ) ; if ( codec - > codec_id == CODEC_ID_NONE ) { av_log ( s , AV_LOG_ERROR , Unknown compression type . Please report verbose ( - v 9 ) debug information . \n ) ; vfw_read_close ( s ) ; return AVERROR_PATCHWELCOME ; } codec - > bits_per_coded_sample = biBitCount ; } else { codec - > codec_id = CODEC_ID_RAWVIDEO ; if ( biCompression == BI_RGB ) codec - > bits_per_coded_sample = biBitCount ; } av_set_pts_info ( st , 32 , 1 , 1000 ) ; ctx - > mutex = CreateMutex ( NULL , 0 , NULL ) ; if ( ! ctx - > mutex ) { av_log ( s , AV_LOG_ERROR , Could not create Mutex . \n ) ; goto fail_io ; } ctx - > event = CreateEvent ( NULL , 1 , 0 , NULL ) ; if ( ! ctx - > event ) { av_log ( s , AV_LOG_ERROR , Could not create Event . \n ) ; goto fail_io ; } ret = SendMessage ( ctx - > hwnd , WM_CAP_SEQUENCE_NOFILE , 0 , 0 ) ; if ( ! ret ) { av_log ( s , AV_LOG_ERROR , Could not start capture sequence . \n ) ; goto fail_io ; } return 0 ; fail_bi : av_free ( bi ) ; fail_io : vfw_read_close ( s ) ; return AVERROR_IO ; }",0
"static int lag_decode_arith_plane ( LagarithContext * l , uint8_t * dst , int width , int height , int stride , const uint8_t * src , int src_size ) { int i = 0 ; int read = 0 ; uint32_t length ; uint32_t offset = 1 ; int esc_count ; GetBitContext gb ; lag_rac rac ; const uint8_t * src_end = src + src_size ; rac . avctx = l - > avctx ; l - > zeros = 0 ; if ( src_size < 2 ) return AVERROR_INVALIDDATA ; esc_count = src[0] ; if ( esc_count < 4 ) { length = width * height ; if ( src_size < 5 ) return AVERROR_INVALIDDATA ; if ( esc_count & & AV_RL32 ( src + 1 ) < length ) { length = AV_RL32 ( src + 1 ) ; offset + = 4 ; } init_get_bits8 ( & gb , src + offset , src_size - offset ) ; if ( lag_read_prob_header ( & rac , & gb ) < 0 ) return - 1 ; ff_lag_rac_init ( & rac , & gb , length - stride ) ; for ( i = 0 ; i < height ; i + + ) read + = lag_decode_line ( l , & rac , dst + ( i * stride ) , width , stride , esc_count ) ; if ( read > length ) av_log ( l - > avctx , AV_LOG_WARNING , Output more bytes than length ( %d of %d ) \n , read , length ) ; } else if ( esc_count < 8 ) { esc_count - = 4 ; src + + ; src_size - - ; if ( esc_count > 0 ) { / * Zero run coding only , no range coding . * / for ( i = 0 ; i < height ; i + + ) { int res = lag_decode_zero_run_line ( l , dst + ( i * stride ) , src , src_end , width , esc_count ) ; if ( res < 0 ) return res ; src + = res ; } } else { if ( src_size < width * height ) return AVERROR_INVALIDDATA ; // buffer not big enough / * Plane is stored uncompressed * / for ( i = 0 ; i < height ; i + + ) { memcpy ( dst + ( i * stride ) , src , width ) ; src + = width ; } } } else if ( esc_count == 0xff ) { / * Plane is a solid run of given value * / for ( i = 0 ; i < height ; i + + ) memset ( dst + i * stride , src[1] , width ) ; / * Do not apply prediction . Note : memset to 0 above , setting first value to src[1] and applying prediction gives the same result . * / return 0 ; } else { av_log ( l - > avctx , AV_LOG_ERROR , Invalid zero run escape code ! ( % x ) \n , esc_count ) ; return - 1 ; } if ( l - > avctx - > pix_fmt ! = AV_PIX_FMT_YUV422P ) { for ( i = 0 ; i < height ; i + + ) { lag_pred_line ( l , dst , width , stride , i ) ; dst + = stride ; } } else { for ( i = 0 ; i < height ; i + + ) { lag_pred_line_yuy2 ( l , dst , width , stride , i , width == l - > avctx - > width ) ; dst + = stride ; } } return 0 ; }",0
"static int decode_wmv9 ( AVCodecContext * avctx , const uint8_t * buf , int buf_size , int x , int y , int w , int h , int wmv9_mask ) { MSS2Context * ctx = avctx - > priv_data ; MSS12Context * c = & ctx - > c ; VC1Context * v = avctx - > priv_data ; MpegEncContext * s = & v - > s ; AVFrame * f ; int ret ; ff_mpeg_flush ( avctx ) ; init_get_bits ( & s - > gb , buf , buf_size * 8 ) ; s - > loop_filter = avctx - > skip_loop_filter < AVDISCARD_ALL ; if ( ff_vc1_parse_frame_header ( v , & s - > gb ) < 0 ) { av_log ( v - > s . avctx , AV_LOG_ERROR , header error\n ) ; return AVERROR_INVALIDDATA ; } if ( s - > pict_type ! = AV_PICTURE_TYPE_I ) { av_log ( v - > s . avctx , AV_LOG_ERROR , expected I - frame\n ) ; return AVERROR_INVALIDDATA ; } avctx - > pix_fmt = AV_PIX_FMT_YUV420P ; if ( ( ret = ff_MPV_frame_start ( s , avctx ) ) < 0 ) { av_log ( v - > s . avctx , AV_LOG_ERROR , ff_MPV_frame_start error\n ) ; avctx - > pix_fmt = AV_PIX_FMT_RGB24 ; return ret ; } ff_mpeg_er_frame_start ( s ) ; v - > bits = buf_size * 8 ; v - > end_mb_x = ( w + 15 ) > > 4 ; s - > end_mb_y = ( h + 15 ) > > 4 ; if ( v - > respic & 1 ) v - > end_mb_x = v - > end_mb_x + 1 > > 1 ; if ( v - > respic & 2 ) s - > end_mb_y = s - > end_mb_y + 1 > > 1 ; ff_vc1_decode_blocks ( v ) ; ff_er_frame_end ( & s - > er ) ; ff_MPV_frame_end ( s ) ; f = & s - > current_picture . f ; if ( v - > respic == 3 ) { ctx - > dsp . upsample_plane ( f - > data[0] , f - > linesize[0] , w , h ) ; ctx - > dsp . upsample_plane ( f - > data[1] , f - > linesize[1] , w > > 1 , h > > 1 ) ; ctx - > dsp . upsample_plane ( f - > data[2] , f - > linesize[2] , w > > 1 , h > > 1 ) ; } else if ( v - > respic ) avpriv_request_sample ( v - > s . avctx , Asymmetric WMV9 rectangle subsampling ) ; av_assert0 ( f - > linesize[1] == f - > linesize[2] ) ; if ( wmv9_mask ! = - 1 ) ctx - > dsp . mss2_blit_wmv9_masked ( c - > rgb_pic + y * c - > rgb_stride + x * 3 , c - > rgb_stride , wmv9_mask , c - > pal_pic + y * c - > pal_stride + x , c - > pal_stride , f - > data[0] , f - > linesize[0] , f - > data[1] , f - > data[2] , f - > linesize[1] , w , h ) ; else ctx - > dsp . mss2_blit_wmv9 ( c - > rgb_pic + y * c - > rgb_stride + x * 3 , c - > rgb_stride , f - > data[0] , f - > linesize[0] , f - > data[1] , f - > data[2] , f - > linesize[1] , w , h ) ; avctx - > pix_fmt = AV_PIX_FMT_RGB24 ; return 0 ; }",1
"static void rv40_h_weak_loop_filter ( uint8_t * src , const int stride , const int filter_p1 , const int filter_q1 , const int alpha , const int beta , const int lim_p0q0 , const int lim_q1 , const int lim_p1 ) { rv40_weak_loop_filter ( src , stride , 1 , filter_p1 , filter_q1 , alpha , beta , lim_p0q0 , lim_q1 , lim_p1 ) ; }",1
"yuv2rgb_1_c_template ( SwsContext * c , const int16_t * buf0 , const int16_t * ubuf[2] , const int16_t * vbuf[2] , const int16_t * abuf0 , uint8_t * dest , int dstW , int uvalpha , int y , enum PixelFormat target , int hasAlpha ) { const int16_t * ubuf0 = ubuf[0] , * vbuf0 = vbuf[0] ; int i ; if ( uvalpha < 2048 ) { for ( i = 0 ; i < ( dstW > > 1 ) ; i + + ) { int Y1 = buf0[i * 2] > > 7 ; int Y2 = buf0[i * 2 + 1] > > 7 ; int U = ubuf0[i] > > 7 ; int V = vbuf0[i] > > 7 ; int A1 , A2 ; const void * r = c - > table_rV[V] , * g = ( c - > table_gU[U] + c - > table_gV[V] ) , * b = c - > table_bU[U] ; if ( hasAlpha ) { A1 = abuf0[i * 2 ] > > 7 ; A2 = abuf0[i * 2 + 1] > > 7 ; } yuv2rgb_write ( dest , i , Y1 , Y2 , hasAlpha ? A1 : 0 , hasAlpha ? A2 : 0 , r , g , b , y , target , hasAlpha ) ; } } else { const int16_t * ubuf1 = ubuf[1] , * vbuf1 = vbuf[1] ; for ( i = 0 ; i < ( dstW > > 1 ) ; i + + ) { int Y1 = buf0[i * 2] > > 7 ; int Y2 = buf0[i * 2 + 1] > > 7 ; int U = ( ubuf0[i] + ubuf1[i] ) > > 8 ; int V = ( vbuf0[i] + vbuf1[i] ) > > 8 ; int A1 , A2 ; const void * r = c - > table_rV[V] , * g = ( c - > table_gU[U] + c - > table_gV[V] ) , * b = c - > table_bU[U] ; if ( hasAlpha ) { A1 = abuf0[i * 2 ] > > 7 ; A2 = abuf0[i * 2 + 1] > > 7 ; } yuv2rgb_write ( dest , i , Y1 , Y2 , hasAlpha ? A1 : 0 , hasAlpha ? A2 : 0 , r , g , b , y , target , hasAlpha ) ; } } }",1
"static AVStream * parse_media_type ( AVFormatContext * s , AVStream * st , int sid , ff_asf_guid mediatype , ff_asf_guid subtype , ff_asf_guid formattype , int size ) { WtvContext * wtv = s - > priv_data ; AVIOContext * pb = wtv - > pb ; if ( ! ff_guidcmp ( subtype , ff_mediasubtype_cpfilters_processed ) & & ! ff_guidcmp ( formattype , ff_format_cpfilters_processed ) ) { ff_asf_guid actual_subtype ; ff_asf_guid actual_formattype ; if ( size < 32 ) { av_log ( s , AV_LOG_WARNING , format buffer size underflow\n ) ; avio_skip ( pb , size ) ; return NULL ; } avio_skip ( pb , size - 32 ) ; ff_get_guid ( pb , & actual_subtype ) ; ff_get_guid ( pb , & actual_formattype ) ; avio_seek ( pb , - size , SEEK_CUR ) ; st = parse_media_type ( s , st , sid , mediatype , actual_subtype , actual_formattype , size - 32 ) ; avio_skip ( pb , 32 ) ; return st ; } else if ( ! ff_guidcmp ( mediatype , ff_mediatype_audio ) ) { st = new_stream ( s , st , sid , AVMEDIA_TYPE_AUDIO ) ; if ( ! st ) return NULL ; if ( ! ff_guidcmp ( formattype , ff_format_waveformatex ) ) { int ret = ff_get_wav_header ( pb , st - > codec , size ) ; if ( ret < 0 ) return NULL ; } else { if ( ff_guidcmp ( formattype , ff_format_none ) ) av_log ( s , AV_LOG_WARNING , unknown formattype : FF_PRI_GUID \n , FF_ARG_GUID ( formattype ) ) ; avio_skip ( pb , size ) ; } if ( ! memcmp ( subtype + 4 , ( const uint8_t[] ) { FF_MEDIASUBTYPE_BASE_GUID } , 12 ) ) { st - > codec - > codec_id = ff_wav_codec_get_id ( AV_RL32 ( subtype ) , st - > codec - > bits_per_coded_sample ) ; } else if ( ! ff_guidcmp ( subtype , mediasubtype_mpeg1payload ) ) { if ( st - > codec - > extradata & & st - > codec - > extradata_size > = 22 ) parse_mpeg1waveformatex ( st ) ; else av_log ( s , AV_LOG_WARNING , MPEG1WAVEFORMATEX underflow\n ) ; } else { st - > codec - > codec_id = ff_codec_guid_get_id ( ff_codec_wav_guids , subtype ) ; if ( st - > codec - > codec_id == AV_CODEC_ID_NONE ) av_log ( s , AV_LOG_WARNING , unknown subtype : FF_PRI_GUID \n , FF_ARG_GUID ( subtype ) ) ; } return st ; } else if ( ! ff_guidcmp ( mediatype , ff_mediatype_video ) ) { st = new_stream ( s , st , sid , AVMEDIA_TYPE_VIDEO ) ; if ( ! st ) return NULL ; if ( ! ff_guidcmp ( formattype , ff_format_videoinfo2 ) ) { int consumed = parse_videoinfoheader2 ( s , st ) ; avio_skip ( pb , FFMAX ( size - consumed , 0 ) ) ; } else if ( ! ff_guidcmp ( formattype , ff_format_mpeg2_video ) ) { int consumed = parse_videoinfoheader2 ( s , st ) ; int count ; avio_skip ( pb , 4 ) ; count = avio_rl32 ( pb ) ; avio_skip ( pb , 12 ) ; if ( count & & ff_get_extradata ( st - > codec , pb , count ) < 0 ) { ff_free_stream ( s , st ) ; return NULL ; } consumed + = 20 + count ; avio_skip ( pb , FFMAX ( size - consumed , 0 ) ) ; } else { if ( ff_guidcmp ( formattype , ff_format_none ) ) av_log ( s , AV_LOG_WARNING , unknown formattype : FF_PRI_GUID \n , FF_ARG_GUID ( formattype ) ) ; avio_skip ( pb , size ) ; } if ( ! memcmp ( subtype + 4 , ( const uint8_t[] ) { FF_MEDIASUBTYPE_BASE_GUID } , 12 ) ) { st - > codec - > codec_id = ff_codec_get_id ( ff_codec_bmp_tags , AV_RL32 ( subtype ) ) ; } else { st - > codec - > codec_id = ff_codec_guid_get_id ( ff_video_guids , subtype ) ; } if ( st - > codec - > codec_id == AV_CODEC_ID_NONE ) av_log ( s , AV_LOG_WARNING , unknown subtype : FF_PRI_GUID \n , FF_ARG_GUID ( subtype ) ) ; return st ; } else if ( ! ff_guidcmp ( mediatype , mediatype_mpeg2_pes ) & & ! ff_guidcmp ( subtype , mediasubtype_dvb_subtitle ) ) { st = new_stream ( s , st , sid , AVMEDIA_TYPE_SUBTITLE ) ; if ( ! st ) return NULL ; if ( ff_guidcmp ( formattype , ff_format_none ) ) av_log ( s , AV_LOG_WARNING , unknown formattype : FF_PRI_GUID \n , FF_ARG_GUID ( formattype ) ) ; avio_skip ( pb , size ) ; st - > codec - > codec_id = AV_CODEC_ID_DVB_SUBTITLE ; return st ; } else if ( ! ff_guidcmp ( mediatype , mediatype_mstvcaption ) & & ( ! ff_guidcmp ( subtype , mediasubtype_teletext ) || ! ff_guidcmp ( subtype , mediasubtype_dtvccdata ) ) ) { st = new_stream ( s , st , sid , AVMEDIA_TYPE_SUBTITLE ) ; if ( ! st ) return NULL ; if ( ff_guidcmp ( formattype , ff_format_none ) ) av_log ( s , AV_LOG_WARNING , unknown formattype : FF_PRI_GUID \n , FF_ARG_GUID ( formattype ) ) ; avio_skip ( pb , size ) ; st - > codec - > codec_id = ! ff_guidcmp ( subtype , mediasubtype_teletext ) ? AV_CODEC_ID_DVB_TELETEXT : AV_CODEC_ID_EIA_608 ; return st ; } else if ( ! ff_guidcmp ( mediatype , mediatype_mpeg2_sections ) & & ! ff_guidcmp ( subtype , mediasubtype_mpeg2_sections ) ) { if ( ff_guidcmp ( formattype , ff_format_none ) ) av_log ( s , AV_LOG_WARNING , unknown formattype : FF_PRI_GUID \n , FF_ARG_GUID ( formattype ) ) ; avio_skip ( pb , size ) ; return NULL ; } av_log ( s , AV_LOG_WARNING , unknown media type , mediatype : FF_PRI_GUID , subtype : FF_PRI_GUID , formattype : FF_PRI_GUID \n , FF_ARG_GUID ( mediatype ) , FF_ARG_GUID ( subtype ) , FF_ARG_GUID ( formattype ) ) ; avio_skip ( pb , size ) ; return NULL ; }",0
"static void intra_predict_dc_4blk_8x8_msa ( uint8_t * src , int32_t stride ) { uint8_t lp_cnt ; uint32_t src0 , src1 , src3 , src2 = 0 ; uint32_t out0 , out1 , out2 , out3 ; v16u8 src_top ; v8u16 add ; v4u32 sum ; src_top = LD_UB ( src - stride ) ; add = __msa_hadd_u_h ( ( v16u8 ) src_top , ( v16u8 ) src_top ) ; sum = __msa_hadd_u_w ( add , add ) ; src0 = __msa_copy_u_w ( ( v4i32 ) sum , 0 ) ; src1 = __msa_copy_u_w ( ( v4i32 ) sum , 1 ) ; for ( lp_cnt = 0 ; lp_cnt < 4 ; lp_cnt + + ) { src0 + = src[lp_cnt * stride - 1] ; src2 + = src[ ( 4 + lp_cnt ) * stride - 1] ; } src0 = ( src0 + 4 ) > > 3 ; src3 = ( src1 + src2 + 4 ) > > 3 ; src1 = ( src1 + 2 ) > > 2 ; src2 = ( src2 + 2 ) > > 2 ; out0 = src0 * 0x01010101 ; out1 = src1 * 0x01010101 ; out2 = src2 * 0x01010101 ; out3 = src3 * 0x01010101 ; for ( lp_cnt = 4 ; lp_cnt - - ; ) { SW ( out0 , src ) ; SW ( out1 , ( src + 4 ) ) ; SW ( out2 , ( src + 4 * stride ) ) ; SW ( out3 , ( src + 4 * stride + 4 ) ) ; src + = stride ; } }",0
"static int init_poc ( H264Context * h ) { MpegEncContext * const s = & h - > s ; const int max_frame_num= 1 < < h - > sps . log2_max_frame_num ; int field_poc[2] ; h - > frame_num_offset= h - > prev_frame_num_offset ; if ( h - > frame_num < h - > prev_frame_num ) h - > frame_num_offset + = max_frame_num ; if ( h - > sps . poc_type==0 ) { const int max_poc_lsb= 1 < < h - > sps . log2_max_poc_lsb ; if ( h - > poc_lsb < h - > prev_poc_lsb & & h - > prev_poc_lsb - h - > poc_lsb > = max_poc_lsb/2 ) h - > poc_msb = h - > prev_poc_msb + max_poc_lsb ; else if ( h - > poc_lsb > h - > prev_poc_lsb & & h - > prev_poc_lsb - h - > poc_lsb < - max_poc_lsb/2 ) h - > poc_msb = h - > prev_poc_msb - max_poc_lsb ; else h - > poc_msb = h - > prev_poc_msb ; //printf ( poc : %d %d\n , h - > poc_msb , h - > poc_lsb ) ; field_poc[0] = field_poc[1] = h - > poc_msb + h - > poc_lsb ; if ( s - > picture_structure == PICT_FRAME ) field_poc[1] + = h - > delta_poc_bottom ; } else if ( h - > sps . poc_type==1 ) { int abs_frame_num , expected_delta_per_poc_cycle , expectedpoc ; int i ; if ( h - > sps . poc_cycle_length ! = 0 ) abs_frame_num = h - > frame_num_offset + h - > frame_num ; else abs_frame_num = 0 ; if ( h - > nal_ref_idc==0 & & abs_frame_num > 0 ) abs_frame_num - - ; expected_delta_per_poc_cycle = 0 ; for ( i=0 ; i < h - > sps . poc_cycle_length ; i + + ) expected_delta_per_poc_cycle + = h - > sps . offset_for_ref_frame[ i ] ; //FIXME integrate during sps parse if ( abs_frame_num > 0 ) { int poc_cycle_cnt = ( abs_frame_num - 1 ) / h - > sps . poc_cycle_length ; int frame_num_in_poc_cycle = ( abs_frame_num - 1 ) % h - > sps . poc_cycle_length ; expectedpoc = poc_cycle_cnt * expected_delta_per_poc_cycle ; for ( i = 0 ; i < = frame_num_in_poc_cycle ; i + + ) expectedpoc = expectedpoc + h - > sps . offset_for_ref_frame[ i ] ; } else expectedpoc = 0 ; if ( h - > nal_ref_idc == 0 ) expectedpoc = expectedpoc + h - > sps . offset_for_non_ref_pic ; field_poc[0] = expectedpoc + h - > delta_poc[0] ; field_poc[1] = field_poc[0] + h - > sps . offset_for_top_to_bottom_field ; if ( s - > picture_structure == PICT_FRAME ) field_poc[1] + = h - > delta_poc[1] ; } else { int poc= 2 * ( h - > frame_num_offset + h - > frame_num ) ; if ( ! h - > nal_ref_idc ) poc - - ; field_poc[0]= poc ; field_poc[1]= poc ; } if ( s - > picture_structure ! = PICT_BOTTOM_FIELD ) { s - > current_picture_ptr - > field_poc[0]= field_poc[0] ; s - > current_picture_ptr - > poc = field_poc[0] ; } if ( s - > picture_structure ! = PICT_TOP_FIELD ) { s - > current_picture_ptr - > field_poc[1]= field_poc[1] ; s - > current_picture_ptr - > poc = field_poc[1] ; } if ( ! FIELD_PICTURE || ! s - > first_field ) { Picture * cur = s - > current_picture_ptr ; cur - > poc= FFMIN ( cur - > field_poc[0] , cur - > field_poc[1] ) ; } return 0 ; }",1
"static int avui_encode_frame ( AVCodecContext * avctx , AVPacket * pkt , const AVFrame * pic , int * got_packet ) { uint8_t * dst , * src = pic - > data[0] ; int i , j , skip , ret , size , interlaced ; interlaced = avctx - > field_order > AV_FIELD_PROGRESSIVE ; if ( avctx - > height == 486 ) { skip = 10 ; } else { skip = 16 ; } size = 2 * avctx - > width * ( avctx - > height + skip ) + 8 * interlaced ; if ( ( ret = ff_alloc_packet2 ( avctx , pkt , size ) ) < 0 ) return ret ; dst = pkt - > data ; if ( ! ( avctx - > extradata = av_mallocz ( 24 + FF_INPUT_BUFFER_PADDING_SIZE ) ) ) return AVERROR ( ENOMEM ) ; avctx - > extradata_size = 24 ; memcpy ( avctx - > extradata , \0\0\0\x18 APRGAPRG0001 , 16 ) ; if ( interlaced ) { avctx - > extradata[19] = 2 ; } else { avctx - > extradata[19] = 1 ; dst + = avctx - > width * skip ; } avctx - > coded_frame - > reference = 0 ; avctx - > coded_frame - > key_frame = 1 ; avctx - > coded_frame - > pict_type = AV_PICTURE_TYPE_I ; for ( i = 0 ; i < = interlaced ; i + + ) { if ( interlaced & & avctx - > height == 486 ) { src = pic - > data[0] + ( 1 - i ) * pic - > linesize[0] ; } else { src = pic - > data[0] + i * pic - > linesize[0] ; } dst + = avctx - > width * skip + 4 * i ; for ( j = 0 ; j < avctx - > height ; j + = interlaced + 1 ) { memcpy ( dst , src , avctx - > width * 2 ) ; src + = ( interlaced + 1 ) * pic - > linesize[0] ; dst + = avctx - > width * 2 ; } } pkt - > flags |= AV_PKT_FLAG_KEY ; * got_packet = 1 ; return 0 ; }",1
"static int decode_subframe ( WmallDecodeCtx * s ) { int offset = s - > samples_per_frame ; int subframe_len = s - > samples_per_frame ; int total_samples = s - > samples_per_frame * s - > num_channels ; int i , j , rawpcm_tile , padding_zeroes , res ; s - > subframe_offset = get_bits_count ( & s - > gb ) ; / * reset channel context and find the next block offset and size == the next block of the channel with the smallest number of decoded samples * / for ( i = 0 ; i < s - > num_channels ; i + + ) { if ( offset > s - > channel[i] . decoded_samples ) { offset = s - > channel[i] . decoded_samples ; subframe_len = s - > channel[i] . subframe_len[s - > channel[i] . cur_subframe] ; } } / * get a list of all channels that contain the estimated block * / s - > channels_for_cur_subframe = 0 ; for ( i = 0 ; i < s - > num_channels ; i + + ) { const int cur_subframe = s - > channel[i] . cur_subframe ; / * subtract already processed samples * / total_samples - = s - > channel[i] . decoded_samples ; / * and count if there are multiple subframes that match our profile * / if ( offset == s - > channel[i] . decoded_samples & & subframe_len == s - > channel[i] . subframe_len[cur_subframe] ) { total_samples - = s - > channel[i] . subframe_len[cur_subframe] ; s - > channel[i] . decoded_samples + = s - > channel[i] . subframe_len[cur_subframe] ; s - > channel_indexes_for_cur_subframe[s - > channels_for_cur_subframe] = i ; + + s - > channels_for_cur_subframe ; } } / * check if the frame will be complete after processing the estimated block * / if ( ! total_samples ) s - > parsed_all_subframes = 1 ; s - > seekable_tile = get_bits1 ( & s - > gb ) ; if ( s - > seekable_tile ) { clear_codec_buffers ( s ) ; s - > do_arith_coding = get_bits1 ( & s - > gb ) ; if ( s - > do_arith_coding ) { avpriv_request_sample ( s - > avctx , Arithmetic coding ) ; return AVERROR_PATCHWELCOME ; } s - > do_ac_filter = get_bits1 ( & s - > gb ) ; s - > do_inter_ch_decorr = get_bits1 ( & s - > gb ) ; s - > do_mclms = get_bits1 ( & s - > gb ) ; if ( s - > do_ac_filter ) decode_ac_filter ( s ) ; if ( s - > do_mclms ) decode_mclms ( s ) ; if ( ( res = decode_cdlms ( s ) ) < 0 ) return res ; s - > movave_scaling = get_bits ( & s - > gb , 3 ) ; s - > quant_stepsize = get_bits ( & s - > gb , 8 ) + 1 ; reset_codec ( s ) ; } else if ( ! s - > cdlms[0][0] . order ) { av_log ( s - > avctx , AV_LOG_DEBUG , Waiting for seekable tile\n ) ; s - > frame . nb_samples = 0 ; return - 1 ; } rawpcm_tile = get_bits1 ( & s - > gb ) ; for ( i = 0 ; i < s - > num_channels ; i + + ) s - > is_channel_coded[i] = 1 ; if ( ! rawpcm_tile ) { for ( i = 0 ; i < s - > num_channels ; i + + ) s - > is_channel_coded[i] = get_bits1 ( & s - > gb ) ; if ( s - > bV3RTM ) { // LPC s - > do_lpc = get_bits1 ( & s - > gb ) ; if ( s - > do_lpc ) { decode_lpc ( s ) ; avpriv_request_sample ( s - > avctx , Expect wrong output since inverse LPC filter ) ; } } else s - > do_lpc = 0 ; } if ( get_bits1 ( & s - > gb ) ) padding_zeroes = get_bits ( & s - > gb , 5 ) ; else padding_zeroes = 0 ; if ( rawpcm_tile ) { int bits = s - > bits_per_sample - padding_zeroes ; if ( bits < = 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , Invalid number of padding bits in raw PCM tile\n ) ; return AVERROR_INVALIDDATA ; } av_dlog ( s - > avctx , RAWPCM %d bits per sample . total %d bits , remain=%d\n , bits , bits * s - > num_channels * subframe_len , get_bits_count ( & s - > gb ) ) ; for ( i = 0 ; i < s - > num_channels ; i + + ) for ( j = 0 ; j < subframe_len ; j + + ) s - > channel_coeffs[i][j] = get_sbits ( & s - > gb , bits ) ; } else { for ( i = 0 ; i < s - > num_channels ; i + + ) if ( s - > is_channel_coded[i] ) { decode_channel_residues ( s , i , subframe_len ) ; if ( s - > seekable_tile ) use_high_update_speed ( s , i ) ; else use_normal_update_speed ( s , i ) ; revert_cdlms ( s , i , 0 , subframe_len ) ; } else { memset ( s - > channel_residues[i] , 0 , sizeof ( * * s - > channel_residues ) * subframe_len ) ; } } if ( s - > do_mclms ) revert_mclms ( s , subframe_len ) ; if ( s - > do_inter_ch_decorr ) revert_inter_ch_decorr ( s , subframe_len ) ; if ( s - > do_ac_filter ) revert_acfilter ( s , subframe_len ) ; / * Dequantize * / if ( s - > quant_stepsize ! = 1 ) for ( i = 0 ; i < s - > num_channels ; i + + ) for ( j = 0 ; j < subframe_len ; j + + ) s - > channel_residues[i][j] * = s - > quant_stepsize ; / * Write to proper output buffer depending on bit - depth * / for ( i = 0 ; i < s - > channels_for_cur_subframe ; i + + ) { int c = s - > channel_indexes_for_cur_subframe[i] ; int subframe_len = s - > channel[c] . subframe_len[s - > channel[c] . cur_subframe] ; for ( j = 0 ; j < subframe_len ; j + + ) { if ( s - > bits_per_sample == 16 ) { * s - > samples_16[c] + + = ( int16_t ) s - > channel_residues[c][j] < < padding_zeroes ; } else { * s - > samples_32[c] + + = s - > channel_residues[c][j] < < padding_zeroes ; } } } / * handled one subframe * / for ( i = 0 ; i < s - > channels_for_cur_subframe ; i + + ) { int c = s - > channel_indexes_for_cur_subframe[i]",1
"int av_resample ( AVResampleContext * c , short * dst , short * src , int * consumed , int src_size , int dst_size , int update_ctx ) { int dst_index , i ; int index= c - > index ; int frac= c - > frac ; int dst_incr_frac= c - > dst_incr % c - > src_incr ; int dst_incr= c - > dst_incr / c - > src_incr ; int compensation_distance= c - > compensation_distance ; if ( compensation_distance == 0 & & c - > filter_length == 1 & & c - > phase_shift==0 ) { int64_t index2= ( ( int64_t ) index ) < < 32 ; int64_t incr= ( 1LL < < 32 ) * c - > dst_incr / c - > src_incr ; dst_size= FFMIN ( dst_size , ( src_size - 1 - index ) * ( int64_t ) c - > src_incr / c - > dst_incr ) ; for ( dst_index=0 ; dst_index < dst_size ; dst_index + + ) { dst[dst_index] = src[index2 > > 32] ; index2 + = incr ; } frac + = dst_index * dst_incr_frac ; index + = dst_index * dst_incr ; index + = frac / c - > src_incr ; frac %= c - > src_incr ; } else { for ( dst_index=0 ; dst_index < dst_size ; dst_index + + ) { FELEM * filter= c - > filter_bank + c - > filter_length * ( index & c - > phase_mask ) ; int sample_index= index > > c - > phase_shift ; FELEM2 val=0 ; if ( sample_index < 0 ) { for ( i=0 ; i < c - > filter_length ; i + + ) val + = src[FFABS ( sample_index + i ) % src_size] * filter[i] ; } else if ( sample_index + c - > filter_length > src_size ) { break ; } else if ( c - > linear ) { FELEM2 v2=0 ; for ( i=0 ; i < c - > filter_length ; i + + ) { val + = src[sample_index + i] * ( FELEM2 ) filter[i] ; v2 + = src[sample_index + i] * ( FELEM2 ) filter[i + c - > filter_length] ; } val + = ( v2 - val ) * ( FELEML ) frac / c - > src_incr ; } else { for ( i=0 ; i < c - > filter_length ; i + + ) { val + = src[sample_index + i] * ( FELEM2 ) filter[i] ; } } ifdef CONFIG_RESAMPLE_AUDIOPHILE_KIDDY_MODE dst[dst_index] = av_clip_int16 ( lrintf ( val ) ) ; else val = ( val + ( 1 < < ( FILTER_SHIFT - 1 ) ) ) > > FILTER_SHIFT ; dst[dst_index] = ( unsigned ) ( val + 32768 ) > 65535 ? ( val > > 31 ) 32767 : val ; endif frac + = dst_incr_frac ; index + = dst_incr ; if ( frac > = c - > src_incr ) { frac - = c - > src_incr ; index + + ; } if ( dst_index + 1 == compensation_distance ) { compensation_distance= 0 ; dst_incr_frac= c - > ideal_dst_incr % c - > src_incr ; dst_incr= c - > ideal_dst_incr / c - > src_incr ; } } } * consumed= FFMAX ( index , 0 ) > > c - > phase_shift ; if ( index > =0 ) index & = c - > phase_mask ; if ( compensation_distance ) { compensation_distance - = dst_index ; assert ( compensation_distance > 0 ) ; } if ( update_ctx ) { c - > frac= frac ; c - > index= index ; c - > dst_incr= dst_incr_frac + c - > src_incr * dst_incr ; c - > compensation_distance= compensation_distance ; } if 0 if ( update_ctx & & ! c - > compensation_distance ) { undef rand av_resample_compensate ( c , rand ( ) % ( 8000 * 2 ) - 8000 , 8000 * 2 ) ; av_log ( NULL , AV_LOG_DEBUG , %d %d %d\n , c - > dst_incr , c - > ideal_dst_incr , c - > compensation_distance ) ; } endif return dst_index ; }",1
"static void FUNCC ( pred4x4_128_dc ) ( uint8_t * _src , const uint8_t * topright , int _stride ) { pixel * src = ( pixel * ) _src ; int stride = _stride/sizeof ( pixel ) ; ( ( pixel4 * ) ( src + 0 * stride ) ) [0]= ( ( pixel4 * ) ( src + 1 * stride ) ) [0]= ( ( pixel4 * ) ( src + 2 * stride ) ) [0]= ( ( pixel4 * ) ( src + 3 * stride ) ) [0]= PIXEL_SPLAT_X4 ( 1 < < ( BIT_DEPTH - 1 ) ) ; }",1
"static void RENAME ( yuv2rgb565_1 ) ( SwsContext * c , const int16_t * buf0 , const int16_t * ubuf[2] , const int16_t * bguf[2] , const int16_t * abuf0 , uint8_t * dest , int dstW , int uvalpha , int y ) { const int16_t * ubuf0 = ubuf[0] , * ubuf1 = ubuf[1] ; const int16_t * buf1= buf0 ; //FIXME needed for RGB1/BGR1 if ( uvalpha < 2048 ) { // note this is not correct ( shifts chrominance by 0 . 5 pixels ) but it is a bit faster __asm__ volatile ( mov %% REG_b , ESP_OFFSET ( %5 ) \n\t mov %4 , %% REG_b \n\t push %% REG_BP \n\t YSCALEYUV2RGB1 ( %%REGBP , %5 ) pxor %%mm7 , %%mm7 \n\t / * mm2=B , %%mm4=G , %%mm5=R , %%mm7=0 * / ifdef DITHER1XBPP paddusb BLUE_DITHER ( %5 ) , %%mm2 \n\t paddusb GREEN_DITHER ( %5 ) , %%mm4 \n\t paddusb RED_DITHER ( %5 ) , %%mm5 \n\t endif WRITERGB16 ( %%REGb , 8280 ( %5 ) , %%REGBP ) pop %% REG_BP \n\t mov ESP_OFFSET ( %5 ) , %% REG_b \n\t : : c ( buf0 ) , d ( buf1 ) , S ( ubuf0 ) , D ( ubuf1 ) , m ( dest ) , a ( & c - > redDither ) ) ; } else { __asm__ volatile ( mov %% REG_b , ESP_OFFSET ( %5 ) \n\t mov %4 , %% REG_b \n\t push %% REG_BP \n\t YSCALEYUV2RGB1b ( %%REGBP , %5 ) pxor %%mm7 , %%mm7 \n\t / * mm2=B , %%mm4=G , %%mm5=R , %%mm7=0 * / ifdef DITHER1XBPP paddusb BLUE_DITHER ( %5 ) , %%mm2 \n\t paddusb GREEN_DITHER ( %5 ) , %%mm4 \n\t paddusb RED_DITHER ( %5 ) , %%mm5 \n\t endif WRITERGB16 ( %%REGb , 8280 ( %5 ) , %%REGBP ) pop %% REG_BP \n\t mov ESP_OFFSET ( %5 ) , %% REG_b \n\t : : c ( buf0 ) , d ( buf1 ) , S ( ubuf0 ) , D ( ubuf1 ) , m ( dest ) , a ( & c - > redDither ) ) ; } }",1
"int ff_dirac_golomb_read_16bit ( DiracGolombLUT * lut_ctx , const uint8_t * buf , int bytes , uint8_t * _dst , int coeffs ) { int i , b , c_idx = 0 ; int16_t * dst = ( int16_t * ) _dst ; DiracGolombLUT * future[4] , * l = & lut_ctx[2 * LUT_SIZE + buf[0]] ; INIT_RESIDUE ( res ) ; for ( b = 1 ; b < = bytes ; b + + ) { future[0] = & lut_ctx[buf[b]] ; future[1] = future[0] + 1 * LUT_SIZE ; future[2] = future[0] + 2 * LUT_SIZE ; future[3] = future[0] + 3 * LUT_SIZE ; if ( ( c_idx + 1 ) > coeffs ) return c_idx ; if ( res_bits & & l - > sign ) { int32_t coeff = 1 ; APPEND_RESIDUE ( res , l - > preamble ) ; for ( i = 0 ; i < ( res_bits > > 1 ) - 1 ; i + + ) { coeff < < = 1 ; coeff |= ( res > > ( RSIZE_BITS - 2 * i - 2 ) ) & 1 ; } dst[c_idx + + ] = l - > sign * ( coeff - 1 ) ; } for ( i = 0 ; i < LUT_BITS ; i + + ) dst[c_idx + i] = l - > ready[i] ; c_idx + = l - > ready_num ; APPEND_RESIDUE ( res , l - > leftover ) ; l = future[l - > need_s ? 3 : ! res_bits ? 2 : res_bits & 1] ; } return c_idx ; }",1
"void ff_add_pixels_clamped_c ( const DCTELEM * block , uint8_t * restrict pixels , int line_size ) { int i ; uint8_t * cm = ff_cropTbl + MAX_NEG_CROP ; / * read the pixels * / for ( i=0 ; i < 8 ; i + + ) { pixels[0] = cm[pixels[0] + block[0]] ; pixels[1] = cm[pixels[1] + block[1]] ; pixels[2] = cm[pixels[2] + block[2]] ; pixels[3] = cm[pixels[3] + block[3]] ; pixels[4] = cm[pixels[4] + block[4]] ; pixels[5] = cm[pixels[5] + block[5]] ; pixels[6] = cm[pixels[6] + block[6]] ; pixels[7] = cm[pixels[7] + block[7]] ; pixels + = line_size ; block + = 8 ; } }",1
"void show_help ( void ) { const OptionDef * po ; int i , expert ; printf ( ffmpeg version FFMPEG_VERSION , Copyright ( c ) 2000 , 2001 Gerard Lantau\n usage : ffmpeg [[options] - i input_file] . . . { [options] outfile } . . . \n Hyper fast MPEG1/MPEG4/H263/RV and AC3/MPEG audio encoder\n \n Main options are : \n ) ; for ( i=0 ; i < 2 ; i + + ) { if ( i == 1 ) printf ( \nAdvanced options are : \n ) ; for ( po = options ; po - > name ! = NULL ; po + + ) { char buf[64] ; expert = ( po - > flags & OPT_EXPERT ) ! = 0 ; if ( expert == i ) { strcpy ( buf , po - > name ) ; if ( po - > flags & HAS_ARG ) { strcat ( buf , ) ; strcat ( buf , po - > argname ) ; } printf ( - % - 17s %s\n , buf , po - > help ) ; } } } exit ( 1 ) ; }",0
"static int ftp_shutdown ( URLContext * h , int flags ) { FTPContext * s = h - > priv_data ; av_dlog ( h , ftp protocol shutdown\n ) ; if ( s - > conn_data ) return ffurl_shutdown ( s - > conn_data , flags ) ; return AVERROR ( EIO ) ; }",0
static av_cold int smc_decode_init ( AVCodecContext * avctx ) { SmcContext * s = avctx - > priv_data ; s - > avctx = avctx ; avctx - > pix_fmt = AV_PIX_FMT_PAL8 ; s - > frame . data[0] = NULL ; return 0 ; },0
"static inline void RENAME ( yuv2yuvX ) ( int16_t * lumFilter , int16_t * * lumSrc , int lumFilterSize , int16_t * chrFilter , int16_t * * chrSrc , int chrFilterSize , uint8_t * dest , uint8_t * uDest , uint8_t * vDest , int dstW , int16_t * lumMmxFilter , int16_t * chrMmxFilter ) { ifdef HAVE_MMX if ( uDest ! = NULL ) { asm volatile ( YSCALEYUV2YV12X ( 0 ) : : m ( - chrFilterSize ) , r ( chrSrc + chrFilterSize ) , r ( chrMmxFilter + chrFilterSize * 4 ) , r ( uDest ) , m ( dstW > > 1 ) : %eax , %edx , %esi ) ; asm volatile ( YSCALEYUV2YV12X ( 4096 ) : : m ( - chrFilterSize ) , r ( chrSrc + chrFilterSize ) , r ( chrMmxFilter + chrFilterSize * 4 ) , r ( vDest ) , m ( dstW > > 1 ) : %eax , %edx , %esi ) ; } asm volatile ( YSCALEYUV2YV12X ( 0 ) : : m ( - lumFilterSize ) , r ( lumSrc + lumFilterSize ) , r ( lumMmxFilter + lumFilterSize * 4 ) , r ( dest ) , m ( dstW ) : %eax , %edx , %esi ) ; else //FIXME Optimize ( just quickly writen not opti . . ) int i ; for ( i=0 ; i < dstW ; i + + ) { int val=0 ; int j ; for ( j=0 ; j < lumFilterSize ; j + + ) val + = lumSrc[j][i] * lumFilter[j] ; dest[i]= MIN ( MAX ( val > > 19 , 0 ) , 255 ) ; } if ( uDest ! = NULL ) for ( i=0 ; i < ( dstW > > 1 ) ; i + + ) { int u=0 ; int v=0 ; int j ; for ( j=0 ; j < lumFilterSize ; j + + ) { u + = chrSrc[j][i] * chrFilter[j] ; v + = chrSrc[j][i + 2048] * chrFilter[j] ; } uDest[i]= MIN ( MAX ( u > > 19 , 0 ) , 255 ) ; vDest[i]= MIN ( MAX ( v > > 19 , 0 ) , 255 ) ; } endif }",1
"static int huff_build12 ( VLC * vlc , uint8_t * len ) { HuffEntry he[4096] ; uint32_t codes[4096] ; uint8_t bits[4096] ; uint16_t syms[4096] ; uint32_t code ; int i ; for ( i = 0 ; i < 4096 ; i + + ) { he[i] . sym = 4095 - i ; he[i] . len = len[i] ; if ( len[i] == 0 ) return AVERROR_INVALIDDATA ; } AV_QSORT ( he , 4096 , HuffEntry , huff_cmp_len12 ) ; code = 1 ; for ( i = 4095 ; i > = 0 ; i - - ) { codes[i] = code > > ( 32 - he[i] . len ) ; bits[i] = he[i] . len ; syms[i] = he[i] . sym ; code + = 0x80000000u > > ( he[i] . len - 1 ) ; } ff_free_vlc ( vlc ) ; return ff_init_vlc_sparse ( vlc , FFMIN ( he[4095] . len , 14 ) , 4096 , bits , sizeof ( * bits ) , sizeof ( * bits ) , codes , sizeof ( * codes ) , sizeof ( * codes ) , syms , sizeof ( * syms ) , sizeof ( * syms ) , 0 ) ; }",1
"void ff_set_fixed_vector ( float * out , const AMRFixed * in , float scale , int size ) { int i ; for ( i=0 ; i < in - > n ; i + + ) { int x = in - > x[i] , repeats = ! ( ( in - > no_repeat_mask > > i ) & 1 ) ; float y = in - > y[i] * scale ; do { out[x] + = y ; y * = in - > pitch_fac ; x + = in - > pitch_lag ; } while ( x < size & & repeats ) ; } }",1
"static int do_bit_allocation ( AC3DecodeContext * ctx , int flags ) { ac3_audio_block * ab = & ctx - > audio_block ; int i , snroffst = 0 ; if ( ! flags ) / * bit allocation is not required * / return 0 ; if ( ab - > flags & AC3_AB_SNROFFSTE ) { / * check whether snroffsts are zero * / snroffst + = ab - > csnroffst ; if ( ab - > flags & AC3_AB_CPLINU ) snroffst + = ab - > cplfsnroffst ; for ( i = 0 ; i < ctx - > bsi . nfchans ; i + + ) snroffst + = ab - > fsnroffst[i] ; if ( ctx - > bsi . flags & AC3_BSI_LFEON ) snroffst + = ab - > lfefsnroffst ; if ( ! snroffst ) { memset ( ab - > cplbap , 0 , sizeof ( ab - > cplbap ) ) ; for ( i = 0 ; i < ctx - > bsi . nfchans ; i + + ) memset ( ab - > bap[i] , 0 , sizeof ( ab - > bap[i] ) ) ; memset ( ab - > lfebap , 0 , sizeof ( ab - > lfebap ) ) ; return 0 ; } } / * perform bit allocation * / if ( ( ab - > flags & AC3_AB_CPLINU ) & & ( flags & 64 ) ) if ( _do_bit_allocation ( ctx , 5 ) ) return - 1 ; for ( i = 0 ; i < ctx - > bsi . nfchans ; i + + ) if ( flags & ( 1 < < i ) ) if ( _do_bit_allocation ( ctx , i ) ) return - 1 ; if ( ( ctx - > bsi . flags & AC3_BSI_LFEON ) & & ( flags & 32 ) ) if ( _do_bit_allocation ( ctx , 6 ) ) return - 1 ; return 0 ; }",0
"int avcodec_default_get_buffer ( AVCodecContext * s , AVFrame * pic ) { int i ; int w= s - > width ; int h= s - > height ; InternalBuffer * buf ; int * picture_number ; assert ( pic - > data[0]==NULL ) ; assert ( INTERNAL_BUFFER_SIZE > s - > internal_buffer_count ) ; if ( avcodec_check_dimensions ( s , w , h ) ) return - 1 ; if ( s - > internal_buffer==NULL ) { s - > internal_buffer= av_mallocz ( INTERNAL_BUFFER_SIZE * sizeof ( InternalBuffer ) ) ; } if 0 s - > internal_buffer= av_fast_realloc ( s - > internal_buffer , & s - > internal_buffer_size , sizeof ( InternalBuffer ) * FFMAX ( 99 , s - > internal_buffer_count + 1 ) / * FIXME * / ) ; endif buf= & ( ( InternalBuffer * ) s - > internal_buffer ) [s - > internal_buffer_count] ; picture_number= & ( ( ( InternalBuffer * ) s - > internal_buffer ) [INTERNAL_BUFFER_SIZE - 1] ) . last_pic_num ; //FIXME ugly hack ( * picture_number ) + + ; if ( buf - > base[0] ) { pic - > age= * picture_number - buf - > last_pic_num ; buf - > last_pic_num= * picture_number ; } else { int h_chroma_shift , v_chroma_shift ; int pixel_size , size[3] ; AVPicture picture ; avcodec_get_chroma_sub_sample ( s - > pix_fmt , & h_chroma_shift , & v_chroma_shift ) ; avcodec_align_dimensions ( s , & w , & h ) ; if ( ! ( s - > flags & CODEC_FLAG_EMU_EDGE ) ) { w + = EDGE_WIDTH * 2 ; h + = EDGE_WIDTH * 2 ; } avpicture_fill ( & picture , NULL , s - > pix_fmt , w , h ) ; pixel_size= picture . linesize[0] * 8 / w ; //av_log ( NULL , AV_LOG_ERROR , %d %d %d %d\n , ( int ) picture . data[1] , w , h , s - > pix_fmt ) ; assert ( pixel_size > =1 ) ; //FIXME next ensures that linesize= 2 x uvlinesize , thats needed because some MC code assumes it if ( pixel_size == 3 * 8 ) w= ALIGN ( w , STRIDE_ALIGN < < h_chroma_shift ) ; else w= ALIGN ( pixel_size * w , STRIDE_ALIGN < < ( h_chroma_shift + 3 ) ) / pixel_size ; size[1] = avpicture_fill ( & picture , NULL , s - > pix_fmt , w , h ) ; size[0] = picture . linesize[0] * h ; size[1] - = size[0] ; if ( picture . data[2] ) size[1]= size[2]= size[1]/2 ; else size[2]= 0 ; buf - > last_pic_num= - 256 * 256 * 256 * 64 ; memset ( buf - > base , 0 , sizeof ( buf - > base ) ) ; memset ( buf - > data , 0 , sizeof ( buf - > data ) ) ; for ( i=0 ; i < 3 & & size[i] ; i + + ) { const int h_shift= i==0 ? 0 : h_chroma_shift ; const int v_shift= i==0 ? 0 : v_chroma_shift ; buf - > linesize[i]= picture . linesize[i] ; buf - > base[i]= av_malloc ( size[i] + 16 ) ; //FIXME 16 if ( buf - > base[i]==NULL ) return - 1 ; memset ( buf - > base[i] , 128 , size[i] ) ; // no edge if EDEG EMU or not planar YUV , we check for PAL8 redundantly to protect against a exploitable bug regression . . . if ( ( s - > flags & CODEC_FLAG_EMU_EDGE ) || ( s - > pix_fmt == PIX_FMT_PAL8 ) || ! size[2] ) buf - > data[i] = buf - > base[i] ; else buf - > data[i] = buf - > base[i] + ALIGN ( ( buf - > linesize[i] * EDGE_WIDTH > > v_shift ) + ( EDGE_WIDTH > > h_shift ) , STRIDE_ALIGN ) ; } pic - > age= 256 * 256 * 256 * 64 ; } pic - > type= FF_BUFFER_TYPE_INTERNAL ; for ( i=0 ; i < 4 ; i + + ) { pic - > base[i]= buf - > base[i] ; pic - > data[i]= buf - > data[i] ; pic - > linesize[i]= buf - > linesize[i] ; } s - > internal_buffer_count + + ; return 0 ; }",0
"matroska_add_stream ( MatroskaDemuxContext * matroska ) { int res = 0 ; uint32_t id ; MatroskaTrack * track ; av_log ( matroska - > ctx , AV_LOG_DEBUG , parsing track , adding stream . . , \n ) ; / * Allocate a generic track . As soon as we know its type we ' ll realloc . * / track = av_mallocz ( MAX_TRACK_SIZE ) ; matroska - > num_tracks + + ; strcpy ( track - > language , eng ) ; / * start with the master * / if ( ( res = ebml_read_master ( matroska , & id ) ) < 0 ) return res ; / * try reading the trackentry headers * / while ( res == 0 ) { if ( ! ( id = ebml_peek_id ( matroska , & matroska - > level_up ) ) ) { res = AVERROR ( EIO ) ; break ; } else if ( matroska - > level_up > 0 ) { matroska - > level_up - - ; break ; } switch ( id ) { / * track number ( unique stream ID ) * / case MATROSKA_ID_TRACKNUMBER : { uint64_t num ; if ( ( res = ebml_read_uint ( matroska , & id , & num ) ) < 0 ) break ; track - > num = num ; break ; } / * track UID ( unique identifier ) * / case MATROSKA_ID_TRACKUID : { uint64_t num ; if ( ( res = ebml_read_uint ( matroska , & id , & num ) ) < 0 ) break ; track - > uid = num ; break ; } / * track type ( video , audio , combined , subtitle , etc . ) * / case MATROSKA_ID_TRACKTYPE : { uint64_t num ; if ( ( res = ebml_read_uint ( matroska , & id , & num ) ) < 0 ) break ; if ( track - > type & & track - > type ! = num ) { av_log ( matroska - > ctx , AV_LOG_INFO , More than one tracktype in an entry - skip\n ) ; break ; } track - > type = num ; switch ( track - > type ) { case MATROSKA_TRACK_TYPE_VIDEO : case MATROSKA_TRACK_TYPE_AUDIO : case MATROSKA_TRACK_TYPE_SUBTITLE : break ; case MATROSKA_TRACK_TYPE_COMPLEX : case MATROSKA_TRACK_TYPE_LOGO : case MATROSKA_TRACK_TYPE_CONTROL : default : av_log ( matroska - > ctx , AV_LOG_INFO , Unknown or unsupported track type 0x%x\n , track - > type ) ; track - > type = MATROSKA_TRACK_TYPE_NONE ; break ; } matroska - > tracks[matroska - > num_tracks - 1] = track ; break ; } / * tracktype specific stuff for video * / case MATROSKA_ID_TRACKVIDEO : { MatroskaVideoTrack * videotrack ; if ( ! track - > type ) track - > type = MATROSKA_TRACK_TYPE_VIDEO ; if ( track - > type ! = MATROSKA_TRACK_TYPE_VIDEO ) { av_log ( matroska - > ctx , AV_LOG_INFO , video data in non - video track - ignoring\n ) ; res = AVERROR_INVALIDDATA ; break ; } else if ( ( res = ebml_read_master ( matroska , & id ) ) < 0 ) break ; videotrack = ( MatroskaVideoTrack * ) track ; while ( res == 0 ) { if ( ! ( id = ebml_peek_id ( matroska , & matroska - > level_up ) ) ) { res = AVERROR ( EIO ) ; break ; } else if ( matroska - > level_up > 0 ) { matroska - > level_up - - ; break ; } switch ( id ) { / * fixme , this should be one - up , but I get it here * / case MATROSKA_ID_TRACKDEFAULTDURATION : { uint64_t num ; if ( ( res = ebml_read_uint ( matroska , & id , & num ) ) < 0 ) break ; track - > default_duration = num ; break ; } / * video framerate * / case MATROSKA_ID_VIDEOFRAMERATE : { double num ; if ( ( res = ebml_read_float ( matroska , & id , & num ) ) < 0 ) break ; if ( ! track - > default_duration ) track - > default_duration = 1000000000/num ; break ; } / * width of the size to display the video at * / case MATROSKA_ID_VIDEODISPLAYWIDTH : { uint64_t num ; if ( ( res = ebml_read_uint ( matroska , & id , & num ) ) < 0 ) break ; videotrack - > display_width = num ; break ; } / * height of the size to display the video at * / case MATROSKA_ID_VIDEODISPLAYHEIGHT : { uint64_t num ; if ( ( res = ebml_read_uint ( matroska , & id , & num ) ) < 0 ) break ; videotrack - > display_height = num ; break ; } / * width of the video in the file * / case MATROSKA_ID_VIDEOPIXELWIDTH : { uint64_t num ; if ( ( res = ebml_read_uint ( matroska , & id , & num ) ) < 0 ) break ; videotrack - > pixel_width = num ; break ; } / * height of the video in the file * / case MATROSKA_ID_VIDEOPIXELHEIGHT : { uint64_t num ; if ( ( res = ebml_read_uint ( matroska , & id , & num ) ) < 0 ) break ; videotrack - > pixel_height = num ; break ; } / * whether the video is interlaced * / case MATROSKA_ID_VIDEOFLAGINTERLACED : { uint64_t num ; if ( ( res = ebml_read_uint ( matroska , & id , & num ) ) < 0 ) break ; if ( num ) track - > flags |= MATROSKA_VIDEOTRACK_INTERLACED ; else track - > flags & = MATROSKA_VIDEOTRACK_INTERLACED ; break ; } / * stereo mode ( whether the video has two streams , * where one is for the left eye and the other for * the right eye , which creates a 3D - like * effect ) * / case MATROSKA_ID_VIDEOSTEREOMODE : { uint64_t num ; if ( ( res = ebml_read_uint ( matroska , & id , & num ) ) < 0 ) break ; if ( num ! = MATROSKA_EYE_MODE_MONO & & num ! = MATROSKA_EYE_MODE_LEFT & & num ! = MATROSKA_EYE_MODE_RIGHT & & num ! = MATROSKA_EYE_MODE_BOTH ) { av_log ( matroska - > ctx , AV_LOG_INFO , Ignoring unknown eye mode 0x%x\n , ( uint32_t ) num ) ; break ; } videotrack - > eye_mode = num ; break ; } / * aspect ratio behaviour * / case MATROSKA_ID_VIDEOASPECTRATIO : { uint64_t num ; if ( ( res = ebml_read_uint ( matroska , & id , & num ) ) < 0 ) break ; if ( num ! = MATROSKA_ASPECT_RATIO_MODE_FREE & & num ! = MATROSKA_ASPECT_RATIO_MODE_KEEP & & num ! = MATROSKA_ASPECT_RATIO_MODE_FIXED ) { av_log ( matroska - > ctx , AV_LOG_INFO , Ignoring unknown aspect ratio 0x%x\n , ( uint32_t ) num ) ; break ; } videotrack - > ar_mode = num ; break ; } / * colorspace ( only matters for",1
"inline static void RENAME ( hcscale ) ( uint16_t * dst , int dstWidth , uint8_t * src1 , uint8_t * src2 , int srcW , int xInc ) { ifdef HAVE_MMX // use the new MMX scaler if th mmx2 cant be used ( its faster than the x86asm one ) if ( sws_flags ! = SWS_FAST_BILINEAR || ( ! canMMX2BeUsed ) ) else if ( sws_flags ! = SWS_FAST_BILINEAR ) endif { RENAME ( hScale ) ( dst , dstWidth , src1 , srcW , xInc , hChrFilter , hChrFilterPos , hChrFilterSize ) ; RENAME ( hScale ) ( dst + 2048 , dstWidth , src2 , srcW , xInc , hChrFilter , hChrFilterPos , hChrFilterSize ) ; } else // Fast Bilinear upscale / crap downscale { ifdef ARCH_X86 ifdef HAVE_MMX2 int i ; if ( canMMX2BeUsed ) { asm volatile ( pxor %%mm7 , %%mm7 \n\t pxor %%mm2 , %%mm2 \n\t // 2 * xalpha movd %5 , %%mm6 \n\t // xInc & 0xFFFF punpcklwd %%mm6 , %%mm6 \n\t punpcklwd %%mm6 , %%mm6 \n\t movq %%mm6 , %%mm2 \n\t psllq 16 , %%mm2 \n\t paddw %%mm6 , %%mm2 \n\t psllq 16 , %%mm2 \n\t paddw %%mm6 , %%mm2 \n\t psllq 16 , %%mm2 \n\t //0 , t , 2t , 3t t=xInc & 0xFFFF movq %%mm2 , MANGLE ( temp0 ) \n\t movd %4 , %%mm6 \n\t // ( xInc * 4 ) & 0xFFFF punpcklwd %%mm6 , %%mm6 \n\t punpcklwd %%mm6 , %%mm6 \n\t xorl %%eax , %%eax \n\t // i movl %0 , %%esi \n\t // src movl %1 , %%edi \n\t // buf1 movl %3 , %%edx \n\t // ( xInc * 4 ) > > 16 xorl %%ecx , %%ecx \n\t xorl %%ebx , %%ebx \n\t movw %4 , %%bx \n\t // ( xInc * 4 ) & 0xFFFF define FUNNYUVCODE \ PREFETCH 1024 ( %%esi ) \n\t \ PREFETCH 1056 ( %%esi ) \n\t \ PREFETCH 1088 ( %%esi ) \n\t \ call MANGLE ( funnyUVCode ) \n\t \ movq MANGLE ( temp0 ) , %%mm2 \n\t \ xorl %%ecx , %%ecx \n\t FUNNYUVCODE FUNNYUVCODE FUNNYUVCODE FUNNYUVCODE FUNNYUVCODE FUNNYUVCODE FUNNYUVCODE FUNNYUVCODE xorl %%eax , %%eax \n\t // i movl %6 , %%esi \n\t // src movl %1 , %%edi \n\t // buf1 addl 4096 , %%edi \n\t FUNNYUVCODE FUNNYUVCODE FUNNYUVCODE FUNNYUVCODE FUNNYUVCODE FUNNYUVCODE FUNNYUVCODE FUNNYUVCODE : : m ( src1 ) , m ( dst ) , m ( dstWidth ) , m ( ( xInc * 4 ) > > 16 ) , m ( ( xInc * 4 ) & 0xFFFF ) , m ( xInc & 0xFFFF ) , m ( src2 ) : %eax , %ebx , %ecx , %edx , %esi , %edi ) ; for ( i=dstWidth - 1 ; ( i * xInc ) > > 16 > =srcW - 1 ; i - - ) { // printf ( %d %d %d\n , dstWidth , i , srcW ) ; dst[i] = src1[srcW - 1] * 128 ; dst[i + 2048] = src2[srcW - 1] * 128 ; } } else { endif asm volatile ( xorl %%eax , %%eax \n\t // i xorl %%ebx , %%ebx \n\t // xx xorl %%ecx , %%ecx \n\t // 2 * xalpha . balign 16 \n\t 1 : \n\t movl %0 , %%esi \n\t movzbl ( %%esi , %%ebx ) , %%edi \n\t //src[xx] movzbl 1 ( %%esi , %%ebx ) , %%esi \n\t //src[xx + 1] subl %%edi , %%esi \n\t //src[xx + 1] - src[xx] imull %%ecx , %%esi \n\t // ( src[xx + 1] - src[xx] ) * 2 * xalpha shll 16 , %%edi \n\t addl %%edi , %%esi \n\t //src[xx + 1] * 2 * xalpha + src[xx] * ( 1 - 2 * xalpha ) movl %1 , %%edi \n\t shrl 9 , %%esi \n\t movw %%si , ( %%edi , %%eax , 2 ) \n\t movzbl ( %5 , %%ebx ) , %%edi \n\t //src[xx] movzbl 1 ( %5 , %%ebx ) , %%esi \n\t //src[xx + 1] subl %%edi , %%esi \n\t //src[xx + 1] - src[xx] imull %%ecx , %%esi \n\t // ( src[xx + 1] - src[xx] ) * 2 * xalpha shll 16 , %%edi \n\t addl %%edi , %%esi \n\t //src[xx + 1] * 2 * xalpha + src[xx] * ( 1 - 2 * xalpha ) movl %1 , %%edi \n\t shrl 9 , %%esi \n\t movw %%si , 4096 ( %%edi , %%eax , 2 ) \n\t addw %4 , %%cx \n\t //2 * xalpha + = xInc & 0xFF adcl %3 , %%ebx \n\t //xx + = xInc > > 8 + carry addl 1 , %%eax \n\t cmpl %2 , %%eax \n\t jb 1b \n\t : : m ( src1 ) , m ( dst ) , m ( dstWidth ) , m ( xInc > > 16 ) , m ( xInc & 0xFFFF ) , r ( src2 ) : %eax , %ebx , %ecx , %edi , %esi ) ; ifdef HAVE_MMX2 } //if MMX2 cant be used endif else int i ; unsigned int xpos=0 ; for ( i=0 ; i < dstWidth ; i + + ) { register unsigned int xx=xpos > > 16 ; register unsigned int xalpha= ( xpos & 0xFFFF ) > > 9 ; dst[i]= ( src1[xx] * ( xalpha 127 ) + src1[xx + 1] * xalpha ) ; dst[i + 2048]= ( src2[xx] * ( xalpha 127 ) + src2[xx + 1] * xalpha ) ; / * slower dst[i]= ( src1[xx] < < 7 ) + ( src1[xx + 1] - src1[xx] ) * xalpha ; dst[i + 2048]= ( src2[xx] < < 7 ) + ( src2[xx + 1] - src2[xx] ) * xalpha ; * / xpos + =xInc ; } endif } }",1
"static int decode_plane10 ( UtvideoContext * c , int plane_no , uint16_t * dst , int step , ptrdiff_t stride , int width , int height , const uint8_t * src , const uint8_t * huff , int use_pred ) { int i , j , slice , pix , ret ; int sstart , send ; VLC vlc ; GetBitContext gb ; int prev , fsym ; if ( ( ret = build_huff10 ( huff , & vlc , & fsym ) ) < 0 ) { av_log ( c - > avctx , AV_LOG_ERROR , Cannot build Huffman codes\n ) ; return ret ; } if ( fsym > = 0 ) { // build_huff reported a symbol to fill slices with send = 0 ; for ( slice = 0 ; slice < c - > slices ; slice + + ) { uint16_t * dest ; sstart = send ; send = ( height * ( slice + 1 ) / c - > slices ) ; dest = dst + sstart * stride ; prev = 0x200 ; for ( j = sstart ; j < send ; j + + ) { for ( i = 0 ; i < width * step ; i + = step ) { pix = fsym ; if ( use_pred ) { prev + = pix ; prev & = 0x3FF ; pix = prev ; } dest[i] = pix ; } dest + = stride ; } } return 0 ; } send = 0 ; for ( slice = 0 ; slice < c - > slices ; slice + + ) { uint16_t * dest ; int slice_data_start , slice_data_end , slice_size ; sstart = send ; send = ( height * ( slice + 1 ) / c - > slices ) ; dest = dst + sstart * stride ; // slice offset and size validation was done earlier slice_data_start = slice ? AV_RL32 ( src + slice * 4 - 4 ) : 0 ; slice_data_end = AV_RL32 ( src + slice * 4 ) ; slice_size = slice_data_end - slice_data_start ; if ( ! slice_size ) { av_log ( c - > avctx , AV_LOG_ERROR , Plane has more than one symbol yet a slice has a length of zero . \n ) ; goto fail ; } memset ( c - > slice_bits + slice_size , 0 , AV_INPUT_BUFFER_PADDING_SIZE ) ; c - > bdsp . bswap_buf ( ( uint32_t * ) c - > slice_bits , ( uint32_t * ) ( src + slice_data_start + c - > slices * 4 ) , ( slice_data_end - slice_data_start + 3 ) > > 2 ) ; init_get_bits ( & gb , c - > slice_bits , slice_size * 8 ) ; prev = 0x200 ; for ( j = sstart ; j < send ; j + + ) { for ( i = 0 ; i < width * step ; i + = step ) { pix = get_vlc2 ( & gb , vlc . table , VLC_BITS , 3 ) ; if ( pix < 0 ) { av_log ( c - > avctx , AV_LOG_ERROR , Decoding error\n ) ; goto fail ; } if ( use_pred ) { prev + = pix ; prev & = 0x3FF ; pix = prev ; } dest[i] = pix ; } dest + = stride ; if ( get_bits_left ( & gb ) < 0 ) { av_log ( c - > avctx , AV_LOG_ERROR , Slice decoding ran out of bits\n ) ; goto fail ; } } if ( get_bits_left ( & gb ) > 32 ) av_log ( c - > avctx , AV_LOG_WARNING , %d bits left after decoding slice\n , get_bits_left ( & gb ) ) ; } ff_free_vlc ( & vlc ) ; return 0 ; fail : ff_free_vlc ( & vlc ) ; return AVERROR_INVALIDDATA ; }",0
"static int encode_slice ( AVCodecContext * avctx , const AVFrame * pic , PutBitContext * pb , int sizes[4] , int x , int y , int quant , int mbs_per_slice ) { ProresContext * ctx = avctx - > priv_data ; int i , xp , yp ; int total_size = 0 ; const uint16_t * src ; int slice_width_factor = av_log2 ( mbs_per_slice ) ; int num_cblocks , pwidth ; int plane_factor , is_chroma ; for ( i = 0 ; i < ctx - > num_planes ; i + + ) { is_chroma = ( i == 1 || i == 2 ) ; plane_factor = slice_width_factor + 2 ; if ( is_chroma ) plane_factor + = ctx - > chroma_factor - 3 ; if ( ! is_chroma || ctx - > chroma_factor == CFACTOR_Y444 ) { xp = x < < 4 ; yp = y < < 4 ; num_cblocks = 4 ; pwidth = avctx - > width ; } else { xp = x < < 3 ; yp = y < < 4 ; num_cblocks = 2 ; pwidth = avctx - > width > > 1 ; } src = ( const uint16_t * ) ( pic - > data[i] + yp * pic - > linesize[i] ) + xp ; get_slice_data ( ctx , src , pic - > linesize[i] , xp , yp , pwidth , avctx - > height , ctx - > blocks[0] , mbs_per_slice , num_cblocks ) ; sizes[i] = encode_slice_plane ( ctx , pb , src , pic - > linesize[i] , mbs_per_slice , ctx - > blocks[0] , num_cblocks , plane_factor , ctx - > quants[quant] ) ; total_size + = sizes[i] ; } return total_size ; }",0
"static int ogg_write_header ( AVFormatContext * s ) { OGGStreamContext * oggstream ; int i , j ; for ( i = 0 ; i < s - > nb_streams ; i + + ) { AVStream * st = s - > streams[i] ; unsigned serial_num = i ; if ( st - > codec - > codec_type == AVMEDIA_TYPE_AUDIO ) { if ( st - > codec - > codec_id == AV_CODEC_ID_OPUS ) / * Opus requires a fixed 48kHz clock * / avpriv_set_pts_info ( st , 64 , 1 , 48000 ) ; else avpriv_set_pts_info ( st , 64 , 1 , st - > codec - > sample_rate ) ; } else if ( st - > codec - > codec_type == AVMEDIA_TYPE_VIDEO ) avpriv_set_pts_info ( st , 64 , st - > codec - > time_base . num , st - > codec - > time_base . den ) ; if ( st - > codec - > codec_id ! = AV_CODEC_ID_VORBIS & & st - > codec - > codec_id ! = AV_CODEC_ID_THEORA & & st - > codec - > codec_id ! = AV_CODEC_ID_SPEEX & & st - > codec - > codec_id ! = AV_CODEC_ID_FLAC & & st - > codec - > codec_id ! = AV_CODEC_ID_OPUS ) { av_log ( s , AV_LOG_ERROR , Unsupported codec id in stream %d\n , i ) ; return - 1 ; } if ( ! st - > codec - > extradata || ! st - > codec - > extradata_size ) { av_log ( s , AV_LOG_ERROR , No extradata present\n ) ; return - 1 ; } oggstream = av_mallocz ( sizeof ( * oggstream ) ) ; oggstream - > page . stream_index = i ; if ( ! ( st - > codec - > flags & CODEC_FLAG_BITEXACT ) ) do { serial_num = av_get_random_seed ( ) ; for ( j = 0 ; j < i ; j + + ) { OGGStreamContext * sc = s - > streams[j] - > priv_data ; if ( serial_num == sc - > serial_num ) break ; } } while ( j < i ) ; oggstream - > serial_num = serial_num ; st - > priv_data = oggstream ; if ( st - > codec - > codec_id == AV_CODEC_ID_FLAC ) { int err = ogg_build_flac_headers ( st - > codec , oggstream , st - > codec - > flags & CODEC_FLAG_BITEXACT , & s - > metadata ) ; if ( err ) { av_log ( s , AV_LOG_ERROR , Error writing FLAC headers\n ) ; av_freep ( & st - > priv_data ) ; return err ; } } else if ( st - > codec - > codec_id == AV_CODEC_ID_SPEEX ) { int err = ogg_build_speex_headers ( st - > codec , oggstream , st - > codec - > flags & CODEC_FLAG_BITEXACT , & s - > metadata ) ; if ( err ) { av_log ( s , AV_LOG_ERROR , Error writing Speex headers\n ) ; av_freep ( & st - > priv_data ) ; return err ; } } else if ( st - > codec - > codec_id == AV_CODEC_ID_OPUS ) { int err = ogg_build_opus_headers ( st - > codec , oggstream , st - > codec - > flags & CODEC_FLAG_BITEXACT , & s - > metadata ) ; if ( err ) { av_log ( s , AV_LOG_ERROR , Error writing Opus headers\n ) ; av_freep ( & st - > priv_data ) ; return err ; } } else { uint8_t * p ; const char * cstr = st - > codec - > codec_id == AV_CODEC_ID_VORBIS ? vorbis : theora ; int header_type = st - > codec - > codec_id == AV_CODEC_ID_VORBIS ? 3 : 0x81 ; int framing_bit = st - > codec - > codec_id == AV_CODEC_ID_VORBIS ? 1 : 0 ; if ( avpriv_split_xiph_headers ( st - > codec - > extradata , st - > codec - > extradata_size , st - > codec - > codec_id == AV_CODEC_ID_VORBIS ? 30 : 42 , oggstream - > header , oggstream - > header_len ) < 0 ) { av_log ( s , AV_LOG_ERROR , Extradata corrupted\n ) ; av_freep ( & st - > priv_data ) ; return - 1 ; } p = ogg_write_vorbiscomment ( 7 , st - > codec - > flags & CODEC_FLAG_BITEXACT , & oggstream - > header_len[1] , & s - > metadata , framing_bit ) ; oggstream - > header[1] = p ; if ( ! p ) return AVERROR ( ENOMEM ) ; bytestream_put_byte ( & p , header_type ) ; bytestream_put_buffer ( & p , cstr , 6 ) ; if ( st - > codec - > codec_id == AV_CODEC_ID_THEORA ) { / * * KFGSHIFT is the width of the less significant section of the granule position The less significant section is the frame count since the last keyframe * / oggstream - > kfgshift = ( ( oggstream - > header[0][40] & 3 ) < < 3 ) | ( oggstream - > header[0][41] > > 5 ) ; oggstream - > vrev = oggstream - > header[0][9] ; av_log ( s , AV_LOG_DEBUG , theora kfgshift %d , vrev %d\n , oggstream - > kfgshift , oggstream - > vrev ) ; } } } for ( j = 0 ; j < s - > nb_streams ; j + + ) { OGGStreamContext * oggstream = s - > streams[j] - > priv_data ; ogg_buffer_data ( s , s - > streams[j] , oggstream - > header[0] , oggstream - > header_len[0] , 0 , 1 ) ; oggstream - > page . flags |= 2 ; // bos ogg_buffer_page ( s , oggstream ) ; } for ( j = 0 ; j < s - > nb_streams ; j + + ) { AVStream * st = s - > streams[j] ; OGGStreamContext * oggstream = st - > priv_data ; for ( i = 1 ; i < 3 ; i + + ) { if ( oggstream & & oggstream - > header_len[i] ) ogg_buffer_data ( s , st , oggstream - > header[i] , oggstream - > header_len[i] , 0 , 1 ) ; } ogg_buffer_page ( s , oggstream ) ; } return 0 ; }",0
"static int revert_channel_correlation ( ALSDecContext * ctx , ALSBlockData * bd , ALSChannelData * * cd , int * reverted , unsigned int offset , int c ) { ALSChannelData * ch = cd[c] ; unsigned int dep = 0 ; unsigned int channels = ctx - > avctx - > channels ; if ( reverted[c] ) return 0 ; reverted[c] = 1 ; while ( dep < channels & & ! ch[dep] . stop_flag ) { revert_channel_correlation ( ctx , bd , cd , reverted , offset , ch[dep] . master_channel ) ; dep + + ; } if ( dep == channels ) { av_log ( ctx - > avctx , AV_LOG_WARNING , Invalid channel correlation ! \n ) ; return AVERROR_INVALIDDATA ; } bd - > const_block = ctx - > const_block + c ; bd - > shift_lsbs = ctx - > shift_lsbs + c ; bd - > opt_order = ctx - > opt_order + c ; bd - > store_prev_samples = ctx - > store_prev_samples + c ; bd - > use_ltp = ctx - > use_ltp + c ; bd - > ltp_lag = ctx - > ltp_lag + c ; bd - > ltp_gain = ctx - > ltp_gain[c] ; bd - > lpc_cof = ctx - > lpc_cof[c] ; bd - > quant_cof = ctx - > quant_cof[c] ; bd - > raw_samples = ctx - > raw_samples[c] + offset ; dep = 0 ; while ( ! ch[dep] . stop_flag ) { unsigned int smp ; unsigned int begin = 1 ; unsigned int end = bd - > block_length - 1 ; int64_t y ; int32_t * master = ctx - > raw_samples[ch[dep] . master_channel] + offset ; if ( ch[dep] . time_diff_flag ) { int t = ch[dep] . time_diff_index ; if ( ch[dep] . time_diff_sign ) { t = - t ; begin - = t ; } else { end - = t ; } for ( smp = begin ; smp < end ; smp + + ) { y = ( 1 < < 6 ) + MUL64 ( ch[dep] . weighting[0] , master[smp - 1 ] ) + MUL64 ( ch[dep] . weighting[1] , master[smp ] ) + MUL64 ( ch[dep] . weighting[2] , master[smp + 1 ] ) + MUL64 ( ch[dep] . weighting[3] , master[smp - 1 + t] ) + MUL64 ( ch[dep] . weighting[4] , master[smp + t] ) + MUL64 ( ch[dep] . weighting[5] , master[smp + 1 + t] ) ; bd - > raw_samples[smp] + = y > > 7 ; } } else { for ( smp = begin ; smp < end ; smp + + ) { y = ( 1 < < 6 ) + MUL64 ( ch[dep] . weighting[0] , master[smp - 1] ) + MUL64 ( ch[dep] . weighting[1] , master[smp ] ) + MUL64 ( ch[dep] . weighting[2] , master[smp + 1] ) ; bd - > raw_samples[smp] + = y > > 7 ; } } dep + + ; } return 0 ; }",0
int av_get_cpu_flags ( void ) { if ( checked ) return flags ; if ( ARCH_AARCH64 ) flags = ff_get_cpu_flags_aarch64 ( ) ; if ( ARCH_ARM ) flags = ff_get_cpu_flags_arm ( ) ; if ( ARCH_PPC ) flags = ff_get_cpu_flags_ppc ( ) ; if ( ARCH_X86 ) flags = ff_get_cpu_flags_x86 ( ) ; checked = 1 ; return flags ; },0
static inline void downmix_3f_1r_to_mono ( float * samples ) { int i ; for ( i = 0 ; i < 256 ; i + + ) { samples[i] + = ( samples[i + 256] + samples[i + 512] + samples[i + 768] ) ; samples[i + 256] = samples[i + 512] = samples[i + 768] = 0 ; } },0
"void ff_snow_pred_block ( SnowContext * s , uint8_t * dst , uint8_t * tmp , int stride , int sx , int sy , int b_w , int b_h , BlockNode * block , int plane_index , int w , int h ) { if ( block - > type & BLOCK_INTRA ) { int x , y ; const unsigned color = block - > color[plane_index] ; const unsigned color4 = color * 0x01010101 ; if ( b_w==32 ) { for ( y=0 ; y < b_h ; y + + ) { * ( uint32_t * ) & dst[0 + y * stride]= color4 ; * ( uint32_t * ) & dst[4 + y * stride]= color4 ; * ( uint32_t * ) & dst[8 + y * stride]= color4 ; * ( uint32_t * ) & dst[12 + y * stride]= color4 ; * ( uint32_t * ) & dst[16 + y * stride]= color4 ; * ( uint32_t * ) & dst[20 + y * stride]= color4 ; * ( uint32_t * ) & dst[24 + y * stride]= color4 ; * ( uint32_t * ) & dst[28 + y * stride]= color4 ; } } else if ( b_w==16 ) { for ( y=0 ; y < b_h ; y + + ) { * ( uint32_t * ) & dst[0 + y * stride]= color4 ; * ( uint32_t * ) & dst[4 + y * stride]= color4 ; * ( uint32_t * ) & dst[8 + y * stride]= color4 ; * ( uint32_t * ) & dst[12 + y * stride]= color4 ; } } else if ( b_w==8 ) { for ( y=0 ; y < b_h ; y + + ) { * ( uint32_t * ) & dst[0 + y * stride]= color4 ; * ( uint32_t * ) & dst[4 + y * stride]= color4 ; } } else if ( b_w==4 ) { for ( y=0 ; y < b_h ; y + + ) { * ( uint32_t * ) & dst[0 + y * stride]= color4 ; } } else { for ( y=0 ; y < b_h ; y + + ) { for ( x=0 ; x < b_w ; x + + ) { dst[x + y * stride]= color ; } } } } else { uint8_t * src= s - > last_picture[block - > ref] - > data[plane_index] ; const int scale= plane_index ? ( 2 * s - > mv_scale ) > > s - > chroma_h_shift : 2 * s - > mv_scale ; int mx= block - > mx * scale ; int my= block - > my * scale ; const int dx= mx & 15 ; const int dy= my & 15 ; const int tab_index= 3 - ( b_w > > 2 ) + ( b_w > > 4 ) ; sx + = ( mx > > 4 ) - ( HTAPS_MAX/2 - 1 ) ; sy + = ( my > > 4 ) - ( HTAPS_MAX/2 - 1 ) ; src + = sx + sy * stride ; if ( ( unsigned ) sx > = FFMAX ( w - b_w - ( HTAPS_MAX - 2 ) , 0 ) || ( unsigned ) sy > = FFMAX ( h - b_h - ( HTAPS_MAX - 2 ) , 0 ) ) { s - > vdsp . emulated_edge_mc ( tmp + MB_SIZE , src , stride , b_w + HTAPS_MAX - 1 , b_h + HTAPS_MAX - 1 , sx , sy , w , h ) ; src= tmp + MB_SIZE ; } av_assert2 ( s - > chroma_h_shift == s - > chroma_v_shift ) ; // only one mv_scale av_assert2 ( b_w > 1 & & b_h > 1 ) ; av_assert2 ( ( tab_index > =0 & & tab_index < 4 ) || b_w==32 ) ; if ( ( dx & 3 ) || ( dy & 3 ) || ! ( b_w == b_h || 2 * b_w == b_h || b_w == 2 * b_h ) || ( b_w & ( b_w - 1 ) ) || ! s - > plane[plane_index] . fast_mc ) mc_block ( & s - > plane[plane_index] , dst , src , stride , b_w , b_h , dx , dy ) ; else if ( b_w==32 ) { int y ; for ( y=0 ; y < b_h ; y + =16 ) { s - > h264qpel . put_h264_qpel_pixels_tab[0][dy + ( dx > > 2 ) ] ( dst + y * stride , src + 3 + ( y + 3 ) * stride , stride ) ; s - > h264qpel . put_h264_qpel_pixels_tab[0][dy + ( dx > > 2 ) ] ( dst + 16 + y * stride , src + 19 + ( y + 3 ) * stride , stride ) ; } } else if ( b_w==b_h ) s - > h264qpel . put_h264_qpel_pixels_tab[tab_index ][dy + ( dx > > 2 ) ] ( dst , src + 3 + 3 * stride , stride ) ; else if ( b_w==2 * b_h ) { s - > h264qpel . put_h264_qpel_pixels_tab[tab_index + 1][dy + ( dx > > 2 ) ] ( dst , src + 3 + 3 * stride , stride ) ; s - > h264qpel . put_h264_qpel_pixels_tab[tab_index + 1][dy + ( dx > > 2 ) ] ( dst + b_h , src + 3 + b_h + 3 * stride , stride ) ; } else { av_assert2 ( 2 * b_w==b_h ) ; s - > h264qpel . put_h264_qpel_pixels_tab[tab_index ][dy + ( dx > > 2 ) ] ( dst , src + 3 + 3 * stride , stride ) ; s - > h264qpel . put_h264_qpel_pixels_tab[tab_index ][dy + ( dx > > 2 ) ] ( dst + b_w * stride , src + 3 + 3 * stride + b_w * stride , stride ) ; } } }",1
"static int decode_pic_timing ( HEVCSEIContext * s , GetBitContext * gb , const HEVCParamSets * ps , void * logctx ) { HEVCSEIPictureTiming * h = & s - > picture_timing ; HEVCSPS * sps ; if ( ! ps - > sps_list[s - > active_seq_parameter_set_id] ) return ( AVERROR ( ENOMEM ) ) ; sps = ( HEVCSPS * ) ps - > sps_list[s - > active_seq_parameter_set_id] - > data ; if ( sps - > vui . frame_field_info_present_flag ) { int pic_struct = get_bits ( gb , 4 ) ; h - > picture_struct = AV_PICTURE_STRUCTURE_UNKNOWN ; if ( pic_struct == 2 ) { av_log ( logctx , AV_LOG_DEBUG , BOTTOM Field\n ) ; h - > picture_struct = AV_PICTURE_STRUCTURE_BOTTOM_FIELD ; } else if ( pic_struct == 1 ) { av_log ( logctx , AV_LOG_DEBUG , TOP Field\n ) ; h - > picture_struct = AV_PICTURE_STRUCTURE_TOP_FIELD ; } get_bits ( gb , 2 ) ; // source_scan_type get_bits ( gb , 1 ) ; // duplicate_flag } return 1 ; }",1
"static int qsv_decode_init ( AVCodecContext * avctx , QSVContext * q ) { const AVPixFmtDescriptor * desc ; mfxSession session = NULL ; int iopattern = 0 ; mfxVideoParam param = { { 0 } } ; int frame_width = avctx - > coded_width ; int frame_height = avctx - > coded_height ; int ret ; desc = av_pix_fmt_desc_get ( avctx - > sw_pix_fmt ) ; if ( ! desc ) return AVERROR_BUG ; if ( ! q - > async_fifo ) { q - > async_fifo = av_fifo_alloc ( ( 1 + q - > async_depth ) * ( sizeof ( mfxSyncPoint * ) + sizeof ( QSVFrame * ) ) ) ; if ( ! q - > async_fifo ) return AVERROR ( ENOMEM ) ; } if ( avctx - > pix_fmt == AV_PIX_FMT_QSV & & avctx - > hwaccel_context ) { AVQSVContext * user_ctx = avctx - > hwaccel_context ; session = user_ctx - > session ; iopattern = user_ctx - > iopattern ; q - > ext_buffers = user_ctx - > ext_buffers ; q - > nb_ext_buffers = user_ctx - > nb_ext_buffers ; } if ( avctx - > hw_frames_ctx ) { AVHWFramesContext * frames_ctx = ( AVHWFramesContext * ) avctx - > hw_frames_ctx - > data ; AVQSVFramesContext * frames_hwctx = frames_ctx - > hwctx ; if ( ! iopattern ) { if ( frames_hwctx - > frame_type & MFX_MEMTYPE_OPAQUE_FRAME ) iopattern = MFX_IOPATTERN_OUT_OPAQUE_MEMORY ; else if ( frames_hwctx - > frame_type & MFX_MEMTYPE_VIDEO_MEMORY_DECODER_TARGET ) iopattern = MFX_IOPATTERN_OUT_VIDEO_MEMORY ; } frame_width = frames_hwctx - > surfaces[0] . Info . Width ; frame_height = frames_hwctx - > surfaces[0] . Info . Height ; } if ( ! iopattern ) iopattern = MFX_IOPATTERN_OUT_SYSTEM_MEMORY ; q - > iopattern = iopattern ; ret = qsv_init_session ( avctx , q , session , avctx - > hw_frames_ctx ) ; if ( ret < 0 ) { av_log ( avctx , AV_LOG_ERROR , Error initializing an MFX session\n ) ; return ret ; } ret = ff_qsv_codec_id_to_mfx ( avctx - > codec_id ) ; if ( ret < 0 ) return ret ; param . mfx . CodecId = ret ; param . mfx . CodecProfile = avctx - > profile ; param . mfx . CodecLevel = avctx - > level ; param . mfx . FrameInfo . BitDepthLuma = desc - > comp[0] . depth ; param . mfx . FrameInfo . BitDepthChroma = desc - > comp[0] . depth ; param . mfx . FrameInfo . Shift = desc - > comp[0] . depth > 8 ; param . mfx . FrameInfo . FourCC = q - > fourcc ; param . mfx . FrameInfo . Width = frame_width ; param . mfx . FrameInfo . Height = frame_height ; param . mfx . FrameInfo . ChromaFormat = MFX_CHROMAFORMAT_YUV420 ; param . IOPattern = q - > iopattern ; param . AsyncDepth = q - > async_depth ; param . ExtParam = q - > ext_buffers ; param . NumExtParam = q - > nb_ext_buffers ; ret = MFXVideoDECODE_Init ( q - > session , & param ) ; if ( ret < 0 ) return ff_qsv_print_error ( avctx , ret , Error initializing the MFX video decoder ) ; q - > frame_info = param . mfx . FrameInfo ; return 0 ; }",0
"static int film_read_header ( AVFormatContext * s ) { FilmDemuxContext * film = s - > priv_data ; AVIOContext * pb = s - > pb ; AVStream * st ; unsigned char scratch[256] ; int i ; unsigned int data_offset ; unsigned int audio_frame_counter ; film - > sample_table = NULL ; film - > stereo_buffer = NULL ; film - > stereo_buffer_size = 0 ; / * load the main FILM header * / if ( avio_read ( pb , scratch , 16 ) ! = 16 ) return AVERROR ( EIO ) ; data_offset = AV_RB32 ( & scratch[4] ) ; film - > version = AV_RB32 ( & scratch[8] ) ; / * load the FDSC chunk * / if ( film - > version == 0 ) { / * special case for Lemmings . film files ; 20 - byte header * / if ( avio_read ( pb , scratch , 20 ) ! = 20 ) return AVERROR ( EIO ) ; / * make some assumptions about the audio parameters * / film - > audio_type = AV_CODEC_ID_PCM_S8 ; film - > audio_samplerate = 22050 ; film - > audio_channels = 1 ; film - > audio_bits = 8 ; } else { / * normal Saturn . cpk files ; 32 - byte header * / if ( avio_read ( pb , scratch , 32 ) ! = 32 ) return AVERROR ( EIO ) ; film - > audio_samplerate = AV_RB16 ( & scratch[24] ) ; film - > audio_channels = scratch[21] ; if ( ! film - > audio_channels || film - > audio_channels > 2 ) { av_log ( s , AV_LOG_ERROR , Invalid number of channels : %d\n , film - > audio_channels ) ; return AVERROR_INVALIDDATA ; } film - > audio_bits = scratch[22] ; if ( scratch[23] == 2 ) film - > audio_type = AV_CODEC_ID_ADPCM_ADX ; else if ( film - > audio_channels > 0 ) { if ( film - > audio_bits == 8 ) film - > audio_type = AV_CODEC_ID_PCM_S8 ; else if ( film - > audio_bits == 16 ) film - > audio_type = AV_CODEC_ID_PCM_S16BE ; else film - > audio_type = AV_CODEC_ID_NONE ; } else film - > audio_type = AV_CODEC_ID_NONE ; } if ( AV_RB32 ( & scratch[0] ) ! = FDSC_TAG ) return AVERROR_INVALIDDATA ; if ( AV_RB32 ( & scratch[8] ) == CVID_TAG ) { film - > video_type = AV_CODEC_ID_CINEPAK ; } else if ( AV_RB32 ( & scratch[8] ) == RAW_TAG ) { film - > video_type = AV_CODEC_ID_RAWVIDEO ; } else { film - > video_type = AV_CODEC_ID_NONE ; } / * initialize the decoder streams * / if ( film - > video_type ) { st = avformat_new_stream ( s , NULL ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; film - > video_stream_index = st - > index ; st - > codec - > codec_type = AVMEDIA_TYPE_VIDEO ; st - > codec - > codec_id = film - > video_type ; st - > codec - > codec_tag = 0 ; / * no fourcc * / st - > codec - > width = AV_RB32 ( & scratch[16] ) ; st - > codec - > height = AV_RB32 ( & scratch[12] ) ; if ( film - > video_type == AV_CODEC_ID_RAWVIDEO ) { if ( scratch[20] == 24 ) { st - > codec - > pix_fmt = AV_PIX_FMT_RGB24 ; } else { av_log ( s , AV_LOG_ERROR , raw video is using unhandled %dbpp\n , scratch[20] ) ; return - 1 ; } } } if ( film - > audio_type ) { st = avformat_new_stream ( s , NULL ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; film - > audio_stream_index = st - > index ; st - > codec - > codec_type = AVMEDIA_TYPE_AUDIO ; st - > codec - > codec_id = film - > audio_type ; st - > codec - > codec_tag = 1 ; st - > codec - > channels = film - > audio_channels ; st - > codec - > sample_rate = film - > audio_samplerate ; if ( film - > audio_type == AV_CODEC_ID_ADPCM_ADX ) { st - > codec - > bits_per_coded_sample = 18 * 8 / 32 ; st - > codec - > block_align = st - > codec - > channels * 18 ; st - > need_parsing = AVSTREAM_PARSE_FULL ; } else { st - > codec - > bits_per_coded_sample = film - > audio_bits ; st - > codec - > block_align = st - > codec - > channels * st - > codec - > bits_per_coded_sample / 8 ; } st - > codec - > bit_rate = st - > codec - > channels * st - > codec - > sample_rate * st - > codec - > bits_per_coded_sample ; } / * load the sample table * / if ( avio_read ( pb , scratch , 16 ) ! = 16 ) return AVERROR ( EIO ) ; if ( AV_RB32 ( & scratch[0] ) ! = STAB_TAG ) return AVERROR_INVALIDDATA ; film - > base_clock = AV_RB32 ( & scratch[8] ) ; film - > sample_count = AV_RB32 ( & scratch[12] ) ; if ( film - > sample_count > = UINT_MAX / sizeof ( film_sample ) ) return - 1 ; film - > sample_table = av_malloc ( film - > sample_count * sizeof ( film_sample ) ) ; if ( ! film - > sample_table ) return AVERROR ( ENOMEM ) ; for ( i = 0 ; i < s - > nb_streams ; i + + ) { st = s - > streams[i] ; if ( st - > codec - > codec_type == AVMEDIA_TYPE_VIDEO ) avpriv_set_pts_info ( st , 33 , 1 , film - > base_clock ) ; else avpriv_set_pts_info ( st , 64 , 1 , film - > audio_samplerate ) ; } audio_frame_counter = 0 ; for ( i = 0 ; i < film - > sample_count ; i + + ) { / * load the next sample record and transfer it to an internal struct * / if ( avio_read ( pb , scratch , 16 ) ! = 16 ) { av_free ( film - > sample_table ) ; return AVERROR ( EIO ) ; } film - > sample_table[i] . sample_offset = data_offset + AV_RB32 ( & scratch[0] ) ; film - > sample_table[i] . sample_size = AV_RB32 ( & scratch[4] ) ; if ( film - > sample_table[i] . sample_size > INT_MAX / 4 ) return AVERROR_INVALIDDATA ; if ( AV_RB32 ( & scratch[8] ) == 0xFFFFFFFF ) { film - > sample_table[i] . stream = film - > audio_stream_index ; film - > sample_table[i] . pts = audio_frame_counter ; if ( film - > audio_type == AV_CODEC_ID_ADPCM_ADX ) audio_frame_counter + = ( film - > sample_table[i] . sample_size * 32 / ( 18 * film - > audio_channels ) ) ; else if ( film - > audio_type",1
"static int encode_q_branch ( SnowContext * s , int level , int x , int y ) { uint8_t p_buffer[1024] ; uint8_t i_buffer[1024] ; uint8_t p_state[sizeof ( s - > block_state ) ] ; uint8_t i_state[sizeof ( s - > block_state ) ] ; RangeCoder pc , ic ; uint8_t * pbbak= s - > c . bytestream ; uint8_t * pbbak_start= s - > c . bytestream_start ; int score , score2 , iscore , i_len , p_len , block_s , sum , base_bits ; const int w= s - > b_width < < s - > block_max_depth ; const int h= s - > b_height < < s - > block_max_depth ; const int rem_depth= s - > block_max_depth - level ; const int index= ( x + y * w ) < < rem_depth ; const int block_w= 1 < < ( LOG2_MB_SIZE - level ) ; int trx= ( x + 1 ) < < rem_depth ; int try= ( y + 1 ) < < rem_depth ; const BlockNode * left = x ? & s - > block[index - 1] : & null_block ; const BlockNode * top = y ? & s - > block[index - w] : & null_block ; const BlockNode * right = trx < w ? & s - > block[index + 1] : & null_block ; const BlockNode * bottom= try < h ? & s - > block[index + w] : & null_block ; const BlockNode * tl = y & & x ? & s - > block[index - w - 1] : left ; const BlockNode * tr = y & & trx < w & & ( ( x & 1 ) ==0 || level==0 ) ? & s - > block[index - w + ( 1 < < rem_depth ) ] : tl ; //FIXME use lt int pl = left - > color[0] ; int pcb= left - > color[1] ; int pcr= left - > color[2] ; int pmx , pmy ; int mx=0 , my=0 ; int l , cr , cb ; const int stride= s - > current_picture - > linesize[0] ; const int uvstride= s - > current_picture - > linesize[1] ; uint8_t * current_data[3]= { s - > input_picture - > data[0] + ( x + y * stride ) * block_w , s - > input_picture - > data[1] + ( ( x * block_w ) > > s - > chroma_h_shift ) + ( ( y * uvstride * block_w ) > > s - > chroma_v_shift ) , s - > input_picture - > data[2] + ( ( x * block_w ) > > s - > chroma_h_shift ) + ( ( y * uvstride * block_w ) > > s - > chroma_v_shift ) } ; int P[10][2] ; int16_t last_mv[3][2] ; int qpel= ! ! ( s - > avctx - > flags & AV_CODEC_FLAG_QPEL ) ; //unused const int shift= 1 + qpel ; MotionEstContext * c= & s - > m . me ; int ref_context= av_log2 ( 2 * left - > ref ) + av_log2 ( 2 * top - > ref ) ; int mx_context= av_log2 ( 2 * FFABS ( left - > mx - top - > mx ) ) ; int my_context= av_log2 ( 2 * FFABS ( left - > my - top - > my ) ) ; int s_context= 2 * left - > level + 2 * top - > level + tl - > level + tr - > level ; int ref , best_ref , ref_score , ref_mx , ref_my ; av_assert0 ( sizeof ( s - > block_state ) > = 256 ) ; if ( s - > keyframe ) { set_blocks ( s , level , x , y , pl , pcb , pcr , 0 , 0 , 0 , BLOCK_INTRA ) ; return 0 ; } // clip predictors / edge ? P_LEFT[0]= left - > mx ; P_LEFT[1]= left - > my ; P_TOP [0]= top - > mx ; P_TOP [1]= top - > my ; P_TOPRIGHT[0]= tr - > mx ; P_TOPRIGHT[1]= tr - > my ; last_mv[0][0]= s - > block[index] . mx ; last_mv[0][1]= s - > block[index] . my ; last_mv[1][0]= right - > mx ; last_mv[1][1]= right - > my ; last_mv[2][0]= bottom - > mx ; last_mv[2][1]= bottom - > my ; s - > m . mb_stride=2 ; s - > m . mb_x= s - > m . mb_y= 0 ; c - > skip= 0 ; av_assert1 ( c - > stride == stride ) ; av_assert1 ( c - > uvstride == uvstride ) ; c - > penalty_factor = get_penalty_factor ( s - > lambda , s - > lambda2 , c - > avctx - > me_cmp ) ; c - > sub_penalty_factor= get_penalty_factor ( s - > lambda , s - > lambda2 , c - > avctx - > me_sub_cmp ) ; c - > mb_penalty_factor = get_penalty_factor ( s - > lambda , s - > lambda2 , c - > avctx - > mb_cmp ) ; c - > current_mv_penalty= c - > mv_penalty[s - > m . f_code=1] + MAX_MV ; c - > xmin = - x * block_w - 16 + 3 ; c - > ymin = - y * block_w - 16 + 3 ; c - > xmax = - ( x + 1 ) * block_w + ( w < < ( LOG2_MB_SIZE - s - > block_max_depth ) ) + 16 - 3 ; c - > ymax = - ( y + 1 ) * block_w + ( h < < ( LOG2_MB_SIZE - s - > block_max_depth ) ) + 16 - 3 ; if ( P_LEFT[0] > ( c - > xmax < < shift ) ) P_LEFT[0] = ( c - > xmax < < shift ) ; if ( P_LEFT[1] > ( c - > ymax < < shift ) ) P_LEFT[1] = ( c - > ymax < < shift ) ; if ( P_TOP[0] > ( c - > xmax < < shift ) ) P_TOP[0] = ( c - > xmax < < shift ) ; if ( P_TOP[1] > ( c - > ymax < < shift ) ) P_TOP[1] = ( c - > ymax < < shift ) ; if ( P_TOPRIGHT[0] < ( c - > xmin < < shift ) ) P_TOPRIGHT[0]= ( c - > xmin < < shift ) ; if ( P_TOPRIGHT[0] > ( c - > xmax < < shift ) ) P_TOPRIGHT[0]= ( c - > xmax < < shift ) ; //due to pmx no clip if ( P_TOPRIGHT[1] > ( c - > ymax < < shift ) ) P_TOPRIGHT[1]= ( c - > ymax < < shift ) ; P_MEDIAN[0]= mid_pred ( P_LEFT[0] , P_TOP[0] , P_TOPRIGHT[0] ) ; P_MEDIAN[1]= mid_pred ( P_LEFT[1] , P_TOP[1] , P_TOPRIGHT[1] ) ; if ( ! y ) { c - > pred_x= P_LEFT[0] ; c - >",0
"static inline int decode_cabac_mb_transform_size ( H264Context * h ) { return get_cabac ( & h - > cabac , & h - > cabac_state[399 + h - > neighbor_transform_size] ) ; }",0
"static av_always_inline void filter_mb_dir ( const H264Context * h , H264SliceContext * sl , int mb_x , int mb_y , uint8_t * img_y , uint8_t * img_cb , uint8_t * img_cr , unsigned int linesize , unsigned int uvlinesize , int mb_xy , int mb_type , int mvy_limit , int first_vertical_edge_done , int a , int b , int chroma , int dir ) { int edge ; int chroma_qp_avg[2] ; int chroma444 = CHROMA444 ( h ) ; int chroma422 = CHROMA422 ( h ) ; const int mbm_xy = dir == 0 ? mb_xy - 1 : sl - > top_mb_xy ; const int mbm_type = dir == 0 ? sl - > left_type[LTOP] : sl - > top_type ; // how often to recheck mv - based bS when iterating between edges static const uint8_t mask_edge_tab[2][8]= { { 0 , 3 , 3 , 3 , 1 , 1 , 1 , 1 } , { 0 , 3 , 1 , 1 , 3 , 3 , 3 , 3 } } ; const int mask_edge = mask_edge_tab[dir][ ( mb_type > > 3 ) & 7] ; const int edges = mask_edge== 3 & & ! ( sl - > cbp & 15 ) ? 1 : 4 ; // how often to recheck mv - based bS when iterating along each edge const int mask_par0 = mb_type & ( MB_TYPE_16x16 | ( MB_TYPE_8x16 > > dir ) ) ; if ( mbm_type & & ! first_vertical_edge_done ) { if ( FRAME_MBAFF ( h ) & & ( dir == 1 ) & & ( ( mb_y & 1 ) == 0 ) & & IS_INTERLACED ( mbm_type & mb_type ) ) { // This is a special case in the norm where the filtering must // be done twice ( one each of the field ) even if we are in a // frame macroblock . // unsigned int tmp_linesize = 2 * linesize ; unsigned int tmp_uvlinesize = 2 * uvlinesize ; int mbn_xy = mb_xy - 2 * h - > mb_stride ; int j ; for ( j=0 ; j < 2 ; j + + , mbn_xy + = h - > mb_stride ) { DECLARE_ALIGNED ( 8 , int16_t , bS ) [4] ; int qp ; if ( IS_INTRA ( mb_type | h - > cur_pic . mb_type[mbn_xy] ) ) { AV_WN64A ( bS , 0x0003000300030003ULL ) ; } else { if ( ! CABAC ( h ) & & IS_8x8DCT ( h - > cur_pic . mb_type[mbn_xy] ) ) { bS[0]= 1 + ( ( h - > cbp_table[mbn_xy] & 0x4000 ) || sl - > non_zero_count_cache[scan8[0] + 0] ) ; bS[1]= 1 + ( ( h - > cbp_table[mbn_xy] & 0x4000 ) || sl - > non_zero_count_cache[scan8[0] + 1] ) ; bS[2]= 1 + ( ( h - > cbp_table[mbn_xy] & 0x8000 ) || sl - > non_zero_count_cache[scan8[0] + 2] ) ; bS[3]= 1 + ( ( h - > cbp_table[mbn_xy] & 0x8000 ) || sl - > non_zero_count_cache[scan8[0] + 3] ) ; } else { const uint8_t * mbn_nnz = h - > non_zero_count[mbn_xy] + 3 * 4 ; int i ; for ( i = 0 ; i < 4 ; i + + ) { bS[i] = 1 + ! ! ( sl - > non_zero_count_cache[scan8[0] + i] | mbn_nnz[i] ) ; } } } // Do not use s - > qscale as luma quantizer because it has not the same // value in IPCM macroblocks . qp = ( h - > cur_pic . qscale_table[mb_xy] + h - > cur_pic . qscale_table[mbn_xy] + 1 ) > > 1 ; ff_tlog ( h - > avctx , filter mb : %d/%d dir : %d edge : %d , QPy : %d ls : %d uvls : %d , mb_x , mb_y , dir , edge , qp , tmp_linesize , tmp_uvlinesize ) ; { int i ; for ( i = 0 ; i < 4 ; i + + ) ff_tlog ( h - > avctx , bS[%d] : %d , i , bS[i] ) ; ff_tlog ( h - > avctx , \n ) ; } filter_mb_edgeh ( & img_y[j * linesize] , tmp_linesize , bS , qp , a , b , h , 0 ) ; chroma_qp_avg[0] = ( sl - > chroma_qp[0] + get_chroma_qp ( h - > ps . pps , 0 , h - > cur_pic . qscale_table[mbn_xy] ) + 1 ) > > 1 ; chroma_qp_avg[1] = ( sl - > chroma_qp[1] + get_chroma_qp ( h - > ps . pps , 1 , h - > cur_pic . qscale_table[mbn_xy] ) + 1 ) > > 1 ; if ( chroma ) { if ( chroma444 ) { filter_mb_edgeh ( & img_cb[j * uvlinesize] , tmp_uvlinesize , bS , chroma_qp_avg[0] , a , b , h , 0 ) ; filter_mb_edgeh ( & img_cr[j * uvlinesize] , tmp_uvlinesize , bS , chroma_qp_avg[1] , a , b , h , 0 ) ; } else { filter_mb_edgech ( & img_cb[j * uvlinesize] , tmp_uvlinesize , bS , chroma_qp_avg[0] , a , b , h , 0 ) ; filter_mb_edgech ( & img_cr[j * uvlinesize] , tmp_uvlinesize , bS , chroma_qp_avg[1] , a , b , h , 0 ) ; } } } } else { DECLARE_ALIGNED ( 8 , int16_t , bS ) [4] ; int qp ; if ( IS_INTRA ( mb_type|mbm_type ) ) { AV_WN64A ( bS , 0x0003000300030003ULL ) ; if ( ( ! IS_INTERLACED ( mb_type|mbm_type ) ) || ( ( FRAME_MBAFF ( h ) || ( h - > picture_structure ! = PICT_FRAME ) ) & & ( dir == 0 ) ) ) AV_WN64A ( bS , 0x0004000400040004ULL ) ; } else { int i ; int mv_done ; if ( dir & & FRAME_MBAFF ( h ) & & IS_INTERLACED ( mb_type mbm_type ) ) { AV_WN64A ( bS , 0x0001000100010001ULL ) ; mv_done = 1 ; } else if ( mask_par0 & & ( ( mbm_type & ( MB_TYPE_16x16 | ( MB_TYPE_8x16 > > dir ) ) ) ) ) { int b_idx= 8 + 4 ; int bn_idx= b_idx - ( dir ? 8 : 1 ) ; bS[0] = bS[1] = bS[2] = bS[3] = check_mv ( sl , 8 + 4 , bn_idx , mvy_limit ) ; mv_done = 1 ; } else mv_done = 0 ; for ( i = 0 ; i < 4 ; i + + ) { int x = dir == 0 ? 0 : i ; int y = dir == 0 ? i : 0 ; int b_idx= 8 + 4 + x + 8 * y ; int bn_idx= b_idx - ( dir ? 8 : 1 ) ; if ( sl - > non_zero_count_cache[b_idx] | sl - > non_zero_count_cache[bn_idx] ) { bS[i] = 2 ; } else if ( ! mv_done ) { bS[i] = check_mv ( sl , b_idx , bn_idx , mvy_limit ) ; } } } / * Filter edge * / // Do not use s - > qscale as",1
"int ff_h263_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , const uint8_t * buf , int buf_size ) { MpegEncContext * s = avctx - > priv_data ; int ret ; AVFrame * pict = data ; ifdef PRINT_FRAME_TIME uint64_t time= rdtsc ( ) ; endif ifdef DEBUG av_log ( avctx , AV_LOG_DEBUG , * * * * * frame %d size=%d\n , avctx - > frame_number , buf_size ) ; if ( buf_size > 0 ) av_log ( avctx , AV_LOG_DEBUG , bytes=%x %x %x %x\n , buf[0] , buf[1] , buf[2] , buf[3] ) ; endif s - > flags= avctx - > flags ; s - > flags2= avctx - > flags2 ; / * no supplementary picture * / if ( buf_size == 0 ) { / * special case for last picture * / if ( s - > low_delay==0 & & s - > next_picture_ptr ) { * pict= * ( AVFrame * ) s - > next_picture_ptr ; s - > next_picture_ptr= NULL ; * data_size = sizeof ( AVFrame ) ; } return 0 ; } if ( s - > flags & CODEC_FLAG_TRUNCATED ) { int next ; if ( CONFIG_MPEG4_DECODER & & s - > codec_id==CODEC_ID_MPEG4 ) { next= ff_mpeg4_find_frame_end ( & s - > parse_context , buf , buf_size ) ; } else if ( CONFIG_H263_DECODER & & s - > codec_id==CODEC_ID_H263 ) { next= ff_h263_find_frame_end ( & s - > parse_context , buf , buf_size ) ; } else { av_log ( s - > avctx , AV_LOG_ERROR , this codec does not support truncated bitstreams\n ) ; return - 1 ; } if ( ff_combine_frame ( & s - > parse_context , next , ( const uint8_t * * ) & buf , & buf_size ) < 0 ) return buf_size ; } retry : if ( s - > bitstream_buffer_size & & ( s - > divx_packed || buf_size < 20 ) ) { //divx 5 . 01 + /xvid frame reorder init_get_bits ( & s - > gb , s - > bitstream_buffer , s - > bitstream_buffer_size * 8 ) ; } else init_get_bits ( & s - > gb , buf , buf_size * 8 ) ; s - > bitstream_buffer_size=0 ; if ( ! s - > context_initialized ) { if ( MPV_common_init ( s ) < 0 ) //we need the idct permutaton for reading a custom matrix return - 1 ; } / * We need to set current_picture_ptr before reading the header , * otherwise we cannot store anyting in there * / if ( s - > current_picture_ptr==NULL || s - > current_picture_ptr - > data[0] ) { int i= ff_find_unused_picture ( s , 0 ) ; s - > current_picture_ptr= & s - > picture[i] ; } / * let ' s go : - ) * / if ( CONFIG_WMV2_DECODER & & s - > msmpeg4_version==5 ) { ret= ff_wmv2_decode_picture_header ( s ) ; } else if ( CONFIG_MSMPEG4_DECODER & & s - > msmpeg4_version ) { ret = msmpeg4_decode_picture_header ( s ) ; } else if ( s - > h263_pred ) { if ( s - > avctx - > extradata_size & & s - > picture_number==0 ) { GetBitContext gb ; init_get_bits ( & gb , s - > avctx - > extradata , s - > avctx - > extradata_size * 8 ) ; ret = ff_mpeg4_decode_picture_header ( s , & gb ) ; } ret = ff_mpeg4_decode_picture_header ( s , & s - > gb ) ; } else if ( s - > codec_id == CODEC_ID_H263I ) { ret = intel_h263_decode_picture_header ( s ) ; } else if ( s - > h263_flv ) { ret = flv_h263_decode_picture_header ( s ) ; } else { ret = h263_decode_picture_header ( s ) ; } if ( ret==FRAME_SKIPPED ) return get_consumed_bytes ( s , buf_size ) ; / * skip if the header was thrashed * / if ( ret < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , header damaged\n ) ; return - 1 ; } avctx - > has_b_frames= ! s - > low_delay ; if ( s - > xvid_build==0 & & s - > divx_version==0 & & s - > lavc_build==0 ) { if ( s - > stream_codec_tag == AV_RL32 ( XVID ) || s - > codec_tag == AV_RL32 ( XVID ) || s - > codec_tag == AV_RL32 ( XVIX ) || s - > codec_tag == AV_RL32 ( RMP4 ) ) s - > xvid_build= - 1 ; if 0 if ( s - > codec_tag == AV_RL32 ( DIVX ) & & s - > vo_type==0 & & s - > vol_control_parameters==1 & & s - > padding_bug_score > 0 & & s - > low_delay ) // XVID with modified fourcc s - > xvid_build= - 1 ; endif } if ( s - > xvid_build==0 & & s - > divx_version==0 & & s - > lavc_build==0 ) { if ( s - > codec_tag == AV_RL32 ( DIVX ) & & s - > vo_type==0 & & s - > vol_control_parameters==0 ) s - > divx_version= 400 ; //divx 4 } if ( s - > xvid_build & & s - > divx_version ) { s - > divx_version= s - > divx_build= 0 ; } if ( s - > workaround_bugs & FF_BUG_AUTODETECT ) { if ( s - > codec_tag == AV_RL32 ( XVIX ) ) s - > workaround_bugs|= FF_BUG_XVID_ILACE ; if ( s - > codec_tag == AV_RL32 ( UMP4 ) ) { s - > workaround_bugs|= FF_BUG_UMP4 ; } if ( s - > divx_version > =500 & & s - > divx_build < 1814 ) { s - > workaround_bugs|= FF_BUG_QPEL_CHROMA ; } if ( s - > divx_version > 502 & & s - > divx_build < 1814 ) { s - > workaround_bugs|= FF_BUG_QPEL_CHROMA2 ; } if ( s - > xvid_build & & s - > xvid_build < =3 ) s - > padding_bug_score= 256 * 256 * 256 * 64 ; if ( s - > xvid_build & & s - > xvid_build < =1 ) s - > workaround_bugs|= FF_BUG_QPEL_CHROMA ; if ( s - > xvid_build & & s - > xvid_build < =12 ) s - > workaround_bugs|= FF_BUG_EDGE ; if ( s - > xvid_build & & s - > xvid_build < =32 ) s - > workaround_bugs|= FF_BUG_DC_CLIP ; define SET_QPEL_FUNC ( postfix1 , postfix2 ) \ s - > dsp . put_ postfix1 = ff_put_ postfix2 ; \ s - > dsp . put_no_rnd_ postfix1 = ff_put_no_rnd_ postfix2 ; \ s - > dsp . avg_ postfix1 = ff_avg_ postfix2 ; if ( s - > lavc_build & & s - > lavc_build < 4653 ) s - > workaround_bugs|= FF_BUG_STD_QPEL ; if ( s - > lavc_build & & s - > lavc_build < 4655 ) s - > workaround_bugs|= FF_BUG_DIRECT_BLOCKSIZE ; if ( s - > lavc_build & & s - > lavc_build < 4670 ) { s - > workaround_bugs|= FF_BUG_EDGE",0
static av_always_inline int lcg_random ( int previous_val ) { return previous_val * 1664525 + 1013904223 ; },1
"static int open_slave ( AVFormatContext * avf , char * slave , TeeSlave * tee_slave ) { int i , ret ; AVDictionary * options = NULL ; AVDictionaryEntry * entry ; char * filename ; char * format = NULL , * select = NULL ; AVFormatContext * avf2 = NULL ; AVStream * st , * st2 ; int stream_count ; int fullret ; char * subselect = NULL , * next_subselect = NULL , * first_subselect = NULL , * tmp_select = NULL ; if ( ( ret = parse_slave_options ( avf , slave , & options , & filename ) ) < 0 ) return ret ; define STEAL_OPTION ( option , field ) do { \ if ( ( entry = av_dict_get ( options , option , NULL , 0 ) ) ) { \ field = entry - > value ; \ entry - > value = NULL ; / * prevent it from being freed * / \ av_dict_set ( & options , option , NULL , 0 ) ; \ } \ } while ( 0 ) STEAL_OPTION ( f , format ) ; STEAL_OPTION ( select , select ) ; ret = avformat_alloc_output_context2 ( & avf2 , NULL , format , filename ) ; if ( ret < 0 ) goto end ; av_dict_copy ( & avf2 - > metadata , avf - > metadata , 0 ) ; avf2 - > opaque = avf - > opaque ; avf2 - > io_open = avf - > io_open ; avf2 - > io_close = avf - > io_close ; tee_slave - > stream_map = av_calloc ( avf - > nb_streams , sizeof ( * tee_slave - > stream_map ) ) ; if ( ! tee_slave - > stream_map ) { ret = AVERROR ( ENOMEM ) ; goto end ; } stream_count = 0 ; for ( i = 0 ; i < avf - > nb_streams ; i + + ) { st = avf - > streams[i] ; if ( select ) { tmp_select = av_strdup ( select ) ; // av_strtok is destructive so we regenerate it in each loop if ( ! tmp_select ) { ret = AVERROR ( ENOMEM ) ; goto end ; } fullret = 0 ; first_subselect = tmp_select ; next_subselect = NULL ; while ( subselect = av_strtok ( first_subselect , slave_select_sep , & next_subselect ) ) { first_subselect = NULL ; ret = avformat_match_stream_specifier ( avf , avf - > streams[i] , subselect ) ; if ( ret < 0 ) { av_log ( avf , AV_LOG_ERROR , Invalid stream specifier ' %s ' for output ' %s ' \n , subselect , slave ) ; goto end ; } if ( ret ! = 0 ) { fullret = 1 ; // match break ; } } av_freep ( & tmp_select ) ; if ( fullret == 0 ) { / * no match * / tee_slave - > stream_map[i] = - 1 ; continue ; } } tee_slave - > stream_map[i] = stream_count + + ; if ( ! ( st2 = avformat_new_stream ( avf2 , NULL ) ) ) { ret = AVERROR ( ENOMEM ) ; goto end ; } st2 - > id = st - > id ; st2 - > r_frame_rate = st - > r_frame_rate ; st2 - > time_base = st - > time_base ; st2 - > start_time = st - > start_time ; st2 - > duration = st - > duration ; st2 - > nb_frames = st - > nb_frames ; st2 - > disposition = st - > disposition ; st2 - > sample_aspect_ratio = st - > sample_aspect_ratio ; st2 - > avg_frame_rate = st - > avg_frame_rate ; av_dict_copy ( & st2 - > metadata , st - > metadata , 0 ) ; if ( ( ret = avcodec_parameters_copy ( st2 - > codecpar , st - > codecpar ) ) < 0 ) goto end ; } if ( ! ( avf2 - > oformat - > flags & AVFMT_NOFILE ) ) { if ( ( ret = avf2 - > io_open ( avf2 , & avf2 - > pb , filename , AVIO_FLAG_WRITE , NULL ) ) < 0 ) { av_log ( avf , AV_LOG_ERROR , Slave ' %s ' : error opening : %s\n , slave , av_err2str ( ret ) ) ; goto end ; } } if ( ( ret = avformat_write_header ( avf2 , & options ) ) < 0 ) { av_log ( avf , AV_LOG_ERROR , Slave ' %s ' : error writing header : %s\n , slave , av_err2str ( ret ) ) ; goto end ; } tee_slave - > avf = avf2 ; tee_slave - > bsfs = av_calloc ( avf2 - > nb_streams , sizeof ( TeeSlave ) ) ; if ( ! tee_slave - > bsfs ) { ret = AVERROR ( ENOMEM ) ; goto end ; } entry = NULL ; while ( entry = av_dict_get ( options , bsfs , NULL , AV_DICT_IGNORE_SUFFIX ) ) { const char * spec = entry - > key + strlen ( bsfs ) ; if ( * spec ) { if ( strspn ( spec , slave_bsfs_spec_sep ) ! = 1 ) { av_log ( avf , AV_LOG_ERROR , Specifier separator in ' %s ' is ' %c ' , but only characters ' %s ' are allowed\n , entry - > key , * spec , slave_bsfs_spec_sep ) ; return AVERROR ( EINVAL ) ; } spec + + ; / * consume separator * / } for ( i = 0 ; i < avf2 - > nb_streams ; i + + ) { ret = avformat_match_stream_specifier ( avf2 , avf2 - > streams[i] , spec ) ; if ( ret < 0 ) { av_log ( avf , AV_LOG_ERROR , Invalid stream specifier ' %s ' in bsfs option ' %s ' for slave output ' %s ' \n , spec , entry - > key , filename ) ; goto end ; } if ( ret > 0 ) { av_log ( avf , AV_LOG_DEBUG , spec : %s bsfs : %s matches stream %d of slave output ' %s ' \n , spec , entry - > value , i , filename ) ; if ( tee_slave - > bsfs[i] ) { av_log ( avf , AV_LOG_WARNING , Duplicate bsfs specification associated to stream %d of slave output ' %s ' , filters will be ignored\n , i , filename ) ; continue ; } ret = parse_bsfs ( avf , entry - > value , & tee_slave - > bsfs[i] ) ; if ( ret < 0 ) { av_log ( avf , AV_LOG_ERROR , Error parsing bitstream filter sequence ' %s ' associated to stream %d of slave output ' %s ' \n , entry - > value , i , filename ) ; goto end ; } } } av_dict_set ( & options , entry - > key , NULL , 0 ) ; } if ( options ) { entry =",1
"static av_cold int cuvid_decode_init ( AVCodecContext * avctx ) { CuvidContext * ctx = avctx - > priv_data ; AVCUDADeviceContext * device_hwctx ; AVHWDeviceContext * device_ctx ; AVHWFramesContext * hwframe_ctx ; CUVIDPARSERPARAMS cuparseinfo ; CUVIDEOFORMATEX cuparse_ext ; CUVIDSOURCEDATAPACKET seq_pkt ; CUdevice device ; CUcontext cuda_ctx = NULL ; CUcontext dummy ; const AVBitStreamFilter * bsf ; int ret = 0 ; enum AVPixelFormat pix_fmts[3] = { AV_PIX_FMT_CUDA , AV_PIX_FMT_NV12 , AV_PIX_FMT_NONE } ; ret = ff_get_format ( avctx , pix_fmts ) ; if ( ret < 0 ) { av_log ( avctx , AV_LOG_ERROR , ff_get_format failed : %d\n , ret ) ; return ret ; } ctx - > frame_queue = av_fifo_alloc ( MAX_FRAME_COUNT * sizeof ( CUVIDPARSERDISPINFO ) ) ; if ( ! ctx - > frame_queue ) { ret = AVERROR ( ENOMEM ) ; goto error ; } avctx - > pix_fmt = ret ; if ( avctx - > hw_frames_ctx ) { ctx - > hwframe = av_buffer_ref ( avctx - > hw_frames_ctx ) ; if ( ! ctx - > hwframe ) { ret = AVERROR ( ENOMEM ) ; goto error ; } hwframe_ctx = ( AVHWFramesContext * ) ctx - > hwframe - > data ; ctx - > hwdevice = av_buffer_ref ( hwframe_ctx - > device_ref ) ; if ( ! ctx - > hwdevice ) { ret = AVERROR ( ENOMEM ) ; goto error ; } device_ctx = hwframe_ctx - > device_ctx ; device_hwctx = device_ctx - > hwctx ; cuda_ctx = device_hwctx - > cuda_ctx ; } else { ctx - > hwdevice = av_hwdevice_ctx_alloc ( AV_HWDEVICE_TYPE_CUDA ) ; if ( ! ctx - > hwdevice ) { av_log ( avctx , AV_LOG_ERROR , Error allocating hwdevice\n ) ; ret = AVERROR ( ENOMEM ) ; goto error ; } ret = CHECK_CU ( cuInit ( 0 ) ) ; if ( ret < 0 ) goto error ; ret = CHECK_CU ( cuDeviceGet ( & device , 0 ) ) ; if ( ret < 0 ) goto error ; ret = CHECK_CU ( cuCtxCreate ( & cuda_ctx , CU_CTX_SCHED_BLOCKING_SYNC , device ) ) ; if ( ret < 0 ) goto error ; device_ctx = ( AVHWDeviceContext * ) ctx - > hwdevice - > data ; device_ctx - > free = cuvid_ctx_free ; device_hwctx = device_ctx - > hwctx ; device_hwctx - > cuda_ctx = cuda_ctx ; ret = CHECK_CU ( cuCtxPopCurrent ( & dummy ) ) ; if ( ret < 0 ) goto error ; ret = av_hwdevice_ctx_init ( ctx - > hwdevice ) ; if ( ret < 0 ) { av_log ( avctx , AV_LOG_ERROR , av_hwdevice_ctx_init failed\n ) ; goto error ; } ctx - > hwframe = av_hwframe_ctx_alloc ( ctx - > hwdevice ) ; if ( ! ctx - > hwframe ) { av_log ( avctx , AV_LOG_ERROR , av_hwframe_ctx_alloc failed\n ) ; ret = AVERROR ( ENOMEM ) ; goto error ; } } memset ( & cuparseinfo , 0 , sizeof ( cuparseinfo ) ) ; memset ( & cuparse_ext , 0 , sizeof ( cuparse_ext ) ) ; memset ( & seq_pkt , 0 , sizeof ( seq_pkt ) ) ; cuparseinfo . pExtVideoInfo = & cuparse_ext ; switch ( avctx - > codec - > id ) { if CONFIG_H264_CUVID_DECODER case AV_CODEC_ID_H264 : cuparseinfo . CodecType = cudaVideoCodec_H264 ; if CONFIG_HEVC_CUVID_DECODER case AV_CODEC_ID_HEVC : cuparseinfo . CodecType = cudaVideoCodec_HEVC ; if CONFIG_MJPEG_CUVID_DECODER case AV_CODEC_ID_MJPEG : cuparseinfo . CodecType = cudaVideoCodec_JPEG ; if CONFIG_MPEG1_CUVID_DECODER case AV_CODEC_ID_MPEG1VIDEO : cuparseinfo . CodecType = cudaVideoCodec_MPEG1 ; if CONFIG_MPEG2_CUVID_DECODER case AV_CODEC_ID_MPEG2VIDEO : cuparseinfo . CodecType = cudaVideoCodec_MPEG2 ; if CONFIG_MPEG4_CUVID_DECODER case AV_CODEC_ID_MPEG4 : if CONFIG_VP8_CUVID_DECODER case AV_CODEC_ID_VP8 : cuparseinfo . CodecType = cudaVideoCodec_VP8 ; if CONFIG_VP9_CUVID_DECODER case AV_CODEC_ID_VP9 : cuparseinfo . CodecType = cudaVideoCodec_VP9 ; if CONFIG_VC1_CUVID_DECODER case AV_CODEC_ID_VC1 : cuparseinfo . CodecType = cudaVideoCodec_VC1 ; default : av_log ( avctx , AV_LOG_ERROR , Invalid CUVID codec ! \n ) ; return AVERROR_BUG ; } if ( avctx - > codec - > id == AV_CODEC_ID_H264 || avctx - > codec - > id == AV_CODEC_ID_HEVC ) { if ( avctx - > codec - > id == AV_CODEC_ID_H264 ) bsf = av_bsf_get_by_name ( h264_mp4toannexb ) ; else bsf = av_bsf_get_by_name ( hevc_mp4toannexb ) ; if ( ! bsf ) { ret = AVERROR_BSF_NOT_FOUND ; goto error ; } if ( ret = av_bsf_alloc ( bsf , & ctx - > bsf ) ) { goto error ; } if ( ( ( ret = avcodec_parameters_from_context ( ctx - > bsf - > par_in , avctx ) ) < 0 ) || ( ( ret = av_bsf_init ( ctx - > bsf ) ) < 0 ) ) { av_bsf_free ( & ctx - > bsf ) ; goto error ; } cuparse_ext . format . seqhdr_data_length = ctx - > bsf - > par_out - > extradata_size ; memcpy ( cuparse_ext . raw_seqhdr_data , ctx - > bsf - > par_out - > extradata , FFMIN ( sizeof ( cuparse_ext . raw_seqhdr_data ) , ctx - > bsf - > par_out - > extradata_size ) ) ; } else if ( avctx - > extradata_size > 0 ) { cuparse_ext . format . seqhdr_data_length = avctx - > extradata_size ; memcpy ( cuparse_ext . raw_seqhdr_data , avctx - > extradata , FFMIN ( sizeof ( cuparse_ext . raw_seqhdr_data ) , avctx - > extradata_size ) ) ; } cuparseinfo . ulMaxNumDecodeSurfaces = MAX_FRAME_COUNT ; cuparseinfo . ulMaxDisplayDelay = 4 ; cuparseinfo . pUserData = avctx ; cuparseinfo . pfnSequenceCallback = cuvid_handle_video_sequence ; cuparseinfo . pfnDecodePicture = cuvid_handle_picture_decode ; cuparseinfo . pfnDisplayPicture = cuvid_handle_picture_display ; ret = CHECK_CU ( cuCtxPushCurrent ( cuda_ctx ) ) ; if ( ret < 0 ) goto error ; ret = cuvid_test_dummy_decoder ( avctx , & cuparseinfo ) ; if ( ret < 0 ) goto error ; ret = CHECK_CU ( cuvidCreateVideoParser ( & ctx - > cuparser , & cuparseinfo ) ) ; if ( ret < 0 ) goto error ; seq_pkt . payload = cuparse_ext . raw_seqhdr_data ; seq_pkt . payload_size = cuparse_ext . format . seqhdr_data_length ; if ( seq_pkt . payload & & seq_pkt . payload_size ) { ret = CHECK_CU ( cuvidParseVideoData ( ctx - > cuparser , & seq_pkt ) ) ; if ( ret < 0 ) goto error ; } ret = CHECK_CU ( cuCtxPopCurrent ( & dummy ) ) ; if ( ret < 0 ) goto error ; return 0 ; error : cuvid_decode_end ( avctx ) ; return ret ; }",1
"static void fill_scaling_lists ( const AVCodecContext * avctx , AVDXVAContext * ctx , const H264Context * h , DXVA_Qmatrix_H264 * qm ) { unsigned i , j ; memset ( qm , 0 , sizeof ( * qm ) ) ; if ( DXVA_CONTEXT_WORKAROUND ( avctx , ctx ) & FF_DXVA2_WORKAROUND_SCALING_LIST_ZIGZAG ) { for ( i = 0 ; i < 6 ; i + + ) for ( j = 0 ; j < 16 ; j + + ) qm - > bScalingLists4x4[i][j] = h - > pps . scaling_matrix4[i][j] ; for ( i = 0 ; i < 64 ; i + + ) { qm - > bScalingLists8x8[0][i] = h - > pps . scaling_matrix8[0][i] ; qm - > bScalingLists8x8[1][i] = h - > pps . scaling_matrix8[3][i] ; } } else { for ( i = 0 ; i < 6 ; i + + ) for ( j = 0 ; j < 16 ; j + + ) qm - > bScalingLists4x4[i][j] = h - > pps . scaling_matrix4[i][ff_zigzag_scan[j]] ; for ( i = 0 ; i < 64 ; i + + ) { qm - > bScalingLists8x8[0][i] = h - > pps . scaling_matrix8[0][ff_zigzag_direct[i]] ; qm - > bScalingLists8x8[1][i] = h - > pps . scaling_matrix8[3][ff_zigzag_direct[i]] ; } } }",0
"static int tcp_wait_fd ( int fd , int write ) { int ev = write ? POLLOUT : POLLIN ; struct pollfd p = { . fd = fd , . events = ev , . revents = 0 } ; int ret ; ret = poll ( & p , 1 , 100 ) ; return ret < 0 ? ff_neterrno ( ) : p . revents & ev ? 0 : AVERROR ( EAGAIN ) ; }",0
"static int file_check ( URLContext * h , int mask ) { if HAVE_ACCESS & & defined ( R_OK ) int ret = 0 ; if ( access ( h - > filename , F_OK ) < 0 ) return AVERROR ( errno ) ; if ( mask & AVIO_FLAG_READ ) if ( access ( h - > filename , R_OK ) > = 0 ) ret |= AVIO_FLAG_READ ; if ( mask & AVIO_FLAG_WRITE ) if ( access ( h - > filename , W_OK ) > = 0 ) ret |= AVIO_FLAG_WRITE ; else struct stat st ; int ret = stat ( h - > filename , & st ) ; if ( ret < 0 ) return AVERROR ( errno ) ; ret |= st . st_mode & S_IRUSR ? mask & AVIO_FLAG_READ : 0 ; ret |= st . st_mode & S_IWUSR ? mask & AVIO_FLAG_WRITE : 0 ; endif return ret ; }",0
"static int rv10_decode_packet ( AVCodecContext * avctx , uint8_t * buf , int buf_size ) { MpegEncContext * s = avctx - > priv_data ; int i , mb_count , mb_pos , left ; init_get_bits ( & s - > gb , buf , buf_size * 8 ) ; if 0 for ( i=0 ; i < buf_size * 8 & & i < 100 ; i + + ) printf ( %d , get_bits1 ( & s - > gb ) ) ; printf ( \n ) ; return 0 ; endif if ( s - > codec_id ==CODEC_ID_RV10 ) mb_count = rv10_decode_picture_header ( s ) ; else mb_count = rv20_decode_picture_header ( s ) ; if ( mb_count < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , HEADER ERROR\n ) ; return - 1 ; } if ( s - > mb_x > = s - > mb_width || s - > mb_y > = s - > mb_height ) { av_log ( s - > avctx , AV_LOG_ERROR , POS ERROR %d %d\n , s - > mb_x , s - > mb_y ) ; return - 1 ; } mb_pos = s - > mb_y * s - > mb_width + s - > mb_x ; left = s - > mb_width * s - > mb_height - mb_pos ; if ( mb_count > left ) { av_log ( s - > avctx , AV_LOG_ERROR , COUNT ERROR\n ) ; return - 1 ; } //if ( s - > pict_type == P_TYPE ) return 0 ; if ( s - > mb_x == 0 & & s - > mb_y == 0 ) { if ( MPV_frame_start ( s , avctx ) < 0 ) return - 1 ; } ifdef DEBUG printf ( qscale=%d\n , s - > qscale ) ; endif / * default quantization values * / if ( s - > codec_id== CODEC_ID_RV10 ) { if ( s - > mb_y==0 ) s - > first_slice_line=1 ; } else { s - > first_slice_line=1 ; s - > resync_mb_x= s - > mb_x ; s - > resync_mb_y= s - > mb_y ; } if ( s - > h263_aic ) { s - > y_dc_scale_table= s - > c_dc_scale_table= ff_aic_dc_scale_table ; } else { s - > y_dc_scale_table= s - > c_dc_scale_table= ff_mpeg1_dc_scale_table ; } s - > y_dc_scale= s - > y_dc_scale_table[ s - > qscale ] ; s - > c_dc_scale= s - > c_dc_scale_table[ s - > qscale ] ; s - > rv10_first_dc_coded[0] = 0 ; s - > rv10_first_dc_coded[1] = 0 ; s - > rv10_first_dc_coded[2] = 0 ; s - > block_wrap[0]= s - > block_wrap[1]= s - > block_wrap[2]= s - > block_wrap[3]= s - > mb_width * 2 + 2 ; s - > block_wrap[4]= s - > block_wrap[5]= s - > mb_width + 2 ; ff_init_block_index ( s ) ; / * decode each macroblock * / for ( i=0 ; i < mb_count ; i + + ) { int ret ; ff_update_block_index ( s ) ; ifdef DEBUG printf ( * * mb x=%d y=%d\n , s - > mb_x , s - > mb_y ) ; endif s - > dsp . clear_blocks ( s - > block[0] ) ; s - > mv_dir = MV_DIR_FORWARD ; s - > mv_type = MV_TYPE_16X16 ; ret=ff_h263_decode_mb ( s , s - > block ) ; if ( ret == SLICE_ERROR ) { av_log ( s - > avctx , AV_LOG_ERROR , ERROR at MB %d %d\n , s - > mb_x , s - > mb_y ) ; return - 1 ; } ff_h263_update_motion_val ( s ) ; MPV_decode_mb ( s , s - > block ) ; if ( + + s - > mb_x == s - > mb_width ) { s - > mb_x = 0 ; s - > mb_y + + ; ff_init_block_index ( s ) ; } if ( s - > mb_x == s - > resync_mb_x ) s - > first_slice_line=0 ; if ( ret == SLICE_END ) break ; } return buf_size ; }",0
"static int decode_tag ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; NellyMoserDecodeContext * s = avctx - > priv_data ; int blocks , i ; int16_t * samples ; * data_size = 0 ; samples = ( int16_t * ) data ; if ( buf_size < avctx - > block_align ) return buf_size ; if ( buf_size % 64 ) { av_log ( avctx , AV_LOG_ERROR , Tag size %d . \n , buf_size ) ; return buf_size ; } blocks = buf_size / 64 ; / * Normal numbers of blocks for sample rates : * 8000 Hz - 1 * 11025 Hz - 2 * 16000 Hz - 3 * 22050 Hz - 4 * 44100 Hz - 8 * / for ( i=0 ; i < blocks ; i + + ) { nelly_decode_block ( s , & buf[i * NELLY_BLOCK_LEN] , s - > float_buf ) ; s - > fmt_conv . float_to_int16 ( & samples[i * NELLY_SAMPLES] , s - > float_buf , NELLY_SAMPLES ) ; * data_size + = NELLY_SAMPLES * sizeof ( int16_t ) ; } return buf_size ; }",0
"static void RENAME ( extract_even ) ( const uint8_t * src , uint8_t * dst , x86_reg count ) { dst + = count ; src + = 2 * count ; count= - count ; if COMPILE_TEMPLATE_MMX if ( count < = - 16 ) { count + = 15 ; __asm__ volatile ( pcmpeqw %%mm7 , %%mm7 \n\t psrlw 8 , %%mm7 \n\t 1 : \n\t movq - 30 ( %1 , %0 , 2 ) , %%mm0 \n\t movq - 22 ( %1 , %0 , 2 ) , %%mm1 \n\t movq - 14 ( %1 , %0 , 2 ) , %%mm2 \n\t movq - 6 ( %1 , %0 , 2 ) , %%mm3 \n\t pand %%mm7 , %%mm0 \n\t pand %%mm7 , %%mm1 \n\t pand %%mm7 , %%mm2 \n\t pand %%mm7 , %%mm3 \n\t packuswb %%mm1 , %%mm0 \n\t packuswb %%mm3 , %%mm2 \n\t MOVNTQ %%mm0 , - 15 ( %2 , %0 ) \n\t MOVNTQ %%mm2 , - 7 ( %2 , %0 ) \n\t add 16 , %0 \n\t js 1b \n\t : + r ( count ) : r ( src ) , r ( dst ) ) ; count - = 15 ; } endif while ( count < 0 ) { dst[count]= src[2 * count] ; count + + ; } }",0
"static void intra_predict_horiz_16x16_msa ( uint8_t * src , int32_t src_stride , uint8_t * dst , int32_t dst_stride ) { uint32_t row ; uint8_t inp0 , inp1 , inp2 , inp3 ; v16u8 src0 , src1 , src2 , src3 ; for ( row = 4 ; row - - ; ) { inp0 = src[0] ; src + = src_stride ; inp1 = src[0] ; src + = src_stride ; inp2 = src[0] ; src + = src_stride ; inp3 = src[0] ; src + = src_stride ; src0 = ( v16u8 ) __msa_fill_b ( inp0 ) ; src1 = ( v16u8 ) __msa_fill_b ( inp1 ) ; src2 = ( v16u8 ) __msa_fill_b ( inp2 ) ; src3 = ( v16u8 ) __msa_fill_b ( inp3 ) ; ST_UB4 ( src0 , src1 , src2 , src3 , dst , dst_stride ) ; dst + = ( 4 * dst_stride ) ; } }",0
"int av_image_check_sar ( unsigned int w , unsigned int h , AVRational sar ) { int64_t scaled_dim ; if ( ! sar . den ) return AVERROR ( EINVAL ) ; if ( ! sar . num || sar . num == sar . den ) return 0 ; if ( sar . num < sar . den ) scaled_dim = av_rescale_rnd ( w , sar . num , sar . den , AV_ROUND_ZERO ) ; else scaled_dim = av_rescale_rnd ( h , sar . den , sar . num , AV_ROUND_ZERO ) ; if ( scaled_dim > 0 ) return 0 ; return AVERROR ( EINVAL ) ; }",1
"int read_file ( const char * filename , char * * bufptr , size_t * size ) { FILE * f = fopen ( filename , rb ) ; if ( ! f ) { av_log ( NULL , AV_LOG_ERROR , Cannot read file ' %s ' : %s\n , filename , strerror ( errno ) ) ; return AVERROR ( errno ) ; } fseek ( f , 0 , SEEK_END ) ; * size = ftell ( f ) ; fseek ( f , 0 , SEEK_SET ) ; * bufptr = av_malloc ( * size + 1 ) ; if ( ! * bufptr ) { av_log ( NULL , AV_LOG_ERROR , Could not allocate file buffer\n ) ; fclose ( f ) ; return AVERROR ( ENOMEM ) ; } fread ( * bufptr , 1 , * size , f ) ; ( * bufptr ) [ * size + + ] = ' \0 ' ; fclose ( f ) ; return 0 ; }",0
"int64_t ff_gen_search ( AVFormatContext * s , int stream_index , int64_t target_ts , int64_t pos_min , int64_t pos_max , int64_t pos_limit , int64_t ts_min , int64_t ts_max , int flags , int64_t * ts_ret , int64_t ( * read_timestamp ) ( struct AVFormatContext * , int , int64_t * , int64_t ) ) { int64_t pos , ts ; int64_t start_pos , filesize ; int no_change ; av_dlog ( s , gen_seek : %d %s\n , stream_index , av_ts2str ( target_ts ) ) ; if ( ts_min == AV_NOPTS_VALUE ) { pos_min = s - > data_offset ; ts_min = ff_read_timestamp ( s , stream_index , & pos_min , INT64_MAX , read_timestamp ) ; if ( ts_min == AV_NOPTS_VALUE ) return - 1 ; } if ( ts_min > = target_ts ) { * ts_ret= ts_min ; return pos_min ; } if ( ts_max == AV_NOPTS_VALUE ) { int step= 1024 ; filesize = avio_size ( s - > pb ) ; pos_max = filesize - 1 ; do { pos_max = FFMAX ( 0 , pos_max - step ) ; ts_max = ff_read_timestamp ( s , stream_index , & pos_max , pos_max + step , read_timestamp ) ; step + = step ; } while ( ts_max == AV_NOPTS_VALUE & & pos_max > 0 ) ; if ( ts_max == AV_NOPTS_VALUE ) return - 1 ; for ( ; ; ) { int64_t tmp_pos= pos_max + 1 ; int64_t tmp_ts= ff_read_timestamp ( s , stream_index , & tmp_pos , INT64_MAX , read_timestamp ) ; if ( tmp_ts == AV_NOPTS_VALUE ) break ; ts_max= tmp_ts ; pos_max= tmp_pos ; if ( tmp_pos > = filesize ) break ; } pos_limit= pos_max ; } if ( ts_max < = target_ts ) { * ts_ret= ts_max ; return pos_max ; } if ( ts_min > ts_max ) { return - 1 ; } else if ( ts_min == ts_max ) { pos_limit= pos_min ; } no_change=0 ; while ( pos_min < pos_limit ) { av_dlog ( s , pos_min=0x% PRIx64 pos_max=0x% PRIx64 dts_min=%s dts_max=%s\n , pos_min , pos_max , av_ts2str ( ts_min ) , av_ts2str ( ts_max ) ) ; assert ( pos_limit < = pos_max ) ; if ( no_change==0 ) { int64_t approximate_keyframe_distance= pos_max - pos_limit ; // interpolate position ( better than dichotomy ) pos = av_rescale ( target_ts - ts_min , pos_max - pos_min , ts_max - ts_min ) + pos_min - approximate_keyframe_distance ; } else if ( no_change==1 ) { // bisection , if interpolation failed to change min or max pos last time pos = ( pos_min + pos_limit ) > > 1 ; } else { / * linear search if bisection failed , can only happen if there are very few or no keyframes between min/max * / pos=pos_min ; } if ( pos < = pos_min ) pos= pos_min + 1 ; else if ( pos > pos_limit ) pos= pos_limit ; start_pos= pos ; ts = ff_read_timestamp ( s , stream_index , & pos , INT64_MAX , read_timestamp ) ; //may pass pos_limit instead of - 1 if ( pos == pos_max ) no_change + + ; else no_change=0 ; av_dlog ( s , % PRId64 % PRId64 % PRId64 / %s %s %s target : %s limit : % PRId64 start : % PRId64 noc : %d\n , pos_min , pos , pos_max , av_ts2str ( ts_min ) , av_ts2str ( ts ) , av_ts2str ( ts_max ) , av_ts2str ( target_ts ) , pos_limit , start_pos , no_change ) ; if ( ts == AV_NOPTS_VALUE ) { av_log ( s , AV_LOG_ERROR , read_timestamp ( ) failed in the middle\n ) ; return - 1 ; } assert ( ts ! = AV_NOPTS_VALUE ) ; if ( target_ts < = ts ) { pos_limit = start_pos - 1 ; pos_max = pos ; ts_max = ts ; } if ( target_ts > = ts ) { pos_min = pos ; ts_min = ts ; } } pos = ( flags & AVSEEK_FLAG_BACKWARD ) ? pos_min : pos_max ; ts = ( flags & AVSEEK_FLAG_BACKWARD ) ? ts_min : ts_max ; if 0 pos_min = pos ; ts_min = ff_read_timestamp ( s , stream_index , & pos_min , INT64_MAX , read_timestamp ) ; pos_min + + ; ts_max = ff_read_timestamp ( s , stream_index , & pos_min , INT64_MAX , read_timestamp ) ; av_dlog ( s , pos=0x% PRIx64 %s < =%s < =%s\n , pos , av_ts2str ( ts_min ) , av_ts2str ( target_ts ) , av_ts2str ( ts_max ) ) ; endif * ts_ret= ts ; return pos ; }",1
"static inline int get_amv ( Mpeg4DecContext * ctx , int n ) { MpegEncContext * s = & ctx - > m ; int x , y , mb_v , sum , dx , dy , shift ; int len = 1 < < ( s - > f_code + 4 ) ; const int a = s - > sprite_warping_accuracy ; if ( s - > workaround_bugs & FF_BUG_AMV ) len > > = s - > quarter_sample ; if ( s - > real_sprite_warping_points == 1 ) { if ( ctx - > divx_version == 500 & & ctx - > divx_build == 413 ) sum = s - > sprite_offset[0][n] / ( 1 < < ( a - s - > quarter_sample ) ) ; else sum = RSHIFT ( s - > sprite_offset[0][n] < < s - > quarter_sample , a ) ; } else { dx = s - > sprite_delta[n][0] ; dy = s - > sprite_delta[n][1] ; shift = ctx - > sprite_shift[0] ; if ( n ) dy - = 1 < < ( shift + a + 1 ) ; else dx - = 1 < < ( shift + a + 1 ) ; mb_v = s - > sprite_offset[0][n] + dx * s - > mb_x * 16 + dy * s - > mb_y * 16 ; sum = 0 ; for ( y = 0 ; y < 16 ; y + + ) { int v ; v = mb_v + dy * y ; // FIXME optimize for ( x = 0 ; x < 16 ; x + + ) { sum + = v > > shift ; v + = dx ; } } sum = RSHIFT ( sum , a + 8 - s - > quarter_sample ) ; } if ( sum < - len ) sum = - len ; else if ( sum > = len ) sum = len - 1 ; return sum ; }",1
"static void decode_gray_bitstream ( HYuvContext * s , int count ) { int i ; OPEN_READER ( re , & s - > gb ) ; count /= 2 ; if ( count > = ( get_bits_left ( & s - > gb ) ) / ( 32 * 2 ) ) { for ( i = 0 ; i < count & & get_bits_left ( & s - > gb ) > 0 ; i + + ) { READ_2PIX ( s - > temp[0][2 * i] , s - > temp[0][2 * i + 1] , 0 ) ; } } else { for ( i = 0 ; i < count ; i + + ) { READ_2PIX ( s - > temp[0][2 * i] , s - > temp[0][2 * i + 1] , 0 ) ; } } CLOSE_READER ( re , & s - > gb ) ; }",1
"static void ready_codebook ( vorbis_enc_codebook * cb ) { int i ; ff_vorbis_len2vlc ( cb - > lens , cb - > codewords , cb - > nentries ) ; if ( ! cb - > lookup ) { cb - > pow2 = cb - > dimentions = NULL ; } else { int vals = cb_lookup_vals ( cb - > lookup , cb - > ndimentions , cb - > nentries ) ; cb - > dimentions = av_malloc ( sizeof ( float ) * cb - > nentries * cb - > ndimentions ) ; cb - > pow2 = av_mallocz ( sizeof ( float ) * cb - > nentries ) ; for ( i = 0 ; i < cb - > nentries ; i + + ) { float last = 0 ; int j ; int div = 1 ; for ( j = 0 ; j < cb - > ndimentions ; j + + ) { int off ; if ( cb - > lookup == 1 ) off = ( i / div ) % vals ; // lookup type 1 else off = i * cb - > ndimentions + j ; // lookup type 2 cb - > dimentions[i * cb - > ndimentions + j] = last + cb - > min + cb - > quantlist[off] * cb - > delta ; if ( cb - > seq_p ) last = cb - > dimentions[i * cb - > ndimentions + j] ; cb - > pow2[i] + = cb - > dimentions[i * cb - > ndimentions + j] * cb - > dimentions[i * cb - > ndimentions + j] ; div * = vals ; } cb - > pow2[i] /= 2 . ; } } }",1
"static int adx_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame_ptr , AVPacket * avpkt ) { int buf_size = avpkt - > size ; ADXContext * c = avctx - > priv_data ; int16_t * samples ; const uint8_t * buf = avpkt - > data ; int num_blocks , ch , ret ; if ( c - > eof ) { * got_frame_ptr = 0 ; return buf_size ; } if ( AV_RB16 ( buf ) == 0x8000 ) { int header_size ; if ( ( ret = avpriv_adx_decode_header ( avctx , buf , buf_size , & header_size , c - > coeff ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , error parsing ADX header\n ) ; } c - > channels = avctx - > channels ; if ( buf_size < header_size ) buf + = header_size ; buf_size - = header_size ; } / * calculate number of blocks in the packet * / num_blocks = buf_size / ( BLOCK_SIZE * c - > channels ) ; / * if the packet is not an even multiple of BLOCK_SIZE , check for an EOF packet * / if ( ! num_blocks || buf_size % ( BLOCK_SIZE * avctx - > channels ) ) { if ( buf_size > = 4 & & ( AV_RB16 ( buf ) & 0x8000 ) ) { c - > eof = 1 ; * got_frame_ptr = 0 ; return avpkt - > size ; } } / * get output buffer * / c - > frame . nb_samples = num_blocks * BLOCK_SAMPLES ; if ( ( ret = avctx - > get_buffer ( avctx , & c - > frame ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed\n ) ; return ret ; } samples = ( int16_t * ) c - > frame . data[0] ; while ( num_blocks - - ) { for ( ch = 0 ; ch < c - > channels ; ch + + ) { if ( adx_decode ( c , samples + ch , buf , ch ) ) { c - > eof = 1 ; buf = avpkt - > data + avpkt - > size ; break ; } buf_size - = BLOCK_SIZE ; buf + = BLOCK_SIZE ; } samples + = BLOCK_SAMPLES * c - > channels ; } * got_frame_ptr = 1 ; * ( AVFrame * ) data = c - > frame ; return buf - avpkt - > data ; }",1
"static int gif_read_image ( GifState * s , AVFrame * frame ) { int left , top , width , height , bits_per_pixel , code_size , flags ; int is_interleaved , has_local_palette , y , pass , y1 , linesize , pal_size ; uint32_t * ptr , * pal , * px , * pr , * ptr1 ; int ret ; uint8_t * idx ; / * At least 9 bytes of Image Descriptor . * / if ( bytestream2_get_bytes_left ( & s - > gb ) < 9 ) return AVERROR_INVALIDDATA ; left = bytestream2_get_le16u ( & s - > gb ) ; top = bytestream2_get_le16u ( & s - > gb ) ; width = bytestream2_get_le16u ( & s - > gb ) ; height = bytestream2_get_le16u ( & s - > gb ) ; flags = bytestream2_get_byteu ( & s - > gb ) ; is_interleaved = flags & 0x40 ; has_local_palette = flags & 0x80 ; bits_per_pixel = ( flags & 0x07 ) + 1 ; av_dlog ( s - > avctx , image x=%d y=%d w=%d h=%d\n , left , top , width , height ) ; if ( has_local_palette ) { pal_size = 1 < < bits_per_pixel ; if ( bytestream2_get_bytes_left ( & s - > gb ) < pal_size * 3 ) return AVERROR_INVALIDDATA ; gif_read_palette ( s , s - > local_palette , pal_size ) ; pal = s - > local_palette ; } else { if ( ! s - > has_global_palette ) { av_log ( s - > avctx , AV_LOG_ERROR , picture doesn ' t have either global or local palette . \n ) ; return AVERROR_INVALIDDATA ; } pal = s - > global_palette ; } if ( s - > keyframe ) { if ( s - > transparent_color_index == - 1 & & s - > has_global_palette ) { / * transparency wasn ' t set before the first frame , fill with background color * / gif_fill ( frame , s - > bg_color ) ; } else { / * otherwise fill with transparent color . * this is necessary since by default picture filled with 0x80808080 . * / gif_fill ( frame , s - > trans_color ) ; } } / * verify that all the image is inside the screen dimensions * / if ( left + width > s - > screen_width || top + height > s - > screen_height ) { av_log ( s - > avctx , AV_LOG_ERROR , image is outside the screen dimensions . \n ) ; return AVERROR_INVALIDDATA ; } if ( width < = 0 || height < = 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , Invalid image dimensions . \n ) ; return AVERROR_INVALIDDATA ; } / * process disposal method * / if ( s - > gce_prev_disposal == GCE_DISPOSAL_BACKGROUND ) { gif_fill_rect ( frame , s - > stored_bg_color , s - > gce_l , s - > gce_t , s - > gce_w , s - > gce_h ) ; } else if ( s - > gce_prev_disposal == GCE_DISPOSAL_RESTORE ) { gif_copy_img_rect ( s - > stored_img , ( uint32_t * ) frame - > data[0] , frame - > linesize[0] / sizeof ( uint32_t ) , s - > gce_l , s - > gce_t , s - > gce_w , s - > gce_h ) ; } s - > gce_prev_disposal = s - > gce_disposal ; if ( s - > gce_disposal ! = GCE_DISPOSAL_NONE ) { s - > gce_l = left ; s - > gce_t = top ; s - > gce_w = width ; s - > gce_h = height ; if ( s - > gce_disposal == GCE_DISPOSAL_BACKGROUND ) { if ( s - > transparent_color_index > = 0 ) s - > stored_bg_color = s - > trans_color ; else s - > stored_bg_color = s - > bg_color ; } else if ( s - > gce_disposal == GCE_DISPOSAL_RESTORE ) { av_fast_malloc ( & s - > stored_img , & s - > stored_img_size , frame - > linesize[0] * frame - > height ) ; if ( ! s - > stored_img ) return AVERROR ( ENOMEM ) ; gif_copy_img_rect ( ( uint32_t * ) frame - > data[0] , s - > stored_img , frame - > linesize[0] / sizeof ( uint32_t ) , left , top , width , height ) ; } } / * Expect at least 2 bytes : 1 for lzw code size and 1 for block size . * / if ( bytestream2_get_bytes_left ( & s - > gb ) < 2 ) return AVERROR_INVALIDDATA ; / * now get the image data * / code_size = bytestream2_get_byteu ( & s - > gb ) ; if ( ( ret = ff_lzw_decode_init ( s - > lzw , code_size , s - > gb . buffer , bytestream2_get_bytes_left ( & s - > gb ) , FF_LZW_GIF ) ) < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , LZW init failed\n ) ; return ret ; } / * read all the image * / linesize = frame - > linesize[0] / sizeof ( uint32_t ) ; ptr1 = ( uint32_t * ) frame - > data[0] + top * linesize + left ; ptr = ptr1 ; pass = 0 ; y1 = 0 ; for ( y = 0 ; y < height ; y + + ) { int count = ff_lzw_decode ( s - > lzw , s - > idx_line , width ) ; if ( count ! = width ) { if ( count ) av_log ( s - > avctx , AV_LOG_ERROR , LZW decode failed\n ) ; goto decode_tail ; } pr = ptr + width ; for ( px = ptr , idx = s - > idx_line ; px < pr ; px + + , idx + + ) { if ( * idx ! = s - > transparent_color_index ) * px = pal[ * idx] ; } if ( is_interleaved ) { switch ( pass ) { default : case 0 : case 1 : y1 + = 8 ; ptr + = linesize * 8 ; if ( y1 > = height ) { y1 = pass ? 2 : 4 ; ptr = ptr1 + linesize * y1 ; pass + + ; } break ; case 2 : y1 + = 4 ; ptr + = linesize * 4 ; if ( y1 > = height ) { y1 = 1 ; ptr = ptr1 + linesize ; pass + + ; } break ; case 3 : y1 + = 2 ; ptr + = linesize * 2 ; break ; } } else { ptr + = linesize ; } } decode_tail : / * read the garbage data until end marker is found * / ff_lzw_decode_tail ( s - > lzw ) ; / * Graphic Control Extension ' s scope is single frame . * Remove its influence . *",1
"static int decode_slice_thread ( AVCodecContext * avctx , void * arg , int jobnr , int threadnr ) { ProresContext * ctx = avctx - > priv_data ; SliceContext * slice = & ctx - > slices[jobnr] ; const uint8_t * buf = slice - > data ; AVFrame * pic = ctx - > frame ; int i , hdr_size , qscale , log2_chroma_blocks_per_mb ; int luma_stride , chroma_stride ; int y_data_size , u_data_size , v_data_size , a_data_size ; uint8_t * dest_y , * dest_u , * dest_v , * dest_a ; int16_t qmat_luma_scaled[64] ; int16_t qmat_chroma_scaled[64] ; int mb_x_shift ; slice - > ret = - 1 ; //av_log ( avctx , AV_LOG_INFO , slice %d mb width %d mb x %d y %d\n , // jobnr , slice - > mb_count , slice - > mb_x , slice - > mb_y ) ; // slice header hdr_size = buf[0] > > 3 ; qscale = av_clip ( buf[1] , 1 , 224 ) ; qscale = qscale > 128 ? qscale - 96 < < 2 : qscale ; y_data_size = AV_RB16 ( buf + 2 ) ; u_data_size = AV_RB16 ( buf + 4 ) ; v_data_size = slice - > data_size - y_data_size - u_data_size - hdr_size ; if ( hdr_size > 7 ) v_data_size = AV_RB16 ( buf + 6 ) ; a_data_size = slice - > data_size - y_data_size - u_data_size - v_data_size - hdr_size ; if ( y_data_size < 0 || u_data_size < 0 || v_data_size < 0 || hdr_size + y_data_size + u_data_size + v_data_size > slice - > data_size ) { av_log ( avctx , AV_LOG_ERROR , invalid plane data size\n ) ; return - 1 ; } buf + = hdr_size ; for ( i = 0 ; i < 64 ; i + + ) { qmat_luma_scaled [i] = ctx - > qmat_luma [i] * qscale ; qmat_chroma_scaled[i] = ctx - > qmat_chroma[i] * qscale ; } if ( ctx - > frame_type == 0 ) { luma_stride = pic - > linesize[0] ; chroma_stride = pic - > linesize[1] ; } else { luma_stride = pic - > linesize[0] < < 1 ; chroma_stride = pic - > linesize[1] < < 1 ; } if ( avctx - > pix_fmt == AV_PIX_FMT_YUV444P10 || avctx - > pix_fmt == AV_PIX_FMT_YUVA444P10 ) { mb_x_shift = 5 ; log2_chroma_blocks_per_mb = 2 ; } else { mb_x_shift = 4 ; log2_chroma_blocks_per_mb = 1 ; } dest_y = pic - > data[0] + ( slice - > mb_y < < 4 ) * luma_stride + ( slice - > mb_x < < 5 ) ; dest_u = pic - > data[1] + ( slice - > mb_y < < 4 ) * chroma_stride + ( slice - > mb_x < < mb_x_shift ) ; dest_v = pic - > data[2] + ( slice - > mb_y < < 4 ) * chroma_stride + ( slice - > mb_x < < mb_x_shift ) ; dest_a = pic - > data[3] + ( slice - > mb_y < < 4 ) * luma_stride + ( slice - > mb_x < < 5 ) ; if ( ctx - > frame_type & & ctx - > first_field ctx - > frame - > top_field_first ) { dest_y + = pic - > linesize[0] ; dest_u + = pic - > linesize[1] ; dest_v + = pic - > linesize[2] ; dest_a + = pic - > linesize[3] ; } decode_slice_luma ( avctx , slice , ( uint16_t * ) dest_y , luma_stride , buf , y_data_size , qmat_luma_scaled ) ; if ( ! ( avctx - > flags & CODEC_FLAG_GRAY ) ) { decode_slice_chroma ( avctx , slice , ( uint16_t * ) dest_u , chroma_stride , buf + y_data_size , u_data_size , qmat_chroma_scaled , log2_chroma_blocks_per_mb ) ; decode_slice_chroma ( avctx , slice , ( uint16_t * ) dest_v , chroma_stride , buf + y_data_size + u_data_size , v_data_size , qmat_chroma_scaled , log2_chroma_blocks_per_mb ) ; } / * decode alpha plane if available * / if ( ctx - > alpha_info & & dest_a & & a_data_size ) decode_slice_alpha ( ctx , ( uint16_t * ) dest_a , luma_stride , buf + y_data_size + u_data_size + v_data_size , a_data_size , slice - > mb_count ) ; slice - > ret = 0 ; return 0 ; }",1
"static void flush_buffered ( AVFormatContext * s1 , int last ) { RTPMuxContext * s = s1 - > priv_data ; if ( s - > buf_ptr ! = s - > buf ) { // If only sending one single NAL unit , skip the aggregation framing if ( s - > buffered_nals == 1 ) ff_rtp_send_data ( s1 , s - > buf + 4 , s - > buf_ptr - s - > buf - 4 , last ) ; else ff_rtp_send_data ( s1 , s - > buf , s - > buf_ptr - s - > buf , last ) ; } s - > buf_ptr = s - > buf ; s - > buffered_nals = 0 ; }",1
"static int vp8_lossy_decode_frame ( AVCodecContext * avctx , AVFrame * p , int * got_frame , uint8_t * data_start , unsigned int data_size ) { WebPContext * s = avctx - > priv_data ; AVPacket pkt ; int ret ; if ( ! s - > initialized ) { ff_vp8_decode_init ( avctx ) ; s - > initialized = 1 ; } avctx - > pix_fmt = s - > has_alpha ? AV_PIX_FMT_YUVA420P : AV_PIX_FMT_YUV420P ; s - > lossless = 0 ; if ( data_size > INT_MAX ) { av_log ( avctx , AV_LOG_ERROR , unsupported chunk size\n ) ; return AVERROR_PATCHWELCOME ; } av_init_packet ( & pkt ) ; pkt . data = data_start ; pkt . size = data_size ; ret = ff_vp8_decode_frame ( avctx , p , got_frame , & pkt ) ; if ( ret < 0 ) return ret ; update_canvas_size ( avctx , avctx - > width , avctx - > height ) ; if ( s - > has_alpha ) { ret = vp8_lossy_decode_alpha ( avctx , p , s - > alpha_data , s - > alpha_data_size ) ; if ( ret < 0 ) return ret ; } return ret ; }",1
"static int pcx_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; PCXContext * const s = avctx - > priv_data ; AVFrame * picture = data ; AVFrame * const p = & s - > picture ; int compressed , xmin , ymin , xmax , ymax ; unsigned int w , h , bits_per_pixel , bytes_per_line , nplanes , stride , y , x , bytes_per_scanline ; uint8_t * ptr ; uint8_t const * bufstart = buf ; uint8_t * scanline ; int ret = - 1 ; if ( buf[0] ! = 0x0a || buf[1] > 5 ) { av_log ( avctx , AV_LOG_ERROR , this is not PCX encoded data\n ) ; return AVERROR_INVALIDDATA ; } compressed = buf[2] ; xmin = AV_RL16 ( buf + 4 ) ; ymin = AV_RL16 ( buf + 6 ) ; xmax = AV_RL16 ( buf + 8 ) ; ymax = AV_RL16 ( buf + 10 ) ; if ( xmax < xmin || ymax < ymin ) { av_log ( avctx , AV_LOG_ERROR , invalid image dimensions\n ) ; return AVERROR_INVALIDDATA ; } w = xmax - xmin + 1 ; h = ymax - ymin + 1 ; bits_per_pixel = buf[3] ; bytes_per_line = AV_RL16 ( buf + 66 ) ; nplanes = buf[65] ; bytes_per_scanline = nplanes * bytes_per_line ; if ( bytes_per_scanline < w * bits_per_pixel * nplanes / 8 ) { av_log ( avctx , AV_LOG_ERROR , PCX data is corrupted\n ) ; return AVERROR_INVALIDDATA ; } switch ( ( nplanes < < 8 ) + bits_per_pixel ) { case 0x0308 : avctx - > pix_fmt = AV_PIX_FMT_RGB24 ; break ; case 0x0108 : case 0x0104 : case 0x0102 : case 0x0101 : case 0x0401 : case 0x0301 : case 0x0201 : avctx - > pix_fmt = AV_PIX_FMT_PAL8 ; break ; default : av_log ( avctx , AV_LOG_ERROR , invalid PCX file\n ) ; return AVERROR_INVALIDDATA ; } buf + = 128 ; if ( p - > data[0] ) avctx - > release_buffer ( avctx , p ) ; if ( av_image_check_size ( w , h , 0 , avctx ) ) return AVERROR_INVALIDDATA ; if ( w ! = avctx - > width || h ! = avctx - > height ) avcodec_set_dimensions ( avctx , w , h ) ; if ( ( ret = avctx - > get_buffer ( avctx , p ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed\n ) ; return ret ; } p - > pict_type = AV_PICTURE_TYPE_I ; ptr = p - > data[0] ; stride = p - > linesize[0] ; scanline = av_malloc ( bytes_per_scanline ) ; if ( ! scanline ) return AVERROR ( ENOMEM ) ; if ( nplanes == 3 & & bits_per_pixel == 8 ) { for ( y=0 ; y < h ; y + + ) { buf = pcx_rle_decode ( buf , scanline , bytes_per_scanline , compressed ) ; for ( x=0 ; x < w ; x + + ) { ptr[3 * x ] = scanline[x ] ; ptr[3 * x + 1] = scanline[x + bytes_per_line ] ; ptr[3 * x + 2] = scanline[x + ( bytes_per_line < < 1 ) ] ; } ptr + = stride ; } } else if ( nplanes == 1 & & bits_per_pixel == 8 ) { const uint8_t * palstart = bufstart + buf_size - 769 ; for ( y=0 ; y < h ; y + + , ptr + =stride ) { buf = pcx_rle_decode ( buf , scanline , bytes_per_scanline , compressed ) ; memcpy ( ptr , scanline , w ) ; } if ( buf ! = palstart ) { av_log ( avctx , AV_LOG_WARNING , image data possibly corrupted\n ) ; buf = palstart ; } if ( * buf + + ! = 12 ) { av_log ( avctx , AV_LOG_ERROR , expected palette after image data\n ) ; ret = AVERROR_INVALIDDATA ; goto end ; } } else if ( nplanes == 1 ) { / * all packed formats , max . 16 colors * / GetBitContext s ; for ( y=0 ; y < h ; y + + ) { init_get_bits ( & s , scanline , bytes_per_scanline < < 3 ) ; buf = pcx_rle_decode ( buf , scanline , bytes_per_scanline , compressed ) ; for ( x=0 ; x < w ; x + + ) ptr[x] = get_bits ( & s , bits_per_pixel ) ; ptr + = stride ; } } else { / * planar , 4 , 8 or 16 colors * / int i ; for ( y=0 ; y < h ; y + + ) { buf = pcx_rle_decode ( buf , scanline , bytes_per_scanline , compressed ) ; for ( x=0 ; x < w ; x + + ) { int m = 0x80 > > ( x & 7 ) , v = 0 ; for ( i=nplanes - 1 ; i > =0 ; i - - ) { v < < = 1 ; v + = ! ! ( scanline[i * bytes_per_line + ( x > > 3 ) ] & m ) ; } ptr[x] = v ; } ptr + = stride ; } } if ( nplanes == 1 & & bits_per_pixel == 8 ) { pcx_palette ( & buf , ( uint32_t * ) p - > data[1] , 256 ) ; } else if ( bits_per_pixel * nplanes == 1 ) { AV_WN32A ( p - > data[1] , 0xFF000000 ) ; AV_WN32A ( p - > data[1] + 4 , 0xFFFFFFFF ) ; } else if ( bits_per_pixel < 8 ) { const uint8_t * palette = bufstart + 16 ; pcx_palette ( & palette , ( uint32_t * ) p - > data[1] , 16 ) ; } * picture = s - > picture ; * data_size = sizeof ( AVFrame ) ; ret = buf - bufstart ; end : av_free ( scanline ) ; return ret ; }",1
"static int v4l2_send_frame ( AVCodecContext * avctx , const AVFrame * frame ) { V4L2m2mContext * s = avctx - > priv_data ; V4L2Context * const output = & s - > output ; return ff_v4l2_context_enqueue_frame ( output , frame ) ; }",1
"static int vp8_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { VP8Context * s = avctx - > priv_data ; int ret , mb_x , mb_y , i , y , referenced ; enum AVDiscard skip_thresh ; AVFrame * curframe ; if ( ( ret = decode_frame_header ( s , avpkt - > data , avpkt - > size ) ) < 0 ) return ret ; referenced = s - > update_last || s - > update_golden == VP56_FRAME_CURRENT || s - > update_altref == VP56_FRAME_CURRENT ; skip_thresh = ! referenced ? AVDISCARD_NONREF : ! s - > keyframe ? AVDISCARD_NONKEY : AVDISCARD_ALL ; if ( avctx - > skip_frame > = skip_thresh ) { s - > invisible = 1 ; goto skip_decode ; } for ( i = 0 ; i < 4 ; i + + ) if ( & s - > frames[i] ! = s - > framep[VP56_FRAME_PREVIOUS] & & & s - > frames[i] ! = s - > framep[VP56_FRAME_GOLDEN] & & & s - > frames[i] ! = s - > framep[VP56_FRAME_GOLDEN2] ) { curframe = s - > framep[VP56_FRAME_CURRENT] = & s - > frames[i] ; break ; } if ( curframe - > data[0] ) avctx - > release_buffer ( avctx , curframe ) ; curframe - > key_frame = s - > keyframe ; curframe - > pict_type = s - > keyframe ? FF_I_TYPE : FF_P_TYPE ; curframe - > reference = referenced ? 3 : 0 ; if ( ( ret = avctx - > get_buffer ( avctx , curframe ) ) ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed ! \n ) ; return ret ; } // Given that arithmetic probabilities are updated every frame , it ' s quite likely // that the values we have on a random interframe are complete junk if we didn ' t // start decode on a keyframe . So just don ' t display anything rather than junk . if ( ! s - > keyframe & & ( ! s - > framep[VP56_FRAME_PREVIOUS] || ! s - > framep[VP56_FRAME_GOLDEN] || ! s - > framep[VP56_FRAME_GOLDEN2] ) ) { av_log ( avctx , AV_LOG_WARNING , Discarding interframe without a prior keyframe ! \n ) ; return AVERROR_INVALIDDATA ; } s - > linesize = curframe - > linesize[0] ; s - > uvlinesize = curframe - > linesize[1] ; if ( ! s - > edge_emu_buffer ) s - > edge_emu_buffer = av_malloc ( 21 * s - > linesize ) ; memset ( s - > top_nnz , 0 , s - > mb_width * sizeof ( * s - > top_nnz ) ) ; // top edge of 127 for intra prediction if ( ! ( avctx - > flags & CODEC_FLAG_EMU_EDGE ) ) { memset ( curframe - > data[0] - s - > linesize - 1 , 127 , s - > linesize + 1 ) ; memset ( curframe - > data[1] - s - > uvlinesize - 1 , 127 , s - > uvlinesize + 1 ) ; memset ( curframe - > data[2] - s - > uvlinesize - 1 , 127 , s - > uvlinesize + 1 ) ; } for ( mb_y = 0 ; mb_y < s - > mb_height ; mb_y + + ) { VP56RangeCoder * c = & s - > coeff_partition[mb_y & ( s - > num_coeff_partitions - 1 ) ] ; VP8Macroblock * mb = s - > macroblocks + mb_y * s - > mb_stride ; uint8_t * intra4x4 = s - > intra4x4_pred_mode + 4 * mb_y * s - > b4_stride ; uint8_t * dst[3] = { curframe - > data[0] + 16 * mb_y * s - > linesize , curframe - > data[1] + 8 * mb_y * s - > uvlinesize , curframe - > data[2] + 8 * mb_y * s - > uvlinesize } ; memset ( s - > left_nnz , 0 , sizeof ( s - > left_nnz ) ) ; // left edge of 129 for intra prediction if ( ! ( avctx - > flags & CODEC_FLAG_EMU_EDGE ) ) for ( i = 0 ; i < 3 ; i + + ) for ( y = 0 ; y < 16 > > ! ! i ; y + + ) dst[i][y * curframe - > linesize[i] - 1] = 129 ; for ( mb_x = 0 ; mb_x < s - > mb_width ; mb_x + + ) { decode_mb_mode ( s , mb , mb_x , mb_y , intra4x4 + 4 * mb_x ) ; if ( ! mb - > skip ) decode_mb_coeffs ( s , c , mb , s - > top_nnz[mb_x] , s - > left_nnz ) ; else { AV_ZERO128 ( s - > non_zero_count_cache ) ; // luma AV_ZERO64 ( s - > non_zero_count_cache[4] ) ; // chroma } if ( mb - > mode < = MODE_I4x4 ) { intra_predict ( s , dst , mb , intra4x4 + 4 * mb_x , mb_x , mb_y ) ; memset ( mb - > bmv , 0 , sizeof ( mb - > bmv ) ) ; } else { inter_predict ( s , dst , mb , mb_x , mb_y ) ; } if ( ! mb - > skip ) { idct_mb ( s , dst[0] , dst[1] , dst[2] , mb ) ; } else { AV_ZERO64 ( s - > left_nnz ) ; AV_WN64 ( s - > top_nnz[mb_x] , 0 ) ; // array of 9 , so unaligned // Reset DC block predictors if they would exist if the mb had coefficients if ( mb - > mode ! = MODE_I4x4 & & mb - > mode ! = VP8_MVMODE_SPLIT ) { s - > left_nnz[8] = 0 ; s - > top_nnz[mb_x][8] = 0 ; } } dst[0] + = 16 ; dst[1] + = 8 ; dst[2] + = 8 ; mb + + ; } if ( mb_y & & s - > filter . level & & avctx - > skip_loop_filter < skip_thresh ) { if ( s - > filter . simple ) filter_mb_row_simple ( s , mb_y - 1 ) ; else filter_mb_row ( s , mb_y - 1 ) ; } } if ( s - > filter . level & & avctx - > skip_loop_filter < skip_thresh ) { if ( s - > filter . simple ) filter_mb_row_simple ( s , mb_y - 1 ) ; else filter_mb_row ( s , mb_y - 1 ) ; } skip_decode : // if future frames don ' t use the updated probabilities , // reset them to the values we saved if ( ! s - > update_probabilities ) s - > prob[0] = s - > prob[1] ; // check if golden and altref are swapped if ( s - > update_altref == VP56_FRAME_GOLDEN & & s - > update_golden == VP56_FRAME_GOLDEN2 ) FFSWAP ( AVFrame * , s - >",0
"void ff_init_vscale_pfn ( SwsContext * c , yuv2planar1_fn yuv2plane1 , yuv2planarX_fn yuv2planeX , yuv2interleavedX_fn yuv2nv12cX , yuv2packed1_fn yuv2packed1 , yuv2packed2_fn yuv2packed2 , yuv2packedX_fn yuv2packedX , yuv2anyX_fn yuv2anyX , int use_mmx ) { VScalerContext * lumCtx = NULL ; VScalerContext * chrCtx = NULL ; int idx = c - > numDesc - ( c - > is_internal_gamma ? 2 : 1 ) ; //FIXME avoid hardcoding indexes if ( isPlanarYUV ( c - > dstFormat ) || ( isGray ( c - > dstFormat ) & & ! isALPHA ( c - > dstFormat ) ) ) { if ( ! isGray ( c - > dstFormat ) ) { chrCtx = c - > desc[idx] . instance ; chrCtx - > filter[0] = use_mmx ? ( int16_t * ) c - > chrMmxFilter : c - > vChrFilter ; chrCtx - > filter_size = c - > vChrFilterSize ; chrCtx - > filter_pos = c - > vChrFilterPos ; chrCtx - > isMMX = use_mmx ; - - idx ; if ( yuv2nv12cX ) chrCtx - > pfn = yuv2nv12cX ; else if ( c - > vChrFilterSize == 1 ) chrCtx - > pfn = yuv2plane1 ; else chrCtx - > pfn = yuv2planeX ; } lumCtx = c - > desc[idx] . instance ; lumCtx - > filter[0] = use_mmx ? ( int16_t * ) c - > lumMmxFilter : c - > vLumFilter ; lumCtx - > filter[1] = use_mmx ? ( int16_t * ) c - > alpMmxFilter : c - > vLumFilter ; lumCtx - > filter_size = c - > vLumFilterSize ; lumCtx - > filter_pos = c - > vLumFilterPos ; lumCtx - > isMMX = use_mmx ; if ( c - > vLumFilterSize == 1 ) lumCtx - > pfn = yuv2plane1 ; else lumCtx - > pfn = yuv2planeX ; } else { lumCtx = c - > desc[idx] . instance ; chrCtx = & lumCtx[1] ; lumCtx - > filter[0] = c - > vLumFilter ; lumCtx - > filter_size = c - > vLumFilterSize ; lumCtx - > filter_pos = c - > vLumFilterPos ; chrCtx - > filter[0] = c - > vChrFilter ; chrCtx - > filter_size = c - > vChrFilterSize ; chrCtx - > filter_pos = c - > vChrFilterPos ; lumCtx - > isMMX = use_mmx ; chrCtx - > isMMX = use_mmx ; if ( yuv2packedX ) { if ( c - > yuv2packed1 & & c - > vLumFilterSize == 1 & & c - > vChrFilterSize < = 2 ) lumCtx - > pfn = yuv2packed1 ; else if ( c - > yuv2packed2 & & c - > vLumFilterSize == 2 & & c - > vChrFilterSize == 2 ) lumCtx - > pfn = yuv2packed2 ; else lumCtx - > pfn = yuv2packedX ; } else lumCtx - > pfn = yuv2anyX ; } }",0
"static int flv_read_packet ( AVFormatContext * s , AVPacket * pkt ) { int ret , i , type , size , pts , flags , is_audio , next , pos ; AVStream * st = NULL ; for ( ; ; ) { pos = url_ftell ( s - > pb ) ; url_fskip ( s - > pb , 4 ) ; / * size of previous packet * / type = get_byte ( s - > pb ) ; size = get_be24 ( s - > pb ) ; pts = get_be24 ( s - > pb ) ; pts |= get_byte ( s - > pb ) < < 24 ; // av_log ( s , AV_LOG_DEBUG , type : %d , size : %d , pts : %d\n , type , size , pts ) ; if ( url_feof ( s - > pb ) ) return AVERROR ( EIO ) ; url_fskip ( s - > pb , 3 ) ; / * stream id , always 0 * / flags = 0 ; if ( size == 0 ) continue ; next= size + url_ftell ( s - > pb ) ; if ( type == FLV_TAG_TYPE_AUDIO ) { is_audio=1 ; flags = get_byte ( s - > pb ) ; } else if ( type == FLV_TAG_TYPE_VIDEO ) { is_audio=0 ; flags = get_byte ( s - > pb ) ; } else { if ( type == FLV_TAG_TYPE_META & & size > 13 + 1 + 4 ) flv_read_metabody ( s , next ) ; else / * skip packet * / av_log ( s , AV_LOG_ERROR , skipping flv packet : type %d , size %d , flags %d\n , type , size , flags ) ; url_fseek ( s - > pb , next , SEEK_SET ) ; continue ; } / * now find stream * / for ( i=0 ; i < s - > nb_streams ; i + + ) { st = s - > streams[i] ; if ( st - > id == is_audio ) break ; } if ( i == s - > nb_streams ) { av_log ( NULL , AV_LOG_ERROR , invalid stream\n ) ; st= create_stream ( s , is_audio ) ; s - > ctx_flags & = AVFMTCTX_NOHEADER ; } // av_log ( NULL , AV_LOG_DEBUG , %d %X %d \n , is_audio , flags , st - > discard ) ; if ( ( st - > discard > = AVDISCARD_NONKEY & & ! ( ( flags & FLV_VIDEO_FRAMETYPE_MASK ) == FLV_FRAME_KEY || is_audio ) ) || ( st - > discard > = AVDISCARD_BIDIR & & ( ( flags & FLV_VIDEO_FRAMETYPE_MASK ) == FLV_FRAME_DISP_INTER & & ! is_audio ) ) || st - > discard > = AVDISCARD_ALL ) { url_fseek ( s - > pb , next , SEEK_SET ) ; continue ; } if ( ( flags & FLV_VIDEO_FRAMETYPE_MASK ) == FLV_FRAME_KEY ) av_add_index_entry ( st , pos , pts , size , 0 , AVINDEX_KEYFRAME ) ; break ; } // if not streamed and no duration from metadata then seek to end to find the duration from the timestamps if ( ! url_is_streamed ( s - > pb ) & & s - > duration==AV_NOPTS_VALUE ) { int size ; const int pos= url_ftell ( s - > pb ) ; const int fsize= url_fsize ( s - > pb ) ; url_fseek ( s - > pb , fsize - 4 , SEEK_SET ) ; size= get_be32 ( s - > pb ) ; url_fseek ( s - > pb , fsize - 3 - size , SEEK_SET ) ; if ( size == get_be24 ( s - > pb ) + 11 ) { s - > duration= get_be24 ( s - > pb ) * ( int64_t ) AV_TIME_BASE / 1000 ; } url_fseek ( s - > pb , pos , SEEK_SET ) ; } if ( is_audio ) { if ( ! st - > codec - > sample_rate || ! st - > codec - > bits_per_sample || ( ! st - > codec - > codec_id & & ! st - > codec - > codec_tag ) ) { st - > codec - > channels = ( flags & FLV_AUDIO_CHANNEL_MASK ) == FLV_STEREO ? 2 : 1 ; if ( ( flags & FLV_AUDIO_CODECID_MASK ) == FLV_CODECID_NELLYMOSER_8HZ_MONO ) st - > codec - > sample_rate= 8000 ; else st - > codec - > sample_rate = ( 44100 < < ( ( flags & FLV_AUDIO_SAMPLERATE_MASK ) > > FLV_AUDIO_SAMPLERATE_OFFSET ) > > 3 ) ; st - > codec - > bits_per_sample = ( flags & FLV_AUDIO_SAMPLESIZE_MASK ) ? 16 : 8 ; flv_set_audio_codec ( s , st , flags & FLV_AUDIO_CODECID_MASK ) ; } } else { size - = flv_set_video_codec ( s , st , flags & FLV_VIDEO_CODECID_MASK ) ; } ret= av_get_packet ( s - > pb , pkt , size - 1 ) ; if ( ret < = 0 ) { return AVERROR ( EIO ) ; } / * note : we need to modify the packet size here to handle the last packet * / pkt - > size = ret ; pkt - > pts = pts ; pkt - > stream_index = st - > index ; if ( is_audio || ( ( flags & FLV_VIDEO_FRAMETYPE_MASK ) == FLV_FRAME_KEY ) ) pkt - > flags |= PKT_FLAG_KEY ; return ret ; }",0
"static inline void fill_caches ( H264Context * h , int mb_type , int for_deblock ) { MpegEncContext * const s = & h - > s ; const int mb_xy= s - > mb_x + s - > mb_y * s - > mb_stride ; int topleft_xy , top_xy , topright_xy , left_xy[2] ; int topleft_type , top_type , topright_type , left_type[2] ; int left_block[4] ; int i ; //wow what a mess , why didnt they simplify the interlacing & intra stuff , i cant imagine that these complex rules are worth it if ( h - > sps . mb_aff ) { //FIXME topleft_xy = 0 ; / * avoid warning * / top_xy = 0 ; / * avoid warning * / topright_xy = 0 ; / * avoid warning * / } else { topleft_xy = mb_xy - 1 - s - > mb_stride ; top_xy = mb_xy - s - > mb_stride ; topright_xy= mb_xy + 1 - s - > mb_stride ; left_xy[0] = mb_xy - 1 ; left_xy[1] = mb_xy - 1 ; left_block[0]= 0 ; left_block[1]= 1 ; left_block[2]= 2 ; left_block[3]= 3 ; } if ( for_deblock ) { topleft_type = h - > slice_table[topleft_xy ] < 255 ? s - > current_picture . mb_type[topleft_xy] : 0 ; top_type = h - > slice_table[top_xy ] < 255 ? s - > current_picture . mb_type[top_xy] : 0 ; topright_type= h - > slice_table[topright_xy] < 255 ? s - > current_picture . mb_type[topright_xy] : 0 ; left_type[0] = h - > slice_table[left_xy[0] ] < 255 ? s - > current_picture . mb_type[left_xy[0]] : 0 ; left_type[1] = h - > slice_table[left_xy[1] ] < 255 ? s - > current_picture . mb_type[left_xy[1]] : 0 ; } else { topleft_type = h - > slice_table[topleft_xy ] == h - > slice_num ? s - > current_picture . mb_type[topleft_xy] : 0 ; top_type = h - > slice_table[top_xy ] == h - > slice_num ? s - > current_picture . mb_type[top_xy] : 0 ; topright_type= h - > slice_table[topright_xy] == h - > slice_num ? s - > current_picture . mb_type[topright_xy] : 0 ; left_type[0] = h - > slice_table[left_xy[0] ] == h - > slice_num ? s - > current_picture . mb_type[left_xy[0]] : 0 ; left_type[1] = h - > slice_table[left_xy[1] ] == h - > slice_num ? s - > current_picture . mb_type[left_xy[1]] : 0 ; } if ( IS_INTRA ( mb_type ) ) { h - > topleft_samples_available= h - > top_samples_available= h - > left_samples_available= 0xFFFF ; h - > topright_samples_available= 0xEEEA ; if ( ! IS_INTRA ( top_type ) & & ( top_type==0 || h - > pps . constrained_intra_pred ) ) { h - > topleft_samples_available= 0xB3FF ; h - > top_samples_available= 0x33FF ; h - > topright_samples_available= 0x26EA ; } for ( i=0 ; i < 2 ; i + + ) { if ( ! IS_INTRA ( left_type[i] ) & & ( left_type[i]==0 || h - > pps . constrained_intra_pred ) ) { h - > topleft_samples_available & = 0xDF5F ; h - > left_samples_available & = 0x5F5F ; } } if ( ! IS_INTRA ( topleft_type ) & & ( topleft_type==0 || h - > pps . constrained_intra_pred ) ) h - > topleft_samples_available & = 0x7FFF ; if ( ! IS_INTRA ( topright_type ) & & ( topright_type==0 || h - > pps . constrained_intra_pred ) ) h - > topright_samples_available & = 0xFBFF ; if ( IS_INTRA4x4 ( mb_type ) ) { if ( IS_INTRA4x4 ( top_type ) ) { h - > intra4x4_pred_mode_cache[4 + 8 * 0]= h - > intra4x4_pred_mode[top_xy][4] ; h - > intra4x4_pred_mode_cache[5 + 8 * 0]= h - > intra4x4_pred_mode[top_xy][5] ; h - > intra4x4_pred_mode_cache[6 + 8 * 0]= h - > intra4x4_pred_mode[top_xy][6] ; h - > intra4x4_pred_mode_cache[7 + 8 * 0]= h - > intra4x4_pred_mode[top_xy][3] ; } else { int pred ; if ( ! top_type || ( IS_INTER ( top_type ) & & h - > pps . constrained_intra_pred ) ) pred= - 1 ; else { pred= 2 ; } h - > intra4x4_pred_mode_cache[4 + 8 * 0]= h - > intra4x4_pred_mode_cache[5 + 8 * 0]= h - > intra4x4_pred_mode_cache[6 + 8 * 0]= h - > intra4x4_pred_mode_cache[7 + 8 * 0]= pred ; } for ( i=0 ; i < 2 ; i + + ) { if ( IS_INTRA4x4 ( left_type[i] ) ) { h - > intra4x4_pred_mode_cache[3 + 8 * 1 + 2 * 8 * i]= h - > intra4x4_pred_mode[left_xy[i]][left_block[0 + 2 * i]] ; h - > intra4x4_pred_mode_cache[3 + 8 * 2 + 2 * 8 * i]= h - > intra4x4_pred_mode[left_xy[i]][left_block[1 + 2 * i]] ; } else { int pred ; if ( ! left_type[i] || ( IS_INTER ( left_type[i] ) & & h - > pps . constrained_intra_pred ) ) pred= - 1 ; else { pred= 2 ; } h - > intra4x4_pred_mode_cache[3 + 8 * 1 + 2 * 8 * i]= h - > intra4x4_pred_mode_cache[3 + 8 * 2 + 2 * 8 * i]= pred ; } } } } / * 0 . T T . T T T T 1 L . . L . . . . 2 L . . L . . . . 3 . T TL . . . . 4 L . . L . . . . 5 L . . . . . . . * / //FIXME constraint_intra_pred & partitioning & nnz ( lets hope this is just a typo in the spec ) if ( top_type ) { h - > non_zero_count_cache[4 + 8 * 0]= h - > non_zero_count[top_xy][0] ; h - > non_zero_count_cache[5 + 8 * 0]= h - > non_zero_count[top_xy][1] ; h - > non_zero_count_cache[6 + 8 * 0]= h - > non_zero_count[top_xy][2] ; h - > non_zero_count_cache[7 + 8 * 0]= h - > non_zero_count[top_xy][3] ; h - > non_zero_count_cache[1 + 8 * 0]= h - > non_zero_count[top_xy][7] ; h - > non_zero_count_cache[2 + 8 * 0]= h - > non_zero_count[top_xy][8] ; h - > non_zero_count_cache[1 + 8 * 3]= h - > non_zero_count[top_xy][10] ; h - > non_zero_count_cache[2 + 8 * 3]= h - > non_zero_count[top_xy][11] ; h - > top_cbp= h - > cbp_table[top_xy] ; } else { h - > non_zero_count_cache[4 + 8 * 0]= h - > non_zero_count_cache[5 + 8 * 0]= h - > non_zero_count_cache[6 + 8 * 0]= h - > non_zero_count_cache[7 + 8 * 0]= h - > non_zero_count_cache[1 + 8 * 0]= h - > non_zero_count_cache[2 + 8 * 0]= h - > non_zero_count_cache[1 + 8 * 3]= h - > non_zero_count_cache[2 + 8 * 3]= h - > pps . cabac & & ! IS_INTRA ( mb_type ) ? 0 : 64 ; if ( IS_INTRA ( mb_type ) ) h - > top_cbp= 0x1C0 ; else h - > top_cbp= 0 ; } if ( left_type[0] ) { h - > non_zero_count_cache[3 + 8 * 1]= h - > non_zero_count[left_xy[0]][6] ; h - > non_zero_count_cache[3 + 8 * 2]= h - > non_zero_count[left_xy[0]][5] ; h - > non_zero_count_cache[0 + 8 * 1]= h - > non_zero_count[left_xy[0]][9] ; //FIXME left_block",0
"static int update_dimensions ( VP8Context * s , int width , int height ) { int i ; if ( avcodec_check_dimensions ( s - > avctx , width , height ) ) return AVERROR_INVALIDDATA ; vp8_decode_flush ( s - > avctx ) ; avcodec_set_dimensions ( s - > avctx , width , height ) ; s - > mb_width = ( s - > avctx - > coded_width + 15 ) / 16 ; s - > mb_height = ( s - > avctx - > coded_height + 15 ) / 16 ; // we allocate a border around the top/left of intra4x4 modes // this is 4 blocks for intra4x4 to keep 4 - byte alignment for fill_rectangle s - > mb_stride = s - > mb_width + 1 ; s - > b4_stride = 4 * s - > mb_stride ; s - > macroblocks_base = av_mallocz ( s - > mb_stride * ( s - > mb_height + 1 ) * sizeof ( * s - > macroblocks ) ) ; s - > intra4x4_pred_mode_base = av_mallocz ( s - > b4_stride * ( 4 * s - > mb_height + 1 ) ) ; s - > top_nnz = av_mallocz ( s - > mb_width * sizeof ( * s - > top_nnz ) ) ; if ( ! s - > macroblocks_base || ! s - > intra4x4_pred_mode_base || ! s - > top_nnz ) return AVERROR ( ENOMEM ) ; s - > macroblocks = s - > macroblocks_base + 1 + s - > mb_stride ; s - > intra4x4_pred_mode = s - > intra4x4_pred_mode_base + 4 + s - > b4_stride ; memset ( s - > intra4x4_pred_mode_base , DC_PRED , s - > b4_stride ) ; for ( i = 0 ; i < 4 * s - > mb_height ; i + + ) s - > intra4x4_pred_mode[i * s - > b4_stride - 1] = DC_PRED ; return 0 ; }",0
"static int http_connect ( URLContext * h , const char * path , const char * local_path , const char * hoststr , const char * auth , const char * proxyauth , int * new_location ) { HTTPContext * s = h - > priv_data ; int post , err ; char headers[HTTP_HEADERS_SIZE] = ; char * authstr = NULL , * proxyauthstr = NULL ; uint64_t off = s - > off ; int len = 0 ; const char * method ; int send_expect_100 = 0 ; / * send http header * / post = h - > flags & AVIO_FLAG_WRITE ; if ( s - > post_data ) { / * force POST method and disable chunked encoding when * custom HTTP post data is set * / post = 1 ; s - > chunked_post = 0 ; } if ( s - > method ) method = s - > method ; else method = post ? POST : GET ; authstr = ff_http_auth_create_response ( & s - > auth_state , auth , local_path , method ) ; proxyauthstr = ff_http_auth_create_response ( & s - > proxy_auth_state , proxyauth , local_path , method ) ; if ( post & & ! s - > post_data ) { send_expect_100 = s - > send_expect_100 ; / * The user has supplied authentication but we don ' t know the auth type , * send Expect : 100 - continue to get the 401 response including the * WWW - Authenticate header , or an 100 continue if no auth actually * is needed . * / if ( auth & & * auth & & s - > auth_state . auth_type == HTTP_AUTH_NONE & & s - > http_code ! = 401 ) send_expect_100 = 1 ; } if FF_API_HTTP_USER_AGENT if ( strcmp ( s - > user_agent_deprecated , DEFAULT_USER_AGENT ) ) { av_log ( s , AV_LOG_WARNING , the user - agent option is deprecated , please use user_agent option\n ) ; s - > user_agent = av_strdup ( s - > user_agent_deprecated ) ; } endif / * set default headers if needed * / if ( ! has_header ( s - > headers , \r\nUser - Agent : ) ) len + = av_strlcatf ( headers + len , sizeof ( headers ) - len , User - Agent : %s\r\n , s - > user_agent ) ; if ( ! has_header ( s - > headers , \r\nAccept : ) ) len + = av_strlcpy ( headers + len , Accept : * / * \r\n , sizeof ( headers ) - len ) ; // Note : we send this on purpose even when s - > off is 0 when we ' re probing , // since it allows us to detect more reliably if a ( non - conforming ) // server supports seeking by analysing the reply headers . if ( ! has_header ( s - > headers , \r\nRange : ) & & ! post & & ( s - > off > 0 || s - > end_off || s - > seekable == - 1 ) ) { len + = av_strlcatf ( headers + len , sizeof ( headers ) - len , Range : bytes=% PRIu64 - , s - > off ) ; if ( s - > end_off ) len + = av_strlcatf ( headers + len , sizeof ( headers ) - len , % PRId64 , s - > end_off - 1 ) ; len + = av_strlcpy ( headers + len , \r\n , sizeof ( headers ) - len ) ; } if ( send_expect_100 & & ! has_header ( s - > headers , \r\nExpect : ) ) len + = av_strlcatf ( headers + len , sizeof ( headers ) - len , Expect : 100 - continue\r\n ) ; if ( ! has_header ( s - > headers , \r\nConnection : ) ) { if ( s - > multiple_requests ) len + = av_strlcpy ( headers + len , Connection : keep - alive\r\n , sizeof ( headers ) - len ) ; else len + = av_strlcpy ( headers + len , Connection : close\r\n , sizeof ( headers ) - len ) ; } if ( ! has_header ( s - > headers , \r\nHost : ) ) len + = av_strlcatf ( headers + len , sizeof ( headers ) - len , Host : %s\r\n , hoststr ) ; if ( ! has_header ( s - > headers , \r\nContent - Length : ) & & s - > post_data ) len + = av_strlcatf ( headers + len , sizeof ( headers ) - len , Content - Length : %d\r\n , s - > post_datalen ) ; if ( ! has_header ( s - > headers , \r\nContent - Type : ) & & s - > content_type ) len + = av_strlcatf ( headers + len , sizeof ( headers ) - len , Content - Type : %s\r\n , s - > content_type ) ; if ( ! has_header ( s - > headers , \r\nCookie : ) & & s - > cookies ) { char * cookies = NULL ; if ( ! get_cookies ( s , & cookies , path , hoststr ) & & cookies ) { len + = av_strlcatf ( headers + len , sizeof ( headers ) - len , Cookie : %s\r\n , cookies ) ; av_free ( cookies ) ; } } if ( ! has_header ( s - > headers , \r\nIcy - MetaData : ) & & s - > icy ) len + = av_strlcatf ( headers + len , sizeof ( headers ) - len , Icy - MetaData : %d\r\n , 1 ) ; / * now add in custom headers * / if ( s - > headers ) av_strlcpy ( headers + len , s - > headers , sizeof ( headers ) - len ) ; snprintf ( s - > buffer , sizeof ( s - > buffer ) , %s %s HTTP/1 . 1\r\n %s %s %s %s%s \r\n , method , path , post & & s - > chunked_post ? Transfer - Encoding : chunked\r\n : , headers , authstr ? authstr : , proxyauthstr ? Proxy - : , proxyauthstr ? proxyauthstr : ) ; av_log ( h , AV_LOG_DEBUG , request : %s\n , s - > buffer ) ; if ( ( err = ffurl_write ( s - > hd , s - > buffer , strlen ( s - > buffer ) ) ) < 0 ) goto done ; if ( s - > post_data ) if ( ( err = ffurl_write ( s - > hd , s - > post_data , s - > post_datalen ) ) < 0 ) goto done ; / * init input buffer * / s - > buf_ptr = s - > buffer ; s - > buf_end = s - > buffer ; s - > line_count =",0
"static void predictor_decompress_fir_adapt ( int32_t * error_buffer , int32_t * buffer_out , int output_size , int readsamplesize , int16_t * predictor_coef_table , int predictor_coef_num , int predictor_quantitization ) { int i ; / * first sample always copies * / * buffer_out = * error_buffer ; if ( ! predictor_coef_num ) { if ( output_size < = 1 ) return ; memcpy ( & buffer_out[1] , & error_buffer[1] , ( output_size - 1 ) * sizeof ( * buffer_out ) ) ; return ; } if ( predictor_coef_num == 31 ) { / * simple 1st - order prediction * / if ( output_size < = 1 ) return ; for ( i = 1 ; i < output_size ; i + + ) { buffer_out[i] = sign_extend ( buffer_out[i - 1] + error_buffer[i] , readsamplesize ) ; } return ; } / * read warm - up samples * / for ( i = 0 ; i < predictor_coef_num ; i + + ) { buffer_out[i + 1] = sign_extend ( buffer_out[i] + error_buffer[i + 1] , readsamplesize ) ; } / * NOTE : 4 and 8 are very common cases that could be optimized . * / / * general case * / for ( i = predictor_coef_num ; i < output_size - 1 ; i + + ) { int j ; int val = 0 ; int error_val = error_buffer[i + 1] ; int error_sign ; int d = buffer_out[i - predictor_coef_num] ; for ( j = 0 ; j < predictor_coef_num ; j + + ) { val + = ( buffer_out[i - j] - d ) * predictor_coef_table[j] ; } val = ( val + ( 1 < < ( predictor_quantitization - 1 ) ) ) > > predictor_quantitization ; val + = d + error_val ; buffer_out[i + 1] = sign_extend ( val , readsamplesize ) ; / * adapt LPC coefficients * / error_sign = sign_only ( error_val ) ; if ( error_sign ) { for ( j = predictor_coef_num - 1 ; j > = 0 & & error_val * error_sign > 0 ; j - - ) { int sign ; val = d - buffer_out[i - j] ; sign = sign_only ( val ) * error_sign ; predictor_coef_table[j] - = sign ; val * = sign ; error_val - = ( ( val > > predictor_quantitization ) * ( predictor_coef_num - j ) ) ; } } } }",0
"static int alloc_audio_output_buf ( AVCodecContext * dec , AVCodecContext * enc , int nb_samples , int * buf_linesize ) { int64_t audio_buf_samples ; int audio_buf_size ; / * calculate required number of samples to allocate * / audio_buf_samples = ( ( int64_t ) nb_samples * enc - > sample_rate + dec - > sample_rate ) / dec - > sample_rate ; audio_buf_samples = 4 * audio_buf_samples + 10000 ; // safety factors for resampling audio_buf_samples = FFMAX ( audio_buf_samples , enc - > frame_size ) ; if ( audio_buf_samples > INT_MAX ) return AVERROR ( EINVAL ) ; audio_buf_size = av_samples_get_buffer_size ( buf_linesize , enc - > channels , audio_buf_samples , enc - > sample_fmt , 0 ) ; if ( audio_buf_size < 0 ) return audio_buf_size ; av_fast_malloc ( & audio_buf , & allocated_audio_buf_size , audio_buf_size ) ; if ( ! audio_buf ) return AVERROR ( ENOMEM ) ; return 0 ; }",1
"static int nut_write_header ( AVFormatContext * avf ) { NUTContext * priv = avf - > priv_data ; AVIOContext * bc = avf - > pb ; nut_muxer_opts_tt mopts = { . output = { . priv = bc , . write = av_write , } , . alloc = { av_malloc , av_realloc , av_free } , . write_index = 1 , . realtime_stream = 0 , . max_distance = 32768 , . fti = NULL , } ; nut_stream_header_tt * s ; int i ; priv - > s = s = av_mallocz ( ( avf - > nb_streams + 1 ) * sizeof * s ) ; for ( i = 0 ; i < avf - > nb_streams ; i + + ) { AVCodecContext * codec = avf - > streams[i] - > codec ; int j ; int fourcc = 0 ; int num , denom , ssize ; s[i] . type = codec - > codec_type == AVMEDIA_TYPE_VIDEO ? NUT_VIDEO_CLASS : NUT_AUDIO_CLASS ; if ( codec - > codec_tag ) fourcc = codec - > codec_tag ; else fourcc = ff_codec_get_tag ( nut_tags , codec - > codec_id ) ; if ( ! fourcc ) { if ( codec - > codec_type == AVMEDIA_TYPE_VIDEO ) fourcc = ff_codec_get_tag ( ff_codec_bmp_tags , codec - > codec_id ) ; if ( codec - > codec_type == AVMEDIA_TYPE_AUDIO ) fourcc = ff_codec_get_tag ( ff_codec_wav_tags , codec - > codec_id ) ; } s[i] . fourcc_len = 4 ; s[i] . fourcc = av_malloc ( s[i] . fourcc_len ) ; for ( j = 0 ; j < s[i] . fourcc_len ; j + + ) s[i] . fourcc[j] = ( fourcc > > ( j * 8 ) ) & 0xFF ; ff_parse_specific_params ( codec , & num , & ssize , & denom ) ; avpriv_set_pts_info ( avf - > streams[i] , 60 , denom , num ) ; s[i] . time_base . num = denom ; s[i] . time_base . den = num ; s[i] . fixed_fps = 0 ; s[i] . decode_delay = codec - > has_b_frames ; s[i] . codec_specific_len = codec - > extradata_size ; s[i] . codec_specific = codec - > extradata ; if ( codec - > codec_type == AVMEDIA_TYPE_VIDEO ) { s[i] . width = codec - > width ; s[i] . height = codec - > height ; s[i] . sample_width = 0 ; s[i] . sample_height = 0 ; s[i] . colorspace_type = 0 ; } else { s[i] . samplerate_num = codec - > sample_rate ; s[i] . samplerate_denom = 1 ; s[i] . channel_count = codec - > channels ; } } s[avf - > nb_streams] . type = - 1 ; priv - > nut = nut_muxer_init ( & mopts , s , NULL ) ; return 0 ; }",1
"static inline int RENAME ( yuv420_rgb16 ) ( SwsContext * c , uint8_t * src[] , int srcStride[] , int srcSliceY , int srcSliceH , uint8_t * dst[] , int dstStride[] ) { int y , h_size ; if ( c - > srcFormat == PIX_FMT_YUV422P ) { srcStride[1] * = 2 ; srcStride[2] * = 2 ; } h_size= ( c - > dstW + 7 ) & 7 ; if ( h_size * 2 > dstStride[0] ) h_size - =8 ; __asm__ __volatile__ ( pxor %mm4 , %mm4 ; / * zero mm4 * / ) ; //printf ( %X %X %X %X %X %X %X %X %X %X\n , ( int ) & c - > redDither , ( int ) & b5Dither , ( int ) src[0] , ( int ) src[1] , ( int ) src[2] , ( int ) dst[0] , //srcStride[0] , srcStride[1] , srcStride[2] , dstStride[0] ) ; for ( y= 0 ; y < srcSliceH ; y + + ) { uint8_t * _image = dst[0] + ( y + srcSliceY ) * dstStride[0] ; uint8_t * _py = src[0] + y * srcStride[0] ; uint8_t * _pu = src[1] + ( y > > 1 ) * srcStride[1] ; uint8_t * _pv = src[2] + ( y > > 1 ) * srcStride[2] ; long index= - h_size/2 ; b5Dither= dither8[y & 1] ; g6Dither= dither4[y & 1] ; g5Dither= dither8[y & 1] ; r5Dither= dither8[ ( y + 1 ) & 1] ; / * this mmx assembly code deals with SINGLE scan line at a time , it convert 8 pixels in each iteration * / __asm__ __volatile__ ( / * load data for start of next scan line * / movd ( %2 , %0 ) , %%mm0 ; / * Load 4 Cb 00 00 00 00 u3 u2 u1 u0 * / movd ( %3 , %0 ) , %%mm1 ; / * Load 4 Cr 00 00 00 00 v3 v2 v1 v0 * / movq ( %5 , %0 , 2 ) , %%mm6 ; / * Load 8 Y Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 * / // . balign 16 \n\t 1 : \n\t / * no speed diference on my p3 500 with prefetch , * if it is faster for anyone with - benchmark then tell me PREFETCH 64 ( %0 ) \n\t PREFETCH 64 ( %1 ) \n\t PREFETCH 64 ( %2 ) \n\t * / YUV2RGB ifdef DITHER1XBPP paddusb MANGLE ( b5Dither ) , %%mm0 ; paddusb MANGLE ( g6Dither ) , %%mm2 ; paddusb MANGLE ( r5Dither ) , %%mm1 ; endif / * mask unneeded bits off * / pand MANGLE ( mmx_redmask ) , %%mm0 ; / * b7b6b5b4 b3_0_0_0 b7b6b5b4 b3_0_0_0 * / pand MANGLE ( mmx_grnmask ) , %%mm2 ; / * g7g6g5g4 g3g2_0_0 g7g6g5g4 g3g2_0_0 * / pand MANGLE ( mmx_redmask ) , %%mm1 ; / * r7r6r5r4 r3_0_0_0 r7r6r5r4 r3_0_0_0 * / psrlw 3 , %%mm0 ; / * 0_0_0_b7 b6b5b4b3 0_0_0_b7 b6b5b4b3 * / pxor %%mm4 , %%mm4 ; / * zero mm4 * / movq %%mm0 , %%mm5 ; / * Copy B7 - B0 * / movq %%mm2 , %%mm7 ; / * Copy G7 - G0 * / / * convert rgb24 plane to rgb16 pack for pixel 0 - 3 * / punpcklbw %%mm4 , %%mm2 ; / * 0_0_0_0 0_0_0_0 g7g6g5g4 g3g2_0_0 * / punpcklbw %%mm1 , %%mm0 ; / * r7r6r5r4 r3_0_0_0 0_0_0_b7 b6b5b4b3 * / psllw 3 , %%mm2 ; / * 0_0_0_0 0_g7g6g5 g4g3g2_0 0_0_0_0 * / por %%mm2 , %%mm0 ; / * r7r6r5r4 r3g7g6g5 g4g3g2b7 b6b5b4b3 * / movq 8 ( %5 , %0 , 2 ) , %%mm6 ; / * Load 8 Y Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 * / MOVNTQ %%mm0 , ( %1 ) ; / * store pixel 0 - 3 * / / * convert rgb24 plane to rgb16 pack for pixel 0 - 3 * / punpckhbw %%mm4 , %%mm7 ; / * 0_0_0_0 0_0_0_0 g7g6g5g4 g3g2_0_0 * / punpckhbw %%mm1 , %%mm5 ; / * r7r6r5r4 r3_0_0_0 0_0_0_b7 b6b5b4b3 * / psllw 3 , %%mm7 ; / * 0_0_0_0 0_g7g6g5 g4g3g2_0 0_0_0_0 * / movd 4 ( %2 , %0 ) , %%mm0 ; / * Load 4 Cb 00 00 00 00 u3 u2 u1 u0 * / por %%mm7 , %%mm5 ; / * r7r6r5r4 r3g7g6g5 g4g3g2b7 b6b5b4b3 * / movd 4 ( %3 , %0 ) , %%mm1 ; / * Load 4 Cr 00 00 00 00 v3 v2 v1 v0 * / MOVNTQ %%mm5 , 8 ( %1 ) ; / * store pixel 4 - 7 * / add 16 , %1 \n\t add 4 , %0 \n\t js 1b \n\t : + r ( index ) , + r ( _image ) : r ( _pu - index ) , r ( _pv - index ) , r ( & c - > redDither ) , r ( _py - 2 * index ) ) ; } __asm__ __volatile__ ( EMMS ) ; return srcSliceH ; }",0
size_t av_cpu_max_align ( void ) { int flags = av_get_cpu_flags ( ) ; if ( flags & AV_CPU_FLAG_AVX ) return 32 ; if ( flags & ( AV_CPU_FLAG_ALTIVEC | AV_CPU_FLAG_SSE | AV_CPU_FLAG_NEON ) ) return 16 ; return 8 ; },0
"static void h261_loop_filter_c ( uint8_t * src , int stride ) { int x , y , xy , yz ; int temp[64] ; for ( x=0 ; x < 8 ; x + + ) { temp[x ] = 4 * src[x ] ; temp[x + 7 * 8] = 4 * src[x + 7 * stride] ; } for ( y=1 ; y < 7 ; y + + ) { for ( x=0 ; x < 8 ; x + + ) { xy = y * stride + x ; yz = y * 8 + x ; temp[yz] = src[xy - stride] + 2 * src[xy] + src[xy + stride] ; } } for ( y=0 ; y < 8 ; y + + ) { src[ y * stride] = ( temp[ y * 8] + 2 ) > > 2 ; src[7 + y * stride] = ( temp[7 + y * 8] + 2 ) > > 2 ; for ( x=1 ; x < 7 ; x + + ) { xy = y * stride + x ; yz = y * 8 + x ; src[xy] = ( temp[yz - 1] + 2 * temp[yz] + temp[yz + 1] + 8 ) > > 4 ; } } }",0
"int ff_rtsp_connect ( AVFormatContext * s ) { RTSPState * rt = s - > priv_data ; char host[1024] , path[1024] , tcpname[1024] , cmd[2048] , auth[128] ; char * option_list , * option , * filename ; int port , err , tcp_fd ; RTSPMessageHeader reply1 = { } , * reply = & reply1 ; int lower_transport_mask = 0 ; char real_challenge[64] ; struct sockaddr_storage peer ; socklen_t peer_len = sizeof ( peer ) ; if ( ! ff_network_init ( ) ) return AVERROR ( EIO ) ; redirect : rt - > control_transport = RTSP_MODE_PLAIN ; / * extract hostname and port * / av_url_split ( NULL , 0 , auth , sizeof ( auth ) , host , sizeof ( host ) , & port , path , sizeof ( path ) , s - > filename ) ; if ( * auth ) { av_strlcpy ( rt - > auth , auth , sizeof ( rt - > auth ) ) ; } if ( port < 0 ) port = RTSP_DEFAULT_PORT ; / * search for options * / option_list = strrchr ( path , ' ? ' ) ; if ( option_list ) { / * Strip out the RTSP specific options , write out the rest of * the options back into the same string . * / filename = option_list ; while ( option_list ) { / * move the option pointer * / option = + + option_list ; option_list = strchr ( option_list , ' & ' ) ; if ( option_list ) * option_list = 0 ; / * handle the options * / if ( ! strcmp ( option , udp ) ) { lower_transport_mask |= ( 1 < < RTSP_LOWER_TRANSPORT_UDP ) ; } else if ( ! strcmp ( option , multicast ) ) { lower_transport_mask |= ( 1 < < RTSP_LOWER_TRANSPORT_UDP_MULTICAST ) ; } else if ( ! strcmp ( option , tcp ) ) { lower_transport_mask |= ( 1 < < RTSP_LOWER_TRANSPORT_TCP ) ; } else if ( ! strcmp ( option , http ) ) { lower_transport_mask |= ( 1 < < RTSP_LOWER_TRANSPORT_TCP ) ; rt - > control_transport = RTSP_MODE_TUNNEL ; } else { / * Write options back into the buffer , using memmove instead * of strcpy since the strings may overlap . * / int len = strlen ( option ) ; memmove ( + + filename , option , len ) ; filename + = len ; if ( option_list ) * filename = ' & ' ; } } * filename = 0 ; } if ( ! lower_transport_mask ) lower_transport_mask = ( 1 < < RTSP_LOWER_TRANSPORT_NB ) - 1 ; if ( s - > oformat ) { / * Only UDP or TCP - UDP multicast isn ' t supported . * / lower_transport_mask & = ( 1 < < RTSP_LOWER_TRANSPORT_UDP ) | ( 1 < < RTSP_LOWER_TRANSPORT_TCP ) ; if ( ! lower_transport_mask || rt - > control_transport == RTSP_MODE_TUNNEL ) { av_log ( s , AV_LOG_ERROR , Unsupported lower transport method , only UDP and TCP are supported for output . \n ) ; err = AVERROR ( EINVAL ) ; goto fail ; } } / * Construct the URI used in request ; this is similar to s - > filename , * but with authentication credentials removed and RTSP specific options * stripped out . * / ff_url_join ( rt - > control_uri , sizeof ( rt - > control_uri ) , rtsp , NULL , host , port , %s , path ) ; if ( rt - > control_transport == RTSP_MODE_TUNNEL ) { / * set up initial handshake for tunneling * / char httpname[1024] ; char sessioncookie[17] ; char headers[1024] ; ff_url_join ( httpname , sizeof ( httpname ) , http , auth , host , port , %s , path ) ; snprintf ( sessioncookie , sizeof ( sessioncookie ) , %08x%08x , av_get_random_seed ( ) , av_get_random_seed ( ) ) ; / * GET requests * / if ( url_alloc ( & rt - > rtsp_hd , httpname , URL_RDONLY ) < 0 ) { err = AVERROR ( EIO ) ; goto fail ; } / * generate GET headers * / snprintf ( headers , sizeof ( headers ) , x - sessioncookie : %s\r\n Accept : application/x - rtsp - tunnelled\r\n Pragma : no - cache\r\n Cache - Control : no - cache\r\n , sessioncookie ) ; ff_http_set_headers ( rt - > rtsp_hd , headers ) ; / * complete the connection * / if ( url_connect ( rt - > rtsp_hd ) ) { err = AVERROR ( EIO ) ; goto fail ; } / * POST requests * / if ( url_alloc ( & rt - > rtsp_hd_out , httpname , URL_WRONLY ) < 0 ) { err = AVERROR ( EIO ) ; goto fail ; } / * generate POST headers * / snprintf ( headers , sizeof ( headers ) , x - sessioncookie : %s\r\n Content - Type : application/x - rtsp - tunnelled\r\n Pragma : no - cache\r\n Cache - Control : no - cache\r\n Content - Length : 32767\r\n Expires : Sun , 9 Jan 1972 00 : 00 : 00 GMT\r\n , sessioncookie ) ; ff_http_set_headers ( rt - > rtsp_hd_out , headers ) ; ff_http_set_chunked_transfer_encoding ( rt - > rtsp_hd_out , 0 ) ; / * Initialize the authentication state for the POST session . The HTTP * protocol implementation doesn ' t properly handle multi - pass * authentication for POST requests , since it would require one of * the following : * - implementing Expect : 100 - continue , which many HTTP servers * don ' t support anyway , even less the RTSP servers that do HTTP * tunneling * - sending the whole POST data until getting a 401 reply specifying * what authentication method to use , then resending all that data * - waiting for potential 401 replies directly after sending the * POST header ( waiting for some unspecified time ) * Therefore , we copy the full auth state , which works for both basic * and digest . ( For digest , we would have to synchronize the nonce * count variable between the two sessions , if we ' d do more requests * with the original session , though . ) * / ff_http_init_auth_state ( rt - > rtsp_hd_out , rt - > rtsp_hd ) ; / * complete the connection * / if ( url_connect ( rt - > rtsp_hd_out ) ) { err = AVERROR ( EIO ) ; goto fail ; } } else { / * open the tcp connection * / ff_url_join ( tcpname , sizeof ( tcpname ) , tcp , NULL , host , port , NULL ) ; if ( url_open ( & rt - > rtsp_hd , tcpname , URL_RDWR ) < 0 ) { err = AVERROR ( EIO ) ; goto fail ; } rt - > rtsp_hd_out = rt - > rtsp_hd ; } rt -",0
"static int ipvideo_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; IpvideoContext * s = avctx - > priv_data ; AVFrame * frame = data ; int ret ; if ( buf_size < 2 ) return AVERROR_INVALIDDATA ; / * decoding map contains 4 bits of information per 8x8 block * / s - > decoding_map_size = AV_RL16 ( avpkt - > data ) ; / * compressed buffer needs to be large enough to at least hold an entire * decoding map * / if ( buf_size < s - > decoding_map_size + 2 ) return buf_size ; if ( av_packet_get_side_data ( avpkt , AV_PKT_DATA_PARAM_CHANGE , NULL ) ) { av_frame_unref ( s - > last_frame ) ; av_frame_unref ( s - > second_last_frame ) ; } s - > decoding_map = buf + 2 ; bytestream2_init ( & s - > stream_ptr , buf + 2 + s - > decoding_map_size , buf_size - s - > decoding_map_size ) ; if ( ( ret = ff_get_buffer ( avctx , frame , AV_GET_BUFFER_FLAG_REF ) ) < 0 ) return ret ; if ( ! s - > is_16bpp ) { int size ; const uint8_t * pal = av_packet_get_side_data ( avpkt , AV_PKT_DATA_PALETTE , & size ) ; if ( pal & & size == AVPALETTE_SIZE ) { frame - > palette_has_changed = 1 ; memcpy ( s - > pal , pal , AVPALETTE_SIZE ) ; } else if ( pal ) { av_log ( avctx , AV_LOG_ERROR , Palette size %d is wrong\n , size ) ; } } ipvideo_decode_opcodes ( s , frame ) ; * got_frame = 1 ; / * shuffle frames * / av_frame_unref ( s - > second_last_frame ) ; FFSWAP ( AVFrame * , s - > second_last_frame , s - > last_frame ) ; if ( ( ret = av_frame_ref ( s - > last_frame , frame ) ) < 0 ) return ret ; / * report that the buffer was completely consumed * / return buf_size ; }",1
"static int process_ipmovie_chunk ( IPMVEContext * s , AVIOContext * pb , AVPacket * pkt ) { unsigned char chunk_preamble[CHUNK_PREAMBLE_SIZE] ; int chunk_type ; int chunk_size ; unsigned char opcode_preamble[OPCODE_PREAMBLE_SIZE] ; unsigned char opcode_type ; unsigned char opcode_version ; int opcode_size ; unsigned char scratch[1024] ; int i , j ; int first_color , last_color ; int audio_flags ; unsigned char r , g , b ; unsigned int width , height ; / * see if there are any pending packets * / chunk_type = load_ipmovie_packet ( s , pb , pkt ) ; if ( chunk_type ! = CHUNK_DONE ) return chunk_type ; / * read the next chunk , wherever the file happens to be pointing * / if ( avio_feof ( pb ) ) return CHUNK_EOF ; if ( avio_read ( pb , chunk_preamble , CHUNK_PREAMBLE_SIZE ) ! = CHUNK_PREAMBLE_SIZE ) return CHUNK_BAD ; chunk_size = AV_RL16 ( & chunk_preamble[0] ) ; chunk_type = AV_RL16 ( & chunk_preamble[2] ) ; av_log ( s - > avf , AV_LOG_TRACE , chunk type 0x%04X , 0x%04X bytes : , chunk_type , chunk_size ) ; switch ( chunk_type ) { case CHUNK_INIT_AUDIO : av_log ( s - > avf , AV_LOG_TRACE , initialize audio\n ) ; break ; case CHUNK_AUDIO_ONLY : av_log ( s - > avf , AV_LOG_TRACE , audio only\n ) ; break ; case CHUNK_INIT_VIDEO : av_log ( s - > avf , AV_LOG_TRACE , initialize video\n ) ; break ; case CHUNK_VIDEO : av_log ( s - > avf , AV_LOG_TRACE , video ( and audio ) \n ) ; break ; case CHUNK_SHUTDOWN : av_log ( s - > avf , AV_LOG_TRACE , shutdown\n ) ; break ; case CHUNK_END : av_log ( s - > avf , AV_LOG_TRACE , end\n ) ; break ; default : av_log ( s - > avf , AV_LOG_TRACE , invalid chunk\n ) ; chunk_type = CHUNK_BAD ; break ; } while ( ( chunk_size > 0 ) & & ( chunk_type ! = CHUNK_BAD ) ) { / * read the next chunk , wherever the file happens to be pointing * / if ( avio_feof ( pb ) ) { chunk_type = CHUNK_EOF ; break ; } if ( avio_read ( pb , opcode_preamble , CHUNK_PREAMBLE_SIZE ) ! = CHUNK_PREAMBLE_SIZE ) { chunk_type = CHUNK_BAD ; break ; } opcode_size = AV_RL16 ( & opcode_preamble[0] ) ; opcode_type = opcode_preamble[2] ; opcode_version = opcode_preamble[3] ; chunk_size - = OPCODE_PREAMBLE_SIZE ; chunk_size - = opcode_size ; if ( chunk_size < 0 ) { av_log ( s - > avf , AV_LOG_TRACE , chunk_size countdown just went negative\n ) ; chunk_type = CHUNK_BAD ; break ; } av_log ( s - > avf , AV_LOG_TRACE , opcode type %02X , version %d , 0x%04X bytes : , opcode_type , opcode_version , opcode_size ) ; switch ( opcode_type ) { case OPCODE_END_OF_STREAM : av_log ( s - > avf , AV_LOG_TRACE , end of stream\n ) ; avio_skip ( pb , opcode_size ) ; break ; case OPCODE_END_OF_CHUNK : av_log ( s - > avf , AV_LOG_TRACE , end of chunk\n ) ; avio_skip ( pb , opcode_size ) ; break ; case OPCODE_CREATE_TIMER : av_log ( s - > avf , AV_LOG_TRACE , create timer\n ) ; if ( ( opcode_version > 0 ) || ( opcode_size ! = 6 ) ) { av_log ( s - > avf , AV_LOG_TRACE , bad create_timer opcode\n ) ; chunk_type = CHUNK_BAD ; break ; } if ( avio_read ( pb , scratch , opcode_size ) ! = opcode_size ) { chunk_type = CHUNK_BAD ; break ; } s - > frame_pts_inc = ( ( uint64_t ) AV_RL32 ( & scratch[0] ) ) * AV_RL16 ( & scratch[4] ) ; break ; case OPCODE_INIT_AUDIO_BUFFERS : av_log ( s - > avf , AV_LOG_TRACE , initialize audio buffers\n ) ; if ( opcode_version > 1 || opcode_size > 10 || opcode_size < 6 ) { av_log ( s - > avf , AV_LOG_TRACE , bad init_audio_buffers opcode\n ) ; chunk_type = CHUNK_BAD ; break ; } if ( avio_read ( pb , scratch , opcode_size ) ! = opcode_size ) { chunk_type = CHUNK_BAD ; break ; } s - > audio_sample_rate = AV_RL16 ( & scratch[4] ) ; audio_flags = AV_RL16 ( & scratch[2] ) ; / * bit 0 of the flags : 0 = mono , 1 = stereo * / s - > audio_channels = ( audio_flags & 1 ) + 1 ; / * bit 1 of the flags : 0 = 8 bit , 1 = 16 bit * / s - > audio_bits = ( ( ( audio_flags > > 1 ) & 1 ) + 1 ) * 8 ; / * bit 2 indicates compressed audio in version 1 opcode * / if ( ( opcode_version == 1 ) & & ( audio_flags & 0x4 ) ) s - > audio_type = AV_CODEC_ID_INTERPLAY_DPCM ; else if ( s - > audio_bits == 16 ) s - > audio_type = AV_CODEC_ID_PCM_S16LE ; else s - > audio_type = AV_CODEC_ID_PCM_U8 ; av_log ( s - > avf , AV_LOG_TRACE , audio : %d bits , %d Hz , %s , %s format\n , s - > audio_bits , s - > audio_sample_rate , ( s - > audio_channels == 2 ) ? stereo : mono , ( s - > audio_type == AV_CODEC_ID_INTERPLAY_DPCM ) ? Interplay audio : PCM ) ; break ; case OPCODE_START_STOP_AUDIO : av_log ( s - > avf , AV_LOG_TRACE , start/stop audio\n ) ; avio_skip ( pb , opcode_size ) ; break ; case OPCODE_INIT_VIDEO_BUFFERS : av_log ( s - > avf , AV_LOG_TRACE , initialize video buffers\n ) ; if ( ( opcode_version > 2 ) || ( opcode_size > 8 ) || opcode_size < 4 || opcode_version == 2 & & opcode_size < 8 ) { av_log ( s - > avf , AV_LOG_TRACE , bad init_video_buffers opcode\n ) ; chunk_type = CHUNK_BAD ; break ; } if ( avio_read ( pb , scratch , opcode_size ) ! = opcode_size ) { chunk_type = CHUNK_BAD ; break ; } width = AV_RL16 ( & scratch[0] ) * 8 ; height = AV_RL16 ( & scratch[2] ) * 8 ; if ( width ! = s - > video_width ) { s - > video_width = width ; s - > changed + + ; } if ( height ! = s - > video_height ) { s - > video_height = height ; s - > changed + + ; } if ( opcode_version < 2 || ! AV_RL16 ( & scratch[6] ) ) { s - > video_bpp = 8 ; } else { s - > video_bpp = 16 ; } av_log ( s - > avf , AV_LOG_TRACE , video resolution : %d x %d\n , s - > video_width , s - > video_height ) ; break ; case OPCODE_UNKNOWN_06 : case OPCODE_UNKNOWN_0E : case OPCODE_UNKNOWN_10 : case OPCODE_UNKNOWN_12 : case OPCODE_UNKNOWN_13 : case OPCODE_UNKNOWN_14 : case OPCODE_UNKNOWN_15 : av_log ( s - > avf , AV_LOG_TRACE , unknown ( but documented )",0
"static OutputStream * new_video_stream ( OptionsContext * o , AVFormatContext * oc , int source_index ) { AVStream * st ; OutputStream * ost ; AVCodecContext * video_enc ; char * frame_rate = NULL , * frame_aspect_ratio = NULL ; ost = new_output_stream ( o , oc , AVMEDIA_TYPE_VIDEO , source_index ) ; st = ost - > st ; video_enc = ost - > enc_ctx ; MATCH_PER_STREAM_OPT ( frame_rates , str , frame_rate , oc , st ) ; if ( frame_rate & & av_parse_video_rate ( & ost - > frame_rate , frame_rate ) < 0 ) { av_log ( NULL , AV_LOG_FATAL , Invalid framerate value : %s\n , frame_rate ) ; exit_program ( 1 ) ; } if ( frame_rate & & video_sync_method == VSYNC_PASSTHROUGH ) av_log ( NULL , AV_LOG_ERROR , Using - vsync 0 and - r can produce invalid output files\n ) ; MATCH_PER_STREAM_OPT ( frame_aspect_ratios , str , frame_aspect_ratio , oc , st ) ; if ( frame_aspect_ratio ) { AVRational q ; if ( av_parse_ratio ( & q , frame_aspect_ratio , 255 , 0 , NULL ) < 0 || q . num < = 0 || q . den < = 0 ) { av_log ( NULL , AV_LOG_FATAL , Invalid aspect ratio : %s\n , frame_aspect_ratio ) ; exit_program ( 1 ) ; } ost - > frame_aspect_ratio = q ; } MATCH_PER_STREAM_OPT ( filter_scripts , str , ost - > filters_script , oc , st ) ; MATCH_PER_STREAM_OPT ( filters , str , ost - > filters , oc , st ) ; if ( ! ost - > stream_copy ) { const char * p = NULL ; char * frame_size = NULL ; char * frame_pix_fmt = NULL ; char * intra_matrix = NULL , * inter_matrix = NULL ; char * chroma_intra_matrix = NULL ; int do_pass = 0 ; int i ; MATCH_PER_STREAM_OPT ( frame_sizes , str , frame_size , oc , st ) ; if ( frame_size & & av_parse_video_size ( & video_enc - > width , & video_enc - > height , frame_size ) < 0 ) { av_log ( NULL , AV_LOG_FATAL , Invalid frame size : %s . \n , frame_size ) ; exit_program ( 1 ) ; } video_enc - > bits_per_raw_sample = frame_bits_per_raw_sample ; MATCH_PER_STREAM_OPT ( frame_pix_fmts , str , frame_pix_fmt , oc , st ) ; if ( frame_pix_fmt & & * frame_pix_fmt == ' + ' ) { ost - > keep_pix_fmt = 1 ; if ( ! * + + frame_pix_fmt ) frame_pix_fmt = NULL ; } if ( frame_pix_fmt & & ( video_enc - > pix_fmt = av_get_pix_fmt ( frame_pix_fmt ) ) == AV_PIX_FMT_NONE ) { av_log ( NULL , AV_LOG_FATAL , Unknown pixel format requested : %s . \n , frame_pix_fmt ) ; exit_program ( 1 ) ; } st - > sample_aspect_ratio = video_enc - > sample_aspect_ratio ; if ( intra_only ) video_enc - > gop_size = 0 ; MATCH_PER_STREAM_OPT ( intra_matrices , str , intra_matrix , oc , st ) ; if ( intra_matrix ) { if ( ! ( video_enc - > intra_matrix = av_mallocz ( sizeof ( * video_enc - > intra_matrix ) * 64 ) ) ) { av_log ( NULL , AV_LOG_FATAL , Could not allocate memory for intra matrix . \n ) ; exit_program ( 1 ) ; } parse_matrix_coeffs ( video_enc - > intra_matrix , intra_matrix ) ; } MATCH_PER_STREAM_OPT ( chroma_intra_matrices , str , chroma_intra_matrix , oc , st ) ; if ( chroma_intra_matrix ) { uint16_t * p = av_mallocz ( sizeof ( * video_enc - > chroma_intra_matrix ) * 64 ) ; if ( ! p ) { av_log ( NULL , AV_LOG_FATAL , Could not allocate memory for intra matrix . \n ) ; exit_program ( 1 ) ; } av_codec_set_chroma_intra_matrix ( video_enc , p ) ; parse_matrix_coeffs ( p , chroma_intra_matrix ) ; } MATCH_PER_STREAM_OPT ( inter_matrices , str , inter_matrix , oc , st ) ; if ( inter_matrix ) { if ( ! ( video_enc - > inter_matrix = av_mallocz ( sizeof ( * video_enc - > inter_matrix ) * 64 ) ) ) { av_log ( NULL , AV_LOG_FATAL , Could not allocate memory for inter matrix . \n ) ; exit_program ( 1 ) ; } parse_matrix_coeffs ( video_enc - > inter_matrix , inter_matrix ) ; } MATCH_PER_STREAM_OPT ( rc_overrides , str , p , oc , st ) ; for ( i = 0 ; p ; i + + ) { int start , end , q ; int e = sscanf ( p , %d , %d , %d , & start , & end , & q ) ; if ( e ! = 3 ) { av_log ( NULL , AV_LOG_FATAL , error parsing rc_override\n ) ; exit_program ( 1 ) ; } / * FIXME realloc failure * / video_enc - > rc_override = av_realloc_array ( video_enc - > rc_override , i + 1 , sizeof ( RcOverride ) ) ; video_enc - > rc_override[i] . start_frame = start ; video_enc - > rc_override[i] . end_frame = end ; if ( q > 0 ) { video_enc - > rc_override[i] . qscale = q ; video_enc - > rc_override[i] . quality_factor = 1 . 0 ; } else { video_enc - > rc_override[i] . qscale = 0 ; video_enc - > rc_override[i] . quality_factor = - q/100 . 0 ; } p = strchr ( p , ' / ' ) ; if ( p ) p + + ; } video_enc - > rc_override_count = i ; if ( do_psnr ) video_enc - > flags|= CODEC_FLAG_PSNR ; / * two pass mode * / MATCH_PER_STREAM_OPT ( pass , i , do_pass , oc , st ) ; if ( do_pass ) { if ( do_pass & 1 ) { video_enc - > flags |= CODEC_FLAG_PASS1 ; av_dict_set ( & ost - > encoder_opts , flags , + pass1 , AV_DICT_APPEND ) ; } if ( do_pass & 2 ) { video_enc - > flags |= CODEC_FLAG_PASS2 ; av_dict_set ( & ost - > encoder_opts , flags , + pass2 , AV_DICT_APPEND ) ; } } MATCH_PER_STREAM_OPT ( passlogfiles , str , ost - > logfile_prefix , oc , st ) ; if ( ost - > logfile_prefix & & ! ( ost - > logfile_prefix = av_strdup ( ost - > logfile_prefix ) ) ) exit_program ( 1 ) ; MATCH_PER_STREAM_OPT ( forced_key_frames , str , ost - > forced_keyframes , oc , st ) ; if ( ost - > forced_keyframes ) ost - > forced_keyframes = av_strdup ( ost - > forced_keyframes ) ; MATCH_PER_STREAM_OPT ( force_fps , i , ost - > force_fps , oc , st ) ; ost - > top_field_first = - 1 ; MATCH_PER_STREAM_OPT ( top_field_first , i , ost - > top_field_first , oc , st ) ; ost - > avfilter = get_ost_filters ( o , oc , ost ) ; if ( ! ost - > avfilter ) exit_program ( 1 ) ; } else { MATCH_PER_STREAM_OPT ( copy_initial_nonkeyframes , i , ost - > copy_initial_nonkeyframes , oc , st",1
"int av_lockmgr_register ( int ( * cb ) ( void * * mutex , enum AVLockOp op ) ) { if ( lockmgr_cb ) { // There is no good way to rollback a failure to destroy the // mutex , so we ignore failures . lockmgr_cb ( & codec_mutex , AV_LOCK_DESTROY ) ; lockmgr_cb ( & avformat_mutex , AV_LOCK_DESTROY ) ; lockmgr_cb = NULL ; codec_mutex = NULL ; avformat_mutex = NULL ; } if ( cb ) { void * new_codec_mutex = NULL ; void * new_avformat_mutex = NULL ; int err ; if ( err = cb ( & new_codec_mutex , AV_LOCK_CREATE ) ) { return err > 0 ? AVERROR_UNKNOWN : err ; } if ( err = cb ( & new_avformat_mutex , AV_LOCK_CREATE ) ) { // Ignore failures to destroy the newly created mutex . cb ( & new_codec_mutex , AV_LOCK_DESTROY ) ; return err > 0 ? AVERROR_UNKNOWN : err ; } lockmgr_cb = cb ; codec_mutex = new_codec_mutex ; avformat_mutex = new_avformat_mutex ; } return 0 ; }",1
"static void compute_stereo ( MPADecodeContext * s , GranuleDef * g0 , GranuleDef * g1 ) { int i , j , k , l ; int sf_max , sf , len , non_zero_found ; INTFLOAT ( * is_tab ) [16] , * tab0 , * tab1 , tmp0 , tmp1 , v1 , v2 ; int non_zero_found_short[3] ; / * intensity stereo * / if ( s - > mode_ext & MODE_EXT_I_STEREO ) { if ( ! s - > lsf ) { is_tab = is_table ; sf_max = 7 ; } else { is_tab = is_table_lsf[g1 - > scalefac_compress & 1] ; sf_max = 16 ; } tab0 = g0 - > sb_hybrid + 576 ; tab1 = g1 - > sb_hybrid + 576 ; non_zero_found_short[0] = 0 ; non_zero_found_short[1] = 0 ; non_zero_found_short[2] = 0 ; k = ( 13 - g1 - > short_start ) * 3 + g1 - > long_end - 3 ; for ( i = 12 ; i > = g1 - > short_start ; i - - ) { / * for last band , use previous scale factor * / if ( i ! = 11 ) k - = 3 ; len = band_size_short[s - > sample_rate_index][i] ; for ( l = 2 ; l > = 0 ; l - - ) { tab0 - = len ; tab1 - = len ; if ( ! non_zero_found_short[l] ) { / * test if non zero band . if so , stop doing i - stereo * / for ( j = 0 ; j < len ; j + + ) { if ( tab1[j] ! = 0 ) { non_zero_found_short[l] = 1 ; goto found1 ; } } sf = g1 - > scale_factors[k + l] ; if ( sf > = sf_max ) goto found1 ; v1 = is_tab[0][sf] ; v2 = is_tab[1][sf] ; for ( j = 0 ; j < len ; j + + ) { tmp0 = tab0[j] ; tab0[j] = MULLx ( tmp0 , v1 , FRAC_BITS ) ; tab1[j] = MULLx ( tmp0 , v2 , FRAC_BITS ) ; } } else { found1 : if ( s - > mode_ext & MODE_EXT_MS_STEREO ) { / * lower part of the spectrum : do ms stereo if enabled * / for ( j = 0 ; j < len ; j + + ) { tmp0 = tab0[j] ; tmp1 = tab1[j] ; tab0[j] = MULLx ( tmp0 + tmp1 , ISQRT2 , FRAC_BITS ) ; tab1[j] = MULLx ( tmp0 - tmp1 , ISQRT2 , FRAC_BITS ) ; } } } } } non_zero_found = non_zero_found_short[0] | non_zero_found_short[1] | non_zero_found_short[2] ; for ( i = g1 - > long_end - 1 ; i > = 0 ; i - - ) { len = band_size_long[s - > sample_rate_index][i] ; tab0 - = len ; tab1 - = len ; / * test if non zero band . if so , stop doing i - stereo * / if ( ! non_zero_found ) { for ( j = 0 ; j < len ; j + + ) { if ( tab1[j] ! = 0 ) { non_zero_found = 1 ; goto found2 ; } } / * for last band , use previous scale factor * / k = ( i == 21 ) ? 20 : i ; sf = g1 - > scale_factors[k] ; if ( sf > = sf_max ) goto found2 ; v1 = is_tab[0][sf] ; v2 = is_tab[1][sf] ; for ( j = 0 ; j < len ; j + + ) { tmp0 = tab0[j] ; tab0[j] = MULLx ( tmp0 , v1 , FRAC_BITS ) ; tab1[j] = MULLx ( tmp0 , v2 , FRAC_BITS ) ; } } else { found2 : if ( s - > mode_ext & MODE_EXT_MS_STEREO ) { / * lower part of the spectrum : do ms stereo if enabled * / for ( j = 0 ; j < len ; j + + ) { tmp0 = tab0[j] ; tmp1 = tab1[j] ; tab0[j] = MULLx ( tmp0 + tmp1 , ISQRT2 , FRAC_BITS ) ; tab1[j] = MULLx ( tmp0 - tmp1 , ISQRT2 , FRAC_BITS ) ; } } } } } else if ( s - > mode_ext & MODE_EXT_MS_STEREO ) { / * ms stereo ONLY * / / * NOTE : the 1/sqrt ( 2 ) normalization factor is included in the global gain * / if USE_FLOATS s - > fdsp - > butterflies_float ( g0 - > sb_hybrid , g1 - > sb_hybrid , 576 ) ; else tab0 = g0 - > sb_hybrid ; tab1 = g1 - > sb_hybrid ; for ( i = 0 ; i < 576 ; i + + ) { tmp0 = tab0[i] ; tmp1 = tab1[i] ; tab0[i] = tmp0 + tmp1 ; tab1[i] = tmp0 - tmp1 ; } endif } }",1
"static void dequantization_int ( int x , int y , Jpeg2000Cblk * cblk , Jpeg2000Component * comp , Jpeg2000T1Context * t1 , Jpeg2000Band * band ) { int i , j ; int w = cblk - > coord[0][1] - cblk - > coord[0][0] ; for ( j = 0 ; j < ( cblk - > coord[1][1] - cblk - > coord[1][0] ) ; + + j ) { int32_t * datap = & comp - > i_data[ ( comp - > coord[0][1] - comp - > coord[0][0] ) * ( y + j ) + x] ; int * src = t1 - > data[j] ; if ( band - > i_stepsize == 16384 ) { for ( i = 0 ; i < w ; + + i ) datap[i] = src[i] / 2 ; } else { // This should be VERY uncommon for ( i = 0 ; i < w ; + + i ) datap[i] = ( src[i] * ( int64_t ) band - > i_stepsize ) / 32768 ; } } }",0
"static int gxf_probe ( AVProbeData * p ) { static const uint8_t startcode[] = { 0 , 0 , 0 , 0 , 1 , 0xbc } ; // start with map packet static const uint8_t endcode[] = { 0 , 0 , 0 , 0 , 0xe1 , 0xe2 } ; if ( p - > buf_size < 16 ) return 0 ; if ( ! memcmp ( p - > buf , startcode , sizeof ( startcode ) ) & & ! memcmp ( & p - > buf[16 - sizeof ( endcode ) ] , endcode , sizeof ( endcode ) ) ) return AVPROBE_SCORE_MAX ; return 0 ; }",0
"static int vaapi_encode_h265_init_sequence_params ( AVCodecContext * avctx ) { VAAPIEncodeContext * ctx = avctx - > priv_data ; VAEncSequenceParameterBufferHEVC * vseq = ctx - > codec_sequence_params ; VAEncPictureParameterBufferHEVC * vpic = ctx - > codec_picture_params ; VAAPIEncodeH265Context * priv = ctx - > priv_data ; VAAPIEncodeH265MiscSequenceParams * mseq = & priv - > misc_sequence_params ; int i ; { // general_profile_space == 0 . vseq - > general_profile_idc = 1 ; // Main profile ( ctx - > codec_profile ? ) vseq - > general_tier_flag = 0 ; vseq - > general_level_idc = avctx - > level * 3 ; vseq - > intra_period = 0 ; vseq - > intra_idr_period = 0 ; vseq - > ip_period = 0 ; vseq - > pic_width_in_luma_samples = ctx - > aligned_width ; vseq - > pic_height_in_luma_samples = ctx - > aligned_height ; vseq - > seq_fields . bits . chroma_format_idc = 1 ; // 4 : 2 : 0 . vseq - > seq_fields . bits . separate_colour_plane_flag = 0 ; vseq - > seq_fields . bits . bit_depth_luma_minus8 = 0 ; // 8 - bit luma . vseq - > seq_fields . bits . bit_depth_chroma_minus8 = 0 ; // 8 - bit chroma . // Other misc flags all zero . // These have to come from the capabilities of the encoder . We have // no way to query it , so just hardcode ones which worked for me . . . // CTB size from 8x8 to 32x32 . vseq - > log2_min_luma_coding_block_size_minus3 = 0 ; vseq - > log2_diff_max_min_luma_coding_block_size = 2 ; // Transform size from 4x4 to 32x32 . vseq - > log2_min_transform_block_size_minus2 = 0 ; vseq - > log2_diff_max_min_transform_block_size = 3 ; // Full transform hierarchy allowed ( 2 - 5 ) . vseq - > max_transform_hierarchy_depth_inter = 3 ; vseq - > max_transform_hierarchy_depth_intra = 3 ; vseq - > vui_parameters_present_flag = 0 ; vseq - > bits_per_second = avctx - > bit_rate ; if ( avctx - > framerate . num > 0 & & avctx - > framerate . den > 0 ) { vseq - > vui_num_units_in_tick = avctx - > framerate . num ; vseq - > vui_time_scale = avctx - > framerate . den ; } else { vseq - > vui_num_units_in_tick = avctx - > time_base . num ; vseq - > vui_time_scale = avctx - > time_base . den ; } vseq - > intra_period = ctx - > p_per_i * ( ctx - > b_per_p + 1 ) ; vseq - > intra_idr_period = vseq - > intra_period ; vseq - > ip_period = ctx - > b_per_p + 1 ; } { vpic - > decoded_curr_pic . picture_id = VA_INVALID_ID ; vpic - > decoded_curr_pic . flags = VA_PICTURE_HEVC_INVALID ; for ( i = 0 ; i < FF_ARRAY_ELEMS ( vpic - > reference_frames ) ; i + + ) { vpic - > reference_frames[i] . picture_id = VA_INVALID_ID ; vpic - > reference_frames[i] . flags = VA_PICTURE_HEVC_INVALID ; } vpic - > collocated_ref_pic_index = 0xff ; vpic - > last_picture = 0 ; vpic - > pic_init_qp = priv - > fixed_qp_idr ; vpic - > diff_cu_qp_delta_depth = 0 ; vpic - > pps_cb_qp_offset = 0 ; vpic - > pps_cr_qp_offset = 0 ; // tiles_enabled_flag == 0 , so ignore num_tile_ ( rows|columns ) _minus1 . vpic - > log2_parallel_merge_level_minus2 = 0 ; // No limit on size . vpic - > ctu_max_bitsize_allowed = 0 ; vpic - > num_ref_idx_l0_default_active_minus1 = 0 ; vpic - > num_ref_idx_l1_default_active_minus1 = 0 ; vpic - > slice_pic_parameter_set_id = 0 ; vpic - > pic_fields . bits . screen_content_flag = 0 ; vpic - > pic_fields . bits . enable_gpu_weighted_prediction = 0 ; // Per - CU QP changes are required for non - constant - QP modes . vpic - > pic_fields . bits . cu_qp_delta_enabled_flag = ctx - > va_rc_mode ! = VA_RC_CQP ; } { mseq - > video_parameter_set_id = 5 ; mseq - > seq_parameter_set_id = 5 ; mseq - > vps_max_layers_minus1 = 0 ; mseq - > vps_max_sub_layers_minus1 = 0 ; mseq - > vps_temporal_id_nesting_flag = 1 ; mseq - > sps_max_sub_layers_minus1 = 0 ; mseq - > sps_temporal_id_nesting_flag = 1 ; for ( i = 0 ; i < 32 ; i + + ) { mseq - > general_profile_compatibility_flag[i] = ( i == vseq - > general_profile_idc ) ; } mseq - > general_progressive_source_flag = 1 ; mseq - > general_interlaced_source_flag = 0 ; mseq - > general_non_packed_constraint_flag = 0 ; mseq - > general_frame_only_constraint_flag = 1 ; mseq - > general_inbld_flag = 0 ; mseq - > log2_max_pic_order_cnt_lsb_minus4 = 8 ; mseq - > vps_sub_layer_ordering_info_present_flag = 0 ; mseq - > vps_max_dec_pic_buffering_minus1[0] = 1 ; mseq - > vps_max_num_reorder_pics[0] = ctx - > b_per_p ; mseq - > vps_max_latency_increase_plus1[0] = 0 ; mseq - > sps_sub_layer_ordering_info_present_flag = 0 ; mseq - > sps_max_dec_pic_buffering_minus1[0] = 1 ; mseq - > sps_max_num_reorder_pics[0] = ctx - > b_per_p ; mseq - > sps_max_latency_increase_plus1[0] = 0 ; mseq - > vps_timing_info_present_flag = 1 ; mseq - > vps_num_units_in_tick = avctx - > time_base . num ; mseq - > vps_time_scale = avctx - > time_base . den ; mseq - > vps_poc_proportional_to_timing_flag = 1 ; mseq - > vps_num_ticks_poc_diff_minus1 = 0 ; if ( ctx - > input_width ! = ctx - > aligned_width || ctx - > input_height ! = ctx - > aligned_height ) { mseq - > conformance_window_flag = 1 ; mseq - > conf_win_left_offset = 0 ; mseq - > conf_win_right_offset = ( ctx - > aligned_width - ctx - > input_width ) / 2 ; mseq - > conf_win_top_offset = 0 ; mseq - > conf_win_bottom_offset = ( ctx - > aligned_height - ctx - > input_height ) / 2 ; } else { mseq - > conformance_window_flag = 0 ; } mseq - > num_short_term_ref_pic_sets = 0 ; // STRPSs should ideally be here rather than repeated in each slice . mseq - > vui_parameters_present_flag = 1 ; if ( avctx - > sample_aspect_ratio . num ! = 0 ) { mseq - > aspect_ratio_info_present_flag = 1 ; if ( avctx - > sample_aspect_ratio . num == avctx - > sample_aspect_ratio . den ) { mseq - > aspect_ratio_idc = 1 ; } else { mseq - > aspect_ratio_idc = 255 ; // Extended SAR . mseq - > sar_width = avctx - > sample_aspect_ratio . num ; mseq - > sar_height = avctx - > sample_aspect_ratio . den ; } } if ( 1 ) { // Should this be conditional on some of these being set ? mseq - > video_signal_type_present_flag = 1 ; mseq - > video_format = 5 ; // Unspecified . mseq - > video_full_range_flag = 0 ; mseq - > colour_description_present_flag = 1 ; mseq - > colour_primaries = avctx - > color_primaries ; mseq - > transfer_characteristics = avctx - > color_trc ; mseq - > matrix_coeffs = avctx - > colorspace ; } } return 0 ; }",0
"int ff_h264_decode_mb_cabac ( const H264Context * h , H264SliceContext * sl ) { int mb_xy ; int mb_type , partition_count , cbp = 0 ; int dct8x8_allowed= h - > pps . transform_8x8_mode ; int decode_chroma = h - > sps . chroma_format_idc == 1 || h - > sps . chroma_format_idc == 2 ; const int pixel_shift = h - > pixel_shift ; mb_xy = sl - > mb_xy = sl - > mb_x + sl - > mb_y * h - > mb_stride ; ff_tlog ( h - > avctx , pic : %d mb : %d/%d\n , h - > frame_num , sl - > mb_x , sl - > mb_y ) ; if ( sl - > slice_type_nos ! = AV_PICTURE_TYPE_I ) { int skip ; / * a skipped mb needs the aff flag from the following mb * / if ( FRAME_MBAFF ( h ) & & ( sl - > mb_y & 1 ) == 1 & & sl - > prev_mb_skipped ) skip = sl - > next_mb_skipped ; else skip = decode_cabac_mb_skip ( h , sl , sl - > mb_x , sl - > mb_y ) ; / * read skip flags * / if ( skip ) { if ( FRAME_MBAFF ( h ) & & ( sl - > mb_y & 1 ) == 0 ) { h - > cur_pic . mb_type[mb_xy] = MB_TYPE_SKIP ; sl - > next_mb_skipped = decode_cabac_mb_skip ( h , sl , sl - > mb_x , sl - > mb_y + 1 ) ; if ( ! sl - > next_mb_skipped ) sl - > mb_mbaff = sl - > mb_field_decoding_flag = decode_cabac_field_decoding_flag ( h , sl ) ; } decode_mb_skip ( h , sl ) ; h - > cbp_table[mb_xy] = 0 ; h - > chroma_pred_mode_table[mb_xy] = 0 ; sl - > last_qscale_diff = 0 ; return 0 ; } } if ( FRAME_MBAFF ( h ) ) { if ( ( sl - > mb_y & 1 ) == 0 ) sl - > mb_mbaff = sl - > mb_field_decoding_flag = decode_cabac_field_decoding_flag ( h , sl ) ; } sl - > prev_mb_skipped = 0 ; fill_decode_neighbors ( h , sl , - ( MB_FIELD ( sl ) ) ) ; if ( sl - > slice_type_nos == AV_PICTURE_TYPE_B ) { int ctx = 0 ; assert ( sl - > slice_type_nos == AV_PICTURE_TYPE_B ) ; if ( ! IS_DIRECT ( sl - > left_type[LTOP] - 1 ) ) ctx + + ; if ( ! IS_DIRECT ( sl - > top_type - 1 ) ) ctx + + ; if ( ! get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[27 + ctx] ) ) { mb_type= 0 ; / * B_Direct_16x16 * / } else if ( ! get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[27 + 3] ) ) { mb_type= 1 + get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[27 + 5] ) ; / * B_L[01]_16x16 * / } else { int bits ; bits = get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[27 + 4] ) < < 3 ; bits + = get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[27 + 5] ) < < 2 ; bits + = get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[27 + 5] ) < < 1 ; bits + = get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[27 + 5] ) ; if ( bits < 8 ) { mb_type= bits + 3 ; / * B_Bi_16x16 through B_L1_L0_16x8 * / } else if ( bits == 13 ) { mb_type = decode_cabac_intra_mb_type ( sl , 32 , 0 ) ; goto decode_intra_mb ; } else if ( bits == 14 ) { mb_type= 11 ; / * B_L1_L0_8x16 * / } else if ( bits == 15 ) { mb_type= 22 ; / * B_8x8 * / } else { bits= ( bits < < 1 ) + get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[27 + 5] ) ; mb_type= bits - 4 ; / * B_L0_Bi_ * through B_Bi_Bi_ * * / } } partition_count = ff_h264_b_mb_type_info[mb_type] . partition_count ; mb_type = ff_h264_b_mb_type_info[mb_type] . type ; } else if ( sl - > slice_type_nos == AV_PICTURE_TYPE_P ) { if ( get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[14] ) == 0 ) { / * P - type * / if ( get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[15] ) == 0 ) { / * P_L0_D16x16 , P_8x8 * / mb_type= 3 * get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[16] ) ; } else { / * P_L0_D8x16 , P_L0_D16x8 * / mb_type= 2 - get_cabac_noinline ( & sl - > cabac , & sl - > cabac_state[17] ) ; } partition_count = ff_h264_p_mb_type_info[mb_type] . partition_count ; mb_type = ff_h264_p_mb_type_info[mb_type] . type ; } else { mb_type = decode_cabac_intra_mb_type ( sl , 17 , 0 ) ; goto decode_intra_mb ; } } else { mb_type = decode_cabac_intra_mb_type ( sl , 3 , 1 ) ; if ( sl - > slice_type == AV_PICTURE_TYPE_SI & & mb_type ) mb_type - - ; assert ( sl - > slice_type_nos == AV_PICTURE_TYPE_I ) ; decode_intra_mb : partition_count = 0 ; cbp = ff_h264_i_mb_type_info[mb_type] . cbp ; sl - > intra16x16_pred_mode = ff_h264_i_mb_type_info[mb_type] . pred_mode ; mb_type = ff_h264_i_mb_type_info[mb_type] . type ; } if ( MB_FIELD ( sl ) ) mb_type |= MB_TYPE_INTERLACED ; h - > slice_table[mb_xy] = sl - > slice_num ; if ( IS_INTRA_PCM ( mb_type ) ) { const int mb_size = ff_h264_mb_sizes[h - > sps . chroma_format_idc] * h - > sps . bit_depth_luma > > 3 ; const uint8_t * ptr ; // We assume these blocks are very rare so we do not optimize it . // FIXME The two following lines get the bitstream position in the cabac // decode , I think it should be done by a function in cabac . h ( or cabac . c ) . ptr= sl - > cabac . bytestream ; if ( sl - > cabac . low & 0x1 ) ptr - - ; if ( CABAC_BITS==16 ) { if ( sl - > cabac . low & 0x1FF ) ptr - - ; } // The pixels are stored in the same order as levels in h - > mb array . if ( ( int ) ( sl - > cabac . bytestream_end - ptr ) < mb_size ) return - 1 ; sl - > intra_pcm_ptr = ptr ; ptr + = mb_size ; ff_init_cabac_decoder ( & sl - > cabac , ptr , sl - > cabac . bytestream_end - ptr ) ; // All blocks are present h - > cbp_table[mb_xy] = 0xf7ef ; h - > chroma_pred_mode_table[mb_xy] = 0 ; // In deblocking ,",0
"static void rdft_calc_c ( RDFTContext * s , FFTSample * data ) { int i , i1 , i2 ; FFTComplex ev , od ; const int n = 1 < < s - > nbits ; const float k1 = 0 . 5 ; const float k2 = 0 . 5 - s - > inverse ; const FFTSample * tcos = s - > tcos ; const FFTSample * tsin = s - > tsin ; if ( ! s - > inverse ) { s - > fft . fft_permute ( & s - > fft , ( FFTComplex * ) data ) ; s - > fft . fft_calc ( & s - > fft , ( FFTComplex * ) data ) ; } / * i=0 is a special case because of packing , the DC term is real , so we are going to throw the N/2 term ( also real ) in with it . * / ev . re = data[0] ; data[0] = ev . re + data[1] ; data[1] = ev . re - data[1] ; for ( i = 1 ; i < ( n > > 2 ) ; i + + ) { i1 = 2 * i ; i2 = n - i1 ; / * Separate even and odd FFTs * / ev . re = k1 * ( data[i1 ] + data[i2 ] ) ; od . im = - k2 * ( data[i1 ] - data[i2 ] ) ; ev . im = k1 * ( data[i1 + 1] - data[i2 + 1] ) ; od . re = k2 * ( data[i1 + 1] + data[i2 + 1] ) ; / * Apply twiddle factors to the odd FFT and add to the even FFT * / data[i1 ] = ev . re + od . re * tcos[i] - od . im * tsin[i] ; data[i1 + 1] = ev . im + od . im * tcos[i] + od . re * tsin[i] ; data[i2 ] = ev . re - od . re * tcos[i] + od . im * tsin[i] ; data[i2 + 1] = - ev . im + od . im * tcos[i] + od . re * tsin[i] ; } data[2 * i + 1]=s - > sign_convention * data[2 * i + 1] ; if ( s - > inverse ) { data[0] * = k1 ; data[1] * = k1 ; s - > fft . fft_permute ( & s - > fft , ( FFTComplex * ) data ) ; s - > fft . fft_calc ( & s - > fft , ( FFTComplex * ) data ) ; } }",0
"static int targa_decode_rle ( AVCodecContext * avctx , TargaContext * s , const uint8_t * src , int src_size , uint8_t * dst , int w , int h , int stride , int bpp ) { int i , x , y ; int depth = ( bpp + 1 ) > > 3 ; int type , count ; int diff ; const uint8_t * src_end = src + src_size ; diff = stride - w * depth ; x = y = 0 ; while ( y < h ) { CHECK_BUFFER_SIZE ( src , src_end , 1 , image type ) ; type = * src + + ; count = ( type & 0x7F ) + 1 ; type & = 0x80 ; if ( ( x + count > w ) & & ( x + count + 1 > ( h - y ) * w ) ) { av_log ( avctx , AV_LOG_ERROR , Packet went out of bounds : position ( %i , %i ) size %i\n , x , y , count ) ; return - 1 ; } if ( type ) { CHECK_BUFFER_SIZE ( src , src_end , depth , image data ) ; } else { CHECK_BUFFER_SIZE ( src , src_end , count * depth , image data ) ; } for ( i = 0 ; i < count ; i + + ) { switch ( depth ) { case 1 : * dst = * src ; break ; case 2 : AV_WN16A ( dst , AV_RN16A ( src ) ) ; break ; case 3 : dst[0] = src[0] ; dst[1] = src[1] ; dst[2] = src[2] ; break ; case 4 : AV_WN32A ( dst , AV_RN32A ( src ) ) ; break ; } dst + = depth ; if ( ! type ) src + = depth ; x + + ; if ( x == w ) { x = 0 ; y + + ; dst + = diff ; } } if ( type ) src + = depth ; } return src_size ; }",0
"static int udp_read_packet ( AVFormatContext * s , RTSPStream * * prtsp_st , uint8_t * buf , int buf_size ) { RTSPState * rt = s - > priv_data ; RTSPStream * rtsp_st ; fd_set rfds ; int fd , fd_max , n , i , ret , tcp_fd , timeout_cnt = 0 ; struct timeval tv ; for ( ; ; ) { if ( url_interrupt_cb ( ) ) return AVERROR ( EINTR ) ; FD_ZERO ( & rfds ) ; if ( rt - > rtsp_hd ) { tcp_fd = fd_max = url_get_file_handle ( rt - > rtsp_hd ) ; FD_SET ( tcp_fd , & rfds ) ; } else { fd_max = 0 ; tcp_fd = - 1 ; } for ( i = 0 ; i < rt - > nb_rtsp_streams ; i + + ) { rtsp_st = rt - > rtsp_streams[i] ; if ( rtsp_st - > rtp_handle ) { / * currently , we cannot probe RTCP handle because of * blocking restrictions * / fd = url_get_file_handle ( rtsp_st - > rtp_handle ) ; if ( fd > fd_max ) fd_max = fd ; FD_SET ( fd , & rfds ) ; } } tv . tv_sec = 0 ; tv . tv_usec = SELECT_TIMEOUT_MS * 1000 ; n = select ( fd_max + 1 , & rfds , NULL , NULL , & tv ) ; if ( n > 0 ) { timeout_cnt = 0 ; for ( i = 0 ; i < rt - > nb_rtsp_streams ; i + + ) { rtsp_st = rt - > rtsp_streams[i] ; if ( rtsp_st - > rtp_handle ) { fd = url_get_file_handle ( rtsp_st - > rtp_handle ) ; if ( FD_ISSET ( fd , & rfds ) ) { ret = url_read ( rtsp_st - > rtp_handle , buf , buf_size ) ; if ( ret > 0 ) { * prtsp_st = rtsp_st ; return ret ; } } } } if CONFIG_RTSP_DEMUXER if ( tcp_fd ! = - 1 & & FD_ISSET ( tcp_fd , & rfds ) ) { RTSPMessageHeader reply ; ret = ff_rtsp_read_reply ( s , & reply , NULL , 0 ) ; if ( ret < 0 ) return ret ; / * XXX : parse message * / if ( rt - > state ! = RTSP_STATE_STREAMING ) return 0 ; } endif } else if ( n == 0 & & + + timeout_cnt > = MAX_TIMEOUTS ) { return FF_NETERROR ( ETIMEDOUT ) ; } else if ( n < 0 & & errno ! = EINTR ) return AVERROR ( errno ) ; } }",0
"static av_cold int g726_init ( AVCodecContext * avctx ) { AVG726Context * c = ( AVG726Context * ) avctx - > priv_data ; unsigned int index= ( avctx - > bit_rate + avctx - > sample_rate/2 ) / avctx - > sample_rate - 2 ; if ( ( avctx - > bit_rate ! = 16000 & & avctx - > bit_rate ! = 24000 & & avctx - > bit_rate ! = 32000 & & avctx - > bit_rate ! = 40000 ) ) { av_log ( avctx , AV_LOG_ERROR , G726 : unsupported audio format\n ) ; return - 1 ; } if ( avctx - > sample_rate ! = 8000 & & avctx - > strict_std_compliance > FF_COMPLIANCE_INOFFICIAL ) { av_log ( avctx , AV_LOG_ERROR , G726 : unsupported audio format\n ) ; return - 1 ; } if ( avctx - > channels ! = 1 ) { av_log ( avctx , AV_LOG_ERROR , Only mono is supported\n ) ; return - 1 ; } if ( index > 3 ) { av_log ( avctx , AV_LOG_ERROR , Unsupported number of bits %d\n , index + 2 ) ; return - 1 ; } g726_reset ( & c - > c , index ) ; c - > code_size = c - > c . tbls - > bits ; c - > bit_buffer = 0 ; c - > bits_left = 0 ; avctx - > coded_frame = avcodec_alloc_frame ( ) ; if ( ! avctx - > coded_frame ) return AVERROR ( ENOMEM ) ; avctx - > coded_frame - > key_frame = 1 ; return 0 ; }",0
"static int amf_parse_object ( AVFormatContext * s , AVStream * astream , AVStream * vstream , const char * key , int64_t max_pos , int depth ) { AVCodecContext * acodec , * vcodec ; ByteIOContext * ioc ; AMFDataType amf_type ; char str_val[256] ; double num_val ; num_val = 0 ; ioc = s - > pb ; amf_type = get_byte ( ioc ) ; switch ( amf_type ) { case AMF_DATA_TYPE_NUMBER : num_val = av_int2dbl ( get_be64 ( ioc ) ) ; break ; case AMF_DATA_TYPE_BOOL : num_val = get_byte ( ioc ) ; break ; case AMF_DATA_TYPE_STRING : if ( amf_get_string ( ioc , str_val , sizeof ( str_val ) ) < 0 ) return - 1 ; break ; case AMF_DATA_TYPE_OBJECT : { unsigned int keylen ; while ( url_ftell ( ioc ) < max_pos - 2 & & ( keylen = get_be16 ( ioc ) ) ) { url_fskip ( ioc , keylen ) ; //skip key string if ( amf_parse_object ( s , NULL , NULL , NULL , max_pos , depth + 1 ) < 0 ) return - 1 ; //if we couldn ' t skip , bomb out . } if ( get_byte ( ioc ) ! = AMF_END_OF_OBJECT ) return - 1 ; } break ; case AMF_DATA_TYPE_NULL : case AMF_DATA_TYPE_UNDEFINED : case AMF_DATA_TYPE_UNSUPPORTED : break ; //these take up no additional space case AMF_DATA_TYPE_MIXEDARRAY : url_fskip ( ioc , 4 ) ; //skip 32 - bit max array index while ( url_ftell ( ioc ) < max_pos - 2 & & amf_get_string ( ioc , str_val , sizeof ( str_val ) ) > 0 ) { //this is the only case in which we would want a nested parse to not skip over the object if ( amf_parse_object ( s , astream , vstream , str_val , max_pos , depth + 1 ) < 0 ) return - 1 ; } if ( get_byte ( ioc ) ! = AMF_END_OF_OBJECT ) return - 1 ; break ; case AMF_DATA_TYPE_ARRAY : { unsigned int arraylen , i ; arraylen = get_be32 ( ioc ) ; for ( i = 0 ; i < arraylen & & url_ftell ( ioc ) < max_pos - 1 ; i + + ) { if ( amf_parse_object ( s , NULL , NULL , NULL , max_pos , depth + 1 ) < 0 ) return - 1 ; //if we couldn ' t skip , bomb out . } } break ; case AMF_DATA_TYPE_DATE : url_fskip ( ioc , 8 + 2 ) ; //timestamp ( double ) and UTC offset ( int16 ) break ; default : //unsupported type , we couldn ' t skip return - 1 ; } if ( depth == 1 & & key ) { //only look for metadata values when we are not nested and key ! = NULL acodec = astream ? astream - > codec : NULL ; vcodec = vstream ? vstream - > codec : NULL ; if ( amf_type == AMF_DATA_TYPE_BOOL ) { } else if ( amf_type == AMF_DATA_TYPE_NUMBER ) { if ( ! strcmp ( key , duration ) ) s - > duration = num_val * AV_TIME_BASE ; else if ( ! strcmp ( key , videodatarate ) & & vcodec & & 0 < = ( int ) ( num_val * 1024 . 0 ) ) vcodec - > bit_rate = num_val * 1024 . 0 ; } } return 0 ; }",0
"static void mkv_write_simpletag ( AVIOContext * pb , AVDictionaryEntry * t ) { uint8_t * key = av_strdup ( t - > key ) ; uint8_t * p = key ; const uint8_t * lang = NULL ; ebml_master tag ; if ( ( p = strrchr ( p , ' - ' ) ) & & ( lang = av_convert_lang_to ( p + 1 , AV_LANG_ISO639_2_BIBL ) ) ) * p = 0 ; p = key ; while ( * p ) { if ( * p == ' ' ) * p = ' _ ' ; else if ( * p > = ' a ' & & * p < = ' z ' ) * p - = ' a ' - ' A ' ; p + + ; } tag = start_ebml_master ( pb , MATROSKA_ID_SIMPLETAG , 0 ) ; put_ebml_string ( pb , MATROSKA_ID_TAGNAME , key ) ; if ( lang ) put_ebml_string ( pb , MATROSKA_ID_TAGLANG , lang ) ; put_ebml_string ( pb , MATROSKA_ID_TAGSTRING , t - > value ) ; end_ebml_master ( pb , tag ) ; av_freep ( & key ) ; }",0
"static inline int decode_hrd_parameters ( H264Context * h , SPS * sps ) { int cpb_count , i ; cpb_count = get_ue_golomb_31 ( & h - > gb ) + 1 ; if ( cpb_count > 32U ) { av_log ( h - > avctx , AV_LOG_ERROR , cpb_count %d invalid\n , cpb_count ) ; return AVERROR_INVALIDDATA ; } get_bits ( & h - > gb , 4 ) ; / * bit_rate_scale * / get_bits ( & h - > gb , 4 ) ; / * cpb_size_scale * / for ( i = 0 ; i < cpb_count ; i + + ) { get_ue_golomb_long ( & h - > gb ) ; / * bit_rate_value_minus1 * / get_ue_golomb_long ( & h - > gb ) ; / * cpb_size_value_minus1 * / get_bits1 ( & h - > gb ) ; / * cbr_flag * / } sps - > initial_cpb_removal_delay_length = get_bits ( & h - > gb , 5 ) + 1 ; sps - > cpb_removal_delay_length = get_bits ( & h - > gb , 5 ) + 1 ; sps - > dpb_output_delay_length = get_bits ( & h - > gb , 5 ) + 1 ; sps - > time_offset_length = get_bits ( & h - > gb , 5 ) ; sps - > cpb_cnt = cpb_count ; return 0 ; }",0
"int av_aes_init ( AVAES * a , const uint8_t * key , int key_bits , int decrypt ) { int i , j , t , rconpointer = 0 ; uint8_t tk[8][4] ; int KC= key_bits > > 5 ; int rounds= KC + 6 ; uint8_t log8[256] ; uint8_t alog8[512] ; if ( ! enc_multbl[4][1023] ) { j=1 ; for ( i=0 ; i < 255 ; i + + ) { alog8[i]= alog8[i + 255]= j ; log8[j]= i ; j = j + j ; if ( j > 255 ) j = 0x11B ; } for ( i=0 ; i < 256 ; i + + ) { j= i ? alog8[255 - log8[i]] : 0 ; j = ( j < < 1 ) ( j < < 2 ) ( j < < 3 ) ( j < < 4 ) ; j = ( j ( j > > 8 ) 99 ) & 255 ; inv_sbox[j]= i ; sbox [i]= j ; } init_multbl2 ( dec_multbl[0] , ( int[4] ) { 0xe , 0x9 , 0xd , 0xb } , log8 , alog8 , inv_sbox ) ; init_multbl2 ( enc_multbl[0] , ( int[4] ) { 0x2 , 0x1 , 0x1 , 0x3 } , log8 , alog8 , sbox ) ; } if ( key_bits ! =128 & & key_bits ! =192 & & key_bits ! =256 ) return - 1 ; a - > rounds= rounds ; memcpy ( tk , key , KC * 4 ) ; for ( t= 0 ; t < ( rounds + 1 ) * 16 ; ) { memcpy ( a - > round_key[0][0] + t , tk , KC * 4 ) ; t + = KC * 4 ; for ( i = 0 ; i < 4 ; i + + ) tk[0][i] = sbox[tk[KC - 1][ ( i + 1 ) & 3]] ; tk[0][0] = rcon[rconpointer + + ] ; for ( j = 1 ; j < KC ; j + + ) { if ( KC ! = 8 || j ! = KC > > 1 ) for ( i = 0 ; i < 4 ; i + + ) tk[j][i] = tk[j - 1][i] ; else for ( i = 0 ; i < 4 ; i + + ) tk[j][i] = sbox[tk[j - 1][i]] ; } } if ( decrypt ) { for ( i=1 ; i < rounds ; i + + ) { uint8_t tmp[3][16] ; memcpy ( tmp[2] , a - > round_key[i][0] , 16 ) ; subshift ( tmp[1] , 0 , sbox ) ; mix ( tmp , dec_multbl , 1 , 3 ) ; memcpy ( a - > round_key[i][0] , tmp[0] , 16 ) ; } } else { for ( i=0 ; i < ( rounds + 1 ) > > 1 ; i + + ) { for ( j=0 ; j < 16 ; j + + ) FFSWAP ( int , a - > round_key[i][0][j] , a - > round_key[rounds - i][0][j] ) ; } } return 0 ; }",0
"static int grab_read_header ( AVFormatContext * s1 , AVFormatParameters * ap ) { VideoData * s = s1 - > priv_data ; AVStream * st ; int video_fd ; int desired_palette , desired_depth ; struct video_tuner tuner ; struct video_audio audio ; struct video_picture pict ; int j ; int vformat_num = FF_ARRAY_ELEMS ( video_formats ) ; av_log ( s1 , AV_LOG_WARNING , V4L input device is deprecated and will be removed in the next release . ) ; if ( ap - > time_base . den < = 0 ) { av_log ( s1 , AV_LOG_ERROR , Wrong time base ( %d ) \n , ap - > time_base . den ) ; return - 1 ; } s - > time_base = ap - > time_base ; s - > video_win . width = ap - > width ; s - > video_win . height = ap - > height ; st = avformat_new_stream ( s1 , NULL ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; avpriv_set_pts_info ( st , 64 , 1 , 1000000 ) ; / * 64 bits pts in us * / video_fd = open ( s1 - > filename , O_RDWR ) ; if ( video_fd < 0 ) { av_log ( s1 , AV_LOG_ERROR , %s : %s\n , s1 - > filename , strerror ( errno ) ) ; goto fail ; } if ( ioctl ( video_fd , VIDIOCGCAP , & s - > video_cap ) < 0 ) { av_log ( s1 , AV_LOG_ERROR , VIDIOCGCAP : %s\n , strerror ( errno ) ) ; goto fail ; } if ( ! ( s - > video_cap . type & VID_TYPE_CAPTURE ) ) { av_log ( s1 , AV_LOG_ERROR , Fatal : grab device does not handle capture\n ) ; goto fail ; } / * no values set , autodetect them * / if ( s - > video_win . width < = 0 || s - > video_win . height < = 0 ) { if ( ioctl ( video_fd , VIDIOCGWIN , & s - > video_win , sizeof ( s - > video_win ) ) < 0 ) { av_log ( s1 , AV_LOG_ERROR , VIDIOCGWIN : %s\n , strerror ( errno ) ) ; goto fail ; } } if ( av_image_check_size ( s - > video_win . width , s - > video_win . height , 0 , s1 ) < 0 ) return - 1 ; desired_palette = - 1 ; desired_depth = - 1 ; for ( j = 0 ; j < vformat_num ; j + + ) { if ( ap - > pix_fmt == video_formats[j] . pix_fmt ) { desired_palette = video_formats[j] . palette ; desired_depth = video_formats[j] . depth ; break ; } } / * set tv standard * / if ( ! ioctl ( video_fd , VIDIOCGTUNER , & tuner ) ) { tuner . mode = s - > standard ; ioctl ( video_fd , VIDIOCSTUNER , & tuner ) ; } / * unmute audio * / audio . audio = 0 ; ioctl ( video_fd , VIDIOCGAUDIO , & audio ) ; memcpy ( & s - > audio_saved , & audio , sizeof ( audio ) ) ; audio . flags & = VIDEO_AUDIO_MUTE ; ioctl ( video_fd , VIDIOCSAUDIO , & audio ) ; ioctl ( video_fd , VIDIOCGPICT , & pict ) ; av_dlog ( s1 , v4l : colour=%d hue=%d brightness=%d constrast=%d whiteness=%d\n , pict . colour , pict . hue , pict . brightness , pict . contrast , pict . whiteness ) ; / * try to choose a suitable video format * / pict . palette = desired_palette ; pict . depth= desired_depth ; if ( desired_palette == - 1 || ioctl ( video_fd , VIDIOCSPICT , & pict ) < 0 ) { for ( j = 0 ; j < vformat_num ; j + + ) { pict . palette = video_formats[j] . palette ; pict . depth = video_formats[j] . depth ; if ( - 1 ! = ioctl ( video_fd , VIDIOCSPICT , & pict ) ) break ; } if ( j > = vformat_num ) goto fail1 ; } if ( ioctl ( video_fd , VIDIOCGMBUF , & s - > gb_buffers ) < 0 ) { / * try to use read based access * / int val ; s - > video_win . x = 0 ; s - > video_win . y = 0 ; s - > video_win . chromakey = - 1 ; s - > video_win . flags = 0 ; if ( ioctl ( video_fd , VIDIOCSWIN , s - > video_win ) < 0 ) { av_log ( s1 , AV_LOG_ERROR , VIDIOCSWIN : %s\n , strerror ( errno ) ) ; goto fail ; } s - > frame_format = pict . palette ; val = 1 ; if ( ioctl ( video_fd , VIDIOCCAPTURE , & val ) < 0 ) { av_log ( s1 , AV_LOG_ERROR , VIDIOCCAPTURE : %s\n , strerror ( errno ) ) ; goto fail ; } s - > time_frame = av_gettime ( ) * s - > time_base . den / s - > time_base . num ; s - > use_mmap = 0 ; } else { s - > video_buf = mmap ( 0 , s - > gb_buffers . size , PROT_READ|PROT_WRITE , MAP_SHARED , video_fd , 0 ) ; if ( ( unsigned char * ) - 1 == s - > video_buf ) { s - > video_buf = mmap ( 0 , s - > gb_buffers . size , PROT_READ|PROT_WRITE , MAP_PRIVATE , video_fd , 0 ) ; if ( ( unsigned char * ) - 1 == s - > video_buf ) { av_log ( s1 , AV_LOG_ERROR , mmap : %s\n , strerror ( errno ) ) ; goto fail ; } } s - > gb_frame = 0 ; s - > time_frame = av_gettime ( ) * s - > time_base . den / s - > time_base . num ; / * start to grab the first frame * / s - > gb_buf . frame = s - > gb_frame % s - > gb_buffers . frames ; s - > gb_buf . height = s - > video_win . height ; s - > gb_buf . width = s - > video_win . width ; s - > gb_buf . format = pict . palette ; if ( ioctl ( video_fd , VIDIOCMCAPTURE , & s - > gb_buf ) < 0 ) { if ( errno ! = EAGAIN ) { fail1 : av_log ( s1 , AV_LOG_ERROR , VIDIOCMCAPTURE : %s\n , strerror ( errno ) ) ; } else { av_log ( s1 , AV_LOG_ERROR , Fatal : grab device does not receive any video signal\n ) ; } goto fail ; } for ( j = 1 ; j < s - > gb_buffers . frames ; j + + ) { s - > gb_buf . frame = j",0
"int mov_write_ftyp_tag ( ByteIOContext * pb , AVFormatContext * s ) { put_be32 ( pb , 0x14 ) ; / * size * / put_tag ( pb , ftyp ) ; if ( ! strcmp ( 3gp , s - > oformat - > name ) ) put_tag ( pb , 3gp4 ) ; else put_tag ( pb , isom ) ; put_be32 ( pb , 0x200 ) ; if ( ! strcmp ( 3gp , s - > oformat - > name ) ) put_tag ( pb , 3gp4 ) ; else put_tag ( pb , mp41 ) ; return 0x14 ; }",0
"static void stereo_processing ( PSContext * ps , float ( * l ) [32][2] , float ( * r ) [32][2] , int is34 ) { int e , b , k ; float ( * H11 ) [PS_MAX_NUM_ENV + 1][PS_MAX_NR_IIDICC] = ps - > H11 ; float ( * H12 ) [PS_MAX_NUM_ENV + 1][PS_MAX_NR_IIDICC] = ps - > H12 ; float ( * H21 ) [PS_MAX_NUM_ENV + 1][PS_MAX_NR_IIDICC] = ps - > H21 ; float ( * H22 ) [PS_MAX_NUM_ENV + 1][PS_MAX_NR_IIDICC] = ps - > H22 ; int8_t * opd_hist = ps - > opd_hist ; int8_t * ipd_hist = ps - > ipd_hist ; int8_t iid_mapped_buf[PS_MAX_NUM_ENV][PS_MAX_NR_IIDICC] ; int8_t icc_mapped_buf[PS_MAX_NUM_ENV][PS_MAX_NR_IIDICC] ; int8_t ipd_mapped_buf[PS_MAX_NUM_ENV][PS_MAX_NR_IIDICC] ; int8_t opd_mapped_buf[PS_MAX_NUM_ENV][PS_MAX_NR_IIDICC] ; int8_t ( * iid_mapped ) [PS_MAX_NR_IIDICC] = iid_mapped_buf ; int8_t ( * icc_mapped ) [PS_MAX_NR_IIDICC] = icc_mapped_buf ; int8_t ( * ipd_mapped ) [PS_MAX_NR_IIDICC] = ipd_mapped_buf ; int8_t ( * opd_mapped ) [PS_MAX_NR_IIDICC] = opd_mapped_buf ; const int8_t * k_to_i = is34 ? k_to_i_34 : k_to_i_20 ; TABLE_CONST float ( * H_LUT ) [8][4] = ( PS_BASELINE || ps - > icc_mode < 3 ) ? HA : HB ; //Remapping if ( ps - > num_env_old ) { memcpy ( H11[0][0] , H11[0][ps - > num_env_old] , PS_MAX_NR_IIDICC * sizeof ( H11[0][0][0] ) ) ; memcpy ( H11[1][0] , H11[1][ps - > num_env_old] , PS_MAX_NR_IIDICC * sizeof ( H11[1][0][0] ) ) ; memcpy ( H12[0][0] , H12[0][ps - > num_env_old] , PS_MAX_NR_IIDICC * sizeof ( H12[0][0][0] ) ) ; memcpy ( H12[1][0] , H12[1][ps - > num_env_old] , PS_MAX_NR_IIDICC * sizeof ( H12[1][0][0] ) ) ; memcpy ( H21[0][0] , H21[0][ps - > num_env_old] , PS_MAX_NR_IIDICC * sizeof ( H21[0][0][0] ) ) ; memcpy ( H21[1][0] , H21[1][ps - > num_env_old] , PS_MAX_NR_IIDICC * sizeof ( H21[1][0][0] ) ) ; memcpy ( H22[0][0] , H22[0][ps - > num_env_old] , PS_MAX_NR_IIDICC * sizeof ( H22[0][0][0] ) ) ; memcpy ( H22[1][0] , H22[1][ps - > num_env_old] , PS_MAX_NR_IIDICC * sizeof ( H22[1][0][0] ) ) ; } if ( is34 ) { remap34 ( & iid_mapped , ps - > iid_par , ps - > nr_iid_par , ps - > num_env , 1 ) ; remap34 ( & icc_mapped , ps - > icc_par , ps - > nr_icc_par , ps - > num_env , 1 ) ; if ( ps - > enable_ipdopd ) { remap34 ( & ipd_mapped , ps - > ipd_par , ps - > nr_ipdopd_par , ps - > num_env , 0 ) ; remap34 ( & opd_mapped , ps - > opd_par , ps - > nr_ipdopd_par , ps - > num_env , 0 ) ; } if ( ! ps - > is34bands_old ) { map_val_20_to_34 ( H11[0][0] ) ; map_val_20_to_34 ( H11[1][0] ) ; map_val_20_to_34 ( H12[0][0] ) ; map_val_20_to_34 ( H12[1][0] ) ; map_val_20_to_34 ( H21[0][0] ) ; map_val_20_to_34 ( H21[1][0] ) ; map_val_20_to_34 ( H22[0][0] ) ; map_val_20_to_34 ( H22[1][0] ) ; ipdopd_reset ( ipd_hist , opd_hist ) ; } } else { remap20 ( & iid_mapped , ps - > iid_par , ps - > nr_iid_par , ps - > num_env , 1 ) ; remap20 ( & icc_mapped , ps - > icc_par , ps - > nr_icc_par , ps - > num_env , 1 ) ; if ( ps - > enable_ipdopd ) { remap20 ( & ipd_mapped , ps - > ipd_par , ps - > nr_ipdopd_par , ps - > num_env , 0 ) ; remap20 ( & opd_mapped , ps - > opd_par , ps - > nr_ipdopd_par , ps - > num_env , 0 ) ; } if ( ps - > is34bands_old ) { map_val_34_to_20 ( H11[0][0] ) ; map_val_34_to_20 ( H11[1][0] ) ; map_val_34_to_20 ( H12[0][0] ) ; map_val_34_to_20 ( H12[1][0] ) ; map_val_34_to_20 ( H21[0][0] ) ; map_val_34_to_20 ( H21[1][0] ) ; map_val_34_to_20 ( H22[0][0] ) ; map_val_34_to_20 ( H22[1][0] ) ; ipdopd_reset ( ipd_hist , opd_hist ) ; } } //Mixing for ( e = 0 ; e < ps - > num_env ; e + + ) { for ( b = 0 ; b < NR_PAR_BANDS[is34] ; b + + ) { float h11 , h12 , h21 , h22 ; h11 = H_LUT[iid_mapped[e][b] + 7 + 23 * ps - > iid_quant][icc_mapped[e][b]][0] ; h12 = H_LUT[iid_mapped[e][b] + 7 + 23 * ps - > iid_quant][icc_mapped[e][b]][1] ; h21 = H_LUT[iid_mapped[e][b] + 7 + 23 * ps - > iid_quant][icc_mapped[e][b]][2] ; h22 = H_LUT[iid_mapped[e][b] + 7 + 23 * ps - > iid_quant][icc_mapped[e][b]][3] ; if ( ! PS_BASELINE & & ps - > enable_ipdopd & & 2 * b < = NR_PAR_BANDS[is34] ) { //The spec say says to only run this smoother when enable_ipdopd //is set but the reference decoder appears to run it constantly float h11i , h12i , h21i , h22i ; float ipd_adj_re , ipd_adj_im ; int opd_idx = opd_hist[b] * 8 + opd_mapped[e][b] ; int ipd_idx = ipd_hist[b] * 8 + ipd_mapped[e][b] ; float opd_re = pd_re_smooth[opd_idx] ; float opd_im = pd_im_smooth[opd_idx] ; float ipd_re = pd_re_smooth[ipd_idx] ; float ipd_im = pd_im_smooth[ipd_idx] ; opd_hist[b] = opd_idx & 0x3F ; ipd_hist[b] = ipd_idx & 0x3F ; ipd_adj_re = opd_re * ipd_re + opd_im * ipd_im ; ipd_adj_im = opd_im * ipd_re - opd_re * ipd_im ; h11i = h11 * opd_im ; h11 = h11 * opd_re ; h12i = h12 * ipd_adj_im ; h12 = h12 * ipd_adj_re ; h21i = h21 * opd_im ; h21 = h21 * opd_re ; h22i = h22 * ipd_adj_im ; h22 = h22 * ipd_adj_re ; H11[1][e + 1][b] = h11i ; H12[1][e + 1][b] = h12i ; H21[1][e + 1][b] = h21i ; H22[1][e + 1][b] = h22i ; } H11[0][e + 1][b] = h11 ; H12[0][e + 1][b] = h12 ; H21[0][e + 1][b] = h21 ; H22[0][e + 1][b] = h22 ; } for ( k = 0 ; k < NR_BANDS[is34] ; k + + ) { float h[2][4] ; float h_step[2][4] ; int start = ps - > border_position[e] ; int stop = ps - > border_position[e + 1] ; float width = 1 . f / ( stop - start ) ; b = k_to_i[k] ; h[0][0] = H11[0][e][b] ; h[0][1] = H12[0][e][b] ; h[0][2] = H21[0][e][b] ; h[0][3] = H22[0][e][b] ; if ( ! PS_BASELINE & & ps - > enable_ipdopd ) { //Is this necessary ? ps_04_new seems unchanged if ( ( is34 & & k < = 13 & & k > = 9 ) || ( ! is34 & & k < = 1 ) ) { h[1][0] = - H11[1][e][b] ; h[1][1] = - H12[1][e][b] ; h[1][2] = - H21[1][e][b] ; h[1][3] = - H22[1][e][b] ; } else { h[1][0] = H11[1][e][b] ; h[1][1] = H12[1][e][b] ; h[1][2] = H21[1][e][b] ; h[1][3] = H22[1][e][b] ; } } //Interpolation h_step[0][0] = ( H11[0][e + 1][b] - h[0][0] ) * width ; h_step[0][1] = ( H12[0][e + 1][b] - h[0][1] ) * width ; h_step[0][2] = ( H21[0][e + 1][b] - h[0][2] ) * width ; h_step[0][3] = ( H22[0][e + 1][b] - h[0][3] ) * width ; if ( ! PS_BASELINE & & ps - > enable_ipdopd )",1
"static int decode_header ( MPADecodeContext * s , uint32_t header ) { int sample_rate , frame_size , mpeg25 , padding ; int sample_rate_index , bitrate_index ; if ( header & ( 1 < < 20 ) ) { s - > lsf = ( header & ( 1 < < 19 ) ) ? 0 : 1 ; mpeg25 = 0 ; } else { s - > lsf = 1 ; mpeg25 = 1 ; } s - > layer = 4 - ( ( header > > 17 ) & 3 ) ; / * extract frequency * / sample_rate_index = ( header > > 10 ) & 3 ; sample_rate = mpa_freq_tab[sample_rate_index] > > ( s - > lsf + mpeg25 ) ; sample_rate_index + = 3 * ( s - > lsf + mpeg25 ) ; s - > sample_rate_index = sample_rate_index ; s - > error_protection = ( ( header > > 16 ) & 1 ) 1 ; s - > sample_rate = sample_rate ; bitrate_index = ( header > > 12 ) & 0xf ; padding = ( header > > 9 ) & 1 ; //extension = ( header > > 8 ) & 1 ; s - > mode = ( header > > 6 ) & 3 ; s - > mode_ext = ( header > > 4 ) & 3 ; //copyright = ( header > > 3 ) & 1 ; //original = ( header > > 2 ) & 1 ; //emphasis = header & 3 ; if ( s - > mode == MPA_MONO ) s - > nb_channels = 1 ; else s - > nb_channels = 2 ; if ( bitrate_index ! = 0 ) { frame_size = mpa_bitrate_tab[s - > lsf][s - > layer - 1][bitrate_index] ; s - > bit_rate = frame_size * 1000 ; switch ( s - > layer ) { case 1 : frame_size = ( frame_size * 12000 ) / sample_rate ; frame_size = ( frame_size + padding ) * 4 ; break ; case 2 : frame_size = ( frame_size * 144000 ) / sample_rate ; frame_size + = padding ; break ; default : case 3 : frame_size = ( frame_size * 144000 ) / ( sample_rate < < s - > lsf ) ; frame_size + = padding ; break ; } s - > frame_size = frame_size ; } else { / * if no frame size computed , signal it * / if ( ! s - > free_format_frame_size ) return 1 ; / * free format : compute bitrate and real frame size from the frame size we extracted by reading the bitstream * / s - > frame_size = s - > free_format_frame_size ; switch ( s - > layer ) { case 1 : s - > frame_size + = padding * 4 ; s - > bit_rate = ( s - > frame_size * sample_rate ) / 48000 ; break ; case 2 : s - > frame_size + = padding ; s - > bit_rate = ( s - > frame_size * sample_rate ) / 144000 ; break ; default : case 3 : s - > frame_size + = padding ; s - > bit_rate = ( s - > frame_size * ( sample_rate < < s - > lsf ) ) / 144000 ; break ; } } if defined ( DEBUG ) dprintf ( layer%d , %d Hz , %d kbits/s , , s - > layer , s - > sample_rate , s - > bit_rate ) ; if ( s - > nb_channels == 2 ) { if ( s - > layer == 3 ) { if ( s - > mode_ext & MODE_EXT_MS_STEREO ) dprintf ( ms - ) ; if ( s - > mode_ext & MODE_EXT_I_STEREO ) dprintf ( i - ) ; } dprintf ( stereo ) ; } else { dprintf ( mono ) ; } dprintf ( \n ) ; endif return 0 ; }",1
"static int dx2_decode_slice_rgb ( GetBitContext * gb , AVFrame * frame , int line , int left , uint8_t lru[3][8] ) { int x , y ; int width = frame - > width ; int stride = frame - > linesize[0] ; uint8_t * dst = frame - > data[0] + stride * line ; for ( y = 0 ; y < left & & get_bits_left ( gb ) > 16 ; y + + ) { for ( x = 0 ; x < width ; x + + ) { dst[x * 3 + 0] = decode_sym ( gb , lru[0] ) ; dst[x * 3 + 1] = decode_sym ( gb , lru[1] ) ; dst[x * 3 + 2] = decode_sym ( gb , lru[2] ) ; } dst + = stride ; } return y ; }",1
"static int mjpeg_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , uint8_t * buf , int buf_size ) { MJpegDecodeContext * s = avctx - > priv_data ; uint8_t * buf_end , * buf_ptr ; int i , start_code ; AVPicture * picture = data ; * data_size = 0 ; / * no supplementary picture * / if ( buf_size == 0 ) return 0 ; buf_ptr = buf ; buf_end = buf + buf_size ; while ( buf_ptr < buf_end ) { / * find start next marker * / start_code = find_marker ( & buf_ptr , buf_end ) ; { / * EOF * / if ( start_code < 0 ) { goto the_end ; } else { dprintf ( marker=%x avail_size_in_buf=%d\n , start_code , buf_end - buf_ptr ) ; if ( ( buf_end - buf_ptr ) > s - > buffer_size ) { av_free ( s - > buffer ) ; s - > buffer_size = buf_end - buf_ptr ; s - > buffer = av_malloc ( s - > buffer_size ) ; dprintf ( buffer too small , expanding to %d bytes\n , s - > buffer_size ) ; } / * unescape buffer of SOS * / if ( start_code == SOS ) { uint8_t * src = buf_ptr ; uint8_t * dst = s - > buffer ; while ( src < buf_end ) { uint8_t x = * ( src + + ) ; * ( dst + + ) = x ; if ( x == 0xff ) { while ( * src == 0xff ) src + + ; x = * ( src + + ) ; if ( x > = 0xd0 & & x < = 0xd7 ) * ( dst + + ) = x ; else if ( x ) break ; } } init_get_bits ( & s - > gb , s - > buffer , ( dst - s - > buffer ) * 8 ) ; dprintf ( escaping removed %d bytes\n , ( buf_end - buf_ptr ) - ( dst - s - > buffer ) ) ; } else init_get_bits ( & s - > gb , buf_ptr , ( buf_end - buf_ptr ) * 8 ) ; s - > start_code = start_code ; if ( s - > avctx - > debug & FF_DEBUG_STARTCODE ) { printf ( startcode : %X\n , start_code ) ; } / * process markers * / if ( start_code > = 0xd0 & & start_code < = 0xd7 ) { dprintf ( restart marker : %d\n , start_code & 0x0f ) ; } else if ( s - > first_picture ) { / * APP fields * / if ( start_code > = 0xe0 & & start_code < = 0xef ) mjpeg_decode_app ( s ) ; / * Comment * / else if ( start_code == COM ) mjpeg_decode_com ( s ) ; } switch ( start_code ) { case SOI : s - > restart_interval = 0 ; / * nothing to do on SOI * / break ; case DQT : mjpeg_decode_dqt ( s ) ; break ; case DHT : mjpeg_decode_dht ( s ) ; break ; case SOF0 : s - > lossless=0 ; if ( mjpeg_decode_sof ( s ) < 0 ) return - 1 ; break ; case SOF3 : s - > lossless=1 ; if ( mjpeg_decode_sof ( s ) < 0 ) return - 1 ; break ; case EOI : eoi_parser : { if ( s - > interlaced ) { s - > bottom_field = 1 ; / * if not bottom field , do not output image yet * / if ( s - > bottom_field ) goto not_the_end ; } for ( i=0 ; i < 3 ; i + + ) { picture - > data[i] = s - > current_picture[i] ; picture - > linesize[i] = ( s - > interlaced ) ? s - > linesize[i] > > 1 : s - > linesize[i] ; } * data_size = sizeof ( AVPicture ) ; avctx - > height = s - > height ; if ( s - > interlaced ) avctx - > height * = 2 ; avctx - > width = s - > width ; / * XXX : not complete test ! * / switch ( ( s - > h_count[0] < < 4 ) | s - > v_count[0] ) { case 0x11 : if ( s - > rgb ) { avctx - > pix_fmt = PIX_FMT_RGBA32 ; } else avctx - > pix_fmt = PIX_FMT_YUV444P ; break ; case 0x21 : avctx - > pix_fmt = PIX_FMT_YUV422P ; break ; default : case 0x22 : avctx - > pix_fmt = PIX_FMT_YUV420P ; break ; } / * dummy quality * / / * XXX : infer it with matrix * / // avctx - > quality = 3 ; goto the_end ; } break ; case SOS : mjpeg_decode_sos ( s ) ; / * buggy avid puts EOI every 10 - 20th frame * / / * if restart period is over process EOI * / if ( ( s - > buggy_avid & & ! s - > interlaced ) || s - > restart_interval ) goto eoi_parser ; break ; case DRI : mjpeg_decode_dri ( s ) ; break ; case SOF1 : case SOF2 : case SOF5 : case SOF6 : case SOF7 : case SOF9 : case SOF10 : case SOF11 : case SOF13 : case SOF14 : case SOF15 : case JPG : printf ( mjpeg : unsupported coding type ( %x ) \n , start_code ) ; break ; // default : // printf ( mjpeg : unsupported marker ( %x ) \n , start_code ) ; // break ; } not_the_end : / * eof process start code * / buf_ptr + = ( get_bits_count ( & s - > gb ) + 7 ) /8 ; dprintf ( marker parser used %d bytes ( %d bits ) \n , ( get_bits_count ( & s - > gb ) + 7 ) /8 , get_bits_count ( & s - > gb ) ) ; } } } the_end : dprintf ( mjpeg decode frame unused %d bytes\n , buf_end - buf_ptr ) ; // return buf_end - buf_ptr ; return buf_ptr - buf ; }",0
"static int int_pow ( int i , int * exp_ptr ) { int e , er , eq , j ; int a , a1 ; / * renormalize * / a = i ; e = POW_FRAC_BITS ; while ( a < ( 1 < < ( POW_FRAC_BITS - 1 ) ) ) { a = a < < 1 ; e - - ; } a - = ( 1 < < POW_FRAC_BITS ) ; a1 = 0 ; for ( j = DEV_ORDER - 1 ; j > = 0 ; j - - ) a1 = POW_MULL ( a , dev_4_3_coefs[j] + a1 ) ; a = ( 1 < < POW_FRAC_BITS ) + a1 ; / * exponent compute ( exact ) * / e = e * 4 ; er = e % 3 ; eq = e / 3 ; a = POW_MULL ( a , pow_mult3[er] ) ; while ( a > = 2 * POW_FRAC_ONE ) { a = a > > 1 ; eq + + ; } / * convert to float * / while ( a < POW_FRAC_ONE ) { a = a < < 1 ; eq - - ; } / * now POW_FRAC_ONE < = a < 2 * POW_FRAC_ONE * / if ( POW_FRAC_BITS - 1 ) > FRAC_BITS a = ( a + ( 1 < < ( POW_FRAC_BITS - FRAC_BITS - 1 ) ) ) > > ( POW_FRAC_BITS - FRAC_BITS ) ; / * correct overflow * / if ( a > = 2 * ( 1 < < FRAC_BITS ) ) { a = a > > 1 ; eq + + ; } endif * exp_ptr = eq ; return a ; }",1
"static av_cold int svq3_decode_init ( AVCodecContext * avctx ) { SVQ3Context * svq3 = avctx - > priv_data ; H264Context * h = & svq3 - > h ; MpegEncContext * s = & h - > s ; int m ; unsigned char * extradata ; unsigned char * extradata_end ; unsigned int size ; int marker_found = 0 ; if ( ff_h264_decode_init ( avctx ) < 0 ) return - 1 ; s - > flags = avctx - > flags ; s - > flags2 = avctx - > flags2 ; s - > unrestricted_mv = 1 ; h - > is_complex=1 ; h - > sps . chroma_format_idc = 1 ; avctx - > pix_fmt = avctx - > codec - > pix_fmts[0] ; if ( ! s - > context_initialized ) { h - > chroma_qp[0] = h - > chroma_qp[1] = 4 ; svq3 - > halfpel_flag = 1 ; svq3 - > thirdpel_flag = 1 ; svq3 - > unknown_flag = 0 ; / * prowl for the SEQH marker in the extradata * / extradata = ( unsigned char * ) avctx - > extradata ; extradata_end = avctx - > extradata + avctx - > extradata_size ; if ( extradata ) { for ( m = 0 ; m + 8 < avctx - > extradata_size ; m + + ) { if ( ! memcmp ( extradata , SEQH , 4 ) ) { marker_found = 1 ; break ; } extradata + + ; } } / * if a match was found , parse the extra data * / if ( marker_found ) { GetBitContext gb ; int frame_size_code ; size = AV_RB32 ( & extradata[4] ) ; if ( size > extradata_end - extradata - 8 ) return AVERROR_INVALIDDATA ; init_get_bits ( & gb , extradata + 8 , size * 8 ) ; / * ' frame size code ' and optional ' width , height ' * / frame_size_code = get_bits ( & gb , 3 ) ; switch ( frame_size_code ) { case 0 : avctx - > width = 160 ; avctx - > height = 120 ; break ; case 1 : avctx - > width = 128 ; avctx - > height = 96 ; break ; case 2 : avctx - > width = 176 ; avctx - > height = 144 ; break ; case 3 : avctx - > width = 352 ; avctx - > height = 288 ; break ; case 4 : avctx - > width = 704 ; avctx - > height = 576 ; break ; case 5 : avctx - > width = 240 ; avctx - > height = 180 ; break ; case 6 : avctx - > width = 320 ; avctx - > height = 240 ; break ; case 7 : avctx - > width = get_bits ( & gb , 12 ) ; avctx - > height = get_bits ( & gb , 12 ) ; break ; } svq3 - > halfpel_flag = get_bits1 ( & gb ) ; svq3 - > thirdpel_flag = get_bits1 ( & gb ) ; / * unknown fields * / skip_bits1 ( & gb ) ; skip_bits1 ( & gb ) ; skip_bits1 ( & gb ) ; skip_bits1 ( & gb ) ; s - > low_delay = get_bits1 ( & gb ) ; / * unknown field * / skip_bits1 ( & gb ) ; while ( get_bits1 ( & gb ) ) { skip_bits ( & gb , 8 ) ; } svq3 - > unknown_flag = get_bits1 ( & gb ) ; avctx - > has_b_frames = ! s - > low_delay ; if ( svq3 - > unknown_flag ) { if CONFIG_ZLIB unsigned watermark_width = svq3_get_ue_golomb ( & gb ) ; unsigned watermark_height = svq3_get_ue_golomb ( & gb ) ; int u1 = svq3_get_ue_golomb ( & gb ) ; int u2 = get_bits ( & gb , 8 ) ; int u3 = get_bits ( & gb , 2 ) ; int u4 = svq3_get_ue_golomb ( & gb ) ; unsigned long buf_len = watermark_width * watermark_height * 4 ; int offset = ( get_bits_count ( & gb ) + 7 ) > > 3 ; uint8_t * buf ; if ( ( uint64_t ) watermark_width * 4 > UINT_MAX/watermark_height ) return - 1 ; buf = av_malloc ( buf_len ) ; av_log ( avctx , AV_LOG_DEBUG , watermark size : %dx%d\n , watermark_width , watermark_height ) ; av_log ( avctx , AV_LOG_DEBUG , u1 : %x u2 : %x u3 : %x compressed data size : %d offset : %d\n , u1 , u2 , u3 , u4 , offset ) ; if ( uncompress ( buf , & buf_len , extradata + 8 + offset , size - offset ) ! = Z_OK ) { av_log ( avctx , AV_LOG_ERROR , could not uncompress watermark logo\n ) ; av_free ( buf ) ; return - 1 ; } svq3 - > watermark_key = ff_svq1_packet_checksum ( buf , buf_len , 0 ) ; svq3 - > watermark_key = svq3 - > watermark_key < < 16 | svq3 - > watermark_key ; av_log ( avctx , AV_LOG_DEBUG , watermark key % x\n , svq3 - > watermark_key ) ; av_free ( buf ) ; else av_log ( avctx , AV_LOG_ERROR , this svq3 file contains watermark which need zlib support compiled in\n ) ; return - 1 ; endif } } s - > width = avctx - > width ; s - > height = avctx - > height ; if ( ff_MPV_common_init ( s ) < 0 ) return - 1 ; h - > b_stride = 4 * s - > mb_width ; if ( ff_h264_alloc_tables ( h ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , svq3 memory allocation failed\n ) ; return AVERROR ( ENOMEM ) ; } } return 0 ; }",1
"int ff_vp56_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; VP56Context * s = avctx - > priv_data ; AVFrame * const p = s - > framep[VP56_FRAME_CURRENT] ; int remaining_buf_size = avpkt - > size ; int is_alpha , av_uninit ( alpha_offset ) ; if ( s - > has_alpha ) { if ( remaining_buf_size < 3 ) return - 1 ; alpha_offset = bytestream_get_be24 ( & buf ) ; remaining_buf_size - = 3 ; if ( remaining_buf_size < alpha_offset ) return - 1 ; } for ( is_alpha=0 ; is_alpha < 1 + s - > has_alpha ; is_alpha + + ) { int mb_row , mb_col , mb_row_flip , mb_offset = 0 ; int block , y , uv , stride_y , stride_uv ; int golden_frame = 0 ; int res ; s - > modelp = & s - > models[is_alpha] ; res = s - > parse_header ( s , buf , remaining_buf_size , & golden_frame ) ; if ( ! res ) return - 1 ; if ( res == 2 ) { int i ; for ( i = 0 ; i < 4 ; i + + ) { if ( s - > frames[i] . data[0] ) avctx - > release_buffer ( avctx , & s - > frames[i] ) ; } if ( is_alpha ) return - 1 ; } if ( ! is_alpha ) { p - > reference = 1 ; if ( avctx - > get_buffer ( avctx , p ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed\n ) ; return - 1 ; } if ( res == 2 ) if ( vp56_size_changed ( avctx ) ) { avctx - > release_buffer ( avctx , p ) ; return - 1 ; } } if ( p - > key_frame ) { p - > pict_type = AV_PICTURE_TYPE_I ; s - > default_models_init ( s ) ; for ( block=0 ; block < s - > mb_height * s - > mb_width ; block + + ) s - > macroblocks[block] . type = VP56_MB_INTRA ; } else { p - > pict_type = AV_PICTURE_TYPE_P ; vp56_parse_mb_type_models ( s ) ; s - > parse_vector_models ( s ) ; s - > mb_type = VP56_MB_INTER_NOVEC_PF ; } s - > parse_coeff_models ( s ) ; memset ( s - > prev_dc , 0 , sizeof ( s - > prev_dc ) ) ; s - > prev_dc[1][VP56_FRAME_CURRENT] = 128 ; s - > prev_dc[2][VP56_FRAME_CURRENT] = 128 ; for ( block=0 ; block < 4 * s - > mb_width + 6 ; block + + ) { s - > above_blocks[block] . ref_frame = VP56_FRAME_NONE ; s - > above_blocks[block] . dc_coeff = 0 ; s - > above_blocks[block] . not_null_dc = 0 ; } s - > above_blocks[2 * s - > mb_width + 2] . ref_frame = VP56_FRAME_CURRENT ; s - > above_blocks[3 * s - > mb_width + 4] . ref_frame = VP56_FRAME_CURRENT ; stride_y = p - > linesize[0] ; stride_uv = p - > linesize[1] ; if ( s - > flip < 0 ) mb_offset = 7 ; / * main macroblocks loop * / for ( mb_row=0 ; mb_row < s - > mb_height ; mb_row + + ) { if ( s - > flip < 0 ) mb_row_flip = s - > mb_height - mb_row - 1 ; else mb_row_flip = mb_row ; for ( block=0 ; block < 4 ; block + + ) { s - > left_block[block] . ref_frame = VP56_FRAME_NONE ; s - > left_block[block] . dc_coeff = 0 ; s - > left_block[block] . not_null_dc = 0 ; } memset ( s - > coeff_ctx , 0 , sizeof ( s - > coeff_ctx ) ) ; memset ( s - > coeff_ctx_last , 24 , sizeof ( s - > coeff_ctx_last ) ) ; s - > above_block_idx[0] = 1 ; s - > above_block_idx[1] = 2 ; s - > above_block_idx[2] = 1 ; s - > above_block_idx[3] = 2 ; s - > above_block_idx[4] = 2 * s - > mb_width + 2 + 1 ; s - > above_block_idx[5] = 3 * s - > mb_width + 4 + 1 ; s - > block_offset[s - > frbi] = ( mb_row_flip * 16 + mb_offset ) * stride_y ; s - > block_offset[s - > srbi] = s - > block_offset[s - > frbi] + 8 * stride_y ; s - > block_offset[1] = s - > block_offset[0] + 8 ; s - > block_offset[3] = s - > block_offset[2] + 8 ; s - > block_offset[4] = ( mb_row_flip * 8 + mb_offset ) * stride_uv ; s - > block_offset[5] = s - > block_offset[4] ; for ( mb_col=0 ; mb_col < s - > mb_width ; mb_col + + ) { vp56_decode_mb ( s , mb_row , mb_col , is_alpha ) ; for ( y=0 ; y < 4 ; y + + ) { s - > above_block_idx[y] + = 2 ; s - > block_offset[y] + = 16 ; } for ( uv=4 ; uv < 6 ; uv + + ) { s - > above_block_idx[uv] + = 1 ; s - > block_offset[uv] + = 8 ; } } } if ( p - > key_frame || golden_frame ) { if ( s - > framep[VP56_FRAME_GOLDEN] - > data[0] & & s - > framep[VP56_FRAME_GOLDEN] ! = s - > framep[VP56_FRAME_GOLDEN2] ) avctx - > release_buffer ( avctx , s - > framep[VP56_FRAME_GOLDEN] ) ; s - > framep[VP56_FRAME_GOLDEN] = p ; } if ( s - > has_alpha ) { FFSWAP ( AVFrame * , s - > framep[VP56_FRAME_GOLDEN] , s - > framep[VP56_FRAME_GOLDEN2] ) ; buf + = alpha_offset ; remaining_buf_size - = alpha_offset ; } } if ( s - > framep[VP56_FRAME_PREVIOUS] == s - > framep[VP56_FRAME_GOLDEN] || s - > framep[VP56_FRAME_PREVIOUS] == s - > framep[VP56_FRAME_GOLDEN2] ) { if ( s - > framep[VP56_FRAME_UNUSED] ! = s - > framep[VP56_FRAME_GOLDEN] & & s - > framep[VP56_FRAME_UNUSED] ! = s - > framep[VP56_FRAME_GOLDEN2] ) FFSWAP ( AVFrame * , s - > framep[VP56_FRAME_PREVIOUS] , s - > framep[VP56_FRAME_UNUSED] ) ; else FFSWAP ( AVFrame * , s - > framep[VP56_FRAME_PREVIOUS] , s - > framep[VP56_FRAME_UNUSED2] ) ; } else if ( s - > framep[VP56_FRAME_PREVIOUS] - > data[0] ) avctx - > release_buffer ( avctx , s - > framep[VP56_FRAME_PREVIOUS] ) ; FFSWAP ( AVFrame * , s - > framep[VP56_FRAME_CURRENT] , s - > framep[VP56_FRAME_PREVIOUS] ) ; p - > qstride = 0 ; p - > qscale_table = s - > qscale_table ; p - > qscale_type = FF_QSCALE_TYPE_VP56 ; * ( AVFrame * ) data = * p ; * data_size = sizeof ( AVFrame ) ; return avpkt - > size ; }",0
"static int mov_read_esds ( MOVContext * c , ByteIOContext * pb , MOVAtom atom ) { AVStream * st = c - > fc - > streams[c - > fc - > nb_streams - 1] ; int tag , len ; get_be32 ( pb ) ; / * version + flags * / len = mp4_read_descr ( c , pb , & tag ) ; if ( tag == MP4ESDescrTag ) { get_be16 ( pb ) ; / * ID * / get_byte ( pb ) ; / * priority * / } else get_be16 ( pb ) ; / * ID * / len = mp4_read_descr ( c , pb , & tag ) ; if ( tag == MP4DecConfigDescrTag ) { int object_type_id = get_byte ( pb ) ; get_byte ( pb ) ; / * stream type * / get_be24 ( pb ) ; / * buffer size db * / get_be32 ( pb ) ; / * max bitrate * / get_be32 ( pb ) ; / * avg bitrate * / st - > codec - > codec_id= ff_codec_get_id ( ff_mp4_obj_type , object_type_id ) ; dprintf ( c - > fc , esds object type id %d\n , object_type_id ) ; len = mp4_read_descr ( c , pb , & tag ) ; if ( tag == MP4DecSpecificDescrTag ) { dprintf ( c - > fc , Specific MPEG4 header len=%d\n , len ) ; if ( ( uint64_t ) len > ( 1 < < 30 ) ) return - 1 ; st - > codec - > extradata = av_mallocz ( len + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! st - > codec - > extradata ) return AVERROR ( ENOMEM ) ; get_buffer ( pb , st - > codec - > extradata , len ) ; st - > codec - > extradata_size = len ; if ( st - > codec - > codec_id == CODEC_ID_AAC ) { MPEG4AudioConfig cfg ; ff_mpeg4audio_get_config ( & cfg , st - > codec - > extradata , st - > codec - > extradata_size ) ; if ( cfg . chan_config > 7 ) return - 1 ; st - > codec - > channels = ff_mpeg4audio_channels[cfg . chan_config] ; if ( cfg . object_type == 29 & & cfg . sampling_index < 3 ) // old mp3on4 st - > codec - > sample_rate = ff_mpa_freq_tab[cfg . sampling_index] ; else st - > codec - > sample_rate = cfg . sample_rate ; // ext sample rate ? dprintf ( c - > fc , mp4a config channels %d obj %d ext obj %d sample rate %d ext sample rate %d\n , st - > codec - > channels , cfg . object_type , cfg . ext_object_type , cfg . sample_rate , cfg . ext_sample_rate ) ; if ( ! ( st - > codec - > codec_id = ff_codec_get_id ( mp4_audio_types , cfg . object_type ) ) ) st - > codec - > codec_id = CODEC_ID_AAC ; } } } return 0 ; }",0
"av_cold int ff_nvenc_encode_close ( AVCodecContext * avctx ) { NVENCContext * ctx = avctx - > priv_data ; NV_ENCODE_API_FUNCTION_LIST * nv = & ctx - > nvel . nvenc_funcs ; int i ; av_frame_free ( & avctx - > coded_frame ) ; if ( ctx - > in ) { for ( i = 0 ; i < ctx - > nb_surfaces ; + + i ) { nv - > nvEncDestroyInputBuffer ( ctx - > nvenc_ctx , ctx - > in[i] . in ) ; nv - > nvEncDestroyBitstreamBuffer ( ctx - > nvenc_ctx , ctx - > out[i] . out ) ; } } av_freep ( & ctx - > in ) ; av_freep ( & ctx - > out ) ; if ( ctx - > nvenc_ctx ) nv - > nvEncDestroyEncoder ( ctx - > nvenc_ctx ) ; if ( ctx - > cu_context ) ctx - > nvel . cu_ctx_destroy ( ctx - > cu_context ) ; if ( ctx - > nvel . nvenc ) dlclose ( ctx - > nvel . nvenc ) ; if ( ctx - > nvel . cuda ) dlclose ( ctx - > nvel . cuda ) ; return 0 ; }",0
"static QDM2SubPNode * qdm2_search_subpacket_type_in_list ( QDM2SubPNode * list , int type ) { while ( list ! = NULL & & list - > packet ! = NULL ) { if ( list - > packet - > type == type ) return list ; list = list - > next ; } return NULL ; }",0
"static int segment_end ( AVFormatContext * s , int write_trailer , int is_last ) { SegmentContext * seg = s - > priv_data ; AVFormatContext * oc = seg - > avf ; int ret = 0 ; av_write_frame ( oc , NULL ) ; / * Flush any buffered data ( fragmented mp4 ) * / if ( write_trailer ) ret = av_write_trailer ( oc ) ; if ( ret < 0 ) av_log ( s , AV_LOG_ERROR , Failure occurred when ending segment ' %s ' \n , oc - > filename ) ; if ( seg - > list ) { if ( seg - > list_size || seg - > list_type == LIST_TYPE_M3U8 ) { SegmentListEntry * entry = av_mallocz ( sizeof ( * entry ) ) ; if ( ! entry ) { ret = AVERROR ( ENOMEM ) ; goto end ; } / * append new element * / memcpy ( entry , & seg - > cur_entry , sizeof ( * entry ) ) ; if ( ! seg - > segment_list_entries ) seg - > segment_list_entries = seg - > segment_list_entries_end = entry ; else seg - > segment_list_entries_end - > next = entry ; seg - > segment_list_entries_end = entry ; / * drop first item * / if ( seg - > list_size & & seg - > segment_count > seg - > list_size ) { entry = seg - > segment_list_entries ; seg - > segment_list_entries = seg - > segment_list_entries - > next ; av_free ( entry - > filename ) ; av_freep ( & entry ) ; } avio_close ( seg - > list_pb ) ; if ( ( ret = segment_list_open ( s ) ) < 0 ) goto end ; for ( entry = seg - > segment_list_entries ; entry ; entry = entry - > next ) segment_list_print_entry ( seg - > list_pb , seg - > list_type , entry , s ) ; if ( seg - > list_type == LIST_TYPE_M3U8 & & is_last ) avio_printf ( seg - > list_pb , EXT - X - ENDLIST\n ) ; } else { segment_list_print_entry ( seg - > list_pb , seg - > list_type , & seg - > cur_entry , s ) ; } avio_flush ( seg - > list_pb ) ; } av_log ( s , AV_LOG_VERBOSE , segment : ' %s ' count : %d ended\n , seg - > avf - > filename , seg - > segment_count ) ; seg - > segment_count + + ; end : avio_close ( oc - > pb ) ; return ret ; }",0
"static void get_default_channel_layouts ( OutputStream * ost , InputStream * ist ) { char layout_name[256] ; AVCodecContext * enc = ost - > st - > codec ; AVCodecContext * dec = ist - > st - > codec ; if ( dec - > channel_layout & & av_get_channel_layout_nb_channels ( dec - > channel_layout ) ! = dec - > channels ) { av_get_channel_layout_string ( layout_name , sizeof ( layout_name ) , dec - > channels , dec - > channel_layout ) ; av_log ( NULL , AV_LOG_ERROR , New channel layout ( %s ) is invalid\n , layout_name ) ; dec - > channel_layout = 0 ; } if ( ! dec - > channel_layout ) { if ( enc - > channel_layout & & dec - > channels == enc - > channels ) { dec - > channel_layout = enc - > channel_layout ; } else { dec - > channel_layout = av_get_default_channel_layout ( dec - > channels ) ; if ( ! dec - > channel_layout ) { av_log ( NULL , AV_LOG_FATAL , Unable to find default channel layout for Input Stream %d . %d\n , ist - > file_index , ist - > st - > index ) ; exit_program ( 1 ) ; } } av_get_channel_layout_string ( layout_name , sizeof ( layout_name ) , dec - > channels , dec - > channel_layout ) ; av_log ( NULL , AV_LOG_WARNING , Guessed Channel Layout for Input Stream %d . %d : %s\n , ist - > file_index , ist - > st - > index , layout_name ) ; } if ( ! enc - > channel_layout ) { if ( dec - > channels == enc - > channels ) { enc - > channel_layout = dec - > channel_layout ; return ; } else { enc - > channel_layout = av_get_default_channel_layout ( enc - > channels ) ; } if ( ! enc - > channel_layout ) { av_log ( NULL , AV_LOG_FATAL , Unable to find default channel layout for Output Stream %d . %d\n , ost - > file_index , ost - > st - > index ) ; exit_program ( 1 ) ; } av_get_channel_layout_string ( layout_name , sizeof ( layout_name ) , enc - > channels , enc - > channel_layout ) ; av_log ( NULL , AV_LOG_WARNING , Guessed Channel Layout for Output Stream %d . %d : %s\n , ost - > file_index , ost - > st - > index , layout_name ) ; } }",1
"static enum AVPixelFormat get_format ( HEVCContext * s , const HEVCSPS * sps ) { define HWACCEL_MAX ( CONFIG_HEVC_DXVA2_HWACCEL + CONFIG_HEVC_D3D11VA_HWACCEL + CONFIG_HEVC_VAAPI_HWACCEL + CONFIG_HEVC_VDPAU_HWACCEL ) enum AVPixelFormat pix_fmts[HWACCEL_MAX + 2] , * fmt = pix_fmts ; switch ( sps - > pix_fmt ) { case AV_PIX_FMT_YUV420P : case AV_PIX_FMT_YUVJ420P : if CONFIG_HEVC_DXVA2_HWACCEL * fmt + + = AV_PIX_FMT_DXVA2_VLD ; endif if CONFIG_HEVC_D3D11VA_HWACCEL * fmt + + = AV_PIX_FMT_D3D11VA_VLD ; endif if CONFIG_HEVC_VAAPI_HWACCEL * fmt + + = AV_PIX_FMT_VAAPI ; endif if CONFIG_HEVC_VDPAU_HWACCEL * fmt + + = AV_PIX_FMT_VDPAU ; endif break ; case AV_PIX_FMT_YUV420P10 : if CONFIG_HEVC_DXVA2_HWACCEL * fmt + + = AV_PIX_FMT_DXVA2_VLD ; endif if CONFIG_HEVC_D3D11VA_HWACCEL * fmt + + = AV_PIX_FMT_D3D11VA_VLD ; endif if CONFIG_HEVC_VAAPI_HWACCEL * fmt + + = AV_PIX_FMT_VAAPI ; endif break ; } * fmt + + = sps - > pix_fmt ; * fmt = AV_PIX_FMT_NONE ; return ff_get_format ( s - > avctx , pix_fmts ) ; }",1
static av_cold int pnm_encode_init ( AVCodecContext * avctx ) { avctx - > coded_frame = av_frame_alloc ( ) ; if ( ! avctx - > coded_frame ) return AVERROR ( ENOMEM ) ; avctx - > coded_frame - > pict_type = AV_PICTURE_TYPE_I ; avctx - > coded_frame - > key_frame = 1 ; return 0 ; },0
"static int ljpeg_decode_yuv_scan ( MJpegDecodeContext * s , int predictor , int point_transform , int nb_components ) { int i , mb_x , mb_y , mask ; int bits= ( s - > bits + 7 ) & 7 ; int resync_mb_y = 0 ; int resync_mb_x = 0 ; point_transform + = bits - s - > bits ; mask = ( ( 1 < < s - > bits ) - 1 ) < < point_transform ; av_assert0 ( nb_components > =1 & & nb_components < =4 ) ; for ( mb_y = 0 ; mb_y < s - > mb_height ; mb_y + + ) { for ( mb_x = 0 ; mb_x < s - > mb_width ; mb_x + + ) { if ( s - > restart_interval & & ! s - > restart_count ) { s - > restart_count = s - > restart_interval ; resync_mb_x = mb_x ; resync_mb_y = mb_y ; } if ( ! mb_x || mb_y == resync_mb_y || mb_y == resync_mb_y + 1 & & mb_x < resync_mb_x || s - > interlaced ) { int toprow = mb_y == resync_mb_y || mb_y == resync_mb_y + 1 & & mb_x < resync_mb_x ; int leftcol = ! mb_x || mb_y == resync_mb_y & & mb_x == resync_mb_x ; for ( i = 0 ; i < nb_components ; i + + ) { uint8_t * ptr ; uint16_t * ptr16 ; int n , h , v , x , y , c , j , linesize ; n = s - > nb_blocks[i] ; c = s - > comp_index[i] ; h = s - > h_scount[i] ; v = s - > v_scount[i] ; x = 0 ; y = 0 ; linesize= s - > linesize[c] ; if ( bits > 8 ) linesize /= 2 ; for ( j=0 ; j < n ; j + + ) { int pred , dc ; dc = mjpeg_decode_dc ( s , s - > dc_index[i] ) ; if ( dc == 0xFFFFF ) return - 1 ; if ( bits < =8 ) { ptr = s - > picture_ptr - > data[c] + ( linesize * ( v * mb_y + y ) ) + ( h * mb_x + x ) ; //FIXME optimize this crap if ( y==0 & & toprow ) { if ( x==0 & & leftcol ) { pred= 1 < < ( bits - 1 ) ; } else { pred= ptr[ - 1] ; } } else { if ( x==0 & & leftcol ) { pred= ptr[ - linesize] ; } else { PREDICT ( pred , ptr[ - linesize - 1] , ptr[ - linesize] , ptr[ - 1] , predictor ) ; } } if ( s - > interlaced & & s - > bottom_field ) ptr + = linesize > > 1 ; pred & = mask ; * ptr= pred + ( dc < < point_transform ) ; } else { ptr16 = ( uint16_t * ) ( s - > picture_ptr - > data[c] + 2 * ( linesize * ( v * mb_y + y ) ) + 2 * ( h * mb_x + x ) ) ; //FIXME optimize this crap if ( y==0 & & toprow ) { if ( x==0 & & leftcol ) { pred= 1 < < ( bits - 1 ) ; } else { pred= ptr16[ - 1] ; } } else { if ( x==0 & & leftcol ) { pred= ptr16[ - linesize] ; } else { PREDICT ( pred , ptr16[ - linesize - 1] , ptr16[ - linesize] , ptr16[ - 1] , predictor ) ; } } if ( s - > interlaced & & s - > bottom_field ) ptr16 + = linesize > > 1 ; pred & = mask ; * ptr16= pred + ( dc < < point_transform ) ; } if ( + + x == h ) { x = 0 ; y + + ; } } } } else { for ( i = 0 ; i < nb_components ; i + + ) { uint8_t * ptr ; uint16_t * ptr16 ; int n , h , v , x , y , c , j , linesize , dc ; n = s - > nb_blocks[i] ; c = s - > comp_index[i] ; h = s - > h_scount[i] ; v = s - > v_scount[i] ; x = 0 ; y = 0 ; linesize = s - > linesize[c] ; if ( bits > 8 ) linesize /= 2 ; for ( j = 0 ; j < n ; j + + ) { int pred ; dc = mjpeg_decode_dc ( s , s - > dc_index[i] ) ; if ( dc == 0xFFFFF ) return - 1 ; if ( bits < =8 ) { ptr = s - > picture_ptr - > data[c] + ( linesize * ( v * mb_y + y ) ) + ( h * mb_x + x ) ; //FIXME optimize this crap PREDICT ( pred , ptr[ - linesize - 1] , ptr[ - linesize] , ptr[ - 1] , predictor ) ; pred & = mask ; * ptr = pred + ( dc < < point_transform ) ; } else { ptr16 = ( uint16_t * ) ( s - > picture_ptr - > data[c] + 2 * ( linesize * ( v * mb_y + y ) ) + 2 * ( h * mb_x + x ) ) ; //FIXME optimize this crap PREDICT ( pred , ptr16[ - linesize - 1] , ptr16[ - linesize] , ptr16[ - 1] , predictor ) ; pred & = mask ; * ptr16= pred + ( dc < < point_transform ) ; } if ( + + x == h ) { x = 0 ; y + + ; } } } } if ( s - > restart_interval & & ! - - s - > restart_count ) { align_get_bits ( & s - > gb ) ; skip_bits ( & s - > gb , 16 ) ; / * skip RSTn * / } } } return 0 ; }",0
"unsigned ff_dxva2_get_surface_index ( const AVCodecContext * avctx , const AVDXVAContext * ctx , const AVFrame * frame ) { void * surface = get_surface ( frame ) ; unsigned i ; for ( i = 0 ; i < DXVA_CONTEXT_COUNT ( avctx , ctx ) ; i + + ) { if CONFIG_D3D11VA if ( avctx - > pix_fmt == AV_PIX_FMT_D3D11VA_VLD & & ctx - > d3d11va . surface[i] == surface ) { D3D11_VIDEO_DECODER_OUTPUT_VIEW_DESC viewDesc ; ID3D11VideoDecoderOutputView_GetDesc ( ctx - > d3d11va . surface[i] , & viewDesc ) ; return viewDesc . Texture2D . ArraySlice ; } endif if CONFIG_DXVA2 if ( avctx - > pix_fmt == AV_PIX_FMT_DXVA2_VLD & & ctx - > dxva2 . surface[i] == surface ) return i ; endif } assert ( 0 ) ; return 0 ; }",0
"static int read_table ( AVFormatContext * avctx , AVStream * st , int ( * parse ) ( AVFormatContext * avctx , AVStream * st , const char * name , int size ) ) { int count , i ; AVIOContext * pb = avctx - > pb ; avio_skip ( pb , 4 ) ; count = avio_rb32 ( pb ) ; avio_skip ( pb , 4 ) ; for ( i = 0 ; i < count ; i + + ) { char name[17] ; int size ; avio_read ( pb , name , 16 ) ; name[sizeof ( name ) - 1] = 0 ; size = avio_rb32 ( pb ) ; if ( size < 0 ) { av_log ( avctx , AV_LOG_ERROR , entry size %d is invalid\n , size ) ; return AVERROR_INVALIDDATA ; } if ( parse ( avctx , st , name , size ) < 0 ) { avpriv_request_sample ( avctx , Variable %s , name ) ; avio_skip ( pb , size ) ; } } return 0 ; }",0
"void avpriv_do_elbg ( int * points , int dim , int numpoints , int * codebook , int numCB , int max_steps , int * closest_cb , AVLFG * rand_state ) { int dist ; elbg_data elbg_d ; elbg_data * elbg = & elbg_d ; int i , j , k , last_error , steps=0 ; int * dist_cb = av_malloc ( numpoints * sizeof ( int ) ) ; int * size_part = av_malloc ( numCB * sizeof ( int ) ) ; cell * list_buffer = av_malloc ( numpoints * sizeof ( cell ) ) ; cell * free_cells ; int best_dist , best_idx = 0 ; elbg - > error = INT_MAX ; elbg - > dim = dim ; elbg - > numCB = numCB ; elbg - > codebook = codebook ; elbg - > cells = av_malloc ( numCB * sizeof ( cell * ) ) ; elbg - > utility = av_malloc ( numCB * sizeof ( int ) ) ; elbg - > nearest_cb = closest_cb ; elbg - > points = points ; elbg - > utility_inc = av_malloc ( numCB * sizeof ( int ) ) ; elbg - > scratchbuf = av_malloc ( 5 * dim * sizeof ( int ) ) ; elbg - > rand_state = rand_state ; do { free_cells = list_buffer ; last_error = elbg - > error ; steps + + ; memset ( elbg - > utility , 0 , numCB * sizeof ( int ) ) ; memset ( elbg - > cells , 0 , numCB * sizeof ( cell * ) ) ; elbg - > error = 0 ; / * This loop evaluate the actual Voronoi partition . It is the most costly part of the algorithm . * / for ( i=0 ; i < numpoints ; i + + ) { best_dist = distance_limited ( elbg - > points + i * elbg - > dim , elbg - > codebook + best_idx * elbg - > dim , dim , INT_MAX ) ; for ( k=0 ; k < elbg - > numCB ; k + + ) { dist = distance_limited ( elbg - > points + i * elbg - > dim , elbg - > codebook + k * elbg - > dim , dim , best_dist ) ; if ( dist < best_dist ) { best_dist = dist ; best_idx = k ; } } elbg - > nearest_cb[i] = best_idx ; dist_cb[i] = best_dist ; elbg - > error + = dist_cb[i] ; elbg - > utility[elbg - > nearest_cb[i]] + = dist_cb[i] ; free_cells - > index = i ; free_cells - > next = elbg - > cells[elbg - > nearest_cb[i]] ; elbg - > cells[elbg - > nearest_cb[i]] = free_cells ; free_cells + + ; } do_shiftings ( elbg ) ; memset ( size_part , 0 , numCB * sizeof ( int ) ) ; memset ( elbg - > codebook , 0 , elbg - > numCB * dim * sizeof ( int ) ) ; for ( i=0 ; i < numpoints ; i + + ) { size_part[elbg - > nearest_cb[i]] + + ; for ( j=0 ; j < elbg - > dim ; j + + ) elbg - > codebook[elbg - > nearest_cb[i] * elbg - > dim + j] + = elbg - > points[i * elbg - > dim + j] ; } for ( i=0 ; i < elbg - > numCB ; i + + ) vect_division ( elbg - > codebook + i * elbg - > dim , elbg - > codebook + i * elbg - > dim , size_part[i] , elbg - > dim ) ; } while ( ( ( last_error - elbg - > error ) > DELTA_ERR_MAX * elbg - > error ) & & ( steps < max_steps ) ) ; av_free ( dist_cb ) ; av_free ( size_part ) ; av_free ( elbg - > utility ) ; av_free ( list_buffer ) ; av_free ( elbg - > cells ) ; av_free ( elbg - > utility_inc ) ; av_free ( elbg - > scratchbuf ) ; }",1
"static int xmv_read_packet ( AVFormatContext * s , AVPacket * pkt ) { XMVDemuxContext * xmv = s - > priv_data ; int result ; if ( xmv - > video . current_frame == xmv - > video . frame_count ) { / * No frames left in this packet , so we fetch a new one * / result = xmv_fetch_new_packet ( s ) ; if ( result ) return result ; } if ( xmv - > current_stream == 0 ) { / * Fetch a video frame * / result = xmv_fetch_video_packet ( s , pkt ) ; } else { / * Fetch an audio frame * / result = xmv_fetch_audio_packet ( s , pkt , xmv - > current_stream - 1 ) ; } if ( result ) return result ; / * Increase our counters * / if ( + + xmv - > current_stream > = xmv - > stream_count ) { xmv - > current_stream = 0 ; xmv - > video . current_frame + = 1 ; } return 0 ; }",0
"static void sbr_mapping ( AACContext * ac , SpectralBandReplication * sbr , SBRData * ch_data , int e_a[2] ) { int e , i , m ; memset ( ch_data - > s_indexmapped[1] , 0 , 7 * sizeof ( ch_data - > s_indexmapped[1] ) ) ; for ( e = 0 ; e < ch_data - > bs_num_env ; e + + ) { const unsigned int ilim = sbr - > n[ch_data - > bs_freq_res[e + 1]] ; uint16_t * table = ch_data - > bs_freq_res[e + 1] ? sbr - > f_tablehigh : sbr - > f_tablelow ; int k ; for ( i = 0 ; i < ilim ; i + + ) for ( m = table[i] ; m < table[i + 1] ; m + + ) sbr - > e_origmapped[e][m - sbr - > kx[1]] = ch_data - > env_facs[e + 1][i] ; // ch_data - > bs_num_noise > 1 = > 2 noise floors k = ( ch_data - > bs_num_noise > 1 ) & & ( ch_data - > t_env[e] > = ch_data - > t_q[1] ) ; for ( i = 0 ; i < sbr - > n_q ; i + + ) for ( m = sbr - > f_tablenoise[i] ; m < sbr - > f_tablenoise[i + 1] ; m + + ) sbr - > q_mapped[e][m - sbr - > kx[1]] = ch_data - > noise_facs[k + 1][i] ; for ( i = 0 ; i < sbr - > n[1] ; i + + ) { if ( ch_data - > bs_add_harmonic_flag ) { const unsigned int m_midpoint = ( sbr - > f_tablehigh[i] + sbr - > f_tablehigh[i + 1] ) > > 1 ; ch_data - > s_indexmapped[e + 1][m_midpoint - sbr - > kx[1]] = ch_data - > bs_add_harmonic[i] * ( e > = e_a[1] || ( ch_data - > s_indexmapped[0][m_midpoint - sbr - > kx[1]] == 1 ) ) ; } } for ( i = 0 ; i < ilim ; i + + ) { int additional_sinusoid_present = 0 ; for ( m = table[i] ; m < table[i + 1] ; m + + ) { if ( ch_data - > s_indexmapped[e + 1][m - sbr - > kx[1]] ) { additional_sinusoid_present = 1 ; break ; } } memset ( & sbr - > s_mapped[e][table[i] - sbr - > kx[1]] , additional_sinusoid_present , ( table[i + 1] - table[i] ) * sizeof ( sbr - > s_mapped[e][0] ) ) ; } } memcpy ( ch_data - > s_indexmapped[0] , ch_data - > s_indexmapped[ch_data - > bs_num_env] , sizeof ( ch_data - > s_indexmapped[0] ) ) ; }",0
"static void draw_mandelbrot ( AVFilterContext * ctx , uint32_t * color , int linesize , int64_t pts ) { MBContext * mb = ctx - > priv ; int x , y , i , in_cidx=0 , next_cidx=0 , tmp_cidx ; double scale= mb - > start_scale * pow ( mb - > end_scale/mb - > start_scale , pts/mb - > end_pts ) ; int use_zyklus=0 ; fill_from_cache ( ctx , NULL , & in_cidx , NULL , mb - > start_y + scale * ( - mb - > h/2 - 0 . 5 ) , scale ) ; tmp_cidx= in_cidx ; memset ( color , 0 , sizeof ( * color ) * mb - > w ) ; for ( y=0 ; y < mb - > h ; y + + ) { int y1= y + 1 ; const double ci=mb - > start_y + scale * ( y - mb - > h/2 ) ; fill_from_cache ( ctx , NULL , & in_cidx , & next_cidx , ci , scale ) ; if ( y1 < mb - > h ) { memset ( color + linesize * y1 , 0 , sizeof ( * color ) * mb - > w ) ; fill_from_cache ( ctx , color + linesize * y1 , & tmp_cidx , NULL , ci + 3 * scale/2 , scale ) ; } for ( x=0 ; x < mb - > w ; x + + ) { float epsilon ; const double cr=mb - > start_x + scale * ( x - mb - > w/2 ) ; double zr=cr ; double zi=ci ; uint32_t c=0 ; double dv= mb - > dither / ( double ) ( 1LL < < 32 ) ; mb - > dither= mb - > dither * 1664525 + 1013904223 ; if ( color[x + y * linesize] & 0xFF000000 ) continue ; if ( interpol ( mb , color , x , y , linesize ) ) { if ( next_cidx < mb - > cache_allocated ) { mb - > next_cache[next_cidx ] . p[0]= cr ; mb - > next_cache[next_cidx ] . p[1]= ci ; mb - > next_cache[next_cidx + + ] . val = color[x + y * linesize] ; } continue ; } use_zyklus= ( x==0 || mb - > inner ! =BLACK ||color[x - 1 + y * linesize] == 0xFF000000 ) ; if ( use_zyklus ) epsilon= scale * 1 * sqrt ( SQR ( x - mb - > w/2 ) + SQR ( y - mb - > h/2 ) ) /mb - > w ; define Z_Z2_C ( outr , outi , inr , ini ) \ outr= inr * inr - ini * ini + cr ; \ outi= 2 * inr * ini + ci ; define Z_Z2_C_ZYKLUS ( outr , outi , inr , ini , Z ) \ Z_Z2_C ( outr , outi , inr , ini ) \ if ( use_zyklus ) { \ if ( Z & & fabs ( mb - > zyklus[i > > 1][0] - outr ) + fabs ( mb - > zyklus[i > > 1][1] - outi ) < = epsilon ) \ break ; \ } \ mb - > zyklus[i][0]= outr ; \ mb - > zyklus[i][1]= outi ; \ for ( i=0 ; i < mb - > maxiter - 8 ; i + + ) { double t ; Z_Z2_C_ZYKLUS ( t , zi , zr , zi , 0 ) i + + ; Z_Z2_C_ZYKLUS ( zr , zi , t , zi , 1 ) i + + ; Z_Z2_C_ZYKLUS ( t , zi , zr , zi , 0 ) i + + ; Z_Z2_C_ZYKLUS ( zr , zi , t , zi , 1 ) i + + ; Z_Z2_C_ZYKLUS ( t , zi , zr , zi , 0 ) i + + ; Z_Z2_C_ZYKLUS ( zr , zi , t , zi , 1 ) i + + ; Z_Z2_C_ZYKLUS ( t , zi , zr , zi , 0 ) i + + ; Z_Z2_C_ZYKLUS ( zr , zi , t , zi , 1 ) if ( zr * zr + zi * zi > mb - > bailout ) { i - = FFMIN ( 7 , i ) ; for ( ; i < mb - > maxiter ; i + + ) { zr= mb - > zyklus[i][0] ; zi= mb - > zyklus[i][1] ; if ( zr * zr + zi * zi > mb - > bailout ) { switch ( mb - > outer ) { case ITERATION_COUNT : zr = i ; break ; case NORMALIZED_ITERATION_COUNT : zr= i + log2 ( log ( mb - > bailout ) / log ( zr * zr + zi * zi ) ) ; break ; } c= lrintf ( ( sin ( zr ) + 1 ) * 127 ) + lrintf ( ( sin ( zr/1 . 234 ) + 1 ) * 127 ) * 256 * 256 + lrintf ( ( sin ( zr/100 ) + 1 ) * 127 ) * 256 ; break ; } } break ; } } if ( ! c ) { if ( mb - > inner==PERIOD ) { int j ; for ( j=i - 1 ; j ; j - - ) if ( SQR ( mb - > zyklus[j][0] - zr ) + SQR ( mb - > zyklus[j][1] - zi ) < epsilon * epsilon * 10 ) break ; if ( j ) { c= i - j ; c= ( ( c < < 5 ) & 0xE0 ) + ( ( c < < 16 ) & 0xE000 ) + ( ( c < < 27 ) & 0xE00000 ) ; } } else if ( mb - > inner==CONVTIME ) { c= floor ( i * 255 . 0/mb - > maxiter + dv ) * 0x010101 ; } else if ( mb - > inner==MINCOL ) { int j ; double closest=9999 ; int closest_index=0 ; for ( j=i - 1 ; j > =0 ; j - - ) if ( SQR ( mb - > zyklus[j][0] ) + SQR ( mb - > zyklus[j][1] ) < closest ) { closest= SQR ( mb - > zyklus[j][0] ) + SQR ( mb - > zyklus[j][1] ) ; closest_index= j ; } closest = sqrt ( closest ) ; c= lrintf ( ( mb - > zyklus[closest_index][0]/closest + 1 ) * 127 + dv ) + lrintf ( ( mb - > zyklus[closest_index][1]/closest + 1 ) * 127 + dv ) * 256 ; } } c |= 0xFF000000 ; color[x + y * linesize]= c ; if ( next_cidx < mb - > cache_allocated ) { mb - > next_cache[next_cidx ] . p[0]= cr ; mb - > next_cache[next_cidx ] . p[1]= ci ; mb - > next_cache[next_cidx + + ] . val = c ; } } fill_from_cache ( ctx , NULL , & in_cidx , & next_cidx , ci +",1
"static int rm_assemble_video_frame ( AVFormatContext * s , AVIOContext * pb , RMDemuxContext * rm , RMStream * vst , AVPacket * pkt , int len , int * pseq , int64_t * timestamp ) { int hdr , seq , pic_num , len2 , pos ; int type ; hdr = avio_r8 ( pb ) ; len - - ; type = hdr > > 6 ; if ( type ! = 3 ) { // not frame as a part of packet seq = avio_r8 ( pb ) ; len - - ; } if ( type ! = 1 ) { // not whole frame len2 = get_num ( pb , & len ) ; pos = get_num ( pb , & len ) ; pic_num = avio_r8 ( pb ) ; len - - ; } if ( len < 0 ) return - 1 ; rm - > remaining_len = len ; if ( type & 1 ) { // frame , not slice if ( type == 3 ) { // frame as a part of packet len= len2 ; * timestamp = pos ; } if ( rm - > remaining_len < len ) return - 1 ; rm - > remaining_len - = len ; if ( av_new_packet ( pkt , len + 9 ) < 0 ) return AVERROR ( EIO ) ; pkt - > data[0] = 0 ; AV_WL32 ( pkt - > data + 1 , 1 ) ; AV_WL32 ( pkt - > data + 5 , 0 ) ; avio_read ( pb , pkt - > data + 9 , len ) ; return 0 ; } //now we have to deal with single slice * pseq = seq ; if ( ( seq & 0x7F ) == 1 || vst - > curpic_num ! = pic_num ) { vst - > slices = ( ( hdr & 0x3F ) < < 1 ) + 1 ; vst - > videobufsize = len2 + 8 * vst - > slices + 1 ; av_free_packet ( & vst - > pkt ) ; //FIXME this should be output . if ( av_new_packet ( & vst - > pkt , vst - > videobufsize ) < 0 ) return AVERROR ( ENOMEM ) ; vst - > videobufpos = 8 * vst - > slices + 1 ; vst - > cur_slice = 0 ; vst - > curpic_num = pic_num ; vst - > pktpos = avio_tell ( pb ) ; } if ( type == 2 ) len = FFMIN ( len , pos ) ; if ( + + vst - > cur_slice > vst - > slices ) return 1 ; AV_WL32 ( vst - > pkt . data - 7 + 8 * vst - > cur_slice , 1 ) ; AV_WL32 ( vst - > pkt . data - 3 + 8 * vst - > cur_slice , vst - > videobufpos - 8 * vst - > slices - 1 ) ; if ( vst - > videobufpos + len > vst - > videobufsize ) return 1 ; if ( avio_read ( pb , vst - > pkt . data + vst - > videobufpos , len ) ! = len ) return AVERROR ( EIO ) ; vst - > videobufpos + = len ; rm - > remaining_len - = len ; if ( type == 2 || vst - > videobufpos == vst - > videobufsize ) { vst - > pkt . data[0] = vst - > cur_slice - 1 ; * pkt= vst - > pkt ; vst - > pkt . data= NULL ; vst - > pkt . size= 0 ; if ( vst - > slices ! = vst - > cur_slice ) //FIXME find out how to set slices correct from the begin memmove ( pkt - > data + 1 + 8 * vst - > cur_slice , pkt - > data + 1 + 8 * vst - > slices , vst - > videobufpos - 1 - 8 * vst - > slices ) ; pkt - > size = vst - > videobufpos + 8 * ( vst - > cur_slice - vst - > slices ) ; pkt - > pts = AV_NOPTS_VALUE ; pkt - > pos = vst - > pktpos ; vst - > slices = 0 ; return 0 ; } return 1 ; }",1
"static void nal_send ( AVFormatContext * s1 , const uint8_t * buf , int size , int last ) { RTPMuxContext * s = s1 - > priv_data ; av_log ( s1 , AV_LOG_DEBUG , Sending NAL %x of len %d M=%d\n , buf[0] & 0x1F , size , last ) ; if ( size < = s - > max_payload_size ) { int buffered_size = s - > buf_ptr - s - > buf ; // Flush buffered NAL units if the current unit doesn ' t fit if ( buffered_size + 2 + size > s - > max_payload_size ) { flush_buffered ( s1 , 0 ) ; buffered_size = 0 ; } // If we aren ' t using mode 0 , and the NAL unit fits including the // framing ( 2 bytes length , plus 1 byte for the STAP - A marker ) , // write the unit to the buffer as a STAP - A packet , otherwise flush // and send as single NAL . if ( buffered_size + 3 + size < = s - > max_payload_size & & ! ( s - > flags & FF_RTP_FLAG_H264_MODE0 ) ) { if ( buffered_size == 0 ) * s - > buf_ptr + + = 24 ; AV_WB16 ( s - > buf_ptr , size ) ; s - > buf_ptr + = 2 ; memcpy ( s - > buf_ptr , buf , size ) ; s - > buf_ptr + = size ; s - > buffered_nals + + ; } else { flush_buffered ( s1 , 0 ) ; ff_rtp_send_data ( s1 , buf , size , last ) ; } } else { uint8_t type = buf[0] & 0x1F ; uint8_t nri = buf[0] & 0x60 ; flush_buffered ( s1 , 0 ) ; if ( s - > flags & FF_RTP_FLAG_H264_MODE0 ) { av_log ( s1 , AV_LOG_ERROR , NAL size %d > %d , try - slice - max - size %d\n , size , s - > max_payload_size , s - > max_payload_size ) ; return ; } av_log ( s1 , AV_LOG_DEBUG , NAL size %d > %d\n , size , s - > max_payload_size ) ; s - > buf[0] = 28 ; / * FU Indicator ; Type = 28 - - - > FU - A * / s - > buf[0] |= nri ; s - > buf[1] = type ; s - > buf[1] |= 1 < < 7 ; buf + = 1 ; size - = 1 ; while ( size + 2 > s - > max_payload_size ) { memcpy ( & s - > buf[2] , buf , s - > max_payload_size - 2 ) ; ff_rtp_send_data ( s1 , s - > buf , s - > max_payload_size , 0 ) ; buf + = s - > max_payload_size - 2 ; size - = s - > max_payload_size - 2 ; s - > buf[1] & = ( 1 < < 7 ) ; } s - > buf[1] |= 1 < < 6 ; memcpy ( & s - > buf[2] , buf , size ) ; ff_rtp_send_data ( s1 , s - > buf , size + 2 , last ) ; } }",1
"static av_always_inline int vmnc_get_pixel ( const uint8_t * buf , int bpp , int be ) { switch ( bpp * 2 + be ) { case 2 : case 3 : return * buf ; case 4 : return AV_RL16 ( buf ) ; case 5 : return AV_RB16 ( buf ) ; case 8 : return AV_RL32 ( buf ) ; case 9 : return AV_RB32 ( buf ) ; default : return 0 ; } }",1
"static int get_moov_size ( AVFormatContext * s ) { int ret ; AVIOContext * moov_buf ; MOVMuxContext * mov = s - > priv_data ; if ( ( ret = ffio_open_null_buf ( & moov_buf ) ) < 0 ) return ret ; mov_write_moov_tag ( moov_buf , mov , s ) ; return ffio_close_null_buf ( moov_buf ) ; }",1
"static void vc1_mc_4mv_luma ( VC1Context * v , int n , int dir , int avg ) { MpegEncContext * s = & v - > s ; uint8_t * srcY ; int dxy , mx , my , src_x , src_y ; int off ; int fieldmv = ( v - > fcm == ILACE_FRAME ) ? v - > blk_mv_type[s - > block_index[n]] : 0 ; int v_edge_pos = s - > v_edge_pos > > v - > field_mode ; uint8_t ( * luty ) [256] ; int use_ic ; if ( ( ! v - > field_mode || ( v - > ref_field_type[dir] == 1 & & v - > cur_field_type == 1 ) ) & & ! v - > s . last_picture . f . data[0] ) return ; mx = s - > mv[dir][n][0] ; my = s - > mv[dir][n][1] ; if ( ! dir ) { if ( v - > field_mode & & ( v - > cur_field_type ! = v - > ref_field_type[dir] ) & & v - > second_field ) { srcY = s - > current_picture . f . data[0] ; luty = v - > curr_luty ; use_ic = v - > curr_use_ic ; } else { srcY = s - > last_picture . f . data[0] ; luty = v - > last_luty ; use_ic = v - > last_use_ic ; } } else { srcY = s - > next_picture . f . data[0] ; luty = v - > next_luty ; use_ic = v - > next_use_ic ; } if ( ! srcY ) { av_log ( v - > s . avctx , AV_LOG_ERROR , Referenced frame missing . \n ) ; return ; } if ( v - > field_mode ) { if ( v - > cur_field_type ! = v - > ref_field_type[dir] ) my = my - 2 + 4 * v - > cur_field_type ; } if ( s - > pict_type == AV_PICTURE_TYPE_P & & n == 3 & & v - > field_mode ) { int same_count = 0 , opp_count = 0 , k ; int chosen_mv[2][4][2] , f ; int tx , ty ; for ( k = 0 ; k < 4 ; k + + ) { f = v - > mv_f[0][s - > block_index[k] + v - > blocks_off] ; chosen_mv[f][f ? opp_count : same_count][0] = s - > mv[0][k][0] ; chosen_mv[f][f ? opp_count : same_count][1] = s - > mv[0][k][1] ; opp_count + = f ; same_count + = 1 - f ; } f = opp_count > same_count ; switch ( f ? opp_count : same_count ) { case 4 : tx = median4 ( chosen_mv[f][0][0] , chosen_mv[f][1][0] , chosen_mv[f][2][0] , chosen_mv[f][3][0] ) ; ty = median4 ( chosen_mv[f][0][1] , chosen_mv[f][1][1] , chosen_mv[f][2][1] , chosen_mv[f][3][1] ) ; break ; case 3 : tx = mid_pred ( chosen_mv[f][0][0] , chosen_mv[f][1][0] , chosen_mv[f][2][0] ) ; ty = mid_pred ( chosen_mv[f][0][1] , chosen_mv[f][1][1] , chosen_mv[f][2][1] ) ; break ; case 2 : tx = ( chosen_mv[f][0][0] + chosen_mv[f][1][0] ) / 2 ; ty = ( chosen_mv[f][0][1] + chosen_mv[f][1][1] ) / 2 ; break ; } s - > current_picture . motion_val[1][s - > block_index[0] + v - > blocks_off][0] = tx ; s - > current_picture . motion_val[1][s - > block_index[0] + v - > blocks_off][1] = ty ; for ( k = 0 ; k < 4 ; k + + ) v - > mv_f[1][s - > block_index[k] + v - > blocks_off] = f ; } if ( v - > fcm == ILACE_FRAME ) { // not sure if needed for other types of picture int qx , qy ; int width = s - > avctx - > coded_width ; int height = s - > avctx - > coded_height > > 1 ; if ( s - > pict_type == AV_PICTURE_TYPE_P ) { s - > current_picture . motion_val[1][s - > block_index[n] + v - > blocks_off][0] = mx ; s - > current_picture . motion_val[1][s - > block_index[n] + v - > blocks_off][1] = my ; } qx = ( s - > mb_x * 16 ) + ( mx > > 2 ) ; qy = ( s - > mb_y * 8 ) + ( my > > 3 ) ; if ( qx < - 17 ) mx - = 4 * ( qx + 17 ) ; else if ( qx > width ) mx - = 4 * ( qx - width ) ; if ( qy < - 18 ) my - = 8 * ( qy + 18 ) ; else if ( qy > height + 1 ) my - = 8 * ( qy - height - 1 ) ; } if ( ( v - > fcm == ILACE_FRAME ) & & fieldmv ) off = ( ( n > 1 ) ? s - > linesize : 0 ) + ( n & 1 ) * 8 ; else off = s - > linesize * 4 * ( n & 2 ) + ( n & 1 ) * 8 ; src_x = s - > mb_x * 16 + ( n & 1 ) * 8 + ( mx > > 2 ) ; if ( ! fieldmv ) src_y = s - > mb_y * 16 + ( n & 2 ) * 4 + ( my > > 2 ) ; else src_y = s - > mb_y * 16 + ( ( n > 1 ) ? 1 : 0 ) + ( my > > 2 ) ; if ( v - > profile ! = PROFILE_ADVANCED ) { src_x = av_clip ( src_x , - 16 , s - > mb_width * 16 ) ; src_y = av_clip ( src_y , - 16 , s - > mb_height * 16 ) ; } else { src_x = av_clip ( src_x , - 17 , s - > avctx - > coded_width ) ; if ( v - > fcm == ILACE_FRAME ) { if ( src_y & 1 ) src_y = av_clip ( src_y , - 17 , s - > avctx - > coded_height + 1 ) ; else src_y = av_clip ( src_y , - 18 , s - > avctx - > coded_height ) ; } else { src_y = av_clip ( src_y , - 18 , s - > avctx - > coded_height + 1 ) ; } } srcY + = src_y * s - > linesize + src_x ; if ( v - > field_mode & & v - > ref_field_type[dir] ) srcY + = s - > current_picture_ptr - > f . linesize[0] ; if ( fieldmv & & ! ( src_y & 1 ) ) v_edge_pos - - ; if ( fieldmv & & ( src_y & 1 ) & & src_y < 4 ) src_y - - ; if ( v - > rangeredfrm || use_ic || s - > h_edge_pos < 13 || v_edge_pos < 23 || ( unsigned ) ( src_x - s - > mspel",1
"static int recover ( WtvContext * wtv , uint64_t broken_pos ) { AVIOContext * pb = wtv - > pb ; int i ; for ( i = 0 ; i < wtv - > nb_index_entries ; i + + ) { if ( wtv - > index_entries[i] . pos > broken_pos ) { int ret = avio_seek ( pb , wtv - > index_entries[i] . pos , SEEK_SET ) ; if ( ret < 0 ) return ret ; wtv - > pts = wtv - > index_entries[i] . timestamp ; return 0 ; } } return AVERROR ( EIO ) ; }",1
"static always_inline void mpeg_motion_lowres ( MpegEncContext * s , uint8_t * dest_y , uint8_t * dest_cb , uint8_t * dest_cr , int field_based , int bottom_field , int field_select , uint8_t * * ref_picture , h264_chroma_mc_func * pix_op , int motion_x , int motion_y , int h ) { uint8_t * ptr_y , * ptr_cb , * ptr_cr ; int mx , my , src_x , src_y , uvsrc_x , uvsrc_y , uvlinesize , linesize , sx , sy , uvsx , uvsy ; const int lowres= s - > avctx - > lowres ; const int block_s= 8 > > lowres ; const int s_mask= ( 2 < < lowres ) - 1 ; const int h_edge_pos = s - > h_edge_pos > > lowres ; const int v_edge_pos = s - > v_edge_pos > > lowres ; linesize = s - > current_picture . linesize[0] < < field_based ; uvlinesize = s - > current_picture . linesize[1] < < field_based ; if ( s - > quarter_sample ) { //FIXME obviously not perfect but qpel wont work in lowres anyway motion_x/=2 ; motion_y/=2 ; } if ( field_based ) { motion_y + = ( bottom_field - field_select ) * ( ( 1 < < lowres ) - 1 ) ; } sx= motion_x & s_mask ; sy= motion_y & s_mask ; src_x = s - > mb_x * 2 * block_s + ( motion_x > > ( lowres + 1 ) ) ; src_y = ( s - > mb_y * 2 * block_s > > field_based ) + ( motion_y > > ( lowres + 1 ) ) ; if ( s - > out_format == FMT_H263 ) { uvsx = ( ( motion_x > > 1 ) & s_mask ) | ( sx & 1 ) ; uvsy = ( ( motion_y > > 1 ) & s_mask ) | ( sy & 1 ) ; uvsrc_x = src_x > > 1 ; uvsrc_y = src_y > > 1 ; } else if ( s - > out_format == FMT_H261 ) { //even chroma mv ' s are full pel in H261 mx = motion_x / 4 ; my = motion_y / 4 ; uvsx = ( 2 * mx ) & s_mask ; uvsy = ( 2 * my ) & s_mask ; uvsrc_x = s - > mb_x * block_s + ( mx > > lowres ) ; uvsrc_y = s - > mb_y * block_s + ( my > > lowres ) ; } else { mx = motion_x / 2 ; my = motion_y / 2 ; uvsx = mx & s_mask ; uvsy = my & s_mask ; uvsrc_x = s - > mb_x * block_s + ( mx > > ( lowres + 1 ) ) ; uvsrc_y = ( s - > mb_y * block_s > > field_based ) + ( my > > ( lowres + 1 ) ) ; } ptr_y = ref_picture[0] + src_y * linesize + src_x ; ptr_cb = ref_picture[1] + uvsrc_y * uvlinesize + uvsrc_x ; ptr_cr = ref_picture[2] + uvsrc_y * uvlinesize + uvsrc_x ; if ( ( unsigned ) src_x > h_edge_pos - ( ! ! sx ) - 2 * block_s || ( unsigned ) src_y > ( v_edge_pos > > field_based ) - ( ! ! sy ) - h ) { ff_emulated_edge_mc ( s - > edge_emu_buffer , ptr_y , s - > linesize , 17 , 17 + field_based , src_x , src_y < < field_based , h_edge_pos , v_edge_pos ) ; ptr_y = s - > edge_emu_buffer ; if ( ! ( s - > flags & CODEC_FLAG_GRAY ) ) { uint8_t * uvbuf= s - > edge_emu_buffer + 18 * s - > linesize ; ff_emulated_edge_mc ( uvbuf , ptr_cb , s - > uvlinesize , 9 , 9 + field_based , uvsrc_x , uvsrc_y < < field_based , h_edge_pos > > 1 , v_edge_pos > > 1 ) ; ff_emulated_edge_mc ( uvbuf + 16 , ptr_cr , s - > uvlinesize , 9 , 9 + field_based , uvsrc_x , uvsrc_y < < field_based , h_edge_pos > > 1 , v_edge_pos > > 1 ) ; ptr_cb= uvbuf ; ptr_cr= uvbuf + 16 ; } } if ( bottom_field ) { //FIXME use this for field pix too instead of the obnoxious hack which changes picture . data dest_y + = s - > linesize ; dest_cb + = s - > uvlinesize ; dest_cr + = s - > uvlinesize ; } if ( field_select ) { ptr_y + = s - > linesize ; ptr_cb + = s - > uvlinesize ; ptr_cr + = s - > uvlinesize ; } sx < < = 2 - lowres ; sy < < = 2 - lowres ; pix_op[lowres - 1] ( dest_y , ptr_y , linesize , h , sx , sy ) ; if ( ! ( s - > flags & CODEC_FLAG_GRAY ) ) { uvsx < < = 2 - lowres ; uvsy < < = 2 - lowres ; pix_op[lowres] ( dest_cb , ptr_cb , uvlinesize , h > > s - > chroma_y_shift , uvsx , uvsy ) ; pix_op[lowres] ( dest_cr , ptr_cr , uvlinesize , h > > s - > chroma_y_shift , uvsx , uvsy ) ; } }",1
"static const uint8_t * decode_nal ( H264Context * h , const uint8_t * src , int * dst_length , int * consumed , int length ) { int i , si , di ; uint8_t * dst ; int bufidx ; // src[0] & 0x80 ; //forbidden bit h - > nal_ref_idc= src[0] > > 5 ; h - > nal_unit_type= src[0] & 0x1F ; src + + ; length - - ; if 0 for ( i=0 ; i < length ; i + + ) printf ( %2X , src[i] ) ; endif for ( i=0 ; i + 1 < length ; i + =2 ) { if ( src[i] ) continue ; if ( i > 0 & & src[i - 1]==0 ) i - - ; if ( i + 2 < length & & src[i + 1]==0 & & src[i + 2] < =3 ) { if ( src[i + 2] ! =3 ) { / * startcode , so we must be past the end * / length=i ; } break ; } } if ( i > =length - 1 ) { //no escaped 0 * dst_length= length ; * consumed= length + 1 ; // + 1 for the header return src ; } bufidx = h - > nal_unit_type == NAL_DPC ? 1 : 0 ; // use second escape buffer for inter data h - > rbsp_buffer[bufidx]= av_fast_realloc ( h - > rbsp_buffer[bufidx] , & h - > rbsp_buffer_size[bufidx] , length ) ; dst= h - > rbsp_buffer[bufidx] ; if ( dst == NULL ) { return NULL ; } //printf ( decoding esc\n ) ; si=di=0 ; while ( si < length ) { //remove escapes ( very rare 1 : 2 22 ) if ( si + 2 < length & & src[si]==0 & & src[si + 1]==0 & & src[si + 2] < =3 ) { if ( src[si + 2]==3 ) { //escape dst[di + + ]= 0 ; dst[di + + ]= 0 ; si + =3 ; continue ; } else //next start code break ; } dst[di + + ]= src[si + + ] ; } * dst_length= di ; * consumed= si + 1 ; // + 1 for the header //FIXME store exact number of bits in the getbitcontext ( it is needed for decoding ) return dst ; }",1
"static int smka_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , uint8_t * buf , int buf_size ) { GetBitContext gb ; HuffContext h[4] ; VLC vlc[4] ; int16_t * samples = data ; int val ; int i , res ; int unp_size ; int bits , stereo ; int pred[2] = { 0 , 0 } ; unp_size = AV_RL32 ( buf ) ; init_get_bits ( & gb , buf + 4 , ( buf_size - 4 ) * 8 ) ; if ( ! get_bits1 ( & gb ) ) { av_log ( avctx , AV_LOG_INFO , Sound : no data\n ) ; * data_size = 0 ; return 1 ; } stereo = get_bits1 ( & gb ) ; bits = get_bits1 ( & gb ) ; if ( ( unp_size < < ! bits ) > * data_size ) { av_log ( avctx , AV_LOG_ERROR , Frame is too large to fit in buffer\n ) ; return - 1 ; } memset ( vlc , 0 , sizeof ( VLC ) * 4 ) ; memset ( h , 0 , sizeof ( HuffContext ) * 4 ) ; // Initialize for ( i = 0 ; i < ( 1 < < ( bits + stereo ) ) ; i + + ) { h[i] . length = 256 ; h[i] . maxlength = 0 ; h[i] . current = 0 ; h[i] . bits = av_mallocz ( 256 * 4 ) ; h[i] . lengths = av_mallocz ( 256 * sizeof ( int ) ) ; h[i] . values = av_mallocz ( 256 * sizeof ( int ) ) ; skip_bits1 ( & gb ) ; smacker_decode_tree ( & gb , & h[i] , 0 , 0 ) ; skip_bits1 ( & gb ) ; if ( h[i] . current > 1 ) { res = init_vlc ( & vlc[i] , SMKTREE_BITS , h[i] . length , h[i] . lengths , sizeof ( int ) , sizeof ( int ) , h[i] . bits , sizeof ( uint32_t ) , sizeof ( uint32_t ) , INIT_VLC_LE ) ; if ( res < 0 ) { av_log ( avctx , AV_LOG_ERROR , Cannot build VLC table\n ) ; return - 1 ; } } } if ( bits ) { //decode 16 - bit data for ( i = stereo ; i > = 0 ; i - - ) pred[i] = bswap_16 ( get_bits ( & gb , 16 ) ) ; for ( i = 0 ; i < stereo ; i + + ) * samples + + = pred[i] ; for ( i = 0 ; i < unp_size / 2 ; i + + ) { if ( i & stereo ) { if ( vlc[2] . table ) res = get_vlc2 ( & gb , vlc[2] . table , SMKTREE_BITS , 3 ) ; else res = 0 ; val = h[2] . values[res] ; if ( vlc[3] . table ) res = get_vlc2 ( & gb , vlc[3] . table , SMKTREE_BITS , 3 ) ; else res = 0 ; val |= h[3] . values[res] < < 8 ; pred[1] + = ( int16_t ) val ; * samples + + = pred[1] ; } else { if ( vlc[0] . table ) res = get_vlc2 ( & gb , vlc[0] . table , SMKTREE_BITS , 3 ) ; else res = 0 ; val = h[0] . values[res] ; if ( vlc[1] . table ) res = get_vlc2 ( & gb , vlc[1] . table , SMKTREE_BITS , 3 ) ; else res = 0 ; val |= h[1] . values[res] < < 8 ; pred[0] + = val ; * samples + + = pred[0] ; } } } else { //8 - bit data for ( i = stereo ; i > = 0 ; i - - ) pred[i] = get_bits ( & gb , 8 ) ; for ( i = 0 ; i < stereo ; i + + ) * samples + + = ( pred[i] - 0x80 ) < < 8 ; for ( i = 0 ; i < unp_size ; i + + ) { if ( i & stereo ) { if ( vlc[1] . table ) res = get_vlc2 ( & gb , vlc[1] . table , SMKTREE_BITS , 3 ) ; else res = 0 ; pred[1] + = ( int8_t ) h[1] . values[res] ; * samples + + = ( pred[1] - 0x80 ) < < 8 ; } else { if ( vlc[0] . table ) res = get_vlc2 ( & gb , vlc[0] . table , SMKTREE_BITS , 3 ) ; else res = 0 ; pred[0] + = ( int8_t ) h[0] . values[res] ; * samples + + = ( pred[0] - 0x80 ) < < 8 ; } } unp_size * = 2 ; } for ( i = 0 ; i < 4 ; i + + ) { if ( vlc[i] . table ) free_vlc ( & vlc[i] ) ; if ( h[i] . bits ) av_free ( h[i] . bits ) ; if ( h[i] . lengths ) av_free ( h[i] . lengths ) ; if ( h[i] . values ) av_free ( h[i] . values ) ; } * data_size = unp_size ; return buf_size ; }",1
"static void avc_wgt_4width_msa ( uint8_t * data , int32_t stride , int32_t height , int32_t log2_denom , int32_t src_weight , int32_t offset_in ) { if ( 2 == height ) { avc_wgt_4x2_msa ( data , stride , log2_denom , src_weight , offset_in ) ; } else { avc_wgt_4x4multiple_msa ( data , stride , height , log2_denom , src_weight , offset_in ) ; } }",0
"static void do_apply_filter ( APEContext * ctx , int version , APEFilter * f , int32_t * data , int count , int order , int fracbits ) { int res ; int absres ; while ( count - - ) { / * round fixedpoint scalar product * / res = ctx - > adsp . scalarproduct_and_madd_int16 ( f - > coeffs , f - > delay - order , f - > adaptcoeffs - order , order , APESIGN ( * data ) ) ; res = ( res + ( 1 < < ( fracbits - 1 ) ) ) > > fracbits ; res + = * data ; * data + + = res ; / * Update the output history * / * f - > delay + + = av_clip_int16 ( res ) ; if ( version < 3980 ) { / * Version ? ? ? to < 3 . 98 files ( untested ) * / f - > adaptcoeffs[0] = ( res == 0 ) ? 0 : ( ( res > > 28 ) & 8 ) - 4 ; f - > adaptcoeffs[ - 4] > > = 1 ; f - > adaptcoeffs[ - 8] > > = 1 ; } else { / * Version 3 . 98 and later files * / / * Update the adaption coefficients * / absres = FFABS ( res ) ; if ( absres ) * f - > adaptcoeffs = ( ( res & ( - 1 < < 31 ) ) ( - 1 < < 30 ) ) > > ( 25 + ( absres < = f - > avg * 3 ) + ( absres < = f - > avg * 4/3 ) ) ; else * f - > adaptcoeffs = 0 ; f - > avg + = ( absres - f - > avg ) / 16 ; f - > adaptcoeffs[ - 1] > > = 1 ; f - > adaptcoeffs[ - 2] > > = 1 ; f - > adaptcoeffs[ - 8] > > = 1 ; } f - > adaptcoeffs + + ; / * Have we filled the history buffer ? * / if ( f - > delay == f - > historybuffer + HISTORY_SIZE + ( order * 2 ) ) { memmove ( f - > historybuffer , f - > delay - ( order * 2 ) , ( order * 2 ) * sizeof ( * f - > historybuffer ) ) ; f - > delay = f - > historybuffer + order * 2 ; f - > adaptcoeffs = f - > historybuffer + order ; } } }",0
"static int ffm2_read_header ( AVFormatContext * s ) { FFMContext * ffm = s - > priv_data ; AVStream * st ; AVIOContext * pb = s - > pb ; AVCodecContext * codec ; const AVCodecDescriptor * codec_desc ; int ret , i ; int f_main = 0 , f_cprv = - 1 , f_stvi = - 1 , f_stau = - 1 ; AVCodec * enc ; char * buffer ; ffm - > packet_size = avio_rb32 ( pb ) ; if ( ffm - > packet_size ! = FFM_PACKET_SIZE ) { av_log ( s , AV_LOG_ERROR , Invalid packet size %d , expected size was %d\n , ffm - > packet_size , FFM_PACKET_SIZE ) ; ret = AVERROR_INVALIDDATA ; ffm - > write_index = avio_rb64 ( pb ) ; / * get also filesize * / if ( pb - > seekable ) { ffm - > file_size = avio_size ( pb ) ; if ( ffm - > write_index & & 0 ) adjust_write_index ( s ) ; } else { ffm - > file_size = ( UINT64_C ( 1 ) < < 63 ) - 1 ; while ( ! avio_feof ( pb ) ) { unsigned id = avio_rb32 ( pb ) ; unsigned size = avio_rb32 ( pb ) ; int64_t next = avio_tell ( pb ) + size ; char rc_eq_buf[128] ; if ( ! id ) break ; switch ( id ) { case MKBETAG ( ' M ' , ' A ' , ' I ' , ' N ' ) : if ( f_main + + ) { ret = AVERROR ( EINVAL ) ; avio_rb32 ( pb ) ; / * nb_streams * / avio_rb32 ( pb ) ; / * total bitrate * / break ; case MKBETAG ( ' C ' , ' O ' , ' M ' , ' M ' ) : f_cprv = f_stvi = f_stau = 0 ; st = avformat_new_stream ( s , NULL ) ; if ( ! st ) { ret = AVERROR ( ENOMEM ) ; avpriv_set_pts_info ( st , 64 , 1 , 1000000 ) ; codec = st - > codec ; / * generic info * / codec - > codec_id = avio_rb32 ( pb ) ; codec_desc = avcodec_descriptor_get ( codec - > codec_id ) ; if ( ! codec_desc ) { av_log ( s , AV_LOG_ERROR , Invalid codec id : %d\n , codec - > codec_id ) ; codec - > codec_id = AV_CODEC_ID_NONE ; codec - > codec_type = avio_r8 ( pb ) ; if ( codec - > codec_type ! = codec_desc - > type ) { av_log ( s , AV_LOG_ERROR , Codec type mismatch : expected %d , found %d\n , codec_desc - > type , codec - > codec_type ) ; codec - > codec_id = AV_CODEC_ID_NONE ; codec - > codec_type = AVMEDIA_TYPE_UNKNOWN ; codec - > bit_rate = avio_rb32 ( pb ) ; codec - > flags = avio_rb32 ( pb ) ; codec - > flags2 = avio_rb32 ( pb ) ; codec - > debug = avio_rb32 ( pb ) ; if ( codec - > flags & AV_CODEC_FLAG_GLOBAL_HEADER ) { int size = avio_rb32 ( pb ) ; codec - > extradata = av_mallocz ( size + AV_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! codec - > extradata ) return AVERROR ( ENOMEM ) ; codec - > extradata_size = size ; avio_read ( pb , codec - > extradata , size ) ; break ; case MKBETAG ( ' S ' , ' T ' , ' V ' , ' I ' ) : if ( f_stvi + + ) { ret = AVERROR ( EINVAL ) ; codec - > time_base . num = avio_rb32 ( pb ) ; codec - > time_base . den = avio_rb32 ( pb ) ; if ( codec - > time_base . num < = 0 || codec - > time_base . den < = 0 ) { av_log ( s , AV_LOG_ERROR , Invalid time base %d/%d\n , codec - > time_base . num , codec - > time_base . den ) ; ret = AVERROR_INVALIDDATA ; codec - > width = avio_rb16 ( pb ) ; codec - > height = avio_rb16 ( pb ) ; codec - > gop_size = avio_rb16 ( pb ) ; codec - > pix_fmt = avio_rb32 ( pb ) ; codec - > qmin = avio_r8 ( pb ) ; codec - > qmax = avio_r8 ( pb ) ; codec - > max_qdiff = avio_r8 ( pb ) ; codec - > qcompress = avio_rb16 ( pb ) / 10000 . 0 ; codec - > qblur = avio_rb16 ( pb ) / 10000 . 0 ; codec - > bit_rate_tolerance = avio_rb32 ( pb ) ; avio_get_str ( pb , INT_MAX , rc_eq_buf , sizeof ( rc_eq_buf ) ) ; codec - > rc_eq = av_strdup ( rc_eq_buf ) ; codec - > rc_max_rate = avio_rb32 ( pb ) ; codec - > rc_min_rate = avio_rb32 ( pb ) ; codec - > rc_buffer_size = avio_rb32 ( pb ) ; codec - > i_quant_factor = av_int2double ( avio_rb64 ( pb ) ) ; codec - > b_quant_factor = av_int2double ( avio_rb64 ( pb ) ) ; codec - > i_quant_offset = av_int2double ( avio_rb64 ( pb ) ) ; codec - > b_quant_offset = av_int2double ( avio_rb64 ( pb ) ) ; codec - > dct_algo = avio_rb32 ( pb ) ; codec - > strict_std_compliance = avio_rb32 ( pb ) ; codec - > max_b_frames = avio_rb32 ( pb ) ; codec - > mpeg_quant = avio_rb32 ( pb ) ; codec - > intra_dc_precision = avio_rb32 ( pb ) ; codec - > me_method = avio_rb32 ( pb ) ; codec - > mb_decision = avio_rb32 ( pb ) ; codec - > nsse_weight = avio_rb32 ( pb ) ; codec - > frame_skip_cmp = avio_rb32 ( pb ) ; codec - > rc_buffer_aggressivity = av_int2double ( avio_rb64 ( pb ) ) ; codec - > codec_tag = avio_rb32 ( pb ) ; codec - > thread_count = avio_r8 ( pb ) ; codec - > coder_type = avio_rb32 ( pb ) ; codec - > me_cmp = avio_rb32 ( pb ) ; codec - > me_subpel_quality = avio_rb32 ( pb ) ; codec - > me_range = avio_rb32 ( pb ) ; codec - > keyint_min = avio_rb32 ( pb ) ; codec - > scenechange_threshold = avio_rb32 ( pb ) ; codec - > b_frame_strategy = avio_rb32 ( pb ) ; codec - > qcompress = av_int2double ( avio_rb64 ( pb ) ) ; codec - > qblur = av_int2double ( avio_rb64 ( pb ) ) ; codec - > max_qdiff = avio_rb32 ( pb ) ; codec - > refs = avio_rb32 ( pb ) ; break ; case MKBETAG ( ' S ' , ' T ' , ' A ' , ' U ' ) : if ( f_stau + + ) { ret = AVERROR ( EINVAL ) ; codec - > sample_rate = avio_rb32",1
"static int h263p_decode_umotion ( MpegEncContext * s , int pred ) { int code = 0 , sign ; if ( get_bits1 ( & s - > gb ) ) / * Motion difference = 0 * / return pred ; code = 2 + get_bits1 ( & s - > gb ) ; while ( get_bits1 ( & s - > gb ) ) { code < < = 1 ; code + = get_bits1 ( & s - > gb ) ; if ( code > = 32768 ) { avpriv_request_sample ( s - > avctx , Huge DMV ) ; return AVERROR_INVALIDDATA ; } } sign = code & 1 ; code > > = 1 ; code = ( sign ) ? ( pred - code ) : ( pred + code ) ; ff_tlog ( s - > avctx , H . 263 + UMV Motion = %d\n , code ) ; return code ; }",1
static void stream_pause ( VideoState * is ) { is - > paused = ! is - > paused ; if ( ! is - > paused ) { if ( is - > read_pause_return ! = AVERROR ( ENOSYS ) ) { is - > video_current_pts = get_video_clock ( is ) ; } is - > frame_timer + = ( av_gettime ( ) - is - > video_current_pts_time ) / 1000000 . 0 ; is - > video_current_pts_time= av_gettime ( ) ; } },1
"int ff_MPV_encode_picture ( AVCodecContext * avctx , AVPacket * pkt , const AVFrame * pic_arg , int * got_packet ) { MpegEncContext * s = avctx - > priv_data ; int i , stuffing_count , ret ; int context_count = s - > slice_context_count ; s - > picture_in_gop_number + + ; if ( load_input_picture ( s , pic_arg ) < 0 ) return - 1 ; if ( select_input_picture ( s ) < 0 ) { return - 1 ; } / * output ? * / if ( s - > new_picture . f . data[0] ) { if ( ! pkt - > data & & ( ret = ff_alloc_packet ( pkt , s - > mb_width * s - > mb_height * MAX_MB_BYTES ) ) < 0 ) return ret ; if ( s - > mb_info ) { s - > mb_info_ptr = av_packet_new_side_data ( pkt , AV_PKT_DATA_H263_MB_INFO , s - > mb_width * s - > mb_height * 12 ) ; s - > prev_mb_info = s - > last_mb_info = s - > mb_info_size = 0 ; } for ( i = 0 ; i < context_count ; i + + ) { int start_y = s - > thread_context[i] - > start_mb_y ; int end_y = s - > thread_context[i] - > end_mb_y ; int h = s - > mb_height ; uint8_t * start = pkt - > data + ( size_t ) ( ( ( int64_t ) pkt - > size ) * start_y / h ) ; uint8_t * end = pkt - > data + ( size_t ) ( ( ( int64_t ) pkt - > size ) * end_y / h ) ; init_put_bits ( & s - > thread_context[i] - > pb , start , end - start ) ; } s - > pict_type = s - > new_picture . f . pict_type ; //emms_c ( ) ; //printf ( qs : %f %f %d\n , s - > new_picture . quality , // s - > current_picture . quality , s - > qscale ) ; ff_MPV_frame_start ( s , avctx ) ; vbv_retry : if ( encode_picture ( s , s - > picture_number ) < 0 ) return - 1 ; avctx - > header_bits = s - > header_bits ; avctx - > mv_bits = s - > mv_bits ; avctx - > misc_bits = s - > misc_bits ; avctx - > i_tex_bits = s - > i_tex_bits ; avctx - > p_tex_bits = s - > p_tex_bits ; avctx - > i_count = s - > i_count ; // FIXME f/b_count in avctx avctx - > p_count = s - > mb_num - s - > i_count - s - > skip_count ; avctx - > skip_count = s - > skip_count ; ff_MPV_frame_end ( s ) ; if ( CONFIG_MJPEG_ENCODER & & s - > out_format == FMT_MJPEG ) ff_mjpeg_encode_picture_trailer ( s ) ; if ( avctx - > rc_buffer_size ) { RateControlContext * rcc = & s - > rc_context ; int max_size = rcc - > buffer_index * avctx - > rc_max_available_vbv_use ; if ( put_bits_count ( & s - > pb ) > max_size & & s - > lambda < s - > avctx - > lmax ) { s - > next_lambda = FFMAX ( s - > lambda + 1 , s - > lambda * ( s - > qscale + 1 ) / s - > qscale ) ; if ( s - > adaptive_quant ) { int i ; for ( i = 0 ; i < s - > mb_height * s - > mb_stride ; i + + ) s - > lambda_table[i] = FFMAX ( s - > lambda_table[i] + 1 , s - > lambda_table[i] * ( s - > qscale + 1 ) / s - > qscale ) ; } s - > mb_skipped = 0 ; // done in MPV_frame_start ( ) // done in encode_picture ( ) so we must undo it if ( s - > pict_type == AV_PICTURE_TYPE_P ) { if ( s - > flipflop_rounding || s - > codec_id == AV_CODEC_ID_H263P || s - > codec_id == AV_CODEC_ID_MPEG4 ) s - > no_rounding = 1 ; } if ( s - > pict_type ! = AV_PICTURE_TYPE_B ) { s - > time_base = s - > last_time_base ; s - > last_non_b_time = s - > time - s - > pp_time ; } //av_log ( NULL , AV_LOG_ERROR , R : %d , s - > next_lambda ) ; for ( i = 0 ; i < context_count ; i + + ) { PutBitContext * pb = & s - > thread_context[i] - > pb ; init_put_bits ( pb , pb - > buf , pb - > buf_end - pb - > buf ) ; } goto vbv_retry ; } assert ( s - > avctx - > rc_max_rate ) ; } if ( s - > flags & CODEC_FLAG_PASS1 ) ff_write_pass1_stats ( s ) ; for ( i = 0 ; i < 4 ; i + + ) { s - > current_picture_ptr - > f . error[i] = s - > current_picture . f . error[i] ; avctx - > error[i] + = s - > current_picture_ptr - > f . error[i] ; } if ( s - > flags & CODEC_FLAG_PASS1 ) assert ( avctx - > header_bits + avctx - > mv_bits + avctx - > misc_bits + avctx - > i_tex_bits + avctx - > p_tex_bits == put_bits_count ( & s - > pb ) ) ; flush_put_bits ( & s - > pb ) ; s - > frame_bits = put_bits_count ( & s - > pb ) ; stuffing_count = ff_vbv_update ( s , s - > frame_bits ) ; if ( stuffing_count ) { if ( s - > pb . buf_end - s - > pb . buf - ( put_bits_count ( & s - > pb ) > > 3 ) < stuffing_count + 50 ) { av_log ( s - > avctx , AV_LOG_ERROR , stuffing too large\n ) ; return - 1 ; } switch ( s - > codec_id ) { case AV_CODEC_ID_MPEG1VIDEO : case AV_CODEC_ID_MPEG2VIDEO : while ( stuffing_count - - ) { put_bits ( & s - > pb , 8 , 0 ) ; } break ; case AV_CODEC_ID_MPEG4 : put_bits ( & s - > pb , 16 , 0 ) ; put_bits ( & s - > pb , 16 , 0x1C3 ) ; stuffing_count - = 4 ; while ( stuffing_count - - ) { put_bits ( & s - > pb , 8 , 0xFF ) ; } break ; default : av_log ( s - > avctx , AV_LOG_ERROR , vbv buffer overflow\n ) ; } flush_put_bits ( & s - > pb ) ; s - > frame_bits = put_bits_count ( & s - > pb ) ; } / * update mpeg1/2 vbv_delay for CBR * / if ( s - > avctx - > rc_max_rate & & s -",1
"static inline void RENAME ( rgb32tobgr15 ) ( const uint8_t * src , uint8_t * dst , unsigned src_size ) { const uint8_t * s = src ; const uint8_t * end ; ifdef HAVE_MMX const uint8_t * mm_end ; endif uint16_t * d = ( uint16_t * ) dst ; end = s + src_size ; ifdef HAVE_MMX __asm __volatile ( PREFETCH %0 : : m ( * src ) : memory ) ; __asm __volatile ( movq %0 , %%mm7\n\t movq %1 , %%mm6\n\t : : m ( red_15mask ) , m ( green_15mask ) ) ; mm_end = end - 15 ; while ( s < mm_end ) { __asm __volatile ( PREFETCH 32%1\n\t movd %1 , %%mm0\n\t movd 4%1 , %%mm3\n\t punpckldq 8%1 , %%mm0\n\t punpckldq 12%1 , %%mm3\n\t movq %%mm0 , %%mm1\n\t movq %%mm0 , %%mm2\n\t movq %%mm3 , %%mm4\n\t movq %%mm3 , %%mm5\n\t psllq 7 , %%mm0\n\t psllq 7 , %%mm3\n\t pand %%mm7 , %%mm0\n\t pand %%mm7 , %%mm3\n\t psrlq 6 , %%mm1\n\t psrlq 6 , %%mm4\n\t pand %%mm6 , %%mm1\n\t pand %%mm6 , %%mm4\n\t psrlq 19 , %%mm2\n\t psrlq 19 , %%mm5\n\t pand %2 , %%mm2\n\t pand %2 , %%mm5\n\t por %%mm1 , %%mm0\n\t por %%mm4 , %%mm3\n\t por %%mm2 , %%mm0\n\t por %%mm5 , %%mm3\n\t psllq 16 , %%mm3\n\t por %%mm3 , %%mm0\n\t MOVNTQ %%mm0 , %0\n\t : =m ( * d ) : m ( * s ) , m ( blue_15mask ) : memory ) ; d + = 4 ; s + = 16 ; } __asm __volatile ( SFENCE : : : memory ) ; __asm __volatile ( EMMS : : : memory ) ; endif while ( s < end ) { const int src= * ( ( uint32_t * ) s ) + + ; * d + + = ( ( src & 0xF8 ) < < 7 ) + ( ( src & 0xF800 ) > > 6 ) + ( ( src & 0xF80000 ) > > 19 ) ; } }",0
"static void FUNC ( hevc_loop_filter_chroma ) ( uint8_t * _pix , ptrdiff_t _xstride , ptrdiff_t _ystride , int * _tc , uint8_t * _no_p , uint8_t * _no_q ) { int d , j , no_p , no_q ; pixel * pix = ( pixel * ) _pix ; ptrdiff_t xstride = _xstride / sizeof ( pixel ) ; ptrdiff_t ystride = _ystride / sizeof ( pixel ) ; for ( j = 0 ; j < 2 ; j + + ) { const int tc = _tc[j] < < ( BIT_DEPTH - 8 ) ; if ( tc < = 0 ) { pix + = 4 * ystride ; continue ; } no_p = _no_p[j] ; no_q = _no_q[j] ; for ( d = 0 ; d < 4 ; d + + ) { int delta0 ; const int p1 = P1 ; const int p0 = P0 ; const int q0 = Q0 ; const int q1 = Q1 ; delta0 = av_clip ( ( ( ( q0 - p0 ) < < 2 ) + p1 - q1 + 4 ) > > 3 , - tc , tc ) ; if ( ! no_p ) P0 = av_clip_pixel ( p0 + delta0 ) ; if ( ! no_q ) Q0 = av_clip_pixel ( q0 - delta0 ) ; pix + = ystride ; } } }",0
"static inline void xchg_mb_border ( H264Context * h , uint8_t * src_y , uint8_t * src_cb , uint8_t * src_cr , int linesize , int uvlinesize , int xchg , int simple , int pixel_shift ) { MpegEncContext * const s = & h - > s ; int deblock_left ; int deblock_top ; int top_idx = 1 ; uint8_t * top_border_m1 ; uint8_t * top_border ; if ( ! simple & & FRAME_MBAFF ) { if ( s - > mb_y & 1 ) { if ( ! MB_MBAFF ) return ; } else { top_idx = MB_MBAFF ? 0 : 1 ; } } if ( h - > deblocking_filter == 2 ) { deblock_left = h - > left_type[0] ; deblock_top = h - > top_type ; } else { deblock_left = ( s - > mb_x > 0 ) ; deblock_top = ( s - > mb_y > ! ! MB_FIELD ) ; } src_y - = linesize + 1 + pixel_shift ; src_cb - = uvlinesize + 1 + pixel_shift ; src_cr - = uvlinesize + 1 + pixel_shift ; top_border_m1 = h - > top_borders[top_idx][s - > mb_x - 1] ; top_border = h - > top_borders[top_idx][s - > mb_x] ; define XCHG ( a , b , xchg ) \ if ( pixel_shift ) { \ if ( xchg ) { \ AV_SWAP64 ( b + 0 , a + 0 ) ; \ AV_SWAP64 ( b + 8 , a + 8 ) ; \ } else { \ AV_COPY128 ( b , a ) ; \ } \ } else \ if ( xchg ) AV_SWAP64 ( b , a ) ; \ else AV_COPY64 ( b , a ) ; if ( deblock_top ) { if ( deblock_left ) { XCHG ( top_border_m1 + ( 8 < < pixel_shift ) , src_y - ( 7 < < pixel_shift ) , 1 ) ; } XCHG ( top_border + ( 0 < < pixel_shift ) , src_y + ( 1 < < pixel_shift ) , xchg ) ; XCHG ( top_border + ( 8 < < pixel_shift ) , src_y + ( 9 < < pixel_shift ) , 1 ) ; if ( s - > mb_x + 1 < s - > mb_width ) { XCHG ( h - > top_borders[top_idx][s - > mb_x + 1] , src_y + ( 17 < < pixel_shift ) , 1 ) ; } } if ( simple || ! CONFIG_GRAY || ! ( s - > flags & CODEC_FLAG_GRAY ) ) { if ( deblock_top ) { if ( deblock_left ) { XCHG ( top_border_m1 + ( 16 < < pixel_shift ) , src_cb - ( 7 < < pixel_shift ) , 1 ) ; XCHG ( top_border_m1 + ( 24 < < pixel_shift ) , src_cr - ( 7 < < pixel_shift ) , 1 ) ; } XCHG ( top_border + ( 16 < < pixel_shift ) , src_cb + 1 + pixel_shift , 1 ) ; XCHG ( top_border + ( 24 < < pixel_shift ) , src_cr + 1 + pixel_shift , 1 ) ; } } }",0
"static int hevc_decode_frame ( AVCodecContext * avctx , void * data , int * got_output , AVPacket * avpkt ) { int ret ; HEVCContext * s = avctx - > priv_data ; if ( ! avpkt - > size ) { ret = ff_hevc_output_frame ( s , data , 1 ) ; if ( ret < 0 ) return ret ; * got_output = ret ; return 0 ; } s - > ref = NULL ; ret = decode_nal_units ( s , avpkt - > data , avpkt - > size ) ; if ( ret < 0 ) return ret ; / * verify the SEI checksum * / if ( avctx - > err_recognition & AV_EF_CRCCHECK & & s - > is_decoded & & avctx - > err_recognition & AV_EF_EXPLODE & & s - > is_md5 ) { ret = verify_md5 ( s , s - > ref - > frame ) ; if ( ret < 0 ) { ff_hevc_unref_frame ( s , s - > ref , 0 ) ; return ret ; } } s - > is_md5 = 0 ; if ( s - > is_decoded ) { av_log ( avctx , AV_LOG_DEBUG , Decoded frame with POC %d . \n , s - > poc ) ; s - > is_decoded = 0 ; } if ( s - > output_frame - > buf[0] ) { av_frame_move_ref ( data , s - > output_frame ) ; * got_output = 1 ; } return avpkt - > size ; }",0
"static int decode_subframe ( TAKDecContext * s , int32_t * decoded , int subframe_size , int prev_subframe_size ) { GetBitContext * gb = & s - > gb ; int x , y , i , j , ret = 0 ; int dshift , size , filter_quant , filter_order , filter_order16 ; int tfilter[MAX_PREDICTORS] ; if ( ! get_bits1 ( gb ) ) return decode_residues ( s , decoded , subframe_size ) ; filter_order = predictor_sizes[get_bits ( gb , 4 ) ] ; if ( prev_subframe_size > 0 & & get_bits1 ( gb ) ) { if ( filter_order > prev_subframe_size ) return AVERROR_INVALIDDATA ; decoded - = filter_order ; subframe_size + = filter_order ; if ( filter_order > subframe_size ) return AVERROR_INVALIDDATA ; } else { int lpc_mode ; if ( filter_order > subframe_size ) return AVERROR_INVALIDDATA ; lpc_mode = get_bits ( gb , 2 ) ; if ( lpc_mode > 2 ) return AVERROR_INVALIDDATA ; if ( ( ret = decode_residues ( s , decoded , filter_order ) ) < 0 ) return ret ; if ( lpc_mode ) decode_lpc ( decoded , lpc_mode , filter_order ) ; } dshift = get_bits_esc4 ( gb ) ; size = get_bits1 ( gb ) + 6 ; filter_quant = 10 ; if ( get_bits1 ( gb ) ) { filter_quant - = get_bits ( gb , 3 ) + 1 ; if ( filter_quant < 3 ) return AVERROR_INVALIDDATA ; } s - > predictors[0] = get_sbits ( gb , 10 ) ; s - > predictors[1] = get_sbits ( gb , 10 ) ; s - > predictors[2] = get_sbits ( gb , size ) < < ( 10 - size ) ; s - > predictors[3] = get_sbits ( gb , size ) < < ( 10 - size ) ; if ( filter_order > 4 ) { int tmp = size - get_bits1 ( gb ) ; for ( i = 4 ; i < filter_order ; i + + ) { if ( ! ( i & 3 ) ) x = tmp - get_bits ( gb , 2 ) ; s - > predictors[i] = get_sbits ( gb , x ) < < ( 10 - size ) ; } } tfilter[0] = s - > predictors[0] < < 6 ; for ( i = 1 ; i < filter_order ; i + + ) { int32_t * p1 = & tfilter[0] ; int32_t * p2 = & tfilter[i - 1] ; for ( j = 0 ; j < ( i + 1 ) / 2 ; j + + ) { x = * p1 + ( s - > predictors[i] * * p2 + 256 > > 9 ) ; * p2 + = s - > predictors[i] * * p1 + 256 > > 9 ; * p1 + + = x ; p2 - - ; } tfilter[i] = s - > predictors[i] < < 6 ; } filter_order16 = FFALIGN ( filter_order , 16 ) ; AV_ZERO128 ( s - > filter + filter_order16 - 16 ) ; AV_ZERO128 ( s - > filter + filter_order16 - 8 ) ; x = 1 < < ( 32 - ( 15 - filter_quant ) ) ; y = 1 < < ( ( 15 - filter_quant ) - 1 ) ; for ( i = 0 , j = filter_order - 1 ; i < filter_order / 2 ; i + + , j - - ) { s - > filter[j] = x - ( ( tfilter[i] + y ) > > ( 15 - filter_quant ) ) ; s - > filter[i] = x - ( ( tfilter[j] + y ) > > ( 15 - filter_quant ) ) ; } if ( ( ret = decode_residues ( s , & decoded[filter_order] , subframe_size - filter_order ) ) < 0 ) return ret ; for ( i = 0 ; i < filter_order ; i + + ) s - > residues[i] = * decoded + + > > dshift ; y = FF_ARRAY_ELEMS ( s - > residues ) - filter_order ; x = subframe_size - filter_order ; while ( x > 0 ) { int tmp = FFMIN ( y , x ) ; for ( i = 0 ; i < tmp ; i + + ) { int v = 1 < < ( filter_quant - 1 ) ; v + = s - > adsp . scalarproduct_int16 ( & s - > residues[i] , s - > filter , filter_order16 ) ; v = ( av_clip_intp2 ( v > > filter_quant , 13 ) < < dshift ) - * decoded ; * decoded + + = v ; s - > residues[filter_order + i] = v > > dshift ; } x - = tmp ; if ( x > 0 ) memcpy ( s - > residues , & s - > residues[y] , 2 * filter_order ) ; } emms_c ( ) ; return 0 ; }",1
"static int dca_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , const uint8_t * buf , int buf_size ) { int i , j , k ; int16_t * samples = data ; DCAContext * s = avctx - > priv_data ; int channels ; s - > dca_buffer_size = dca_convert_bitstream ( buf , buf_size , s - > dca_buffer , DCA_MAX_FRAME_SIZE ) ; if ( s - > dca_buffer_size == - 1 ) { av_log ( avctx , AV_LOG_ERROR , Not a valid DCA frame\n ) ; return - 1 ; } init_get_bits ( & s - > gb , s - > dca_buffer , s - > dca_buffer_size * 8 ) ; if ( dca_parse_frame_header ( s ) < 0 ) { //seems like the frame is corrupt , try with the next one * data_size=0 ; return buf_size ; } //set AVCodec values with parsed data avctx - > sample_rate = s - > sample_rate ; avctx - > bit_rate = s - > bit_rate ; channels = s - > prim_channels + ! ! s - > lfe ; if ( avctx - > request_channels == 2 & & s - > prim_channels > 2 ) { channels = 2 ; s - > output = DCA_STEREO ; } avctx - > channels = channels ; if ( * data_size < ( s - > sample_blocks / 8 ) * 256 * sizeof ( int16_t ) * channels ) return - 1 ; * data_size = 0 ; for ( i = 0 ; i < ( s - > sample_blocks / 8 ) ; i + + ) { dca_decode_block ( s ) ; s - > dsp . float_to_int16 ( s - > tsamples , s - > samples , 256 * channels ) ; / * interleave samples * / for ( j = 0 ; j < 256 ; j + + ) { for ( k = 0 ; k < channels ; k + + ) samples[k] = s - > tsamples[j + k * 256] ; samples + = channels ; } * data_size + = 256 * sizeof ( int16_t ) * channels ; } return buf_size ; }",1
"static int teletext_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * pkt ) { TeletextContext * ctx = avctx - > priv_data ; AVSubtitle * sub = data ; int ret = 0 ; if ( ! ctx - > vbi ) { if ( ! ( ctx - > vbi = vbi_decoder_new ( ) ) ) return AVERROR ( ENOMEM ) ; if ( ! vbi_event_handler_add ( ctx - > vbi , VBI_EVENT_TTX_PAGE , handler , ctx ) ) { vbi_decoder_delete ( ctx - > vbi ) ; ctx - > vbi = NULL ; return AVERROR ( ENOMEM ) ; } } if ( avctx - > pkt_timebase . den & & pkt - > pts ! = AV_NOPTS_VALUE ) ctx - > pts = av_rescale_q ( pkt - > pts , avctx - > pkt_timebase , AV_TIME_BASE_Q ) ; if ( pkt - > size ) { int lines ; const int full_pes_size = pkt - > size + 45 ; / * PES header is 45 bytes * / // We allow unreasonably big packets , even if the standard only allows a max size of 1472 if ( full_pes_size < 184 || full_pes_size > 65504 || full_pes_size % 184 ! = 0 ) return AVERROR_INVALIDDATA ; ctx - > handler_ret = pkt - > size ; if ( data_identifier_is_teletext ( * pkt - > data ) ) { if ( ( lines = slice_to_vbi_lines ( ctx , pkt - > data + 1 , pkt - > size - 1 ) ) < 0 ) return lines ; av_dlog ( avctx , ctx=%p buf_size=%d lines=%u pkt_pts=%7 . 3f\n , ctx , pkt - > size , lines , ( double ) pkt - > pts/90000 . 0 ) ; if ( lines > 0 ) { ifdef DEBUG int i ; av_log ( avctx , AV_LOG_DEBUG , line numbers : ) ; for ( i = 0 ; i < lines ; i + + ) av_log ( avctx , AV_LOG_DEBUG , %d , ctx - > sliced[i] . line ) ; av_log ( avctx , AV_LOG_DEBUG , \n ) ; endif vbi_decode ( ctx - > vbi , ctx - > sliced , lines , 0 . 0 ) ; ctx - > lines_processed + = lines ; } } ctx - > pts = AV_NOPTS_VALUE ; ret = ctx - > handler_ret ; } if ( ret < 0 ) return ret ; // is there a subtitle to pass ? if ( ctx - > nb_pages ) { int i ; sub - > format = ctx - > format_id ; sub - > start_display_time = 0 ; sub - > end_display_time = ctx - > sub_duration ; sub - > num_rects = 0 ; sub - > pts = ctx - > pages - > pts ; if ( ctx - > pages - > sub_rect - > type ! = SUBTITLE_NONE ) { sub - > rects = av_malloc ( sizeof ( * sub - > rects ) ) ; if ( sub - > rects ) { sub - > num_rects = 1 ; sub - > rects[0] = ctx - > pages - > sub_rect ; } else { ret = AVERROR ( ENOMEM ) ; } } else { av_log ( avctx , AV_LOG_DEBUG , sending empty sub\n ) ; sub - > rects = NULL ; } if ( ! sub - > rects ) // no rect was passed subtitle_rect_free ( & ctx - > pages - > sub_rect ) ; for ( i = 0 ; i < ctx - > nb_pages - 1 ; i + + ) ctx - > pages[i] = ctx - > pages[i + 1] ; ctx - > nb_pages - - ; if ( ret > = 0 ) * data_size = 1 ; } else * data_size = 0 ; return ret ; }",0
"static inline int hpel_motion_lowres ( MpegEncContext * s , uint8_t * dest , uint8_t * src , int field_based , int field_select , int src_x , int src_y , int width , int height , int stride , int h_edge_pos , int v_edge_pos , int w , int h , h264_chroma_mc_func * pix_op , int motion_x , int motion_y ) { const int lowres = s - > avctx - > lowres ; const int op_index = FFMIN ( lowres , 3 ) ; const int s_mask = ( 2 < < lowres ) - 1 ; int emu = 0 ; int sx , sy ; if ( s - > quarter_sample ) { motion_x /= 2 ; motion_y /= 2 ; } sx = motion_x & s_mask ; sy = motion_y & s_mask ; src_x + = motion_x > > lowres + 1 ; src_y + = motion_y > > lowres + 1 ; src + = src_y * stride + src_x ; if ( ( unsigned ) src_x > FFMAX ( h_edge_pos - ( ! ! sx ) - w , 0 ) || ( unsigned ) src_y > FFMAX ( ( v_edge_pos > > field_based ) - ( ! ! sy ) - h , 0 ) ) { s - > vdsp . emulated_edge_mc ( s - > edge_emu_buffer , src , s - > linesize , w + 1 , ( h + 1 ) < < field_based , src_x , src_y < < field_based , h_edge_pos , v_edge_pos ) ; src = s - > edge_emu_buffer ; emu = 1 ; } sx = ( sx < < 2 ) > > lowres ; sy = ( sy < < 2 ) > > lowres ; if ( field_select ) src + = s - > linesize ; pix_op[op_index] ( dest , src , stride , h , sx , sy ) ; return emu ; }",1
"av_cold void ff_mlz_init_dict ( void * context , MLZ * mlz ) { mlz - > dict = av_malloc_array ( TABLE_SIZE , sizeof ( * mlz - > dict ) ) ; mlz - > flush_code = FLUSH_CODE ; mlz - > current_dic_index_max = DIC_INDEX_INIT ; mlz - > dic_code_bit = CODE_BIT_INIT ; mlz - > bump_code = ( DIC_INDEX_INIT - 1 ) ; mlz - > next_code = FIRST_CODE ; mlz - > freeze_flag = 0 ; mlz - > context = context ; }",1
"static int decode_slice_chroma ( AVCodecContext * avctx , SliceContext * slice , uint16_t * dst , int dst_stride , const uint8_t * buf , unsigned buf_size , const int16_t * qmat , int log2_blocks_per_mb ) { ProresContext * ctx = avctx - > priv_data ; LOCAL_ALIGNED_16 ( int16_t , blocks , [8 * 4 * 64] ) ; int16_t * block ; GetBitContext gb ; int i , j , blocks_per_slice = slice - > mb_count < < log2_blocks_per_mb ; int ret ; for ( i = 0 ; i < blocks_per_slice ; i + + ) ctx - > bdsp . clear_block ( blocks + ( i < < 6 ) ) ; init_get_bits ( & gb , buf , buf_size < < 3 ) ; decode_dc_coeffs ( & gb , blocks , blocks_per_slice ) ; if ( ( ret = decode_ac_coeffs ( avctx , & gb , blocks , blocks_per_slice ) ) < 0 ) return ret ; block = blocks ; for ( i = 0 ; i < slice - > mb_count ; i + + ) { for ( j = 0 ; j < log2_blocks_per_mb ; j + + ) { ctx - > prodsp . idct_put ( dst , dst_stride , block + ( 0 < < 6 ) , qmat ) ; ctx - > prodsp . idct_put ( dst + 4 * dst_stride , dst_stride , block + ( 1 < < 6 ) , qmat ) ; block + = 2 * 64 ; dst + = 8 ; } } return 0 ; }",1
"static int roq_dpcm_encode_frame ( AVCodecContext * avctx , AVPacket * avpkt , const AVFrame * frame , int * got_packet_ptr ) { int i , stereo , data_size , ret ; const int16_t * in = frame ? ( const int16_t * ) frame - > data[0] : NULL ; uint8_t * out ; ROQDPCMContext * context = avctx - > priv_data ; stereo = ( avctx - > channels == 2 ) ; if ( ! in & & context - > input_frames > = 8 ) return 0 ; if ( in & & context - > input_frames < 8 ) { memcpy ( & context - > frame_buffer[context - > buffered_samples * avctx - > channels] , in , avctx - > frame_size * avctx - > channels * sizeof ( * in ) ) ; context - > buffered_samples + = avctx - > frame_size ; if ( context - > input_frames == 0 ) context - > first_pts = frame - > pts ; if ( context - > input_frames < 7 ) { context - > input_frames + + ; return 0 ; in = context - > frame_buffer ; if ( stereo ) { context - > lastSample[0] & = 0xFF00 ; context - > lastSample[1] & = 0xFF00 ; if ( context - > input_frames == 7 || ! in ) data_size = avctx - > channels * context - > buffered_samples ; else data_size = avctx - > channels * avctx - > frame_size ; if ( ( ret = ff_alloc_packet2 ( avctx , avpkt , ROQ_HEADER_SIZE + data_size ) ) ) return ret ; out = avpkt - > data ; bytestream_put_byte ( & out , stereo ? 0x21 : 0x20 ) ; bytestream_put_byte ( & out , 0x10 ) ; bytestream_put_le32 ( & out , data_size ) ; if ( stereo ) { bytestream_put_byte ( & out , ( context - > lastSample[1] ) > > 8 ) ; bytestream_put_byte ( & out , ( context - > lastSample[0] ) > > 8 ) ; } else bytestream_put_le16 ( & out , context - > lastSample[0] ) ; / * Write the actual samples * / for ( i = 0 ; i < data_size ; i + + ) * out + + = dpcm_predict ( & context - > lastSample[i & 1] , * in + + ) ; avpkt - > pts = context - > input_frames < = 7 ? context - > first_pts : frame - > pts ; avpkt - > duration = data_size / avctx - > channels ; context - > input_frames + + ; if ( ! in ) context - > input_frames = FFMAX ( context - > input_frames , 8 ) ; * got_packet_ptr = 1 ; return 0 ;",1
"static int mxf_write_footer ( AVFormatContext * s ) { MXFContext * mxf = s - > priv_data ; AVIOContext * pb = s - > pb ; mxf - > duration = mxf - > last_indexed_edit_unit + mxf - > edit_units_count ; mxf_write_klv_fill ( s ) ; mxf - > footer_partition_offset = avio_tell ( pb ) ; if ( mxf - > edit_unit_byte_count ) { // no need to repeat index mxf_write_partition ( s , 0 , 0 , footer_partition_key , 0 ) ; } else { mxf_write_partition ( s , 0 , 2 , footer_partition_key , 0 ) ; mxf_write_klv_fill ( s ) ; mxf_write_index_table_segment ( s ) ; } mxf_write_klv_fill ( s ) ; mxf_write_random_index_pack ( s ) ; if ( s - > pb - > seekable ) { avio_seek ( pb , 0 , SEEK_SET ) ; if ( mxf - > edit_unit_byte_count ) { mxf_write_partition ( s , 1 , 2 , header_closed_partition_key , 1 ) ; mxf_write_klv_fill ( s ) ; mxf_write_index_table_segment ( s ) ; } else { mxf_write_partition ( s , 0 , 0 , header_closed_partition_key , 1 ) ; } } ff_audio_interleave_close ( s ) ; av_freep ( & mxf - > index_entries ) ; av_freep ( & mxf - > body_partition_offset ) ; av_freep ( & mxf - > timecode_track - > priv_data ) ; av_freep ( & mxf - > timecode_track ) ; mxf_free ( s ) ; return 0 ; }",0
"static int decode_frame ( AVCodecContext * avctx , void * data , int * data_size , uint8_t * buf , int buf_size ) { H264Context * h = avctx - > priv_data ; MpegEncContext * s = & h - > s ; AVFrame * pict = data ; int buf_index ; s - > flags= avctx - > flags ; s - > flags2= avctx - > flags2 ; / * no supplementary picture * / if ( buf_size == 0 ) { return 0 ; } if ( s - > flags & CODEC_FLAG_TRUNCATED ) { int next= find_frame_end ( h , buf , buf_size ) ; if ( ff_combine_frame ( & s - > parse_context , next , & buf , & buf_size ) < 0 ) return buf_size ; //printf ( next : %d buf_size : %d last_index : %d\n , next , buf_size , s - > parse_context . last_index ) ; } if ( h - > is_avc & & ! h - > got_avcC ) { int i , cnt , nalsize ; unsigned char * p = avctx - > extradata ; if ( avctx - > extradata_size < 7 ) { av_log ( avctx , AV_LOG_ERROR , avcC too short\n ) ; return - 1 ; } if ( * p ! = 1 ) { av_log ( avctx , AV_LOG_ERROR , Unknown avcC version %d\n , * p ) ; return - 1 ; } / * sps and pps in the avcC always have length coded with 2 bytes , so put a fake nal_length_size = 2 while parsing them * / h - > nal_length_size = 2 ; // Decode sps from avcC cnt = * ( p + 5 ) & 0x1f ; // Number of sps p + = 6 ; for ( i = 0 ; i < cnt ; i + + ) { nalsize = BE_16 ( p ) + 2 ; if ( decode_nal_units ( h , p , nalsize ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , Decoding sps %d from avcC failed\n , i ) ; return - 1 ; } p + = nalsize ; } // Decode pps from avcC cnt = * ( p + + ) ; // Number of pps for ( i = 0 ; i < cnt ; i + + ) { nalsize = BE_16 ( p ) + 2 ; if ( decode_nal_units ( h , p , nalsize ) ! = nalsize ) { av_log ( avctx , AV_LOG_ERROR , Decoding pps %d from avcC failed\n , i ) ; return - 1 ; } p + = nalsize ; } // Now store right nal length size , that will be use to parse all other nals h - > nal_length_size = ( ( * ( ( ( char * ) ( avctx - > extradata ) ) + 4 ) ) & 0x03 ) + 1 ; // Do not reparse avcC h - > got_avcC = 1 ; } if ( ! h - > is_avc & & s - > avctx - > extradata_size & & s - > picture_number==0 ) { if ( decode_nal_units ( h , s - > avctx - > extradata , s - > avctx - > extradata_size ) < 0 ) return - 1 ; } buf_index=decode_nal_units ( h , buf , buf_size ) ; if ( buf_index < 0 ) return - 1 ; //FIXME do something with unavailable reference frames // if ( ret==FRAME_SKIPPED ) return get_consumed_bytes ( s , buf_index , buf_size ) ; if ( ! s - > current_picture_ptr ) { av_log ( h - > s . avctx , AV_LOG_DEBUG , error , NO frame\n ) ; return - 1 ; } { Picture * out = s - > current_picture_ptr ; if 0 //decode order * data_size = sizeof ( AVFrame ) ; else / * Sort B - frames into display order * / Picture * cur = s - > current_picture_ptr ; Picture * prev = h - > delayed_output_pic ; int out_idx = 0 ; int pics = 0 ; int out_of_order ; int cross_idr = 0 ; int dropped_frame = 0 ; int i ; if ( h - > sps . bitstream_restriction_flag & & s - > avctx - > has_b_frames < h - > sps . num_reorder_frames ) { s - > avctx - > has_b_frames = h - > sps . num_reorder_frames ; s - > low_delay = 0 ; } while ( h - > delayed_pic[pics] ) pics + + ; h - > delayed_pic[pics + + ] = cur ; if ( cur - > reference == 0 ) cur - > reference = 1 ; for ( i=0 ; h - > delayed_pic[i] ; i + + ) if ( h - > delayed_pic[i] - > key_frame || h - > delayed_pic[i] - > poc==0 ) cross_idr = 1 ; out = h - > delayed_pic[0] ; for ( i=1 ; h - > delayed_pic[i] & & ! h - > delayed_pic[i] - > key_frame ; i + + ) if ( h - > delayed_pic[i] - > poc < out - > poc ) { out = h - > delayed_pic[i] ; out_idx = i ; } out_of_order = ! cross_idr & & prev & & out - > poc < prev - > poc ; if ( prev & & pics < = s - > avctx - > has_b_frames ) out = prev ; else if ( ( out_of_order & & pics - 1 == s - > avctx - > has_b_frames ) || ( s - > low_delay & & ( ( ! cross_idr & & prev & & out - > poc > prev - > poc + 2 ) || cur - > pict_type == B_TYPE ) ) ) { s - > low_delay = 0 ; s - > avctx - > has_b_frames + + ; out = prev ; } else if ( out_of_order ) out = prev ; if ( out_of_order || pics > s - > avctx - > has_b_frames ) { dropped_frame = ( out ! = h - > delayed_pic[out_idx] ) ; for ( i=out_idx ; h - > delayed_pic[i] ; i + + ) h - > delayed_pic[i] = h - > delayed_pic[i + 1] ; } if ( prev == out & & ! dropped_frame ) * data_size = 0 ; else * data_size = sizeof ( AVFrame ) ; if ( prev & & prev ! = out & & prev - > reference == 1 ) prev - > reference = 0 ; h - > delayed_output_pic = out ; endif * pict= * ( AVFrame * ) out ; } assert ( pict - > data[0] ) ; ff_print_debug_info ( s , pict ) ; //printf ( out %d\n , ( int ) pict - > data[0] ) ; if 0 // ? / * Return the Picture timestamp as the frame number * / / * we substract 1 because it is",1
"static int mkv_write_packet ( AVFormatContext * s , AVPacket * pkt ) { MatroskaMuxContext * mkv = s - > priv_data ; int codec_type = s - > streams[pkt - > stream_index] - > codec - > codec_type ; int keyframe = ! ! ( pkt - > flags & AV_PKT_FLAG_KEY ) ; int cluster_size ; int cluster_size_limit ; int64_t cluster_time ; int64_t cluster_time_limit ; AVIOContext * pb ; int ret ; if ( mkv - > tracks[pkt - > stream_index] . write_dts ) cluster_time = pkt - > dts - mkv - > cluster_pts ; else cluster_time = pkt - > pts - mkv - > cluster_pts ; // start a new cluster every 5 MB or 5 sec , or 32k / 1 sec for streaming or // after 4k and on a keyframe if ( s - > pb - > seekable ) { pb = s - > pb ; cluster_size = avio_tell ( pb ) - mkv - > cluster_pos ; cluster_time_limit = 5000 ; cluster_size_limit = 5 * 1024 * 1024 ; } else { pb = mkv - > dyn_bc ; cluster_size = avio_tell ( pb ) ; cluster_time_limit = 1000 ; cluster_size_limit = 32 * 1024 ; } if ( mkv - > cluster_pos & & ( cluster_size > cluster_size_limit || cluster_time > cluster_time_limit || ( codec_type == AVMEDIA_TYPE_VIDEO & & keyframe & & cluster_size > 4 * 1024 ) ) ) { av_log ( s , AV_LOG_DEBUG , Starting new cluster at offset % PRIu64 bytes , pts % PRIu64 dts % PRIu64 \n , avio_tell ( pb ) , pkt - > pts , pkt - > dts ) ; end_ebml_master ( pb , mkv - > cluster ) ; mkv - > cluster_pos = 0 ; if ( mkv - > dyn_bc ) mkv_flush_dynbuf ( s ) ; } // check if we have an audio packet cached if ( mkv - > cur_audio_pkt . size > 0 ) { ret = mkv_write_packet_internal ( s , & mkv - > cur_audio_pkt ) ; av_free_packet ( & mkv - > cur_audio_pkt ) ; if ( ret < 0 ) { av_log ( s , AV_LOG_ERROR , Could not write cached audio packet ret : %d\n , ret ) ; return ret ; } } // buffer an audio packet to ensure the packet containing the video // keyframe ' s timecode is contained in the same cluster for WebM if ( codec_type == AVMEDIA_TYPE_AUDIO ) { mkv - > cur_audio_pkt = * pkt ; if ( pkt - > buf ) { mkv - > cur_audio_pkt . buf = av_buffer_ref ( pkt - > buf ) ; ret = mkv - > cur_audio_pkt . buf ? 0 : AVERROR ( ENOMEM ) ; } else ret = av_dup_packet ( & mkv - > cur_audio_pkt ) ; } else ret = mkv_write_packet_internal ( s , pkt ) ; return ret ; }",0
"static int64_t getutime ( void ) { ifdef HAVE_GETRUSAGE struct rusage rusage ; getrusage ( RUSAGE_SELF , & rusage ) ; return ( rusage . ru_utime . tv_sec * 1000000LL ) + rusage . ru_utime . tv_usec ; elif defined ( __MINGW32__ ) return av_gettime ( ) ; endif }",0
"static void colored_fputs ( int level , const char * str ) { if ( ! * str ) return ; if ( use_color < 0 ) { if HAVE_SETCONSOLETEXTATTRIBUTE CONSOLE_SCREEN_BUFFER_INFO con_info ; con = GetStdHandle ( STD_ERROR_HANDLE ) ; use_color = ( con ! = INVALID_HANDLE_VALUE ) & & ! getenv ( NO_COLOR ) & & ! getenv ( AV_LOG_FORCE_NOCOLOR ) ; if ( use_color ) { GetConsoleScreenBufferInfo ( con , & con_info ) ; attr_orig = con_info . wAttributes ; background = attr_orig & 0xF0 ; } elif HAVE_ISATTY use_color = ! getenv ( NO_COLOR ) & & ! getenv ( AV_LOG_FORCE_NOCOLOR ) & & ( getenv ( TERM ) & & isatty ( 2 ) || getenv ( AV_LOG_FORCE_COLOR ) ) ; if ( getenv ( AV_LOG_FORCE_256COLOR ) ) use_color * = 256 ; else use_color = getenv ( AV_LOG_FORCE_COLOR ) & & ! getenv ( NO_COLOR ) & & ! getenv ( AV_LOG_FORCE_NOCOLOR ) ; endif } if HAVE_SETCONSOLETEXTATTRIBUTE if ( use_color & & level ! = AV_LOG_INFO/8 ) SetConsoleTextAttribute ( con , background | color[level] ) ; fputs ( str , stderr ) ; if ( use_color & & level ! = AV_LOG_INFO/8 ) SetConsoleTextAttribute ( con , attr_orig ) ; else if ( use_color == 1 & & level ! = AV_LOG_INFO/8 ) { fprintf ( stderr , \033[%d ; 3%dm%s\033[0m , ( color[level] > > 4 ) & 15 , color[level] & 15 , str ) ; } else if ( use_color == 256 & & level ! = AV_LOG_INFO/8 ) { fprintf ( stderr , \033[48 ; 5 ; %dm\033[38 ; 5 ; %dm%s\033[0m , ( color[level] > > 16 ) & 0xff , ( color[level] > > 8 ) & 0xff , str ) ; } else fputs ( str , stderr ) ; endif }",0
"AVFilterBufferRef * avfilter_default_get_audio_buffer ( AVFilterLink * link , int perms , enum AVSampleFormat sample_fmt , int size , int64_t channel_layout , int planar ) { AVFilterBuffer * samples = av_mallocz ( sizeof ( AVFilterBuffer ) ) ; AVFilterBufferRef * ref = NULL ; int i , sample_size , chans_nb , bufsize , per_channel_size , step_size = 0 ; char * buf ; if ( ! samples || ! ( ref = av_mallocz ( sizeof ( AVFilterBufferRef ) ) ) ) goto fail ; ref - > buf = samples ; ref - > format = sample_fmt ; ref - > audio = av_mallocz ( sizeof ( AVFilterBufferRefAudioProps ) ) ; if ( ! ref - > audio ) goto fail ; ref - > audio - > channel_layout = channel_layout ; ref - > audio - > size = size ; ref - > audio - > planar = planar ; / * make sure the buffer gets read permission or it ' s useless for output * / ref - > perms = perms | AV_PERM_READ ; samples - > refcount = 1 ; samples - > free = ff_avfilter_default_free_buffer ; sample_size = av_get_bytes_per_sample ( sample_fmt ) ; chans_nb = av_get_channel_layout_nb_channels ( channel_layout ) ; per_channel_size = size/chans_nb ; ref - > audio - > nb_samples = per_channel_size/sample_size ; / * Set the number of bytes to traverse to reach next sample of a particular channel : * For planar , this is simply the sample size . * For packed , this is the number of samples * sample_size . * / for ( i = 0 ; i < chans_nb ; i + + ) samples - > linesize[i] = planar > 0 ? per_channel_size : sample_size ; memset ( & samples - > linesize[chans_nb] , 0 , ( 8 - chans_nb ) * sizeof ( samples - > linesize[0] ) ) ; / * Calculate total buffer size , round to multiple of 16 to be SIMD friendly * / bufsize = ( size + 15 ) & 15 ; buf = av_malloc ( bufsize ) ; if ( ! buf ) goto fail ; / * For planar , set the start point of each channel ' s data within the buffer * For packed , set the start point of the entire buffer only * / samples - > data[0] = buf ; if ( buf & & planar ) { for ( i = 1 ; i < chans_nb ; i + + ) { step_size + = per_channel_size ; samples - > data[i] = buf + step_size ; } } else { for ( i = 1 ; i < chans_nb ; i + + ) samples - > data[i] = buf ; } memset ( & samples - > data[chans_nb] , 0 , ( 8 - chans_nb ) * sizeof ( samples - > data[0] ) ) ; memcpy ( ref - > data , samples - > data , sizeof ( ref - > data ) ) ; memcpy ( ref - > linesize , samples - > linesize , sizeof ( ref - > linesize ) ) ; return ref ; fail : if ( ref ) av_free ( ref - > audio ) ; av_free ( ref ) ; av_free ( samples ) ; return NULL ; }",0
"static int encode_packet ( Jpeg2000EncoderContext * s , Jpeg2000ResLevel * rlevel , int precno , uint8_t * expn , int numgbits ) { int bandno , empty = 1 ; // init bitstream * s - > buf = 0 ; s - > bit_index = 0 ; // header // is the packet empty ? for ( bandno = 0 ; bandno < rlevel - > nbands ; bandno + + ) { if ( rlevel - > band[bandno] . coord[0][0] < rlevel - > band[bandno] . coord[0][1] & & rlevel - > band[bandno] . coord[1][0] < rlevel - > band[bandno] . coord[1][1] ) { empty = 0 ; break ; } } put_bits ( s , ! empty , 1 ) ; if ( empty ) { j2k_flush ( s ) ; return 0 ; } for ( bandno = 0 ; bandno < rlevel - > nbands ; bandno + + ) { Jpeg2000Band * band = rlevel - > band + bandno ; Jpeg2000Prec * prec = band - > prec + precno ; int yi , xi , pos ; int cblknw = prec - > nb_codeblocks_width ; if ( band - > coord[0][0] == band - > coord[0][1] || band - > coord[1][0] == band - > coord[1][1] ) continue ; for ( pos=0 , yi = 0 ; yi < prec - > nb_codeblocks_height ; yi + + ) { for ( xi = 0 ; xi < cblknw ; xi + + , pos + + ) { prec - > cblkincl[pos] . val = prec - > cblk[yi * cblknw + xi] . ninclpasses == 0 ; tag_tree_update ( prec - > cblkincl + pos ) ; prec - > zerobits[pos] . val = expn[bandno] + numgbits - 1 - prec - > cblk[yi * cblknw + xi] . nonzerobits ; tag_tree_update ( prec - > zerobits + pos ) ; } } for ( pos=0 , yi = 0 ; yi < prec - > nb_codeblocks_height ; yi + + ) { for ( xi = 0 ; xi < cblknw ; xi + + , pos + + ) { int pad = 0 , llen , length ; Jpeg2000Cblk * cblk = prec - > cblk + yi * cblknw + xi ; if ( s - > buf_end - s - > buf < 20 ) // approximately return - 1 ; // inclusion information tag_tree_code ( s , prec - > cblkincl + pos , 1 ) ; if ( ! cblk - > ninclpasses ) continue ; // zerobits information tag_tree_code ( s , prec - > zerobits + pos , 100 ) ; // number of passes putnumpasses ( s , cblk - > ninclpasses ) ; length = cblk - > passes[cblk - > ninclpasses - 1] . rate ; llen = av_log2 ( length ) - av_log2 ( cblk - > ninclpasses ) - 2 ; if ( llen < 0 ) { pad = - llen ; llen = 0 ; } // length of code block put_bits ( s , 1 , llen ) ; put_bits ( s , 0 , 1 ) ; put_num ( s , length , av_log2 ( length ) + 1 + pad ) ; } } } j2k_flush ( s ) ; for ( bandno = 0 ; bandno < rlevel - > nbands ; bandno + + ) { Jpeg2000Band * band = rlevel - > band + bandno ; Jpeg2000Prec * prec = band - > prec + precno ; int yi , cblknw = prec - > nb_codeblocks_width ; for ( yi =0 ; yi < prec - > nb_codeblocks_height ; yi + + ) { int xi ; for ( xi = 0 ; xi < cblknw ; xi + + ) { Jpeg2000Cblk * cblk = prec - > cblk + yi * cblknw + xi ; if ( cblk - > ninclpasses ) { if ( s - > buf_end - s - > buf < cblk - > passes[cblk - > ninclpasses - 1] . rate ) return - 1 ; bytestream_put_buffer ( & s - > buf , cblk - > data , cblk - > passes[cblk - > ninclpasses - 1] . rate - cblk - > passes[cblk - > ninclpasses - 1] . flushed_len ) ; bytestream_put_buffer ( & s - > buf , cblk - > passes[cblk - > ninclpasses - 1] . flushed , cblk - > passes[cblk - > ninclpasses - 1] . flushed_len ) ; } } } } return 0 ; }",1
"static int ivi_init_tiles ( IVIBandDesc * band , IVITile * ref_tile , int p , int b , int t_height , int t_width ) { int x , y ; IVITile * tile = band - > tiles ; for ( y = 0 ; y < band - > height ; y + = t_height ) { for ( x = 0 ; x < band - > width ; x + = t_width ) { tile - > xpos = x ; tile - > ypos = y ; tile - > mb_size = band - > mb_size ; tile - > width = FFMIN ( band - > width - x , t_width ) ; tile - > height = FFMIN ( band - > height - y , t_height ) ; tile - > is_empty = tile - > data_size = 0 ; / * calculate number of macroblocks * / tile - > num_MBs = IVI_MBs_PER_TILE ( tile - > width , tile - > height , band - > mb_size ) ; av_freep ( & tile - > mbs ) ; tile - > mbs = av_malloc ( tile - > num_MBs * sizeof ( IVIMbInfo ) ) ; if ( ! tile - > mbs ) return AVERROR ( ENOMEM ) ; tile - > ref_mbs = 0 ; if ( p || b ) { if ( tile - > num_MBs ! = ref_tile - > num_MBs ) { av_log ( NULL , AV_LOG_DEBUG , ref_tile mismatch\n ) ; return AVERROR_INVALIDDATA ; } tile - > ref_mbs = ref_tile - > mbs ; ref_tile + + ; } tile + + ; } } return 0 ; }",1
"static av_cold int common_end ( AVCodecContext * avctx ) { FFV1Context * s = avctx - > priv_data ; int i , j ; for ( j=0 ; j < s - > slice_count ; j + + ) { FFV1Context * fs= s - > slice_context[j] ; for ( i=0 ; i < s - > plane_count ; i + + ) { PlaneContext * p= & fs - > plane[i] ; av_freep ( & p - > state ) ; av_freep ( & p - > vlc_state ) ; av_freep ( & fs - > sample_buffer ) ; av_freep ( & avctx - > stats_out ) ; for ( j=0 ; j < s - > quant_table_count ; j + + ) { av_freep ( & s - > initial_states[j] ) ; FFV1Context * sf= s - > slice_context[i] ; av_freep ( & sf - > rc_stat2[j] ) ; av_freep ( & s - > rc_stat2[j] ) ; return 0 ;",1
"unsigned ff_dxva2_get_surface_index ( const AVCodecContext * avctx , const AVDXVAContext * ctx , const AVFrame * frame ) { void * surface = ff_dxva2_get_surface ( frame ) ; unsigned i ; for ( i = 0 ; i < DXVA_CONTEXT_COUNT ( avctx , ctx ) ; i + + ) if ( DXVA_CONTEXT_SURFACE ( avctx , ctx , i ) == surface ) return i ; assert ( 0 ) ; return 0 ; }",1
"static int find_optimal_param ( uint32_t sum , int n ) { int k , k_opt ; uint32_t nbits[MAX_RICE_PARAM + 1] ; k_opt = 0 ; nbits[0] = UINT32_MAX ; for ( k=0 ; k < =MAX_RICE_PARAM ; k + + ) { nbits[k] = rice_encode_count ( sum , n , k ) ; if ( nbits[k] < nbits[k_opt] ) { k_opt = k ; } } return k_opt ; }",0
"static void ts_str ( char buffer[60] , int64_t ts , AVRational base ) { if ( ts == AV_NOPTS_VALUE ) { strcpy ( buffer , NOPTS ) ; return ; } ts= av_rescale_q ( ts , base , ( AVRational ) { 1 , 1000000 } ) ; snprintf ( buffer , 60 , %c%Ld . %06Ld , ts < 0 ? ' - ' : ' ' , FFABS ( ts ) /1000000 , FFABS ( ts ) %1000000 ) ; }",0
"static void rpza_decode_stream ( RpzaContext * s ) { int width = s - > avctx - > width ; int stride = s - > frame . linesize[0] / 2 ; int row_inc = stride - 4 ; int stream_ptr = 0 ; int chunk_size ; unsigned char opcode ; int n_blocks ; unsigned short colorA = 0 , colorB ; unsigned short color4[4] ; unsigned char index , idx ; unsigned short ta , tb ; unsigned short * pixels = ( unsigned short * ) s - > frame . data[0] ; int row_ptr = 0 ; int pixel_ptr = 0 ; int block_ptr ; int pixel_x , pixel_y ; int total_blocks ; / * First byte is always 0xe1 . Warn if it ' s different * / if ( s - > buf[stream_ptr] ! = 0xe1 ) av_log ( s - > avctx , AV_LOG_ERROR , First chunk byte is 0x%02x instead of 0xe1\n , s - > buf[stream_ptr] ) ; / * Get chunk size , ingnoring first byte * / chunk_size = AV_RB32 ( & s - > buf[stream_ptr] ) & 0x00FFFFFF ; stream_ptr + = 4 ; / * If length mismatch use size from MOV file and try to decode anyway * / if ( chunk_size ! = s - > size ) av_log ( s - > avctx , AV_LOG_ERROR , MOV chunk size ! = encoded chunk size ; using MOV chunk size\n ) ; chunk_size = s - > size ; / * Number of 4x4 blocks in frame . * / total_blocks = ( ( s - > avctx - > width + 3 ) / 4 ) * ( ( s - > avctx - > height + 3 ) / 4 ) ; / * Process chunk data * / while ( stream_ptr < chunk_size ) { opcode = s - > buf[stream_ptr + + ] ; / * Get opcode * / n_blocks = ( opcode & 0x1f ) + 1 ; / * Extract block counter from opcode * / / * If opcode MSbit is 0 , we need more data to decide what to do * / if ( ( opcode & 0x80 ) == 0 ) { colorA = ( opcode < < 8 ) | ( s - > buf[stream_ptr + + ] ) ; opcode = 0 ; if ( ( s - > buf[stream_ptr] & 0x80 ) ! = 0 ) { / * Must behave as opcode 110xxxxx , using colorA computed * above . Use fake opcode 0x20 to enter switch block at * the right place * / opcode = 0x20 ; n_blocks = 1 ; } } switch ( opcode & 0xe0 ) { / * Skip blocks * / case 0x80 : while ( n_blocks - - ) { ADVANCE_BLOCK ( ) ; } break ; / * Fill blocks with one color * / case 0xa0 : colorA = AV_RB16 ( & s - > buf[stream_ptr] ) ; stream_ptr + = 2 ; while ( n_blocks - - ) { block_ptr = row_ptr + pixel_ptr ; for ( pixel_y = 0 ; pixel_y < 4 ; pixel_y + + ) { for ( pixel_x = 0 ; pixel_x < 4 ; pixel_x + + ) { pixels[block_ptr] = colorA ; block_ptr + + ; } block_ptr + = row_inc ; } ADVANCE_BLOCK ( ) ; } break ; / * Fill blocks with 4 colors * / case 0xc0 : colorA = AV_RB16 ( & s - > buf[stream_ptr] ) ; stream_ptr + = 2 ; case 0x20 : colorB = AV_RB16 ( & s - > buf[stream_ptr] ) ; stream_ptr + = 2 ; / * sort out the colors * / color4[0] = colorB ; color4[1] = 0 ; color4[2] = 0 ; color4[3] = colorA ; / * red components * / ta = ( colorA > > 10 ) & 0x1F ; tb = ( colorB > > 10 ) & 0x1F ; color4[1] |= ( ( 11 * ta + 21 * tb ) > > 5 ) < < 10 ; color4[2] |= ( ( 21 * ta + 11 * tb ) > > 5 ) < < 10 ; / * green components * / ta = ( colorA > > 5 ) & 0x1F ; tb = ( colorB > > 5 ) & 0x1F ; color4[1] |= ( ( 11 * ta + 21 * tb ) > > 5 ) < < 5 ; color4[2] |= ( ( 21 * ta + 11 * tb ) > > 5 ) < < 5 ; / * blue components * / ta = colorA & 0x1F ; tb = colorB & 0x1F ; color4[1] |= ( ( 11 * ta + 21 * tb ) > > 5 ) ; color4[2] |= ( ( 21 * ta + 11 * tb ) > > 5 ) ; if ( s - > size - stream_ptr < n_blocks * 4 ) return ; while ( n_blocks - - ) { block_ptr = row_ptr + pixel_ptr ; for ( pixel_y = 0 ; pixel_y < 4 ; pixel_y + + ) { index = s - > buf[stream_ptr + + ] ; for ( pixel_x = 0 ; pixel_x < 4 ; pixel_x + + ) { idx = ( index > > ( 2 * ( 3 - pixel_x ) ) ) & 0x03 ; pixels[block_ptr] = color4[idx] ; block_ptr + + ; } block_ptr + = row_inc ; } ADVANCE_BLOCK ( ) ; } break ; / * Fill block with 16 colors * / case 0x00 : if ( s - > size - stream_ptr < 16 ) return ; block_ptr = row_ptr + pixel_ptr ; for ( pixel_y = 0 ; pixel_y < 4 ; pixel_y + + ) { for ( pixel_x = 0 ; pixel_x < 4 ; pixel_x + + ) { / * We already have color of upper left pixel * / if ( ( pixel_y ! = 0 ) || ( pixel_x ! =0 ) ) { colorA = AV_RB16 ( & s - > buf[stream_ptr] ) ; stream_ptr + = 2 ; } pixels[block_ptr] = colorA ; block_ptr + + ; } block_ptr + = row_inc ; } ADVANCE_BLOCK ( ) ; break ; / * Unknown opcode * / default : av_log ( s - > avctx , AV_LOG_ERROR , Unknown opcode %d in rpza chunk . Skip remaining %d bytes of chunk data . \n , opcode , chunk_size - stream_ptr ) ; return ; } / * Opcode switch * / } }",0
"static int ast_read_header ( AVFormatContext * s ) { int codec ; AVStream * st ; st = avformat_new_stream ( s , NULL ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; avio_skip ( s - > pb , 8 ) ; codec = avio_rb16 ( s - > pb ) ; switch ( codec ) { case 1 : st - > codec - > codec_id = AV_CODEC_ID_PCM_S16BE_PLANAR ; break ; default : av_log ( s , AV_LOG_ERROR , unsupported codec %d\n , codec ) ; } avio_skip ( s - > pb , 2 ) ; st - > codec - > codec_type = AVMEDIA_TYPE_AUDIO ; st - > codec - > channels = avio_rb16 ( s - > pb ) ; if ( ! st - > codec - > channels ) return AVERROR_INVALIDDATA ; if ( st - > codec - > channels == 2 ) st - > codec - > channel_layout = AV_CH_LAYOUT_STEREO ; else if ( st - > codec - > channels == 4 ) st - > codec - > channel_layout = AV_CH_LAYOUT_4POINT0 ; avio_skip ( s - > pb , 2 ) ; st - > codec - > sample_rate = avio_rb32 ( s - > pb ) ; if ( st - > codec - > sample_rate < = 0 ) return AVERROR_INVALIDDATA ; st - > start_time = 0 ; st - > duration = avio_rb32 ( s - > pb ) ; avio_skip ( s - > pb , 40 ) ; avpriv_set_pts_info ( st , 64 , 1 , st - > codec - > sample_rate ) ; return 0 ; }",0
"static av_cold int vsink_init ( AVFilterContext * ctx , void * opaque ) { BufferSinkContext * buf = ctx - > priv ; AVBufferSinkParams * params = opaque ; if ( params & & params - > pixel_fmts ) { const int * pixel_fmts = params - > pixel_fmts ; buf - > pixel_fmts = ff_copy_int_list ( pixel_fmts ) ; if ( ! buf - > pixel_fmts ) return AVERROR ( ENOMEM ) ; } return common_init ( ctx ) ; }",0
"static int aac_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame_ptr , AVPacket * avpkt ) { AACContext * ac = avctx - > priv_data ; const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; GetBitContext gb ; int buf_consumed ; int buf_offset ; int err ; int new_extradata_size ; const uint8_t * new_extradata = av_packet_get_side_data ( avpkt , AV_PKT_DATA_NEW_EXTRADATA , & new_extradata_size ) ; int jp_dualmono_size ; const uint8_t * jp_dualmono = av_packet_get_side_data ( avpkt , AV_PKT_DATA_JP_DUALMONO , & jp_dualmono_size ) ; if ( new_extradata & & 0 ) { av_free ( avctx - > extradata ) ; avctx - > extradata = av_mallocz ( new_extradata_size + AV_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! avctx - > extradata ) return AVERROR ( ENOMEM ) ; avctx - > extradata_size = new_extradata_size ; memcpy ( avctx - > extradata , new_extradata , new_extradata_size ) ; push_output_configuration ( ac ) ; if ( decode_audio_specific_config ( ac , ac - > avctx , & ac - > oc[1] . m4ac , avctx - > extradata , avctx - > extradata_size * 8 , 1 ) < 0 ) { pop_output_configuration ( ac ) ; return AVERROR_INVALIDDATA ; } } ac - > dmono_mode = 0 ; if ( jp_dualmono & & jp_dualmono_size > 0 ) ac - > dmono_mode = 1 + * jp_dualmono ; if ( ac - > force_dmono_mode > = 0 ) ac - > dmono_mode = ac - > force_dmono_mode ; if ( INT_MAX / 8 < = buf_size ) return AVERROR_INVALIDDATA ; if ( ( err = init_get_bits8 ( & gb , buf , buf_size ) ) < 0 ) return err ; switch ( ac - > oc[1] . m4ac . object_type ) { case AOT_ER_AAC_LC : case AOT_ER_AAC_LTP : case AOT_ER_AAC_LD : case AOT_ER_AAC_ELD : err = aac_decode_er_frame ( avctx , data , got_frame_ptr , & gb ) ; break ; default : err = aac_decode_frame_int ( avctx , data , got_frame_ptr , & gb , avpkt ) ; } if ( err < 0 ) return err ; buf_consumed = ( get_bits_count ( & gb ) + 7 ) > > 3 ; for ( buf_offset = buf_consumed ; buf_offset < buf_size ; buf_offset + + ) if ( buf[buf_offset] ) break ; return buf_size > buf_offset ? buf_consumed : buf_size ; }",1
"int ff_dirac_golomb_read_32bit ( DiracGolombLUT * lut_ctx , const uint8_t * buf , int bytes , uint8_t * _dst , int coeffs ) { int i , b , c_idx = 0 ; int32_t * dst = ( int32_t * ) _dst ; DiracGolombLUT * future[4] , * l = & lut_ctx[2 * LUT_SIZE + buf[0]] ; INIT_RESIDUE ( res ) ; for ( b = 1 ; b < = bytes ; b + + ) { future[0] = & lut_ctx[buf[b]] ; future[1] = future[0] + 1 * LUT_SIZE ; future[2] = future[0] + 2 * LUT_SIZE ; future[3] = future[0] + 3 * LUT_SIZE ; if ( ( c_idx + 1 ) > coeffs ) return c_idx ; / * res_bits is a hint for better branch prediction * / if ( res_bits & & l - > sign ) { int32_t coeff = 1 ; APPEND_RESIDUE ( res , l - > preamble ) ; for ( i = 0 ; i < ( res_bits > > 1 ) - 1 ; i + + ) { coeff < < = 1 ; coeff |= ( res > > ( RSIZE_BITS - 2 * i - 2 ) ) & 1 ; } dst[c_idx + + ] = l - > sign * ( coeff - 1 ) ; } memcpy ( & dst[c_idx] , l - > ready , LUT_BITS * sizeof ( int32_t ) ) ; c_idx + = l - > ready_num ; APPEND_RESIDUE ( res , l - > leftover ) ; l = future[l - > need_s ? 3 : ! res_bits ? 2 : res_bits & 1] ; } return c_idx ; }",1
"static void lz_unpack ( const unsigned char * src , int src_len , unsigned char * dest , int dest_len ) { const unsigned char * s ; const unsigned char * s_end ; unsigned char * d ; unsigned char * d_end ; unsigned char queue[QUEUE_SIZE] ; unsigned int qpos ; unsigned int dataleft ; unsigned int chainofs ; unsigned int chainlen ; unsigned int speclen ; unsigned char tag ; unsigned int i , j ; s = src ; s_end = src + src_len ; d = dest ; d_end = d + dest_len ; if ( s_end - s < 8 ) return ; dataleft = AV_RL32 ( s ) ; s + = 4 ; memset ( queue , 0x20 , QUEUE_SIZE ) ; if ( AV_RL32 ( s ) == 0x56781234 ) { s + = 4 ; qpos = 0x111 ; speclen = 0xF + 3 ; } else { qpos = 0xFEE ; speclen = 100 ; / * no speclen * / } while ( s_end - s > 0 & & dataleft > 0 ) { tag = * s + + ; if ( ( tag == 0xFF ) & & ( dataleft > 8 ) ) { if ( d + 8 > d_end || s_end - s < 8 ) return ; for ( i = 0 ; i < 8 ; i + + ) { queue[qpos + + ] = * d + + = * s + + ; qpos & = QUEUE_MASK ; } dataleft - = 8 ; } else { for ( i = 0 ; i < 8 ; i + + ) { if ( dataleft == 0 ) break ; if ( tag & 0x01 ) { if ( d + 1 > d_end || s_end - s < 1 ) return ; queue[qpos + + ] = * d + + = * s + + ; qpos & = QUEUE_MASK ; dataleft - - ; } else { if ( s_end - s < 2 ) return ; chainofs = * s + + ; chainofs |= ( ( * s & 0xF0 ) < < 4 ) ; chainlen = ( * s + + & 0x0F ) + 3 ; if ( chainlen == speclen ) { if ( s_end - s < 1 ) return ; chainlen = * s + + + 0xF + 3 ; } if ( d + chainlen > d_end ) return ; for ( j = 0 ; j < chainlen ; j + + ) { * d = queue[chainofs + + & QUEUE_MASK] ; queue[qpos + + ] = * d + + ; qpos & = QUEUE_MASK ; } dataleft - = chainlen ; } tag > > = 1 ; } } } }",1
"static void clone_tables ( H264Context * dst , H264Context * src ) { dst - > intra4x4_pred_mode = src - > intra4x4_pred_mode ; dst - > non_zero_count = src - > non_zero_count ; dst - > slice_table = src - > slice_table ; dst - > cbp_table = src - > cbp_table ; dst - > mb2b_xy = src - > mb2b_xy ; dst - > mb2b8_xy = src - > mb2b8_xy ; dst - > chroma_pred_mode_table = src - > chroma_pred_mode_table ; dst - > mvd_table[0] = src - > mvd_table[0] ; dst - > mvd_table[1] = src - > mvd_table[1] ; dst - > direct_table = src - > direct_table ; if ( ! dst - > dequant4_coeff[0] ) init_dequant_tables ( dst ) ; dst - > s . obmc_scratchpad = NULL ; ff_h264_pred_init ( & dst - > hpc , src - > s . codec_id ) ; dst - > dequant_coeff_pps= - 1 ; }",1
"static int ipvideo_decode_block_opcode_0x9 ( IpvideoContext * s ) { int x , y ; unsigned char P[4] ; / * 4 - color encoding * / CHECK_STREAM_PTR ( 4 ) ; memcpy ( P , s - > stream_ptr , 4 ) ; s - > stream_ptr + = 4 ; if ( P[0] < = P[1] ) { if ( P[2] < = P[3] ) { / * 1 of 4 colors for each pixel , need 16 more bytes * / CHECK_STREAM_PTR ( 16 ) ; for ( y = 0 ; y < 8 ; y + + ) { / * get the next set of 8 2 - bit flags * / int flags = bytestream_get_le16 ( & s - > stream_ptr ) ; for ( x = 0 ; x < 8 ; x + + , flags > > = 2 ) * s - > pixel_ptr + + = P[flags & 0x03] ; s - > pixel_ptr + = s - > line_inc ; } } else { uint32_t flags ; / * 1 of 4 colors for each 2x2 block , need 4 more bytes * / CHECK_STREAM_PTR ( 4 ) ; flags = bytestream_get_le32 ( & s - > stream_ptr ) ; for ( y = 0 ; y < 8 ; y + = 2 ) { for ( x = 0 ; x < 8 ; x + = 2 , flags > > = 2 ) { s - > pixel_ptr[x ] = s - > pixel_ptr[x + 1 ] = s - > pixel_ptr[x + s - > stride] = s - > pixel_ptr[x + 1 + s - > stride] = P[flags & 0x03] ; } s - > pixel_ptr + = s - > stride * 2 ; } } } else { uint64_t flags ; / * 1 of 4 colors for each 2x1 or 1x2 block , need 8 more bytes * / CHECK_STREAM_PTR ( 8 ) ; flags = bytestream_get_le64 ( & s - > stream_ptr ) ; if ( P[2] < = P[3] ) { for ( y = 0 ; y < 8 ; y + + ) { for ( x = 0 ; x < 8 ; x + = 2 , flags > > = 2 ) { s - > pixel_ptr[x ] = s - > pixel_ptr[x + 1] = P[flags & 0x03] ; } s - > pixel_ptr + = s - > stride ; } } else { for ( y = 0 ; y < 8 ; y + = 2 ) { for ( x = 0 ; x < 8 ; x + + , flags > > = 2 ) { s - > pixel_ptr[x ] = s - > pixel_ptr[x + s - > stride] = P[flags & 0x03] ; } s - > pixel_ptr + = s - > stride * 2 ; } } } / * report success * / return 0 ; }",0
"int ff_mjpeg_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; MJpegDecodeContext * s = avctx - > priv_data ; const uint8_t * buf_end , * buf_ptr ; const uint8_t * unescaped_buf_ptr ; int unescaped_buf_size ; int start_code ; AVFrame * picture = data ; s - > got_picture = 0 ; // picture from previous image can not be reused buf_ptr = buf ; buf_end = buf + buf_size ; while ( buf_ptr < buf_end ) { / * find start next marker * / start_code = ff_mjpeg_find_marker ( s , & buf_ptr , buf_end , & unescaped_buf_ptr , & unescaped_buf_size ) ; { / * EOF * / if ( start_code < 0 ) { goto the_end ; } else { av_log ( avctx , AV_LOG_DEBUG , marker=%x avail_size_in_buf=%td\n , start_code , buf_end - buf_ptr ) ; init_get_bits ( & s - > gb , unescaped_buf_ptr , unescaped_buf_size * 8 ) ; s - > start_code = start_code ; if ( s - > avctx - > debug & FF_DEBUG_STARTCODE ) { av_log ( avctx , AV_LOG_DEBUG , startcode : %X\n , start_code ) ; } / * process markers * / if ( start_code > = 0xd0 & & start_code < = 0xd7 ) { av_log ( avctx , AV_LOG_DEBUG , restart marker : %d\n , start_code & 0x0f ) ; / * APP fields * / } else if ( start_code > = APP0 & & start_code < = APP15 ) { mjpeg_decode_app ( s ) ; / * Comment * / } else if ( start_code == COM ) { mjpeg_decode_com ( s ) ; } switch ( start_code ) { case SOI : s - > restart_interval = 0 ; s - > restart_count = 0 ; / * nothing to do on SOI * / break ; case DQT : ff_mjpeg_decode_dqt ( s ) ; break ; case DHT : if ( ff_mjpeg_decode_dht ( s ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , huffman table decode error\n ) ; return - 1 ; } break ; case SOF0 : case SOF1 : s - > lossless=0 ; s - > ls=0 ; s - > progressive=0 ; if ( ff_mjpeg_decode_sof ( s ) < 0 ) return - 1 ; break ; case SOF2 : s - > lossless=0 ; s - > ls=0 ; s - > progressive=1 ; if ( ff_mjpeg_decode_sof ( s ) < 0 ) return - 1 ; break ; case SOF3 : s - > lossless=1 ; s - > ls=0 ; s - > progressive=0 ; if ( ff_mjpeg_decode_sof ( s ) < 0 ) return - 1 ; break ; case SOF48 : s - > lossless=1 ; s - > ls=1 ; s - > progressive=0 ; if ( ff_mjpeg_decode_sof ( s ) < 0 ) return - 1 ; break ; case LSE : if ( ! CONFIG_JPEGLS_DECODER || ff_jpegls_decode_lse ( s ) < 0 ) return - 1 ; break ; case EOI : if ( ( s - > buggy_avid & & ! s - > interlaced ) || s - > restart_interval ) break ; eoi_parser : s - > cur_scan = 0 ; if ( ! s - > got_picture ) { av_log ( avctx , AV_LOG_WARNING , Found EOI before any SOF , ignoring\n ) ; break ; } if ( s - > interlaced ) { s - > bottom_field = 1 ; / * if not bottom field , do not output image yet * / if ( s - > bottom_field == ! s - > interlace_polarity ) break ; } * picture = * s - > picture_ptr ; * data_size = sizeof ( AVFrame ) ; if ( ! s - > lossless ) { picture - > quality= FFMAX3 ( s - > qscale[0] , s - > qscale[1] , s - > qscale[2] ) ; picture - > qstride= 0 ; picture - > qscale_table= s - > qscale_table ; memset ( picture - > qscale_table , picture - > quality , ( s - > width + 15 ) /16 ) ; if ( avctx - > debug & FF_DEBUG_QP ) av_log ( avctx , AV_LOG_DEBUG , QP : %d\n , picture - > quality ) ; picture - > quality * = FF_QP2LAMBDA ; } goto the_end ; case SOS : if ( ! s - > got_picture ) { av_log ( avctx , AV_LOG_WARNING , Can not process SOS before SOF , skipping\n ) ; break ; } if ( ff_mjpeg_decode_sos ( s , NULL , NULL ) < 0 & & avctx - > error_recognition > = FF_ER_EXPLODE ) return AVERROR_INVALIDDATA ; / * buggy avid puts EOI every 10 - 20th frame * / / * if restart period is over process EOI * / if ( ( s - > buggy_avid & & ! s - > interlaced ) || s - > restart_interval ) goto eoi_parser ; break ; case DRI : mjpeg_decode_dri ( s ) ; break ; case SOF5 : case SOF6 : case SOF7 : case SOF9 : case SOF10 : case SOF11 : case SOF13 : case SOF14 : case SOF15 : case JPG : av_log ( avctx , AV_LOG_ERROR , mjpeg : unsupported coding type ( %x ) \n , start_code ) ; break ; // default : // printf ( mjpeg : unsupported marker ( %x ) \n , start_code ) ; // break ; } / * eof process start code * / buf_ptr + = ( get_bits_count ( & s - > gb ) + 7 ) /8 ; av_log ( avctx , AV_LOG_DEBUG , marker parser used %d bytes ( %d bits ) \n , ( get_bits_count ( & s - > gb ) + 7 ) /8 , get_bits_count ( & s - > gb ) ) ; } } } if ( s - > got_picture ) { av_log ( avctx , AV_LOG_WARNING , EOI missing , emulating\n ) ; goto eoi_parser ; } av_log ( avctx , AV_LOG_FATAL , No JPEG data found in image\n ) ; return - 1 ; the_end : av_log ( avctx , AV_LOG_DEBUG , mjpeg decode frame unused %td bytes\n , buf_end - buf_ptr ) ; // return buf_end - buf_ptr ; return buf_ptr - buf ; }",0
"static int mjpeg_decode_scan ( MJpegDecodeContext * s , int nb_components , int Ah , int Al , const uint8_t * mb_bitmask , const AVFrame * reference ) { int i , mb_x , mb_y ; uint8_t * data[MAX_COMPONENTS] ; const uint8_t * reference_data[MAX_COMPONENTS] ; int linesize[MAX_COMPONENTS] ; GetBitContext mb_bitmask_gb ; if ( mb_bitmask ) { init_get_bits ( & mb_bitmask_gb , mb_bitmask , s - > mb_width * s - > mb_height ) ; if ( s - > flipped & & s - > avctx - > flags & CODEC_FLAG_EMU_EDGE ) { av_log ( s - > avctx , AV_LOG_ERROR , Can not flip image with CODEC_FLAG_EMU_EDGE set ! \n ) ; s - > flipped = 0 ; for ( i=0 ; i < nb_components ; i + + ) { int c = s - > comp_index[i] ; data[c] = s - > picture_ptr - > data[c] ; reference_data[c] = reference ? reference - > data[c] : NULL ; linesize[c]=s - > linesize[c] ; s - > coefs_finished[c] |= 1 ; if ( s - > flipped ) { //picture should be flipped upside - down for this codec int offset = ( linesize[c] * ( s - > v_scount[i] * ( 8 * s - > mb_height - ( ( s - > height/s - > v_max ) & 7 ) ) - 1 ) ) ; data[c] + = offset ; reference_data[c] + = offset ; linesize[c] * = - 1 ; for ( mb_y = 0 ; mb_y < s - > mb_height ; mb_y + + ) { for ( mb_x = 0 ; mb_x < s - > mb_width ; mb_x + + ) { const int copy_mb = mb_bitmask & & ! get_bits1 ( & mb_bitmask_gb ) ; if ( s - > restart_interval & & ! s - > restart_count ) s - > restart_count = s - > restart_interval ; for ( i=0 ; i < nb_components ; i + + ) { uint8_t * ptr ; int n , h , v , x , y , c , j ; int block_offset ; n = s - > nb_blocks[i] ; c = s - > comp_index[i] ; h = s - > h_scount[i] ; v = s - > v_scount[i] ; x = 0 ; y = 0 ; for ( j=0 ; j < n ; j + + ) { block_offset = ( ( ( linesize[c] * ( v * mb_y + y ) * 8 ) + ( h * mb_x + x ) * 8 ) > > s - > avctx - > lowres ) ; if ( s - > interlaced & & s - > bottom_field ) block_offset + = linesize[c] > > 1 ; ptr = data[c] + block_offset ; if ( ! s - > progressive ) { if ( copy_mb ) { mjpeg_copy_block ( ptr , reference_data[c] + block_offset , linesize[c] , s - > avctx - > lowres ) ; } else { s - > dsp . clear_block ( s - > block ) ; if ( decode_block ( s , s - > block , i , s - > dc_index[i] , s - > ac_index[i] , s - > quant_matrixes[ s - > quant_index[c] ] ) < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , error y=%d x=%d\n , mb_y , mb_x ) ; s - > dsp . idct_put ( ptr , linesize[c] , s - > block ) ; } else { int block_idx = s - > block_stride[c] * ( v * mb_y + y ) + ( h * mb_x + x ) ; DCTELEM * block = s - > blocks[c][block_idx] ; if ( Ah ) block[0] + = get_bits1 ( & s - > gb ) * s - > quant_matrixes[ s - > quant_index[c] ][0] < < Al ; else if ( decode_dc_progressive ( s , block , i , s - > dc_index[i] , s - > quant_matrixes[ s - > quant_index[c] ] , Al ) < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , error y=%d x=%d\n , mb_y , mb_x ) ; // av_log ( s - > avctx , AV_LOG_DEBUG , mb : %d %d processed\n , mb_y , mb_x ) ; //av_log ( NULL , AV_LOG_DEBUG , %d %d %d %d %d %d %d %d \n , mb_x , mb_y , x , y , c , s - > bottom_field , ( v * mb_y + y ) * 8 , ( h * mb_x + x ) * 8 ) ; if ( + + x == h ) { x = 0 ; y + + ; if ( s - > restart_interval & & ! - - s - > restart_count ) { align_get_bits ( & s - > gb ) ; skip_bits ( & s - > gb , 16 ) ; / * skip RSTn * / for ( i=0 ; i < nb_components ; i + + ) / * reset dc * / s - > last_dc[i] = 1024 ; return 0 ;",1
"static int nvenc_find_free_reg_resource ( AVCodecContext * avctx ) { NvencContext * ctx = avctx - > priv_data ; NvencDynLoadFunctions * dl_fn = & ctx - > nvenc_dload_funcs ; NV_ENCODE_API_FUNCTION_LIST * p_nvenc = & dl_fn - > nvenc_funcs ; int i ; if ( ctx - > nb_registered_frames == FF_ARRAY_ELEMS ( ctx - > registered_frames ) ) { for ( i = 0 ; i < ctx - > nb_registered_frames ; i + + ) { if ( ! ctx - > registered_frames[i] . mapped ) { if ( ctx - > registered_frames[i] . regptr ) { p_nvenc - > nvEncUnregisterResource ( ctx - > nvencoder , ctx - > registered_frames[i] . regptr ) ; ctx - > registered_frames[i] . regptr = NULL ; } return i ; } } } else { return ctx - > nb_registered_frames + + ; } av_log ( avctx , AV_LOG_ERROR , Too many registered CUDA frames\n ) ; return AVERROR ( ENOMEM ) ; }",0
"static int flv_data_packet ( AVFormatContext * s , AVPacket * pkt , int64_t dts , int64_t next ) { AVIOContext * pb = s - > pb ; AVStream * st = NULL ; char buf[20] ; int ret = AVERROR_INVALIDDATA ; int i , length = - 1 ; switch ( avio_r8 ( pb ) ) { case AMF_DATA_TYPE_MIXEDARRAY : avio_seek ( pb , 4 , SEEK_CUR ) ; case AMF_DATA_TYPE_OBJECT : break ; default : goto skip ; } while ( ( ret = amf_get_string ( pb , buf , sizeof ( buf ) ) ) > 0 ) { AMFDataType type = avio_r8 ( pb ) ; if ( type == AMF_DATA_TYPE_STRING & & ! strcmp ( buf , text ) ) { length = avio_rb16 ( pb ) ; ret = av_get_packet ( pb , pkt , length ) ; if ( ret < 0 ) goto skip ; else break ; } else { if ( ( ret = amf_skip_tag ( pb , type ) ) < 0 ) goto skip ; } } if ( length < 0 ) { ret = AVERROR_INVALIDDATA ; goto skip ; } for ( i = 0 ; i < s - > nb_streams ; i + + ) { st = s - > streams[i] ; if ( st - > codec - > codec_type == AVMEDIA_TYPE_DATA ) break ; } if ( i == s - > nb_streams ) { st = create_stream ( s , AVMEDIA_TYPE_DATA ) ; if ( ! st ) return AVERROR_INVALIDDATA ; st - > codec - > codec_id = AV_CODEC_ID_TEXT ; } pkt - > dts = dts ; pkt - > pts = dts ; pkt - > size = ret ; pkt - > stream_index = st - > index ; pkt - > flags |= AV_PKT_FLAG_KEY ; skip : avio_seek ( s - > pb , next + 4 , SEEK_SET ) ; return ret ; }",0
"void ff_h264_write_back_intra_pred_mode ( H264Context * h ) { int8_t * mode= h - > intra4x4_pred_mode + h - > mb2br_xy[h - > mb_xy] ; AV_COPY32 ( mode , h - > intra4x4_pred_mode_cache + 4 + 8 * 4 ) ; mode[4]= h - > intra4x4_pred_mode_cache[7 + 8 * 3] ; mode[5]= h - > intra4x4_pred_mode_cache[7 + 8 * 2] ; mode[6]= h - > intra4x4_pred_mode_cache[7 + 8 * 1] ; }",0
"static int noise ( AVBitStreamFilterContext * bsfc , AVCodecContext * avctx , const char * args , uint8_t * * poutbuf , int * poutbuf_size , const uint8_t * buf , int buf_size , int keyframe ) { unsigned int * state= bsfc - > priv_data ; int amount= args ? atoi ( args ) : ( * state % 10001 + 1 ) ; int i ; * poutbuf= av_malloc ( buf_size + FF_INPUT_BUFFER_PADDING_SIZE ) ; memcpy ( * poutbuf , buf , buf_size + FF_INPUT_BUFFER_PADDING_SIZE ) ; for ( i=0 ; i < buf_size ; i + + ) { ( * state ) + = ( * poutbuf ) [i] + 1 ; if ( * state % amount == 0 ) ( * poutbuf ) [i] = * state ; } return 1 ; }",1
"static int mjpeg_decode_scan ( MJpegDecodeContext * s , int nb_components , int Ah , int Al , const uint8_t * mb_bitmask , const AVFrame * reference ) { int i , mb_x , mb_y ; uint8_t * data[MAX_COMPONENTS] ; const uint8_t * reference_data[MAX_COMPONENTS] ; int linesize[MAX_COMPONENTS] ; GetBitContext mb_bitmask_gb ; if ( mb_bitmask ) { init_get_bits ( & mb_bitmask_gb , mb_bitmask , s - > mb_width * s - > mb_height ) ; } if ( s - > flipped & & s - > avctx - > flags & CODEC_FLAG_EMU_EDGE ) { av_log ( s - > avctx , AV_LOG_ERROR , Can not flip image with CODEC_FLAG_EMU_EDGE set ! \n ) ; s - > flipped = 0 ; } for ( i=0 ; i < nb_components ; i + + ) { int c = s - > comp_index[i] ; data[c] = s - > picture_ptr - > data[c] ; reference_data[c] = reference ? reference - > data[c] : NULL ; linesize[c]=s - > linesize[c] ; s - > coefs_finished[c] |= 1 ; if ( s - > flipped ) { //picture should be flipped upside - down for this codec int offset = ( linesize[c] * ( s - > v_scount[i] * ( 8 * s - > mb_height - ( ( s - > height/s - > v_max ) & 7 ) ) - 1 ) ) ; data[c] + = offset ; reference_data[c] + = offset ; linesize[c] * = - 1 ; } } for ( mb_y = 0 ; mb_y < s - > mb_height ; mb_y + + ) { for ( mb_x = 0 ; mb_x < s - > mb_width ; mb_x + + ) { const int copy_mb = mb_bitmask & & ! get_bits1 ( & mb_bitmask_gb ) ; if ( s - > restart_interval & & ! s - > restart_count ) s - > restart_count = s - > restart_interval ; if ( get_bits_count ( & s - > gb ) > s - > gb . size_in_bits ) { av_log ( s - > avctx , AV_LOG_ERROR , overread %d\n , get_bits_count ( & s - > gb ) - s - > gb . size_in_bits ) ; return - 1 ; } for ( i=0 ; i < nb_components ; i + + ) { uint8_t * ptr ; int n , h , v , x , y , c , j ; int block_offset ; n = s - > nb_blocks[i] ; c = s - > comp_index[i] ; h = s - > h_scount[i] ; v = s - > v_scount[i] ; x = 0 ; y = 0 ; for ( j=0 ; j < n ; j + + ) { block_offset = ( ( ( linesize[c] * ( v * mb_y + y ) * 8 ) + ( h * mb_x + x ) * 8 ) > > s - > avctx - > lowres ) ; if ( s - > interlaced & & s - > bottom_field ) block_offset + = linesize[c] > > 1 ; ptr = data[c] + block_offset ; if ( ! s - > progressive ) { if ( copy_mb ) { mjpeg_copy_block ( ptr , reference_data[c] + block_offset , linesize[c] , s - > avctx - > lowres ) ; } else { s - > dsp . clear_block ( s - > block ) ; if ( decode_block ( s , s - > block , i , s - > dc_index[i] , s - > ac_index[i] , s - > quant_matrixes[ s - > quant_index[c] ] ) < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , error y=%d x=%d\n , mb_y , mb_x ) ; return - 1 ; } s - > dsp . idct_put ( ptr , linesize[c] , s - > block ) ; } } else { int block_idx = s - > block_stride[c] * ( v * mb_y + y ) + ( h * mb_x + x ) ; DCTELEM * block = s - > blocks[c][block_idx] ; if ( Ah ) block[0] + = get_bits1 ( & s - > gb ) * s - > quant_matrixes[ s - > quant_index[c] ][0] < < Al ; else if ( decode_dc_progressive ( s , block , i , s - > dc_index[i] , s - > quant_matrixes[ s - > quant_index[c] ] , Al ) < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , error y=%d x=%d\n , mb_y , mb_x ) ; return - 1 ; } } // av_log ( s - > avctx , AV_LOG_DEBUG , mb : %d %d processed\n , mb_y , mb_x ) ; //av_log ( NULL , AV_LOG_DEBUG , %d %d %d %d %d %d %d %d \n , mb_x , mb_y , x , y , c , s - > bottom_field , ( v * mb_y + y ) * 8 , ( h * mb_x + x ) * 8 ) ; if ( + + x == h ) { x = 0 ; y + + ; } } } if ( s - > restart_interval & & show_bits ( & s - > gb , 8 ) == 0xFF ) { / * skip RSTn * / - - s - > restart_count ; align_get_bits ( & s - > gb ) ; while ( show_bits ( & s - > gb , 8 ) == 0xFF ) skip_bits ( & s - > gb , 8 ) ; skip_bits ( & s - > gb , 8 ) ; for ( i=0 ; i < nb_components ; i + + ) / * reset dc * / s - > last_dc[i] = 1024 ; } } } return 0 ; }",0
"static av_cold int avui_encode_init ( AVCodecContext * avctx ) { avctx - > coded_frame = av_frame_alloc ( ) ; if ( avctx - > width ! = 720 || avctx - > height ! = 486 & & avctx - > height ! = 576 ) { av_log ( avctx , AV_LOG_ERROR , Only 720x486 and 720x576 are supported . \n ) ; return AVERROR ( EINVAL ) ; } if ( ! avctx - > coded_frame ) { av_log ( avctx , AV_LOG_ERROR , Could not allocate frame . \n ) ; return AVERROR ( ENOMEM ) ; } if ( ! ( avctx - > extradata = av_mallocz ( 24 + FF_INPUT_BUFFER_PADDING_SIZE ) ) ) return AVERROR ( ENOMEM ) ; avctx - > extradata_size = 24 ; memcpy ( avctx - > extradata , \0\0\0\x18 APRGAPRG0001 , 16 ) ; if ( avctx - > field_order > AV_FIELD_PROGRESSIVE ) { avctx - > extradata[19] = 2 ; } else { avctx - > extradata[19] = 1 ; } return 0 ; }",1
"static int decode_frame ( AVCodecContext * avctx , void * data , int * got_frame_ptr , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; MPADecodeContext * s = avctx - > priv_data ; uint32_t header ; int ret ; if ( buf_size < HEADER_SIZE ) return AVERROR_INVALIDDATA ; header = AV_RB32 ( buf ) ; if ( ff_mpa_check_header ( header ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , Header missing\n ) ; return AVERROR_INVALIDDATA ; } if ( avpriv_mpegaudio_decode_header ( ( MPADecodeHeader * ) s , header ) == 1 ) { / * free format : prepare to compute frame size * / s - > frame_size = - 1 ; return AVERROR_INVALIDDATA ; } / * update codec info * / avctx - > channels = s - > nb_channels ; avctx - > channel_layout = s - > nb_channels == 1 ? AV_CH_LAYOUT_MONO : AV_CH_LAYOUT_STEREO ; if ( ! avctx - > bit_rate ) avctx - > bit_rate = s - > bit_rate ; s - > frame = data ; ret = mp_decode_frame ( s , NULL , buf , buf_size ) ; if ( ret > = 0 ) { s - > frame - > nb_samples = avctx - > frame_size ; * got_frame_ptr = 1 ; avctx - > sample_rate = s - > sample_rate ; //FIXME maybe move the other codec info stuff from above here too } else { av_log ( avctx , AV_LOG_ERROR , Error while decoding MPEG audio frame . \n ) ; / * Only return an error if the bad frame makes up the whole packet or * the error is related to buffer management . * If there is more data in the packet , just consume the bad frame * instead of returning an error , which would discard the whole * packet . * / * got_frame_ptr = 0 ; if ( buf_size == avpkt - > size || ret ! = AVERROR_INVALIDDATA ) return ret ; } s - > frame_size = 0 ; return buf_size ; }",0
"int attribute_align_arg avcodec_open2 ( AVCodecContext * avctx , AVCodec * codec , AVDictionary * * options ) { int ret = 0 ; AVDictionary * tmp = NULL ; if ( avcodec_is_open ( avctx ) ) return 0 ; if ( ( ! codec & & ! avctx - > codec ) ) { av_log ( avctx , AV_LOG_ERROR , No codec provided to avcodec_open2 ( ) . \n ) ; return AVERROR ( EINVAL ) ; } if ( ( codec & & avctx - > codec & & codec ! = avctx - > codec ) ) { av_log ( avctx , AV_LOG_ERROR , This AVCodecContext was allocated for %s , but %s passed to avcodec_open2 ( ) . \n , avctx - > codec - > name , codec - > name ) ; return AVERROR ( EINVAL ) ; } if ( ! codec ) codec = avctx - > codec ; if ( avctx - > extradata_size < 0 || avctx - > extradata_size > = FF_MAX_EXTRADATA_SIZE ) return AVERROR ( EINVAL ) ; if ( options ) av_dict_copy ( & tmp , * options , 0 ) ; / * If there is a user - supplied mutex locking routine , call it . * / if ( ff_lockmgr_cb ) { if ( ( * ff_lockmgr_cb ) ( & codec_mutex , AV_LOCK_OBTAIN ) ) return - 1 ; } entangled_thread_counter + + ; if ( entangled_thread_counter ! = 1 ) { av_log ( avctx , AV_LOG_ERROR , insufficient thread locking around avcodec_open/close ( ) \n ) ; ret = - 1 ; goto end ; } avctx - > internal = av_mallocz ( sizeof ( AVCodecInternal ) ) ; if ( ! avctx - > internal ) { ret = AVERROR ( ENOMEM ) ; goto end ; } if ( codec - > priv_data_size > 0 ) { if ( ! avctx - > priv_data ) { avctx - > priv_data = av_mallocz ( codec - > priv_data_size ) ; if ( ! avctx - > priv_data ) { ret = AVERROR ( ENOMEM ) ; goto end ; } if ( codec - > priv_class ) { * ( const AVClass * * ) avctx - > priv_data= codec - > priv_class ; av_opt_set_defaults ( avctx - > priv_data ) ; } } if ( codec - > priv_class & & ( ret = av_opt_set_dict ( avctx - > priv_data , & tmp ) ) < 0 ) goto free_and_end ; } else { avctx - > priv_data = NULL ; } if ( ( ret = av_opt_set_dict ( avctx , & tmp ) ) < 0 ) goto free_and_end ; if ( codec - > capabilities & CODEC_CAP_EXPERIMENTAL ) if ( avctx - > strict_std_compliance > FF_COMPLIANCE_EXPERIMENTAL ) { av_log ( avctx , AV_LOG_ERROR , Codec is experimental but experimental codecs are not enabled , try - strict - 2\n ) ; ret = - 1 ; goto free_and_end ; } //We only call avcodec_set_dimensions ( ) for non h264 codecs so as not to overwrite previously setup dimensions if ( ! ( avctx - > coded_width & & avctx - > coded_height & & avctx - > width & & avctx - > height & & avctx - > codec_id == CODEC_ID_H264 ) ) { if ( avctx - > coded_width & & avctx - > coded_height ) avcodec_set_dimensions ( avctx , avctx - > coded_width , avctx - > coded_height ) ; else if ( avctx - > width & & avctx - > height ) avcodec_set_dimensions ( avctx , avctx - > width , avctx - > height ) ; } if ( ( avctx - > coded_width || avctx - > coded_height || avctx - > width || avctx - > height ) & & ( av_image_check_size ( avctx - > coded_width , avctx - > coded_height , 0 , avctx ) < 0 || av_image_check_size ( avctx - > width , avctx - > height , 0 , avctx ) < 0 ) ) { av_log ( avctx , AV_LOG_WARNING , ignoring invalid width/height values\n ) ; avcodec_set_dimensions ( avctx , 0 , 0 ) ; } / * if the decoder init function was already called previously , free the already allocated subtitle_header before overwriting it * / if ( av_codec_is_decoder ( codec ) ) av_freep ( & avctx - > subtitle_header ) ; define SANE_NB_CHANNELS 128U if ( avctx - > channels > SANE_NB_CHANNELS ) { ret = AVERROR ( EINVAL ) ; goto free_and_end ; } avctx - > codec = codec ; if ( ( avctx - > codec_type == AVMEDIA_TYPE_UNKNOWN || avctx - > codec_type == codec - > type ) & & avctx - > codec_id == CODEC_ID_NONE ) { avctx - > codec_type = codec - > type ; avctx - > codec_id = codec - > id ; } if ( avctx - > codec_id ! = codec - > id || ( avctx - > codec_type ! = codec - > type & & avctx - > codec_type ! = AVMEDIA_TYPE_ATTACHMENT ) ) { av_log ( avctx , AV_LOG_ERROR , codec type or id mismatches\n ) ; ret = AVERROR ( EINVAL ) ; goto free_and_end ; } avctx - > frame_number = 0 ; if ( avctx - > codec_type == AVMEDIA_TYPE_AUDIO & & ( ! avctx - > time_base . num || ! avctx - > time_base . den ) ) { avctx - > time_base . num = 1 ; avctx - > time_base . den = avctx - > sample_rate ; } if ( ! HAVE_THREADS ) av_log ( avctx , AV_LOG_WARNING , Warning : not compiled with thread support , using thread emulation\n ) ; if ( HAVE_THREADS & & ! avctx - > thread_opaque ) { ret = ff_thread_init ( avctx ) ; if ( ret < 0 ) { goto free_and_end ; } } if ( ! HAVE_THREADS & & ! ( codec - > capabilities & CODEC_CAP_AUTO_THREADS ) ) avctx - > thread_count = 1 ; if ( avctx - > codec - > max_lowres < avctx - > lowres || avctx - > lowres < 0 ) { av_log ( avctx , AV_LOG_ERROR , The maximum value for lowres supported by the decoder is %d\n , avctx - > codec - > max_lowres ) ; ret = AVERROR ( EINVAL ) ; goto free_and_end ; } if ( av_codec_is_encoder ( avctx - > codec ) ) { int i ; if ( avctx - > codec - > sample_fmts ) { for ( i = 0 ; avctx - > codec - > sample_fmts[i] ! = AV_SAMPLE_FMT_NONE ; i + + ) if ( avctx - > sample_fmt == avctx - > codec - > sample_fmts[i] ) break ; if ( avctx - > codec - > sample_fmts[i] == AV_SAMPLE_FMT_NONE ) { av_log ( avctx , AV_LOG_ERROR , Specified sample_fmt is not supported . \n ) ; ret = AVERROR ( EINVAL ) ; goto free_and_end ; } } if ( avctx - > codec - > pix_fmts ) { for ( i = 0 ; avctx -",0
"static int get_transform_coeffs1 ( uint8_t * exps , uint8_t * bap , float chcoeff , float * coeffs , int start , int end , int dith_flag , GetBitContext * gb , dither_state * state ) { int16_t mantissa ; int i ; int gcode ; mant_group l3_grp , l5_grp , l11_grp ; for ( i = 0 ; i < 3 ; i + + ) l3_grp . gcodes[i] = l5_grp . gcodes[i] = l11_grp . gcodes[i] = - 1 ; l3_grp . gcptr = l5_grp . gcptr = 3 ; l11_grp . gcptr = 2 ; i = 0 ; while ( i < start ) coeffs[i + + ] = 0 ; for ( i = start ; i < end ; i + + ) { switch ( bap[i] ) { case 0 : if ( ! dith_flag ) { coeffs[i] = 0 ; continue ; } else { mantissa = dither_int16 ( state ) ; coeffs[i] = to_float ( exps[i] , mantissa ) * chcoeff ; continue ; } case 1 : if ( l3_grp . gcptr > 2 ) { gcode = get_bits ( gb , 5 ) ; if ( gcode > 26 ) return - 1 ; l3_grp . gcodes[0] = gcode / 9 ; l3_grp . gcodes[1] = ( gcode % 9 ) / 3 ; l3_grp . gcodes[2] = ( gcode % 9 ) % 3 ; l3_grp . gcptr = 0 ; } mantissa = l3_q_tab[l3_grp . gcodes[l3_grp . gcptr + + ]] ; coeffs[i] = to_float ( exps[i] , mantissa ) * chcoeff ; continue ; case 2 : if ( l5_grp . gcptr > 2 ) { gcode = get_bits ( gb , 7 ) ; if ( gcode > 124 ) return - 1 ; l5_grp . gcodes[0] = gcode / 25 ; l5_grp . gcodes[1] = ( gcode % 25 ) / 5 ; l5_grp . gcodes[2] = ( gcode % 25 ) % 5 ; l5_grp . gcptr = 0 ; } mantissa = l5_q_tab[l5_grp . gcodes[l5_grp . gcptr + + ]] ; coeffs[i] = to_float ( exps[i] , mantissa ) * chcoeff ; continue ; case 3 : mantissa = get_bits ( gb , 3 ) ; if ( mantissa > 6 ) return - 1 ; mantissa = l7_q_tab[mantissa] ; coeffs[i] = to_float ( exps[i] , mantissa ) ; continue ; case 4 : if ( l11_grp . gcptr > 1 ) { gcode = get_bits ( gb , 7 ) ; if ( gcode > 120 ) return - 1 ; l11_grp . gcodes[0] = gcode / 11 ; l11_grp . gcodes[1] = gcode % 11 ; } mantissa = l11_q_tab[l11_grp . gcodes[l11_grp . gcptr + + ]] ; coeffs[i] = to_float ( exps[i] , mantissa ) * chcoeff ; continue ; case 5 : mantissa = get_bits ( gb , 4 ) ; if ( mantissa > 14 ) return - 1 ; mantissa = l15_q_tab[mantissa] ; coeffs[i] = to_float ( exps[i] , mantissa ) * chcoeff ; continue ; default : mantissa = get_bits ( gb , qntztab[bap[i]] ) < < ( 16 - qntztab[bap[i]] ) ; coeffs[i] = to_float ( exps[i] , mantissa ) * chcoeff ; continue ; } } i = end ; while ( i < 256 ) coeffs[i + + ] = 0 ; return 0 ; }",0
"static int fits_write_packet ( AVFormatContext * s , AVPacket * pkt ) { write_image_header ( s ) ; avio_write ( s - > pb , pkt - > data , pkt - > size ) ; return 0 ; }",0
"static int mkv_write_tag_targets ( AVFormatContext * s , unsigned int elementid , unsigned int uid , ebml_master * tags , ebml_master * tag ) { AVIOContext * pb ; MatroskaMuxContext * mkv = s - > priv_data ; ebml_master targets ; int ret ; if ( ! tags - > pos ) { ret = mkv_add_seekhead_entry ( mkv - > main_seekhead , MATROSKA_ID_TAGS , avio_tell ( s - > pb ) ) ; if ( ret < 0 ) return ret ; start_ebml_master_crc32 ( s - > pb , & mkv - > tags_bc , tags , MATROSKA_ID_TAGS , 0 ) ; } pb = mkv - > tags_bc ; * tag = start_ebml_master ( pb , MATROSKA_ID_TAG , 0 ) ; targets = start_ebml_master ( pb , MATROSKA_ID_TAGTARGETS , 0 ) ; if ( elementid ) put_ebml_uint ( pb , elementid , uid ) ; end_ebml_master ( pb , targets ) ; return 0 ; }",0
"static void formant_postfilter ( G723_1_Context * p , int16_t * lpc , int16_t * buf ) { int16_t filter_coef[2][LPC_ORDER] , * buf_ptr ; int filter_signal[LPC_ORDER + FRAME_LEN] , * signal_ptr ; int i , j , k ; memcpy ( buf , p - > fir_mem , LPC_ORDER * sizeof ( * buf ) ) ; memcpy ( filter_signal , p - > iir_mem , LPC_ORDER * sizeof ( * filter_signal ) ) ; for ( i = LPC_ORDER , j = 0 ; j < SUBFRAMES ; i + = SUBFRAME_LEN , j + + ) { for ( k = 0 ; k < LPC_ORDER ; k + + ) { filter_coef[0][k] = ( - lpc[k] * postfilter_tbl[0][k] + ( 1 < < 14 ) ) > > 15 ; filter_coef[1][k] = ( - lpc[k] * postfilter_tbl[1][k] + ( 1 < < 14 ) ) > > 15 ; } iir_filter ( filter_coef[0] , filter_coef[1] , buf + i , filter_signal + i ) ; lpc + = LPC_ORDER ; } memcpy ( p - > fir_mem , buf + FRAME_LEN , LPC_ORDER * sizeof ( * p - > fir_mem ) ) ; memcpy ( p - > iir_mem , filter_signal + FRAME_LEN , LPC_ORDER * sizeof ( * p - > iir_mem ) ) ; buf_ptr = buf + LPC_ORDER ; signal_ptr = filter_signal + LPC_ORDER ; for ( i = 0 ; i < SUBFRAMES ; i + + ) { int16_t temp_vector[SUBFRAME_LEN] ; int temp ; int auto_corr[2] ; int scale , energy ; / * Normalize * / memcpy ( temp_vector , buf_ptr , SUBFRAME_LEN * sizeof ( * temp_vector ) ) ; scale = scale_vector ( temp_vector , SUBFRAME_LEN ) ; / * Compute auto correlation coefficients * / auto_corr[0] = dot_product ( temp_vector , temp_vector + 1 , SUBFRAME_LEN - 1 , 1 ) ; auto_corr[1] = dot_product ( temp_vector , temp_vector , SUBFRAME_LEN , 1 ) ; / * Compute reflection coefficient * / temp = auto_corr[1] > > 16 ; if ( temp ) { temp = ( auto_corr[0] > > 2 ) / temp ; } p - > reflection_coef = ( 3 * p - > reflection_coef + temp + 2 ) > > 2 ; temp = - p - > reflection_coef > > 1 & 3 ; / * Compensation filter * / for ( j = 0 ; j < SUBFRAME_LEN ; j + + ) { buf_ptr[j] = av_clipl_int32 ( signal_ptr[j] + ( ( signal_ptr[j - 1] > > 16 ) * temp < < 1 ) ) > > 16 ; } / * Compute normalized signal energy * / temp = 2 * scale + 4 ; if ( temp < 0 ) { energy = av_clipl_int32 ( ( int64_t ) auto_corr[1] < < - temp ) ; } else energy = auto_corr[1] > > temp ; gain_scale ( p , buf_ptr , energy ) ; buf_ptr + = SUBFRAME_LEN ; signal_ptr + = SUBFRAME_LEN ; } }",1
"int attribute_align_arg avresample_convert ( AVAudioResampleContext * avr , uint8_t * * output , int out_plane_size , int out_samples , uint8_t * * input , int in_plane_size , int in_samples ) { AudioData input_buffer ; AudioData output_buffer ; AudioData * current_buffer ; int ret , direct_output ; / * reset internal buffers * / if ( avr - > in_buffer ) { avr - > in_buffer - > nb_samples = 0 ; ff_audio_data_set_channels ( avr - > in_buffer , avr - > in_buffer - > allocated_channels ) ; } if ( avr - > resample_out_buffer ) { avr - > resample_out_buffer - > nb_samples = 0 ; ff_audio_data_set_channels ( avr - > resample_out_buffer , avr - > resample_out_buffer - > allocated_channels ) ; } if ( avr - > out_buffer ) { avr - > out_buffer - > nb_samples = 0 ; ff_audio_data_set_channels ( avr - > out_buffer , avr - > out_buffer - > allocated_channels ) ; } av_dlog ( avr , [start conversion]\n ) ; / * initialize output_buffer with output data * / direct_output = output & & av_audio_fifo_size ( avr - > out_fifo ) == 0 ; if ( output ) { ret = ff_audio_data_init ( & output_buffer , output , out_plane_size , avr - > out_channels , out_samples , avr - > out_sample_fmt , 0 , output ) ; if ( ret < 0 ) return ret ; output_buffer . nb_samples = 0 ; } if ( input ) { / * initialize input_buffer with input data * / ret = ff_audio_data_init ( & input_buffer , input , in_plane_size , avr - > in_channels , in_samples , avr - > in_sample_fmt , 1 , input ) ; if ( ret < 0 ) return ret ; current_buffer = & input_buffer ; if ( avr - > upmix_needed & & ! avr - > in_convert_needed & & ! avr - > resample_needed & & ! avr - > out_convert_needed & & direct_output & & out_samples > = in_samples ) { / * in some rare cases we can copy input to output and upmix directly in the output buffer * / av_dlog ( avr , [copy] %s to output\n , current_buffer - > name ) ; ret = ff_audio_data_copy ( & output_buffer , current_buffer , avr - > remap_point == REMAP_OUT_COPY ? & avr - > ch_map_info : NULL ) ; if ( ret < 0 ) return ret ; current_buffer = & output_buffer ; } else if ( avr - > remap_point == REMAP_OUT_COPY & & ( ! direct_output || out_samples < in_samples ) ) { / * if remapping channels during output copy , we may need to * use an intermediate buffer in order to remap before adding * samples to the output fifo * / av_dlog ( avr , [copy] %s to out_buffer\n , current_buffer - > name ) ; ret = ff_audio_data_copy ( avr - > out_buffer , current_buffer , & avr - > ch_map_info ) ; if ( ret < 0 ) return ret ; current_buffer = avr - > out_buffer ; } else if ( avr - > in_copy_needed || avr - > in_convert_needed ) { / * if needed , copy or convert input to in_buffer , and downmix if applicable * / if ( avr - > in_convert_needed ) { ret = ff_audio_data_realloc ( avr - > in_buffer , current_buffer - > nb_samples ) ; if ( ret < 0 ) return ret ; av_dlog ( avr , [convert] %s to in_buffer\n , current_buffer - > name ) ; ret = ff_audio_convert ( avr - > ac_in , avr - > in_buffer , current_buffer ) ; if ( ret < 0 ) return ret ; } else { av_dlog ( avr , [copy] %s to in_buffer\n , current_buffer - > name ) ; ret = ff_audio_data_copy ( avr - > in_buffer , current_buffer , avr - > remap_point == REMAP_IN_COPY ? & avr - > ch_map_info : NULL ) ; if ( ret < 0 ) return ret ; } ff_audio_data_set_channels ( avr - > in_buffer , avr - > in_channels ) ; if ( avr - > downmix_needed ) { av_dlog ( avr , [downmix] in_buffer\n ) ; ret = ff_audio_mix ( avr - > am , avr - > in_buffer ) ; if ( ret < 0 ) return ret ; } current_buffer = avr - > in_buffer ; } } else { / * flush resampling buffer and/or output FIFO if input is NULL * / if ( ! avr - > resample_needed ) return handle_buffered_output ( avr , output ? & output_buffer : NULL , NULL ) ; current_buffer = NULL ; } if ( avr - > resample_needed ) { AudioData * resample_out ; if ( ! avr - > out_convert_needed & & direct_output & & out_samples > 0 ) resample_out = & output_buffer ; else resample_out = avr - > resample_out_buffer ; av_dlog ( avr , [resample] %s to %s\n , current_buffer - > name , resample_out - > name ) ; ret = ff_audio_resample ( avr - > resample , resample_out , current_buffer ) ; if ( ret < 0 ) return ret ; / * if resampling did not produce any samples , just return 0 * / if ( resample_out - > nb_samples == 0 ) { av_dlog ( avr , [end conversion]\n ) ; return 0 ; } current_buffer = resample_out ; } if ( avr - > upmix_needed ) { av_dlog ( avr , [upmix] %s\n , current_buffer - > name ) ; ret = ff_audio_mix ( avr - > am , current_buffer ) ; if ( ret < 0 ) return ret ; } / * if we resampled or upmixed directly to output , return here * / if ( current_buffer == & output_buffer ) { av_dlog ( avr , [end conversion]\n ) ; return current_buffer - > nb_samples ; } if ( avr - > out_convert_needed ) { if ( direct_output & & out_samples > = current_buffer - > nb_samples ) { / * convert directly to output * / av_dlog ( avr , [convert] %s to output\n , current_buffer - > name ) ; ret = ff_audio_convert ( avr - > ac_out , & output_buffer , current_buffer ) ; if ( ret < 0 ) return ret ; av_dlog ( avr , [end conversion]\n ) ; return output_buffer . nb_samples ; } else { ret = ff_audio_data_realloc ( avr - > out_buffer , current_buffer - > nb_samples ) ; if ( ret < 0 ) return ret ; av_dlog ( avr , [convert] %s to out_buffer\n , current_buffer - > name ) ; ret = ff_audio_convert ( avr - > ac_out , avr - > out_buffer , current_buffer ) ; if ( ret < 0 ) return ret ; current_buffer = avr - > out_buffer ; } } return handle_buffered_output ( avr , output ? & output_buffer : NULL , current_buffer ) ; }",1
"static int ogg_read_header ( AVFormatContext * avfcontext , AVFormatParameters * ap ) { OggContext * context = avfcontext - > priv_data ; ogg_packet op ; char * buf ; ogg_page og ; AVStream * ast ; AVCodecContext * codec ; uint8_t * p ; int i ; ogg_sync_init ( & context - > oy ) ; buf = ogg_sync_buffer ( & context - > oy , DECODER_BUFFER_SIZE ) ; if ( get_buffer ( & avfcontext - > pb , buf , DECODER_BUFFER_SIZE ) < = 0 ) return AVERROR_IO ; ogg_sync_wrote ( & context - > oy , DECODER_BUFFER_SIZE ) ; ogg_sync_pageout ( & context - > oy , & og ) ; ogg_stream_init ( & context - > os , ogg_page_serialno ( & og ) ) ; ogg_stream_pagein ( & context - > os , & og ) ; / * currently only one vorbis stream supported * / ast = av_new_stream ( avfcontext , 0 ) ; if ( ! ast ) return AVERROR_NOMEM ; av_set_pts_info ( ast , 60 , 1 , AV_TIME_BASE ) ; codec= & ast - > codec ; codec - > codec_type = CODEC_TYPE_AUDIO ; codec - > codec_id = CODEC_ID_VORBIS ; for ( i=0 ; i < 3 ; i + + ) { if ( next_packet ( avfcontext , & op ) ) { } codec - > extradata_size + = 2 + op . bytes ; codec - > extradata= av_realloc ( codec - > extradata , codec - > extradata_size + FF_INPUT_BUFFER_PADDING_SIZE ) ; p= codec - > extradata + codec - > extradata_size - 2 - op . bytes ; * ( p + + ) = op . bytes > > 8 ; * ( p + + ) = op . bytes & 0xFF ; memcpy ( p , op . packet , op . bytes ) ; } return 0 ; }",1
"static int vp56_size_changed ( VP56Context * s ) { AVCodecContext * avctx = s - > avctx ; int stride = s - > frames[VP56_FRAME_CURRENT] - > linesize[0] ; int i ; s - > plane_width[0] = s - > plane_width[3] = avctx - > coded_width ; s - > plane_width[1] = s - > plane_width[2] = avctx - > coded_width/2 ; s - > plane_height[0] = s - > plane_height[3] = avctx - > coded_height ; s - > plane_height[1] = s - > plane_height[2] = avctx - > coded_height/2 ; for ( i=0 ; i < 4 ; i + + ) s - > stride[i] = s - > flip * s - > frames[VP56_FRAME_CURRENT] - > linesize[i] ; s - > mb_width = ( avctx - > coded_width + 15 ) / 16 ; s - > mb_height = ( avctx - > coded_height + 15 ) / 16 ; if ( s - > mb_width > 1000 || s - > mb_height > 1000 ) { ff_set_dimensions ( avctx , 0 , 0 ) ; av_log ( avctx , AV_LOG_ERROR , picture too big\n ) ; return AVERROR_INVALIDDATA ; } av_reallocp_array ( & s - > above_blocks , 4 * s - > mb_width + 6 , sizeof ( * s - > above_blocks ) ) ; av_reallocp_array ( & s - > macroblocks , s - > mb_width * s - > mb_height , sizeof ( * s - > macroblocks ) ) ; av_free ( s - > edge_emu_buffer_alloc ) ; s - > edge_emu_buffer_alloc = av_malloc ( 16 * stride ) ; s - > edge_emu_buffer = s - > edge_emu_buffer_alloc ; if ( ! s - > above_blocks || ! s - > macroblocks || ! s - > edge_emu_buffer_alloc ) return AVERROR ( ENOMEM ) ; if ( s - > flip < 0 ) s - > edge_emu_buffer + = 15 * stride ; if ( s - > alpha_context ) return vp56_size_changed ( s - > alpha_context ) ; return 0 ; }",1
"static void rtsp_cmd_teardown ( HTTPContext * c , const char * url , RTSPHeader * h ) { HTTPContext * rtp_c ; rtp_c = find_rtp_session_with_url ( url , h - > session_id ) ; if ( ! rtp_c ) { rtsp_reply_error ( c , RTSP_STATUS_SESSION ) ; return ; } / * abort the session * / close_connection ( rtp_c ) ; / * now everything is OK , so we can send the connection parameters * / rtsp_reply_header ( c , RTSP_STATUS_OK ) ; / * session ID * / url_fprintf ( c - > pb , Session : %s\r\n , rtp_c - > session_id ) ; url_fprintf ( c - > pb , \r\n ) ; }",1
"static av_cold int twin_decode_init ( AVCodecContext * avctx ) { int ret ; TwinContext * tctx = avctx - > priv_data ; int isampf , ibps ; tctx - > avctx = avctx ; avctx - > sample_fmt = AV_SAMPLE_FMT_FLTP ; if ( ! avctx - > extradata || avctx - > extradata_size < 12 ) { av_log ( avctx , AV_LOG_ERROR , Missing or incomplete extradata\n ) ; return AVERROR_INVALIDDATA ; } avctx - > channels = AV_RB32 ( avctx - > extradata ) + 1 ; avctx - > bit_rate = AV_RB32 ( avctx - > extradata + 4 ) * 1000 ; isampf = AV_RB32 ( avctx - > extradata + 8 ) ; switch ( isampf ) { case 44 : avctx - > sample_rate = 44100 ; break ; case 22 : avctx - > sample_rate = 22050 ; break ; case 11 : avctx - > sample_rate = 11025 ; break ; default : avctx - > sample_rate = isampf * 1000 ; break ; } if ( avctx - > channels > CHANNELS_MAX ) { av_log ( avctx , AV_LOG_ERROR , Unsupported number of channels : %i\n , avctx - > channels ) ; return - 1 ; } ibps = avctx - > bit_rate / ( 1000 * avctx - > channels ) ; switch ( ( isampf < < 8 ) + ibps ) { case ( 8 < < 8 ) + 8 : tctx - > mtab = & mode_08_08 ; break ; case ( 11 < < 8 ) + 8 : tctx - > mtab = & mode_11_08 ; break ; case ( 11 < < 8 ) + 10 : tctx - > mtab = & mode_11_10 ; break ; case ( 16 < < 8 ) + 16 : tctx - > mtab = & mode_16_16 ; break ; case ( 22 < < 8 ) + 20 : tctx - > mtab = & mode_22_20 ; break ; case ( 22 < < 8 ) + 24 : tctx - > mtab = & mode_22_24 ; break ; case ( 22 < < 8 ) + 32 : tctx - > mtab = & mode_22_32 ; break ; case ( 44 < < 8 ) + 40 : tctx - > mtab = & mode_44_40 ; break ; case ( 44 < < 8 ) + 48 : tctx - > mtab = & mode_44_48 ; break ; default : av_log ( avctx , AV_LOG_ERROR , This version does not support %d kHz - %d kbit/s/ch mode . \n , isampf , isampf ) ; return - 1 ; } ff_dsputil_init ( & tctx - > dsp , avctx ) ; avpriv_float_dsp_init ( & tctx - > fdsp , avctx - > flags & CODEC_FLAG_BITEXACT ) ; if ( ( ret = init_mdct_win ( tctx ) ) ) { av_log ( avctx , AV_LOG_ERROR , Error initializing MDCT\n ) ; twin_decode_close ( avctx ) ; return ret ; } init_bitstream_params ( tctx ) ; memset_float ( tctx - > bark_hist[0][0] , 0 . 1 , FF_ARRAY_ELEMS ( tctx - > bark_hist ) ) ; avcodec_get_frame_defaults ( & tctx - > frame ) ; avctx - > coded_frame = & tctx - > frame ; return 0 ; }",1
"static int mov_read_sidx ( MOVContext * c , AVIOContext * pb , MOVAtom atom ) { int64_t offset = avio_tell ( pb ) + atom . size , pts , timestamp ; uint8_t version ; unsigned i , j , track_id , item_count ; AVStream * st = NULL ; AVStream * ref_st = NULL ; MOVStreamContext * sc , * ref_sc = NULL ; AVRational timescale ; version = avio_r8 ( pb ) ; if ( version > 1 ) { avpriv_request_sample ( c - > fc , sidx version %u , version ) ; return 0 ; } avio_rb24 ( pb ) ; // flags track_id = avio_rb32 ( pb ) ; // Reference ID for ( i = 0 ; i < c - > fc - > nb_streams ; i + + ) { if ( c - > fc - > streams[i] - > id == track_id ) { st = c - > fc - > streams[i] ; break ; } } if ( ! st ) { av_log ( c - > fc , AV_LOG_WARNING , could not find corresponding track id %d\n , track_id ) ; return 0 ; } sc = st - > priv_data ; timescale = av_make_q ( 1 , avio_rb32 ( pb ) ) ; if ( timescale . den < = 0 ) { av_log ( c - > fc , AV_LOG_ERROR , Invalid sidx timescale 1/%d\n , timescale . den ) ; return AVERROR_INVALIDDATA ; } if ( version == 0 ) { pts = avio_rb32 ( pb ) ; offset + = avio_rb32 ( pb ) ; } else { pts = avio_rb64 ( pb ) ; offset + = avio_rb64 ( pb ) ; } avio_rb16 ( pb ) ; // reserved item_count = avio_rb16 ( pb ) ; for ( i = 0 ; i < item_count ; i + + ) { int index ; MOVFragmentStreamInfo * frag_stream_info ; uint32_t size = avio_rb32 ( pb ) ; uint32_t duration = avio_rb32 ( pb ) ; if ( size & 0x80000000 ) { avpriv_request_sample ( c - > fc , sidx reference_type 1 ) ; return AVERROR_PATCHWELCOME ; } avio_rb32 ( pb ) ; // sap_flags timestamp = av_rescale_q ( pts , st - > time_base , timescale ) ; index = update_frag_index ( c , offset ) ; frag_stream_info = get_frag_stream_info ( & c - > frag_index , index , track_id ) ; if ( frag_stream_info ) frag_stream_info - > sidx_pts = timestamp ; offset + = size ; pts + = duration ; } st - > duration = sc - > track_end = pts ; sc - > has_sidx = 1 ; if ( offset == avio_size ( pb ) ) { // Find first entry in fragment index that came from an sidx . // This will pretty much always be the first entry . for ( i = 0 ; i < c - > frag_index . nb_items ; i + + ) { MOVFragmentIndexItem * item = & c - > frag_index . item[i] ; for ( j = 0 ; ref_st == NULL & & j < item - > nb_stream_info ; j + + ) { MOVFragmentStreamInfo * si ; si = & item - > stream_info[j] ; if ( si - > sidx_pts ! = AV_NOPTS_VALUE ) { ref_st = c - > fc - > streams[i] ; ref_sc = ref_st - > priv_data ; break ; } } } for ( i = 0 ; i < c - > fc - > nb_streams ; i + + ) { st = c - > fc - > streams[i] ; sc = st - > priv_data ; if ( ! sc - > has_sidx ) { st - > duration = sc - > track_end = av_rescale ( ref_st - > duration , sc - > time_scale , ref_sc - > time_scale ) ; } } c - > frag_index . complete = 1 ; } return 0 ; }",1
"void ff_hevc_cabac_init ( HEVCContext * s , int ctb_addr_ts ) { if ( ctb_addr_ts == s - > ps . pps - > ctb_addr_rs_to_ts[s - > sh . slice_ctb_addr_rs] ) { cabac_init_decoder ( s ) ; if ( s - > sh . dependent_slice_segment_flag == 0 || ( s - > ps . pps - > tiles_enabled_flag & & s - > ps . pps - > tile_id[ctb_addr_ts] ! = s - > ps . pps - > tile_id[ctb_addr_ts - 1] ) ) cabac_init_state ( s ) ; if ( ! s - > sh . first_slice_in_pic_flag & & s - > ps . pps - > entropy_coding_sync_enabled_flag ) { if ( ctb_addr_ts % s - > ps . sps - > ctb_width == 0 ) { if ( s - > ps . sps - > ctb_width == 1 ) cabac_init_state ( s ) ; else if ( s - > sh . dependent_slice_segment_flag == 1 ) load_states ( s ) ; } } } else { if ( s - > ps . pps - > tiles_enabled_flag & & s - > ps . pps - > tile_id[ctb_addr_ts] ! = s - > ps . pps - > tile_id[ctb_addr_ts - 1] ) { if ( s - > threads_number == 1 ) cabac_reinit ( s - > HEVClc ) ; else cabac_init_decoder ( s ) ; cabac_init_state ( s ) ; } if ( s - > ps . pps - > entropy_coding_sync_enabled_flag ) { if ( ctb_addr_ts % s - > ps . sps - > ctb_width == 0 ) { get_cabac_terminate ( & s - > HEVClc - > cc ) ; if ( s - > threads_number == 1 ) cabac_reinit ( s - > HEVClc ) ; else cabac_init_decoder ( s ) ; if ( s - > ps . sps - > ctb_width == 1 ) cabac_init_state ( s ) ; else load_states ( s ) ; } } } }",1
"int ff_snow_frame_start ( SnowContext * s ) { AVFrame tmp ; int i , ret ; int w= s - > avctx - > width ; //FIXME round up to x16 ? int h= s - > avctx - > height ; if ( s - > current_picture . data[0] & & ! ( s - > avctx - > flags & CODEC_FLAG_EMU_EDGE ) ) { s - > dsp . draw_edges ( s - > current_picture . data[0] , s - > current_picture . linesize[0] , w , h , EDGE_WIDTH , EDGE_WIDTH , EDGE_TOP | EDGE_BOTTOM ) ; s - > dsp . draw_edges ( s - > current_picture . data[1] , s - > current_picture . linesize[1] , w > > s - > chroma_h_shift , h > > s - > chroma_v_shift , EDGE_WIDTH > > s - > chroma_h_shift , EDGE_WIDTH > > s - > chroma_v_shift , EDGE_TOP | EDGE_BOTTOM ) ; s - > dsp . draw_edges ( s - > current_picture . data[2] , s - > current_picture . linesize[2] , w > > s - > chroma_h_shift , h > > s - > chroma_v_shift , EDGE_WIDTH > > s - > chroma_h_shift , EDGE_WIDTH > > s - > chroma_v_shift , EDGE_TOP | EDGE_BOTTOM ) ; } ff_snow_release_buffer ( s - > avctx ) ; av_frame_move_ref ( & tmp , & s - > last_picture[s - > max_ref_frames - 1] ) ; for ( i=s - > max_ref_frames - 1 ; i > 0 ; i - - ) av_frame_move_ref ( & s - > last_picture[i] , & s - > last_picture[i - 1] ) ; memmove ( s - > halfpel_plane + 1 , s - > halfpel_plane , ( s - > max_ref_frames - 1 ) * sizeof ( void * ) * 4 * 4 ) ; if ( USE_HALFPEL_PLANE & & s - > current_picture . data[0] ) halfpel_interpol ( s , s - > halfpel_plane[0] , & s - > current_picture ) ; av_frame_move_ref ( & s - > last_picture[0] , & s - > current_picture ) ; av_frame_move_ref ( & s - > current_picture , & tmp ) ; if ( s - > keyframe ) { s - > ref_frames= 0 ; } else { int i ; for ( i=0 ; i < s - > max_ref_frames & & s - > last_picture[i] . data[0] ; i + + ) if ( i & & s - > last_picture[i - 1] . key_frame ) break ; s - > ref_frames= i ; if ( s - > ref_frames==0 ) { av_log ( s - > avctx , AV_LOG_ERROR , No reference frames\n ) ; return - 1 ; } } if ( ( ret = ff_get_buffer ( s - > avctx , & s - > current_picture , AV_GET_BUFFER_FLAG_REF ) ) < 0 ) return ret ; s - > current_picture . key_frame= s - > keyframe ; return 0 ; }",1
"static int h264_slice_header_parse ( const H264Context * h , H264SliceContext * sl , const H2645NAL * nal ) { const SPS * sps ; const PPS * pps ; int ret ; unsigned int slice_type , tmp , i ; int field_pic_flag , bottom_field_flag ; int first_slice = sl == h - > slice_ctx & & ! h - > current_slice ; int picture_structure ; if ( first_slice ) av_assert0 ( ! h - > setup_finished ) ; sl - > first_mb_addr = get_ue_golomb_long ( & sl - > gb ) ; slice_type = get_ue_golomb_31 ( & sl - > gb ) ; if ( slice_type > 9 ) { av_log ( h - > avctx , AV_LOG_ERROR , slice type %d too large at %d\n , slice_type , sl - > first_mb_addr ) ; return AVERROR_INVALIDDATA ; } if ( slice_type > 4 ) { slice_type - = 5 ; sl - > slice_type_fixed = 1 ; } else sl - > slice_type_fixed = 0 ; slice_type = ff_h264_golomb_to_pict_type[slice_type] ; sl - > slice_type = slice_type ; sl - > slice_type_nos = slice_type & 3 ; if ( nal - > type == H264_NAL_IDR_SLICE & & sl - > slice_type_nos ! = AV_PICTURE_TYPE_I ) { av_log ( h - > avctx , AV_LOG_ERROR , A non - intra slice in an IDR NAL unit . \n ) ; return AVERROR_INVALIDDATA ; } sl - > pps_id = get_ue_golomb ( & sl - > gb ) ; if ( sl - > pps_id > = MAX_PPS_COUNT ) { av_log ( h - > avctx , AV_LOG_ERROR , pps_id %u out of range\n , sl - > pps_id ) ; return AVERROR_INVALIDDATA ; } if ( ! h - > ps . pps_list[sl - > pps_id] ) { av_log ( h - > avctx , AV_LOG_ERROR , non - existing PPS %u referenced\n , sl - > pps_id ) ; return AVERROR_INVALIDDATA ; } pps = ( const PPS * ) h - > ps . pps_list[sl - > pps_id] - > data ; if ( ! h - > ps . sps_list[pps - > sps_id] ) { av_log ( h - > avctx , AV_LOG_ERROR , non - existing SPS %u referenced\n , pps - > sps_id ) ; return AVERROR_INVALIDDATA ; } sps = ( const SPS * ) h - > ps . sps_list[pps - > sps_id] - > data ; sl - > frame_num = get_bits ( & sl - > gb , sps - > log2_max_frame_num ) ; if ( ! first_slice ) { if ( h - > poc . frame_num ! = sl - > frame_num ) { av_log ( h - > avctx , AV_LOG_ERROR , Frame num change from %d to %d\n , h - > poc . frame_num , sl - > frame_num ) ; return AVERROR_INVALIDDATA ; } } sl - > mb_mbaff = 0 ; if ( sps - > frame_mbs_only_flag ) { picture_structure = PICT_FRAME ; } else { if ( ! sps - > direct_8x8_inference_flag & & slice_type == AV_PICTURE_TYPE_B ) { av_log ( h - > avctx , AV_LOG_ERROR , This stream was generated by a broken encoder , invalid 8x8 inference\n ) ; return - 1 ; } field_pic_flag = get_bits1 ( & sl - > gb ) ; if ( field_pic_flag ) { bottom_field_flag = get_bits1 ( & sl - > gb ) ; picture_structure = PICT_TOP_FIELD + bottom_field_flag ; } else { picture_structure = PICT_FRAME ; } } sl - > picture_structure = picture_structure ; sl - > mb_field_decoding_flag = picture_structure ! = PICT_FRAME ; if ( picture_structure == PICT_FRAME ) { sl - > curr_pic_num = sl - > frame_num ; sl - > max_pic_num = 1 < < sps - > log2_max_frame_num ; } else { sl - > curr_pic_num = 2 * sl - > frame_num + 1 ; sl - > max_pic_num = 1 < < ( sps - > log2_max_frame_num + 1 ) ; } if ( nal - > type == H264_NAL_IDR_SLICE ) get_ue_golomb_long ( & sl - > gb ) ; / * idr_pic_id * / if ( sps - > poc_type == 0 ) { sl - > poc_lsb = get_bits ( & sl - > gb , sps - > log2_max_poc_lsb ) ; if ( pps - > pic_order_present == 1 & & picture_structure == PICT_FRAME ) sl - > delta_poc_bottom = get_se_golomb ( & sl - > gb ) ; } if ( sps - > poc_type == 1 & & ! sps - > delta_pic_order_always_zero_flag ) { sl - > delta_poc[0] = get_se_golomb ( & sl - > gb ) ; if ( pps - > pic_order_present == 1 & & picture_structure == PICT_FRAME ) sl - > delta_poc[1] = get_se_golomb ( & sl - > gb ) ; } sl - > redundant_pic_count = 0 ; if ( pps - > redundant_pic_cnt_present ) sl - > redundant_pic_count = get_ue_golomb ( & sl - > gb ) ; if ( sl - > slice_type_nos == AV_PICTURE_TYPE_B ) sl - > direct_spatial_mv_pred = get_bits1 ( & sl - > gb ) ; ret = ff_h264_parse_ref_count ( & sl - > list_count , sl - > ref_count , & sl - > gb , pps , sl - > slice_type_nos , picture_structure , h - > avctx ) ; if ( ret < 0 ) return ret ; if ( sl - > slice_type_nos ! = AV_PICTURE_TYPE_I ) { ret = ff_h264_decode_ref_pic_list_reordering ( sl , h - > avctx ) ; if ( ret < 0 ) { sl - > ref_count[1] = sl - > ref_count[0] = 0 ; return ret ; } } sl - > pwt . use_weight = 0 ; for ( i = 0 ; i < 2 ; i + + ) { sl - > pwt . luma_weight_flag[i] = 0 ; sl - > pwt . chroma_weight_flag[i] = 0 ; } if ( ( pps - > weighted_pred & & sl - > slice_type_nos == AV_PICTURE_TYPE_P ) || ( pps - > weighted_bipred_idc == 1 & & sl - > slice_type_nos == AV_PICTURE_TYPE_B ) ) { ret = ff_h264_pred_weight_table ( & sl - > gb , sps , sl - > ref_count , sl - > slice_type_nos , & sl - > pwt , h - > avctx ) ; if ( ret < 0 ) return ret ; } sl - > explicit_ref_marking = 0 ; if ( nal - > ref_idc ) { ret = ff_h264_decode_ref_pic_marking ( sl , & sl - > gb , nal , h - > avctx ) ; if ( ret < 0 & & ( h - > avctx - > err_recognition & AV_EF_EXPLODE ) ) return AVERROR_INVALIDDATA ; } if ( sl - > slice_type_nos ! = AV_PICTURE_TYPE_I & & pps - > cabac ) { tmp = get_ue_golomb_31 ( & sl - > gb ) ; if ( tmp > 2 ) { av_log ( h - > avctx , AV_LOG_ERROR , cabac_init_idc %u overflow\n , tmp ) ; return AVERROR_INVALIDDATA ; } sl - > cabac_init_idc = tmp ; } sl - > last_qscale_diff = 0",1
"static inline void RENAME ( yuv2rgb565_2 ) ( SwsContext * c , const uint16_t * buf0 , const uint16_t * buf1 , const uint16_t * ubuf0 , const uint16_t * ubuf1 , const uint16_t * vbuf0 , const uint16_t * vbuf1 , const uint16_t * abuf0 , const uint16_t * abuf1 , uint8_t * dest , int dstW , int yalpha , int uvalpha , int y ) { x86_reg uv_off = c - > uv_off < < 1 ; //Note 8280 == DSTW_OFFSET but the preprocessor can ' t handle that there : ( __asm__ volatile ( mov %% REG_b , ESP_OFFSET ( %5 ) \n\t mov %4 , %% REG_b \n\t push %% REG_BP \n\t YSCALEYUV2RGB ( %%REGBP , %5 , %6 ) pxor %%mm7 , %%mm7 \n\t / * mm2=B , %%mm4=G , %%mm5=R , %%mm7=0 * / ifdef DITHER1XBPP paddusb BLUE_DITHER ( %5 ) , %%mm2 \n\t paddusb GREEN_DITHER ( %5 ) , %%mm4 \n\t paddusb RED_DITHER ( %5 ) , %%mm5 \n\t endif WRITERGB16 ( %%REGb , 8280 ( %5 ) , %%REGBP ) pop %% REG_BP \n\t mov ESP_OFFSET ( %5 ) , %% REG_b \n\t : : c ( buf0 ) , d ( buf1 ) , S ( ubuf0 ) , D ( ubuf1 ) , m ( dest ) , a ( & c - > redDither ) , m ( uv_off ) ) ; }",1
"static int mov_write_moov_tag ( AVIOContext * pb , MOVMuxContext * mov , AVFormatContext * s ) { int i ; int64_t pos = avio_tell ( pb ) ; avio_wb32 ( pb , 0 ) ; / * size placeholder * / ffio_wfourcc ( pb , moov ) ; for ( i = 0 ; i < mov - > nb_streams ; i + + ) { if ( mov - > tracks[i] . entry < = 0 & & ! ( mov - > flags & FF_MOV_FLAG_FRAGMENT ) ) continue ; mov - > tracks[i] . time = mov - > time ; mov - > tracks[i] . track_id = i + 1 ; if ( mov - > tracks[i] . entry ) build_chunks ( & mov - > tracks[i] ) ; } if ( mov - > chapter_track ) for ( i = 0 ; i < s - > nb_streams ; i + + ) { mov - > tracks[i] . tref_tag = MKTAG ( ' c ' , ' h ' , ' a ' , ' p ' ) ; mov - > tracks[i] . tref_id = mov - > tracks[mov - > chapter_track] . track_id ; } for ( i = 0 ; i < mov - > nb_streams ; i + + ) { if ( mov - > tracks[i] . tag == MKTAG ( ' r ' , ' t ' , ' p ' , ' ' ) ) { mov - > tracks[i] . tref_tag = MKTAG ( ' h ' , ' i ' , ' n ' , ' t ' ) ; mov - > tracks[i] . tref_id = mov - > tracks[mov - > tracks[i] . src_track] . track_id ; } } for ( i = 0 ; i < mov - > nb_streams ; i + + ) { if ( mov - > tracks[i] . tag == MKTAG ( ' t ' , ' m ' , ' c ' , ' d ' ) ) { int src_trk = mov - > tracks[i] . src_track ; mov - > tracks[src_trk] . tref_tag = mov - > tracks[i] . tag ; mov - > tracks[src_trk] . tref_id = mov - > tracks[i] . track_id ; //src_trk may have a different timescale than the tmcd track mov - > tracks[i] . track_duration = av_rescale ( mov - > tracks[src_trk] . track_duration , mov - > tracks[i] . timescale , mov - > tracks[src_trk] . timescale ) ; } } mov_write_mvhd_tag ( pb , mov ) ; if ( mov - > mode ! = MODE_MOV & & ! mov - > iods_skip ) mov_write_iods_tag ( pb , mov ) ; for ( i = 0 ; i < mov - > nb_streams ; i + + ) { if ( mov - > tracks[i] . entry > 0 || mov - > flags & FF_MOV_FLAG_FRAGMENT ) { mov_write_trak_tag ( pb , mov , & ( mov - > tracks[i] ) , i < s - > nb_streams ? s - > streams[i] : NULL ) ; } } if ( mov - > flags & FF_MOV_FLAG_FRAGMENT ) mov_write_mvex_tag ( pb , mov ) ; / * QuickTime requires trak to precede this * / if ( mov - > mode == MODE_PSP ) mov_write_uuidusmt_tag ( pb , s ) ; else mov_write_udta_tag ( pb , mov , s ) ; return update_size ( pb , pos ) ; }",1
"void FUNC ( ff_simple_idct_put ) ( uint8_t * dest_ , int line_size , DCTELEM * block ) { pixel * dest = ( pixel * ) dest_ ; int i ; line_size /= sizeof ( pixel ) ; for ( i = 0 ; i < 8 ; i + + ) FUNC ( idctRowCondDC ) ( block + i * 8 ) ; for ( i = 0 ; i < 8 ; i + + ) FUNC ( idctSparseColPut ) ( dest + i , line_size , block + i ) ; }",1
"static void quantize_and_encode_band_cost_UPAIR7_mips ( struct AACEncContext * s , PutBitContext * pb , const float * in , float * out , const float * scaled , int size , int scale_idx , int cb , const float lambda , const float uplim , int * bits , const float ROUNDING ) { const float Q34 = ff_aac_pow34sf_tab[POW_SF2_ZERO - scale_idx + SCALE_ONE_POS - SCALE_DIV_512] ; const float IQ = ff_aac_pow2sf_tab [POW_SF2_ZERO + scale_idx - SCALE_ONE_POS + SCALE_DIV_512] ; int i ; int qc1 , qc2 , qc3 , qc4 ; uint8_t * p_bits = ( uint8_t * ) ff_aac_spectral_bits[cb - 1] ; uint16_t * p_codes = ( uint16_t * ) ff_aac_spectral_codes[cb - 1] ; float * p_vec = ( float * ) ff_aac_codebook_vectors[cb - 1] ; abs_pow34_v ( s - > scoefs , in , size ) ; scaled = s - > scoefs ; for ( i = 0 ; i < size ; i + = 4 ) { int curidx1 , curidx2 , sign1 , count1 , sign2 , count2 ; int * in_int = ( int * ) & in[i] ; uint8_t v_bits ; unsigned int v_codes ; int t0 , t1 , t2 , t3 , t4 ; const float * vec1 , * vec2 ; qc1 = scaled[i ] * Q34 + ROUND_STANDARD ; qc2 = scaled[i + 1] * Q34 + ROUND_STANDARD ; qc3 = scaled[i + 2] * Q34 + ROUND_STANDARD ; qc4 = scaled[i + 3] * Q34 + ROUND_STANDARD ; __asm__ volatile ( . set push \n\t . set noreorder \n\t ori %[t4] , zero , 7 \n\t ori %[sign1] , zero , 0 \n\t ori %[sign2] , zero , 0 \n\t slt %[t0] , %[t4] , %[qc1] \n\t slt %[t1] , %[t4] , %[qc2] \n\t slt %[t2] , %[t4] , %[qc3] \n\t slt %[t3] , %[t4] , %[qc4] \n\t movn %[qc1] , %[t4] , %[t0] \n\t movn %[qc2] , %[t4] , %[t1] \n\t movn %[qc3] , %[t4] , %[t2] \n\t movn %[qc4] , %[t4] , %[t3] \n\t lw %[t0] , 0 ( %[in_int] ) \n\t lw %[t1] , 4 ( %[in_int] ) \n\t lw %[t2] , 8 ( %[in_int] ) \n\t lw %[t3] , 12 ( %[in_int] ) \n\t slt %[t0] , %[t0] , zero \n\t movn %[sign1] , %[t0] , %[qc1] \n\t slt %[t2] , %[t2] , zero \n\t movn %[sign2] , %[t2] , %[qc3] \n\t slt %[t1] , %[t1] , zero \n\t sll %[t0] , %[sign1] , 1 \n\t or %[t0] , %[t0] , %[t1] \n\t movn %[sign1] , %[t0] , %[qc2] \n\t slt %[t3] , %[t3] , zero \n\t sll %[t0] , %[sign2] , 1 \n\t or %[t0] , %[t0] , %[t3] \n\t movn %[sign2] , %[t0] , %[qc4] \n\t slt %[count1] , zero , %[qc1] \n\t slt %[t1] , zero , %[qc2] \n\t slt %[count2] , zero , %[qc3] \n\t slt %[t2] , zero , %[qc4] \n\t addu %[count1] , %[count1] , %[t1] \n\t addu %[count2] , %[count2] , %[t2] \n\t . set pop \n\t : [qc1] + r ( qc1 ) , [qc2] + r ( qc2 ) , [qc3] + r ( qc3 ) , [qc4] + r ( qc4 ) , [sign1] = & r ( sign1 ) , [count1] = & r ( count1 ) , [sign2] = & r ( sign2 ) , [count2] = & r ( count2 ) , [t0] = & r ( t0 ) , [t1] = & r ( t1 ) , [t2] = & r ( t2 ) , [t3] = & r ( t3 ) , [t4] = & r ( t4 ) : [in_int] r ( in_int ) : t0 , t1 , t2 , t3 , t4 , memory ) ; curidx1 = 8 * qc1 ; curidx1 + = qc2 ; v_codes = ( p_codes[curidx1] < < count1 ) | sign1 ; v_bits = p_bits[curidx1] + count1 ; put_bits ( pb , v_bits , v_codes ) ; curidx2 = 8 * qc3 ; curidx2 + = qc4 ; v_codes = ( p_codes[curidx2] < < count2 ) | sign2 ; v_bits = p_bits[curidx2] + count2 ; put_bits ( pb , v_bits , v_codes ) ; if ( out ) { vec1 = & p_vec[curidx1 * 2] ; vec2 = & p_vec[curidx2 * 2] ; out[i + 0] = copysignf ( vec1[0] * IQ , in[i + 0] ) ; out[i + 1] = copysignf ( vec1[1] * IQ , in[i + 1] ) ; out[i + 2] = copysignf ( vec2[0] * IQ , in[i + 2] ) ; out[i + 3] = copysignf ( vec2[1] * IQ , in[i + 3] ) ; } } }",1
"static int rtmp_packet_read_one_chunk ( URLContext * h , RTMPPacket * p , int chunk_size , RTMPPacket * * prev_pkt_ptr , int * nb_prev_pkt , uint8_t hdr ) { uint8_t buf[16] ; int channel_id , timestamp , size ; uint32_t ts_field ; // non - extended timestamp or delta field uint32_t extra = 0 ; enum RTMPPacketType type ; int written = 0 ; int ret , toread ; RTMPPacket * prev_pkt ; written + + ; channel_id = hdr & 0x3F ; if ( channel_id < 2 ) { //special case for channel number > = 64 buf[1] = 0 ; if ( ffurl_read_complete ( h , buf , channel_id + 1 ) ! = channel_id + 1 ) return AVERROR ( EIO ) ; written + = channel_id + 1 ; channel_id = AV_RL16 ( buf ) + 64 ; } if ( ( ret = ff_rtmp_check_alloc_array ( prev_pkt_ptr , nb_prev_pkt , channel_id ) ) < 0 ) return ret ; prev_pkt = * prev_pkt_ptr ; size = prev_pkt[channel_id] . size ; type = prev_pkt[channel_id] . type ; extra = prev_pkt[channel_id] . extra ; hdr > > = 6 ; // header size indicator if ( hdr == RTMP_PS_ONEBYTE ) { ts_field = prev_pkt[channel_id] . ts_field ; } else { if ( ffurl_read_complete ( h , buf , 3 ) ! = 3 ) return AVERROR ( EIO ) ; written + = 3 ; ts_field = AV_RB24 ( buf ) ; if ( hdr ! = RTMP_PS_FOURBYTES ) { if ( ffurl_read_complete ( h , buf , 3 ) ! = 3 ) return AVERROR ( EIO ) ; written + = 3 ; size = AV_RB24 ( buf ) ; if ( ffurl_read_complete ( h , buf , 1 ) ! = 1 ) return AVERROR ( EIO ) ; written + + ; type = buf[0] ; if ( hdr == RTMP_PS_TWELVEBYTES ) { if ( ffurl_read_complete ( h , buf , 4 ) ! = 4 ) return AVERROR ( EIO ) ; written + = 4 ; extra = AV_RL32 ( buf ) ; } } } if ( ts_field == 0xFFFFFF ) { if ( ffurl_read_complete ( h , buf , 4 ) ! = 4 ) return AVERROR ( EIO ) ; timestamp = AV_RB32 ( buf ) ; } else { timestamp = ts_field ; } if ( hdr ! = RTMP_PS_TWELVEBYTES ) timestamp + = prev_pkt[channel_id] . timestamp ; if ( ! prev_pkt[channel_id] . read ) { if ( ( ret = ff_rtmp_packet_create ( p , channel_id , type , timestamp , size ) ) < 0 ) return ret ; p - > read = written ; p - > offset = 0 ; prev_pkt[channel_id] . ts_field = ts_field ; prev_pkt[channel_id] . timestamp = timestamp ; } else { // previous packet in this channel hasn ' t completed reading RTMPPacket * prev = & prev_pkt[channel_id] ; p - > data = prev - > data ; p - > size = prev - > size ; p - > channel_id = prev - > channel_id ; p - > type = prev - > type ; p - > ts_field = prev - > ts_field ; p - > extra = prev - > extra ; p - > offset = prev - > offset ; p - > read = prev - > read + written ; p - > timestamp = prev - > timestamp ; prev - > data = NULL ; } p - > extra = extra ; // save history prev_pkt[channel_id] . channel_id = channel_id ; prev_pkt[channel_id] . type = type ; prev_pkt[channel_id] . size = size ; prev_pkt[channel_id] . extra = extra ; size = size - p - > offset ; toread = FFMIN ( size , chunk_size ) ; if ( ffurl_read_complete ( h , p - > data + p - > offset , toread ) ! = toread ) { ff_rtmp_packet_destroy ( p ) ; return AVERROR ( EIO ) ; } size - = toread ; p - > read + = toread ; p - > offset + = toread ; if ( size > 0 ) { RTMPPacket * prev = & prev_pkt[channel_id] ; prev - > data = p - > data ; prev - > read = p - > read ; prev - > offset = p - > offset ; return AVERROR ( EAGAIN ) ; } prev_pkt[channel_id] . read = 0 ; // read complete ; reset if needed return p - > read ; }",1
"int ff_h264_execute_ref_pic_marking ( H264Context * h , MMCO * mmco , int mmco_count ) { int i , av_uninit ( j ) ; int current_ref_assigned = 0 , err = 0 ; Picture * av_uninit ( pic ) ; if ( ( h - > avctx - > debug & FF_DEBUG_MMCO ) & & mmco_count == 0 ) av_log ( h - > avctx , AV_LOG_DEBUG , no mmco here\n ) ; for ( i = 0 ; i < mmco_count ; i + + ) { int av_uninit ( structure ) , av_uninit ( frame_num ) ; if ( h - > avctx - > debug & FF_DEBUG_MMCO ) av_log ( h - > avctx , AV_LOG_DEBUG , mmco : %d %d %d\n , h - > mmco[i] . opcode , h - > mmco[i] . short_pic_num , h - > mmco[i] . long_arg ) ; if ( mmco[i] . opcode == MMCO_SHORT2UNUSED || mmco[i] . opcode == MMCO_SHORT2LONG ) { frame_num = pic_num_extract ( h , mmco[i] . short_pic_num , & structure ) ; pic = find_short ( h , frame_num , & j ) ; if ( ! pic ) { if ( mmco[i] . opcode ! = MMCO_SHORT2LONG || ! h - > long_ref[mmco[i] . long_arg] || h - > long_ref[mmco[i] . long_arg] - > frame_num ! = frame_num ) { av_log ( h - > avctx , AV_LOG_ERROR , mmco : unref short failure\n ) ; err = AVERROR_INVALIDDATA ; continue ; switch ( mmco[i] . opcode ) { case MMCO_SHORT2UNUSED : if ( h - > avctx - > debug & FF_DEBUG_MMCO ) av_log ( h - > avctx , AV_LOG_DEBUG , mmco : unref short %d count %d\n , h - > mmco[i] . short_pic_num , h - > short_ref_count ) ; remove_short ( h , frame_num , structure PICT_FRAME ) ; break ; case MMCO_SHORT2LONG : if ( h - > long_ref[mmco[i] . long_arg] ! = pic ) remove_long ( h , mmco[i] . long_arg , 0 ) ; remove_short_at_index ( h , j ) ; h - > long_ref[ mmco[i] . long_arg ] = pic ; if ( h - > long_ref[mmco[i] . long_arg] ) { h - > long_ref[mmco[i] . long_arg] - > long_ref = 1 ; h - > long_ref_count + + ; break ; case MMCO_LONG2UNUSED : j = pic_num_extract ( h , mmco[i] . long_arg , & structure ) ; pic = h - > long_ref[j] ; if ( pic ) { remove_long ( h , j , structure PICT_FRAME ) ; } else if ( h - > avctx - > debug & FF_DEBUG_MMCO ) av_log ( h - > avctx , AV_LOG_DEBUG , mmco : unref long failure\n ) ; break ; case MMCO_LONG : // Comment below left from previous code as it is an interresting note . / * First field in pair is in short term list or * at a different long term index . * This is not allowed ; see 7 . 4 . 3 . 3 , notes 2 and 3 . * Report the problem and keep the pair where it is , * and mark this field valid . * / if ( h - > long_ref[mmco[i] . long_arg] ! = h - > cur_pic_ptr ) { remove_long ( h , mmco[i] . long_arg , 0 ) ; h - > long_ref[mmco[i] . long_arg] = h - > cur_pic_ptr ; h - > long_ref[mmco[i] . long_arg] - > long_ref = 1 ; h - > long_ref_count + + ; h - > cur_pic_ptr - > reference |= h - > picture_structure ; current_ref_assigned = 1 ; break ; case MMCO_SET_MAX_LONG : assert ( mmco[i] . long_arg < = 16 ) ; // just remove the long term which index is greater than new max for ( j = mmco[i] . long_arg ; j < 16 ; j + + ) { remove_long ( h , j , 0 ) ; break ; case MMCO_RESET : while ( h - > short_ref_count ) { remove_short ( h , h - > short_ref[0] - > frame_num , 0 ) ; for ( j = 0 ; j < 16 ; j + + ) { remove_long ( h , j , 0 ) ; h - > frame_num = h - > cur_pic_ptr - > frame_num = 0 ; h - > mmco_reset = 1 ; h - > cur_pic_ptr - > mmco_reset = 1 ; for ( j = 0 ; j < MAX_DELAYED_PIC_COUNT ; j + + ) h - > last_pocs[j] = INT_MIN ; break ; default : assert ( 0 ) ; if ( ! current_ref_assigned ) { / * Second field of complementary field pair ; the first field of * which is already referenced . If short referenced , it * should be first entry in short_ref . If not , it must exist * in long_ref ; trying to put it on the short list here is an * error in the encoded bit stream ( ref : 7 . 4 . 3 . 3 , NOTE 2 and 3 ) . * / if ( h - > short_ref_count & & h - > short_ref[0] == h - > cur_pic_ptr ) { / * Just mark the second field valid * / h - > cur_pic_ptr - > reference = PICT_FRAME ; } else if ( h - > cur_pic_ptr - > long_ref ) { av_log ( h - > avctx , AV_LOG_ERROR , illegal short term reference assignment for second field in complementary field pair ( first field is long term ) \n ) ; err = AVERROR_INVALIDDATA ; } else { pic = remove_short ( h , h - > cur_pic_ptr - > frame_num , 0 ) ; if ( pic ) { av_log ( h - > avctx , AV_LOG_ERROR , illegal short term buffer state detected\n ) ; err = AVERROR_INVALIDDATA ; if ( h - > short_ref_count ) memmove ( & h - > short_ref[1] , & h - > short_ref[0] , h - > short_ref_count * sizeof ( Picture * ) ) ; h - > short_ref[0] = h - > cur_pic_ptr ; h - > short_ref_count + + ; h - > cur_pic_ptr - > reference |= h - > picture_structure ; if ( h - > long_ref_count + h - > short_ref_count > FFMAX ( h - > sps . ref_frame_count , 1 ) ) { / * We have too many reference frames , probably due to corrupted * stream . Need to discard one frame . Prevents overrun of the * short_ref and long_ref buffers . * / av_log ( h - > avctx , AV_LOG_ERROR , number of reference frames ( %d + %d ) exceeds max ( %d ; probably corrupt input ) , discarding one\n , h - > long_ref_count , h - > short_ref_count , h - > sps . ref_frame_count ) ; err = AVERROR_INVALIDDATA ; if ( h - > long_ref_count & & ! h - > short_ref_count ) { for ( i = 0 ; i < 16 ; + + i )",1
"void * av_tree_insert ( AVTreeNode * * tp , void * key , int ( * cmp ) ( void * key , const void * b ) , AVTreeNode * * next ) { AVTreeNode * t= * tp ; if ( t ) { unsigned int v= cmp ( t - > elem , key ) ; void * ret ; if ( ! v ) { if ( * next ) return t - > elem ; else if ( t - > child[0]||t - > child[1] ) { int i= ! t - > child[0] ; void * next_elem[2] ; av_tree_find ( t - > child[i] , key , cmp , next_elem ) ; key= t - > elem= next_elem[i] ; v= - i ; } else { * next= t ; * tp=NULL ; return NULL ; } } ret= av_tree_insert ( & t - > child[v > > 31] , key , cmp , next ) ; if ( ! ret ) { int i= ( v > > 31 ) ! ! * next ; AVTreeNode * * child= & t - > child[i] ; t - > state + = 2 * i - 1 ; if ( ! ( t - > state & 1 ) ) { if ( t - > state ) { / * The following code is equivalent to if ( ( * child ) - > state * 2 == - t - > state ) rotate ( child , i 1 ) ; rotate ( tp , i ) ; with rotate ( ) : static void rotate ( AVTreeNode * * tp , int i ) { AVTreeNode * t= * tp ; * tp= t - > child[i] ; t - > child[i]= t - > child[i] - > child[i 1] ; ( * tp ) - > child[i 1]= t ; i= 4 * t - > state + 2 * ( * tp ) - > state + 12 ; t - > state= ( ( 0x614586 > > i ) & 3 ) - 1 ; ( * tp ) - > state= ( ( * tp ) - > state > > 1 ) + ( ( 0x400EEA > > i ) & 3 ) - 1 ; } but such a rotate function is both bigger and slower * / if ( ( * child ) - > state * 2 == - t - > state ) { * tp= ( * child ) - > child[i 1] ; ( * child ) - > child[i 1]= ( * tp ) - > child[i] ; ( * tp ) - > child[i]= * child ; * child= ( * tp ) - > child[i 1] ; ( * tp ) - > child[i 1]= t ; ( * tp ) - > child[0] - > state= - ( ( * tp ) - > state > 0 ) ; ( * tp ) - > child[1] - > state= ( * tp ) - > state < 0 ; ( * tp ) - > state=0 ; } else { * tp= * child ; * child= ( * child ) - > child[i 1] ; ( * tp ) - > child[i 1]= t ; if ( ( * tp ) - > state ) t - > state = 0 ; else t - > state > > = 1 ; ( * tp ) - > state= - t - > state ; } } } if ( ! ( * tp ) - > state ! ! * next ) return key ; } return ret ; } else { * tp= * next ; * next= NULL ; ( * tp ) - > elem= key ; return NULL ; } }",1
"static inline void RENAME ( hyscale ) ( SwsContext * c , uint16_t * dst , long dstWidth , uint8_t * src , int srcW , int xInc , int flags , int canMMX2BeUsed , int16_t * hLumFilter , int16_t * hLumFilterPos , int hLumFilterSize , void * funnyYCode , int srcFormat , uint8_t * formatConvBuffer , int16_t * mmx2Filter , int32_t * mmx2FilterPos , uint8_t * pal ) { if ( srcFormat==PIX_FMT_YUYV422 || srcFormat==PIX_FMT_GRAY16BE ) { RENAME ( yuy2ToY ) ( formatConvBuffer , src , srcW ) ; src= formatConvBuffer ; } else if ( srcFormat==PIX_FMT_UYVY422 || srcFormat==PIX_FMT_GRAY16LE ) { RENAME ( uyvyToY ) ( formatConvBuffer , src , srcW ) ; src= formatConvBuffer ; } else if ( srcFormat==PIX_FMT_RGB32 ) { RENAME ( bgr32ToY ) ( formatConvBuffer , src , srcW ) ; src= formatConvBuffer ; } else if ( srcFormat==PIX_FMT_RGB32_1 ) { RENAME ( bgr32ToY ) ( formatConvBuffer , src + ALT32_CORR , srcW ) ; src= formatConvBuffer ; } else if ( srcFormat==PIX_FMT_BGR24 ) { RENAME ( bgr24ToY ) ( formatConvBuffer , src , srcW ) ; src= formatConvBuffer ; } else if ( srcFormat==PIX_FMT_BGR565 ) { RENAME ( bgr16ToY ) ( formatConvBuffer , src , srcW ) ; src= formatConvBuffer ; } else if ( srcFormat==PIX_FMT_BGR555 ) { RENAME ( bgr15ToY ) ( formatConvBuffer , src , srcW ) ; src= formatConvBuffer ; } else if ( srcFormat==PIX_FMT_BGR32 ) { RENAME ( rgb32ToY ) ( formatConvBuffer , src , srcW ) ; src= formatConvBuffer ; } else if ( srcFormat==PIX_FMT_BGR32_1 ) { RENAME ( rgb32ToY ) ( formatConvBuffer , src + ALT32_CORR , srcW ) ; src= formatConvBuffer ; } else if ( srcFormat==PIX_FMT_RGB24 ) { RENAME ( rgb24ToY ) ( formatConvBuffer , src , srcW ) ; src= formatConvBuffer ; } else if ( srcFormat==PIX_FMT_RGB565 ) { RENAME ( rgb16ToY ) ( formatConvBuffer , src , srcW ) ; src= formatConvBuffer ; } else if ( srcFormat==PIX_FMT_RGB555 ) { RENAME ( rgb15ToY ) ( formatConvBuffer , src , srcW ) ; src= formatConvBuffer ; } else if ( srcFormat==PIX_FMT_RGB8 || srcFormat==PIX_FMT_BGR8 || srcFormat==PIX_FMT_PAL8 || srcFormat==PIX_FMT_BGR4_BYTE || srcFormat==PIX_FMT_RGB4_BYTE ) { RENAME ( palToY ) ( formatConvBuffer , src , srcW , ( uint32_t * ) pal ) ; src= formatConvBuffer ; } ifdef HAVE_MMX // Use the new MMX scaler if the MMX2 one can ' t be used ( it is faster than the x86 ASM one ) . if ( ! ( flags & SWS_FAST_BILINEAR ) || ( ! canMMX2BeUsed ) ) else if ( ! ( flags & SWS_FAST_BILINEAR ) ) endif { RENAME ( hScale ) ( dst , dstWidth , src , srcW , xInc , hLumFilter , hLumFilterPos , hLumFilterSize ) ; } else // fast bilinear upscale / crap downscale { if defined ( ARCH_X86 ) ifdef HAVE_MMX2 int i ; if defined ( PIC ) uint64_t ebxsave __attribute__ ( ( aligned ( 8 ) ) ) ; endif if ( canMMX2BeUsed ) { asm volatile ( if defined ( PIC ) mov %% REG_b , %5 \n\t endif pxor %%mm7 , %%mm7 \n\t mov %0 , %% REG_c \n\t mov %1 , %% REG_D \n\t mov %2 , %% REG_d \n\t mov %3 , %% REG_b \n\t xor %% REG_a , %% REG_a \n\t // i PREFETCH ( %% REG_c ) \n\t PREFETCH 32 ( %% REG_c ) \n\t PREFETCH 64 ( %% REG_c ) \n\t ifdef ARCH_X86_64 define FUNNY_Y_CODE \ movl ( %% REG_b ) , %%esi \n\t \ call * %4 \n\t \ movl ( %% REG_b , %% REG_a ) , %%esi \n\t \ add %% REG_S , %% REG_c \n\t \ add %% REG_a , %% REG_D \n\t \ xor %% REG_a , %% REG_a \n\t \ else define FUNNY_Y_CODE \ movl ( %% REG_b ) , %%esi \n\t \ call * %4 \n\t \ addl ( %% REG_b , %% REG_a ) , %% REG_c \n\t \ add %% REG_a , %% REG_D \n\t \ xor %% REG_a , %% REG_a \n\t \ endif / * ARCH_X86_64 * / FUNNY_Y_CODE FUNNY_Y_CODE FUNNY_Y_CODE FUNNY_Y_CODE FUNNY_Y_CODE FUNNY_Y_CODE FUNNY_Y_CODE FUNNY_Y_CODE if defined ( PIC ) mov %5 , %% REG_b \n\t endif : : m ( src ) , m ( dst ) , m ( mmx2Filter ) , m ( mmx2FilterPos ) , m ( funnyYCode ) if defined ( PIC ) , m ( ebxsave ) endif : % REG_a , % REG_c , % REG_d , % REG_S , % REG_D if ! defined ( PIC ) , % REG_b endif ) ; for ( i=dstWidth - 1 ; ( i * xInc ) > > 16 > =srcW - 1 ; i - - ) dst[i] = src[srcW - 1] * 128 ; } else { endif / * HAVE_MMX2 * / long xInc_shr16 = xInc > > 16 ; uint16_t xInc_mask = xInc & 0xffff ; //NO MMX just normal asm . . . asm volatile ( xor %% REG_a , %% REG_a \n\t // i xor %% REG_d , %% REG_d \n\t // xx xorl %%ecx , %%ecx \n\t // 2 * xalpha ASMALIGN ( 4 ) 1 : \n\t movzbl ( %0 , %% REG_d ) , %%edi \n\t //src[xx] movzbl 1 ( %0 , %% REG_d ) , %%esi \n\t //src[xx + 1] subl %%edi , %%esi \n\t //src[xx + 1] - src[xx] imull %%ecx , %%esi \n\t // ( src[xx + 1] - src[xx] ) * 2 * xalpha shll 16 , %%edi \n\t addl %%edi , %%esi \n\t //src[xx + 1] * 2 * xalpha + src[xx] * ( 1 - 2 * xalpha ) mov %1 , %% REG_D \n\t shrl 9 , %%esi \n\t movw %%si , ( %% REG_D , %% REG_a , 2 ) \n\t addw %4 , %%cx \n\t //2 * xalpha + = xInc & 0xFF adc %3 , %% REG_d \n\t //xx + = xInc > > 8 + carry movzbl ( %0 , %% REG_d ) , %%edi \n\t //src[xx] movzbl 1 ( %0 , %% REG_d ) , %%esi \n\t //src[xx + 1] subl %%edi , %%esi \n\t //src[xx + 1] - src[xx] imull %%ecx , %%esi \n\t // ( src[xx + 1] - src[xx] ) * 2 * xalpha shll 16 , %%edi \n\t addl %%edi , %%esi \n\t //src[xx + 1] * 2 * xalpha + src[xx] * ( 1 - 2 * xalpha ) mov %1 , %% REG_D \n\t shrl 9 , %%esi \n\t movw %%si , 2 ( %% REG_D , %% REG_a , 2 ) \n\t addw %4 , %%cx \n\t //2 * xalpha + = xInc & 0xFF adc %3 , %% REG_d \n\t //xx + = xInc > > 8 + carry add 2 , %% REG_a \n\t cmp %2 , %% REG_a \n\t jb 1b \n\t : : r ( src ) , m ( dst ) , m ( dstWidth ) , m ( xInc_shr16 ) , m ( xInc_mask ) : % REG_a , % REG_d , %ecx , % REG_D , %esi ) ; ifdef HAVE_MMX2 } //if MMX2 can ' t be used endif else int i ; unsigned int xpos=0 ; for",1
"static int applehttp_read_header ( AVFormatContext * s , AVFormatParameters * ap ) { AppleHTTPContext * c = s - > priv_data ; int ret = 0 , i , j , stream_offset = 0 ; if ( ( ret = parse_playlist ( c , s - > filename , NULL , s - > pb ) ) < 0 ) goto fail ; if ( c - > n_variants == 0 ) { av_log ( NULL , AV_LOG_WARNING , Empty playlist\n ) ; ret = AVERROR_EOF ; goto fail ; } / * If the playlist only contained variants , parse each individual * variant playlist . * / if ( c - > n_variants > 1 || c - > variants[0] - > n_segments == 0 ) { for ( i = 0 ; i < c - > n_variants ; i + + ) { struct variant * v = c - > variants[i] ; if ( ( ret = parse_playlist ( c , v - > url , v , NULL ) ) < 0 ) goto fail ; } } if ( c - > variants[0] - > n_segments == 0 ) { av_log ( NULL , AV_LOG_WARNING , Empty playlist\n ) ; ret = AVERROR_EOF ; goto fail ; } / * If this isn ' t a live stream , calculate the total duration of the * stream . * / if ( c - > finished ) { int duration = 0 ; for ( i = 0 ; i < c - > variants[0] - > n_segments ; i + + ) duration + = c - > variants[0] - > segments[i] - > duration ; s - > duration = duration * AV_TIME_BASE ; } c - > min_end_seq = INT_MAX ; / * Open the demuxer for each variant * / for ( i = 0 ; i < c - > n_variants ; i + + ) { struct variant * v = c - > variants[i] ; if ( v - > n_segments == 0 ) continue ; c - > max_start_seq = FFMAX ( c - > max_start_seq , v - > start_seq_no ) ; c - > min_end_seq = FFMIN ( c - > min_end_seq , v - > start_seq_no + v - > n_segments ) ; ret = av_open_input_file ( & v - > ctx , v - > segments[0] - > url , NULL , 0 , NULL ) ; if ( ret < 0 ) goto fail ; url_fclose ( v - > ctx - > pb ) ; v - > ctx - > pb = NULL ; v - > stream_offset = stream_offset ; / * Create new AVStreams for each stream in this variant * / for ( j = 0 ; j < v - > ctx - > nb_streams ; j + + ) { AVStream * st = av_new_stream ( s , i ) ; if ( ! st ) { ret = AVERROR ( ENOMEM ) ; goto fail ; } avcodec_copy_context ( st - > codec , v - > ctx - > streams[j] - > codec ) ; } stream_offset + = v - > ctx - > nb_streams ; } c - > last_packet_dts = AV_NOPTS_VALUE ; c - > cur_seq_no = c - > max_start_seq ; / * If this is a live stream with more than 3 segments , start at the * third last segment . * / if ( ! c - > finished & & c - > min_end_seq - c - > max_start_seq > 3 ) c - > cur_seq_no = c - > min_end_seq - 2 ; return 0 ; fail : free_variant_list ( c ) ; return ret ; }",1
"static int nvenc_encode_frame ( AVCodecContext * avctx , AVPacket * pkt , const AVFrame * frame , int * got_packet ) { NVENCSTATUS nv_status ; NvencOutputSurface * tmpoutsurf ; int res , i = 0 ; NvencContext * ctx = avctx - > priv_data ; NvencDynLoadFunctions * dl_fn = & ctx - > nvenc_dload_funcs ; NV_ENCODE_API_FUNCTION_LIST * p_nvenc = & dl_fn - > nvenc_funcs ; NV_ENC_PIC_PARAMS pic_params = { 0 } ; pic_params . version = NV_ENC_PIC_PARAMS_VER ; if ( frame ) { NV_ENC_LOCK_INPUT_BUFFER lockBufferParams = { 0 } ; NvencInputSurface * inSurf = NULL ; for ( i = 0 ; i < ctx - > max_surface_count ; + + i ) { if ( ! ctx - > input_surfaces[i] . lockCount ) { inSurf = & ctx - > input_surfaces[i] ; break ; } } av_assert0 ( inSurf ) ; inSurf - > lockCount = 1 ; lockBufferParams . version = NV_ENC_LOCK_INPUT_BUFFER_VER ; lockBufferParams . inputBuffer = inSurf - > input_surface ; nv_status = p_nvenc - > nvEncLockInputBuffer ( ctx - > nvencoder , & lockBufferParams ) ; if ( nv_status ! = NV_ENC_SUCCESS ) { av_log ( avctx , AV_LOG_ERROR , Failed locking nvenc input buffer\n ) ; return 0 ; } if ( avctx - > pix_fmt == AV_PIX_FMT_YUV420P ) { uint8_t * buf = lockBufferParams . bufferDataPtr ; av_image_copy_plane ( buf , lockBufferParams . pitch , frame - > data[0] , frame - > linesize[0] , avctx - > width , avctx - > height ) ; buf + = inSurf - > height * lockBufferParams . pitch ; av_image_copy_plane ( buf , lockBufferParams . pitch > > 1 , frame - > data[2] , frame - > linesize[2] , avctx - > width > > 1 , avctx - > height > > 1 ) ; buf + = ( inSurf - > height * lockBufferParams . pitch ) > > 2 ; av_image_copy_plane ( buf , lockBufferParams . pitch > > 1 , frame - > data[1] , frame - > linesize[1] , avctx - > width > > 1 , avctx - > height > > 1 ) ; } else if ( avctx - > pix_fmt == AV_PIX_FMT_NV12 ) { uint8_t * buf = lockBufferParams . bufferDataPtr ; av_image_copy_plane ( buf , lockBufferParams . pitch , frame - > data[0] , frame - > linesize[0] , avctx - > width , avctx - > height ) ; buf + = inSurf - > height * lockBufferParams . pitch ; av_image_copy_plane ( buf , lockBufferParams . pitch , frame - > data[1] , frame - > linesize[1] , avctx - > width , avctx - > height > > 1 ) ; } else if ( avctx - > pix_fmt == AV_PIX_FMT_YUV444P ) { uint8_t * buf = lockBufferParams . bufferDataPtr ; av_image_copy_plane ( buf , lockBufferParams . pitch , frame - > data[0] , frame - > linesize[0] , avctx - > width , avctx - > height ) ; buf + = inSurf - > height * lockBufferParams . pitch ; av_image_copy_plane ( buf , lockBufferParams . pitch , frame - > data[1] , frame - > linesize[1] , avctx - > width , avctx - > height ) ; buf + = inSurf - > height * lockBufferParams . pitch ; av_image_copy_plane ( buf , lockBufferParams . pitch , frame - > data[2] , frame - > linesize[2] , avctx - > width , avctx - > height ) ; } else { av_log ( avctx , AV_LOG_FATAL , Invalid pixel format ! \n ) ; return AVERROR ( EINVAL ) ; } nv_status = p_nvenc - > nvEncUnlockInputBuffer ( ctx - > nvencoder , inSurf - > input_surface ) ; if ( nv_status ! = NV_ENC_SUCCESS ) { av_log ( avctx , AV_LOG_FATAL , Failed unlocking input buffer ! \n ) ; return AVERROR_EXTERNAL ; } for ( i = 0 ; i < ctx - > max_surface_count ; + + i ) if ( ! ctx - > output_surfaces[i] . busy ) break ; if ( i == ctx - > max_surface_count ) { inSurf - > lockCount = 0 ; av_log ( avctx , AV_LOG_FATAL , No free output surface found ! \n ) ; return AVERROR_EXTERNAL ; } ctx - > output_surfaces[i] . input_surface = inSurf ; pic_params . inputBuffer = inSurf - > input_surface ; pic_params . bufferFmt = inSurf - > format ; pic_params . inputWidth = avctx - > width ; pic_params . inputHeight = avctx - > height ; pic_params . outputBitstream = ctx - > output_surfaces[i] . output_surface ; pic_params . completionEvent = 0 ; if ( avctx - > flags & AV_CODEC_FLAG_INTERLACED_DCT ) { if ( frame - > top_field_first ) { pic_params . pictureStruct = NV_ENC_PIC_STRUCT_FIELD_TOP_BOTTOM ; } else { pic_params . pictureStruct = NV_ENC_PIC_STRUCT_FIELD_BOTTOM_TOP ; } } else { pic_params . pictureStruct = NV_ENC_PIC_STRUCT_FRAME ; } pic_params . encodePicFlags = 0 ; pic_params . inputTimeStamp = frame - > pts ; pic_params . inputDuration = 0 ; switch ( avctx - > codec - > id ) { case AV_CODEC_ID_H264 : pic_params . codecPicParams . h264PicParams . sliceMode = ctx - > encode_config . encodeCodecConfig . h264Config . sliceMode ; pic_params . codecPicParams . h264PicParams . sliceModeData = ctx - > encode_config . encodeCodecConfig . h264Config . sliceModeData ; break ; case AV_CODEC_ID_H265 : pic_params . codecPicParams . hevcPicParams . sliceMode = ctx - > encode_config . encodeCodecConfig . hevcConfig . sliceMode ; pic_params . codecPicParams . hevcPicParams . sliceModeData = ctx - > encode_config . encodeCodecConfig . hevcConfig . sliceModeData ; break ; default : av_log ( avctx , AV_LOG_ERROR , Unknown codec name\n ) ; return AVERROR ( EINVAL ) ; } res = timestamp_queue_enqueue ( & ctx - > timestamp_list , frame - > pts ) ; if ( res ) return res ; } else { pic_params . encodePicFlags = NV_ENC_PIC_FLAG_EOS ; } nv_status = p_nvenc - > nvEncEncodePicture ( ctx - > nvencoder , & pic_params ) ; if ( frame & & nv_status == NV_ENC_ERR_NEED_MORE_INPUT ) { res = out_surf_queue_enqueue ( & ctx - > output_surface_queue , & ctx - > output_surfaces[i] ) ; if ( res ) return res ; ctx - > output_surfaces[i] . busy = 1 ; } if ( nv_status ! = NV_ENC_SUCCESS & & nv_status ! = NV_ENC_ERR_NEED_MORE_INPUT ) { av_log ( avctx , AV_LOG_ERROR , EncodePicture failed ! \n ) ; return AVERROR_EXTERNAL ; } if ( nv_status ! = NV_ENC_ERR_NEED_MORE_INPUT ) { while ( ctx - > output_surface_queue . count ) { tmpoutsurf = out_surf_queue_dequeue ( & ctx - > output_surface_queue ) ; res = out_surf_queue_enqueue ( & ctx - > output_surface_ready_queue , tmpoutsurf ) ; if ( res ) return res ; } if ( frame ) { res = out_surf_queue_enqueue ( & ctx - > output_surface_ready_queue , & ctx - > output_surfaces[i] ) ; if ( res ) return res ; ctx - > output_surfaces[i] . busy = 1 ; } } if ( ctx - > output_surface_ready_queue . count & & ( ! frame || ctx - > output_surface_ready_queue . count + ctx - > output_surface_queue . count > = ctx",1
"static int mov_read_glbl ( MOVContext * c , ByteIOContext * pb , MOVAtom atom ) { AVStream * st = c - > fc - > streams[c - > fc - > nb_streams - 1] ; if ( ( uint64_t ) atom . size > ( 1 < < 30 ) ) return - 1 ; av_free ( st - > codec - > extradata ) ; st - > codec - > extradata = av_mallocz ( atom . size + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! st - > codec - > extradata ) return AVERROR ( ENOMEM ) ; st - > codec - > extradata_size = atom . size ; get_buffer ( pb , st - > codec - > extradata , atom . size ) ; return 0 ; }",0
"static uint64_t find_any_startcode ( ByteIOContext * bc , int64_t pos ) { uint64_t state=0 ; if ( pos > = 0 ) url_fseek ( bc , pos , SEEK_SET ) ; //note , this may fail if the stream isnt seekable , but that shouldnt matter , as in this case we simply start where we are currently while ( bytes_left ( bc ) ) { state= ( state < < 8 ) | get_byte ( bc ) ; if ( ( state > > 56 ) ! = ' N ' ) continue ; switch ( state ) { case MAIN_STARTCODE : case STREAM_STARTCODE : case KEYFRAME_STARTCODE : case INFO_STARTCODE : case INDEX_STARTCODE : return state ; } } return 0 ; }",0
"static void ape_unpack_stereo ( APEContext * ctx , int count ) { int32_t left , right ; int32_t * decoded0 = ctx - > decoded[0] ; int32_t * decoded1 = ctx - > decoded[1] ; if ( ctx - > frameflags & APE_FRAMECODE_STEREO_SILENCE ) { / * We are pure silence , so we ' re done . * / av_log ( ctx - > avctx , AV_LOG_DEBUG , pure silence stereo\n ) ; return ; } entropy_decode ( ctx , count , 1 ) ; ape_apply_filters ( ctx , decoded0 , decoded1 , count ) ; / * Now apply the predictor decoding * / predictor_decode_stereo ( ctx , count ) ; / * Decorrelate and scale to output depth * / while ( count - - ) { left = * decoded1 - ( * decoded0 / 2 ) ; right = left + * decoded0 ; * ( decoded0 + + ) = left ; * ( decoded1 + + ) = right ; } }",0
"static int jpeg2000_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { Jpeg2000DecoderContext * s = avctx - > priv_data ; ThreadFrame frame = { . f = data } ; AVFrame * picture = data ; int tileno , ret ; s - > avctx = avctx ; s - > buf = s - > buf_start = avpkt - > data ; s - > buf_end = s - > buf_start + avpkt - > size ; s - > curtileno = 0 ; // TODO : only one tile in DCI JP2K . to implement for more tiles // reduction factor , i . e number of resolution levels to skip s - > reduction_factor = s - > lowres ; ff_jpeg2000_init_tier1_luts ( ) ; if ( s - > buf_end - s - > buf < 2 ) return AVERROR ( EINVAL ) ; // check if the image is in jp2 format if ( ( AV_RB32 ( s - > buf ) == 12 ) & & ( AV_RB32 ( s - > buf + 4 ) == JP2_SIG_TYPE ) & & ( AV_RB32 ( s - > buf + 8 ) == JP2_SIG_VALUE ) ) { if ( ! jp2_find_codestream ( s ) ) { av_log ( avctx , AV_LOG_ERROR , couldn ' t find jpeg2k codestream atom\n ) ; return - 1 ; } } if ( bytestream_get_be16 ( & s - > buf ) ! = JPEG2000_SOC ) { av_log ( avctx , AV_LOG_ERROR , SOC marker not present\n ) ; return - 1 ; } if ( ret = jpeg2000_read_main_headers ( s ) ) goto end ; / * get picture buffer * / if ( ( ret = ff_thread_get_buffer ( avctx , & frame , 0 ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , ff_thread_get_buffer ( ) failed . \n ) ; goto end ; } picture - > pict_type = AV_PICTURE_TYPE_I ; picture - > key_frame = 1 ; if ( ret = jpeg2000_read_bitstream_packets ( s ) ) goto end ; for ( tileno = 0 ; tileno < s - > numXtiles * s - > numYtiles ; tileno + + ) if ( ret = jpeg2000_decode_tile ( s , s - > tile + tileno , picture ) ) goto end ; * got_frame = 1 ; end : jpeg2000_dec_cleanup ( s ) ; return ret ? ret : s - > buf - s - > buf_start ; }",0
"static int mp_decode_layer3 ( MPADecodeContext * s ) { int nb_granules , main_data_begin ; int gr , ch , blocksplit_flag , i , j , k , n , bits_pos ; GranuleDef * g ; int16_t exponents[576] ; //FIXME try INTFLOAT / * read side info * / if ( s - > lsf ) { main_data_begin = get_bits ( & s - > gb , 8 ) ; skip_bits ( & s - > gb , s - > nb_channels ) ; nb_granules = 1 ; } else { main_data_begin = get_bits ( & s - > gb , 9 ) ; if ( s - > nb_channels == 2 ) skip_bits ( & s - > gb , 3 ) ; else skip_bits ( & s - > gb , 5 ) ; nb_granules = 2 ; for ( ch = 0 ; ch < s - > nb_channels ; ch + + ) { s - > granules[ch][0] . scfsi = 0 ; / * all scale factors are transmitted * / s - > granules[ch][1] . scfsi = get_bits ( & s - > gb , 4 ) ; } } for ( gr = 0 ; gr < nb_granules ; gr + + ) { for ( ch = 0 ; ch < s - > nb_channels ; ch + + ) { av_dlog ( s - > avctx , gr=%d ch=%d : side_info\n , gr , ch ) ; g = & s - > granules[ch][gr] ; g - > part2_3_length = get_bits ( & s - > gb , 12 ) ; g - > big_values = get_bits ( & s - > gb , 9 ) ; if ( g - > big_values > 288 ) { av_log ( s - > avctx , AV_LOG_ERROR , big_values too big\n ) ; return AVERROR_INVALIDDATA ; } g - > global_gain = get_bits ( & s - > gb , 8 ) ; / * if MS stereo only is selected , we precompute the 1/sqrt ( 2 ) renormalization factor * / if ( ( s - > mode_ext & ( MODE_EXT_MS_STEREO | MODE_EXT_I_STEREO ) ) == MODE_EXT_MS_STEREO ) g - > global_gain - = 2 ; if ( s - > lsf ) g - > scalefac_compress = get_bits ( & s - > gb , 9 ) ; else g - > scalefac_compress = get_bits ( & s - > gb , 4 ) ; blocksplit_flag = get_bits1 ( & s - > gb ) ; if ( blocksplit_flag ) { g - > block_type = get_bits ( & s - > gb , 2 ) ; if ( g - > block_type == 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , invalid block type\n ) ; return AVERROR_INVALIDDATA ; } g - > switch_point = get_bits1 ( & s - > gb ) ; for ( i = 0 ; i < 2 ; i + + ) g - > table_select[i] = get_bits ( & s - > gb , 5 ) ; for ( i = 0 ; i < 3 ; i + + ) g - > subblock_gain[i] = get_bits ( & s - > gb , 3 ) ; ff_init_short_region ( s , g ) ; } else { int region_address1 , region_address2 ; g - > block_type = 0 ; g - > switch_point = 0 ; for ( i = 0 ; i < 3 ; i + + ) g - > table_select[i] = get_bits ( & s - > gb , 5 ) ; / * compute huffman coded region sizes * / region_address1 = get_bits ( & s - > gb , 4 ) ; region_address2 = get_bits ( & s - > gb , 3 ) ; av_dlog ( s - > avctx , region1=%d region2=%d\n , region_address1 , region_address2 ) ; ff_init_long_region ( s , g , region_address1 , region_address2 ) ; } ff_region_offset2size ( g ) ; ff_compute_band_indexes ( s , g ) ; g - > preflag = 0 ; if ( ! s - > lsf ) g - > preflag = get_bits1 ( & s - > gb ) ; g - > scalefac_scale = get_bits1 ( & s - > gb ) ; g - > count1table_select = get_bits1 ( & s - > gb ) ; av_dlog ( s - > avctx , block_type=%d switch_point=%d\n , g - > block_type , g - > switch_point ) ; } } if ( ! s - > adu_mode ) { const uint8_t * ptr = s - > gb . buffer + ( get_bits_count ( & s - > gb ) > > 3 ) ; int extrasize = av_clip ( get_bits_left ( & s - > gb ) > > 3 , 0 , EXTRABYTES ) ; assert ( ( get_bits_count ( & s - > gb ) & 7 ) == 0 ) ; / * now we get bits from the main_data_begin offset * / av_dlog ( s - > avctx , seekback : %d\n , main_data_begin ) ; //av_log ( NULL , AV_LOG_ERROR , backstep : %d , lastbuf : %d\n , main_data_begin , s - > last_buf_size ) ; memcpy ( s - > last_buf + s - > last_buf_size , ptr , extrasize ) ; s - > in_gb = s - > gb ; init_get_bits ( & s - > gb , s - > last_buf , s - > last_buf_size * 8 ) ; if ! UNCHECKED_BITSTREAM_READER s - > gb . size_in_bits_plus8 + = FFMAX ( extrasize , LAST_BUF_SIZE - s - > last_buf_size ) * 8 ; endif skip_bits_long ( & s - > gb , 8 * ( s - > last_buf_size - main_data_begin ) ) ; } for ( gr = 0 ; gr < nb_granules ; gr + + ) { for ( ch = 0 ; ch < s - > nb_channels ; ch + + ) { g = & s - > granules[ch][gr] ; if ( get_bits_count ( & s - > gb ) < 0 ) { av_log ( s - > avctx , AV_LOG_DEBUG , mdb : %d , lastbuf : %d skipping granule %d\n , main_data_begin , s - > last_buf_size , gr ) ; skip_bits_long ( & s - > gb , g - > part2_3_length ) ; memset ( g - > sb_hybrid , 0 , sizeof ( g - > sb_hybrid ) ) ; if ( get_bits_count ( & s - > gb ) > = s - > gb . size_in_bits & & s - > in_gb . buffer ) { skip_bits_long ( & s - > in_gb , get_bits_count ( & s - > gb ) - s - > gb . size_in_bits ) ; s - > gb = s - > in_gb ; s - > in_gb . buffer = NULL ; } continue ; } bits_pos = get_bits_count ( & s - > gb ) ; if ( ! s - > lsf ) { uint8_t * sc ; int slen , slen1",0
"static int decorrelate ( TAKDecContext * s , int c1 , int c2 , int length ) { GetBitContext * gb = & s - > gb ; int32_t * p1 = s - > decoded[c1] + ( s - > dmode > 5 ) ; int32_t * p2 = s - > decoded[c2] + ( s - > dmode > 5 ) ; int32_t bp1 = p1[0] ; int32_t bp2 = p2[0] ; int i ; int dshift , dfactor ; length + = s - > dmode < 6 ; switch ( s - > dmode ) { case 1 : / * left/side * / s - > tdsp . decorrelate_ls ( p1 , p2 , length ) ; break ; case 2 : / * side/right * / s - > tdsp . decorrelate_sr ( p1 , p2 , length ) ; break ; case 3 : / * side/mid * / s - > tdsp . decorrelate_sm ( p1 , p2 , length ) ; break ; case 4 : / * side/left with scale factor * / FFSWAP ( int32_t * , p1 , p2 ) ; FFSWAP ( int32_t , bp1 , bp2 ) ; case 5 : / * side/right with scale factor * / dshift = get_bits_esc4 ( gb ) ; dfactor = get_sbits ( gb , 10 ) ; s - > tdsp . decorrelate_sf ( p1 , p2 , length , dshift , dfactor ) ; break ; case 6 : FFSWAP ( int32_t * , p1 , p2 ) ; case 7 : { int length2 , order_half , filter_order , dval1 , dval2 ; int tmp , x , code_size ; if ( length < 256 ) return AVERROR_INVALIDDATA ; dshift = get_bits_esc4 ( gb ) ; filter_order = 8 < < get_bits1 ( gb ) ; dval1 = get_bits1 ( gb ) ; dval2 = get_bits1 ( gb ) ; for ( i = 0 ; i < filter_order ; i + + ) { if ( ! ( i & 3 ) ) code_size = 14 - get_bits ( gb , 3 ) ; s - > filter[i] = get_sbits ( gb , code_size ) ; } order_half = filter_order / 2 ; length2 = length - ( filter_order - 1 ) ; / * decorrelate beginning samples * / if ( dval1 ) { for ( i = 0 ; i < order_half ; i + + ) { int32_t a = p1[i] ; int32_t b = p2[i] ; p1[i] = a + b ; } } / * decorrelate ending samples * / if ( dval2 ) { for ( i = length2 + order_half ; i < length ; i + + ) { int32_t a = p1[i] ; int32_t b = p2[i] ; p1[i] = a + b ; } } for ( i = 0 ; i < filter_order ; i + + ) s - > residues[i] = * p2 + + > > dshift ; p1 + = order_half ; x = FF_ARRAY_ELEMS ( s - > residues ) - filter_order ; for ( ; length2 > 0 ; length2 - = tmp ) { tmp = FFMIN ( length2 , x ) ; for ( i = 0 ; i < tmp ; i + + ) s - > residues[filter_order + i] = * p2 + + > > dshift ; for ( i = 0 ; i < tmp ; i + + ) { int v = 1 < < 9 ; if ( filter_order == 16 ) { v + = s - > adsp . scalarproduct_int16 ( & s - > residues[i] , s - > filter , filter_order ) ; } else { v + = s - > residues[i + 7] * s - > filter[7] + s - > residues[i + 6] * s - > filter[6] + s - > residues[i + 5] * s - > filter[5] + s - > residues[i + 4] * s - > filter[4] + s - > residues[i + 3] * s - > filter[3] + s - > residues[i + 2] * s - > filter[2] + s - > residues[i + 1] * s - > filter[1] + s - > residues[i ] * s - > filter[0] ; } v = ( av_clip_intp2 ( v > > 10 , 13 ) < < dshift ) - * p1 ; * p1 + + = v ; } memmove ( s - > residues , & s - > residues[tmp] , 2 * filter_order ) ; } emms_c ( ) ; break ; } } if ( s - > dmode > 0 & & s - > dmode < 6 ) { p1[0] = bp1 ; p2[0] = bp2 ; } return 0 ; }",0
"static int ebml_parse_elem ( MatroskaDemuxContext * matroska , EbmlSyntax * syntax , void * data ) { static const uint64_t max_lengths[EBML_TYPE_COUNT] = { [EBML_UINT] = 8 , [EBML_FLOAT] = 8 , // max . 16 MB for strings [EBML_STR] = 0x1000000 , [EBML_UTF8] = 0x1000000 , // max . 256 MB for binary data [EBML_BIN] = 0x10000000 , // no limits for anything else } ; AVIOContext * pb = matroska - > ctx - > pb ; uint32_t id = syntax - > id ; uint64_t length ; int res ; data = ( char * ) data + syntax - > data_offset ; if ( syntax - > list_elem_size ) { EbmlList * list = data ; list - > elem = av_realloc ( list - > elem , ( list - > nb_elem + 1 ) * syntax - > list_elem_size ) ; data = ( char * ) list - > elem + list - > nb_elem * syntax - > list_elem_size ; memset ( data , 0 , syntax - > list_elem_size ) ; list - > nb_elem + + ; } if ( syntax - > type ! = EBML_PASS & & syntax - > type ! = EBML_STOP ) { matroska - > current_id = 0 ; if ( ( res = ebml_read_length ( matroska , pb , & length ) ) < 0 ) return res ; if ( max_lengths[syntax - > type] & & length > max_lengths[syntax - > type] ) { av_log ( matroska - > ctx , AV_LOG_ERROR , Invalid length 0x% PRIx64 > 0x% PRIx64 for syntax element %i\n , length , max_lengths[syntax - > type] , syntax - > type ) ; return AVERROR_INVALIDDATA ; } } switch ( syntax - > type ) { case EBML_UINT : res = ebml_read_uint ( pb , length , data ) ; break ; case EBML_FLOAT : res = ebml_read_float ( pb , length , data ) ; break ; case EBML_STR : case EBML_UTF8 : res = ebml_read_ascii ( pb , length , data ) ; break ; case EBML_BIN : res = ebml_read_binary ( pb , length , data ) ; break ; case EBML_NEST : if ( ( res=ebml_read_master ( matroska , length ) ) < 0 ) return res ; if ( id == MATROSKA_ID_SEGMENT ) matroska - > segment_start = avio_tell ( matroska - > ctx - > pb ) ; return ebml_parse_nest ( matroska , syntax - > def . n , data ) ; case EBML_PASS : return ebml_parse_id ( matroska , syntax - > def . n , id , data ) ; case EBML_STOP : return 1 ; default : return avio_skip ( pb , length ) < 0 ? AVERROR ( EIO ) : 0 ; } if ( res == AVERROR_INVALIDDATA ) av_log ( matroska - > ctx , AV_LOG_ERROR , Invalid element\n ) ; else if ( res == AVERROR ( EIO ) ) av_log ( matroska - > ctx , AV_LOG_ERROR , Read error\n ) ; return res ; }",1
"static int au_write_header ( AVFormatContext * s ) { AVIOContext * pb = s - > pb ; AVCodecContext * enc = s - > streams[0] - > codec ; if ( ! enc - > codec_tag ) return AVERROR ( EINVAL ) ; ffio_wfourcc ( pb , . snd ) ; / * magic number * / avio_wb32 ( pb , AU_HEADER_SIZE ) ; / * header size * / avio_wb32 ( pb , AU_UNKNOWN_SIZE ) ; / * data size * / avio_wb32 ( pb , enc - > codec_tag ) ; / * codec ID * / avio_wb32 ( pb , enc - > sample_rate ) ; avio_wb32 ( pb , enc - > channels ) ; avio_wb64 ( pb , 0 ) ; / * annotation field * / avio_flush ( pb ) ; return 0 ; }",1
"static int process_cc608 ( CCaptionSubContext * ctx , int64_t pts , uint8_t hi , uint8_t lo ) { int ret = 0 ; define COR3 ( var , with1 , with2 , with3 ) ( ( var ) == ( with1 ) || ( var ) == ( with2 ) || ( var ) == ( with3 ) ) if ( hi == ctx - > prev_cmd[0] & & lo == ctx - > prev_cmd[1] ) { / * ignore redundant command * / } else if ( ( hi == 0x10 & & ( lo > = 0x40 || lo < = 0x5f ) ) || ( ( hi > = 0x11 & & hi < = 0x17 ) & & ( lo > = 0x40 & & lo < = 0x7f ) ) ) { handle_pac ( ctx , hi , lo ) ; } else if ( ( hi == 0x11 & & lo > = 0x20 & & lo < = 0x2f ) || ( hi == 0x17 & & lo > = 0x2e & & lo < = 0x2f ) ) { handle_textattr ( ctx , hi , lo ) ; } else if ( COR3 ( hi , 0x14 , 0x15 , 0x1C ) & & lo == 0x20 ) { / * resume caption loading * / ctx - > mode = CCMODE_POPON ; } else if ( COR3 ( hi , 0x14 , 0x15 , 0x1C ) & & lo == 0x24 ) { handle_delete_end_of_row ( ctx , hi , lo ) ; } else if ( COR3 ( hi , 0x14 , 0x15 , 0x1C ) & & lo == 0x25 ) { ctx - > rollup = 2 ; ctx - > mode = CCMODE_ROLLUP_2 ; } else if ( COR3 ( hi , 0x14 , 0x15 , 0x1C ) & & lo == 0x26 ) { ctx - > rollup = 3 ; ctx - > mode = CCMODE_ROLLUP_3 ; } else if ( COR3 ( hi , 0x14 , 0x15 , 0x1C ) & & lo == 0x27 ) { ctx - > rollup = 4 ; ctx - > mode = CCMODE_ROLLUP_4 ; } else if ( COR3 ( hi , 0x14 , 0x15 , 0x1C ) & & lo == 0x29 ) { / * resume direct captioning * / ctx - > mode = CCMODE_PAINTON ; } else if ( COR3 ( hi , 0x14 , 0x15 , 0x1C ) & & lo == 0x2B ) { / * resume text display * / ctx - > mode = CCMODE_TEXT ; } else if ( COR3 ( hi , 0x14 , 0x15 , 0x1C ) & & lo == 0x2C ) { / * erase display memory * / ret = handle_edm ( ctx , pts ) ; } else if ( COR3 ( hi , 0x14 , 0x15 , 0x1C ) & & lo == 0x2D ) { / * carriage return * / av_dlog ( ctx , carriage return\n ) ; reap_screen ( ctx , pts ) ; roll_up ( ctx ) ; ctx - > screen_changed = 1 ; ctx - > cursor_column = 0 ; } else if ( COR3 ( hi , 0x14 , 0x15 , 0x1C ) & & lo == 0x2F ) { / * end of caption * / av_dlog ( ctx , handle_eoc\n ) ; ret = handle_eoc ( ctx , pts ) ; } else if ( hi > =0x20 ) { / * Standard characters ( always in pairs ) * / handle_char ( ctx , hi , lo , pts ) ; } else { / * Ignoring all other non data code * / av_dlog ( ctx , Unknown command 0x%hhx 0x%hhx\n , hi , lo ) ; } / * set prev command * / ctx - > prev_cmd[0] = hi ; ctx - > prev_cmd[1] = lo ; undef COR3 return ret ; }",0
"static int h264_find_frame_end ( H264ParseContext * p , const uint8_t * buf , int buf_size ) { int i ; uint32_t state ; ParseContext * pc = & p - > pc ; // mb_addr= pc - > mb_addr - 1 ; state = pc - > state ; if ( state > 13 ) state = 7 ; for ( i = 0 ; i < buf_size ; i + + ) { if ( state == 7 ) { i + = p - > h264dsp . startcode_find_candidate ( buf + i , buf_size - i ) ; if ( i < buf_size ) state = 2 ; } else if ( state < = 2 ) { if ( buf[i] == 1 ) state = 5 ; // 2 - > 7 , 1 - > 4 , 0 - > 5 else if ( buf[i] ) state = 7 ; else state > > = 1 ; // 2 - > 1 , 1 - > 0 , 0 - > 0 } else if ( state < = 5 ) { int nalu_type = buf[i] & 0x1F ; if ( nalu_type == NAL_SEI || nalu_type == NAL_SPS || nalu_type == NAL_PPS || nalu_type == NAL_AUD ) { if ( pc - > frame_start_found ) { i + + ; goto found ; } } else if ( nalu_type == NAL_SLICE || nalu_type == NAL_DPA || nalu_type == NAL_IDR_SLICE ) { if ( pc - > frame_start_found ) { state + = 8 ; continue ; } else pc - > frame_start_found = 1 ; } state = 7 ; } else { // first_mb_in_slice is 0 , probably the first nal of a new slice if ( buf[i] & 0x80 ) goto found ; state = 7 ; } } pc - > state = state ; return END_NOT_FOUND ; found : pc - > state = 7 ; pc - > frame_start_found = 0 ; return i - ( state & 5 ) ; }",0
"int ffurl_connect ( URLContext * uc , AVDictionary * * options ) { int err = uc - > prot - > url_open2 ? uc - > prot - > url_open2 ( uc , uc - > filename , uc - > flags , options ) : uc - > prot - > url_open ( uc , uc - > filename , uc - > flags ) ; if ( err ) return err ; uc - > is_connected = 1 ; / * We must be careful here as ffurl_seek ( ) could be slow , * for example for http * / if ( ( uc - > flags & AVIO_FLAG_WRITE ) || ! strcmp ( uc - > prot - > name , file ) ) if ( ! uc - > is_streamed & & ffurl_seek ( uc , 0 , SEEK_SET ) < 0 ) uc - > is_streamed = 1 ; return 0 ; }",0
"void put_pixels8_xy2_altivec ( uint8_t * block , const uint8_t * pixels , int line_size , int h ) { POWERPC_TBL_DECLARE ( altivec_put_pixels8_xy2_num , 1 ) ; ifdef ALTIVEC_USE_REFERENCE_C_CODE int j ; POWERPC_TBL_START_COUNT ( altivec_put_pixels8_xy2_num , 1 ) ; for ( j = 0 ; j < 2 ; j + + ) { int i ; const uint32_t a = ( ( ( const struct unaligned_32 * ) ( pixels ) ) - > l ) ; const uint32_t b = ( ( ( const struct unaligned_32 * ) ( pixels + 1 ) ) - > l ) ; uint32_t l0 = ( a & 0x03030303UL ) + ( b & 0x03030303UL ) + 0x02020202UL ; uint32_t h0 = ( ( a & 0xFCFCFCFCUL ) > > 2 ) + ( ( b & 0xFCFCFCFCUL ) > > 2 ) ; uint32_t l1 , h1 ; pixels + = line_size ; for ( i = 0 ; i < h ; i + = 2 ) { uint32_t a = ( ( ( const struct unaligned_32 * ) ( pixels ) ) - > l ) ; uint32_t b = ( ( ( const struct unaligned_32 * ) ( pixels + 1 ) ) - > l ) ; l1 = ( a & 0x03030303UL ) + ( b & 0x03030303UL ) ; h1 = ( ( a & 0xFCFCFCFCUL ) > > 2 ) + ( ( b & 0xFCFCFCFCUL ) > > 2 ) ; * ( ( uint32_t * ) block ) = h0 + h1 + ( ( ( l0 + l1 ) > > 2 ) & 0x0F0F0F0FUL ) ; pixels + = line_size ; block + = line_size ; a = ( ( ( const struct unaligned_32 * ) ( pixels ) ) - > l ) ; b = ( ( ( const struct unaligned_32 * ) ( pixels + 1 ) ) - > l ) ; l0 = ( a & 0x03030303UL ) + ( b & 0x03030303UL ) + 0x02020202UL ; h0 = ( ( a & 0xFCFCFCFCUL ) > > 2 ) + ( ( b & 0xFCFCFCFCUL ) > > 2 ) ; * ( ( uint32_t * ) block ) = h0 + h1 + ( ( ( l0 + l1 ) > > 2 ) & 0x0F0F0F0FUL ) ; pixels + = line_size ; block + = line_size ; } pixels + = 4 - line_size * ( h + 1 ) ; block + = 4 - line_size * h ; } POWERPC_TBL_STOP_COUNT ( altivec_put_pixels8_xy2_num , 1 ) ; else / * ALTIVEC_USE_REFERENCE_C_CODE * / register int i ; register vector unsigned char pixelsv1 , pixelsv2 , pixelsavg ; register vector unsigned char blockv , temp1 , temp2 ; register vector unsigned short pixelssum1 , pixelssum2 , temp3 ; register const vector unsigned char vczero = ( const vector unsigned char ) vec_splat_u8 ( 0 ) ; register const vector unsigned short vctwo = ( const vector unsigned short ) vec_splat_u16 ( 2 ) ; temp1 = vec_ld ( 0 , pixels ) ; temp2 = vec_ld ( 16 , pixels ) ; pixelsv1 = vec_perm ( temp1 , temp2 , vec_lvsl ( 0 , pixels ) ) ; if ( ( ( ( unsigned long ) pixels ) & 0x0000000F ) == 0x0000000F ) { pixelsv2 = temp2 ; } else { pixelsv2 = vec_perm ( temp1 , temp2 , vec_lvsl ( 1 , pixels ) ) ; } pixelsv1 = vec_mergeh ( vczero , pixelsv1 ) ; pixelsv2 = vec_mergeh ( vczero , pixelsv2 ) ; pixelssum1 = vec_add ( ( vector unsigned short ) pixelsv1 , ( vector unsigned short ) pixelsv2 ) ; pixelssum1 = vec_add ( pixelssum1 , vctwo ) ; POWERPC_TBL_START_COUNT ( altivec_put_pixels8_xy2_num , 1 ) ; for ( i = 0 ; i < h ; i + + ) { int rightside = ( ( unsigned long ) block & 0x0000000F ) ; blockv = vec_ld ( 0 , block ) ; temp1 = vec_ld ( line_size , pixels ) ; temp2 = vec_ld ( line_size + 16 , pixels ) ; pixelsv1 = vec_perm ( temp1 , temp2 , vec_lvsl ( line_size , pixels ) ) ; if ( ( ( ( ( unsigned long ) pixels ) + line_size ) & 0x0000000F ) == 0x0000000F ) { pixelsv2 = temp2 ; } else { pixelsv2 = vec_perm ( temp1 , temp2 , vec_lvsl ( line_size + 1 , pixels ) ) ; } pixelsv1 = vec_mergeh ( vczero , pixelsv1 ) ; pixelsv2 = vec_mergeh ( vczero , pixelsv2 ) ; pixelssum2 = vec_add ( ( vector unsigned short ) pixelsv1 , ( vector unsigned short ) pixelsv2 ) ; temp3 = vec_add ( pixelssum1 , pixelssum2 ) ; temp3 = vec_sra ( temp3 , vctwo ) ; pixelssum1 = vec_add ( pixelssum2 , vctwo ) ; pixelsavg = vec_packsu ( temp3 , ( vector unsigned short ) vczero ) ; if ( rightside ) { blockv = vec_perm ( blockv , pixelsavg , vcprm ( 0 , 1 , s0 , s1 ) ) ; } else { blockv = vec_perm ( blockv , pixelsavg , vcprm ( s0 , s1 , 2 , 3 ) ) ; } vec_st ( blockv , 0 , block ) ; block + = line_size ; pixels + = line_size ; } POWERPC_TBL_STOP_COUNT ( altivec_put_pixels8_xy2_num , 1 ) ; endif / * ALTIVEC_USE_REFERENCE_C_CODE * / }",0
"static inline void libopenjpeg_copy_to_packed16 ( AVFrame * picture , opj_image_t * image ) { uint16_t * img_ptr ; int index , x , y , c ; int adjust[4] ; for ( x = 0 ; x < image - > numcomps ; x + + ) adjust[x] = FFMAX ( FFMIN ( av_pix_fmt_desc_get ( picture - > format ) - > comp[x] . depth_minus1 + 1 - image - > comps[x] . prec , 8 ) , 0 ) ; for ( y = 0 ; y < picture - > height ; y + + ) { index = y * picture - > width ; img_ptr = ( uint16_t * ) ( picture - > data[0] + y * picture - > linesize[0] ) ; for ( x = 0 ; x < picture - > width ; x + + , index + + ) { for ( c = 0 ; c < image - > numcomps ; c + + ) { * img_ptr + + = 0x8000 * image - > comps[c] . sgnd + ( image - > comps[c] . data[index] < < adjust[c] ) ; } } } }",1
"static int flic_read_packet ( AVFormatContext * s , AVPacket * pkt ) { FlicDemuxContext * flic = ( FlicDemuxContext * ) s - > priv_data ; ByteIOContext * pb = & s - > pb ; int packet_read = 0 ; unsigned int size ; int magic ; int ret = 0 ; unsigned char preamble[FLIC_PREAMBLE_SIZE] ; while ( ! packet_read ) { if ( ( ret = get_buffer ( pb , preamble , FLIC_PREAMBLE_SIZE ) ) ! = FLIC_PREAMBLE_SIZE ) { ret = AVERROR_IO ; break ; } size = LE_32 ( & preamble[0] ) ; magic = LE_16 ( & preamble[4] ) ; if ( ( magic == FLIC_CHUNK_MAGIC_1 ) || ( magic == FLIC_CHUNK_MAGIC_2 ) ) { if ( av_new_packet ( pkt , size ) ) { ret = AVERROR_IO ; break ; } pkt - > stream_index = flic - > video_stream_index ; pkt - > pts = flic - > pts ; memcpy ( pkt - > data , preamble , FLIC_PREAMBLE_SIZE ) ; ret = get_buffer ( pb , pkt - > data + FLIC_PREAMBLE_SIZE , size - FLIC_PREAMBLE_SIZE ) ; if ( ret ! = size - FLIC_PREAMBLE_SIZE ) { av_free_packet ( pkt ) ; ret = AVERROR_IO ; } flic - > pts + = flic - > frame_pts_inc ; packet_read = 1 ; } else { / * not interested in this chunk * / url_fseek ( pb , size - 6 , SEEK_CUR ) ; } } return ret ; }",1
"int MPV_encode_picture ( AVCodecContext * avctx , unsigned char * buf , int buf_size , void * data ) { MpegEncContext * s = avctx - > priv_data ; AVFrame * pic_arg = data ; int i , stuffing_count ; for ( i=0 ; i < avctx - > thread_count ; i + + ) { int start_y= s - > thread_context[i] - > start_mb_y ; int end_y= s - > thread_context[i] - > end_mb_y ; int h= s - > mb_height ; uint8_t * start= buf + ( size_t ) ( ( ( int64_t ) buf_size ) * start_y/h ) ; uint8_t * end = buf + ( size_t ) ( ( ( int64_t ) buf_size ) * end_y/h ) ; init_put_bits ( & s - > thread_context[i] - > pb , start , end - start ) ; } s - > picture_in_gop_number + + ; if ( load_input_picture ( s , pic_arg ) < 0 ) return - 1 ; select_input_picture ( s ) ; / * output ? * / if ( s - > new_picture . data[0] ) { s - > pict_type= s - > new_picture . pict_type ; //emms_c ( ) ; //printf ( qs : %f %f %d\n , s - > new_picture . quality , s - > current_picture . quality , s - > qscale ) ; MPV_frame_start ( s , avctx ) ; if ( encode_picture ( s , s - > picture_number ) < 0 ) return - 1 ; avctx - > real_pict_num = s - > picture_number ; avctx - > header_bits = s - > header_bits ; avctx - > mv_bits = s - > mv_bits ; avctx - > misc_bits = s - > misc_bits ; avctx - > i_tex_bits = s - > i_tex_bits ; avctx - > p_tex_bits = s - > p_tex_bits ; avctx - > i_count = s - > i_count ; avctx - > p_count = s - > mb_num - s - > i_count - s - > skip_count ; //FIXME f/b_count in avctx avctx - > skip_count = s - > skip_count ; MPV_frame_end ( s ) ; if ( s - > out_format == FMT_MJPEG ) mjpeg_picture_trailer ( s ) ; if ( s - > flags & CODEC_FLAG_PASS1 ) ff_write_pass1_stats ( s ) ; for ( i=0 ; i < 4 ; i + + ) { s - > current_picture_ptr - > error[i]= s - > current_picture . error[i] ; avctx - > error[i] + = s - > current_picture_ptr - > error[i] ; } if ( s - > flags & CODEC_FLAG_PASS1 ) assert ( avctx - > header_bits + avctx - > mv_bits + avctx - > misc_bits + avctx - > i_tex_bits + avctx - > p_tex_bits == put_bits_count ( & s - > pb ) ) ; flush_put_bits ( & s - > pb ) ; s - > frame_bits = put_bits_count ( & s - > pb ) ; stuffing_count= ff_vbv_update ( s , s - > frame_bits ) ; if ( stuffing_count ) { if ( s - > pb . buf_end - s - > pb . buf - ( put_bits_count ( & s - > pb ) > > 3 ) < stuffing_count + 50 ) { av_log ( s - > avctx , AV_LOG_ERROR , stuffing too large\n ) ; return - 1 ; } switch ( s - > codec_id ) { case CODEC_ID_MPEG1VIDEO : case CODEC_ID_MPEG2VIDEO : while ( stuffing_count - - ) { put_bits ( & s - > pb , 8 , 0 ) ; } break ; case CODEC_ID_MPEG4 : put_bits ( & s - > pb , 16 , 0 ) ; put_bits ( & s - > pb , 16 , 0x1C3 ) ; stuffing_count - = 4 ; while ( stuffing_count - - ) { put_bits ( & s - > pb , 8 , 0xFF ) ; } break ; default : av_log ( s - > avctx , AV_LOG_ERROR , vbv buffer overflow\n ) ; } flush_put_bits ( & s - > pb ) ; s - > frame_bits = put_bits_count ( & s - > pb ) ; } / * update mpeg1/2 vbv_delay for CBR * / if ( s - > avctx - > rc_max_rate & & s - > avctx - > rc_min_rate == s - > avctx - > rc_max_rate & & s - > out_format == FMT_MPEG1 & & 90000LL * ( avctx - > rc_buffer_size - 1 ) < = s - > avctx - > rc_max_rate * 0xFFFFLL ) { int vbv_delay ; assert ( s - > repeat_first_field==0 ) ; vbv_delay= lrintf ( 90000 * s - > rc_context . buffer_index / s - > avctx - > rc_max_rate ) ; assert ( vbv_delay < 0xFFFF ) ; s - > vbv_delay_ptr[0] & = 0xF8 ; s - > vbv_delay_ptr[0] |= vbv_delay > > 13 ; s - > vbv_delay_ptr[1] = vbv_delay > > 5 ; s - > vbv_delay_ptr[2] & = 0x07 ; s - > vbv_delay_ptr[2] |= vbv_delay < < 3 ; } s - > total_bits + = s - > frame_bits ; avctx - > frame_bits = s - > frame_bits ; } else { assert ( ( pbBufPtr ( & s - > pb ) == s - > pb . buf ) ) ; s - > frame_bits=0 ; } assert ( ( s - > frame_bits & 7 ) ==0 ) ; return s - > frame_bits/8 ; }",1
static int get_ref_idx ( AVFrame * frame ) { FrameDecodeData * fdd ; NVDECFrame * cf ; if ( ! frame || ! frame - > private_ref ) return - 1 ; fdd = ( FrameDecodeData * ) frame - > private_ref - > data ; cf = ( NVDECFrame * ) fdd - > hwaccel_priv ; return cf - > idx ; },0
"static void vp3_draw_horiz_band ( Vp3DecodeContext * s , int y ) { int h , cy , i ; int offset[AV_NUM_DATA_POINTERS] ; if ( HAVE_THREADS & & s - > avctx - > active_thread_type & FF_THREAD_FRAME ) { int y_flipped = s - > flipped_image ? s - > avctx - > height - y : y ; / * At the end of the frame , report INT_MAX instead of the height of * the frame . This makes the other threads ' ff_thread_await_progress ( ) * calls cheaper , because they don ' t have to clip their values . * / ff_thread_report_progress ( & s - > current_frame , y_flipped == s - > avctx - > height ? INT_MAX : y_flipped - 1 , 0 ) ; } if ( s - > avctx - > draw_horiz_band == NULL ) return ; h = y - s - > last_slice_end ; s - > last_slice_end = y ; y - = h ; if ( ! s - > flipped_image ) y = s - > avctx - > height - y - h ; cy = y > > s - > chroma_y_shift ; offset[0] = s - > current_frame . f - > linesize[0] * y ; offset[1] = s - > current_frame . f - > linesize[1] * cy ; offset[2] = s - > current_frame . f - > linesize[2] * cy ; for ( i = 3 ; i < AV_NUM_DATA_POINTERS ; i + + ) offset[i] = 0 ; emms_c ( ) ; s - > avctx - > draw_horiz_band ( s - > avctx , s - > current_frame . f , offset , y , 3 , h ) ; }",0
"static int gif_write_header ( AVFormatContext * s ) { GIFContext * gif = s - > priv_data ; AVIOContext * pb = s - > pb ; AVCodecContext * enc , * video_enc ; int i , width , height , loop_count / * , rate * / ; / * XXX : do we reject audio streams or just ignore them ? if ( s - > nb_streams > 1 ) return - 1 ; * / gif - > time = 0 ; gif - > file_time = 0 ; video_enc = NULL ; for ( i=0 ; i < s - > nb_streams ; i + + ) { enc = s - > streams[i] - > codec ; if ( enc - > codec_type ! = AVMEDIA_TYPE_AUDIO ) video_enc = enc ; } if ( ! video_enc ) { av_free ( gif ) ; return - 1 ; } else { width = video_enc - > width ; height = video_enc - > height ; loop_count = s - > loop_output ; // rate = video_enc - > time_base . den ; } if ( video_enc - > pix_fmt ! = PIX_FMT_RGB24 ) { av_log ( s , AV_LOG_ERROR , ERROR : gif only handles the rgb24 pixel format . Use - pix_fmt rgb24 . \n ) ; return AVERROR ( EIO ) ; } gif_image_write_header ( pb , width , height , loop_count , NULL ) ; avio_flush ( s - > pb ) ; return 0 ; }",0
"static int put_packetheader ( NUTContext * nut , ByteIOContext * bc , int max_size , int calculate_checksum ) { put_flush_packet ( bc ) ; nut - > packet_start[2]= url_ftell ( bc ) - 8 ; nut - > written_packet_size = max_size ; if ( calculate_checksum ) init_checksum ( bc , update_adler32 , 0 ) ; / * packet header * / put_v ( bc , nut - > written_packet_size ) ; / * forward ptr * / return 0 ; }",0
"inline static void RENAME ( hcscale ) ( SwsContext * c , uint16_t * dst , long dstWidth , uint8_t * src1 , uint8_t * src2 , int srcW , int xInc , int flags , int canMMX2BeUsed , int16_t * hChrFilter , int16_t * hChrFilterPos , int hChrFilterSize , void * funnyUVCode , int srcFormat , uint8_t * formatConvBuffer , int16_t * mmx2Filter , int32_t * mmx2FilterPos , uint8_t * pal ) { if ( srcFormat==PIX_FMT_YUYV422 ) { RENAME ( yuy2ToUV ) ( formatConvBuffer , formatConvBuffer + VOFW , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + VOFW ; } else if ( srcFormat==PIX_FMT_UYVY422 ) { RENAME ( uyvyToUV ) ( formatConvBuffer , formatConvBuffer + VOFW , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + VOFW ; } else if ( srcFormat==PIX_FMT_RGB32 ) { if ( c - > chrSrcHSubSample ) RENAME ( bgr32ToUV_half ) ( formatConvBuffer , formatConvBuffer + VOFW , src1 , src2 , srcW ) ; else RENAME ( bgr32ToUV ) ( formatConvBuffer , formatConvBuffer + VOFW , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + VOFW ; } else if ( srcFormat==PIX_FMT_RGB32_1 ) { if ( c - > chrSrcHSubSample ) RENAME ( bgr32ToUV_half ) ( formatConvBuffer , formatConvBuffer + VOFW , src1 + ALT32_CORR , src2 + ALT32_CORR , srcW ) ; else RENAME ( bgr32ToUV ) ( formatConvBuffer , formatConvBuffer + VOFW , src1 + ALT32_CORR , src2 + ALT32_CORR , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + VOFW ; } else if ( srcFormat==PIX_FMT_BGR24 ) { if ( c - > chrSrcHSubSample ) RENAME ( bgr24ToUV_half ) ( formatConvBuffer , formatConvBuffer + VOFW , src1 , src2 , srcW ) ; else RENAME ( bgr24ToUV ) ( formatConvBuffer , formatConvBuffer + VOFW , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + VOFW ; } else if ( srcFormat==PIX_FMT_BGR565 ) { if ( c - > chrSrcHSubSample ) RENAME ( bgr16ToUV_half ) ( formatConvBuffer , formatConvBuffer + VOFW , src1 , src2 , srcW ) ; else RENAME ( bgr16ToUV ) ( formatConvBuffer , formatConvBuffer + VOFW , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + VOFW ; } else if ( srcFormat==PIX_FMT_BGR555 ) { if ( c - > chrSrcHSubSample ) RENAME ( bgr15ToUV_half ) ( formatConvBuffer , formatConvBuffer + VOFW , src1 , src2 , srcW ) ; else RENAME ( bgr15ToUV ) ( formatConvBuffer , formatConvBuffer + VOFW , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + VOFW ; } else if ( srcFormat==PIX_FMT_BGR32 ) { if ( c - > chrSrcHSubSample ) RENAME ( rgb32ToUV_half ) ( formatConvBuffer , formatConvBuffer + VOFW , src1 , src2 , srcW ) ; else RENAME ( rgb32ToUV ) ( formatConvBuffer , formatConvBuffer + VOFW , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + VOFW ; } else if ( srcFormat==PIX_FMT_BGR32_1 ) { if ( c - > chrSrcHSubSample ) RENAME ( rgb32ToUV_half ) ( formatConvBuffer , formatConvBuffer + VOFW , src1 + ALT32_CORR , src2 + ALT32_CORR , srcW ) ; else RENAME ( rgb32ToUV ) ( formatConvBuffer , formatConvBuffer + VOFW , src1 + ALT32_CORR , src2 + ALT32_CORR , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + VOFW ; } else if ( srcFormat==PIX_FMT_RGB24 ) { if ( c - > chrSrcHSubSample ) RENAME ( rgb24ToUV_half ) ( formatConvBuffer , formatConvBuffer + VOFW , src1 , src2 , srcW ) ; else RENAME ( rgb24ToUV ) ( formatConvBuffer , formatConvBuffer + VOFW , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + VOFW ; } else if ( srcFormat==PIX_FMT_RGB565 ) { if ( c - > chrSrcHSubSample ) RENAME ( rgb16ToUV_half ) ( formatConvBuffer , formatConvBuffer + VOFW , src1 , src2 , srcW ) ; else RENAME ( rgb16ToUV ) ( formatConvBuffer , formatConvBuffer + VOFW , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + VOFW ; } else if ( srcFormat==PIX_FMT_RGB555 ) { if ( c - > chrSrcHSubSample ) RENAME ( rgb15ToUV_half ) ( formatConvBuffer , formatConvBuffer + VOFW , src1 , src2 , srcW ) ; else RENAME ( rgb15ToUV ) ( formatConvBuffer , formatConvBuffer + VOFW , src1 , src2 , srcW ) ; src1= formatConvBuffer ; src2= formatConvBuffer + VOFW ; } else if ( isGray ( srcFormat ) || srcFormat==PIX_FMT_MONOBLACK || PIX_FMT_MONOWHITE ) { return ; } else if ( srcFormat==PIX_FMT_RGB8 || srcFormat==PIX_FMT_BGR8 || srcFormat==PIX_FMT_PAL8 || srcFormat==PIX_FMT_BGR4_BYTE || srcFormat==PIX_FMT_RGB4_BYTE ) { RENAME ( palToUV ) ( formatConvBuffer , formatConvBuffer + VOFW , src1 , src2 , srcW , ( uint32_t * ) pal ) ; src1= formatConvBuffer ; src2= formatConvBuffer + VOFW ; } ifdef HAVE_MMX // Use the new MMX scaler if the MMX2 one can ' t be used ( it is faster than the x86 ASM one ) . if ( ! ( flags & SWS_FAST_BILINEAR ) || ( ! canMMX2BeUsed ) ) else if ( ! ( flags & SWS_FAST_BILINEAR ) ) endif { RENAME ( hScale ) ( dst , dstWidth , src1 , srcW , xInc , hChrFilter , hChrFilterPos , hChrFilterSize ) ; RENAME ( hScale ) ( dst + VOFW , dstWidth , src2 , srcW , xInc , hChrFilter , hChrFilterPos , hChrFilterSize ) ; } else // fast bilinear upscale / crap downscale { if defined ( ARCH_X86 ) ifdef HAVE_MMX2 int i ; if defined ( PIC ) uint64_t ebxsave __attribute__ ( ( aligned ( 8 ) ) ) ; endif if ( canMMX2BeUsed ) { asm volatile ( if defined ( PIC ) mov %% REG_b , %6 \n\t endif pxor %%mm7 , %%mm7 \n\t mov %0 , %% REG_c \n\t mov %1 , %% REG_D \n\t mov %2 , %% REG_d \n\t mov %3 , %% REG_b \n\t xor %% REG_a , %% REG_a \n\t // i PREFETCH ( %% REG_c ) \n\t PREFETCH 32 ( %% REG_c ) \n\t PREFETCH 64 ( %% REG_c ) \n\t ifdef ARCH_X86_64 define FUNNY_UV_CODE \ movl ( %% REG_b ) , %%esi \n\t \ call * %4 \n\t \ movl ( %% REG_b , %% REG_a ) , %%esi \n\t \ add %% REG_S , %% REG_c \n\t \ add %% REG_a , %% REG_D \n\t \ xor %% REG_a , %% REG_a \n\t \ else define FUNNY_UV_CODE \ movl ( %% REG_b ) , %%esi \n\t \ call * %4 \n\t \ addl ( %% REG_b , %% REG_a ) , %% REG_c \n\t \ add %% REG_a , %% REG_D \n\t \ xor %% REG_a , %% REG_a \n\t \ endif / * ARCH_X86_64 * / FUNNY_UV_CODE FUNNY_UV_CODE FUNNY_UV_CODE FUNNY_UV_CODE xor %% REG_a , %% REG_a \n\t // i mov %5 , %% REG_c \n\t // src mov %1 , %% REG_D \n\t // buf1 add AV_STRINGIFY ( VOF ) , %% REG_D \n\t PREFETCH ( %% REG_c ) \n\t PREFETCH 32 ( %% REG_c ) \n\t PREFETCH 64 ( %% REG_c ) \n\t FUNNY_UV_CODE FUNNY_UV_CODE FUNNY_UV_CODE FUNNY_UV_CODE if defined ( PIC ) mov",0
"static int read_kuki_chunk ( AVFormatContext * s , int64_t size ) { AVIOContext * pb = s - > pb ; AVStream * st = s - > streams[0] ; if ( size < 0 || size > INT_MAX - FF_INPUT_BUFFER_PADDING_SIZE ) return - 1 ; if ( st - > codec - > codec_id == AV_CODEC_ID_AAC ) { / * The magic cookie format for AAC is an mp4 esds atom . The lavc AAC decoder requires the data from the codec specific description as extradata input . * / int strt , skip ; MOVAtom atom ; strt = avio_tell ( pb ) ; ff_mov_read_esds ( s , pb , atom ) ; skip = size - ( avio_tell ( pb ) - strt ) ; if ( skip < 0 || ! st - > codec - > extradata || st - > codec - > codec_id ! = AV_CODEC_ID_AAC ) { av_log ( s , AV_LOG_ERROR , invalid AAC magic cookie\n ) ; return AVERROR_INVALIDDATA ; } avio_skip ( pb , skip ) ; } else if ( st - > codec - > codec_id == AV_CODEC_ID_ALAC ) { define ALAC_PREAMBLE 12 define ALAC_HEADER 36 define ALAC_NEW_KUKI 24 uint8_t preamble[12] ; if ( size < ALAC_NEW_KUKI ) { av_log ( s , AV_LOG_ERROR , invalid ALAC magic cookie\n ) ; avio_skip ( pb , size ) ; return AVERROR_INVALIDDATA ; } avio_read ( pb , preamble , ALAC_PREAMBLE ) ; st - > codec - > extradata = av_mallocz ( ALAC_HEADER + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! st - > codec - > extradata ) return AVERROR ( ENOMEM ) ; / * For the old style cookie , we skip 12 bytes , then read 36 bytes . * The new style cookie only contains the last 24 bytes of what was * 36 bytes in the old style cookie , so we fabricate the first 12 bytes * in that case to maintain compatibility . * / if ( ! memcmp ( & preamble[4] , frmaalac , 8 ) ) { if ( size < ALAC_PREAMBLE + ALAC_HEADER ) { av_log ( s , AV_LOG_ERROR , invalid ALAC magic cookie\n ) ; av_freep ( & st - > codec - > extradata ) ; return AVERROR_INVALIDDATA ; } avio_read ( pb , st - > codec - > extradata , ALAC_HEADER ) ; avio_skip ( pb , size - ALAC_PREAMBLE - ALAC_HEADER ) ; } else { AV_WB32 ( st - > codec - > extradata , 36 ) ; memcpy ( & st - > codec - > extradata[4] , alac , 4 ) ; AV_WB32 ( & st - > codec - > extradata[8] , 0 ) ; memcpy ( & st - > codec - > extradata[12] , preamble , 12 ) ; avio_read ( pb , & st - > codec - > extradata[24] , ALAC_NEW_KUKI - 12 ) ; avio_skip ( pb , size - ALAC_NEW_KUKI ) ; } st - > codec - > extradata_size = ALAC_HEADER ; } else { st - > codec - > extradata = av_mallocz ( size + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! st - > codec - > extradata ) return AVERROR ( ENOMEM ) ; avio_read ( pb , st - > codec - > extradata , size ) ; st - > codec - > extradata_size = size ; } return 0 ; }",1
"int avpriv_unlock_avformat ( void ) { if ( lockmgr_cb ) { if ( ( * lockmgr_cb ) ( & avformat_mutex , AV_LOCK_RELEASE ) ) return - 1 ; } return 0 ; }",1
"fixup_vorbis_headers ( AVFormatContext * as , struct oggvorbis_private * priv , uint8_t * * buf ) { int i , offset , len , buf_len ; unsigned char * ptr ; len = priv - > len[0] + priv - > len[1] + priv - > len[2] ; buf_len = len + len/255 + 64 ; ptr = * buf = av_realloc ( NULL , buf_len ) ; memset ( * buf , ' \0 ' , buf_len ) ; ptr[0] = 2 ; offset = 1 ; offset + = av_xiphlacing ( & ptr[offset] , priv - > len[0] ) ; offset + = av_xiphlacing ( & ptr[offset] , priv - > len[1] ) ; for ( i = 0 ; i < 3 ; i + + ) { memcpy ( & ptr[offset] , priv - > packet[i] , priv - > len[i] ) ; offset + = priv - > len[i] ; av_freep ( & priv - > packet[i] ) ; } * buf = av_realloc ( * buf , offset + FF_INPUT_BUFFER_PADDING_SIZE ) ; return offset ; }",1
"static int build_vlc ( VLC * vlc , const uint8_t * bits_table , const uint8_t * val_table , int nb_codes ) { uint8_t huff_size[256] ; uint16_t huff_code[256] ; memset ( huff_size , 0 , sizeof ( huff_size ) ) ; build_huffman_codes ( huff_size , huff_code , bits_table , val_table ) ; return init_vlc ( vlc , 9 , nb_codes , huff_size , 1 , 1 , huff_code , 2 , 2 ) ; }",1
"static int lavfi_read_packet ( AVFormatContext * avctx , AVPacket * pkt ) { LavfiContext * lavfi = avctx - > priv_data ; double min_pts = DBL_MAX ; int stream_idx , min_pts_sink_idx = 0 ; AVFilterBufferRef * ref ; AVPicture pict ; int ret , i ; int size = 0 ; / * iterate through all the graph sinks . Select the sink with the * minimum PTS * / for ( i = 0 ; i < avctx - > nb_streams ; i + + ) { AVRational tb = lavfi - > sinks[i] - > inputs[0] - > time_base ; double d ; int ret ; if ( lavfi - > sink_eof[i] ) continue ; ret = av_buffersink_get_buffer_ref ( lavfi - > sinks[i] , & ref , AV_BUFFERSINK_FLAG_PEEK ) ; if ( ret == AVERROR_EOF ) { av_dlog ( avctx , EOF sink_idx : %d\n , i ) ; lavfi - > sink_eof[i] = 1 ; continue ; } else if ( ret < 0 ) return ret ; d = av_rescale_q ( ref - > pts , tb , AV_TIME_BASE_Q ) ; av_dlog ( avctx , sink_idx : %d time : %f\n , i , d ) ; if ( d < min_pts ) { min_pts = d ; min_pts_sink_idx = i ; } } if ( min_pts == DBL_MAX ) return AVERROR_EOF ; av_dlog ( avctx , min_pts_sink_idx : %i\n , min_pts_sink_idx ) ; av_buffersink_get_buffer_ref ( lavfi - > sinks[min_pts_sink_idx] , & ref , 0 ) ; stream_idx = lavfi - > sink_stream_map[min_pts_sink_idx] ; if ( ref - > video ) { size = avpicture_get_size ( ref - > format , ref - > video - > w , ref - > video - > h ) ; if ( ( ret = av_new_packet ( pkt , size ) ) < 0 ) return ret ; memcpy ( pict . data , ref - > data , 4 * sizeof ( ref - > data[0] ) ) ; memcpy ( pict . linesize , ref - > linesize , 4 * sizeof ( ref - > linesize[0] ) ) ; avpicture_layout ( & pict , ref - > format , ref - > video - > w , ref - > video - > h , pkt - > data , size ) ; } else if ( ref - > audio ) { size = ref - > audio - > nb_samples * av_get_bytes_per_sample ( ref - > format ) * av_get_channel_layout_nb_channels ( ref - > audio - > channel_layout ) ; if ( ( ret = av_new_packet ( pkt , size ) ) < 0 ) return ret ; memcpy ( pkt - > data , ref - > data[0] , size ) ; } if ( ref - > metadata ) { uint8_t * metadata ; AVDictionaryEntry * e = NULL ; AVBPrint meta_buf ; av_bprint_init ( & meta_buf , 0 , AV_BPRINT_SIZE_UNLIMITED ) ; while ( ( e = av_dict_get ( ref - > metadata , , e , AV_DICT_IGNORE_SUFFIX ) ) ) { av_bprintf ( & meta_buf , %s , e - > key ) ; av_bprint_chars ( & meta_buf , ' \0 ' , 1 ) ; av_bprintf ( & meta_buf , %s , e - > value ) ; av_bprint_chars ( & meta_buf , ' \0 ' , 1 ) ; } if ( ! av_bprint_is_complete ( & meta_buf ) || ! ( metadata = av_packet_new_side_data ( pkt , AV_PKT_DATA_STRINGS_METADATA , meta_buf . len ) ) ) { av_bprint_finalize ( & meta_buf , NULL ) ; return AVERROR ( ENOMEM ) ; } memcpy ( metadata , meta_buf . str , meta_buf . len ) ; av_bprint_finalize ( & meta_buf , NULL ) ; } pkt - > stream_index = stream_idx ; pkt - > pts = ref - > pts ; pkt - > pos = ref - > pos ; pkt - > size = size ; avfilter_unref_buffer ( ref ) ; return size ; }",1
"static inline void qtrle_decode_2n4bpp ( QtrleContext * s , int stream_ptr , int row_ptr , int lines_to_change , int bpp ) { int rle_code , i ; int pixel_ptr ; int row_inc = s - > frame . linesize[0] ; unsigned char pi[16] ; / * 16 palette indices * / unsigned char * rgb = s - > frame . data[0] ; int pixel_limit = s - > frame . linesize[0] * s - > avctx - > height ; int num_pixels = ( bpp == 4 ) ? 8 : 16 ; while ( lines_to_change - - ) { CHECK_STREAM_PTR ( 2 ) ; pixel_ptr = row_ptr + ( num_pixels * ( s - > buf[stream_ptr + + ] - 1 ) ) ; while ( ( rle_code = ( signed char ) s - > buf[stream_ptr + + ] ) ! = - 1 ) { if ( rle_code == 0 ) { / * there ' s another skip code in the stream * / CHECK_STREAM_PTR ( 1 ) ; pixel_ptr + = ( num_pixels * ( s - > buf[stream_ptr + + ] - 1 ) ) ; } else if ( rle_code < 0 ) { / * decode the run length code * / rle_code = - rle_code ; / * get the next 4 bytes from the stream , treat them as palette * indexes , and output them rle_code times * / CHECK_STREAM_PTR ( 4 ) ; for ( i = num_pixels - 1 ; i > = 0 ; i - - ) { pi[num_pixels - 1 - i] = ( s - > buf[stream_ptr] > > ( ( i * bpp ) & 0x07 ) ) & ( ( 1 < < bpp ) - 1 ) ; stream_ptr + = ( ( i & ( ( num_pixels > > 2 ) - 1 ) ) == 0 ) ; } CHECK_PIXEL_PTR ( rle_code * num_pixels ) ; while ( rle_code - - ) { for ( i = 0 ; i < num_pixels ; i + + ) rgb[pixel_ptr + + ] = pi[i] ; } } else { / * copy the same pixel directly to output 4 times * / rle_code * = 4 ; CHECK_STREAM_PTR ( rle_code ) ; CHECK_PIXEL_PTR ( rle_code * ( num_pixels > > 2 ) ) ; while ( rle_code - - ) { if ( bpp == 4 ) { rgb[pixel_ptr + + ] = ( ( s - > buf[stream_ptr] ) > > 4 ) & 0x0f ; rgb[pixel_ptr + + ] = ( s - > buf[stream_ptr + + ] ) & 0x0f ; } else { rgb[pixel_ptr + + ] = ( ( s - > buf[stream_ptr] ) > > 6 ) & 0x03 ; rgb[pixel_ptr + + ] = ( ( s - > buf[stream_ptr] ) > > 4 ) & 0x03 ; rgb[pixel_ptr + + ] = ( ( s - > buf[stream_ptr] ) > > 2 ) & 0x03 ; rgb[pixel_ptr + + ] = ( s - > buf[stream_ptr + + ] ) & 0x03 ; } } } } row_ptr + = row_inc ; } }",1
"static void display_picref ( AVFilterBufferRef * picref , AVRational time_base ) { int x , y ; uint8_t * p0 , * p ; int64_t delay ; if ( picref - > pts ! = AV_NOPTS_VALUE ) { if ( last_pts ! = AV_NOPTS_VALUE ) { / * sleep roughly the right amount of time ; * usleep is in microseconds , just like AV_TIME_BASE . * / delay = av_rescale_q ( picref - > pts - last_pts , time_base , AV_TIME_BASE_Q ) ; if ( delay > 0 & & delay < 1000000 ) usleep ( delay ) ; } last_pts = picref - > pts ; } / * Trivial ASCII grayscale display . * / p0 = picref - > data[0] ; puts ( \033c ) ; for ( y = 0 ; y < picref - > video - > h ; y + + ) { p = p0 ; for ( x = 0 ; x < picref - > video - > w ; x + + ) putchar ( . - + [ * ( p + + ) / 52] ) ; putchar ( ' \n ' ) ; p0 + = picref - > linesize[0] ; } fflush ( stdout ) ; }",1
"static int decode_codestream ( J2kDecoderContext * s ) { J2kCodingStyle * codsty = s - > codsty ; J2kQuantStyle * qntsty = s - > qntsty ; uint8_t * properties = s - > properties ; for ( ; ; ) { int marker , len , ret = 0 ; const uint8_t * oldbuf ; if ( s - > buf_end - s - > buf < 2 ) { av_log ( s - > avctx , AV_LOG_ERROR , Missing EOC\n ) ; break ; } marker = bytestream_get_be16 ( & s - > buf ) ; if ( s - > avctx - > debug & FF_DEBUG_STARTCODE ) av_log ( s - > avctx , AV_LOG_DEBUG , marker 0x% . 4X at pos 0x%tx\n , marker , s - > buf - s - > buf_start - 4 ) ; oldbuf = s - > buf ; if ( marker == J2K_SOD ) { J2kTile * tile = s - > tile + s - > curtileno ; if ( ret = init_tile ( s , s - > curtileno ) ) return ret ; if ( ret = decode_packets ( s , tile ) ) return ret ; continue ; } if ( marker == J2K_EOC ) break ; if ( s - > buf_end - s - > buf < 2 ) return AVERROR ( EINVAL ) ; len = bytestream_get_be16 ( & s - > buf ) ; switch ( marker ) { case J2K_SIZ : ret = get_siz ( s ) ; break ; case J2K_COC : ret = get_coc ( s , codsty , properties ) ; break ; case J2K_COD : ret = get_cod ( s , codsty , properties ) ; break ; case J2K_QCC : ret = get_qcc ( s , len , qntsty , properties ) ; break ; case J2K_QCD : ret = get_qcd ( s , len , qntsty , properties ) ; break ; case J2K_SOT : if ( ! ( ret = get_sot ( s ) ) ) { codsty = s - > tile[s - > curtileno] . codsty ; qntsty = s - > tile[s - > curtileno] . qntsty ; properties = s - > tile[s - > curtileno] . properties ; } break ; case J2K_COM : // the comment is ignored s - > buf + = len - 2 ; break ; default : av_log ( s - > avctx , AV_LOG_ERROR , unsupported marker 0x% . 4X at pos 0x%tx\n , marker , s - > buf - s - > buf_start - 4 ) ; s - > buf + = len - 2 ; break ; } if ( s - > buf - oldbuf ! = len || ret ) { av_log ( s - > avctx , AV_LOG_ERROR , error during processing marker segment % . 4x\n , marker ) ; return ret ? ret : - 1 ; } } return 0 ; }",1
"static int read_channel_params ( MLPDecodeContext * m , unsigned int substr , GetBitContext * gbp , unsigned int ch ) { SubStream * s = & m - > substream[substr] ; ChannelParams * cp = & s - > channel_params[ch] ; FilterParams * fir = & cp - > filter_params[FIR] ; FilterParams * iir = & cp - > filter_params[IIR] ; int ret ; if ( s - > param_presence_flags & PARAM_FIR ) if ( get_bits1 ( gbp ) ) if ( ( ret = read_filter_params ( m , gbp , substr , ch , FIR ) ) < 0 ) return ret ; if ( s - > param_presence_flags & PARAM_IIR ) if ( get_bits1 ( gbp ) ) if ( ( ret = read_filter_params ( m , gbp , substr , ch , IIR ) ) < 0 ) return ret ; if ( fir - > order + iir - > order > 8 ) { av_log ( m - > avctx , AV_LOG_ERROR , Total filter orders too high . \n ) ; return AVERROR_INVALIDDATA ; } if ( fir - > order & & iir - > order & & fir - > shift ! = iir - > shift ) { av_log ( m - > avctx , AV_LOG_ERROR , FIR and IIR filters must use the same precision . \n ) ; return AVERROR_INVALIDDATA ; } / * The FIR and IIR filters must have the same precision . * To simplify the filtering code , only the precision of the * FIR filter is considered . If only the IIR filter is employed , * the FIR filter precision is set to that of the IIR filter , so * that the filtering code can use it . * / if ( ! fir - > order & & iir - > order ) fir - > shift = iir - > shift ; if ( s - > param_presence_flags & PARAM_HUFFOFFSET ) if ( get_bits1 ( gbp ) ) cp - > huff_offset = get_sbits ( gbp , 15 ) ; cp - > codebook = get_bits ( gbp , 2 ) ; cp - > huff_lsbs = get_bits ( gbp , 5 ) ; if ( cp - > huff_lsbs > 24 ) { av_log ( m - > avctx , AV_LOG_ERROR , Invalid huff_lsbs . \n ) ; cp - > huff_lsbs = 0 ; return AVERROR_INVALIDDATA ; } cp - > sign_huff_offset = calculate_sign_huff ( m , substr , ch ) ; return 0 ; }",1
"static int wsvqa_read_packet ( AVFormatContext * s , AVPacket * pkt ) { WsVqaDemuxContext * wsvqa = s - > priv_data ; AVIOContext * pb = s - > pb ; int ret = - 1 ; unsigned char preamble[VQA_PREAMBLE_SIZE] ; unsigned int chunk_type ; unsigned int chunk_size ; int skip_byte ; while ( avio_read ( pb , preamble , VQA_PREAMBLE_SIZE ) == VQA_PREAMBLE_SIZE ) { chunk_type = AV_RB32 ( & preamble[0] ) ; chunk_size = AV_RB32 ( & preamble[4] ) ; skip_byte = chunk_size & 0x01 ; if ( ( chunk_type == SND0_TAG ) || ( chunk_type == SND1_TAG ) || ( chunk_type == SND2_TAG ) || ( chunk_type == VQFR_TAG ) ) { ret= av_get_packet ( pb , pkt , chunk_size ) ; if ( ret < 0 ) return AVERROR ( EIO ) ; switch ( chunk_type ) { case SND0_TAG : case SND1_TAG : case SND2_TAG : if ( wsvqa - > audio_stream_index == - 1 ) { AVStream * st = avformat_new_stream ( s , NULL ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; wsvqa - > audio_stream_index = st - > index ; if ( ! wsvqa - > sample_rate ) wsvqa - > sample_rate = 22050 ; if ( ! wsvqa - > channels ) wsvqa - > channels = 1 ; if ( ! wsvqa - > bps ) wsvqa - > bps = 8 ; st - > codec - > sample_rate = wsvqa - > sample_rate ; st - > codec - > bits_per_coded_sample = wsvqa - > bps ; st - > codec - > channels = wsvqa - > channels ; st - > codec - > codec_type = AVMEDIA_TYPE_AUDIO ; avpriv_set_pts_info ( st , 64 , 1 , st - > codec - > sample_rate ) ; switch ( chunk_type ) { case SND0_TAG : if ( wsvqa - > bps == 16 ) st - > codec - > codec_id = AV_CODEC_ID_PCM_S16LE ; else st - > codec - > codec_id = AV_CODEC_ID_PCM_U8 ; break ; case SND1_TAG : st - > codec - > codec_id = AV_CODEC_ID_WESTWOOD_SND1 ; break ; case SND2_TAG : st - > codec - > codec_id = AV_CODEC_ID_ADPCM_IMA_WS ; st - > codec - > extradata_size = 2 ; st - > codec - > extradata = av_mallocz ( 2 + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! st - > codec - > extradata ) return AVERROR ( ENOMEM ) ; AV_WL16 ( st - > codec - > extradata , wsvqa - > version ) ; break ; } } pkt - > stream_index = wsvqa - > audio_stream_index ; switch ( chunk_type ) { case SND1_TAG : / * unpacked size is stored in header * / pkt - > duration = AV_RL16 ( pkt - > data ) / wsvqa - > channels ; break ; case SND2_TAG : / * 2 samples/byte , 1 or 2 samples per frame depending on stereo * / pkt - > duration = ( chunk_size * 2 ) / wsvqa - > channels ; break ; } break ; case VQFR_TAG : pkt - > stream_index = wsvqa - > video_stream_index ; pkt - > duration = 1 ; break ; } / * stay on 16 - bit alignment * / if ( skip_byte ) avio_skip ( pb , 1 ) ; return ret ; } else { switch ( chunk_type ) { case CMDS_TAG : break ; default : av_log ( s , AV_LOG_INFO , Skipping unknown chunk 0x%08X\n , chunk_type ) ; } avio_skip ( pb , chunk_size + skip_byte ) ; } } return ret ; }",1
"static int create_filter ( AVFilterContext * * filt_ctx , AVFilterGraph * ctx , int index , const char * filt_name , const char * args , void * log_ctx ) { AVFilter * filt ; char inst_name[30] ; char tmp_args[256] ; int ret ; snprintf ( inst_name , sizeof ( inst_name ) , Parsed_%s_%d , filt_name , index ) ; filt = avfilter_get_by_name ( filt_name ) ; if ( ! filt ) { av_log ( log_ctx , AV_LOG_ERROR , No such filter : ' %s ' \n , filt_name ) ; return AVERROR ( EINVAL ) ; } * filt_ctx = avfilter_graph_alloc_filter ( ctx , filt , inst_name ) ; if ( ! * filt_ctx ) { av_log ( log_ctx , AV_LOG_ERROR , Error creating filter ' %s ' \n , filt_name ) ; return AVERROR ( ENOMEM ) ; } if ( ! strcmp ( filt_name , scale ) & & args & & ! strstr ( args , flags ) & & ctx - > scale_sws_opts ) { snprintf ( tmp_args , sizeof ( tmp_args ) , %s : %s , args , ctx - > scale_sws_opts ) ; args = tmp_args ; } ret = avfilter_init_str ( * filt_ctx , args ) ; if ( ret < 0 ) { av_log ( log_ctx , AV_LOG_ERROR , Error initializing filter ' %s ' , filt_name ) ; if ( args ) av_log ( log_ctx , AV_LOG_ERROR , with args ' %s ' , args ) ; av_log ( log_ctx , AV_LOG_ERROR , \n ) ; return ret ; } return 0 ; }",0
"static void flush_packet ( AVFormatContext * ctx , int stream_index , int64_t pts , int64_t dts , int64_t scr ) { MpegMuxContext * s = ctx - > priv_data ; StreamInfo * stream = ctx - > streams[stream_index] - > priv_data ; uint8_t * buf_ptr ; int size , payload_size , startcode , id , stuffing_size , i , header_len ; int packet_size ; uint8_t buffer[128] ; int zero_trail_bytes = 0 ; int pad_packet_bytes = 0 ; id = stream - > id ; if 0 printf ( packet ID=%2x PTS=%0 . 3f\n , id , pts / 90000 . 0 ) ; endif buf_ptr = buffer ; if ( ( ( s - > packet_number % s - > pack_header_freq ) == 0 ) ) { / * output pack and systems header if needed * / size = put_pack_header ( ctx , buf_ptr , scr ) ; buf_ptr + = size ; if ( s - > is_vcd ) { / * there is exactly one system header for each stream in a VCD MPEG , One in the very first video packet and one in the very first audio packet ( see VCD standard p . IV - 7 and IV - 8 ) . * / if ( stream - > packet_number==0 ) { size = put_system_header ( ctx , buf_ptr , id ) ; buf_ptr + = size ; } } else { if ( ( s - > packet_number % s - > system_header_freq ) == 0 ) { size = put_system_header ( ctx , buf_ptr , 0 ) ; buf_ptr + = size ; } } } size = buf_ptr - buffer ; put_buffer ( & ctx - > pb , buffer , size ) ; packet_size = s - > packet_size - size ; if ( s - > is_vcd & & id == AUDIO_ID ) / * The VCD standard demands that 20 zero bytes follow each audio pack ( see standard p . IV - 8 ) . * / zero_trail_bytes + = 20 ; if ( s - > is_vcd & & stream - > packet_number==0 ) { / * the first pack of each stream contains only the pack header , the system header and lots of padding ( see VCD standard p . IV - 6 ) . In the case of an audio pack , 20 zero bytes are also added at the end . * / pad_packet_bytes = packet_size - zero_trail_bytes ; } packet_size - = pad_packet_bytes + zero_trail_bytes ; if ( packet_size > 0 ) { / * packet header size * / packet_size - = 6 ; / * packet header * / if ( s - > is_mpeg2 ) { header_len = 3 ; } else { header_len = 0 ; } if ( pts ! = AV_NOPTS_VALUE ) { if ( dts ! = pts ) header_len + = 5 + 5 ; else header_len + = 5 ; } else { if ( ! s - > is_mpeg2 ) header_len + + ; } payload_size = packet_size - header_len ; if ( id < 0xc0 ) { startcode = PRIVATE_STREAM_1 ; payload_size - = 4 ; if ( id > = 0xa0 ) payload_size - = 3 ; } else { startcode = 0x100 + id ; } stuffing_size = payload_size - stream - > buffer_ptr ; if ( stuffing_size < 0 ) stuffing_size = 0 ; put_be32 ( & ctx - > pb , startcode ) ; put_be16 ( & ctx - > pb , packet_size ) ; if ( ! s - > is_mpeg2 ) for ( i=0 ; i < stuffing_size ; i + + ) put_byte ( & ctx - > pb , 0xff ) ; if ( s - > is_mpeg2 ) { put_byte ( & ctx - > pb , 0x80 ) ; / * mpeg2 id * / if ( pts ! = AV_NOPTS_VALUE ) { if ( dts ! = pts ) { put_byte ( & ctx - > pb , 0xc0 ) ; / * flags * / put_byte ( & ctx - > pb , header_len - 3 + stuffing_size ) ; put_timestamp ( & ctx - > pb , 0x03 , pts ) ; put_timestamp ( & ctx - > pb , 0x01 , dts ) ; } else { put_byte ( & ctx - > pb , 0x80 ) ; / * flags * / put_byte ( & ctx - > pb , header_len - 3 + stuffing_size ) ; put_timestamp ( & ctx - > pb , 0x02 , pts ) ; } } else { put_byte ( & ctx - > pb , 0x00 ) ; / * flags * / put_byte ( & ctx - > pb , header_len - 3 + stuffing_size ) ; } } else { if ( pts ! = AV_NOPTS_VALUE ) { if ( dts ! = pts ) { put_timestamp ( & ctx - > pb , 0x03 , pts ) ; put_timestamp ( & ctx - > pb , 0x01 , dts ) ; } else { put_timestamp ( & ctx - > pb , 0x02 , pts ) ; } } else { put_byte ( & ctx - > pb , 0x0f ) ; } } if ( startcode == PRIVATE_STREAM_1 ) { put_byte ( & ctx - > pb , id ) ; if ( id > = 0xa0 ) { / * LPCM ( XXX : check nb_frames ) * / put_byte ( & ctx - > pb , 7 ) ; put_be16 ( & ctx - > pb , 4 ) ; / * skip 3 header bytes * / put_byte ( & ctx - > pb , stream - > lpcm_header[0] ) ; put_byte ( & ctx - > pb , stream - > lpcm_header[1] ) ; put_byte ( & ctx - > pb , stream - > lpcm_header[2] ) ; } else { / * AC3 * / put_byte ( & ctx - > pb , stream - > nb_frames ) ; put_be16 ( & ctx - > pb , stream - > frame_start_offset ) ; } } if ( s - > is_mpeg2 ) for ( i=0 ; i < stuffing_size ; i + + ) put_byte ( & ctx - > pb , 0xff ) ; / * output data * / put_buffer ( & ctx - > pb , stream - > buffer , payload_size - stuffing_size ) ; } if ( pad_packet_bytes > 0 ) put_padding_packet ( ctx , & ctx - > pb , pad_packet_bytes ) ; for ( i=0 ; i < zero_trail_bytes ; i + + ) put_byte ( & ctx - > pb , 0x00 ) ; put_flush_packet ( & ctx - > pb ) ; s - > packet_number + + ; stream - > packet_number + + ; stream - > nb_frames = 0 ; stream - > frame_start_offset = 0 ; }",0
void ff_xvmc_init_block ( MpegEncContext * s ) { struct xvmc_pix_fmt * render = ( struct xvmc_pix_fmt * ) s - > current_picture . f - > data[2] ; assert ( render & & render - > xvmc_id == AV_XVMC_ID ) ; s - > block = ( int16_t ( * ) [64] ) ( render - > data_blocks + render - > next_free_data_block_num * 64 ) ; },0
"static inline int small_diamond_search4MV ( MpegEncContext * s , int * best , int dmin , UINT8 * new_pic , UINT8 * old_pic , int pic_stride , int pred_x , int pred_y , UINT16 * mv_penalty , int quant , int xmin , int ymin , int xmax , int ymax , int shift ) { int next_dir= - 1 ; for ( ; ; ) { int d ; const int dir= next_dir ; const int x= best[0] ; const int y= best[1] ; next_dir= - 1 ; //printf ( %d , dir ) ; if ( dir ! =2 & & x > xmin ) CHECK_MV4_DIR ( x - 1 , y , 0 ) if ( dir ! =3 & & y > ymin ) CHECK_MV4_DIR ( x , y - 1 , 1 ) if ( dir ! =0 & & x < xmax ) CHECK_MV4_DIR ( x + 1 , y , 2 ) if ( dir ! =1 & & y < ymax ) CHECK_MV4_DIR ( x , y + 1 , 3 ) if ( next_dir== - 1 ) { return dmin ; } } }",0
"static inline void set_p_mv_tables ( MpegEncContext * s , int mx , int my ) { const int xy= s - > mb_x + 1 + ( s - > mb_y + 1 ) * ( s - > mb_width + 2 ) ; s - > p_mv_table[xy][0] = mx ; s - > p_mv_table[xy][1] = my ; / * has allready been set to the 4 MV if 4MV is done * / if ( ! ( s - > flags & CODEC_FLAG_4MV ) ) { int mot_xy= s - > block_index[0] ; s - > motion_val[mot_xy ][0]= mx ; s - > motion_val[mot_xy ][1]= my ; s - > motion_val[mot_xy + 1][0]= mx ; s - > motion_val[mot_xy + 1][1]= my ; mot_xy + = s - > block_wrap[0] ; s - > motion_val[mot_xy ][0]= mx ; s - > motion_val[mot_xy ][1]= my ; s - > motion_val[mot_xy + 1][0]= mx ; s - > motion_val[mot_xy + 1][1]= my ; } }",0
"static int hds_flush ( AVFormatContext * s , OutputStream * os , int final , int64_t end_ts ) { HDSContext * c = s - > priv_data ; int i , ret = 0 ; char target_filename[1024] ; int index = s - > streams[os - > first_stream] - > id ; if ( ! os - > packets_written ) return 0 ; avio_flush ( os - > ctx - > pb ) ; os - > packets_written = 0 ; close_file ( os ) ; snprintf ( target_filename , sizeof ( target_filename ) , %s/stream%dSeg1 - Frag%d , s - > filename , index , os - > fragment_index ) ; ret = ff_rename ( os - > temp_filename , target_filename ) ; if ( ret < 0 ) return ret ; add_fragment ( os , target_filename , os - > frag_start_ts , end_ts - os - > frag_start_ts ) ; if ( ! final ) { ret = init_file ( s , os , end_ts ) ; if ( ret < 0 ) return ret ; } if ( c - > window_size || ( final & & c - > remove_at_exit ) ) { int remove = os - > nb_fragments - c - > window_size - c - > extra_window_size ; if ( final & & c - > remove_at_exit ) remove = os - > nb_fragments ; if ( remove > 0 ) { for ( i = 0 ; i < remove ; i + + ) { unlink ( os - > fragments[i] - > file ) ; av_free ( os - > fragments[i] ) ; } os - > nb_fragments - = remove ; memmove ( os - > fragments , os - > fragments + remove , os - > nb_fragments * sizeof ( * os - > fragments ) ) ; } } if ( ret > = 0 ) ret = write_abst ( s , os , final ) ; return ret ; }",0
"static void init_input_filter ( FilterGraph * fg , AVFilterInOut * in ) { InputStream * ist ; enum AVMediaType type = avfilter_pad_get_type ( in - > filter_ctx - > input_pads , in - > pad_idx ) ; int i ; // TODO : support other filter types if ( type ! = AVMEDIA_TYPE_VIDEO & & type ! = AVMEDIA_TYPE_AUDIO ) { av_log ( NULL , AV_LOG_FATAL , Only video and audio filters supported currently . \n ) ; exit_program ( 1 ) ; } if ( in - > name ) { AVFormatContext * s ; AVStream * st = NULL ; char * p ; int file_idx = strtol ( in - > name , & p , 0 ) ; if ( file_idx < 0 || file_idx > = nb_input_files ) { av_log ( NULL , AV_LOG_FATAL , Invalid file index %d in filtegraph description %s . \n , file_idx , fg - > graph_desc ) ; exit_program ( 1 ) ; } s = input_files[file_idx] - > ctx ; for ( i = 0 ; i < s - > nb_streams ; i + + ) { if ( s - > streams[i] - > codec - > codec_type ! = type ) continue ; if ( check_stream_specifier ( s , s - > streams[i] , * p == ' : ' ? p + 1 : p ) == 1 ) { st = s - > streams[i] ; break ; } } if ( ! st ) { av_log ( NULL , AV_LOG_FATAL , Stream specifier ' %s ' in filtergraph description %s matches no streams . \n , p , fg - > graph_desc ) ; exit_program ( 1 ) ; } ist = input_streams[input_files[file_idx] - > ist_index + st - > index] ; } else { / * find the first unused stream of corresponding type * / for ( i = 0 ; i < nb_input_streams ; i + + ) { ist = input_streams[i] ; if ( ist - > st - > codec - > codec_type == type & & ist - > discard ) break ; } if ( i == nb_input_streams ) { av_log ( NULL , AV_LOG_FATAL , Cannot find a matching stream for unlabeled input pad %d on filter %s , in - > pad_idx , in - > filter_ctx - > name ) ; exit_program ( 1 ) ; } } ist - > discard = 0 ; ist - > decoding_needed = 1 ; ist - > st - > discard = AVDISCARD_NONE ; fg - > inputs = grow_array ( fg - > inputs , sizeof ( * fg - > inputs ) , & fg - > nb_inputs , fg - > nb_inputs + 1 ) ; if ( ! ( fg - > inputs[fg - > nb_inputs - 1] = av_mallocz ( sizeof ( * fg - > inputs[0] ) ) ) ) exit_program ( 1 ) ; fg - > inputs[fg - > nb_inputs - 1] - > ist = ist ; fg - > inputs[fg - > nb_inputs - 1] - > graph = fg ; ist - > filters = grow_array ( ist - > filters , sizeof ( * ist - > filters ) , & ist - > nb_filters , ist - > nb_filters + 1 ) ; ist - > filters[ist - > nb_filters - 1] = fg - > inputs[fg - > nb_inputs - 1] ; }",1
"static inline void RENAME ( yuy2ToY ) ( uint8_t * dst , uint8_t * src , int width ) { ifdef HAVE_MMX asm volatile ( movq MANGLE ( bm01010101 ) , %%mm2\n\t mov %0 , %% REG_a \n\t 1 : \n\t movq ( %1 , %% REG_a , 2 ) , %%mm0 \n\t movq 8 ( %1 , %% REG_a , 2 ) , %%mm1 \n\t pand %%mm2 , %%mm0 \n\t pand %%mm2 , %%mm1 \n\t packuswb %%mm1 , %%mm0 \n\t movq %%mm0 , ( %2 , %% REG_a ) \n\t add 8 , %% REG_a \n\t js 1b \n\t : : g ( ( long ) - width ) , r ( src + width * 2 ) , r ( dst + width ) : % REG_a ) ; else int i ; for ( i=0 ; i < width ; i + + ) dst[i]= src[2 * i] ; endif }",1
"av_cold void ff_msmpeg4_encode_init ( MpegEncContext * s ) { static int init_done=0 ; int i ; common_init ( s ) ; if ( s - > msmpeg4_version > =4 ) { s - > min_qcoeff= - 255 ; s - > max_qcoeff= 255 ; } if ( ! init_done ) { / * init various encoding tables * / init_done = 1 ; init_mv_table ( & mv_tables[0] ) ; init_mv_table ( & mv_tables[1] ) ; for ( i=0 ; i < NB_RL_TABLES ; i + + ) init_rl ( & rl_table[i] , static_rl_table_store[i] ) ; for ( i=0 ; i < NB_RL_TABLES ; i + + ) { int level ; for ( level=0 ; level < =MAX_LEVEL ; level + + ) { int run ; for ( run=0 ; run < =MAX_RUN ; run + + ) { int last ; for ( last=0 ; last < 2 ; last + + ) { rl_length[i][level][run][last]= get_size_of_code ( s , & rl_table[ i] , last , run , level , 0 ) ; } } } } } }",1
"av_cold void ff_init_range_decoder ( RangeCoder * c , const uint8_t * buf , int buf_size ) { / * cast to avoid compiler warning * / ff_init_range_encoder ( c , ( uint8_t * ) buf , buf_size ) ; c - > low = AV_RB16 ( c - > bytestream ) ; c - > bytestream + = 2 ;",1
"static int vcr1_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; VCR1Context * const a = avctx - > priv_data ; AVFrame * const p = data ; const uint8_t * bytestream = buf ; int i , x , y , ret ; if ( ( ret = ff_get_buffer ( avctx , p , 0 ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed\n ) ; return ret ; } p - > pict_type = AV_PICTURE_TYPE_I ; p - > key_frame = 1 ; if ( buf_size < 32 ) goto packet_small ; for ( i = 0 ; i < 16 ; i + + ) { a - > delta[i] = * bytestream + + ; bytestream + + ; buf_size - - ; } for ( y = 0 ; y < avctx - > height ; y + + ) { int offset ; uint8_t * luma = & p - > data[0][y * p - > linesize[0]] ; if ( ( y & 3 ) == 0 ) { uint8_t * cb = & p - > data[1][ ( y > > 2 ) * p - > linesize[1]] ; uint8_t * cr = & p - > data[2][ ( y > > 2 ) * p - > linesize[2]] ; if ( buf_size < 4 + avctx - > width ) goto packet_small ; for ( i = 0 ; i < 4 ; i + + ) a - > offset[i] = * bytestream + + ; buf_size - = 4 ; offset = a - > offset[0] - a - > delta[bytestream[2] & 0xF] ; for ( x = 0 ; x < avctx - > width ; x + = 4 ) { luma[0] = offset + = a - > delta[bytestream[2] & 0xF] ; luma[1] = offset + = a - > delta[bytestream[2] > > 4] ; luma[2] = offset + = a - > delta[bytestream[0] & 0xF] ; luma[3] = offset + = a - > delta[bytestream[0] > > 4] ; luma + = 4 ; * cb + + = bytestream[3] ; * cr + + = bytestream[1] ; bytestream + = 4 ; } } else { if ( buf_size < avctx - > width / 2 ) goto packet_small ; offset = a - > offset[y & 3] - a - > delta[bytestream[2] & 0xF] ; for ( x = 0 ; x < avctx - > width ; x + = 8 ) { luma[0] = offset + = a - > delta[bytestream[2] & 0xF] ; luma[1] = offset + = a - > delta[bytestream[2] > > 4] ; luma[2] = offset + = a - > delta[bytestream[3] & 0xF] ; luma[3] = offset + = a - > delta[bytestream[3] > > 4] ; luma[4] = offset + = a - > delta[bytestream[0] & 0xF] ; luma[5] = offset + = a - > delta[bytestream[0] > > 4] ; luma[6] = offset + = a - > delta[bytestream[1] & 0xF] ; luma[7] = offset + = a - > delta[bytestream[1] > > 4] ; luma + = 8 ; bytestream + = 4 ; } } } * got_frame = 1 ; return buf_size ; packet_small : av_log ( avctx , AV_LOG_ERROR , Input packet too small . \n ) ; return AVERROR_INVALIDDATA ; }",1
"static void sbr_hf_inverse_filter ( SBRDSPContext * dsp , int ( * alpha0 ) [2] , int ( * alpha1 ) [2] , const int X_low[32][40][2] , int k0 ) { int k ; int shift , round ; for ( k = 0 ; k < k0 ; k + + ) { SoftFloat phi[3][2][2] ; SoftFloat a00 , a01 , a10 , a11 ; SoftFloat dk ; dsp - > autocorrelate ( X_low[k] , phi ) ; dk = av_sub_sf ( av_mul_sf ( phi[2][1][0] , phi[1][0][0] ) , av_mul_sf ( av_add_sf ( av_mul_sf ( phi[1][1][0] , phi[1][1][0] ) , av_mul_sf ( phi[1][1][1] , phi[1][1][1] ) ) , FLOAT_0999999 ) ) ; if ( ! dk . mant ) { a10 = FLOAT_0 ; a11 = FLOAT_0 ; } else { SoftFloat temp_real , temp_im ; temp_real = av_sub_sf ( av_sub_sf ( av_mul_sf ( phi[0][0][0] , phi[1][1][0] ) , av_mul_sf ( phi[0][0][1] , phi[1][1][1] ) ) , av_mul_sf ( phi[0][1][0] , phi[1][0][0] ) ) ; temp_im = av_sub_sf ( av_add_sf ( av_mul_sf ( phi[0][0][0] , phi[1][1][1] ) , av_mul_sf ( phi[0][0][1] , phi[1][1][0] ) ) , av_mul_sf ( phi[0][1][1] , phi[1][0][0] ) ) ; a10 = av_div_sf ( temp_real , dk ) ; a11 = av_div_sf ( temp_im , dk ) ; } if ( ! phi[1][0][0] . mant ) { a00 = FLOAT_0 ; a01 = FLOAT_0 ; } else { SoftFloat temp_real , temp_im ; temp_real = av_add_sf ( phi[0][0][0] , av_add_sf ( av_mul_sf ( a10 , phi[1][1][0] ) , av_mul_sf ( a11 , phi[1][1][1] ) ) ) ; temp_im = av_add_sf ( phi[0][0][1] , av_sub_sf ( av_mul_sf ( a11 , phi[1][1][0] ) , av_mul_sf ( a10 , phi[1][1][1] ) ) ) ; temp_real . mant = - temp_real . mant ; temp_im . mant = - temp_im . mant ; a00 = av_div_sf ( temp_real , phi[1][0][0] ) ; a01 = av_div_sf ( temp_im , phi[1][0][0] ) ; } shift = a00 . exp ; if ( shift > = 3 ) alpha0[k][0] = 0x7fffffff ; else if ( shift < = - 30 ) alpha0[k][0] = 0 ; else { a00 . mant * = 2 ; shift = 2 - shift ; if ( shift == 0 ) alpha0[k][0] = a00 . mant ; else { round = 1 < < ( shift - 1 ) ; alpha0[k][0] = ( a00 . mant + round ) > > shift ; } } shift = a01 . exp ; if ( shift > = 3 ) alpha0[k][1] = 0x7fffffff ; else if ( shift < = - 30 ) alpha0[k][1] = 0 ; else { a01 . mant * = 2 ; shift = 2 - shift ; if ( shift == 0 ) alpha0[k][1] = a01 . mant ; else { round = 1 < < ( shift - 1 ) ; alpha0[k][1] = ( a01 . mant + round ) > > shift ; } } shift = a10 . exp ; if ( shift > = 3 ) alpha1[k][0] = 0x7fffffff ; else if ( shift < = - 30 ) alpha1[k][0] = 0 ; else { a10 . mant * = 2 ; shift = 2 - shift ; if ( shift == 0 ) alpha1[k][0] = a10 . mant ; else { round = 1 < < ( shift - 1 ) ; alpha1[k][0] = ( a10 . mant + round ) > > shift ; } } shift = a11 . exp ; if ( shift > = 3 ) alpha1[k][1] = 0x7fffffff ; else if ( shift < = - 30 ) alpha1[k][1] = 0 ; else { a11 . mant * = 2 ; shift = 2 - shift ; if ( shift == 0 ) alpha1[k][1] = a11 . mant ; else { round = 1 < < ( shift - 1 ) ; alpha1[k][1] = ( a11 . mant + round ) > > shift ; } } shift = ( int ) ( ( ( int64_t ) ( alpha1[k][0] > > 1 ) * ( alpha1[k][0] > > 1 ) + \ ( int64_t ) ( alpha1[k][1] > > 1 ) * ( alpha1[k][1] > > 1 ) + \ 0x40000000 ) > > 31 ) ; if ( shift > = 0x20000000 ) { alpha1[k][0] = 0 ; alpha1[k][1] = 0 ; alpha0[k][0] = 0 ; alpha0[k][1] = 0 ; } shift = ( int ) ( ( ( int64_t ) ( alpha0[k][0] > > 1 ) * ( alpha0[k][0] > > 1 ) + \ ( int64_t ) ( alpha0[k][1] > > 1 ) * ( alpha0[k][1] > > 1 ) + \ 0x40000000 ) > > 31 ) ; if ( shift > = 0x20000000 ) { alpha1[k][0] = 0 ; alpha1[k][1] = 0 ; alpha0[k][0] = 0 ; alpha0[k][1] = 0 ; } } }",1
"static int open_in ( HLSContext * c , AVIOContext * * in , const char * url ) { AVDictionary * tmp = NULL ; int ret ; av_dict_copy ( & tmp , c - > avio_opts , 0 ) ; ret = avio_open2 ( in , url , AVIO_FLAG_READ , c - > interrupt_callback , & tmp ) ; av_dict_free ( & tmp ) ; return ret ; }",0
"static int mov_write_trak_tag ( AVIOContext * pb , MOVMuxContext * mov , MOVTrack * track , AVStream * st ) { int64_t pos = avio_tell ( pb ) ; avio_wb32 ( pb , 0 ) ; / * size * / ffio_wfourcc ( pb , trak ) ; mov_write_tkhd_tag ( pb , track , st ) ; if ( supports_edts ( mov ) ) mov_write_edts_tag ( pb , track ) ; // PSP Movies and several other cases require edts box if ( track - > tref_tag ) mov_write_tref_tag ( pb , track ) ; mov_write_mdia_tag ( pb , track ) ; if ( track - > mode == MODE_PSP ) mov_write_uuid_tag_psp ( pb , track ) ; // PSP Movies require this uuid box if ( track - > tag == MKTAG ( ' r ' , ' t ' , ' p ' , ' ' ) ) mov_write_udta_sdp ( pb , track ) ; if ( track - > mode == MODE_MOV ) { if ( track - > enc - > codec_type == AVMEDIA_TYPE_VIDEO ) { double sample_aspect_ratio = av_q2d ( st - > sample_aspect_ratio ) ; if ( st - > sample_aspect_ratio . num & & 1 . 0 ! = sample_aspect_ratio ) { mov_write_tapt_tag ( pb , track ) ; } } if ( is_clcp_track ( track ) ) { mov_write_tapt_tag ( pb , track ) ; } } return update_size ( pb , pos ) ; }",0
"static int write_extradata ( FFV1Context * f ) { RangeCoder * const c = & f - > c ; uint8_t state[CONTEXT_SIZE] ; int i , j , k ; uint8_t state2[32][CONTEXT_SIZE] ; unsigned v ; memset ( state2 , 128 , sizeof ( state2 ) ) ; memset ( state , 128 , sizeof ( state ) ) ; f - > avctx - > extradata_size = 10000 + 4 + ( 11 * 11 * 5 * 5 * 5 + 11 * 11 * 11 ) * 32 ; f - > avctx - > extradata = av_malloc ( f - > avctx - > extradata_size ) ; ff_init_range_encoder ( c , f - > avctx - > extradata , f - > avctx - > extradata_size ) ; ff_build_rac_states ( c , 0 . 05 * ( 1LL < < 32 ) , 256 - 8 ) ; put_symbol ( c , state , f - > version , 0 ) ; if ( f - > version > 2 ) { if ( f - > version == 3 ) f - > minor_version = 2 ; put_symbol ( c , state , f - > minor_version , 0 ) ; } put_symbol ( c , state , f - > ac , 0 ) ; if ( f - > ac > 1 ) for ( i = 1 ; i < 256 ; i + + ) put_symbol ( c , state , f - > state_transition[i] - c - > one_state[i] , 1 ) ; put_symbol ( c , state , f - > colorspace , 0 ) ; // YUV cs type put_symbol ( c , state , f - > bits_per_raw_sample , 0 ) ; put_rac ( c , state , f - > chroma_planes ) ; put_symbol ( c , state , f - > chroma_h_shift , 0 ) ; put_symbol ( c , state , f - > chroma_v_shift , 0 ) ; put_rac ( c , state , f - > transparency ) ; put_symbol ( c , state , f - > num_h_slices - 1 , 0 ) ; put_symbol ( c , state , f - > num_v_slices - 1 , 0 ) ; put_symbol ( c , state , f - > quant_table_count , 0 ) ; for ( i = 0 ; i < f - > quant_table_count ; i + + ) write_quant_tables ( c , f - > quant_tables[i] ) ; for ( i = 0 ; i < f - > quant_table_count ; i + + ) { for ( j = 0 ; j < f - > context_count[i] * CONTEXT_SIZE ; j + + ) if ( f - > initial_states[i] & & f - > initial_states[i][0][j] ! = 128 ) break ; if ( j < f - > context_count[i] * CONTEXT_SIZE ) { put_rac ( c , state , 1 ) ; for ( j = 0 ; j < f - > context_count[i] ; j + + ) for ( k = 0 ; k < CONTEXT_SIZE ; k + + ) { int pred = j ? f - > initial_states[i][j - 1][k] : 128 ; put_symbol ( c , state2[k] , ( int8_t ) ( f - > initial_states[i][j][k] - pred ) , 1 ) ; } } else { put_rac ( c , state , 0 ) ; } } if ( f - > version > 2 ) { put_symbol ( c , state , f - > ec , 0 ) ; } f - > avctx - > extradata_size = ff_rac_terminate ( c ) ; v = av_crc ( av_crc_get_table ( AV_CRC_32_IEEE ) , 0 , f - > avctx - > extradata , f - > avctx - > extradata_size ) ; AV_WL32 ( f - > avctx - > extradata + f - > avctx - > extradata_size , v ) ; f - > avctx - > extradata_size + = 4 ; return 0 ; }",0
"static av_cold int ass_decode_init ( AVCodecContext * avctx ) { avctx - > subtitle_header = av_malloc ( avctx - > extradata_size ) ; if ( ! avctx - > extradata ) return AVERROR ( ENOMEM ) ; memcpy ( avctx - > subtitle_header , avctx - > extradata , avctx - > extradata_size ) ; avctx - > subtitle_header_size = avctx - > extradata_size ; return 0 ; }",0
"static int mpeg4_decode_gop_header ( MpegEncContext * s , GetBitContext * gb ) { int hours , minutes , seconds ; if ( ! show_bits ( gb , 18 ) ) { av_log ( s - > avctx , AV_LOG_WARNING , GOP header invalid\n ) ; return - 1 ; } hours= get_bits ( gb , 5 ) ; minutes= get_bits ( gb , 6 ) ; skip_bits1 ( gb ) ; seconds= get_bits ( gb , 6 ) ; s - > time_base= seconds + 60 * ( minutes + 60 * hours ) ; skip_bits1 ( gb ) ; skip_bits1 ( gb ) ; return 0 ; }",0
"static void init_vlcs ( ASV1Context * a ) { static int done = 0 ; if ( ! done ) { done = 1 ; init_vlc ( & ccp_vlc , VLC_BITS , 17 , & ccp_tab[0][1] , 2 , 1 , & ccp_tab[0][0] , 2 , 1 ) ; init_vlc ( & dc_ccp_vlc , VLC_BITS , 8 , & dc_ccp_tab[0][1] , 2 , 1 , & dc_ccp_tab[0][0] , 2 , 1 ) ; init_vlc ( & ac_ccp_vlc , VLC_BITS , 16 , & ac_ccp_tab[0][1] , 2 , 1 , & ac_ccp_tab[0][0] , 2 , 1 ) ; init_vlc ( & level_vlc , VLC_BITS , 7 , & level_tab[0][1] , 2 , 1 , & level_tab[0][0] , 2 , 1 ) ; init_vlc ( & asv2_level_vlc , ASV2_LEVEL_VLC_BITS , 63 , & asv2_level_tab[0][1] , 2 , 1 , & asv2_level_tab[0][0] , 2 , 1 ) ; } }",1
static int applehttp_close ( URLContext * h ) { AppleHTTPContext * s = h - > priv_data ; free_segment_list ( s ) ; free_variant_list ( s ) ; ffurl_close ( s - > seg_hd ) ; av_free ( s ) ; return 0 ; },1
"int swri_dither_init ( SwrContext * s , enum AVSampleFormat out_fmt , enum AVSampleFormat in_fmt ) { int i ; double scale = 0 ; if ( s - > dither . method > SWR_DITHER_TRIANGULAR_HIGHPASS & & s - > dither . method < = SWR_DITHER_NS ) return AVERROR ( EINVAL ) ; out_fmt = av_get_packed_sample_fmt ( out_fmt ) ; in_fmt = av_get_packed_sample_fmt ( in_fmt ) ; if ( in_fmt == AV_SAMPLE_FMT_FLT || in_fmt == AV_SAMPLE_FMT_DBL ) { if ( out_fmt == AV_SAMPLE_FMT_S32 ) scale = 1 . 0/ ( 1L < < 31 ) ; if ( out_fmt == AV_SAMPLE_FMT_S16 ) scale = 1 . 0/ ( 1L < < 15 ) ; if ( out_fmt == AV_SAMPLE_FMT_U8 ) scale = 1 . 0/ ( 1L < < 7 ) ; } if ( in_fmt == AV_SAMPLE_FMT_S32 & & out_fmt == AV_SAMPLE_FMT_S16 ) scale = 1L < < 16 ; if ( in_fmt == AV_SAMPLE_FMT_S32 & & out_fmt == AV_SAMPLE_FMT_U8 ) scale = 1L < < 24 ; if ( in_fmt == AV_SAMPLE_FMT_S16 & & out_fmt == AV_SAMPLE_FMT_U8 ) scale = 1L < < 8 ; scale * = s - > dither . scale ; s - > dither . ns_pos = 0 ; s - > dither . noise_scale= scale ; s - > dither . ns_scale = scale ; s - > dither . ns_scale_1 = 1/scale ; memset ( s - > dither . ns_errors , 0 , sizeof ( s - > dither . ns_errors ) ) ; for ( i=0 ; filters[i] . coefs ; i + + ) { const filter_t * f = & filters[i] ; if ( fabs ( s - > out_sample_rate - f - > rate ) / f - > rate < = . 05 & & f - > name == s - > dither . method ) { int j ; s - > dither . ns_taps = f - > len ; for ( j=0 ; j < f - > len ; j + + ) s - > dither . ns_coeffs[j] = f - > coefs[j] ; s - > dither . ns_scale_1 * = 1 - exp ( f - > gain_cB * M_LN10 * 0 . 005 ) * 2 / ( 1 < < ( 8 * av_get_bytes_per_sample ( out_fmt ) ) ) ; break ; } } if ( ! filters[i] . coefs & & s - > dither . method > SWR_DITHER_NS ) { av_log ( s , AV_LOG_WARNING , Requested noise shaping dither not available at this sampling rate , using triangular hp dither\n ) ; s - > dither . method = SWR_DITHER_TRIANGULAR_HIGHPASS ; } av_assert0 ( ! s - > preout . count ) ; s - > dither . noise = s - > preout ; s - > dither . temp = s - > preout ; if ( s - > dither . method > SWR_DITHER_NS ) { s - > dither . noise . bps = 4 ; s - > dither . noise . fmt = AV_SAMPLE_FMT_FLTP ; s - > dither . noise_scale = 1 ; } return 0 ; }",1
"static void h264_v_loop_filter_luma_intra_c ( uint8_t * pix , int stride , int alpha , int beta ) { h264_loop_filter_luma_intra_c ( pix , stride , 1 , alpha , beta ) ; }",0
"static int wsd_read_header ( AVFormatContext * s ) { AVIOContext * pb = s - > pb ; AVStream * st ; int version ; uint32_t text_offset , data_offset , channel_assign ; char playback_time[AV_TIMECODE_STR_SIZE] ; st = avformat_new_stream ( s , NULL ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; avio_skip ( pb , 8 ) ; version = avio_r8 ( pb ) ; av_log ( s , AV_LOG_DEBUG , version : %i . %i\n , version > > 4 , version & 0xF ) ; avio_skip ( pb , 11 ) ; if ( version < 0x10 ) { text_offset = 0x80 ; data_offset = 0x800 ; avio_skip ( pb , 8 ) ; } else { text_offset = avio_rb32 ( pb ) ; data_offset = avio_rb32 ( pb ) ; } avio_skip ( pb , 4 ) ; av_timecode_make_smpte_tc_string ( playback_time , avio_rb32 ( pb ) , 0 ) ; av_dict_set ( & s - > metadata , playback_time , playback_time , 0 ) ; st - > codecpar - > codec_type = AVMEDIA_TYPE_AUDIO ; st - > codecpar - > codec_id = s - > iformat - > raw_codec_id ; st - > codecpar - > sample_rate = avio_rb32 ( pb ) / 8 ; avio_skip ( pb , 4 ) ; st - > codecpar - > channels = avio_r8 ( pb ) & 0xF ; st - > codecpar - > bit_rate = st - > codecpar - > channels * st - > codecpar - > sample_rate * 8LL ; if ( ! st - > codecpar - > channels ) return AVERROR_INVALIDDATA ; avio_skip ( pb , 3 ) ; channel_assign = avio_rb32 ( pb ) ; if ( ! ( channel_assign & 1 ) ) { int i ; for ( i = 1 ; i < 32 ; i + + ) if ( channel_assign & ( 1 < < i ) ) st - > codecpar - > channel_layout |= wsd_to_av_channel_layoyt ( s , i ) ; } avio_skip ( pb , 16 ) ; if ( avio_rb32 ( pb ) ) avpriv_request_sample ( s , emphasis ) ; if ( avio_seek ( pb , text_offset , SEEK_SET ) > = 0 ) { get_metadata ( s , title , 128 ) ; get_metadata ( s , composer , 128 ) ; get_metadata ( s , song_writer , 128 ) ; get_metadata ( s , artist , 128 ) ; get_metadata ( s , album , 128 ) ; get_metadata ( s , genre , 32 ) ; get_metadata ( s , date , 32 ) ; get_metadata ( s , location , 32 ) ; get_metadata ( s , comment , 512 ) ; get_metadata ( s , user , 512 ) ; } return avio_seek ( pb , data_offset , SEEK_SET ) ; }",1
"static inline void decode_subblock3 ( DCTELEM * dst , int code , const int is_block2 , GetBitContext * gb , VLC * vlc , int q_dc , int q_ac1 , int q_ac2 ) { int coeffs[4] ; coeffs[0] = modulo_three_table[code][0] ; coeffs[1] = modulo_three_table[code][1] ; coeffs[2] = modulo_three_table[code][2] ; coeffs[3] = modulo_three_table[code][3] ; decode_coeff ( dst , coeffs[0] , 3 , gb , vlc , q_dc ) ; if ( is_block2 ) { decode_coeff ( dst + 8 , coeffs[1] , 2 , gb , vlc , q_ac1 ) ; decode_coeff ( dst + 1 , coeffs[2] , 2 , gb , vlc , q_ac1 ) ; } else { decode_coeff ( dst + 1 , coeffs[1] , 2 , gb , vlc , q_ac1 ) ; decode_coeff ( dst + 8 , coeffs[2] , 2 , gb , vlc , q_ac1 ) ; } decode_coeff ( dst + 9 , coeffs[3] , 2 , gb , vlc , q_ac2 ) ; }",0
"void ff_h264_remove_all_refs ( H264Context * h ) { int i ; for ( i = 0 ; i < 16 ; i + + ) { remove_long ( h , i , 0 ) ; } assert ( h - > long_ref_count == 0 ) ; ff_h264_unref_picture ( h , & h - > last_pic_for_ec ) ; if ( h - > short_ref_count ) ff_h264_ref_picture ( h , & h - > last_pic_for_ec , h - > short_ref[0] ) ; for ( i = 0 ; i < h - > short_ref_count ; i + + ) { unreference_pic ( h , h - > short_ref[i] , 0 ) ; h - > short_ref[i] = NULL ; } h - > short_ref_count = 0 ; memset ( h - > default_ref_list , 0 , sizeof ( h - > default_ref_list ) ) ; memset ( h - > ref_list , 0 , sizeof ( h - > ref_list ) ) ; }",0
static int mm_probe ( AVProbeData * p ) { / * the first chunk is always the header * / if ( p - > buf_size < MM_PREAMBLE_SIZE ) return 0 ; if ( AV_RL16 ( & p - > buf[0] ) ! = MM_TYPE_HEADER ) return 0 ; if ( AV_RL32 ( & p - > buf[2] ) ! = MM_HEADER_LEN_V & & AV_RL32 ( & p - > buf[2] ) ! = MM_HEADER_LEN_AV ) return 0 ; / * only return half certainty since this check is a bit sketchy * / return AVPROBE_SCORE_MAX / 2 ; },0
"static int tcp_write_packet ( AVFormatContext * s , RTSPStream * rtsp_st ) { RTSPState * rt = s - > priv_data ; AVFormatContext * rtpctx = rtsp_st - > transport_priv ; uint8_t * buf , * ptr ; int size ; uint8_t * interleave_header , * interleaved_packet ; size = avio_close_dyn_buf ( rtpctx - > pb , & buf ) ; ptr = buf ; while ( size > 4 ) { uint32_t packet_len = AV_RB32 ( ptr ) ; int id ; / * The interleaving header is exactly 4 bytes , which happens to be * the same size as the packet length header from * url_open_dyn_packet_buf . So by writing the interleaving header * over these bytes , we get a consecutive interleaved packet * that can be written in one call . * / interleaved_packet = interleave_header = ptr ; ptr + = 4 ; size - = 4 ; if ( packet_len > size || packet_len < 2 ) break ; if ( ptr[1] > = RTCP_SR & & ptr[1] < = RTCP_APP ) id = rtsp_st - > interleaved_max ; / * RTCP * / else id = rtsp_st - > interleaved_min ; / * RTP * / interleave_header[0] = ' ' ; interleave_header[1] = id ; AV_WB16 ( interleave_header + 2 , packet_len ) ; url_write ( rt - > rtsp_hd_out , interleaved_packet , 4 + packet_len ) ; ptr + = packet_len ; size - = packet_len ; } av_free ( buf ) ; url_open_dyn_packet_buf ( & rtpctx - > pb , RTSP_TCP_MAX_PACKET_SIZE ) ; return 0 ; }",0
"static int find_and_decode_index ( NUTContext * nut ) { AVFormatContext * s= nut - > avf ; ByteIOContext * bc = s - > pb ; uint64_t tmp , end ; int i , j , syncpoint_count ; int64_t filesize= url_fsize ( bc ) ; int64_t * syncpoints ; int8_t * has_keyframe ; url_fseek ( bc , filesize - 12 , SEEK_SET ) ; url_fseek ( bc , filesize - get_be64 ( bc ) , SEEK_SET ) ; if ( get_be64 ( bc ) ! = INDEX_STARTCODE ) { av_log ( s , AV_LOG_ERROR , no index at the end\n ) ; return - 1 ; } end= get_packetheader ( nut , bc , 1 , INDEX_STARTCODE ) ; end + = url_ftell ( bc ) ; ff_get_v ( bc ) ; //max_pts GET_V ( syncpoint_count , tmp < INT_MAX/8 & & tmp > 0 ) syncpoints= av_malloc ( sizeof ( int64_t ) * syncpoint_count ) ; has_keyframe= av_malloc ( sizeof ( int8_t ) * ( syncpoint_count + 1 ) ) ; for ( i=0 ; i < syncpoint_count ; i + + ) { GET_V ( syncpoints[i] , tmp > 0 ) if ( i ) syncpoints[i] + = syncpoints[i - 1] ; } for ( i=0 ; i < s - > nb_streams ; i + + ) { int64_t last_pts= - 1 ; for ( j=0 ; j < syncpoint_count ; ) { uint64_t x= ff_get_v ( bc ) ; int type= x & 1 ; int n= j ; x > > =1 ; if ( type ) { int flag= x & 1 ; x > > =1 ; if ( n + x > = syncpoint_count + 1 ) { av_log ( s , AV_LOG_ERROR , index overflow A\n ) ; return - 1 ; } while ( x - - ) has_keyframe[n + + ]= flag ; has_keyframe[n + + ]= ! flag ; } else { while ( x ! = 1 ) { if ( n > =syncpoint_count + 1 ) { av_log ( s , AV_LOG_ERROR , index overflow B\n ) ; return - 1 ; } has_keyframe[n + + ]= x & 1 ; x > > =1 ; } } if ( has_keyframe[0] ) { av_log ( s , AV_LOG_ERROR , keyframe before first syncpoint in index\n ) ; return - 1 ; } assert ( n < =syncpoint_count + 1 ) ; for ( ; j < n ; j + + ) { if ( has_keyframe[j] ) { uint64_t B , A= ff_get_v ( bc ) ; if ( ! A ) { A= ff_get_v ( bc ) ; B= ff_get_v ( bc ) ; //eor_pts[j][i] = last_pts + A + B } else B= 0 ; av_add_index_entry ( s - > streams[i] , 16 * syncpoints[j - 1] , last_pts + A , 0 , 0 , AVINDEX_KEYFRAME ) ; last_pts + = A + B ; } } } } if ( skip_reserved ( bc , end ) || get_checksum ( bc ) ) { av_log ( s , AV_LOG_ERROR , index checksum mismatch\n ) ; return - 1 ; } return 0 ; }",0
"x11grab_read_header ( AVFormatContext * s1 ) { struct x11grab * x11grab = s1 - > priv_data ; Display * dpy ; AVStream * st = NULL ; enum AVPixelFormat input_pixfmt ; XImage * image ; int x_off = 0 ; int y_off = 0 ; int screen ; int use_shm ; char * dpyname , * offset ; int ret = 0 ; Colormap color_map ; XColor color[256] ; int i ; dpyname = av_strdup ( s1 - > filename ) ; if ( ! dpyname ) goto out ; offset = strchr ( dpyname , ' + ' ) ; if ( offset ) { sscanf ( offset , %d , %d , & x_off , & y_off ) ; if ( strstr ( offset , nomouse ) ) { av_log ( s1 , AV_LOG_WARNING , ' nomouse ' specification in argument is deprecated : use ' draw_mouse ' option with value 0 instead\n ) ; x11grab - > draw_mouse = 0 ; } * offset= 0 ; } av_log ( s1 , AV_LOG_INFO , device : %s - > display : %s x : %d y : %d width : %d height : %d\n , s1 - > filename , dpyname , x_off , y_off , x11grab - > width , x11grab - > height ) ; dpy = XOpenDisplay ( dpyname ) ; av_freep ( & dpyname ) ; if ( ! dpy ) { av_log ( s1 , AV_LOG_ERROR , Could not open X display . \n ) ; ret = AVERROR ( EIO ) ; goto out ; } st = avformat_new_stream ( s1 , NULL ) ; if ( ! st ) { ret = AVERROR ( ENOMEM ) ; goto out ; } avpriv_set_pts_info ( st , 64 , 1 , 1000000 ) ; / * 64 bits pts in us * / screen = DefaultScreen ( dpy ) ; if ( x11grab - > follow_mouse ) { int screen_w , screen_h ; Window w ; screen_w = DisplayWidth ( dpy , screen ) ; screen_h = DisplayHeight ( dpy , screen ) ; XQueryPointer ( dpy , RootWindow ( dpy , screen ) , & w , & w , & x_off , & y_off , & ret , & ret , & ret ) ; x_off - = x11grab - > width / 2 ; y_off - = x11grab - > height / 2 ; x_off = FFMIN ( FFMAX ( x_off , 0 ) , screen_w - x11grab - > width ) ; y_off = FFMIN ( FFMAX ( y_off , 0 ) , screen_h - x11grab - > height ) ; av_log ( s1 , AV_LOG_INFO , followmouse is enabled , resetting grabbing region to x : %d y : %d\n , x_off , y_off ) ; } use_shm = XShmQueryExtension ( dpy ) ; av_log ( s1 , AV_LOG_INFO , shared memory extension%s found\n , use_shm ? : not ) ; if ( use_shm ) { int scr = XDefaultScreen ( dpy ) ; image = XShmCreateImage ( dpy , DefaultVisual ( dpy , scr ) , DefaultDepth ( dpy , scr ) , ZPixmap , NULL , & x11grab - > shminfo , x11grab - > width , x11grab - > height ) ; x11grab - > shminfo . shmid = shmget ( IPC_PRIVATE , image - > bytes_per_line * image - > height , IPC_CREAT|0777 ) ; if ( x11grab - > shminfo . shmid == - 1 ) { av_log ( s1 , AV_LOG_ERROR , Fatal : Can ' t get shared memory ! \n ) ; ret = AVERROR ( ENOMEM ) ; goto out ; } x11grab - > shminfo . shmaddr = image - > data = shmat ( x11grab - > shminfo . shmid , 0 , 0 ) ; x11grab - > shminfo . readOnly = False ; if ( ! XShmAttach ( dpy , & x11grab - > shminfo ) ) { av_log ( s1 , AV_LOG_ERROR , Fatal : Failed to attach shared memory ! \n ) ; / * needs some better error subroutine : ) * / ret = AVERROR ( EIO ) ; goto out ; } } else { image = XGetImage ( dpy , RootWindow ( dpy , screen ) , x_off , y_off , x11grab - > width , x11grab - > height , AllPlanes , ZPixmap ) ; } switch ( image - > bits_per_pixel ) { case 8 : av_log ( s1 , AV_LOG_DEBUG , 8 bit palette\n ) ; input_pixfmt = AV_PIX_FMT_PAL8 ; color_map = DefaultColormap ( dpy , screen ) ; for ( i = 0 ; i < 256 ; + + i ) color[i] . pixel = i ; XQueryColors ( dpy , color_map , color , 256 ) ; for ( i = 0 ; i < 256 ; + + i ) x11grab - > palette[i] = ( color[i] . red & 0xFF00 ) < < 8 | ( color[i] . green & 0xFF00 ) | ( color[i] . blue & 0xFF00 ) > > 8 ; x11grab - > palette_changed = 1 ; break ; case 16 : if ( image - > red_mask == 0xf800 & & image - > green_mask == 0x07e0 & & image - > blue_mask == 0x001f ) { av_log ( s1 , AV_LOG_DEBUG , 16 bit RGB565\n ) ; input_pixfmt = AV_PIX_FMT_RGB565 ; } else if ( image - > red_mask == 0x7c00 & & image - > green_mask == 0x03e0 & & image - > blue_mask == 0x001f ) { av_log ( s1 , AV_LOG_DEBUG , 16 bit RGB555\n ) ; input_pixfmt = AV_PIX_FMT_RGB555 ; } else { av_log ( s1 , AV_LOG_ERROR , RGB ordering at image depth %i not supported . . . aborting\n , image - > bits_per_pixel ) ; av_log ( s1 , AV_LOG_ERROR , color masks : r 0x% . 6lx g 0x% . 6lx b 0x% . 6lx\n , image - > red_mask , image - > green_mask , image - > blue_mask ) ; ret = AVERROR_PATCHWELCOME ; goto out ; } break ; case 24 : if ( image - > red_mask == 0xff0000 & & image - > green_mask == 0x00ff00 & & image - > blue_mask == 0x0000ff ) { input_pixfmt = AV_PIX_FMT_BGR24 ; } else if ( image - > red_mask == 0x0000ff & & image - > green_mask == 0x00ff00 & & image - > blue_mask == 0xff0000 ) { input_pixfmt = AV_PIX_FMT_RGB24 ; } else { av_log ( s1 , AV_LOG_ERROR , rgb ordering at image depth %i not supported . . . aborting\n , image - > bits_per_pixel ) ; av_log ( s1 , AV_LOG_ERROR , color masks : r 0x% . 6lx g 0x% . 6lx b 0x% . 6lx\n , image - > red_mask , image - > green_mask , image - > blue_mask ) ; ret = AVERROR_PATCHWELCOME ; goto out ; } break ; case 32 : input_pixfmt = AV_PIX_FMT_0RGB32 ; break ; default : av_log ( s1 , AV_LOG_ERROR , image depth %i not supported . . . aborting\n , image - > bits_per_pixel ) ; ret",0
"static int get_max_p_order ( int max_porder , int n , int order ) { int porder , max_parts ; porder = max_porder ; while ( porder > 0 ) { max_parts = ( 1 < < porder ) ; if ( ! ( n % max_parts ) & & ( n > max_parts * order ) ) { break ; } porder - - ; } return porder ; }",0
"static void vp8_h_loop_filter_simple_c ( uint8_t * dst , ptrdiff_t stride , int flim ) { int i ; for ( i = 0 ; i < 16 ; i + + ) if ( simple_limit ( dst + i * stride , 1 , flim ) ) filter_common ( dst + i * stride , 1 , 1 ) ; }",0
"static int get_packet_size ( const uint8_t * buf , int size ) { int score , fec_score , dvhs_score ; if ( size < ( TS_FEC_PACKET_SIZE * 5 + 1 ) ) return AVERROR_INVALIDDATA ; score = analyze ( buf , size , TS_PACKET_SIZE , NULL ) ; dvhs_score = analyze ( buf , size , TS_DVHS_PACKET_SIZE , NULL ) ; fec_score = analyze ( buf , size , TS_FEC_PACKET_SIZE , NULL ) ; av_dlog ( NULL , score : %d , dvhs_score : %d , fec_score : %d \n , score , dvhs_score , fec_score ) ; if ( score > fec_score & & score > dvhs_score ) return TS_PACKET_SIZE ; else if ( dvhs_score > score & & dvhs_score > fec_score ) return TS_DVHS_PACKET_SIZE ; else if ( score < fec_score & & dvhs_score < fec_score ) return TS_FEC_PACKET_SIZE ; else return AVERROR_INVALIDDATA ; }",1
"static void matroska_execute_seekhead ( MatroskaDemuxContext * matroska ) { EbmlList * seekhead_list = & matroska - > seekhead ; MatroskaSeekhead * seekhead = seekhead_list - > elem ; int64_t before_pos = avio_tell ( matroska - > ctx - > pb ) ; int i ; // we should not do any seeking in the streaming case if ( ! matroska - > ctx - > pb - > seekable || ( matroska - > ctx - > flags & AVFMT_FLAG_IGNIDX ) ) return ; for ( i = 0 ; i < seekhead_list - > nb_elem ; i + + ) { if ( seekhead[i] . pos < = before_pos ) continue ; // defer cues parsing until we actually need cue data . if ( seekhead[i] . id == MATROSKA_ID_CUES ) { matroska - > cues_parsing_deferred = 1 ; continue ; } if ( matroska_parse_seekhead_entry ( matroska , i ) < 0 ) break ; } }",1
"static void load_cursor ( VmncContext * c , const uint8_t * src ) { int i , j , p ; const int bpp = c - > bpp2 ; uint8_t * dst8 = c - > curbits ; uint16_t * dst16 = ( uint16_t * ) c - > curbits ; uint32_t * dst32 = ( uint32_t * ) c - > curbits ; for ( j = 0 ; j < c - > cur_h ; j + + ) { for ( i = 0 ; i < c - > cur_w ; i + + ) { p = vmnc_get_pixel ( src , bpp , c - > bigendian ) ; src + = bpp ; if ( bpp == 1 ) * dst8 + + = p ; if ( bpp == 2 ) * dst16 + + = p ; if ( bpp == 4 ) * dst32 + + = p ; } } dst8 = c - > curmask ; dst16 = ( uint16_t * ) c - > curmask ; dst32 = ( uint32_t * ) c - > curmask ; for ( j = 0 ; j < c - > cur_h ; j + + ) { for ( i = 0 ; i < c - > cur_w ; i + + ) { p = vmnc_get_pixel ( src , bpp , c - > bigendian ) ; src + = bpp ; if ( bpp == 1 ) * dst8 + + = p ; if ( bpp == 2 ) * dst16 + + = p ; if ( bpp == 4 ) * dst32 + + = p ; } } }",1
"av_cold void ff_dsputil_init ( DSPContext * c , AVCodecContext * avctx ) { int i , j ; ff_check_alignment ( ) ; if CONFIG_ENCODERS if ( avctx - > bits_per_raw_sample == 10 ) { c - > fdct = ff_jpeg_fdct_islow_10 ; c - > fdct248 = ff_fdct248_islow_10 ; } else { if ( avctx - > dct_algo==FF_DCT_FASTINT ) { c - > fdct = ff_fdct_ifast ; c - > fdct248 = ff_fdct_ifast248 ; } else if ( avctx - > dct_algo==FF_DCT_FAAN ) { c - > fdct = ff_faandct ; c - > fdct248 = ff_faandct248 ; } else { c - > fdct = ff_jpeg_fdct_islow_8 ; //slow/accurate/default c - > fdct248 = ff_fdct248_islow_8 ; } } endif //CONFIG_ENCODERS if ( avctx - > bits_per_raw_sample == 10 ) { c - > idct_put = ff_simple_idct_put_10 ; c - > idct_add = ff_simple_idct_add_10 ; c - > idct = ff_simple_idct_10 ; c - > idct_permutation_type = FF_NO_IDCT_PERM ; } else { if ( avctx - > idct_algo==FF_IDCT_INT ) { c - > idct_put= ff_jref_idct_put ; c - > idct_add= ff_jref_idct_add ; c - > idct = ff_j_rev_dct ; c - > idct_permutation_type= FF_LIBMPEG2_IDCT_PERM ; } else if ( ( CONFIG_VP3_DECODER || CONFIG_VP5_DECODER || CONFIG_VP6_DECODER ) & & avctx - > idct_algo==FF_IDCT_VP3 ) { c - > idct_put= ff_vp3_idct_put_c ; c - > idct_add= ff_vp3_idct_add_c ; c - > idct = ff_vp3_idct_c ; c - > idct_permutation_type= FF_NO_IDCT_PERM ; } else if ( avctx - > idct_algo==FF_IDCT_WMV2 ) { c - > idct_put= ff_wmv2_idct_put_c ; c - > idct_add= ff_wmv2_idct_add_c ; c - > idct = ff_wmv2_idct_c ; c - > idct_permutation_type= FF_NO_IDCT_PERM ; } else if ( avctx - > idct_algo==FF_IDCT_FAAN ) { c - > idct_put= ff_faanidct_put ; c - > idct_add= ff_faanidct_add ; c - > idct = ff_faanidct ; c - > idct_permutation_type= FF_NO_IDCT_PERM ; } else if ( CONFIG_EATGQ_DECODER & & avctx - > idct_algo==FF_IDCT_EA ) { c - > idct_put= ff_ea_idct_put_c ; c - > idct_permutation_type= FF_NO_IDCT_PERM ; } else { //accurate/default c - > idct_put = ff_simple_idct_put_8 ; c - > idct_add = ff_simple_idct_add_8 ; c - > idct = ff_simple_idct_8 ; c - > idct_permutation_type= FF_NO_IDCT_PERM ; } } c - > diff_pixels = diff_pixels_c ; c - > put_pixels_clamped = ff_put_pixels_clamped_c ; c - > put_signed_pixels_clamped = ff_put_signed_pixels_clamped_c ; c - > add_pixels_clamped = ff_add_pixels_clamped_c ; c - > sum_abs_dctelem = sum_abs_dctelem_c ; c - > gmc1 = gmc1_c ; c - > gmc = ff_gmc_c ; c - > pix_sum = pix_sum_c ; c - > pix_norm1 = pix_norm1_c ; c - > fill_block_tab[0] = fill_block16_c ; c - > fill_block_tab[1] = fill_block8_c ; / * TODO [0] 16 [1] 8 * / c - > pix_abs[0][0] = pix_abs16_c ; c - > pix_abs[0][1] = pix_abs16_x2_c ; c - > pix_abs[0][2] = pix_abs16_y2_c ; c - > pix_abs[0][3] = pix_abs16_xy2_c ; c - > pix_abs[1][0] = pix_abs8_c ; c - > pix_abs[1][1] = pix_abs8_x2_c ; c - > pix_abs[1][2] = pix_abs8_y2_c ; c - > pix_abs[1][3] = pix_abs8_xy2_c ; c - > put_tpel_pixels_tab[ 0] = put_tpel_pixels_mc00_c ; c - > put_tpel_pixels_tab[ 1] = put_tpel_pixels_mc10_c ; c - > put_tpel_pixels_tab[ 2] = put_tpel_pixels_mc20_c ; c - > put_tpel_pixels_tab[ 4] = put_tpel_pixels_mc01_c ; c - > put_tpel_pixels_tab[ 5] = put_tpel_pixels_mc11_c ; c - > put_tpel_pixels_tab[ 6] = put_tpel_pixels_mc21_c ; c - > put_tpel_pixels_tab[ 8] = put_tpel_pixels_mc02_c ; c - > put_tpel_pixels_tab[ 9] = put_tpel_pixels_mc12_c ; c - > put_tpel_pixels_tab[10] = put_tpel_pixels_mc22_c ; c - > avg_tpel_pixels_tab[ 0] = avg_tpel_pixels_mc00_c ; c - > avg_tpel_pixels_tab[ 1] = avg_tpel_pixels_mc10_c ; c - > avg_tpel_pixels_tab[ 2] = avg_tpel_pixels_mc20_c ; c - > avg_tpel_pixels_tab[ 4] = avg_tpel_pixels_mc01_c ; c - > avg_tpel_pixels_tab[ 5] = avg_tpel_pixels_mc11_c ; c - > avg_tpel_pixels_tab[ 6] = avg_tpel_pixels_mc21_c ; c - > avg_tpel_pixels_tab[ 8] = avg_tpel_pixels_mc02_c ; c - > avg_tpel_pixels_tab[ 9] = avg_tpel_pixels_mc12_c ; c - > avg_tpel_pixels_tab[10] = avg_tpel_pixels_mc22_c ; define dspfunc ( PFX , IDX , NUM ) \ c - > PFX _pixels_tab[IDX][ 0] = PFX NUM _mc00_c ; \ c - > PFX _pixels_tab[IDX][ 1] = PFX NUM _mc10_c ; \ c - > PFX _pixels_tab[IDX][ 2] = PFX NUM _mc20_c ; \ c - > PFX _pixels_tab[IDX][ 3] = PFX NUM _mc30_c ; \ c - > PFX _pixels_tab[IDX][ 4] = PFX NUM _mc01_c ; \ c - > PFX _pixels_tab[IDX][ 5] = PFX NUM _mc11_c ; \ c - > PFX _pixels_tab[IDX][ 6] = PFX NUM _mc21_c ; \ c - > PFX _pixels_tab[IDX][ 7] = PFX NUM _mc31_c ; \ c - > PFX _pixels_tab[IDX][ 8] = PFX NUM _mc02_c ; \ c - > PFX _pixels_tab[IDX][ 9] = PFX NUM _mc12_c ; \ c - > PFX _pixels_tab[IDX][10] = PFX NUM _mc22_c ; \ c - > PFX _pixels_tab[IDX][11] = PFX NUM _mc32_c ; \ c - > PFX _pixels_tab[IDX][12] = PFX NUM _mc03_c ; \ c - > PFX _pixels_tab[IDX][13] = PFX NUM _mc13_c ; \ c - > PFX _pixels_tab[IDX][14] = PFX NUM _mc23_c ; \ c - > PFX _pixels_tab[IDX][15] = PFX NUM _mc33_c dspfunc ( put_qpel , 0 , 16 ) ; dspfunc ( put_no_rnd_qpel , 0 , 16 ) ; dspfunc ( avg_qpel , 0 , 16 ) ; / * dspfunc ( avg_no_rnd_qpel , 0 , 16 ) ; * / dspfunc ( put_qpel , 1 , 8 ) ; dspfunc ( put_no_rnd_qpel , 1 , 8 ) ; dspfunc ( avg_qpel , 1 , 8 ) ; / * dspfunc ( avg_no_rnd_qpel , 1 , 8 ) ; * / undef dspfunc if CONFIG_MLP_DECODER || CONFIG_TRUEHD_DECODER ff_mlp_init ( c , avctx ) ; endif if CONFIG_WMV2_DECODER || CONFIG_VC1_DECODER ff_intrax8dsp_init ( c , avctx ) ; endif c - > put_mspel_pixels_tab[0]= ff_put_pixels8x8_c ; c - > put_mspel_pixels_tab[1]= put_mspel8_mc10_c ; c - > put_mspel_pixels_tab[2]= put_mspel8_mc20_c ; c - > put_mspel_pixels_tab[3]= put_mspel8_mc30_c ; c - > put_mspel_pixels_tab[4]= put_mspel8_mc02_c ; c - > put_mspel_pixels_tab[5]= put_mspel8_mc12_c ; c - > put_mspel_pixels_tab[6]= put_mspel8_mc22_c ; c - > put_mspel_pixels_tab[7]= put_mspel8_mc32_c ; define SET_CMP_FUNC ( name ) \ c - > name[0]= name 16_c ; \ c - > name[1]= name 8x8_c ; SET_CMP_FUNC ( hadamard8_diff ) c - > hadamard8_diff[4]= hadamard8_intra16_c ; c - > hadamard8_diff[5]= hadamard8_intra8x8_c ; SET_CMP_FUNC ( dct_sad ) SET_CMP_FUNC ( dct_max ) if CONFIG_GPL SET_CMP_FUNC ( dct264_sad ) endif c - > sad[0]= pix_abs16_c ; c - > sad[1]= pix_abs8_c ; c - > sse[0]= sse16_c ; c - > sse[1]= sse8_c ; c - > sse[2]= sse4_c ; SET_CMP_FUNC ( quant_psnr ) SET_CMP_FUNC ( rd ) SET_CMP_FUNC ( bit ) c - > vsad[0]= vsad16_c ; c - > vsad[4]= vsad_intra16_c ; c - > vsad[5]= vsad_intra8_c ; c - > vsse[0]= vsse16_c ; c - > vsse[4]= vsse_intra16_c ; c - > vsse[5]= vsse_intra8_c ; c - > nsse[0]= nsse16_c ; c - > nsse[1]= nsse8_c ; if CONFIG_DWT ff_dsputil_init_dwt ( c ) ; endif c - > ssd_int8_vs_int16 = ssd_int8_vs_int16_c ; c - > add_bytes= add_bytes_c ; c - > diff_bytes= diff_bytes_c ; c - > add_hfyu_median_prediction= add_hfyu_median_prediction_c ; c - > sub_hfyu_median_prediction= sub_hfyu_median_prediction_c ; c - > add_hfyu_left_prediction = add_hfyu_left_prediction_c ; c - > add_hfyu_left_prediction_bgr32 = add_hfyu_left_prediction_bgr32_c ; c - > bswap_buf= bswap_buf ; c -",0
"static int dash_flush ( AVFormatContext * s , int final , int stream ) { DASHContext * c = s - > priv_data ; int i , ret = 0 ; const char * proto = avio_find_protocol_name ( s - > filename ) ; int use_rename = proto & & ! strcmp ( proto , file ) ; int cur_flush_segment_index = 0 ; if ( stream > = 0 ) cur_flush_segment_index = c - > streams[stream] . segment_index ; for ( i = 0 ; i < s - > nb_streams ; i + + ) { OutputStream * os = & c - > streams[i] ; AVStream * st = s - > streams[i] ; char filename[1024] = , full_path[1024] , temp_path[1024] ; int range_length , index_length = 0 ; if ( ! os - > packets_written ) continue ; // Flush the single stream that got a keyframe right now . // Flush all audio streams as well , in sync with video keyframes , // but not the other video streams . if ( stream > = 0 & & i ! = stream ) { if ( s - > streams[i] - > codecpar - > codec_type ! = AVMEDIA_TYPE_AUDIO ) continue ; // Make sure we don ' t flush audio streams multiple times , when // all video streams are flushed one at a time . if ( c - > has_video & & os - > segment_index > cur_flush_segment_index ) continue ; } if ( ! os - > init_range_length ) { flush_init_segment ( s , os ) ; } if ( ! c - > single_file ) { ff_dash_fill_tmpl_params ( filename , sizeof ( filename ) , c - > media_seg_name , i , os - > segment_index , os - > bit_rate , os - > start_pts ) ; snprintf ( full_path , sizeof ( full_path ) , %s%s , c - > dirname , filename ) ; snprintf ( temp_path , sizeof ( temp_path ) , use_rename ? %s . tmp : %s , full_path ) ; ret = s - > io_open ( s , & os - > out , temp_path , AVIO_FLAG_WRITE , NULL ) ; if ( ret < 0 ) break ; if ( ! strcmp ( os - > format_name , mp4 ) ) write_styp ( os - > ctx - > pb ) ; } else { snprintf ( full_path , sizeof ( full_path ) , %s%s , c - > dirname , os - > initfile ) ; } ret = flush_dynbuf ( os , & range_length ) ; if ( ret < 0 ) break ; os - > packets_written = 0 ; if ( c - > single_file ) { find_index_range ( s , full_path , os - > pos , & index_length ) ; } else { ff_format_io_close ( s , & os - > out ) ; if ( use_rename ) { ret = avpriv_io_move ( temp_path , full_path ) ; if ( ret < 0 ) break ; } } if ( ! os - > bit_rate ) { // calculate average bitrate of first segment int64_t bitrate = ( int64_t ) range_length * 8 * AV_TIME_BASE / av_rescale_q ( os - > max_pts - os - > start_pts , st - > time_base , AV_TIME_BASE_Q ) ; if ( bitrate > = 0 ) { os - > bit_rate = bitrate ; snprintf ( os - > bandwidth_str , sizeof ( os - > bandwidth_str ) , bandwidth=\ %d\ , os - > bit_rate ) ; } } add_segment ( os , filename , os - > start_pts , os - > max_pts - os - > start_pts , os - > pos , range_length , index_length ) ; av_log ( s , AV_LOG_VERBOSE , Representation %d media segment %d written to : %s\n , i , os - > segment_index , full_path ) ; os - > pos + = range_length ; } if ( c - > window_size || ( final & & c - > remove_at_exit ) ) { for ( i = 0 ; i < s - > nb_streams ; i + + ) { OutputStream * os = & c - > streams[i] ; int j ; int remove = os - > nb_segments - c - > window_size - c - > extra_window_size ; if ( final & & c - > remove_at_exit ) remove = os - > nb_segments ; if ( remove > 0 ) { for ( j = 0 ; j < remove ; j + + ) { char filename[1024] ; snprintf ( filename , sizeof ( filename ) , %s%s , c - > dirname , os - > segments[j] - > file ) ; unlink ( filename ) ; av_free ( os - > segments[j] ) ; } os - > nb_segments - = remove ; memmove ( os - > segments , os - > segments + remove , os - > nb_segments * sizeof ( * os - > segments ) ) ; } } } if ( ret > = 0 ) ret = write_manifest ( s , final ) ; return ret ; }",0
"void put_pixels16_xy2_altivec ( uint8_t * block , const uint8_t * pixels , int line_size , int h ) { POWERPC_TBL_DECLARE ( altivec_put_pixels16_xy2_num , 1 ) ; ifdef ALTIVEC_USE_REFERENCE_C_CODE int j ; POWERPC_TBL_START_COUNT ( altivec_put_pixels16_xy2_num , 1 ) ; for ( j = 0 ; j < 4 ; j + + ) { int i ; const uint32_t a = ( ( ( const struct unaligned_32 * ) ( pixels ) ) - > l ) ; const uint32_t b = ( ( ( const struct unaligned_32 * ) ( pixels + 1 ) ) - > l ) ; uint32_t l0 = ( a & 0x03030303UL ) + ( b & 0x03030303UL ) + 0x02020202UL ; uint32_t h0 = ( ( a & 0xFCFCFCFCUL ) > > 2 ) + ( ( b & 0xFCFCFCFCUL ) > > 2 ) ; uint32_t l1 , h1 ; pixels + = line_size ; for ( i = 0 ; i < h ; i + = 2 ) { uint32_t a = ( ( ( const struct unaligned_32 * ) ( pixels ) ) - > l ) ; uint32_t b = ( ( ( const struct unaligned_32 * ) ( pixels + 1 ) ) - > l ) ; l1 = ( a & 0x03030303UL ) + ( b & 0x03030303UL ) ; h1 = ( ( a & 0xFCFCFCFCUL ) > > 2 ) + ( ( b & 0xFCFCFCFCUL ) > > 2 ) ; * ( ( uint32_t * ) block ) = h0 + h1 + ( ( ( l0 + l1 ) > > 2 ) & 0x0F0F0F0FUL ) ; pixels + = line_size ; block + = line_size ; a = ( ( ( const struct unaligned_32 * ) ( pixels ) ) - > l ) ; b = ( ( ( const struct unaligned_32 * ) ( pixels + 1 ) ) - > l ) ; l0 = ( a & 0x03030303UL ) + ( b & 0x03030303UL ) + 0x02020202UL ; h0 = ( ( a & 0xFCFCFCFCUL ) > > 2 ) + ( ( b & 0xFCFCFCFCUL ) > > 2 ) ; * ( ( uint32_t * ) block ) = h0 + h1 + ( ( ( l0 + l1 ) > > 2 ) & 0x0F0F0F0FUL ) ; pixels + = line_size ; block + = line_size ; } pixels + = 4 - line_size * ( h + 1 ) ; block + = 4 - line_size * h ; } POWERPC_TBL_STOP_COUNT ( altivec_put_pixels16_xy2_num , 1 ) ; else / * ALTIVEC_USE_REFERENCE_C_CODE * / register int i ; register vector unsigned char pixelsv1 , pixelsv2 , pixelsv3 , pixelsv4 ; register vector unsigned char blockv , temp1 , temp2 ; register vector unsigned short pixelssum1 , pixelssum2 , temp3 , pixelssum3 , pixelssum4 , temp4 ; register const vector unsigned char vczero = ( const vector unsigned char ) vec_splat_u8 ( 0 ) ; register const vector unsigned short vctwo = ( const vector unsigned short ) vec_splat_u16 ( 2 ) ; POWERPC_TBL_START_COUNT ( altivec_put_pixels16_xy2_num , 1 ) ; temp1 = vec_ld ( 0 , pixels ) ; temp2 = vec_ld ( 16 , pixels ) ; pixelsv1 = vec_perm ( temp1 , temp2 , vec_lvsl ( 0 , pixels ) ) ; if ( ( ( ( unsigned long ) pixels ) & 0x0000000F ) == 0x0000000F ) { pixelsv2 = temp2 ; } else { pixelsv2 = vec_perm ( temp1 , temp2 , vec_lvsl ( 1 , pixels ) ) ; } pixelsv3 = vec_mergel ( vczero , pixelsv1 ) ; pixelsv4 = vec_mergel ( vczero , pixelsv2 ) ; pixelsv1 = vec_mergeh ( vczero , pixelsv1 ) ; pixelsv2 = vec_mergeh ( vczero , pixelsv2 ) ; pixelssum3 = vec_add ( ( vector unsigned short ) pixelsv3 , ( vector unsigned short ) pixelsv4 ) ; pixelssum3 = vec_add ( pixelssum3 , vctwo ) ; pixelssum1 = vec_add ( ( vector unsigned short ) pixelsv1 , ( vector unsigned short ) pixelsv2 ) ; pixelssum1 = vec_add ( pixelssum1 , vctwo ) ; for ( i = 0 ; i < h ; i + + ) { blockv = vec_ld ( 0 , block ) ; temp1 = vec_ld ( line_size , pixels ) ; temp2 = vec_ld ( line_size + 16 , pixels ) ; pixelsv1 = vec_perm ( temp1 , temp2 , vec_lvsl ( line_size , pixels ) ) ; if ( ( ( ( ( unsigned long ) pixels ) + line_size ) & 0x0000000F ) == 0x0000000F ) { pixelsv2 = temp2 ; } else { pixelsv2 = vec_perm ( temp1 , temp2 , vec_lvsl ( line_size + 1 , pixels ) ) ; } pixelsv3 = vec_mergel ( vczero , pixelsv1 ) ; pixelsv4 = vec_mergel ( vczero , pixelsv2 ) ; pixelsv1 = vec_mergeh ( vczero , pixelsv1 ) ; pixelsv2 = vec_mergeh ( vczero , pixelsv2 ) ; pixelssum4 = vec_add ( ( vector unsigned short ) pixelsv3 , ( vector unsigned short ) pixelsv4 ) ; pixelssum2 = vec_add ( ( vector unsigned short ) pixelsv1 , ( vector unsigned short ) pixelsv2 ) ; temp4 = vec_add ( pixelssum3 , pixelssum4 ) ; temp4 = vec_sra ( temp4 , vctwo ) ; temp3 = vec_add ( pixelssum1 , pixelssum2 ) ; temp3 = vec_sra ( temp3 , vctwo ) ; pixelssum3 = vec_add ( pixelssum4 , vctwo ) ; pixelssum1 = vec_add ( pixelssum2 , vctwo ) ; blockv = vec_packsu ( temp3 , temp4 ) ; vec_st ( blockv , 0 , block ) ; block + = line_size ; pixels + = line_size ; } POWERPC_TBL_STOP_COUNT ( altivec_put_pixels16_xy2_num , 1 ) ; endif / * ALTIVEC_USE_REFERENCE_C_CODE * / }",0
"AVChapter * ff_new_chapter ( AVFormatContext * s , int id , AVRational time_base , int64_t start , int64_t end , const char * title ) { AVChapter * chapter = NULL ; int i ; for ( i=0 ; i < s - > nb_chapters ; i + + ) if ( s - > chapters[i] - > id == id ) chapter = s - > chapters[i] ; if ( ! chapter ) { chapter= av_mallocz ( sizeof ( AVChapter ) ) ; if ( ! chapter ) return NULL ; dynarray_add ( & s - > chapters , & s - > nb_chapters , chapter ) ; } if ( chapter - > title ) av_free ( chapter - > title ) ; chapter - > title = av_strdup ( title ) ; chapter - > id = id ; chapter - > time_base= time_base ; chapter - > start = start ; chapter - > end = end ; return chapter ; }",0
"int ff_hevc_split_packet ( HEVCContext * s , HEVCPacket * pkt , const uint8_t * buf , int length , AVCodecContext * avctx , int is_nalff , int nal_length_size ) { int consumed , ret = 0 ; pkt - > nb_nals = 0 ; while ( length > = 4 ) { HEVCNAL * nal ; int extract_length = 0 ; if ( is_nalff ) { int i ; for ( i = 0 ; i < nal_length_size ; i + + ) extract_length = ( extract_length < < 8 ) | buf[i] ; buf + = nal_length_size ; length - = nal_length_size ; if ( extract_length > length ) { av_log ( avctx , AV_LOG_ERROR , Invalid NAL unit size . \n ) ; return AVERROR_INVALIDDATA ; } } else { / * search start code * / while ( buf[0] ! = 0 || buf[1] ! = 0 || buf[2] ! = 1 ) { + + buf ; - - length ; if ( length < 4 ) { if ( pkt - > nb_nals > 0 ) { // No more start codes : we discarded some irrelevant // bytes at the end of the packet . return 0 ; } else { av_log ( avctx , AV_LOG_ERROR , No start code is found . \n ) ; return AVERROR_INVALIDDATA ; } } } buf + = 3 ; length - = 3 ; extract_length = length ; } if ( pkt - > nals_allocated < pkt - > nb_nals + 1 ) { int new_size = pkt - > nals_allocated + 1 ; void * tmp = av_realloc_array ( pkt - > nals , new_size , sizeof ( * pkt - > nals ) ) ; if ( ! tmp ) return AVERROR ( ENOMEM ) ; pkt - > nals = tmp ; memset ( pkt - > nals + pkt - > nals_allocated , 0 , ( new_size - pkt - > nals_allocated ) * sizeof ( * pkt - > nals ) ) ; nal = & pkt - > nals[pkt - > nb_nals] ; nal - > skipped_bytes_pos_size = 1024 ; // initial buffer size nal - > skipped_bytes_pos = av_malloc_array ( nal - > skipped_bytes_pos_size , sizeof ( * nal - > skipped_bytes_pos ) ) ; if ( ! nal - > skipped_bytes_pos ) return AVERROR ( ENOMEM ) ; pkt - > nals_allocated = new_size ; } nal = & pkt - > nals[pkt - > nb_nals] ; consumed = ff_hevc_extract_rbsp ( s , buf , extract_length , nal ) ; if ( consumed < 0 ) return consumed ; pkt - > nb_nals + + ; ret = init_get_bits8 ( & nal - > gb , nal - > data , nal - > size ) ; if ( ret < 0 ) return ret ; ret = hls_nal_unit ( nal , avctx ) ; if ( ret < = 0 ) { if ( ret < 0 ) { av_log ( avctx , AV_LOG_ERROR , Invalid NAL unit %d , skipping . \n , nal - > type ) ; } pkt - > nb_nals - - ; } buf + = consumed ; length - = consumed ; } return 0 ; }",0
"static int mxf_decrypt_triplet ( AVFormatContext * s , AVPacket * pkt , KLVPacket * klv ) { static const uint8_t checkv[16] = { 0x43 , 0x48 , 0x55 , 0x4b , 0x43 , 0x48 , 0x55 , 0x4b , 0x43 , 0x48 , 0x55 , 0x4b , 0x43 , 0x48 , 0x55 , 0x4b } ; MXFContext * mxf = s - > priv_data ; AVIOContext * pb = s - > pb ; int64_t end = avio_tell ( pb ) + klv - > length ; uint64_t size ; uint64_t orig_size ; uint64_t plaintext_size ; uint8_t ivec[16] ; uint8_t tmpbuf[16] ; int index ; if ( ! mxf - > aesc & & s - > key & & s - > keylen == 16 ) { mxf - > aesc = av_malloc ( av_aes_size ) ; if ( ! mxf - > aesc ) return - 1 ; av_aes_init ( mxf - > aesc , s - > key , 128 , 1 ) ; } // crypto context avio_skip ( pb , klv_decode_ber_length ( pb ) ) ; // plaintext offset klv_decode_ber_length ( pb ) ; plaintext_size = avio_rb64 ( pb ) ; // source klv key klv_decode_ber_length ( pb ) ; avio_read ( pb , klv - > key , 16 ) ; if ( ! IS_KLV_KEY ( klv , mxf_essence_element_key ) ) return - 1 ; index = mxf_get_stream_index ( s , klv ) ; if ( index < 0 ) return - 1 ; // source size klv_decode_ber_length ( pb ) ; orig_size = avio_rb64 ( pb ) ; if ( orig_size < plaintext_size ) return - 1 ; // enc . code size = klv_decode_ber_length ( pb ) ; if ( size < 32 || size - 32 < orig_size ) return - 1 ; avio_read ( pb , ivec , 16 ) ; avio_read ( pb , tmpbuf , 16 ) ; if ( mxf - > aesc ) av_aes_crypt ( mxf - > aesc , tmpbuf , tmpbuf , 1 , ivec , 1 ) ; if ( memcmp ( tmpbuf , checkv , 16 ) ) av_log ( s , AV_LOG_ERROR , probably incorrect decryption key\n ) ; size - = 32 ; av_get_packet ( pb , pkt , size ) ; size - = plaintext_size ; if ( mxf - > aesc ) av_aes_crypt ( mxf - > aesc , & pkt - > data[plaintext_size] , & pkt - > data[plaintext_size] , size > > 4 , ivec , 1 ) ; pkt - > size = orig_size ; pkt - > stream_index = index ; avio_skip ( pb , end - avio_tell ( pb ) ) ; return 0 ; }",1
"void avfilter_register_all ( void ) { static int initialized ; if ( initialized ) return ; initialized = 1 ; REGISTER_FILTER ( ACONVERT , aconvert , af ) ; REGISTER_FILTER ( AFIFO , afifo , af ) ; REGISTER_FILTER ( AFORMAT , aformat , af ) ; REGISTER_FILTER ( AMERGE , amerge , af ) ; REGISTER_FILTER ( AMIX , amix , af ) ; REGISTER_FILTER ( ANULL , anull , af ) ; REGISTER_FILTER ( ARESAMPLE , aresample , af ) ; REGISTER_FILTER ( ASETNSAMPLES , asetnsamples , af ) ; REGISTER_FILTER ( ASETPTS , asetpts , af ) ; REGISTER_FILTER ( ASETTB , asettb , af ) ; REGISTER_FILTER ( ASHOWINFO , ashowinfo , af ) ; REGISTER_FILTER ( ASPLIT , asplit , af ) ; REGISTER_FILTER ( ASTREAMSYNC , astreamsync , af ) ; REGISTER_FILTER ( ASYNCTS , asyncts , af ) ; REGISTER_FILTER ( ATEMPO , atempo , af ) ; REGISTER_FILTER ( CHANNELMAP , channelmap , af ) ; REGISTER_FILTER ( CHANNELSPLIT , channelsplit , af ) ; REGISTER_FILTER ( EARWAX , earwax , af ) ; REGISTER_FILTER ( JOIN , join , af ) ; REGISTER_FILTER ( PAN , pan , af ) ; REGISTER_FILTER ( SILENCEDETECT , silencedetect , af ) ; REGISTER_FILTER ( VOLUME , volume , af ) ; REGISTER_FILTER ( VOLUMEDETECT , volumedetect , af ) ; REGISTER_FILTER ( RESAMPLE , resample , af ) ; REGISTER_FILTER ( AEVALSRC , aevalsrc , asrc ) ; REGISTER_FILTER ( ANULLSRC , anullsrc , asrc ) ; REGISTER_FILTER ( FLITE , flite , asrc ) ; REGISTER_FILTER ( ABUFFERSINK , abuffersink , asink ) ; REGISTER_FILTER ( ANULLSINK , anullsink , asink ) ; REGISTER_FILTER ( ALPHAEXTRACT , alphaextract , vf ) ; REGISTER_FILTER ( ALPHAMERGE , alphamerge , vf ) ; REGISTER_FILTER ( ASS , ass , vf ) ; REGISTER_FILTER ( BBOX , bbox , vf ) ; REGISTER_FILTER ( BLACKDETECT , blackdetect , vf ) ; REGISTER_FILTER ( BLACKFRAME , blackframe , vf ) ; REGISTER_FILTER ( BOXBLUR , boxblur , vf ) ; REGISTER_FILTER ( COLORMATRIX , colormatrix , vf ) ; REGISTER_FILTER ( COPY , copy , vf ) ; REGISTER_FILTER ( CROP , crop , vf ) ; REGISTER_FILTER ( CROPDETECT , cropdetect , vf ) ; REGISTER_FILTER ( DECIMATE , decimate , vf ) ; REGISTER_FILTER ( DELOGO , delogo , vf ) ; REGISTER_FILTER ( DESHAKE , deshake , vf ) ; REGISTER_FILTER ( DRAWBOX , drawbox , vf ) ; REGISTER_FILTER ( DRAWTEXT , drawtext , vf ) ; REGISTER_FILTER ( EDGEDETECT , edgedetect , vf ) ; REGISTER_FILTER ( FADE , fade , vf ) ; REGISTER_FILTER ( FIELDORDER , fieldorder , vf ) ; REGISTER_FILTER ( FIFO , fifo , vf ) ; REGISTER_FILTER ( FORMAT , format , vf ) ; REGISTER_FILTER ( FPS , fps , vf ) ; REGISTER_FILTER ( FRAMESTEP , framestep , vf ) ; REGISTER_FILTER ( FREI0R , frei0r , vf ) ; REGISTER_FILTER ( GRADFUN , gradfun , vf ) ; REGISTER_FILTER ( HFLIP , hflip , vf ) ; REGISTER_FILTER ( HQDN3D , hqdn3d , vf ) ; REGISTER_FILTER ( HUE , hue , vf ) ; REGISTER_FILTER ( IDET , idet , vf ) ; REGISTER_FILTER ( LUT , lut , vf ) ; REGISTER_FILTER ( LUTRGB , lutrgb , vf ) ; REGISTER_FILTER ( LUTYUV , lutyuv , vf ) ; REGISTER_FILTER ( MP , mp , vf ) ; REGISTER_FILTER ( NEGATE , negate , vf ) ; REGISTER_FILTER ( NOFORMAT , noformat , vf ) ; REGISTER_FILTER ( NULL , null , vf ) ; REGISTER_FILTER ( OCV , ocv , vf ) ; REGISTER_FILTER ( OVERLAY , overlay , vf ) ; REGISTER_FILTER ( PAD , pad , vf ) ; REGISTER_FILTER ( PIXDESCTEST , pixdesctest , vf ) ; REGISTER_FILTER ( REMOVELOGO , removelogo , vf ) ; REGISTER_FILTER ( SCALE , scale , vf ) ; REGISTER_FILTER ( SELECT , select , vf ) ; REGISTER_FILTER ( SETDAR , setdar , vf ) ; REGISTER_FILTER ( SETFIELD , setfield , vf ) ; REGISTER_FILTER ( SETPTS , setpts , vf ) ; REGISTER_FILTER ( SETSAR , setsar , vf ) ; REGISTER_FILTER ( SETTB , settb , vf ) ; REGISTER_FILTER ( SHOWINFO , showinfo , vf ) ; REGISTER_FILTER ( SLICIFY , slicify , vf ) ; REGISTER_FILTER ( SMARTBLUR , smartblur , vf ) ; REGISTER_FILTER ( SPLIT , split , vf ) ; REGISTER_FILTER ( SUPER2XSAI , super2xsai , vf ) ; REGISTER_FILTER ( SWAPUV , swapuv , vf ) ; REGISTER_FILTER ( THUMBNAIL , thumbnail , vf ) ; REGISTER_FILTER ( TILE , tile , vf ) ; REGISTER_FILTER ( TINTERLACE , tinterlace , vf ) ; REGISTER_FILTER ( TRANSPOSE , transpose , vf ) ; REGISTER_FILTER ( UNSHARP , unsharp , vf ) ; REGISTER_FILTER ( VFLIP , vflip , vf ) ; REGISTER_FILTER ( YADIF , yadif , vf ) ; REGISTER_FILTER ( CELLAUTO , cellauto , vsrc ) ; REGISTER_FILTER ( COLOR , color , vsrc ) ; REGISTER_FILTER ( FREI0R , frei0r_src , vsrc ) ; REGISTER_FILTER ( LIFE , life , vsrc ) ; REGISTER_FILTER ( MANDELBROT , mandelbrot , vsrc ) ; REGISTER_FILTER ( MPTESTSRC , mptestsrc , vsrc ) ; REGISTER_FILTER ( NULLSRC , nullsrc , vsrc ) ; REGISTER_FILTER ( RGBTESTSRC , rgbtestsrc , vsrc ) ; REGISTER_FILTER ( SMPTEBARS , smptebars , vsrc ) ; REGISTER_FILTER ( TESTSRC , testsrc , vsrc ) ; REGISTER_FILTER ( BUFFERSINK , buffersink , vsink ) ; REGISTER_FILTER ( FFBUFFERSINK , ffbuffersink , vsink ) ; REGISTER_FILTER ( NULLSINK , nullsink , vsink ) ; / * multimedia filters * / REGISTER_FILTER ( CONCAT , concat , avf ) ; REGISTER_FILTER ( SHOWSPECTRUM , showspectrum , avf ) ; REGISTER_FILTER ( SHOWWAVES , showwaves , avf ) ; / * multimedia sources * / REGISTER_FILTER ( AMOVIE , amovie , avsrc ) ; REGISTER_FILTER ( MOVIE , movie , avsrc ) ; / * those filters are part of public or internal API = > registered * unconditionally * / { extern AVFilter avfilter_vsrc_buffer ; avfilter_register ( & avfilter_vsrc_buffer ) ; } { extern AVFilter avfilter_asrc_abuffer ; avfilter_register ( & avfilter_asrc_abuffer ) ; } { extern AVFilter avfilter_vsink_buffer ; avfilter_register ( & avfilter_vsink_buffer ) ; } { extern AVFilter avfilter_asink_abuffer ; avfilter_register ( & avfilter_asink_abuffer ) ; } }",1
"static void qtrle_decode_16bpp ( QtrleContext * s ) { int stream_ptr ; int header ; int start_line ; int lines_to_change ; signed char rle_code ; int row_ptr , pixel_ptr ; int row_inc = s - > frame . linesize[0] ; unsigned short rgb16 ; unsigned char * rgb = s - > frame . data[0] ; int pixel_limit = s - > frame . linesize[0] * s - > avctx - > height ; / * check if this frame is even supposed to change * / if ( s - > size < 8 ) return ; / * start after the chunk size * / stream_ptr = 4 ; / * fetch the header * / CHECK_STREAM_PTR ( 2 ) ; header = BE_16 ( & s - > buf[stream_ptr] ) ; stream_ptr + = 2 ; / * if a header is present , fetch additional decoding parameters * / if ( header & 0x0008 ) { CHECK_STREAM_PTR ( 8 ) ; start_line = BE_16 ( & s - > buf[stream_ptr] ) ; stream_ptr + = 4 ; lines_to_change = BE_16 ( & s - > buf[stream_ptr] ) ; stream_ptr + = 4 ; } else { start_line = 0 ; lines_to_change = s - > avctx - > height ; } row_ptr = row_inc * start_line ; while ( lines_to_change - - ) { CHECK_STREAM_PTR ( 2 ) ; pixel_ptr = row_ptr + ( s - > buf[stream_ptr + + ] - 1 ) * 2 ; while ( ( rle_code = ( signed char ) s - > buf[stream_ptr + + ] ) ! = - 1 ) { if ( rle_code == 0 ) { / * there ' s another skip code in the stream * / CHECK_STREAM_PTR ( 1 ) ; pixel_ptr + = ( s - > buf[stream_ptr + + ] - 1 ) * 2 ; CHECK_PIXEL_PTR ( 0 ) ; / * make sure pixel_ptr is positive * / } else if ( rle_code < 0 ) { / * decode the run length code * / rle_code = - rle_code ; CHECK_STREAM_PTR ( 2 ) ; rgb16 = BE_16 ( & s - > buf[stream_ptr] ) ; stream_ptr + = 2 ; CHECK_PIXEL_PTR ( rle_code * 2 ) ; while ( rle_code - - ) { * ( unsigned short * ) ( & rgb[pixel_ptr] ) = rgb16 ; pixel_ptr + = 2 ; } } else { CHECK_STREAM_PTR ( rle_code * 2 ) ; CHECK_PIXEL_PTR ( rle_code * 2 ) ; / * copy pixels directly to output * / while ( rle_code - - ) { rgb16 = BE_16 ( & s - > buf[stream_ptr] ) ; stream_ptr + = 2 ; * ( unsigned short * ) ( & rgb[pixel_ptr] ) = rgb16 ; pixel_ptr + = 2 ; } } } row_ptr + = row_inc ; } }",1
"void show_banner ( void ) { fprintf ( stderr , %s version FFMPEG_VERSION , Copyright ( c ) %d - %d the FFmpeg developers\n , program_name , program_birth_year , this_year ) ; fprintf ( stderr , built on %s %s with %s %s\n , __DATE__ , __TIME__ , CC_TYPE , CC_VERSION ) ; fprintf ( stderr , configuration : FFMPEG_CONFIGURATION \n ) ; print_all_libs_info ( stderr , INDENT|SHOW_CONFIG ) ; print_all_libs_info ( stderr , INDENT|SHOW_VERSION ) ; }",0
"static int decode_delta_block ( bit_buffer_t * bitbuf , uint8_t * current , uint8_t * previous , int pitch , svq1_pmv_t * motion , int x , int y ) { uint32_t bit_cache ; uint32_t block_type ; int result = 0 ; / * get block type * / bit_cache = get_bit_cache ( bitbuf ) ; bit_cache > > = ( 32 - 3 ) ; block_type = block_type_table[bit_cache] . value ; skip_bits ( bitbuf , block_type_table[bit_cache] . length ) ; / * reset motion vectors * / if ( block_type == SVQ1_BLOCK_SKIP || block_type == SVQ1_BLOCK_INTRA ) { motion[0] . x = 0 ; motion[0] . y = 0 ; motion[ ( x / 8 ) + 2] . x = 0 ; motion[ ( x / 8 ) + 2] . y = 0 ; motion[ ( x / 8 ) + 3] . x = 0 ; motion[ ( x / 8 ) + 3] . y = 0 ; } switch ( block_type ) { case SVQ1_BLOCK_SKIP : skip_block ( current , previous , pitch , x , y ) ; break ; case SVQ1_BLOCK_INTER : result = motion_inter_block ( bitbuf , current , previous , pitch , motion , x , y ) ; if ( result ! = 0 ) { ifdef DEBUG_SVQ1 printf ( Error in motion_inter_block %i\n , result ) ; endif break ; } result = decode_svq1_block ( bitbuf , current , pitch , 0 ) ; break ; case SVQ1_BLOCK_INTER_4V : result = motion_inter_4v_block ( bitbuf , current , previous , pitch , motion , x , y ) ; if ( result ! = 0 ) { ifdef DEBUG_SVQ1 printf ( Error in motion_inter_4v_block %i\n , result ) ; endif break ; } result = decode_svq1_block ( bitbuf , current , pitch , 0 ) ; break ; case SVQ1_BLOCK_INTRA : result = decode_svq1_block ( bitbuf , current , pitch , 1 ) ; break ; } return result ; }",0
"void powerpc_display_perf_report ( void ) { int i ; ifndef POWERPC_PERF_USE_PMC fprintf ( stderr , PowerPC performance report\n Values are from the Time Base register , and represent 4 bus cycles . \n ) ; else / * POWERPC_PERF_USE_PMC * / fprintf ( stderr , PowerPC performance report\n Values are from the PMC registers , and represent whatever the registers are set to record . \n ) ; endif / * POWERPC_PERF_USE_PMC * / for ( i = 0 ; i < powerpc_perf_total ; i + + ) { if ( perfdata[i][powerpc_data_num] ! = ( unsigned long long ) 0 ) fprintf ( stderr , Function \ %s\ ( pmc1 ) : \n\tmin : %llu\n\tmax : %llu\n\tavg : %1 . 2lf ( %llu ) \n , perfname[i] , perfdata[i][powerpc_data_min] , perfdata[i][powerpc_data_max] , ( double ) perfdata[i][powerpc_data_sum] / ( double ) perfdata[i][powerpc_data_num] , perfdata[i][powerpc_data_num] ) ; ifdef POWERPC_PERF_USE_PMC if ( perfdata_pmc2[i][powerpc_data_num] ! = ( unsigned long long ) 0 ) fprintf ( stderr , Function \ %s\ ( pmc2 ) : \n\tmin : %llu\n\tmax : %llu\n\tavg : %1 . 2lf ( %llu ) \n , perfname[i] , perfdata_pmc2[i][powerpc_data_min] , perfdata_pmc2[i][powerpc_data_max] , ( double ) perfdata_pmc2[i][powerpc_data_sum] / ( double ) perfdata_pmc2[i][powerpc_data_num] , perfdata_pmc2[i][powerpc_data_num] ) ; if ( perfdata_pmc3[i][powerpc_data_num] ! = ( unsigned long long ) 0 ) fprintf ( stderr , Function \ %s\ ( pmc3 ) : \n\tmin : %llu\n\tmax : %llu\n\tavg : %1 . 2lf ( %llu ) \n , perfname[i] , perfdata_pmc3[i][powerpc_data_min] , perfdata_pmc3[i][powerpc_data_max] , ( double ) perfdata_pmc3[i][powerpc_data_sum] / ( double ) perfdata_pmc3[i][powerpc_data_num] , perfdata_pmc3[i][powerpc_data_num] ) ; endif } }",0
"static int msrle_decode_pal4 ( AVCodecContext * avctx , AVPicture * pic , const uint8_t * data , int data_size ) { int stream_ptr = 0 ; unsigned char rle_code ; unsigned char extra_byte , odd_pixel ; unsigned char stream_byte ; int pixel_ptr = 0 ; int row_dec = pic - > linesize[0] ; int row_ptr = ( avctx - > height - 1 ) * row_dec ; int frame_size = row_dec * avctx - > height ; int i ; while ( row_ptr > = 0 ) { FETCH_NEXT_STREAM_BYTE ( ) ; rle_code = stream_byte ; if ( rle_code == 0 ) { / * fetch the next byte to see how to handle escape code * / FETCH_NEXT_STREAM_BYTE ( ) ; if ( stream_byte == 0 ) { / * line is done , goto the next one * / row_ptr - = row_dec ; pixel_ptr = 0 ; } else if ( stream_byte == 1 ) { / * decode is done * / return 0 ; } else if ( stream_byte == 2 ) { / * reposition frame decode coordinates * / FETCH_NEXT_STREAM_BYTE ( ) ; pixel_ptr + = stream_byte ; FETCH_NEXT_STREAM_BYTE ( ) ; row_ptr - = stream_byte * row_dec ; } else { // copy pixels from encoded stream odd_pixel = stream_byte & 1 ; rle_code = ( stream_byte + 1 ) / 2 ; extra_byte = rle_code & 0x01 ; if ( row_ptr + pixel_ptr + stream_byte > frame_size ) { av_log ( avctx , AV_LOG_ERROR , MS RLE : frame ptr just went out of bounds ( 1 ) \n ) ; return - 1 ; } for ( i = 0 ; i < rle_code ; i + + ) { if ( pixel_ptr > = avctx - > width ) break ; FETCH_NEXT_STREAM_BYTE ( ) ; pic - > data[0][row_ptr + pixel_ptr] = stream_byte > > 4 ; pixel_ptr + + ; if ( i + 1 == rle_code & & odd_pixel ) break ; if ( pixel_ptr > = avctx - > width ) break ; pic - > data[0][row_ptr + pixel_ptr] = stream_byte & 0x0F ; pixel_ptr + + ; } // if the RLE code is odd , skip a byte in the stream if ( extra_byte ) stream_ptr + + ; } } else { // decode a run of data if ( row_ptr + pixel_ptr + stream_byte > frame_size ) { av_log ( avctx , AV_LOG_ERROR , MS RLE : frame ptr just went out of bounds ( 1 ) \n ) ; return - 1 ; } FETCH_NEXT_STREAM_BYTE ( ) ; for ( i = 0 ; i < rle_code ; i + + ) { if ( pixel_ptr > = avctx - > width ) break ; if ( ( i & 1 ) == 0 ) pic - > data[0][row_ptr + pixel_ptr] = stream_byte > > 4 ; else pic - > data[0][row_ptr + pixel_ptr] = stream_byte & 0x0F ; pixel_ptr + + ; } } } / * one last sanity check on the way out * / if ( stream_ptr < data_size ) { av_log ( avctx , AV_LOG_ERROR , MS RLE : ended frame decode with bytes left over ( %d < %d ) \n , stream_ptr , data_size ) ; return - 1 ; } return 0 ; }",1
"static void vc1_mc_4mv_chroma4 ( VC1Context * v ) { MpegEncContext * s = & v - > s ; DSPContext * dsp = & v - > s . dsp ; uint8_t * srcU , * srcV ; int uvsrc_x , uvsrc_y ; int uvmx_field[4] , uvmy_field[4] ; int i , off , tx , ty ; int fieldmv = v - > blk_mv_type[s - > block_index[0]] ; static const int s_rndtblfield[16] = { 0 , 0 , 1 , 2 , 4 , 4 , 5 , 6 , 2 , 2 , 3 , 8 , 6 , 6 , 7 , 12 } ; int v_dist = fieldmv ? 1 : 4 ; // vertical offset for lower sub - blocks int v_edge_pos = s - > v_edge_pos > > 1 ; if ( ! v - > s . last_picture . f . data[0] ) return ; if ( s - > flags & CODEC_FLAG_GRAY ) return ; for ( i = 0 ; i < 4 ; i + + ) { tx = s - > mv[0][i][0] ; uvmx_field[i] = ( tx + ( ( tx & 3 ) == 3 ) ) > > 1 ; ty = s - > mv[0][i][1] ; if ( fieldmv ) uvmy_field[i] = ( ty > > 4 ) * 8 + s_rndtblfield[ty & 0xF] ; else uvmy_field[i] = ( ty + ( ( ty & 3 ) == 3 ) ) > > 1 ; } for ( i = 0 ; i < 4 ; i + + ) { off = ( i & 1 ) * 4 + ( ( i & 2 ) ? v_dist * s - > uvlinesize : 0 ) ; uvsrc_x = s - > mb_x * 8 + ( i & 1 ) * 4 + ( uvmx_field[i] > > 2 ) ; uvsrc_y = s - > mb_y * 8 + ( ( i & 2 ) ? v_dist : 0 ) + ( uvmy_field[i] > > 2 ) ; // FIXME : implement proper pull - back ( see vc1cropmv . c , vc1CROPMV_ChromaPullBack ( ) ) uvsrc_x = av_clip ( uvsrc_x , - 8 , s - > avctx - > coded_width > > 1 ) ; uvsrc_y = av_clip ( uvsrc_y , - 8 , s - > avctx - > coded_height > > 1 ) ; srcU = s - > last_picture . f . data[1] + uvsrc_y * s - > uvlinesize + uvsrc_x ; srcV = s - > last_picture . f . data[2] + uvsrc_y * s - > uvlinesize + uvsrc_x ; uvmx_field[i] = ( uvmx_field[i] & 3 ) < < 1 ; uvmy_field[i] = ( uvmy_field[i] & 3 ) < < 1 ; if ( fieldmv & & ! ( uvsrc_y & 1 ) ) v_edge_pos - - ; if ( fieldmv & & ( uvsrc_y & 1 ) & & uvsrc_y < 2 ) uvsrc_y - - ; if ( ( v - > mv_mode == MV_PMODE_INTENSITY_COMP ) || s - > h_edge_pos < 10 || v_edge_pos < ( 5 < < fieldmv ) || ( unsigned ) uvsrc_x > ( s - > h_edge_pos > > 1 ) - 5 || ( unsigned ) uvsrc_y > v_edge_pos - ( 5 < < fieldmv ) ) { s - > dsp . emulated_edge_mc ( s - > edge_emu_buffer , srcU , s - > uvlinesize , 5 , ( 5 < < fieldmv ) , uvsrc_x , uvsrc_y , s - > h_edge_pos > > 1 , v_edge_pos ) ; s - > dsp . emulated_edge_mc ( s - > edge_emu_buffer + 16 , srcV , s - > uvlinesize , 5 , ( 5 < < fieldmv ) , uvsrc_x , uvsrc_y , s - > h_edge_pos > > 1 , v_edge_pos ) ; srcU = s - > edge_emu_buffer ; srcV = s - > edge_emu_buffer + 16 ; / * if we deal with intensity compensation we need to scale source blocks * / if ( v - > mv_mode == MV_PMODE_INTENSITY_COMP ) { int i , j ; uint8_t * src , * src2 ; src = srcU ; src2 = srcV ; for ( j = 0 ; j < 5 ; j + + ) { for ( i = 0 ; i < 5 ; i + + ) { src[i] = v - > lutuv[src[i]] ; src2[i] = v - > lutuv[src2[i]] ; } src + = s - > uvlinesize < < 1 ; src2 + = s - > uvlinesize < < 1 ; } } } if ( ! v - > rnd ) { dsp - > put_h264_chroma_pixels_tab[1] ( s - > dest[1] + off , srcU , s - > uvlinesize < < fieldmv , 4 , uvmx_field[i] , uvmy_field[i] ) ; dsp - > put_h264_chroma_pixels_tab[1] ( s - > dest[2] + off , srcV , s - > uvlinesize < < fieldmv , 4 , uvmx_field[i] , uvmy_field[i] ) ; } else { v - > vc1dsp . put_no_rnd_vc1_chroma_pixels_tab[1] ( s - > dest[1] + off , srcU , s - > uvlinesize < < fieldmv , 4 , uvmx_field[i] , uvmy_field[i] ) ; v - > vc1dsp . put_no_rnd_vc1_chroma_pixels_tab[1] ( s - > dest[2] + off , srcV , s - > uvlinesize < < fieldmv , 4 , uvmx_field[i] , uvmy_field[i] ) ; } } }",1
"yuv2rgba64_1_c_template ( SwsContext * c , const int32_t * buf0 , const int32_t * ubuf[2] , const int32_t * vbuf[2] , const int32_t * abuf0 , uint16_t * dest , int dstW , int uvalpha , int y , enum AVPixelFormat target , int hasAlpha , int eightbytes ) { const int32_t * ubuf0 = ubuf[0] , * vbuf0 = vbuf[0] ; int i ; int A1 = 0xffff < < 14 , A2= 0xffff < < 14 ; if ( uvalpha < 2048 ) { for ( i = 0 ; i < ( ( dstW + 1 ) > > 1 ) ; i + + ) { int Y1 = ( buf0[i * 2] ) > > 2 ; int Y2 = ( buf0[i * 2 + 1] ) > > 2 ; int U = ( ubuf0[i] + ( - 128 < < 11 ) ) > > 2 ; int V = ( vbuf0[i] + ( - 128 < < 11 ) ) > > 2 ; int R , G , B ; Y1 - = c - > yuv2rgb_y_offset ; Y2 - = c - > yuv2rgb_y_offset ; Y1 * = c - > yuv2rgb_y_coeff ; Y2 * = c - > yuv2rgb_y_coeff ; Y1 + = 1 < < 13 ; Y2 + = 1 < < 13 ; if ( hasAlpha ) { A1 = abuf0[i * 2 ] < < 11 ; A2 = abuf0[i * 2 + 1] < < 11 ; A1 + = 1 < < 13 ; A2 + = 1 < < 13 ; } R = V * c - > yuv2rgb_v2r_coeff ; G = V * c - > yuv2rgb_v2g_coeff + U * c - > yuv2rgb_u2g_coeff ; B = U * c - > yuv2rgb_u2b_coeff ; output_pixel ( & dest[0] , av_clip_uintp2 ( R_B + Y1 , 30 ) > > 14 ) ; output_pixel ( & dest[1] , av_clip_uintp2 ( G + Y1 , 30 ) > > 14 ) ; output_pixel ( & dest[2] , av_clip_uintp2 ( B_R + Y1 , 30 ) > > 14 ) ; if ( eightbytes ) { output_pixel ( & dest[3] , av_clip_uintp2 ( A1 , 30 ) > > 14 ) ; output_pixel ( & dest[4] , av_clip_uintp2 ( R_B + Y2 , 30 ) > > 14 ) ; output_pixel ( & dest[5] , av_clip_uintp2 ( G + Y2 , 30 ) > > 14 ) ; output_pixel ( & dest[6] , av_clip_uintp2 ( B_R + Y2 , 30 ) > > 14 ) ; output_pixel ( & dest[7] , av_clip_uintp2 ( A2 , 30 ) > > 14 ) ; dest + = 8 ; } else { output_pixel ( & dest[3] , av_clip_uintp2 ( R_B + Y2 , 30 ) > > 14 ) ; output_pixel ( & dest[4] , av_clip_uintp2 ( G + Y2 , 30 ) > > 14 ) ; output_pixel ( & dest[5] , av_clip_uintp2 ( B_R + Y2 , 30 ) > > 14 ) ; dest + = 6 ; } } } else { const int32_t * ubuf1 = ubuf[1] , * vbuf1 = vbuf[1] ; int A1 = 0xffff < < 14 , A2 = 0xffff < < 14 ; for ( i = 0 ; i < ( ( dstW + 1 ) > > 1 ) ; i + + ) { int Y1 = ( buf0[i * 2] ) > > 2 ; int Y2 = ( buf0[i * 2 + 1] ) > > 2 ; int U = ( ubuf0[i] + ubuf1[i] + ( - 128 < < 12 ) ) > > 3 ; int V = ( vbuf0[i] + vbuf1[i] + ( - 128 < < 12 ) ) > > 3 ; int R , G , B ; Y1 - = c - > yuv2rgb_y_offset ; Y2 - = c - > yuv2rgb_y_offset ; Y1 * = c - > yuv2rgb_y_coeff ; Y2 * = c - > yuv2rgb_y_coeff ; Y1 + = 1 < < 13 ; Y2 + = 1 < < 13 ; if ( hasAlpha ) { A1 = abuf0[i * 2 ] < < 11 ; A2 = abuf0[i * 2 + 1] < < 11 ; A1 + = 1 < < 13 ; A2 + = 1 < < 13 ; } R = V * c - > yuv2rgb_v2r_coeff ; G = V * c - > yuv2rgb_v2g_coeff + U * c - > yuv2rgb_u2g_coeff ; B = U * c - > yuv2rgb_u2b_coeff ; output_pixel ( & dest[0] , av_clip_uintp2 ( R_B + Y1 , 30 ) > > 14 ) ; output_pixel ( & dest[1] , av_clip_uintp2 ( G + Y1 , 30 ) > > 14 ) ; output_pixel ( & dest[2] , av_clip_uintp2 ( B_R + Y1 , 30 ) > > 14 ) ; if ( eightbytes ) { output_pixel ( & dest[3] , av_clip_uintp2 ( A1 , 30 ) > > 14 ) ; output_pixel ( & dest[4] , av_clip_uintp2 ( R_B + Y2 , 30 ) > > 14 ) ; output_pixel ( & dest[5] , av_clip_uintp2 ( G + Y2 , 30 ) > > 14 ) ; output_pixel ( & dest[6] , av_clip_uintp2 ( B_R + Y2 , 30 ) > > 14 ) ; output_pixel ( & dest[7] , av_clip_uintp2 ( A2 , 30 ) > > 14 ) ; dest + = 8 ; } else { output_pixel ( & dest[3] , av_clip_uintp2 ( R_B + Y2 , 30 ) > > 14 ) ; output_pixel ( & dest[4] , av_clip_uintp2 ( G + Y2 , 30 ) > > 14 ) ; output_pixel ( & dest[5] , av_clip_uintp2 ( B_R + Y2 , 30 ) > > 14 ) ; dest + = 6 ; } } } }",0
"static int mjpegb_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , UINT8 * buf , int buf_size ) { MJpegDecodeContext * s = avctx - > priv_data ; UINT8 * buf_end , * buf_ptr ; int i ; AVPicture * picture = data ; GetBitContext hgb ; / * for the header * / uint32_t dqt_offs , dht_offs , sof_offs , sos_offs , second_field_offs ; uint32_t field_size ; * data_size = 0 ; / * no supplementary picture * / if ( buf_size == 0 ) return 0 ; buf_ptr = buf ; buf_end = buf + buf_size ; read_header : / * reset on every SOI * / s - > restart_interval = 0 ; init_get_bits ( & hgb , buf_ptr , / * buf_size * / buf_end - buf_ptr ) ; skip_bits ( & hgb , 32 ) ; / * reserved zeros * / if ( get_bits ( & hgb , 32 ) ! = be2me_32 ( ff_get_fourcc ( mjpg ) ) ) { dprintf ( not mjpeg - b ( bad fourcc ) \n ) ; return 0 ; } field_size = get_bits ( & hgb , 32 ) ; / * field size * / dprintf ( field size : 0x%x\n , field_size ) ; skip_bits ( & hgb , 32 ) ; / * padded field size * / second_field_offs = get_bits ( & hgb , 32 ) ; dprintf ( second field offs : 0x%x\n , second_field_offs ) ; if ( second_field_offs ) s - > interlaced = 1 ; dqt_offs = get_bits ( & hgb , 32 ) ; dprintf ( dqt offs : 0x%x\n , dqt_offs ) ; if ( dqt_offs ) { init_get_bits ( & s - > gb , buf + dqt_offs , buf_end - ( buf + dqt_offs ) ) ; s - > start_code = DQT ; mjpeg_decode_dqt ( s ) ; } dht_offs = get_bits ( & hgb , 32 ) ; dprintf ( dht offs : 0x%x\n , dht_offs ) ; if ( dht_offs ) { init_get_bits ( & s - > gb , buf + dht_offs , buf_end - ( buf + dht_offs ) ) ; s - > start_code = DHT ; mjpeg_decode_dht ( s ) ; } sof_offs = get_bits ( & hgb , 32 ) ; dprintf ( sof offs : 0x%x\n , sof_offs ) ; if ( sof_offs ) { init_get_bits ( & s - > gb , buf + sof_offs , buf_end - ( buf + sof_offs ) ) ; s - > start_code = SOF0 ; if ( mjpeg_decode_sof0 ( s ) < 0 ) return - 1 ; } sos_offs = get_bits ( & hgb , 32 ) ; dprintf ( sos offs : 0x%x\n , sos_offs ) ; if ( sos_offs ) { // init_get_bits ( & s - > gb , buf + sos_offs , buf_end - ( buf + sos_offs ) ) ; init_get_bits ( & s - > gb , buf + sos_offs , field_size ) ; s - > start_code = SOS ; mjpeg_decode_sos ( s ) ; } skip_bits ( & hgb , 32 ) ; / * start of data offset * / if ( s - > interlaced ) { s - > bottom_field = 1 ; / * if not bottom field , do not output image yet * / if ( s - > bottom_field & & second_field_offs ) { buf_ptr = buf + second_field_offs ; second_field_offs = 0 ; goto read_header ; } } for ( i=0 ; i < 3 ; i + + ) { picture - > data[i] = s - > current_picture[i] ; picture - > linesize[i] = ( s - > interlaced ) ? s - > linesize[i] > > 1 : s - > linesize[i] ; } * data_size = sizeof ( AVPicture ) ; avctx - > height = s - > height ; if ( s - > interlaced ) avctx - > height * = 2 ; avctx - > width = s - > width ; / * XXX : not complete test ! * / switch ( ( s - > h_count[0] < < 4 ) | s - > v_count[0] ) { case 0x11 : avctx - > pix_fmt = PIX_FMT_YUV444P ; break ; case 0x21 : avctx - > pix_fmt = PIX_FMT_YUV422P ; break ; default : case 0x22 : avctx - > pix_fmt = PIX_FMT_YUV420P ; break ; } / * dummy quality * / / * XXX : infer it with matrix * / // avctx - > quality = 3 ; return buf_ptr - buf ; }",0
"static int idcin_read_seek ( AVFormatContext * s , int stream_index , int64_t timestamp , int flags ) { IdcinDemuxContext * idcin = s - > priv_data ; if ( idcin - > first_pkt_pos > 0 ) { int ret = avio_seek ( s - > pb , idcin - > first_pkt_pos , SEEK_SET ) ; if ( ret < 0 ) return ret ; ff_update_cur_dts ( s , s - > streams[idcin - > video_stream_index] , 0 ) ; idcin - > next_chunk_is_video = 1 ; idcin - > current_audio_chunk = 0 ; return 0 ; } return - 1 ; }",1
"static int output_frame ( H264Context * h , AVFrame * dst , H264Picture * srcp ) { AVFrame * src = srcp - > f ; const AVPixFmtDescriptor * desc = av_pix_fmt_desc_get ( src - > format ) ; int i ; int ret = av_frame_ref ( dst , src ) ; if ( ret < 0 ) return ret ; av_dict_set ( & dst - > metadata , stereo_mode , ff_h264_sei_stereo_mode ( h ) , 0 ) ; if ( srcp - > sei_recovery_frame_cnt == 0 ) dst - > key_frame = 1 ; if ( ! srcp - > crop ) return 0 ; for ( i = 0 ; i < desc - > nb_components ; i + + ) { int hshift = ( i > 0 ) ? desc - > log2_chroma_w : 0 ; int vshift = ( i > 0 ) ? desc - > log2_chroma_h : 0 ; int off = ( ( srcp - > crop_left > > hshift ) < < h - > pixel_shift ) + ( srcp - > crop_top > > vshift ) * dst - > linesize[i] ; dst - > data[i] + = off ; } return 0 ; }",1
"int ff_mjpeg_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { AVFrame * frame = data ; const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; MJpegDecodeContext * s = avctx - > priv_data ; const uint8_t * buf_end , * buf_ptr ; const uint8_t * unescaped_buf_ptr ; int hshift , vshift ; int unescaped_buf_size ; int start_code ; int i , index ; int ret = 0 ; int is16bit ; av_dict_free ( & s - > exif_metadata ) ; av_freep ( & s - > stereo3d ) ; s - > adobe_transform = - 1 ; buf_ptr = buf ; buf_end = buf + buf_size ; while ( buf_ptr < buf_end ) { / * find start next marker * / start_code = ff_mjpeg_find_marker ( s , & buf_ptr , buf_end , & unescaped_buf_ptr , & unescaped_buf_size ) ; / * EOF * / if ( start_code < 0 ) { break ; } else if ( unescaped_buf_size > INT_MAX / 8 ) { av_log ( avctx , AV_LOG_ERROR , MJPEG packet 0x%x too big ( %d/%d ) , corrupt data ? \n , start_code , unescaped_buf_size , buf_size ) ; return AVERROR_INVALIDDATA ; } av_log ( avctx , AV_LOG_DEBUG , marker=%x avail_size_in_buf=% PTRDIFF_SPECIFIER \n , start_code , buf_end - buf_ptr ) ; ret = init_get_bits8 ( & s - > gb , unescaped_buf_ptr , unescaped_buf_size ) ; if ( ret < 0 ) { av_log ( avctx , AV_LOG_ERROR , invalid buffer\n ) ; goto fail ; } s - > start_code = start_code ; if ( s - > avctx - > debug & FF_DEBUG_STARTCODE ) av_log ( avctx , AV_LOG_DEBUG , startcode : %X\n , start_code ) ; / * process markers * / if ( start_code > = 0xd0 & & start_code < = 0xd7 ) av_log ( avctx , AV_LOG_DEBUG , restart marker : %d\n , start_code & 0x0f ) ; / * APP fields * / else if ( start_code > = APP0 & & start_code < = APP15 ) mjpeg_decode_app ( s ) ; / * Comment * / else if ( start_code == COM ) mjpeg_decode_com ( s ) ; ret = - 1 ; if ( ! CONFIG_JPEGLS_DECODER & & ( start_code == SOF48 || start_code == LSE ) ) { av_log ( avctx , AV_LOG_ERROR , JPEG - LS support not enabled . \n ) ; return AVERROR ( ENOSYS ) ; } if ( avctx - > skip_frame == AVDISCARD_ALL ) { switch ( start_code ) { case SOF0 : case SOF1 : case SOF2 : case SOF3 : case SOF48 : case SOI : case SOS : case EOI : break ; default : goto skip ; } } switch ( start_code ) { case SOI : s - > restart_interval = 0 ; s - > restart_count = 0 ; / * nothing to do on SOI * / break ; case DQT : ff_mjpeg_decode_dqt ( s ) ; break ; case DHT : if ( ( ret = ff_mjpeg_decode_dht ( s ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , huffman table decode error\n ) ; goto fail ; } break ; case SOF0 : case SOF1 : s - > lossless = 0 ; s - > ls = 0 ; s - > progressive = 0 ; if ( ( ret = ff_mjpeg_decode_sof ( s ) ) < 0 ) goto fail ; break ; case SOF2 : s - > lossless = 0 ; s - > ls = 0 ; s - > progressive = 1 ; if ( ( ret = ff_mjpeg_decode_sof ( s ) ) < 0 ) goto fail ; break ; case SOF3 : s - > avctx - > properties |= FF_CODEC_PROPERTY_LOSSLESS ; s - > lossless = 1 ; s - > ls = 0 ; s - > progressive = 0 ; if ( ( ret = ff_mjpeg_decode_sof ( s ) ) < 0 ) goto fail ; break ; case SOF48 : s - > avctx - > properties |= FF_CODEC_PROPERTY_LOSSLESS ; s - > lossless = 1 ; s - > ls = 1 ; s - > progressive = 0 ; if ( ( ret = ff_mjpeg_decode_sof ( s ) ) < 0 ) goto fail ; break ; case LSE : if ( ! CONFIG_JPEGLS_DECODER || ( ret = ff_jpegls_decode_lse ( s ) ) < 0 ) goto fail ; break ; case EOI : eoi_parser : s - > cur_scan = 0 ; if ( ! s - > got_picture ) { av_log ( avctx , AV_LOG_WARNING , Found EOI before any SOF , ignoring\n ) ; break ; } if ( s - > interlaced ) { s - > bottom_field = 1 ; / * if not bottom field , do not output image yet * / if ( s - > bottom_field == ! s - > interlace_polarity ) break ; } if ( avctx - > skip_frame == AVDISCARD_ALL ) { s - > got_picture = 0 ; goto the_end_no_picture ; } if ( ( ret = av_frame_ref ( frame , s - > picture_ptr ) ) < 0 ) return ret ; * got_frame = 1 ; s - > got_picture = 0 ; if ( ! s - > lossless ) { int qp = FFMAX3 ( s - > qscale[0] , s - > qscale[1] , s - > qscale[2] ) ; int qpw = ( s - > width + 15 ) / 16 ; AVBufferRef * qp_table_buf = av_buffer_alloc ( qpw ) ; if ( qp_table_buf ) { memset ( qp_table_buf - > data , qp , qpw ) ; av_frame_set_qp_table ( data , qp_table_buf , 0 , FF_QSCALE_TYPE_MPEG1 ) ; } if ( avctx - > debug & FF_DEBUG_QP ) av_log ( avctx , AV_LOG_DEBUG , QP : %d\n , qp ) ; } goto the_end ; case SOS : s - > cur_scan + + ; if ( avctx - > skip_frame == AVDISCARD_ALL ) break ; if ( ( ret = ff_mjpeg_decode_sos ( s , NULL , 0 , NULL ) ) < 0 & & ( avctx - > err_recognition & AV_EF_EXPLODE ) ) goto fail ; break ; case DRI : mjpeg_decode_dri ( s ) ; break ; case SOF5 : case SOF6 : case SOF7 : case SOF9 : case SOF10 : case SOF11 : case SOF13 : case SOF14 : case SOF15 : case JPG : av_log ( avctx , AV_LOG_ERROR , mjpeg : unsupported coding type ( %x ) \n , start_code ) ; break ; } skip : / * eof process start code * / buf_ptr + = ( get_bits_count ( & s - > gb ) + 7 ) / 8 ; av_log ( avctx , AV_LOG_DEBUG , marker parser used %d bytes ( %d bits ) \n , ( get_bits_count ( & s - > gb ) + 7 ) / 8 , get_bits_count ( & s - > gb ) ) ; } if (",1
"static int vp3_update_thread_context ( AVCodecContext * dst , const AVCodecContext * src ) { Vp3DecodeContext * s = dst - > priv_data , * s1 = src - > priv_data ; int qps_changed = 0 , i , err ; define copy_fields ( to , from , start_field , end_field ) memcpy ( & to - > start_field , & from - > start_field , ( char * ) & to - > end_field - ( char * ) & to - > start_field ) if ( ! s1 - > current_frame . data[0] ||s - > width ! = s1 - > width ||s - > height ! = s1 - > height ) { if ( s ! = s1 ) copy_fields ( s , s1 , golden_frame , current_frame ) ; return - 1 ; } if ( s ! = s1 ) { // init tables if the first frame hasn ' t been decoded if ( ! s - > current_frame . data[0] ) { int y_fragment_count , c_fragment_count ; s - > avctx = dst ; err = allocate_tables ( dst ) ; if ( err ) return err ; y_fragment_count = s - > fragment_width[0] * s - > fragment_height[0] ; c_fragment_count = s - > fragment_width[1] * s - > fragment_height[1] ; memcpy ( s - > motion_val[0] , s1 - > motion_val[0] , y_fragment_count * sizeof ( * s - > motion_val[0] ) ) ; memcpy ( s - > motion_val[1] , s1 - > motion_val[1] , c_fragment_count * sizeof ( * s - > motion_val[1] ) ) ; } // copy previous frame data copy_fields ( s , s1 , golden_frame , dsp ) ; // copy qscale data if necessary for ( i = 0 ; i < 3 ; i + + ) { if ( s - > qps[i] ! = s1 - > qps[1] ) { qps_changed = 1 ; memcpy ( & s - > qmat[i] , & s1 - > qmat[i] , sizeof ( s - > qmat[i] ) ) ; } } if ( s - > qps[0] ! = s1 - > qps[0] ) memcpy ( & s - > bounding_values_array , & s1 - > bounding_values_array , sizeof ( s - > bounding_values_array ) ) ; if ( qps_changed ) copy_fields ( s , s1 , qps , superblock_count ) ; undef copy_fields } update_frames ( dst ) ; return 0 ; }",1
"static void avc_luma_mid_8w_msa ( const uint8_t * src , int32_t src_stride , uint8_t * dst , int32_t dst_stride , int32_t height ) { uint32_t loop_cnt ; v16i8 src0 , src1 , src2 , src3 , src4 ; v16i8 mask0 , mask1 , mask2 ; v8i16 hz_out0 , hz_out1 , hz_out2 , hz_out3 ; v8i16 hz_out4 , hz_out5 , hz_out6 , hz_out7 , hz_out8 ; v8i16 dst0 , dst1 , dst2 , dst3 ; v16u8 out0 , out1 ; LD_SB3 ( & luma_mask_arr[0] , 16 , mask0 , mask1 , mask2 ) ; LD_SB5 ( src , src_stride , src0 , src1 , src2 , src3 , src4 ) ; XORI_B5_128_SB ( src0 , src1 , src2 , src3 , src4 ) ; src + = ( 5 * src_stride ) ; hz_out0 = AVC_HORZ_FILTER_SH ( src0 , src0 , mask0 , mask1 , mask2 ) ; hz_out1 = AVC_HORZ_FILTER_SH ( src1 , src1 , mask0 , mask1 , mask2 ) ; hz_out2 = AVC_HORZ_FILTER_SH ( src2 , src2 , mask0 , mask1 , mask2 ) ; hz_out3 = AVC_HORZ_FILTER_SH ( src3 , src3 , mask0 , mask1 , mask2 ) ; hz_out4 = AVC_HORZ_FILTER_SH ( src4 , src4 , mask0 , mask1 , mask2 ) ; for ( loop_cnt = ( height > > 2 ) ; loop_cnt - - ; ) { LD_SB4 ( src , src_stride , src0 , src1 , src2 , src3 ) ; XORI_B4_128_SB ( src0 , src1 , src2 , src3 ) ; src + = ( 4 * src_stride ) ; hz_out5 = AVC_HORZ_FILTER_SH ( src0 , src0 , mask0 , mask1 , mask2 ) ; hz_out6 = AVC_HORZ_FILTER_SH ( src1 , src1 , mask0 , mask1 , mask2 ) ; hz_out7 = AVC_HORZ_FILTER_SH ( src2 , src2 , mask0 , mask1 , mask2 ) ; hz_out8 = AVC_HORZ_FILTER_SH ( src3 , src3 , mask0 , mask1 , mask2 ) ; dst0 = AVC_CALC_DPADD_H_6PIX_2COEFF_SH ( hz_out0 , hz_out1 , hz_out2 , hz_out3 , hz_out4 , hz_out5 ) ; dst1 = AVC_CALC_DPADD_H_6PIX_2COEFF_SH ( hz_out1 , hz_out2 , hz_out3 , hz_out4 , hz_out5 , hz_out6 ) ; dst2 = AVC_CALC_DPADD_H_6PIX_2COEFF_SH ( hz_out2 , hz_out3 , hz_out4 , hz_out5 , hz_out6 , hz_out7 ) ; dst3 = AVC_CALC_DPADD_H_6PIX_2COEFF_SH ( hz_out3 , hz_out4 , hz_out5 , hz_out6 , hz_out7 , hz_out8 ) ; out0 = PCKEV_XORI128_UB ( dst0 , dst1 ) ; out1 = PCKEV_XORI128_UB ( dst2 , dst3 ) ; ST8x4_UB ( out0 , out1 , dst , dst_stride ) ; dst + = ( 4 * dst_stride ) ; hz_out3 = hz_out7 ; hz_out1 = hz_out5 ; hz_out5 = hz_out4 ; hz_out4 = hz_out8 ; hz_out2 = hz_out6 ; hz_out0 = hz_out5 ; } }",0
"void ff_init_elbg ( int * points , int dim , int numpoints , int * codebook , int numCB , int max_steps , int * closest_cb , AVLFG * rand_state ) { int i , k ; if ( numpoints > 24 * numCB ) { / * ELBG is very costly for a big number of points . So if we have a lot of them , get a good initial codebook to save on iterations * / int * temp_points = av_malloc ( dim * ( numpoints/8 ) * sizeof ( int ) ) ; for ( i=0 ; i < numpoints/8 ; i + + ) { k = ( i * BIG_PRIME ) % numpoints ; memcpy ( temp_points + i * dim , points + k * dim , dim * sizeof ( int ) ) ; } ff_init_elbg ( temp_points , dim , numpoints/8 , codebook , numCB , 2 * max_steps , closest_cb , rand_state ) ; ff_do_elbg ( temp_points , dim , numpoints/8 , codebook , numCB , 2 * max_steps , closest_cb , rand_state ) ; av_free ( temp_points ) ; } else // If not , initialize the codebook with random positions for ( i=0 ; i < numCB ; i + + ) memcpy ( codebook + i * dim , points + ( ( i * BIG_PRIME ) %numpoints ) * dim , dim * sizeof ( int ) ) ; }",0
av_cold void ff_lpc_init_x86 ( LPCContext * c ) { if HAVE_SSE2_INLINE int cpu_flags = av_get_cpu_flags ( ) ; if ( INLINE_SSE2 ( cpu_flags ) & & ( cpu_flags & AV_CPU_FLAG_SSE2SLOW ) ) { c - > lpc_apply_welch_window = lpc_apply_welch_window_sse2 ; c - > lpc_compute_autocorr = lpc_compute_autocorr_sse2 ; } endif / * HAVE_SSE2_INLINE * / },0
static av_cold int pam_encode_close ( AVCodecContext * avctx ) { av_frame_free ( & avctx - > coded_frame ) ; return 0 ; },0
"int ff_pcm_read_packet ( AVFormatContext * s , AVPacket * pkt ) { int ret , size ; size= RAW_SAMPLES * s - > streams[0] - > codec - > block_align ; if ( size < = 0 ) return AVERROR ( EINVAL ) ; ret= av_get_packet ( s - > pb , pkt , size ) ; pkt - > flags & = AV_PKT_FLAG_CORRUPT ; pkt - > stream_index = 0 ; if ( ret < 0 ) return ret ; return ret ; }",0
"static int decode_cabac_mb_skip ( H264Context * h , int mb_x , int mb_y ) { MpegEncContext * const s = & h - > s ; int mba_xy , mbb_xy ; int ctx = 0 ; if ( FRAME_MBAFF ) { //FIXME merge with the stuff in fill_caches ? int mb_xy = mb_x + ( mb_y & 1 ) * s - > mb_stride ; mba_xy = mb_xy - 1 ; if ( ( mb_y & 1 ) & & h - > slice_table[mba_xy] == h - > slice_num & & MB_FIELD == ! ! IS_INTERLACED ( s - > current_picture . mb_type[mba_xy] ) ) mba_xy + = s - > mb_stride ; if ( MB_FIELD ) { mbb_xy = mb_xy - s - > mb_stride ; if ( ! ( mb_y & 1 ) & & h - > slice_table[mbb_xy] == h - > slice_num & & IS_INTERLACED ( s - > current_picture . mb_type[mbb_xy] ) ) mbb_xy - = s - > mb_stride ; } else mbb_xy = mb_x + ( mb_y - 1 ) * s - > mb_stride ; } else { int mb_xy = mb_x + mb_y * s - > mb_stride ; mba_xy = mb_xy - 1 ; mbb_xy = mb_xy - s - > mb_stride ; } if ( h - > slice_table[mba_xy] == h - > slice_num & & ! IS_SKIP ( s - > current_picture . mb_type[mba_xy] ) ) ctx + + ; if ( h - > slice_table[mbb_xy] == h - > slice_num & & ! IS_SKIP ( s - > current_picture . mb_type[mbb_xy] ) ) ctx + + ; if ( h - > slice_type == B_TYPE ) ctx + = 13 ; return get_cabac ( & h - > cabac , & h - > cabac_state[11 + ctx] ) ; }",0
"static int handle_packets ( AVFormatContext * s , int nb_packets ) { MpegTSContext * ts = s - > priv_data ; ByteIOContext * pb = & s - > pb ; uint8_t packet[TS_FEC_PACKET_SIZE] ; int packet_num , len ; ts - > stop_parse = 0 ; packet_num = 0 ; for ( ; ; ) { if ( ts - > stop_parse ) break ; packet_num + + ; if ( nb_packets ! = 0 & & packet_num > = nb_packets ) break ; len = get_buffer ( pb , packet , ts - > raw_packet_size ) ; if ( len ! = ts - > raw_packet_size ) return AVERROR_IO ; / * check paquet sync byte * / / * XXX : accept to resync ? * / if ( packet[0] ! = 0x47 ) return AVERROR_INVALIDDATA ; handle_packet ( s , packet ) ; } return 0 ; }",0
"static av_cold int oggvorbis_init_encoder ( vorbis_info * vi , AVCodecContext * avccontext ) { OggVorbisContext * context = avccontext - > priv_data ; double cfreq ; if ( avccontext - > flags & CODEC_FLAG_QSCALE ) { / * variable bitrate * / if ( vorbis_encode_setup_vbr ( vi , avccontext - > channels , avccontext - > sample_rate , avccontext - > global_quality / ( float ) FF_QP2LAMBDA / 10 . 0 ) ) return - 1 ; } else { int minrate = avccontext - > rc_min_rate > 0 ? avccontext - > rc_min_rate : - 1 ; int maxrate = avccontext - > rc_min_rate > 0 ? avccontext - > rc_max_rate : - 1 ; / * constant bitrate * / if ( vorbis_encode_setup_managed ( vi , avccontext - > channels , avccontext - > sample_rate , minrate , avccontext - > bit_rate , maxrate ) ) return - 1 ; / * variable bitrate by estimate , disable slow rate management * / if ( minrate == - 1 & & maxrate == - 1 ) if ( vorbis_encode_ctl ( vi , OV_ECTL_RATEMANAGE2_SET , NULL ) ) return - 1 ; } / * cutoff frequency * / if ( avccontext - > cutoff > 0 ) { cfreq = avccontext - > cutoff / 1000 . 0 ; if ( vorbis_encode_ctl ( vi , OV_ECTL_LOWPASS_SET , & cfreq ) ) return - 1 ; } if ( context - > iblock ) { vorbis_encode_ctl ( vi , OV_ECTL_IBLOCK_SET , & context - > iblock ) ; } return vorbis_encode_setup_init ( vi ) ; }",0
"static int decode_packet ( J2kDecoderContext * s , J2kCodingStyle * codsty , J2kResLevel * rlevel , int precno , int layno , uint8_t * expn , int numgbits ) { int bandno , cblkny , cblknx , cblkno , ret ; if ( ! ( ret = get_bits ( s , 1 ) ) ) { j2k_flush ( s ) ; return 0 ; } else if ( ret < 0 ) return ret ; for ( bandno = 0 ; bandno < rlevel - > nbands ; bandno + + ) { J2kBand * band = rlevel - > band + bandno ; J2kPrec * prec = band - > prec + precno ; int pos = 0 ; if ( band - > coord[0][0] == band - > coord[0][1] || band - > coord[1][0] == band - > coord[1][1] ) continue ; for ( cblkny = prec - > yi0 ; cblkny < prec - > yi1 ; cblkny + + ) for ( cblknx = prec - > xi0 , cblkno = cblkny * band - > cblknx + cblknx ; cblknx < prec - > xi1 ; cblknx + + , cblkno + + , pos + + ) { J2kCblk * cblk = band - > cblk + cblkno ; int incl , newpasses , llen ; if ( cblk - > npasses ) incl = get_bits ( s , 1 ) ; else incl = tag_tree_decode ( s , prec - > cblkincl + pos , layno + 1 ) == layno ; if ( ! incl ) continue ; else if ( incl < 0 ) return incl ; if ( ! cblk - > npasses ) cblk - > nonzerobits = expn[bandno] + numgbits - 1 - tag_tree_decode ( s , prec - > zerobits + pos , 100 ) ; if ( ( newpasses = getnpasses ( s ) ) < 0 ) return newpasses ; if ( ( llen = getlblockinc ( s ) ) < 0 ) return llen ; cblk - > lblock + = llen ; if ( ( ret = get_bits ( s , av_log2 ( newpasses ) + cblk - > lblock ) ) < 0 ) return ret ; cblk - > lengthinc = ret ; cblk - > npasses + = newpasses ; } } j2k_flush ( s ) ; if ( codsty - > csty & J2K_CSTY_EPH ) { if ( AV_RB16 ( s - > buf ) == J2K_EPH ) { s - > buf + = 2 ; } else { av_log ( s - > avctx , AV_LOG_ERROR , EPH marker not found . \n ) ; } } for ( bandno = 0 ; bandno < rlevel - > nbands ; bandno + + ) { J2kBand * band = rlevel - > band + bandno ; int yi , cblknw = band - > prec[precno] . xi1 - band - > prec[precno] . xi0 ; for ( yi = band - > prec[precno] . yi0 ; yi < band - > prec[precno] . yi1 ; yi + + ) { int xi ; for ( xi = band - > prec[precno] . xi0 ; xi < band - > prec[precno] . xi1 ; xi + + ) { J2kCblk * cblk = band - > cblk + yi * cblknw + xi ; if ( s - > buf_end - s - > buf < cblk - > lengthinc ) return AVERROR ( EINVAL ) ; bytestream_get_buffer ( & s - > buf , cblk - > data , cblk - > lengthinc ) ; cblk - > length + = cblk - > lengthinc ; cblk - > lengthinc = 0 ; } } } return 0 ; }",1
"static inline void RENAME ( palToY ) ( uint8_t * dst , uint8_t * src , int width , uint32_t * pal ) { int i ; for ( i=0 ; i < width ; i + + ) { int d= src[i] ; dst[i]= pal[d] & 0xFF ; } }",1
"static SoftFloat sbr_sum_square_c ( int ( * x ) [2] , int n ) { SoftFloat ret ; uint64_t accu = 0 , round ; int i , nz ; unsigned u ; for ( i = 0 ; i < n ; i + = 2 ) { // Larger values are inavlid and could cause overflows of accu . av_assert2 ( FFABS ( x[i + 0][0] ) > > 29 == 0 ) ; accu + = ( int64_t ) x[i + 0][0] * x[i + 0][0] ; av_assert2 ( FFABS ( x[i + 0][1] ) > > 29 == 0 ) ; accu + = ( int64_t ) x[i + 0][1] * x[i + 0][1] ; av_assert2 ( FFABS ( x[i + 1][0] ) > > 29 == 0 ) ; accu + = ( int64_t ) x[i + 1][0] * x[i + 1][0] ; av_assert2 ( FFABS ( x[i + 1][1] ) > > 29 == 0 ) ; accu + = ( int64_t ) x[i + 1][1] * x[i + 1][1] ; } u = accu > > 32 ; if ( u == 0 ) { nz = 1 ; } else { nz = - 1 ; while ( u < 0x80000000U ) { u < < = 1 ; nz + + ; } nz = 32 - nz ; } round = 1ULL < < ( nz - 1 ) ; u = ( ( accu + round ) > > nz ) ; u > > = 1 ; ret = av_int2sf ( u , 15 - nz ) ; return ret ; }",1
"static int sofalizer_convolute ( AVFilterContext * ctx , void * arg , int jobnr , int nb_jobs ) { SOFAlizerContext * s = ctx - > priv ; ThreadData * td = arg ; AVFrame * in = td - > in , * out = td - > out ; int offset = jobnr ; int * write = & td - > write[jobnr] ; const int * const delay = td - > delay[jobnr] ; const float * const ir = td - > ir[jobnr] ; int * n_clippings = & td - > n_clippings[jobnr] ; float * ringbuffer = td - > ringbuffer[jobnr] ; float * temp_src = td - > temp_src[jobnr] ; const int n_samples = s - > sofa . n_samples ; / * length of one IR * / const float * src = ( const float * ) in - > data[0] ; / * get pointer to audio input buffer * / float * dst = ( float * ) out - > data[0] ; / * get pointer to audio output buffer * / const int in_channels = s - > n_conv ; / * number of input channels * / / * ring buffer length is : longest IR plus max . delay - > next power of 2 * / const int buffer_length = s - > buffer_length ; / * - 1 for AND instead of MODULO ( applied to powers of 2 ) : * / const uint32_t modulo = ( uint32_t ) buffer_length - 1 ; float * buffer[16] ; / * holds ringbuffer for each input channel * / int wr = * write ; int read ; int i , l ; dst + = offset ; for ( l = 0 ; l < in_channels ; l + + ) { / * get starting address of ringbuffer for each input channel * / buffer[l] = ringbuffer + l * buffer_length ; } for ( i = 0 ; i < in - > nb_samples ; i + + ) { const float * temp_ir = ir ; / * using same set of IRs for each sample * / * dst = 0 ; for ( l = 0 ; l < in_channels ; l + + ) { / * write current input sample to ringbuffer ( for each channel ) * / * ( buffer[l] + wr ) = src[l] ; } / * loop goes through all channels to be convolved * / for ( l = 0 ; l < in_channels ; l + + ) { const float * const bptr = buffer[l] ; if ( l == s - > lfe_channel ) { / * LFE is an input channel but requires no convolution * / / * apply gain to LFE signal and add to output buffer * / * dst + = * ( buffer[s - > lfe_channel] + wr ) * s - > gain_lfe ; temp_ir + = n_samples ; continue ; } / * current read position in ringbuffer : input sample write position * - delay for l - th ch . + diff . betw . IR length and buffer length * ( mod buffer length ) * / read = ( wr - * ( delay + l ) - ( n_samples - 1 ) + buffer_length ) & modulo ; if ( read + n_samples < buffer_length ) { memcpy ( temp_src , bptr + read , n_samples * sizeof ( * temp_src ) ) ; } else { int len = FFMIN ( n_samples - ( read % n_samples ) , buffer_length - read ) ; memcpy ( temp_src , bptr + read , len * sizeof ( * temp_src ) ) ; memcpy ( temp_src + len , bptr , ( n_samples - len ) * sizeof ( * temp_src ) ) ; } / * multiply signal and IR , and add up the results * / dst[0] + = s - > fdsp - > scalarproduct_float ( temp_ir , temp_src , n_samples ) ; temp_ir + = n_samples ; } / * clippings counter * / if ( fabs ( * dst ) > 1 ) * n_clippings + = 1 ; / * move output buffer pointer by + 2 to get to next sample of processed channel : * / dst + = 2 ; src + = in_channels ; wr = ( wr + 1 ) & modulo ; / * update ringbuffer write position * / } * write = wr ; / * remember write position in ringbuffer for next call * / return 0 ; }",1
"int ff_htmlmarkup_to_ass ( void * log_ctx , AVBPrint * dst , const char * in ) { char * param , buffer[128] , tmp[128] ; int len , tag_close , sptr = 1 , line_start = 1 , an = 0 , end = 0 ; SrtStack stack[16] ; int closing_brace_missing = 0 ; stack[0] . tag[0] = 0 ; strcpy ( stack[0] . param[PARAM_SIZE] , { \\fs } ) ; strcpy ( stack[0] . param[PARAM_COLOR] , { \\c } ) ; strcpy ( stack[0] . param[PARAM_FACE] , { \\fn } ) ; for ( ; ! end & & * in ; in + + ) { switch ( * in ) { case ' \r ' : break ; case ' \n ' : if ( line_start ) { end = 1 ; break ; } rstrip_spaces_buf ( dst ) ; av_bprintf ( dst , \\N ) ; line_start = 1 ; break ; case ' ' : if ( ! line_start ) av_bprint_chars ( dst , * in , 1 ) ; break ; case ' { ' : handle_open_brace ( dst , & in , & an , & closing_brace_missing ) ; break ; case ' < ' : tag_close = in[1] == ' / ' ; len = 0 ; if ( sscanf ( in + tag_close + 1 , %127[ > ] > %n , buffer , & len ) > = 1 & & len > 0 ) { const char * tagname = buffer ; while ( * tagname == ' ' ) tagname + + ; if ( ( param = strchr ( tagname , ' ' ) ) ) * param + + = 0 ; if ( ( ! tag_close & & sptr < FF_ARRAY_ELEMS ( stack ) ) || ( tag_close & & sptr > 0 & & ! av_strcasecmp ( stack[sptr - 1] . tag , tagname ) ) ) { int i , j , unknown = 0 ; in + = len + tag_close ; if ( ! tag_close ) memset ( stack + sptr , 0 , sizeof ( * stack ) ) ; if ( ! av_strcasecmp ( tagname , font ) ) { if ( tag_close ) { for ( i=PARAM_NUMBER - 1 ; i > =0 ; i - - ) if ( stack[sptr - 1] . param[i][0] ) for ( j=sptr - 2 ; j > =0 ; j - - ) if ( stack[j] . param[i][0] ) { av_bprintf ( dst , %s , stack[j] . param[i] ) ; break ; } } else { while ( param ) { if ( ! av_strncasecmp ( param , size= , 5 ) ) { unsigned font_size ; param + = 5 + ( param[5] == ' ' ) ; if ( sscanf ( param , %u , & font_size ) == 1 ) { snprintf ( stack[sptr] . param[PARAM_SIZE] , sizeof ( stack[0] . param[PARAM_SIZE] ) , { \\fs%u } , font_size ) ; } } else if ( ! av_strncasecmp ( param , color= , 6 ) ) { param + = 6 + ( param[6] == ' ' ) ; snprintf ( stack[sptr] . param[PARAM_COLOR] , sizeof ( stack[0] . param[PARAM_COLOR] ) , { \\c & H%X & } , html_color_parse ( log_ctx , param ) ) ; } else if ( ! av_strncasecmp ( param , face= , 5 ) ) { param + = 5 + ( param[5] == ' ' ) ; len = strcspn ( param , param[ - 1] == ' ' ? \ : ) ; av_strlcpy ( tmp , param , FFMIN ( sizeof ( tmp ) , len + 1 ) ) ; param + = len ; snprintf ( stack[sptr] . param[PARAM_FACE] , sizeof ( stack[0] . param[PARAM_FACE] ) , { \\fn%s } , tmp ) ; } if ( ( param = strchr ( param , ' ' ) ) ) param + + ; } for ( i=0 ; i < PARAM_NUMBER ; i + + ) if ( stack[sptr] . param[i][0] ) av_bprintf ( dst , %s , stack[sptr] . param[i] ) ; } } else if ( tagname[0] & & ! tagname[1] & & av_stristr ( bisu , tagname ) ) { av_bprintf ( dst , { \\%c%d } , ( char ) av_tolower ( tagname[0] ) , ! tag_close ) ; } else if ( ! av_strcasecmp ( tagname , br ) ) { av_bprintf ( dst , \\N ) ; } else { unknown = 1 ; snprintf ( tmp , sizeof ( tmp ) , < /%s > , tagname ) ; } if ( tag_close ) { sptr - - ; } else if ( unknown & & ! strstr ( in , tmp ) ) { in - = len + tag_close ; av_bprint_chars ( dst , * in , 1 ) ; } else av_strlcpy ( stack[sptr + + ] . tag , tagname , sizeof ( stack[0] . tag ) ) ; break ; } } default : av_bprint_chars ( dst , * in , 1 ) ; break ; } if ( * in ! = ' ' & & * in ! = ' \r ' & & * in ! = ' \n ' ) line_start = 0 ; } if ( ! av_bprint_is_complete ( dst ) ) return AVERROR ( ENOMEM ) ; while ( dst - > len > = 2 & & ! strncmp ( & dst - > str[dst - > len - 2] , \\N , 2 ) ) dst - > len - = 2 ; dst - > str[dst - > len] = 0 ; rstrip_spaces_buf ( dst ) ; return 0 ; }",1
"static int mxf_read_partition_pack ( void * arg , AVIOContext * pb , int tag , int size , UID uid ) { MXFContext * mxf = arg ; MXFPartition * partition ; UID op ; uint64_t footer_partition ; if ( mxf - > partitions_count + 1 > = UINT_MAX / sizeof ( * mxf - > partitions ) ) return AVERROR ( ENOMEM ) ; mxf - > partitions = av_realloc ( mxf - > partitions , ( mxf - > partitions_count + 1 ) * sizeof ( * mxf - > partitions ) ) ; if ( ! mxf - > partitions ) return AVERROR ( ENOMEM ) ; if ( mxf - > parsing_backward ) { / * insert the new partition pack in the middle * this makes the entries in mxf - > partitions sorted by offset * / memmove ( & mxf - > partitions[mxf - > last_forward_partition + 1] , & mxf - > partitions[mxf - > last_forward_partition] , ( mxf - > partitions_count - mxf - > last_forward_partition ) * sizeof ( * mxf - > partitions ) ) ; partition = mxf - > current_partition = & mxf - > partitions[mxf - > last_forward_partition] ; } else { mxf - > last_forward_partition + + ; partition = mxf - > current_partition = & mxf - > partitions[mxf - > partitions_count] ; } memset ( partition , 0 , sizeof ( * partition ) ) ; mxf - > partitions_count + + ; switch ( uid[13] ) { case 2 : partition - > type = Header ; break ; case 3 : partition - > type = BodyPartition ; break ; case 4 : partition - > type = Footer ; break ; default : av_log ( mxf - > fc , AV_LOG_ERROR , unknown partition type %i\n , uid[13] ) ; return AVERROR_INVALIDDATA ; } / * consider both footers to be closed ( there is only Footer and CompleteFooter ) * / partition - > closed = partition - > type == Footer || ! ( uid[14] & 1 ) ; partition - > complete = uid[14] > 2 ; avio_skip ( pb , 8 ) ; partition - > this_partition = avio_rb64 ( pb ) ; partition - > previous_partition = avio_rb64 ( pb ) ; footer_partition = avio_rb64 ( pb ) ; avio_skip ( pb , 16 ) ; partition - > index_sid = avio_rb32 ( pb ) ; avio_skip ( pb , 8 ) ; partition - > body_sid = avio_rb32 ( pb ) ; avio_read ( pb , op , sizeof ( UID ) ) ; / * some files don ' thave FooterPartition set in every partition * / if ( footer_partition ) { if ( mxf - > footer_partition & & mxf - > footer_partition ! = footer_partition ) { av_log ( mxf - > fc , AV_LOG_ERROR , inconsistent FooterPartition value : %li ! = %li\n , mxf - > footer_partition , footer_partition ) ; } else { mxf - > footer_partition = footer_partition ; } } av_dlog ( mxf - > fc , PartitionPack : ThisPartition = 0x%lx , PreviousPartition = 0x%lx , FooterPartition = 0x%lx , IndexSID = %i , BodySID = %i\n , partition - > this_partition , partition - > previous_partition , footer_partition , partition - > index_sid , partition - > body_sid ) ; if ( op[12] == 1 & & op[13] == 1 ) mxf - > op = OP1a ; else if ( op[12] == 1 & & op[13] == 2 ) mxf - > op = OP1b ; else if ( op[12] == 1 & & op[13] == 3 ) mxf - > op = OP1c ; else if ( op[12] == 2 & & op[13] == 1 ) mxf - > op = OP2a ; else if ( op[12] == 2 & & op[13] == 2 ) mxf - > op = OP2b ; else if ( op[12] == 2 & & op[13] == 3 ) mxf - > op = OP2c ; else if ( op[12] == 3 & & op[13] == 1 ) mxf - > op = OP3a ; else if ( op[12] == 3 & & op[13] == 2 ) mxf - > op = OP3b ; else if ( op[12] == 3 & & op[13] == 3 ) mxf - > op = OP3c ; else if ( op[12] == 0x10 ) mxf - > op = OPAtom ; else av_log ( mxf - > fc , AV_LOG_ERROR , unknown operational pattern : %02xh %02xh\n , op[12] , op[13] ) ; return 0 ; }",1
"static uint64_t getSSD ( uint8_t * src1 , uint8_t * src2 , int stride1 , int stride2 , int w , int h ) { int x , y ; uint64_t ssd=0 ; //printf ( %d %d\n , w , h ) ; for ( y=0 ; y < h ; y + + ) { for ( x=0 ; x < w ; x + + ) { int d= src1[x + y * stride1] - src2[x + y * stride2] ; ssd + = d * d ; //printf ( %d , abs ( src1[x + y * stride1] - src2[x + y * stride2] ) /26 ) ; } //printf ( \n ) ; } return ssd ; }",1
"static int put_system_header ( AVFormatContext * ctx , uint8_t * buf , int only_for_stream_id ) { MpegMuxContext * s = ctx - > priv_data ; int size , i , private_stream_coded , id ; PutBitContext pb ; init_put_bits ( & pb , buf , 128 ) ; put_bits ( & pb , 32 , SYSTEM_HEADER_START_CODE ) ; put_bits ( & pb , 16 , 0 ) ; put_bits ( & pb , 1 , 1 ) ; put_bits ( & pb , 22 , s - > mux_rate ) ; / * maximum bit rate of the multiplexed stream * / put_bits ( & pb , 1 , 1 ) ; / * marker * / if ( s - > is_vcd & & only_for_stream_id==VIDEO_ID ) { / * This header applies only to the video stream ( see VCD standard p . IV - 7 ) * / put_bits ( & pb , 6 , 0 ) ; } else put_bits ( & pb , 6 , s - > audio_bound ) ; if ( s - > is_vcd ) { / * see VCD standard , p . IV - 7 * / put_bits ( & pb , 1 , 0 ) ; put_bits ( & pb , 1 , 1 ) ; } else { put_bits ( & pb , 1 , 0 ) ; / * variable bitrate * / put_bits ( & pb , 1 , 0 ) ; / * non constrainted bit stream * / } if ( s - > is_vcd || s - > is_dvd ) { / * see VCD standard p IV - 7 * / put_bits ( & pb , 1 , 1 ) ; / * audio locked * / put_bits ( & pb , 1 , 1 ) ; / * video locked * / } else { put_bits ( & pb , 1 , 0 ) ; / * audio locked * / put_bits ( & pb , 1 , 0 ) ; / * video locked * / } put_bits ( & pb , 1 , 1 ) ; / * marker * / if ( s - > is_vcd & & only_for_stream_id==AUDIO_ID ) { / * This header applies only to the audio stream ( see VCD standard p . IV - 7 ) * / put_bits ( & pb , 5 , 0 ) ; } else put_bits ( & pb , 5 , s - > video_bound ) ; if ( s - > is_dvd ) { put_bits ( & pb , 1 , 0 ) ; / * packet_rate_restriction_flag * / put_bits ( & pb , 7 , 0x7f ) ; / * reserved byte * / } else put_bits ( & pb , 8 , 0xff ) ; / * reserved byte * / / * DVD - Video Stream_bound entries id ( 0xB9 ) video , maximum P - STD for stream 0xE0 . ( P - STD_buffer_bound_scale = 1 ) id ( 0xB8 ) audio , maximum P - STD for any MPEG audio ( 0xC0 to 0xC7 ) streams . If there are none set to 4096 ( 32x128 ) . ( P - STD_buffer_bound_scale = 0 ) id ( 0xBD ) private stream 1 ( audio other than MPEG and subpictures ) . ( P - STD_buffer_bound_scale = 1 ) id ( 0xBF ) private stream 2 , NAV packs , set to 2x1024 . * / if ( s - > is_dvd ) { int P_STD_max_video = 0 ; int P_STD_max_mpeg_audio = 0 ; int P_STD_max_mpeg_PS1 = 0 ; for ( i=0 ; i < ctx - > nb_streams ; i + + ) { StreamInfo * stream = ctx - > streams[i] - > priv_data ; id = stream - > id ; if ( id == 0xbd & & stream - > max_buffer_size > P_STD_max_mpeg_PS1 ) { P_STD_max_mpeg_PS1 = stream - > max_buffer_size ; } else if ( id > = 0xc0 & & id < = 0xc7 & & stream - > max_buffer_size > P_STD_max_mpeg_audio ) { P_STD_max_mpeg_audio = stream - > max_buffer_size ; } else if ( id == 0xe0 & & stream - > max_buffer_size > P_STD_max_video ) { P_STD_max_video = stream - > max_buffer_size ; } } / * video * / put_bits ( & pb , 8 , 0xb9 ) ; / * stream ID * / put_bits ( & pb , 2 , 3 ) ; put_bits ( & pb , 1 , 1 ) ; put_bits ( & pb , 13 , P_STD_max_video / 1024 ) ; / * audio * / if ( P_STD_max_mpeg_audio == 0 ) P_STD_max_mpeg_audio = 4096 ; put_bits ( & pb , 8 , 0xb8 ) ; / * stream ID * / put_bits ( & pb , 2 , 3 ) ; put_bits ( & pb , 1 , 0 ) ; put_bits ( & pb , 13 , P_STD_max_mpeg_audio / 128 ) ; / * private stream 1 * / put_bits ( & pb , 8 , 0xbd ) ; / * stream ID * / put_bits ( & pb , 2 , 3 ) ; put_bits ( & pb , 1 , 0 ) ; put_bits ( & pb , 13 , P_STD_max_mpeg_PS1 / 128 ) ; / * private stream 2 * / put_bits ( & pb , 8 , 0xbf ) ; / * stream ID * / put_bits ( & pb , 2 , 3 ) ; put_bits ( & pb , 1 , 1 ) ; put_bits ( & pb , 13 , 2 ) ; } else { / * audio stream info * / private_stream_coded = 0 ; for ( i=0 ; i < ctx - > nb_streams ; i + + ) { StreamInfo * stream = ctx - > streams[i] - > priv_data ; / * For VCDs , only include the stream info for the stream that the pack which contains this system belongs to . ( see VCD standard p . IV - 7 ) * / if ( ! s - > is_vcd || stream - > id==only_for_stream_id || only_for_stream_id==0 ) { id = stream - > id ; if ( id < 0xc0 ) { / * special case for private streams ( AC - 3 uses that ) * / if ( private_stream_coded ) continue ; private_stream_coded = 1 ; id = 0xbd ; } put_bits ( & pb , 8 , id ) ; / * stream ID * / put_bits ( & pb , 2 , 3 ) ; if ( id < 0xe0 ) { / * audio * / put_bits ( & pb , 1 , 0 ) ; put_bits ( & pb , 13 , stream - > max_buffer_size / 128 ) ; } else { / * video * / put_bits ( & pb , 1 , 1 ) ; put_bits ( & pb , 13 , stream - > max_buffer_size / 1024 ) ; } } } } flush_put_bits ( & pb ) ; size = put_bits_ptr ( & pb ) - pb . buf ; /",0
"static int standard_decode_i_mbs ( VC9Context * v ) { int x , y , ac_pred , cbpcy ; / * Select ttmb table depending on pq * / if ( v - > pq < 5 ) v - > ttmb_vlc = & vc9_ttmb_vlc[0] ; else if ( v - > pq < 13 ) v - > ttmb_vlc = & vc9_ttmb_vlc[1] ; else v - > ttmb_vlc = & vc9_ttmb_vlc[2] ; for ( y=0 ; y < v - > height_mb ; y + + ) { for ( x=0 ; x < v - > width_mb ; x + + ) { cbpcy = get_vlc2 ( & v - > gb , vc9_cbpcy_i_vlc . table , VC9_CBPCY_I_VLC_BITS , 2 ) ; ac_pred = get_bits ( & v - > gb , 1 ) ; //Decode blocks from that mb wrt cbpcy } } return 0 ; }",0
"static void ff_h264_idct8_dc_add_mmx2 ( uint8_t * dst , int16_t * block , int stride ) { int dc = ( block[0] + 32 ) > > 6 ; int y ; __asm__ volatile ( movd %0 , %%mm0 \n\t pshufw 0 , %%mm0 , %%mm0 \n\t pxor %%mm1 , %%mm1 \n\t psubw %%mm0 , %%mm1 \n\t packuswb %%mm0 , %%mm0 \n\t packuswb %%mm1 , %%mm1 \n\t : : r ( dc ) ) ; for ( y=2 ; y - - ; dst + = 4 * stride ) { __asm__ volatile ( movq %0 , %%mm2 \n\t movq %1 , %%mm3 \n\t movq %2 , %%mm4 \n\t movq %3 , %%mm5 \n\t paddusb %%mm0 , %%mm2 \n\t paddusb %%mm0 , %%mm3 \n\t paddusb %%mm0 , %%mm4 \n\t paddusb %%mm0 , %%mm5 \n\t psubusb %%mm1 , %%mm2 \n\t psubusb %%mm1 , %%mm3 \n\t psubusb %%mm1 , %%mm4 \n\t psubusb %%mm1 , %%mm5 \n\t movq %%mm2 , %0 \n\t movq %%mm3 , %1 \n\t movq %%mm4 , %2 \n\t movq %%mm5 , %3 \n\t : + m ( * ( uint64_t * ) ( dst + 0 * stride ) ) , + m ( * ( uint64_t * ) ( dst + 1 * stride ) ) , + m ( * ( uint64_t * ) ( dst + 2 * stride ) ) , + m ( * ( uint64_t * ) ( dst + 3 * stride ) ) ) ; } }",0
"static int movie_get_frame ( AVFilterLink * outlink ) { MovieContext * movie = outlink - > src - > priv ; AVPacket pkt ; int ret , frame_decoded ; AVStream * st = movie - > format_ctx - > streams[movie - > stream_index] ; if ( movie - > is_done == 1 ) return 0 ; while ( ( ret = av_read_frame ( movie - > format_ctx , & pkt ) ) > = 0 ) { // Is this a packet from the video stream ? if ( pkt . stream_index == movie - > stream_index ) { avcodec_decode_video2 ( movie - > codec_ctx , movie - > frame , & frame_decoded , & pkt ) ; if ( frame_decoded ) { / * FIXME : avoid the memcpy * / movie - > picref = avfilter_get_video_buffer ( outlink , AV_PERM_WRITE | AV_PERM_PRESERVE | AV_PERM_REUSE2 , outlink - > w , outlink - > h ) ; av_image_copy ( movie - > picref - > data , movie - > picref - > linesize , ( void * ) movie - > frame - > data , movie - > frame - > linesize , movie - > picref - > format , outlink - > w , outlink - > h ) ; avfilter_copy_frame_props ( movie - > picref , movie - > frame ) ; / * FIXME : use a PTS correction mechanism as that in * ffplay . c when some API will be available for that * / / * use pkt_dts if pkt_pts is not available * / movie - > picref - > pts = movie - > frame - > pkt_pts == AV_NOPTS_VALUE ? movie - > frame - > pkt_dts : movie - > frame - > pkt_pts ; if ( ! movie - > frame - > sample_aspect_ratio . num ) movie - > picref - > video - > sample_aspect_ratio = st - > sample_aspect_ratio ; av_dlog ( outlink - > src , movie_get_frame ( ) : file : ' %s ' pts : % PRId64 time : %lf pos : % PRId64 aspect : %d/%d\n , movie - > file_name , movie - > picref - > pts , ( double ) movie - > picref - > pts * av_q2d ( st - > time_base ) , movie - > picref - > pos , movie - > picref - > video - > sample_aspect_ratio . num , movie - > picref - > video - > sample_aspect_ratio . den ) ; // We got it . Free the packet since we are returning av_free_packet ( & pkt ) ; return 0 ; } } // Free the packet that was allocated by av_read_frame av_free_packet ( & pkt ) ; } // On multi - frame source we should stop the mixing process when // the movie source does not have more frames if ( ret == AVERROR_EOF ) movie - > is_done = 1 ; return ret ; }",0
"void ff_dsputil_init_neon ( DSPContext * c , AVCodecContext * avctx ) { c - > put_pixels_tab[0][0] = ff_put_pixels16_neon ; c - > put_pixels_tab[0][1] = ff_put_pixels16_x2_neon ; c - > put_pixels_tab[0][2] = ff_put_pixels16_y2_neon ; c - > put_pixels_tab[0][3] = ff_put_pixels16_xy2_neon ; c - > put_pixels_tab[1][0] = ff_put_pixels8_neon ; c - > put_pixels_tab[1][1] = ff_put_pixels8_x2_neon ; c - > put_pixels_tab[1][2] = ff_put_pixels8_y2_neon ; c - > put_pixels_tab[1][3] = ff_put_pixels8_xy2_neon ; c - > put_no_rnd_pixels_tab[0][0] = ff_put_pixels16_neon ; c - > put_no_rnd_pixels_tab[0][1] = ff_put_pixels16_x2_no_rnd_neon ; c - > put_no_rnd_pixels_tab[0][2] = ff_put_pixels16_y2_no_rnd_neon ; c - > put_no_rnd_pixels_tab[0][3] = ff_put_pixels16_xy2_no_rnd_neon ; c - > put_no_rnd_pixels_tab[1][0] = ff_put_pixels8_neon ; c - > put_no_rnd_pixels_tab[1][1] = ff_put_pixels8_x2_no_rnd_neon ; c - > put_no_rnd_pixels_tab[1][2] = ff_put_pixels8_y2_no_rnd_neon ; c - > put_no_rnd_pixels_tab[1][3] = ff_put_pixels8_xy2_no_rnd_neon ; c - > avg_pixels_tab[0][0] = ff_avg_pixels16_neon ; c - > add_pixels_clamped = ff_add_pixels_clamped_neon ; c - > put_pixels_clamped = ff_put_pixels_clamped_neon ; c - > put_signed_pixels_clamped = ff_put_signed_pixels_clamped_neon ; c - > put_h264_chroma_pixels_tab[0] = ff_put_h264_chroma_mc8_neon ; c - > put_h264_chroma_pixels_tab[1] = ff_put_h264_chroma_mc4_neon ; c - > avg_h264_chroma_pixels_tab[0] = ff_avg_h264_chroma_mc8_neon ; c - > avg_h264_chroma_pixels_tab[1] = ff_avg_h264_chroma_mc4_neon ; c - > put_h264_qpel_pixels_tab[0][ 0] = ff_put_h264_qpel16_mc00_neon ; c - > put_h264_qpel_pixels_tab[0][ 1] = ff_put_h264_qpel16_mc10_neon ; c - > put_h264_qpel_pixels_tab[0][ 2] = ff_put_h264_qpel16_mc20_neon ; c - > put_h264_qpel_pixels_tab[0][ 3] = ff_put_h264_qpel16_mc30_neon ; c - > put_h264_qpel_pixels_tab[0][ 4] = ff_put_h264_qpel16_mc01_neon ; c - > put_h264_qpel_pixels_tab[0][ 5] = ff_put_h264_qpel16_mc11_neon ; c - > put_h264_qpel_pixels_tab[0][ 6] = ff_put_h264_qpel16_mc21_neon ; c - > put_h264_qpel_pixels_tab[0][ 7] = ff_put_h264_qpel16_mc31_neon ; c - > put_h264_qpel_pixels_tab[0][ 8] = ff_put_h264_qpel16_mc02_neon ; c - > put_h264_qpel_pixels_tab[0][ 9] = ff_put_h264_qpel16_mc12_neon ; c - > put_h264_qpel_pixels_tab[0][10] = ff_put_h264_qpel16_mc22_neon ; c - > put_h264_qpel_pixels_tab[0][11] = ff_put_h264_qpel16_mc32_neon ; c - > put_h264_qpel_pixels_tab[0][12] = ff_put_h264_qpel16_mc03_neon ; c - > put_h264_qpel_pixels_tab[0][13] = ff_put_h264_qpel16_mc13_neon ; c - > put_h264_qpel_pixels_tab[0][14] = ff_put_h264_qpel16_mc23_neon ; c - > put_h264_qpel_pixels_tab[0][15] = ff_put_h264_qpel16_mc33_neon ; c - > put_h264_qpel_pixels_tab[1][ 0] = ff_put_h264_qpel8_mc00_neon ; c - > put_h264_qpel_pixels_tab[1][ 1] = ff_put_h264_qpel8_mc10_neon ; c - > put_h264_qpel_pixels_tab[1][ 2] = ff_put_h264_qpel8_mc20_neon ; c - > put_h264_qpel_pixels_tab[1][ 3] = ff_put_h264_qpel8_mc30_neon ; c - > put_h264_qpel_pixels_tab[1][ 4] = ff_put_h264_qpel8_mc01_neon ; c - > put_h264_qpel_pixels_tab[1][ 5] = ff_put_h264_qpel8_mc11_neon ; c - > put_h264_qpel_pixels_tab[1][ 6] = ff_put_h264_qpel8_mc21_neon ; c - > put_h264_qpel_pixels_tab[1][ 7] = ff_put_h264_qpel8_mc31_neon ; c - > put_h264_qpel_pixels_tab[1][ 8] = ff_put_h264_qpel8_mc02_neon ; c - > put_h264_qpel_pixels_tab[1][ 9] = ff_put_h264_qpel8_mc12_neon ; c - > put_h264_qpel_pixels_tab[1][10] = ff_put_h264_qpel8_mc22_neon ; c - > put_h264_qpel_pixels_tab[1][11] = ff_put_h264_qpel8_mc32_neon ; c - > put_h264_qpel_pixels_tab[1][12] = ff_put_h264_qpel8_mc03_neon ; c - > put_h264_qpel_pixels_tab[1][13] = ff_put_h264_qpel8_mc13_neon ; c - > put_h264_qpel_pixels_tab[1][14] = ff_put_h264_qpel8_mc23_neon ; c - > put_h264_qpel_pixels_tab[1][15] = ff_put_h264_qpel8_mc33_neon ; c - > avg_h264_qpel_pixels_tab[0][ 0] = ff_avg_h264_qpel16_mc00_neon ; c - > h264_v_loop_filter_luma = ff_h264_v_loop_filter_luma_neon ; c - > h264_h_loop_filter_luma = ff_h264_h_loop_filter_luma_neon ; c - > h264_v_loop_filter_chroma = ff_h264_v_loop_filter_chroma_neon ; c - > h264_h_loop_filter_chroma = ff_h264_h_loop_filter_chroma_neon ; c - > weight_h264_pixels_tab[0] = ff_weight_h264_pixels_16x16_neon ; c - > weight_h264_pixels_tab[1] = ff_weight_h264_pixels_16x8_neon ; c - > weight_h264_pixels_tab[2] = ff_weight_h264_pixels_8x16_neon ; c - > weight_h264_pixels_tab[3] = ff_weight_h264_pixels_8x8_neon ; c - > weight_h264_pixels_tab[4] = ff_weight_h264_pixels_8x4_neon ; c - > weight_h264_pixels_tab[5] = ff_weight_h264_pixels_4x8_neon ; c - > weight_h264_pixels_tab[6] = ff_weight_h264_pixels_4x4_neon ; c - > weight_h264_pixels_tab[7] = ff_weight_h264_pixels_4x2_neon ; c - > biweight_h264_pixels_tab[0] = ff_biweight_h264_pixels_16x16_neon ; c - > biweight_h264_pixels_tab[1] = ff_biweight_h264_pixels_16x8_neon ; c - > biweight_h264_pixels_tab[2] = ff_biweight_h264_pixels_8x16_neon ; c - > biweight_h264_pixels_tab[3] = ff_biweight_h264_pixels_8x8_neon ; c - > biweight_h264_pixels_tab[4] = ff_biweight_h264_pixels_8x4_neon ; c - > biweight_h264_pixels_tab[5] = ff_biweight_h264_pixels_4x8_neon ; c - > biweight_h264_pixels_tab[6] = ff_biweight_h264_pixels_4x4_neon ; c - > biweight_h264_pixels_tab[7] = ff_biweight_h264_pixels_4x2_neon ; c - > h264_idct_add = ff_h264_idct_add_neon ; c - > h264_idct_dc_add = ff_h264_idct_dc_add_neon ; c - > h264_idct_add16 = ff_h264_idct_add16_neon ; c - > h264_idct_add16intra = ff_h264_idct_add16intra_neon ; c - > h264_idct_add8 = ff_h264_idct_add8_neon ; if ( CONFIG_VP3_DECODER || CONFIG_THEORA_DECODER ) { c - > vp3_v_loop_filter = ff_vp3_v_loop_filter_neon ; c - > vp3_h_loop_filter = ff_vp3_h_loop_filter_neon ; } c - > vector_fmul = ff_vector_fmul_neon ; c - > vector_fmul_window = ff_vector_fmul_window_neon ; if ( ! ( avctx - > flags & CODEC_FLAG_BITEXACT ) ) { c - > float_to_int16 = ff_float_to_int16_neon ; c - > float_to_int16_interleave = ff_float_to_int16_interleave_neon ; } }",0
"static int encode_frame ( AVCodecContext * avctx , AVPacket * avpkt , const AVFrame * frame , int * got_packet_ptr ) { NellyMoserEncodeContext * s = avctx - > priv_data ; int ret ; if ( s - > last_frame ) return 0 ; memcpy ( s - > buf , s - > buf + NELLY_SAMPLES , NELLY_BUF_LEN * sizeof ( * s - > buf ) ) ; if ( frame ) { memcpy ( s - > buf + NELLY_BUF_LEN , frame - > data[0] , frame - > nb_samples * sizeof ( * s - > buf ) ) ; if ( frame - > nb_samples < NELLY_SAMPLES ) { memset ( s - > buf + NELLY_BUF_LEN + avctx - > frame_size , 0 , ( NELLY_SAMPLES - frame - > nb_samples ) * sizeof ( * s - > buf ) ) ; if ( frame - > nb_samples > = NELLY_BUF_LEN ) s - > last_frame = 1 ; } if ( ( ret = ff_af_queue_add ( & s - > afq , frame ) < 0 ) ) return ret ; } else { memset ( s - > buf + NELLY_BUF_LEN , 0 , NELLY_SAMPLES * sizeof ( * s - > buf ) ) ; s - > last_frame = 1 ; } if ( ( ret = ff_alloc_packet ( avpkt , NELLY_BLOCK_LEN ) ) ) { av_log ( avctx , AV_LOG_ERROR , Error getting output packet\n ) ; return ret ; } encode_block ( s , avpkt - > data , avpkt - > size ) ; / * Get the next frame pts/duration * / ff_af_queue_remove ( & s - > afq , avctx - > frame_size , & avpkt - > pts , & avpkt - > duration ) ; * got_packet_ptr = 1 ; return 0 ; }",1
"static int rtp_new_av_stream ( HTTPContext * c , int stream_index , struct sockaddr_in * dest_addr , HTTPContext * rtsp_c ) { AVFormatContext * ctx ; AVStream * st ; char * ipaddr ; URLContext * h = NULL ; uint8_t * dummy_buf ; int max_packet_size ; / * now we can open the relevant output stream * / ctx = avformat_alloc_context ( ) ; if ( ! ctx ) return - 1 ; ctx - > oformat = av_guess_format ( rtp , NULL , NULL ) ; st = av_mallocz ( sizeof ( AVStream ) ) ; if ( ! st ) goto fail ; st - > codec= avcodec_alloc_context ( ) ; ctx - > nb_streams = 1 ; ctx - > streams[0] = st ; if ( ! c - > stream - > feed || c - > stream - > feed == c - > stream ) memcpy ( st , c - > stream - > streams[stream_index] , sizeof ( AVStream ) ) ; else memcpy ( st , c - > stream - > feed - > streams[c - > stream - > feed_streams[stream_index]] , sizeof ( AVStream ) ) ; st - > priv_data = NULL ; / * build destination RTP address * / ipaddr = inet_ntoa ( dest_addr - > sin_addr ) ; switch ( c - > rtp_protocol ) { case RTSP_LOWER_TRANSPORT_UDP : case RTSP_LOWER_TRANSPORT_UDP_MULTICAST : / * RTP/UDP case * / / * XXX : also pass as parameter to function ? * / if ( c - > stream - > is_multicast ) { int ttl ; ttl = c - > stream - > multicast_ttl ; if ( ! ttl ) ttl = 16 ; snprintf ( ctx - > filename , sizeof ( ctx - > filename ) , rtp : //%s : %d ? multicast=1 & ttl=%d , ipaddr , ntohs ( dest_addr - > sin_port ) , ttl ) ; } else { snprintf ( ctx - > filename , sizeof ( ctx - > filename ) , rtp : //%s : %d , ipaddr , ntohs ( dest_addr - > sin_port ) ) ; } if ( url_open ( & h , ctx - > filename , URL_WRONLY ) < 0 ) goto fail ; c - > rtp_handles[stream_index] = h ; max_packet_size = url_get_max_packet_size ( h ) ; break ; case RTSP_LOWER_TRANSPORT_TCP : / * RTP/TCP case * / c - > rtsp_c = rtsp_c ; max_packet_size = RTSP_TCP_MAX_PACKET_SIZE ; break ; default : goto fail ; } http_log ( %s : %d - - \ PLAY %s/streamid=%d %s\ \n , ipaddr , ntohs ( dest_addr - > sin_port ) , c - > stream - > filename , stream_index , c - > protocol ) ; / * normally , no packets should be output here , but the packet size may be checked * / if ( url_open_dyn_packet_buf ( & ctx - > pb , max_packet_size ) < 0 ) { / * XXX : close stream * / goto fail ; } av_set_parameters ( ctx , NULL ) ; if ( av_write_header ( ctx ) < 0 ) { fail : if ( h ) url_close ( h ) ; av_free ( ctx ) ; return - 1 ; } url_close_dyn_buf ( ctx - > pb , & dummy_buf ) ; av_free ( dummy_buf ) ; c - > rtp_ctx[stream_index] = ctx ; return 0 ; }",1
"static int dvbsub_parse_clut_segment ( AVCodecContext * avctx , const uint8_t * buf , int buf_size ) { DVBSubContext * ctx = avctx - > priv_data ; const uint8_t * buf_end = buf + buf_size ; int i , clut_id ; int version ; DVBSubCLUT * clut ; int entry_id , depth , full_range ; int y , cr , cb , alpha ; int r , g , b , r_add , g_add , b_add ; ff_dlog ( avctx , DVB clut packet : \n ) ; for ( i=0 ; i < buf_size ; i + + ) { ff_dlog ( avctx , %02x , buf[i] ) ; if ( i % 16 == 15 ) ff_dlog ( avctx , \n ) ; } if ( i % 16 ) ff_dlog ( avctx , \n ) ; clut_id = * buf + + ; version = ( ( * buf ) > > 4 ) & 15 ; buf + = 1 ; clut = get_clut ( ctx , clut_id ) ; if ( ! clut ) { clut = av_malloc ( sizeof ( DVBSubCLUT ) ) ; if ( ! clut ) return AVERROR ( ENOMEM ) ; memcpy ( clut , & default_clut , sizeof ( DVBSubCLUT ) ) ; clut - > id = clut_id ; clut - > version = - 1 ; clut - > next = ctx - > clut_list ; ctx - > clut_list = clut ; } if ( clut - > version ! = version ) { clut - > version = version ; while ( buf + 4 < buf_end ) { entry_id = * buf + + ; depth = ( * buf ) & 0xe0 ; if ( depth == 0 ) { av_log ( avctx , AV_LOG_ERROR , Invalid clut depth 0x%x ! \n , * buf ) ; } full_range = ( * buf + + ) & 1 ; if ( full_range ) { y = * buf + + ; cr = * buf + + ; cb = * buf + + ; alpha = * buf + + ; } else { y = buf[0] & 0xfc ; cr = ( ( ( buf[0] & 3 ) < < 2 ) | ( ( buf[1] > > 6 ) & 3 ) ) < < 4 ; cb = ( buf[1] < < 2 ) & 0xf0 ; alpha = ( buf[1] < < 6 ) & 0xc0 ; buf + = 2 ; } if ( y == 0 ) alpha = 0xff ; YUV_TO_RGB1_CCIR ( cb , cr ) ; YUV_TO_RGB2_CCIR ( r , g , b , y ) ; ff_dlog ( avctx , clut %d : = ( %d , %d , %d , %d ) \n , entry_id , r , g , b , alpha ) ; if ( ! ! ( depth & 0x80 ) + ! ! ( depth & 0x40 ) + ! ! ( depth & 0x20 ) > 1 ) { ff_dlog ( avctx , More than one bit level marked : %x\n , depth ) ; if ( avctx - > strict_std_compliance > FF_COMPLIANCE_NORMAL ) return AVERROR_INVALIDDATA ; } if ( depth & 0x80 ) clut - > clut4[entry_id] = RGBA ( r , g , b , 255 - alpha ) ; else if ( depth & 0x40 ) clut - > clut16[entry_id] = RGBA ( r , g , b , 255 - alpha ) ; else if ( depth & 0x20 ) clut - > clut256[entry_id] = RGBA ( r , g , b , 255 - alpha ) ; } } return 0 ; }",1
"static inline void vc1_pred_mv_intfr ( VC1Context * v , int n , int dmv_x , int dmv_y , int mvn , int r_x , int r_y , uint8_t * is_intra ) { MpegEncContext * s = & v - > s ; int xy , wrap , off = 0 ; int A[2] , B[2] , C[2] ; int px , py ; int a_valid = 0 , b_valid = 0 , c_valid = 0 ; int field_a , field_b , field_c ; // 0 : same , 1 : opposit int total_valid , num_samefield , num_oppfield ; int pos_c , pos_b , n_adj ; wrap = s - > b8_stride ; xy = s - > block_index[n] ; if ( s - > mb_intra ) { s - > mv[0][n][0] = s - > current_picture . f . motion_val[0][xy][0] = 0 ; s - > mv[0][n][1] = s - > current_picture . f . motion_val[0][xy][1] = 0 ; s - > current_picture . f . motion_val[1][xy][0] = 0 ; s - > current_picture . f . motion_val[1][xy][1] = 0 ; if ( mvn == 1 ) { / * duplicate motion data for 1 - MV block * / s - > current_picture . f . motion_val[0][xy + 1][0] = 0 ; s - > current_picture . f . motion_val[0][xy + 1][1] = 0 ; s - > current_picture . f . motion_val[0][xy + wrap][0] = 0 ; s - > current_picture . f . motion_val[0][xy + wrap][1] = 0 ; s - > current_picture . f . motion_val[0][xy + wrap + 1][0] = 0 ; s - > current_picture . f . motion_val[0][xy + wrap + 1][1] = 0 ; v - > luma_mv[s - > mb_x][0] = v - > luma_mv[s - > mb_x][1] = 0 ; s - > current_picture . f . motion_val[1][xy + 1][0] = 0 ; s - > current_picture . f . motion_val[1][xy + 1][1] = 0 ; s - > current_picture . f . motion_val[1][xy + wrap][0] = 0 ; s - > current_picture . f . motion_val[1][xy + wrap][1] = 0 ; s - > current_picture . f . motion_val[1][xy + wrap + 1][0] = 0 ; s - > current_picture . f . motion_val[1][xy + wrap + 1][1] = 0 ; } return ; } off = ( ( n == 0 ) || ( n == 1 ) ) ? 1 : - 1 ; / * predict A * / if ( s - > mb_x || ( n == 1 ) || ( n == 3 ) ) { if ( ( v - > blk_mv_type[xy] ) // current block ( MB ) has a field MV || ( ! v - > blk_mv_type[xy] & & ! v - > blk_mv_type[xy - 1] ) ) { // or both have frame MV A[0] = s - > current_picture . f . motion_val[0][xy - 1][0] ; A[1] = s - > current_picture . f . motion_val[0][xy - 1][1] ; a_valid = 1 ; } else { // current block has frame mv and cand . has field MV ( so average ) A[0] = ( s - > current_picture . f . motion_val[0][xy - 1][0] + s - > current_picture . f . motion_val[0][xy - 1 + off * wrap][0] + 1 ) > > 1 ; A[1] = ( s - > current_picture . f . motion_val[0][xy - 1][1] + s - > current_picture . f . motion_val[0][xy - 1 + off * wrap][1] + 1 ) > > 1 ; a_valid = 1 ; } if ( ! ( n & 1 ) & & v - > is_intra[s - > mb_x - 1] ) { a_valid = 0 ; A[0] = A[1] = 0 ; } } else A[0] = A[1] = 0 ; / * Predict B and C * / B[0] = B[1] = C[0] = C[1] = 0 ; if ( n == 0 || n == 1 || v - > blk_mv_type[xy] ) { if ( ! s - > first_slice_line ) { if ( ! v - > is_intra[s - > mb_x - s - > mb_stride] ) { b_valid = 1 ; n_adj = n | 2 ; pos_b = s - > block_index[n_adj] - 2 * wrap ; if ( v - > blk_mv_type[pos_b] & & v - > blk_mv_type[xy] ) { n_adj = ( n & 2 ) | ( n & 1 ) ; } B[0] = s - > current_picture . f . motion_val[0][s - > block_index[n_adj] - 2 * wrap][0] ; B[1] = s - > current_picture . f . motion_val[0][s - > block_index[n_adj] - 2 * wrap][1] ; if ( v - > blk_mv_type[pos_b] & & ! v - > blk_mv_type[xy] ) { B[0] = ( B[0] + s - > current_picture . f . motion_val[0][s - > block_index[n_adj 2] - 2 * wrap][0] + 1 ) > > 1 ; B[1] = ( B[1] + s - > current_picture . f . motion_val[0][s - > block_index[n_adj 2] - 2 * wrap][1] + 1 ) > > 1 ; } } if ( s - > mb_width > 1 ) { if ( ! v - > is_intra[s - > mb_x - s - > mb_stride + 1] ) { c_valid = 1 ; n_adj = 2 ; pos_c = s - > block_index[2] - 2 * wrap + 2 ; if ( v - > blk_mv_type[pos_c] & & v - > blk_mv_type[xy] ) { n_adj = n & 2 ; } C[0] = s - > current_picture . f . motion_val[0][s - > block_index[n_adj] - 2 * wrap + 2][0] ; C[1] = s - > current_picture . f . motion_val[0][s - > block_index[n_adj] - 2 * wrap + 2][1] ; if ( v - > blk_mv_type[pos_c] & & ! v - > blk_mv_type[xy] ) { C[0] = ( 1 + C[0] + ( s - > current_picture . f . motion_val[0][s - > block_index[n_adj 2] - 2 * wrap + 2][0] ) ) > > 1 ; C[1] = ( 1 + C[1] + ( s - > current_picture . f . motion_val[0][s - > block_index[n_adj 2] - 2 * wrap + 2][1] ) ) > > 1 ; } if ( s - > mb_x == s - > mb_width - 1 ) { if ( ! v - > is_intra[s - > mb_x - s - > mb_stride - 1] ) { c_valid = 1 ; n_adj = 3 ; pos_c = s - > block_index[3] - 2 * wrap - 2 ; if ( v - > blk_mv_type[pos_c] & & v - > blk_mv_type[xy] ) { n_adj = n | 1 ; } C[0] = s - > current_picture . f . motion_val[0][s - > block_index[n_adj] - 2 * wrap - 2][0] ; C[1] = s - > current_picture . f . motion_val[0][s - > block_index[n_adj] - 2 * wrap - 2][1] ; if ( v - > blk_mv_type[pos_c] & & ! v - > blk_mv_type[xy] ) { C[0] = ( 1 + C[0] + s - > current_picture . f . motion_val[0][s - > block_index[1] -",1
"static void qtrle_encode_line ( QtrleEncContext * s , AVFrame * p , int line , uint8_t * * buf ) { int width=s - > logical_width ; int i ; signed char rlecode ; / * We will use it to compute the best bulk copy sequence * / unsigned int bulkcount ; / * This will be the number of pixels equal to the preivous frame one ' s * starting from the ith pixel * / unsigned int skipcount ; / * This will be the number of consecutive equal pixels in the current * frame , starting from the ith one also * / unsigned int repeatcount ; / * The cost of the three different possibilities * / int total_bulk_cost ; int total_skip_cost ; int total_repeat_cost ; int temp_cost ; int j ; uint8_t * this_line = p - > data[0] + line * p - > linesize[0] + ( width - 1 ) * s - > pixel_size ; uint8_t * prev_line = s - > previous_frame . data[0] + line * s - > previous_frame . linesize[0] + ( width - 1 ) * s - > pixel_size ; s - > length_table[width] = 0 ; skipcount = 0 ; for ( i = width - 1 ; i > = 0 ; i - - ) { if ( ! s - > frame . key_frame & & ! memcmp ( this_line , prev_line , s - > pixel_size ) ) skipcount = FFMIN ( skipcount + 1 , MAX_RLE_SKIP ) ; else skipcount = 0 ; total_skip_cost = s - > length_table[i + skipcount] + 2 ; s - > skip_table[i] = skipcount ; if ( i < width - 1 & & ! memcmp ( this_line , this_line + s - > pixel_size , s - > pixel_size ) ) repeatcount = FFMIN ( repeatcount + 1 , MAX_RLE_REPEAT ) ; else repeatcount = 1 ; total_repeat_cost = s - > length_table[i + repeatcount] + 1 + s - > pixel_size ; / * skip code is free for the first pixel , it costs one byte for repeat and bulk copy * so let ' s make it aware * / if ( i == 0 ) { total_skip_cost - - ; total_repeat_cost + + ; } if ( repeatcount > 1 & & ( skipcount == 0 || total_repeat_cost < total_skip_cost ) ) { / * repeat is the best * / s - > length_table[i] = total_repeat_cost ; s - > rlecode_table[i] = - repeatcount ; } else if ( skipcount > 0 ) { / * skip is the best choice here * / s - > length_table[i] = total_skip_cost ; s - > rlecode_table[i] = 0 ; } else { / * We cannot do neither skip nor repeat * thus we search for the best bulk copy to do * / int limit = FFMIN ( width - i , MAX_RLE_BULK ) ; temp_cost = 1 + s - > pixel_size + ! i ; total_bulk_cost = INT_MAX ; for ( j = 1 ; j < = limit ; j + + ) { if ( s - > length_table[i + j] + temp_cost < total_bulk_cost ) { / * We have found a better bulk copy . . . * / total_bulk_cost = s - > length_table[i + j] + temp_cost ; bulkcount = j ; } temp_cost + = s - > pixel_size ; } s - > length_table[i] = total_bulk_cost ; s - > rlecode_table[i] = bulkcount ; } this_line - = s - > pixel_size ; prev_line - = s - > pixel_size ; } / * Good ! Now we have the best sequence for this line , let ' s output it * / / * We do a special case for the first pixel so that we avoid testing it in * the whole loop * / i=0 ; this_line = p - > data[0] + line * p - > linesize[0] ; if ( s - > rlecode_table[0] == 0 ) { bytestream_put_byte ( buf , s - > skip_table[0] + 1 ) ; i + = s - > skip_table[0] ; } else bytestream_put_byte ( buf , 1 ) ; while ( i < width ) { rlecode = s - > rlecode_table[i] ; bytestream_put_byte ( buf , rlecode ) ; if ( rlecode == 0 ) { / * Write a skip sequence * / bytestream_put_byte ( buf , s - > skip_table[i] + 1 ) ; i + = s - > skip_table[i] ; } else if ( rlecode > 0 ) { / * bulk copy * / if ( s - > avctx - > pix_fmt == PIX_FMT_GRAY8 ) { int j ; // QT grayscale colorspace has 0=white and 255=black , we will // ignore the palette that is included in the AVFrame because // PIX_FMT_GRAY8 has defined color mapping for ( j = 0 ; j < rlecode * s - > pixel_size ; + + j ) bytestream_put_byte ( buf , * ( this_line + i * s - > pixel_size + j ) 0xff ) ; } else { bytestream_put_buffer ( buf , this_line + i * s - > pixel_size , rlecode * s - > pixel_size ) ; } i + = rlecode ; } else { / * repeat the bits * / if ( s - > avctx - > pix_fmt == PIX_FMT_GRAY8 ) { int j ; // QT grayscale colorspace has 0=white and 255=black , . . . for ( j = 0 ; j < s - > pixel_size ; + + j ) bytestream_put_byte ( buf , * ( this_line + i * s - > pixel_size + j ) 0xff ) ; } else { bytestream_put_buffer ( buf , this_line + i * s - > pixel_size , s - > pixel_size ) ; } i - = rlecode ; } } bytestream_put_byte ( buf , - 1 ) ; // end RLE line }",1
"static void rv34_idct_add_c ( uint8_t * dst , ptrdiff_t stride , DCTELEM * block ) { int temp[16] ; uint8_t * cm = ff_cropTbl + MAX_NEG_CROP ; int i ; rv34_row_transform ( temp , block ) ; memset ( block , 0 , 16 * sizeof ( DCTELEM ) ) ; for ( i = 0 ; i < 4 ; i + + ) { const int z0 = 13 * ( temp[4 * 0 + i] + temp[4 * 2 + i] ) + 0x200 ; const int z1 = 13 * ( temp[4 * 0 + i] - temp[4 * 2 + i] ) + 0x200 ; const int z2 = 7 * temp[4 * 1 + i] - 17 * temp[4 * 3 + i] ; const int z3 = 17 * temp[4 * 1 + i] + 7 * temp[4 * 3 + i] ; dst[0] = cm[ dst[0] + ( ( z0 + z3 ) > > 10 ) ] ; dst[1] = cm[ dst[1] + ( ( z1 + z2 ) > > 10 ) ] ; dst[2] = cm[ dst[2] + ( ( z1 - z2 ) > > 10 ) ] ; dst[3] = cm[ dst[3] + ( ( z0 - z3 ) > > 10 ) ] ; dst + = stride ; } }",1
"int ff_lpc_calc_coefs ( DSPContext * s , const int32_t * samples , int blocksize , int min_order , int max_order , int precision , int32_t coefs[][MAX_LPC_ORDER] , int * shift , int use_lpc , int omethod , int max_shift , int zero_shift ) { double autoc[MAX_LPC_ORDER + 1] ; double ref[MAX_LPC_ORDER] ; double lpc[MAX_LPC_ORDER][MAX_LPC_ORDER] ; int i , j , pass ; int opt_order ; assert ( max_order > = MIN_LPC_ORDER & & max_order < = MAX_LPC_ORDER & & use_lpc > 0 ) ; if ( use_lpc == 1 ) { s - > flac_compute_autocorr ( samples , blocksize , max_order , autoc ) ; compute_lpc_coefs ( autoc , max_order , & lpc[0][0] , MAX_LPC_ORDER , 0 , 1 ) ; for ( i=0 ; i < max_order ; i + + ) ref[i] = fabs ( lpc[i][i] ) ; } else { LLSModel m[2] ; double var[MAX_LPC_ORDER + 1] , weight ; for ( pass=0 ; pass < use_lpc - 1 ; pass + + ) { av_init_lls ( & m[pass & 1] , max_order ) ; weight=0 ; for ( i=max_order ; i < blocksize ; i + + ) { for ( j=0 ; j < =max_order ; j + + ) var[j]= samples[i - j] ; if ( pass ) { double eval , inv , rinv ; eval= av_evaluate_lls ( & m[ ( pass - 1 ) & 1] , var + 1 , max_order - 1 ) ; eval= ( 512 > > pass ) + fabs ( eval - var[0] ) ; inv = 1/eval ; rinv = sqrt ( inv ) ; for ( j=0 ; j < =max_order ; j + + ) var[j] * = rinv ; weight + = inv ; } else weight + + ; av_update_lls ( & m[pass & 1] , var , 1 . 0 ) ; } av_solve_lls ( & m[pass & 1] , 0 . 001 , 0 ) ; } for ( i=0 ; i < max_order ; i + + ) { for ( j=0 ; j < max_order ; j + + ) lpc[i][j]= - m[ ( pass - 1 ) & 1] . coeff[i][j] ; ref[i]= sqrt ( m[ ( pass - 1 ) & 1] . variance[i] / weight ) * ( blocksize - max_order ) / 4000 ; } for ( i=max_order - 1 ; i > 0 ; i - - ) ref[i] = ref[i - 1] - ref[i] ; } opt_order = max_order ; if ( omethod == ORDER_METHOD_EST ) { opt_order = estimate_best_order ( ref , min_order , max_order ) ; i = opt_order - 1 ; quantize_lpc_coefs ( lpc[i] , i + 1 , precision , coefs[i] , & shift[i] , max_shift , zero_shift ) ; } else { for ( i=min_order - 1 ; i < max_order ; i + + ) { quantize_lpc_coefs ( lpc[i] , i + 1 , precision , coefs[i] , & shift[i] , max_shift , zero_shift ) ; } } return opt_order ; }",1
"av_cold void ff_cavsdsp_init_x86 ( CAVSDSPContext * c , AVCodecContext * avctx ) { av_unused int cpu_flags = av_get_cpu_flags ( ) ; cavsdsp_init_mmx ( c , avctx ) ; if HAVE_AMD3DNOW_INLINE if ( INLINE_AMD3DNOW ( cpu_flags ) ) cavsdsp_init_3dnow ( c , avctx ) ; endif / * HAVE_AMD3DNOW_INLINE * / if HAVE_MMXEXT_INLINE if ( INLINE_MMXEXT ( cpu_flags ) ) { DSPFUNC ( put , 0 , 16 , mmxext ) ; DSPFUNC ( put , 1 , 8 , mmxext ) ; DSPFUNC ( avg , 0 , 16 , mmxext ) ; DSPFUNC ( avg , 1 , 8 , mmxext ) ; } endif if HAVE_MMX_EXTERNAL if ( EXTERNAL_MMXEXT ( cpu_flags ) ) { c - > avg_cavs_qpel_pixels_tab[0][0] = avg_cavs_qpel16_mc00_mmxext ; c - > avg_cavs_qpel_pixels_tab[1][0] = avg_cavs_qpel8_mc00_mmxext ; } endif if HAVE_SSE2_EXTERNAL if ( EXTERNAL_SSE2 ( cpu_flags ) ) { c - > put_cavs_qpel_pixels_tab[0][0] = put_cavs_qpel16_mc00_sse2 ; c - > avg_cavs_qpel_pixels_tab[0][0] = avg_cavs_qpel16_mc00_sse2 ; } endif }",1
"static int svq3_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , uint8_t * buf , int buf_size ) { MpegEncContext * const s = avctx - > priv_data ; H264Context * const h = avctx - > priv_data ; int m , mb_type ; unsigned char * extradata ; unsigned int size ; s - > flags = avctx - > flags ; s - > flags2 = avctx - > flags2 ; s - > unrestricted_mv = 1 ; if ( ! s - > context_initialized ) { s - > width = avctx - > width ; s - > height = avctx - > height ; h - > pred4x4[DIAG_DOWN_LEFT_PRED] = pred4x4_down_left_svq3_c ; h - > pred16x16[PLANE_PRED8x8] = pred16x16_plane_svq3_c ; h - > halfpel_flag = 1 ; h - > thirdpel_flag = 1 ; h - > unknown_svq3_flag = 0 ; h - > chroma_qp = 4 ; if ( MPV_common_init ( s ) < 0 ) return - 1 ; h - > b_stride = 4 * s - > mb_width ; alloc_tables ( h ) ; / * prowl for the SEQH marker in the extradata * / extradata = ( unsigned char * ) avctx - > extradata ; for ( m = 0 ; m < avctx - > extradata_size ; m + + ) { if ( ! memcmp ( extradata , SEQH , 4 ) ) break ; extradata + + ; } / * if a match was found , parse the extra data * / if ( extradata & & ! memcmp ( extradata , SEQH , 4 ) ) { GetBitContext gb ; size = AV_RB32 ( & extradata[4] ) ; init_get_bits ( & gb , extradata + 8 , size * 8 ) ; / * ' frame size code ' and optional ' width , height ' * / if ( get_bits ( & gb , 3 ) == 7 ) { get_bits ( & gb , 12 ) ; get_bits ( & gb , 12 ) ; } h - > halfpel_flag = get_bits1 ( & gb ) ; h - > thirdpel_flag = get_bits1 ( & gb ) ; / * unknown fields * / get_bits1 ( & gb ) ; get_bits1 ( & gb ) ; get_bits1 ( & gb ) ; get_bits1 ( & gb ) ; s - > low_delay = get_bits1 ( & gb ) ; / * unknown field * / get_bits1 ( & gb ) ; while ( get_bits1 ( & gb ) ) { get_bits ( & gb , 8 ) ; } h - > unknown_svq3_flag = get_bits1 ( & gb ) ; avctx - > has_b_frames = ! s - > low_delay ; } } / * special case for last picture * / if ( buf_size == 0 ) { if ( s - > next_picture_ptr & & ! s - > low_delay ) { * ( AVFrame * ) data = * ( AVFrame * ) & s - > next_picture ; * data_size = sizeof ( AVFrame ) ; } return 0 ; } init_get_bits ( & s - > gb , buf , 8 * buf_size ) ; s - > mb_x = s - > mb_y = 0 ; if ( svq3_decode_slice_header ( h ) ) return - 1 ; s - > pict_type = h - > slice_type ; s - > picture_number = h - > slice_num ; if ( avctx - > debug & FF_DEBUG_PICT_INFO ) { av_log ( h - > s . avctx , AV_LOG_DEBUG , %c hpel : %d , tpel : %d aqp : %d qp : %d\n , av_get_pict_type_char ( s - > pict_type ) , h - > halfpel_flag , h - > thirdpel_flag , s - > adaptive_quant , s - > qscale ) ; } / * for hurry_up==5 * / s - > current_picture . pict_type = s - > pict_type ; s - > current_picture . key_frame = ( s - > pict_type == I_TYPE ) ; / * skip b frames if we dont have reference frames * / if ( s - > last_picture_ptr == NULL & & s - > pict_type == B_TYPE ) return 0 ; / * skip b frames if we are in a hurry * / if ( avctx - > hurry_up & & s - > pict_type == B_TYPE ) return 0 ; / * skip everything if we are in a hurry > = 5 * / if ( avctx - > hurry_up > = 5 ) return 0 ; if ( ( avctx - > skip_frame > = AVDISCARD_NONREF & & s - > pict_type==B_TYPE ) || ( avctx - > skip_frame > = AVDISCARD_NONKEY & & s - > pict_type ! =I_TYPE ) || avctx - > skip_frame > = AVDISCARD_ALL ) return 0 ; if ( s - > next_p_frame_damaged ) { if ( s - > pict_type == B_TYPE ) return 0 ; else s - > next_p_frame_damaged = 0 ; } frame_start ( h ) ; if ( s - > pict_type == B_TYPE ) { h - > frame_num_offset = ( h - > slice_num - h - > prev_frame_num ) ; if ( h - > frame_num_offset < 0 ) { h - > frame_num_offset + = 256 ; } if ( h - > frame_num_offset == 0 || h - > frame_num_offset > = h - > prev_frame_num_offset ) { av_log ( h - > s . avctx , AV_LOG_ERROR , error in B - frame picture id\n ) ; return - 1 ; } } else { h - > prev_frame_num = h - > frame_num ; h - > frame_num = h - > slice_num ; h - > prev_frame_num_offset = ( h - > frame_num - h - > prev_frame_num ) ; if ( h - > prev_frame_num_offset < 0 ) { h - > prev_frame_num_offset + = 256 ; } } for ( m=0 ; m < 2 ; m + + ) { int i ; for ( i=0 ; i < 4 ; i + + ) { int j ; for ( j= - 1 ; j < 4 ; j + + ) h - > ref_cache[m][scan8[0] + 8 * i + j]= 1 ; h - > ref_cache[m][scan8[0] + 8 * i + j]= PART_NOT_AVAILABLE ; } } for ( s - > mb_y=0 ; s - > mb_y < s - > mb_height ; s - > mb_y + + ) { for ( s - > mb_x=0 ; s - > mb_x < s - > mb_width ; s - > mb_x + + ) { if ( ( get_bits_count ( & s - > gb ) + 7 ) > = s - > gb . size_in_bits & & ( ( get_bits_count ( & s - > gb ) & 7 ) == 0 || show_bits ( & s - > gb , ( - get_bits_count ( & s - > gb ) & 7 ) ) == 0 ) ) { skip_bits",1
"static int vorbis_parse_id_hdr ( vorbis_context * vc ) { GetBitContext * gb= & vc - > gb ; uint_fast8_t bl0 , bl1 ; if ( ( get_bits ( gb , 8 ) ! = ' v ' ) || ( get_bits ( gb , 8 ) ! = ' o ' ) || ( get_bits ( gb , 8 ) ! = ' r ' ) || ( get_bits ( gb , 8 ) ! = ' b ' ) || ( get_bits ( gb , 8 ) ! = ' i ' ) || ( get_bits ( gb , 8 ) ! = ' s ' ) ) { av_log ( vc - > avccontext , AV_LOG_ERROR , Vorbis id header packet corrupt ( no vorbis signature ) . \n ) ; return 1 ; } vc - > version=get_bits_long ( gb , 32 ) ; //FIXME check 0 vc - > audio_channels=get_bits ( gb , 8 ) ; //FIXME check > 0 vc - > audio_samplerate=get_bits_long ( gb , 32 ) ; //FIXME check > 0 vc - > bitrate_maximum=get_bits_long ( gb , 32 ) ; vc - > bitrate_nominal=get_bits_long ( gb , 32 ) ; vc - > bitrate_minimum=get_bits_long ( gb , 32 ) ; bl0=get_bits ( gb , 4 ) ; bl1=get_bits ( gb , 4 ) ; vc - > blocksize[0]= ( 1 < < bl0 ) ; vc - > blocksize[1]= ( 1 < < bl1 ) ; if ( bl0 > 13 || bl0 < 6 || bl1 > 13 || bl1 < 6 || bl1 < bl0 ) { av_log ( vc - > avccontext , AV_LOG_ERROR , Vorbis id header packet corrupt ( illegal blocksize ) . \n ) ; return 3 ; } // output format int16 if ( vc - > blocksize[1]/2 * vc - > audio_channels * 2 > AVCODEC_MAX_AUDIO_FRAME_SIZE ) { av_log ( vc - > avccontext , AV_LOG_ERROR , Vorbis channel count makes output packets too large . \n ) ; return 4 ; } vc - > win[0]=ff_vorbis_vwin[bl0 - 6] ; vc - > win[1]=ff_vorbis_vwin[bl1 - 6] ; if ( vc - > exp_bias ) { int i , j ; for ( j=0 ; j < 2 ; j + + ) { float * win = av_malloc ( vc - > blocksize[j]/2 * sizeof ( float ) ) ; for ( i=0 ; i < vc - > blocksize[j]/2 ; i + + ) win[i] = vc - > win[j][i] * ( 1 < < 15 ) ; vc - > win[j] = win ; } } if ( ( get_bits1 ( gb ) ) == 0 ) { av_log ( vc - > avccontext , AV_LOG_ERROR , Vorbis id header packet corrupt ( framing flag not set ) . \n ) ; return 2 ; } vc - > channel_residues= ( float * ) av_malloc ( ( vc - > blocksize[1]/2 ) * vc - > audio_channels * sizeof ( float ) ) ; vc - > channel_floors= ( float * ) av_malloc ( ( vc - > blocksize[1]/2 ) * vc - > audio_channels * sizeof ( float ) ) ; vc - > saved= ( float * ) av_malloc ( ( vc - > blocksize[1]/2 ) * vc - > audio_channels * sizeof ( float ) ) ; vc - > ret= ( float * ) av_malloc ( ( vc - > blocksize[1]/2 ) * vc - > audio_channels * sizeof ( float ) ) ; vc - > buf= ( float * ) av_malloc ( vc - > blocksize[1] * sizeof ( float ) ) ; vc - > buf_tmp= ( float * ) av_malloc ( vc - > blocksize[1] * sizeof ( float ) ) ; vc - > saved_start=0 ; ff_mdct_init ( & vc - > mdct[0] , bl0 , 1 ) ; ff_mdct_init ( & vc - > mdct[1] , bl1 , 1 ) ; AV_DEBUG ( vorbis version %d \n audio_channels %d \n audio_samplerate %d \n bitrate_max %d \n bitrate_nom %d \n bitrate_min %d \n blk_0 %d blk_1 %d \n , vc - > version , vc - > audio_channels , vc - > audio_samplerate , vc - > bitrate_maximum , vc - > bitrate_nominal , vc - > bitrate_minimum , vc - > blocksize[0] , vc - > blocksize[1] ) ; / * BLK=vc - > blocksize[0] ; for ( i=0 ; i < BLK/2 ; + + i ) { vc - > win[0][i]=sin ( 0 . 5 * 3 . 14159265358 * ( sin ( ( ( float ) i + 0 . 5 ) / ( float ) BLK * 3 . 14159265358 ) ) * ( sin ( ( ( float ) i + 0 . 5 ) / ( float ) BLK * 3 . 14159265358 ) ) ) ; } * / return 0 ; }",0
"static void imdct_and_windowing ( AACContext * ac , SingleChannelElement * sce , float bias ) { IndividualChannelStream * ics = & sce - > ics ; float * in = sce - > coeffs ; float * out = sce - > ret ; float * saved = sce - > saved ; const float * swindow = ics - > use_kb_window[0] ? ff_aac_kbd_short_128 : ff_sine_128 ; const float * lwindow_prev = ics - > use_kb_window[1] ? ff_aac_kbd_long_1024 : ff_sine_1024 ; const float * swindow_prev = ics - > use_kb_window[1] ? ff_aac_kbd_short_128 : ff_sine_128 ; float * buf = ac - > buf_mdct ; float * temp = ac - > temp ; int i ; // imdct if ( ics - > window_sequence[0] == EIGHT_SHORT_SEQUENCE ) { if ( ics - > window_sequence[1] == ONLY_LONG_SEQUENCE || ics - > window_sequence[1] == LONG_STOP_SEQUENCE ) av_log ( ac - > avctx , AV_LOG_WARNING , Transition from an ONLY_LONG or LONG_STOP to an EIGHT_SHORT sequence detected . If you heard an audible artifact , please submit the sample to the FFmpeg developers . \n ) ; for ( i = 0 ; i < 1024 ; i + = 128 ) ff_imdct_half ( & ac - > mdct_small , buf + i , in + i ) ; } else ff_imdct_half ( & ac - > mdct , buf , in ) ; / * window overlapping * NOTE : To simplify the overlapping code , all ' meaningless ' short to long * and long to short transitions are considered to be short to short * transitions . This leaves just two cases ( long to long and short to short ) * with a little special sauce for EIGHT_SHORT_SEQUENCE . * / if ( ( ics - > window_sequence[1] == ONLY_LONG_SEQUENCE || ics - > window_sequence[1] == LONG_STOP_SEQUENCE ) & & ( ics - > window_sequence[0] == ONLY_LONG_SEQUENCE || ics - > window_sequence[0] == LONG_START_SEQUENCE ) ) { ac - > dsp . vector_fmul_window ( out , saved , buf , lwindow_prev , bias , 512 ) ; } else { for ( i = 0 ; i < 448 ; i + + ) out[i] = saved[i] + bias ; if ( ics - > window_sequence[0] == EIGHT_SHORT_SEQUENCE ) { ac - > dsp . vector_fmul_window ( out + 448 + 0 * 128 , saved + 448 , buf + 0 * 128 , swindow_prev , bias , 64 ) ; ac - > dsp . vector_fmul_window ( out + 448 + 1 * 128 , buf + 0 * 128 + 64 , buf + 1 * 128 , swindow , bias , 64 ) ; ac - > dsp . vector_fmul_window ( out + 448 + 2 * 128 , buf + 1 * 128 + 64 , buf + 2 * 128 , swindow , bias , 64 ) ; ac - > dsp . vector_fmul_window ( out + 448 + 3 * 128 , buf + 2 * 128 + 64 , buf + 3 * 128 , swindow , bias , 64 ) ; ac - > dsp . vector_fmul_window ( temp , buf + 3 * 128 + 64 , buf + 4 * 128 , swindow , bias , 64 ) ; memcpy ( out + 448 + 4 * 128 , temp , 64 * sizeof ( float ) ) ; } else { ac - > dsp . vector_fmul_window ( out + 448 , saved + 448 , buf , swindow_prev , bias , 64 ) ; for ( i = 576 ; i < 1024 ; i + + ) out[i] = buf[i - 512] + bias ; } } // buffer update if ( ics - > window_sequence[0] == EIGHT_SHORT_SEQUENCE ) { for ( i = 0 ; i < 64 ; i + + ) saved[i] = temp[64 + i] - bias ; ac - > dsp . vector_fmul_window ( saved + 64 , buf + 4 * 128 + 64 , buf + 5 * 128 , swindow , 0 , 64 ) ; ac - > dsp . vector_fmul_window ( saved + 192 , buf + 5 * 128 + 64 , buf + 6 * 128 , swindow , 0 , 64 ) ; ac - > dsp . vector_fmul_window ( saved + 320 , buf + 6 * 128 + 64 , buf + 7 * 128 , swindow , 0 , 64 ) ; memcpy ( saved + 448 , buf + 7 * 128 + 64 , 64 * sizeof ( float ) ) ; } else if ( ics - > window_sequence[0] == LONG_START_SEQUENCE ) { memcpy ( saved , buf + 512 , 448 * sizeof ( float ) ) ; memcpy ( saved + 448 , buf + 7 * 128 + 64 , 64 * sizeof ( float ) ) ; } else { // LONG_STOP or ONLY_LONG memcpy ( saved , buf + 512 , 512 * sizeof ( float ) ) ; } }",1
"void ff_dsputil_init_alpha ( DSPContext * c , AVCodecContext * avctx ) { const int high_bit_depth = avctx - > bits_per_raw_sample > 8 ; if ( ! high_bit_depth ) { c - > put_pixels_tab[0][0] = put_pixels16_axp_asm ; c - > put_pixels_tab[0][1] = put_pixels16_x2_axp ; c - > put_pixels_tab[0][2] = put_pixels16_y2_axp ; c - > put_pixels_tab[0][3] = put_pixels16_xy2_axp ; c - > put_no_rnd_pixels_tab[0][0] = put_pixels16_axp_asm ; c - > put_no_rnd_pixels_tab[0][1] = put_no_rnd_pixels16_x2_axp ; c - > put_no_rnd_pixels_tab[0][2] = put_no_rnd_pixels16_y2_axp ; c - > put_no_rnd_pixels_tab[0][3] = put_no_rnd_pixels16_xy2_axp ; c - > avg_pixels_tab[0][0] = avg_pixels16_axp ; c - > avg_pixels_tab[0][1] = avg_pixels16_x2_axp ; c - > avg_pixels_tab[0][2] = avg_pixels16_y2_axp ; c - > avg_pixels_tab[0][3] = avg_pixels16_xy2_axp ; c - > avg_no_rnd_pixels_tab[0][0] = avg_no_rnd_pixels16_axp ; c - > avg_no_rnd_pixels_tab[0][1] = avg_no_rnd_pixels16_x2_axp ; c - > avg_no_rnd_pixels_tab[0][2] = avg_no_rnd_pixels16_y2_axp ; c - > avg_no_rnd_pixels_tab[0][3] = avg_no_rnd_pixels16_xy2_axp ; c - > put_pixels_tab[1][0] = put_pixels_axp_asm ; c - > put_pixels_tab[1][1] = put_pixels_x2_axp ; c - > put_pixels_tab[1][2] = put_pixels_y2_axp ; c - > put_pixels_tab[1][3] = put_pixels_xy2_axp ; c - > put_no_rnd_pixels_tab[1][0] = put_pixels_axp_asm ; c - > put_no_rnd_pixels_tab[1][1] = put_no_rnd_pixels_x2_axp ; c - > put_no_rnd_pixels_tab[1][2] = put_no_rnd_pixels_y2_axp ; c - > put_no_rnd_pixels_tab[1][3] = put_no_rnd_pixels_xy2_axp ; c - > avg_pixels_tab[1][0] = avg_pixels_axp ; c - > avg_pixels_tab[1][1] = avg_pixels_x2_axp ; c - > avg_pixels_tab[1][2] = avg_pixels_y2_axp ; c - > avg_pixels_tab[1][3] = avg_pixels_xy2_axp ; c - > avg_no_rnd_pixels_tab[1][0] = avg_no_rnd_pixels_axp ; c - > avg_no_rnd_pixels_tab[1][1] = avg_no_rnd_pixels_x2_axp ; c - > avg_no_rnd_pixels_tab[1][2] = avg_no_rnd_pixels_y2_axp ; c - > avg_no_rnd_pixels_tab[1][3] = avg_no_rnd_pixels_xy2_axp ; c - > clear_blocks = clear_blocks_axp ; } / * amask clears all bits that correspond to present features . * / if ( amask ( AMASK_MVI ) == 0 ) { c - > put_pixels_clamped = put_pixels_clamped_mvi_asm ; c - > add_pixels_clamped = add_pixels_clamped_mvi_asm ; if ( ! high_bit_depth ) c - > get_pixels = get_pixels_mvi ; c - > diff_pixels = diff_pixels_mvi ; c - > sad[0] = pix_abs16x16_mvi_asm ; c - > sad[1] = pix_abs8x8_mvi ; c - > pix_abs[0][0] = pix_abs16x16_mvi_asm ; c - > pix_abs[1][0] = pix_abs8x8_mvi ; c - > pix_abs[0][1] = pix_abs16x16_x2_mvi ; c - > pix_abs[0][2] = pix_abs16x16_y2_mvi ; c - > pix_abs[0][3] = pix_abs16x16_xy2_mvi ; } put_pixels_clamped_axp_p = c - > put_pixels_clamped ; add_pixels_clamped_axp_p = c - > add_pixels_clamped ; if ( avctx - > bits_per_raw_sample < = 8 & & ( avctx - > idct_algo == FF_IDCT_AUTO || avctx - > idct_algo == FF_IDCT_SIMPLEALPHA ) ) { c - > idct_put = ff_simple_idct_put_axp ; c - > idct_add = ff_simple_idct_add_axp ; c - > idct = ff_simple_idct_axp ; } }",0
"static int add_string_metadata ( int count , const char * name , TiffContext * s ) { char * value ; if ( bytestream2_get_bytes_left ( & s - > gb ) < count ) return AVERROR_INVALIDDATA ; value = av_malloc ( count + 1 ) ; if ( ! value ) return AVERROR ( ENOMEM ) ; bytestream2_get_bufferu ( & s - > gb , value , count ) ; value[count] = 0 ; av_dict_set ( & s - > picture . metadata , name , value , AV_DICT_DONT_STRDUP_VAL ) ; return 0 ; }",0
"static int idcin_read_header ( AVFormatContext * s ) { AVIOContext * pb = s - > pb ; IdcinDemuxContext * idcin = s - > priv_data ; AVStream * st ; unsigned int width , height ; unsigned int sample_rate , bytes_per_sample , channels ; int ret ; / * get the 5 header parameters * / width = avio_rl32 ( pb ) ; height = avio_rl32 ( pb ) ; sample_rate = avio_rl32 ( pb ) ; bytes_per_sample = avio_rl32 ( pb ) ; channels = avio_rl32 ( pb ) ; if ( s - > pb - > eof_reached ) { av_log ( s , AV_LOG_ERROR , incomplete header\n ) ; return s - > pb - > error ? s - > pb - > error : AVERROR_EOF ; } if ( av_image_check_size ( width , height , 0 , s ) < 0 ) return AVERROR_INVALIDDATA ; if ( sample_rate > 0 ) { if ( sample_rate < 14 || sample_rate > INT_MAX ) { av_log ( s , AV_LOG_ERROR , invalid sample rate : %u\n , sample_rate ) ; return AVERROR_INVALIDDATA ; } if ( bytes_per_sample < 1 || bytes_per_sample > 2 ) { av_log ( s , AV_LOG_ERROR , invalid bytes per sample : %u\n , bytes_per_sample ) ; return AVERROR_INVALIDDATA ; } if ( channels < 1 || channels > 2 ) { av_log ( s , AV_LOG_ERROR , invalid channels : %u\n , channels ) ; return AVERROR_INVALIDDATA ; } idcin - > audio_present = 1 ; } else { / * if sample rate is 0 , assume no audio * / idcin - > audio_present = 0 ; } st = avformat_new_stream ( s , NULL ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; avpriv_set_pts_info ( st , 33 , 1 , IDCIN_FPS ) ; st - > start_time = 0 ; idcin - > video_stream_index = st - > index ; st - > codec - > codec_type = AVMEDIA_TYPE_VIDEO ; st - > codec - > codec_id = AV_CODEC_ID_IDCIN ; st - > codec - > codec_tag = 0 ; / * no fourcc * / st - > codec - > width = width ; st - > codec - > height = height ; / * load up the Huffman tables into extradata * / st - > codec - > extradata_size = HUFFMAN_TABLE_SIZE ; st - > codec - > extradata = av_malloc ( HUFFMAN_TABLE_SIZE ) ; ret = avio_read ( pb , st - > codec - > extradata , HUFFMAN_TABLE_SIZE ) ; if ( ret < 0 ) { return ret ; } else if ( ret ! = HUFFMAN_TABLE_SIZE ) { av_log ( s , AV_LOG_ERROR , incomplete header\n ) ; return AVERROR ( EIO ) ; } if ( idcin - > audio_present ) { idcin - > audio_present = 1 ; st = avformat_new_stream ( s , NULL ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; avpriv_set_pts_info ( st , 63 , 1 , sample_rate ) ; st - > start_time = 0 ; idcin - > audio_stream_index = st - > index ; st - > codec - > codec_type = AVMEDIA_TYPE_AUDIO ; st - > codec - > codec_tag = 1 ; st - > codec - > channels = channels ; st - > codec - > channel_layout = channels > 1 ? AV_CH_LAYOUT_STEREO : AV_CH_LAYOUT_MONO ; st - > codec - > sample_rate = sample_rate ; st - > codec - > bits_per_coded_sample = bytes_per_sample * 8 ; st - > codec - > bit_rate = sample_rate * bytes_per_sample * 8 * channels ; st - > codec - > block_align = idcin - > block_align = bytes_per_sample * channels ; if ( bytes_per_sample == 1 ) st - > codec - > codec_id = AV_CODEC_ID_PCM_U8 ; else st - > codec - > codec_id = AV_CODEC_ID_PCM_S16LE ; if ( sample_rate % 14 ! = 0 ) { idcin - > audio_chunk_size1 = ( sample_rate / 14 ) * bytes_per_sample * channels ; idcin - > audio_chunk_size2 = ( sample_rate / 14 + 1 ) * bytes_per_sample * channels ; } else { idcin - > audio_chunk_size1 = idcin - > audio_chunk_size2 = ( sample_rate / 14 ) * bytes_per_sample * channels ; } idcin - > current_audio_chunk = 0 ; } idcin - > next_chunk_is_video = 1 ; idcin - > first_pkt_pos = avio_tell ( s - > pb ) ; return 0 ; }",0
"static int decode_profile_tier_level ( GetBitContext * gb , AVCodecContext * avctx , PTLCommon * ptl ) { int i ; if ( get_bits_left ( gb ) < 2 + 1 + 5 + 32 + 4 + 16 + 16 + 12 ) return - 1 ; ptl - > profile_space = get_bits ( gb , 2 ) ; ptl - > tier_flag = get_bits1 ( gb ) ; ptl - > profile_idc = get_bits ( gb , 5 ) ; if ( ptl - > profile_idc == FF_PROFILE_HEVC_MAIN ) av_log ( avctx , AV_LOG_DEBUG , Main profile bitstream\n ) ; else if ( ptl - > profile_idc == FF_PROFILE_HEVC_MAIN_10 ) av_log ( avctx , AV_LOG_DEBUG , Main 10 profile bitstream\n ) ; else if ( ptl - > profile_idc == FF_PROFILE_HEVC_MAIN_STILL_PICTURE ) av_log ( avctx , AV_LOG_DEBUG , Main Still Picture profile bitstream\n ) ; else if ( ptl - > profile_idc == FF_PROFILE_HEVC_REXT ) av_log ( avctx , AV_LOG_DEBUG , Range Extension profile bitstream\n ) ; else av_log ( avctx , AV_LOG_WARNING , Unknown HEVC profile : %d\n , ptl - > profile_idc ) ; for ( i = 0 ; i < 32 ; i + + ) ptl - > profile_compatibility_flag[i] = get_bits1 ( gb ) ; ptl - > progressive_source_flag = get_bits1 ( gb ) ; ptl - > interlaced_source_flag = get_bits1 ( gb ) ; ptl - > non_packed_constraint_flag = get_bits1 ( gb ) ; ptl - > frame_only_constraint_flag = get_bits1 ( gb ) ; skip_bits ( gb , 16 ) ; // XXX_reserved_zero_44bits[0 . . 15] skip_bits ( gb , 16 ) ; // XXX_reserved_zero_44bits[16 . . 31] skip_bits ( gb , 12 ) ; // XXX_reserved_zero_44bits[32 . . 43] return 0 ; }",0
"static int filter_frame ( AVFilterLink * link , AVFrame * frame ) { AVFilterContext * ctx = link - > dst ; AudioFIRContext * s = ctx - > priv ; AVFilterLink * outlink = ctx - > outputs[0] ; int ret = 0 ; av_audio_fifo_write ( s - > fifo[0] , ( void * * ) frame - > extended_data , frame - > nb_samples ) ; if ( s - > pts == AV_NOPTS_VALUE ) s - > pts = frame - > pts ; av_frame_free ( & frame ) ; if ( ! s - > have_coeffs & & s - > eof_coeffs ) { ret = convert_coeffs ( ctx ) ; if ( ret < 0 ) return ret ; } if ( s - > have_coeffs ) { while ( av_audio_fifo_size ( s - > fifo[0] ) > = s - > part_size ) { ret = fir_frame ( s , outlink ) ; if ( ret < 0 ) break ; } } return ret ; }",0
"int ff_dca_lbr_parse ( DCALbrDecoder * s , uint8_t * data , DCAExssAsset * asset ) { struct { LBRChunk lfe ; LBRChunk tonal ; LBRChunk tonal_grp[5] ; LBRChunk grid1[DCA_LBR_CHANNELS / 2] ; LBRChunk hr_grid[DCA_LBR_CHANNELS / 2] ; LBRChunk ts1[DCA_LBR_CHANNELS / 2] ; LBRChunk ts2[DCA_LBR_CHANNELS / 2] ; } chunk = { } ; GetByteContext gb ; int i , ch , sb , sf , ret , group , chunk_id , chunk_len ; bytestream2_init ( & gb , data + asset - > lbr_offset , asset - > lbr_size ) ; // LBR sync word if ( bytestream2_get_be32 ( & gb ) ! = DCA_SYNCWORD_LBR ) { av_log ( s - > avctx , AV_LOG_ERROR , Invalid LBR sync word\n ) ; return AVERROR_INVALIDDATA ; } // LBR header type switch ( bytestream2_get_byte ( & gb ) ) { case LBR_HEADER_SYNC_ONLY : if ( ! s - > sample_rate ) { av_log ( s - > avctx , AV_LOG_ERROR , LBR decoder not initialized\n ) ; return AVERROR_INVALIDDATA ; } break ; case LBR_HEADER_DECODER_INIT : if ( ( ret = parse_decoder_init ( s , & gb ) ) < 0 ) { s - > sample_rate = 0 ; return ret ; } break ; default : av_log ( s - > avctx , AV_LOG_ERROR , Invalid LBR header type\n ) ; return AVERROR_INVALIDDATA ; } // LBR frame chunk header chunk_id = bytestream2_get_byte ( & gb ) ; chunk_len = ( chunk_id & 0x80 ) ? bytestream2_get_be16 ( & gb ) : bytestream2_get_byte ( & gb ) ; if ( chunk_len > bytestream2_get_bytes_left ( & gb ) ) { chunk_len = bytestream2_get_bytes_left ( & gb ) ; av_log ( s - > avctx , AV_LOG_WARNING , LBR frame chunk was truncated\n ) ; if ( s - > avctx - > err_recognition & AV_EF_EXPLODE ) return AVERROR_INVALIDDATA ; } bytestream2_init ( & gb , gb . buffer , chunk_len ) ; switch ( chunk_id & 0x7f ) { case LBR_CHUNK_FRAME : if ( s - > avctx - > err_recognition & ( AV_EF_CRCCHECK | AV_EF_CAREFUL ) ) { int checksum = bytestream2_get_be16 ( & gb ) ; uint16_t res = chunk_id ; res + = ( chunk_len > > 8 ) & 0xff ; res + = chunk_len & 0xff ; for ( i = 0 ; i < chunk_len - 2 ; i + + ) res + = gb . buffer[i] ; if ( checksum ! = res ) { av_log ( s - > avctx , AV_LOG_WARNING , Invalid LBR checksum\n ) ; if ( s - > avctx - > err_recognition & AV_EF_EXPLODE ) return AVERROR_INVALIDDATA ; } } else { bytestream2_skip ( & gb , 2 ) ; } break ; case LBR_CHUNK_FRAME_NO_CSUM : break ; default : av_log ( s - > avctx , AV_LOG_ERROR , Invalid LBR frame chunk ID\n ) ; return AVERROR_INVALIDDATA ; } // Clear current frame memset ( s - > quant_levels , 0 , sizeof ( s - > quant_levels ) ) ; memset ( s - > sb_indices , 0xff , sizeof ( s - > sb_indices ) ) ; memset ( s - > sec_ch_sbms , 0 , sizeof ( s - > sec_ch_sbms ) ) ; memset ( s - > sec_ch_lrms , 0 , sizeof ( s - > sec_ch_lrms ) ) ; memset ( s - > ch_pres , 0 , sizeof ( s - > ch_pres ) ) ; memset ( s - > grid_1_scf , 0 , sizeof ( s - > grid_1_scf ) ) ; memset ( s - > grid_2_scf , 0 , sizeof ( s - > grid_2_scf ) ) ; memset ( s - > grid_3_avg , 0 , sizeof ( s - > grid_3_avg ) ) ; memset ( s - > grid_3_scf , 0 , sizeof ( s - > grid_3_scf ) ) ; memset ( s - > grid_3_pres , 0 , sizeof ( s - > grid_3_pres ) ) ; memset ( s - > tonal_scf , 0 , sizeof ( s - > tonal_scf ) ) ; memset ( s - > lfe_data , 0 , sizeof ( s - > lfe_data ) ) ; s - > part_stereo_pres = 0 ; s - > framenum = ( s - > framenum + 1 ) & 31 ; for ( ch = 0 ; ch < s - > nchannels ; ch + + ) { for ( sb = 0 ; sb < s - > nsubbands / 4 ; sb + + ) { s - > part_stereo[ch][sb][0] = s - > part_stereo[ch][sb][4] ; s - > part_stereo[ch][sb][4] = 16 ; } } memset ( s - > lpc_coeff[s - > framenum & 1] , 0 , sizeof ( s - > lpc_coeff[0] ) ) ; for ( group = 0 ; group < 5 ; group + + ) { for ( sf = 0 ; sf < 1 < < group ; sf + + ) { int sf_idx = ( ( s - > framenum < < group ) + sf ) & 31 ; s - > tonal_bounds[group][sf_idx][0] = s - > tonal_bounds[group][sf_idx][1] = s - > ntones ; } } // Parse chunk headers while ( bytestream2_get_bytes_left ( & gb ) > 0 ) { chunk_id = bytestream2_get_byte ( & gb ) ; chunk_len = ( chunk_id & 0x80 ) ? bytestream2_get_be16 ( & gb ) : bytestream2_get_byte ( & gb ) ; chunk_id & = 0x7f ; if ( chunk_len > bytestream2_get_bytes_left ( & gb ) ) { chunk_len = bytestream2_get_bytes_left ( & gb ) ; av_log ( s - > avctx , AV_LOG_WARNING , LBR chunk % x was truncated\n , chunk_id ) ; if ( s - > avctx - > err_recognition & AV_EF_EXPLODE ) return AVERROR_INVALIDDATA ; } switch ( chunk_id ) { case LBR_CHUNK_LFE : chunk . lfe . len = chunk_len ; chunk . lfe . data = gb . buffer ; break ; case LBR_CHUNK_SCF : case LBR_CHUNK_TONAL : case LBR_CHUNK_TONAL_SCF : chunk . tonal . id = chunk_id ; chunk . tonal . len = chunk_len ; chunk . tonal . data = gb . buffer ; break ; case LBR_CHUNK_TONAL_GRP_1 : case LBR_CHUNK_TONAL_GRP_2 : case LBR_CHUNK_TONAL_GRP_3 : case LBR_CHUNK_TONAL_GRP_4 : case LBR_CHUNK_TONAL_GRP_5 : i = LBR_CHUNK_TONAL_GRP_5 - chunk_id ; chunk . tonal_grp[i] . id = i ; chunk . tonal_grp[i] . len = chunk_len ; chunk . tonal_grp[i] . data = gb . buffer ; break ; case LBR_CHUNK_TONAL_SCF_GRP_1 : case LBR_CHUNK_TONAL_SCF_GRP_2 : case LBR_CHUNK_TONAL_SCF_GRP_3 : case LBR_CHUNK_TONAL_SCF_GRP_4 : case LBR_CHUNK_TONAL_SCF_GRP_5 : i = LBR_CHUNK_TONAL_SCF_GRP_5 - chunk_id ; chunk . tonal_grp[i] . id = i ; chunk . tonal_grp[i] . len = chunk_len ; chunk . tonal_grp[i] . data = gb . buffer ; break ; case LBR_CHUNK_RES_GRID_LR : case LBR_CHUNK_RES_GRID_LR + 1 : case LBR_CHUNK_RES_GRID_LR + 2 : i = chunk_id - LBR_CHUNK_RES_GRID_LR ; chunk . grid1[i] . len = chunk_len ; chunk . grid1[i] . data = gb . buffer ; break ; case LBR_CHUNK_RES_GRID_HR : case LBR_CHUNK_RES_GRID_HR + 1 : case LBR_CHUNK_RES_GRID_HR + 2 : i = chunk_id - LBR_CHUNK_RES_GRID_HR ; chunk",0
"static av_cold int wmv2_decode_init ( AVCodecContext * avctx ) { Wmv2Context * const w = avctx - > priv_data ; int ret ; if ( ( ret = ff_msmpeg4_decode_init ( avctx ) ) < 0 ) return ret ; ff_wmv2_common_init ( w ) ; return ff_intrax8_common_init ( & w - > x8 , & w - > s . idsp , & w - > s ) ; }",0
static char * check_nan_suffix ( char * s ) { char * start = s ; if ( * s + + ! = ' ( ' ) return start ; while ( ( * s > = ' a ' & & * s < = ' z ' ) || ( * s > = ' A ' & & * s < = ' Z ' ) || ( * s > = ' 0 ' & & * s < = ' 9 ' ) || * s == ' _ ' ) s + + ; return * s == ' ) ' ? s + 1 : start ; },0
"static int amovie_get_samples ( AVFilterLink * outlink ) { MovieContext * movie = outlink - > src - > priv ; AVPacket pkt ; int ret , got_frame = 0 ; if ( ! movie - > pkt . size & & movie - > is_done == 1 ) return AVERROR_EOF ; / * check for another frame , in case the previous one was completely consumed * / if ( ! movie - > pkt . size ) { while ( ( ret = av_read_frame ( movie - > format_ctx , & pkt ) ) > = 0 ) { // Is this a packet from the selected stream ? if ( pkt . stream_index ! = movie - > stream_index ) { av_free_packet ( & pkt ) ; continue ; } else { movie - > pkt0 = movie - > pkt = pkt ; break ; } } if ( ret == AVERROR_EOF ) { movie - > is_done = 1 ; return ret ; } } / * decode and update the movie pkt * / avcodec_get_frame_defaults ( movie - > frame ) ; ret = avcodec_decode_audio4 ( movie - > codec_ctx , movie - > frame , & got_frame , & movie - > pkt ) ; if ( ret < 0 ) { movie - > pkt . size = 0 ; return ret ; } movie - > pkt . data + = ret ; movie - > pkt . size - = ret ; / * wrap the decoded data in a samplesref * / if ( got_frame ) { int nb_samples = movie - > frame - > nb_samples ; int data_size = av_samples_get_buffer_size ( NULL , movie - > codec_ctx - > channels , nb_samples , movie - > codec_ctx - > sample_fmt , 1 ) ; if ( data_size < 0 ) return data_size ; movie - > samplesref = ff_get_audio_buffer ( outlink , AV_PERM_WRITE , nb_samples ) ; memcpy ( movie - > samplesref - > data[0] , movie - > frame - > data[0] , data_size ) ; movie - > samplesref - > pts = movie - > pkt . pts ; movie - > samplesref - > pos = movie - > pkt . pos ; movie - > samplesref - > audio - > sample_rate = movie - > codec_ctx - > sample_rate ; } // We got it . Free the packet since we are returning if ( movie - > pkt . size < = 0 ) av_free_packet ( & movie - > pkt0 ) ; return 0 ; }",0
"static int h264_init_context ( AVCodecContext * avctx , H264Context * h ) { int i ; h - > avctx = avctx ; h - > picture_structure = PICT_FRAME ; h - > slice_context_count = 1 ; h - > workaround_bugs = avctx - > workaround_bugs ; h - > flags = avctx - > flags ; h - > prev_poc_msb = 1 < < 16 ; h - > x264_build = - 1 ; h - > recovery_frame = - 1 ; h - > frame_recovered = 0 ; h - > next_outputed_poc = INT_MIN ; for ( i = 0 ; i < MAX_DELAYED_PIC_COUNT ; i + + ) h - > last_pocs[i] = INT_MIN ; ff_h264_reset_sei ( h ) ; avctx - > chroma_sample_location = AVCHROMA_LOC_LEFT ; h - > nb_slice_ctx = ( avctx - > active_thread_type & FF_THREAD_SLICE ) ? H264_MAX_THREADS : 1 ; h - > slice_ctx = av_mallocz_array ( h - > nb_slice_ctx , sizeof ( * h - > slice_ctx ) ) ; if ( ! h - > slice_ctx ) { h - > nb_slice_ctx = 0 ; return AVERROR ( ENOMEM ) ; } for ( i = 0 ; i < H264_MAX_PICTURE_COUNT ; i + + ) { h - > DPB[i] . f = av_frame_alloc ( ) ; if ( ! h - > DPB[i] . f ) return AVERROR ( ENOMEM ) ; } h - > cur_pic . f = av_frame_alloc ( ) ; if ( ! h - > cur_pic . f ) return AVERROR ( ENOMEM ) ; for ( i = 0 ; i < h - > nb_slice_ctx ; i + + ) h - > slice_ctx[i] . h264 = h ; return 0 ; }",0
"static int dnxhd_encode_init ( AVCodecContext * avctx ) { DNXHDEncContext * ctx = avctx - > priv_data ; int i , index , bit_depth ; switch ( avctx - > pix_fmt ) { case AV_PIX_FMT_YUV422P : bit_depth = 8 ; break ; case AV_PIX_FMT_YUV422P10 : bit_depth = 10 ; break ; default : av_log ( avctx , AV_LOG_ERROR , pixel format is incompatible with DNxHD\n ) ; return - 1 ; } ctx - > cid = ff_dnxhd_find_cid ( avctx , bit_depth ) ; if ( ! ctx - > cid ) { av_log ( avctx , AV_LOG_ERROR , video parameters incompatible with DNxHD\n ) ; return - 1 ; } av_log ( avctx , AV_LOG_DEBUG , cid %d\n , ctx - > cid ) ; index = ff_dnxhd_get_cid_table ( ctx - > cid ) ; av_assert0 ( index > = 0 ) ; ctx - > cid_table = & ff_dnxhd_cid_table[index] ; ctx - > m . avctx = avctx ; ctx - > m . mb_intra = 1 ; ctx - > m . h263_aic = 1 ; avctx - > bits_per_raw_sample = ctx - > cid_table - > bit_depth ; ff_dct_common_init ( & ctx - > m ) ; ff_dct_encode_init ( & ctx - > m ) ; if ( ! ctx - > m . dct_quantize ) ctx - > m . dct_quantize = ff_dct_quantize_c ; if ( ctx - > cid_table - > bit_depth == 10 ) { ctx - > m . dct_quantize = dnxhd_10bit_dct_quantize ; ctx - > get_pixels_8x4_sym = dnxhd_10bit_get_pixels_8x4_sym ; ctx - > block_width_l2 = 4 ; } else { ctx - > get_pixels_8x4_sym = dnxhd_8bit_get_pixels_8x4_sym ; ctx - > block_width_l2 = 3 ; } if ( ARCH_X86 ) ff_dnxhdenc_init_x86 ( ctx ) ; ctx - > m . mb_height = ( avctx - > height + 15 ) / 16 ; ctx - > m . mb_width = ( avctx - > width + 15 ) / 16 ; if ( avctx - > flags & CODEC_FLAG_INTERLACED_DCT ) { ctx - > interlaced = 1 ; ctx - > m . mb_height /= 2 ; } ctx - > m . mb_num = ctx - > m . mb_height * ctx - > m . mb_width ; if ( avctx - > intra_quant_bias ! = FF_DEFAULT_QUANT_BIAS ) ctx - > m . intra_quant_bias = avctx - > intra_quant_bias ; if ( dnxhd_init_qmat ( ctx , ctx - > m . intra_quant_bias , 0 ) < 0 ) // XXX tune lbias/cbias return - 1 ; // Avid Nitris hardware decoder requires a minimum amount of padding in the coding unit payload if ( ctx - > nitris_compat ) ctx - > min_padding = 1600 ; if ( dnxhd_init_vlc ( ctx ) < 0 ) return - 1 ; if ( dnxhd_init_rc ( ctx ) < 0 ) return - 1 ; FF_ALLOCZ_OR_GOTO ( ctx - > m . avctx , ctx - > slice_size , ctx - > m . mb_height * sizeof ( uint32_t ) , fail ) ; FF_ALLOCZ_OR_GOTO ( ctx - > m . avctx , ctx - > slice_offs , ctx - > m . mb_height * sizeof ( uint32_t ) , fail ) ; FF_ALLOCZ_OR_GOTO ( ctx - > m . avctx , ctx - > mb_bits , ctx - > m . mb_num * sizeof ( uint16_t ) , fail ) ; FF_ALLOCZ_OR_GOTO ( ctx - > m . avctx , ctx - > mb_qscale , ctx - > m . mb_num * sizeof ( uint8_t ) , fail ) ; ctx - > frame . key_frame = 1 ; ctx - > frame . pict_type = AV_PICTURE_TYPE_I ; ctx - > m . avctx - > coded_frame = & ctx - > frame ; if ( avctx - > thread_count > MAX_THREADS ) { av_log ( avctx , AV_LOG_ERROR , too many threads\n ) ; return - 1 ; } ctx - > thread[0] = ctx ; for ( i = 1 ; i < avctx - > thread_count ; i + + ) { ctx - > thread[i] = av_malloc ( sizeof ( DNXHDEncContext ) ) ; memcpy ( ctx - > thread[i] , ctx , sizeof ( DNXHDEncContext ) ) ; } return 0 ; fail : //for FF_ALLOCZ_OR_GOTO return - 1 ; }",0
"static int mpegaudio_parse ( AVCodecParserContext * s1 , AVCodecContext * avctx , const uint8_t * * poutbuf , int * poutbuf_size , const uint8_t * buf , int buf_size ) { MpegAudioParseContext * s = s1 - > priv_data ; int len , ret , sr ; uint32_t header ; const uint8_t * buf_ptr ; * poutbuf = NULL ; * poutbuf_size = 0 ; buf_ptr = buf ; while ( buf_size > 0 ) { len = s - > inbuf_ptr - s - > inbuf ; if ( s - > frame_size == 0 ) { / * special case for next header for first frame in free format case ( XXX : find a simpler method ) * / if ( s - > free_format_next_header ! = 0 ) { AV_WB32 ( s - > inbuf , s - > free_format_next_header ) ; s - > inbuf_ptr = s - > inbuf + 4 ; s - > free_format_next_header = 0 ; goto got_header ; } / * no header seen : find one . We need at least MPA_HEADER_SIZE bytes to parse it * / len = FFMIN ( MPA_HEADER_SIZE - len , buf_size ) ; if ( len > 0 ) { memcpy ( s - > inbuf_ptr , buf_ptr , len ) ; buf_ptr + = len ; buf_size - = len ; s - > inbuf_ptr + = len ; } if ( ( s - > inbuf_ptr - s - > inbuf ) > = MPA_HEADER_SIZE ) { got_header : header = AV_RB32 ( s - > inbuf ) ; ret = ff_mpa_decode_header ( avctx , header , & sr ) ; if ( ret < 0 ) { s - > header_count= - 2 ; / * no sync found : move by one byte ( inefficient , but simple ! ) * / memmove ( s - > inbuf , s - > inbuf + 1 , s - > inbuf_ptr - s - > inbuf - 1 ) ; s - > inbuf_ptr - - ; dprintf ( avctx , skip %x\n , header ) ; / * reset free format frame size to give a chance to get a new bitrate * / s - > free_format_frame_size = 0 ; } else { if ( ( header & SAME_HEADER_MASK ) ! = ( s - > header & SAME_HEADER_MASK ) & & s - > header ) s - > header_count= - 3 ; s - > header= header ; s - > header_count + + ; s - > frame_size = ret ; if 0 / * free format : prepare to compute frame size * / if ( ff_mpegaudio_decode_header ( s , header ) == 1 ) { s - > frame_size = - 1 ; } endif if ( s - > header_count > 1 ) avctx - > sample_rate= sr ; } } } else if 0 if ( s - > frame_size == - 1 ) { / * free format : find next sync to compute frame size * / len = MPA_MAX_CODED_FRAME_SIZE - len ; if ( len > buf_size ) len = buf_size ; if ( len == 0 ) { / * frame too long : resync * / s - > frame_size = 0 ; memmove ( s - > inbuf , s - > inbuf + 1 , s - > inbuf_ptr - s - > inbuf - 1 ) ; s - > inbuf_ptr - - ; } else { uint8_t * p , * pend ; uint32_t header1 ; int padding ; memcpy ( s - > inbuf_ptr , buf_ptr , len ) ; / * check for header * / p = s - > inbuf_ptr - 3 ; pend = s - > inbuf_ptr + len - 4 ; while ( p < = pend ) { header = AV_RB32 ( p ) ; header1 = AV_RB32 ( s - > inbuf ) ; / * check with high probability that we have a valid header * / if ( ( header & SAME_HEADER_MASK ) == ( header1 & SAME_HEADER_MASK ) ) { / * header found : update pointers * / len = ( p + 4 ) - s - > inbuf_ptr ; buf_ptr + = len ; buf_size - = len ; s - > inbuf_ptr = p ; / * compute frame size * / s - > free_format_next_header = header ; s - > free_format_frame_size = s - > inbuf_ptr - s - > inbuf ; padding = ( header1 > > 9 ) & 1 ; if ( s - > layer == 1 ) s - > free_format_frame_size - = padding * 4 ; else s - > free_format_frame_size - = padding ; dprintf ( avctx , free frame size=%d padding=%d\n , s - > free_format_frame_size , padding ) ; ff_mpegaudio_decode_header ( s , header1 ) ; goto next_data ; } p + + ; } / * not found : simply increase pointers * / buf_ptr + = len ; s - > inbuf_ptr + = len ; buf_size - = len ; } } else endif if ( len < s - > frame_size ) { if ( s - > frame_size > MPA_MAX_CODED_FRAME_SIZE ) s - > frame_size = MPA_MAX_CODED_FRAME_SIZE ; len = FFMIN ( s - > frame_size - len , buf_size ) ; memcpy ( s - > inbuf_ptr , buf_ptr , len ) ; buf_ptr + = len ; s - > inbuf_ptr + = len ; buf_size - = len ; } if ( s - > frame_size > 0 & & buf_ptr - buf == s - > inbuf_ptr - s - > inbuf & & buf_size + buf_ptr - buf > = s - > frame_size ) { if ( s - > header_count > 0 ) { * poutbuf = buf ; * poutbuf_size = s - > frame_size ; } buf_ptr = buf + s - > frame_size ; s - > inbuf_ptr = s - > inbuf ; s - > frame_size = 0 ; break ; } // next_data : if ( s - > frame_size > 0 & & ( s - > inbuf_ptr - s - > inbuf ) > = s - > frame_size ) { if ( s - > header_count > 0 ) { * poutbuf = s - > inbuf ; * poutbuf_size = s - > inbuf_ptr - s - > inbuf ; } s - > inbuf_ptr = s - > inbuf ; s - > frame_size = 0 ; break ; } } return buf_ptr - buf ; }",0
"int ff_replaygain_export_raw ( AVStream * st , int32_t tg , uint32_t tp , int32_t ag , uint32_t ap ) { AVReplayGain * replaygain ; if ( tg == INT32_MIN & & ag == INT32_MIN ) return 0 ; replaygain = ( AVReplayGain * ) ff_stream_new_side_data ( st , AV_PKT_DATA_REPLAYGAIN , sizeof ( * replaygain ) ) ; if ( ! replaygain ) return AVERROR ( ENOMEM ) ; replaygain - > track_gain = tg ; replaygain - > track_peak = tp ; replaygain - > album_gain = ag ; replaygain - > album_peak = ap ; return 0 ; }",0
"static int decode_nal_units ( H264Context * h , const uint8_t * buf , int buf_size , int parse_extradata ) { AVCodecContext * const avctx = h - > avctx ; H264SliceContext * sl ; int buf_index ; unsigned context_count ; int next_avc ; int nals_needed = 0 ; /// < number of NALs that need decoding before the next frame thread starts int nal_index ; int idr_cleared=0 ; int ret = 0 ; h - > nal_unit_type= 0 ; if ( ! h - > slice_context_count ) h - > slice_context_count= 1 ; h - > max_contexts = h - > slice_context_count ; if ( ! ( avctx - > flags2 & CODEC_FLAG2_CHUNKS ) ) { h - > current_slice = 0 ; if ( ! h - > first_field ) h - > cur_pic_ptr = NULL ; ff_h264_reset_sei ( h ) ; if ( h - > nal_length_size == 4 ) { if ( buf_size > 8 & & AV_RB32 ( buf ) == 1 & & AV_RB32 ( buf + 5 ) > ( unsigned ) buf_size ) { h - > is_avc = 0 ; } else if ( buf_size > 3 & & AV_RB32 ( buf ) > 1 & & AV_RB32 ( buf ) < = ( unsigned ) buf_size ) h - > is_avc = 1 ; if ( avctx - > active_thread_type & FF_THREAD_FRAME ) nals_needed = get_last_needed_nal ( h , buf , buf_size ) ; { buf_index = 0 ; next_avc = h - > is_avc ? 0 : buf_size ; nal_index = 0 ; for ( ; ; ) { int consumed ; int dst_length ; int bit_length ; const uint8_t * ptr ; int nalsize = 0 ; int err ; if ( buf_index > = next_avc ) { nalsize = get_avc_nalsize ( h , buf , buf_size , & buf_index ) ; if ( nalsize < 0 ) break ; next_avc = buf_index + nalsize ; } else { buf_index = find_start_code ( buf , buf_size , buf_index , next_avc ) ; if ( buf_index > = buf_size ) break ; if ( buf_index > = next_avc ) continue ; sl = & h - > slice_ctx[context_count] ; ptr = ff_h264_decode_nal ( h , sl , buf + buf_index , & dst_length , & consumed , next_avc - buf_index ) ; if ( ! ptr || dst_length < 0 ) { ret = - 1 ; bit_length = get_bit_length ( h , buf , ptr , dst_length , buf_index + consumed , next_avc ) ; if ( h - > avctx - > debug & FF_DEBUG_STARTCODE ) av_log ( h - > avctx , AV_LOG_DEBUG , NAL %d/%d at %d/%d length %d\n , h - > nal_unit_type , h - > nal_ref_idc , buf_index , buf_size , dst_length ) ; if ( h - > is_avc & & ( nalsize ! = consumed ) & & nalsize ) av_log ( h - > avctx , AV_LOG_DEBUG , AVC : Consumed only %d bytes instead of %d\n , consumed , nalsize ) ; buf_index + = consumed ; nal_index + + ; if ( avctx - > skip_frame > = AVDISCARD_NONREF & & h - > nal_ref_idc == 0 & & h - > nal_unit_type ! = NAL_SEI ) continue ; again : if ( ( ! ( avctx - > active_thread_type & FF_THREAD_FRAME ) || nals_needed > = nal_index ) & & ! h - > current_slice ) h - > au_pps_id = - 1 ; / * Ignore per frame NAL unit type during extradata * parsing . Decoding slices is not possible in codec init * with frame - mt * / if ( parse_extradata ) { switch ( h - > nal_unit_type ) { case NAL_IDR_SLICE : case NAL_SLICE : case NAL_DPA : case NAL_DPB : case NAL_DPC : av_log ( h - > avctx , AV_LOG_WARNING , Ignoring NAL %d in global header/extradata\n , h - > nal_unit_type ) ; // fall through to next case case NAL_AUXILIARY_SLICE : h - > nal_unit_type = NAL_FF_IGNORE ; err = 0 ; switch ( h - > nal_unit_type ) { case NAL_IDR_SLICE : if ( ( ptr[0] & 0xFC ) == 0x98 ) { av_log ( h - > avctx , AV_LOG_ERROR , Invalid inter IDR frame\n ) ; h - > next_outputed_poc = INT_MIN ; ret = - 1 ; if ( h - > nal_unit_type ! = NAL_IDR_SLICE ) { av_log ( h - > avctx , AV_LOG_ERROR , Invalid mix of idr and non - idr slices\n ) ; ret = - 1 ; if ( ! idr_cleared ) { if ( h - > current_slice & & ( avctx - > active_thread_type & FF_THREAD_SLICE ) ) { av_log ( h , AV_LOG_ERROR , invalid mixed IDR / non IDR frames cannot be decoded in slice multithreading mode\n ) ; ret = AVERROR_INVALIDDATA ; idr ( h ) ; // FIXME ensure we don ' t lose some frames if there is reordering idr_cleared = 1 ; h - > has_recovery_point = 1 ; case NAL_SLICE : init_get_bits ( & sl - > gb , ptr , bit_length ) ; if ( ( err = ff_h264_decode_slice_header ( h , sl ) ) ) break ; if ( h - > sei_recovery_frame_cnt > = 0 ) { if ( h - > frame_num ! = h - > sei_recovery_frame_cnt || sl - > slice_type_nos ! = AV_PICTURE_TYPE_I ) h - > valid_recovery_point = 1 ; if ( h - > recovery_frame < 0 || ( ( h - > recovery_frame - h - > frame_num ) & ( ( 1 < < h - > sps . log2_max_frame_num ) - 1 ) ) > h - > sei_recovery_frame_cnt ) { h - > recovery_frame = ( h - > frame_num + h - > sei_recovery_frame_cnt ) & ( ( 1 < < h - > sps . log2_max_frame_num ) - 1 ) ; if ( ! h - > valid_recovery_point ) h - > recovery_frame = h - > frame_num ; h - > cur_pic_ptr - > f . key_frame |= ( h - > nal_unit_type == NAL_IDR_SLICE ) ; if ( h - > nal_unit_type == NAL_IDR_SLICE || h - > recovery_frame == h - > frame_num ) { h - > recovery_frame = - 1 ; h - > cur_pic_ptr - > recovered = 1 ; // If we have an IDR , all frames after it in decoded order are // recovered . if ( h - > nal_unit_type == NAL_IDR_SLICE ) h - > frame_recovered |= FRAME_RECOVERED_IDR ; h - > frame_recovered |= 3 * ! ! ( avctx - > flags2 & CODEC_FLAG2_SHOW_ALL ) ; h - > frame_recovered |= 3 * ! ! ( avctx - > flags & CODEC_FLAG_OUTPUT_CORRUPT ) ; if 1 h - > cur_pic_ptr - > recovered |= h - > frame_recovered ; else h - > cur_pic_ptr - > recovered |= ! ! ( h - > frame_recovered & FRAME_RECOVERED_IDR ) ; endif if ( h - > current_slice == 1 ) { if ( ! ( avctx - > flags2 & CODEC_FLAG2_CHUNKS )",1
"static int check_tag ( AVIOContext * s , int offset , unsigned int len ) { char tag[4] ; if ( len > 4 || avio_seek ( s , offset , SEEK_SET ) < 0 || avio_read ( s , tag , len ) < len ) return - 1 ; else if ( ! AV_RB32 ( tag ) || is_tag ( tag , len ) ) return 1 ; return 0 ; }",1
static int rm_probe ( AVProbeData * p ) { / * check file header * / if ( p - > buf_size < = 32 ) return 0 ; if ( ( p - > buf[0] == ' . ' & & p - > buf[1] == ' R ' & & p - > buf[2] == ' M ' & & p - > buf[3] == ' F ' & & p - > buf[4] == 0 & & p - > buf[5] == 0 ) || ( p - > buf[0] == ' . ' & & p - > buf[1] == ' r ' & & p - > buf[2] == ' a ' & & p - > buf[3] == 0xfd ) ) return AVPROBE_SCORE_MAX ; else return 0 ; },0
"static int read_sm_data ( AVFormatContext * s , AVIOContext * bc , AVPacket * pkt , int is_meta , int64_t maxpos ) { int count = ffio_read_varlen ( bc ) ; int skip_start = 0 ; int skip_end = 0 ; int channels = 0 ; int64_t channel_layout = 0 ; int sample_rate = 0 ; int width = 0 ; int height = 0 ; int i ; for ( i=0 ; i < count ; i + + ) { uint8_t name[256] , str_value[256] , type_str[256] ; int value ; if ( avio_tell ( bc ) > = maxpos ) return AVERROR_INVALIDDATA ; get_str ( bc , name , sizeof ( name ) ) ; value = get_s ( bc ) ; if ( value == - 1 ) { get_str ( bc , str_value , sizeof ( str_value ) ) ; av_log ( s , AV_LOG_WARNING , Unknown string %s / %s\n , name , str_value ) ; } else if ( value == - 2 ) { uint8_t * dst = NULL ; int64_t v64 , value_len ; get_str ( bc , type_str , sizeof ( type_str ) ) ; value_len = ffio_read_varlen ( bc ) ; if ( avio_tell ( bc ) + value_len > = maxpos ) return AVERROR_INVALIDDATA ; if ( ! strcmp ( name , Palette ) ) { dst = av_packet_new_side_data ( pkt , AV_PKT_DATA_PALETTE , value_len ) ; } else if ( ! strcmp ( name , Extradata ) ) { dst = av_packet_new_side_data ( pkt , AV_PKT_DATA_NEW_EXTRADATA , value_len ) ; } else if ( sscanf ( name , CodecSpecificSide% SCNd64 , & v64 ) == 1 ) { dst = av_packet_new_side_data ( pkt , AV_PKT_DATA_MATROSKA_BLOCKADDITIONAL , value_len + 8 ) ; if ( ! dst ) return AVERROR ( ENOMEM ) ; AV_WB64 ( dst , v64 ) ; dst + = 8 ; } else if ( ! strcmp ( name , ChannelLayout ) & & value_len == 8 ) { channel_layout = avio_rl64 ( bc ) ; continue ; } else { av_log ( s , AV_LOG_WARNING , Unknown data %s / %s\n , name , type_str ) ; avio_skip ( bc , value_len ) ; continue ; } if ( ! dst ) return AVERROR ( ENOMEM ) ; avio_read ( bc , dst , value_len ) ; } else if ( value == - 3 ) { value = get_s ( bc ) ; } else if ( value == - 4 ) { value = ffio_read_varlen ( bc ) ; } else if ( value < - 4 ) { get_s ( bc ) ; } else { if ( ! strcmp ( name , SkipStart ) ) { skip_start = value ; } else if ( ! strcmp ( name , SkipEnd ) ) { skip_end = value ; } else if ( ! strcmp ( name , Channels ) ) { channels = value ; } else if ( ! strcmp ( name , SampleRate ) ) { sample_rate = value ; } else if ( ! strcmp ( name , Width ) ) { width = value ; } else if ( ! strcmp ( name , Height ) ) { height = value ; } else { av_log ( s , AV_LOG_WARNING , Unknown integer %s\n , name ) ; } } } if ( channels || channel_layout || sample_rate || width || height ) { uint8_t * dst = av_packet_new_side_data ( pkt , AV_PKT_DATA_PARAM_CHANGE , 28 ) ; if ( ! dst ) return AVERROR ( ENOMEM ) ; bytestream_put_le32 ( & dst , AV_SIDE_DATA_PARAM_CHANGE_CHANNEL_COUNT * ( ! ! channels ) + AV_SIDE_DATA_PARAM_CHANGE_CHANNEL_LAYOUT * ( ! ! channel_layout ) + AV_SIDE_DATA_PARAM_CHANGE_SAMPLE_RATE * ( ! ! sample_rate ) + AV_SIDE_DATA_PARAM_CHANGE_DIMENSIONS * ( ! ! ( width|height ) ) ) ; if ( channels ) bytestream_put_le32 ( & dst , channels ) ; if ( channel_layout ) bytestream_put_le64 ( & dst , channel_layout ) ; if ( sample_rate ) bytestream_put_le32 ( & dst , sample_rate ) ; if ( width || height ) { bytestream_put_le32 ( & dst , width ) ; bytestream_put_le32 ( & dst , height ) ; } } if ( skip_start || skip_end ) { uint8_t * dst = av_packet_new_side_data ( pkt , AV_PKT_DATA_SKIP_SAMPLES , 10 ) ; if ( ! dst ) return AVERROR ( ENOMEM ) ; AV_WL32 ( dst , skip_start ) ; AV_WL32 ( dst + 4 , skip_end ) ; } return 0 ; }",0
"static FFPsyWindowInfo psy_lame_window ( FFPsyContext * ctx , const float * audio , const float * la , int channel , int prev_type ) { AacPsyContext * pctx = ( AacPsyContext * ) ctx - > model_priv_data ; AacPsyChannel * pch = & pctx - > ch[channel] ; int grouping = 0 ; int uselongblock = 1 ; int attacks[AAC_NUM_BLOCKS_SHORT + 1] = { 0 } ; float clippings[AAC_NUM_BLOCKS_SHORT] ; int i ; FFPsyWindowInfo wi = { { 0 } } ; if ( la ) { float hpfsmpl[AAC_BLOCK_SIZE_LONG] ; float const * pf = hpfsmpl ; float attack_intensity[ ( AAC_NUM_BLOCKS_SHORT + 1 ) * PSY_LAME_NUM_SUBBLOCKS] ; float energy_subshort[ ( AAC_NUM_BLOCKS_SHORT + 1 ) * PSY_LAME_NUM_SUBBLOCKS] ; float energy_short[AAC_NUM_BLOCKS_SHORT + 1] = { 0 } ; const float * firbuf = la + ( AAC_BLOCK_SIZE_SHORT/4 - PSY_LAME_FIR_LEN ) ; int att_sum = 0 ; / * LAME comment : apply high pass filter of fs/4 * / psy_hp_filter ( firbuf , hpfsmpl , psy_fir_coeffs ) ; / * Calculate the energies of each sub - shortblock * / for ( i = 0 ; i < PSY_LAME_NUM_SUBBLOCKS ; i + + ) { energy_subshort[i] = pch - > prev_energy_subshort[i + ( ( AAC_NUM_BLOCKS_SHORT - 1 ) * PSY_LAME_NUM_SUBBLOCKS ) ] ; assert ( pch - > prev_energy_subshort[i + ( ( AAC_NUM_BLOCKS_SHORT - 2 ) * PSY_LAME_NUM_SUBBLOCKS + 1 ) ] > 0 ) ; attack_intensity[i] = energy_subshort[i] / pch - > prev_energy_subshort[i + ( ( AAC_NUM_BLOCKS_SHORT - 2 ) * PSY_LAME_NUM_SUBBLOCKS + 1 ) ] ; energy_short[0] + = energy_subshort[i] ; } for ( i = 0 ; i < AAC_NUM_BLOCKS_SHORT * PSY_LAME_NUM_SUBBLOCKS ; i + + ) { float const * const pfe = pf + AAC_BLOCK_SIZE_LONG / ( AAC_NUM_BLOCKS_SHORT * PSY_LAME_NUM_SUBBLOCKS ) ; float p = 1 . 0f ; for ( ; pf < pfe ; pf + + ) p = FFMAX ( p , fabsf ( * pf ) ) ; pch - > prev_energy_subshort[i] = energy_subshort[i + PSY_LAME_NUM_SUBBLOCKS] = p ; energy_short[1 + i / PSY_LAME_NUM_SUBBLOCKS] + = p ; / * NOTE : The indexes below are [i + 3 - 2] in the LAME source . * Obviously the 3 and 2 have some significance , or this would be just [i + 1] * ( which is what we use here ) . What the 3 stands for is ambiguous , as it is both * number of short blocks , and the number of sub - short blocks . * It seems that LAME is comparing each sub - block to sub - block + 1 in the * previous block . * / if ( p > energy_subshort[i + 1] ) p = p / energy_subshort[i + 1] ; else if ( energy_subshort[i + 1] > p * 10 . 0f ) p = energy_subshort[i + 1] / ( p * 10 . 0f ) ; else p = 0 . 0 ; attack_intensity[i + PSY_LAME_NUM_SUBBLOCKS] = p ; } / * compare energy between sub - short blocks * / for ( i = 0 ; i < ( AAC_NUM_BLOCKS_SHORT + 1 ) * PSY_LAME_NUM_SUBBLOCKS ; i + + ) if ( ! attacks[i / PSY_LAME_NUM_SUBBLOCKS] ) if ( attack_intensity[i] > pch - > attack_threshold ) attacks[i / PSY_LAME_NUM_SUBBLOCKS] = ( i % PSY_LAME_NUM_SUBBLOCKS ) + 1 ; / * should have energy change between short blocks , in order to avoid periodic signals * / / * Good samples to show the effect are Trumpet test songs * / / * GB : tuned ( 1 ) to avoid too many short blocks for test sample TRUMPET * / / * RH : tuned ( 2 ) to let enough short blocks through for test sample FSOL and SNAPS * / for ( i = 1 ; i < AAC_NUM_BLOCKS_SHORT + 1 ; i + + ) { float const u = energy_short[i - 1] ; float const v = energy_short[i] ; float const m = FFMAX ( u , v ) ; if ( m < 40000 ) { / * ( 2 ) * / if ( u < 1 . 7f * v & & v < 1 . 7f * u ) { / * ( 1 ) * / if ( i == 1 & & attacks[0] < attacks[i] ) attacks[0] = 0 ; attacks[i] = 0 ; } } att_sum + = attacks[i] ; } if ( attacks[0] < = pch - > prev_attack ) attacks[0] = 0 ; att_sum + = attacks[0] ; / * 3 below indicates the previous attack happened in the last sub - block of the previous sequence * / if ( pch - > prev_attack == 3 || att_sum ) { uselongblock = 0 ; for ( i = 1 ; i < AAC_NUM_BLOCKS_SHORT + 1 ; i + + ) if ( attacks[i] & & attacks[i - 1] ) attacks[i] = 0 ; } } else { / * We have no lookahead info , so just use same type as the previous sequence . * / uselongblock = ! ( prev_type == EIGHT_SHORT_SEQUENCE ) ; } lame_apply_block_type ( pch , & wi , uselongblock ) ; / * Calculate input sample maximums and evaluate clipping risk * / if ( audio ) { for ( i = 0 ; i < AAC_NUM_BLOCKS_SHORT ; i + + ) { const float * wbuf = audio + i * AAC_BLOCK_SIZE_SHORT ; float max = 0 ; int j ; for ( j = 0 ; j < AAC_BLOCK_SIZE_SHORT ; j + + ) max = FFMAX ( max , fabsf ( wbuf[j] ) ) ; clippings[i] = max ; } } else { for ( i = 0 ; i < 8 ; i + + ) clippings[i] = 0 ; } wi . window_type[1] = prev_type ; if ( wi . window_type[0] ! = EIGHT_SHORT_SEQUENCE ) { float clipping = 0 . 0f ; wi . num_windows = 1 ; wi . grouping[0] = 1 ; if ( wi . window_type[0] == LONG_START_SEQUENCE ) wi . window_shape = 0 ; else wi . window_shape = 1 ; for ( i = 0 ; i < 8 ; i + + ) clipping = FFMAX ( clipping , clippings[i] ) ; wi . clipping[0] = clipping ; } else { int lastgrp = 0 ; wi . num_windows = 8 ; wi . window_shape = 0 ; for ( i = 0 ; i < 8 ; i + + ) { if ( ! ( ( pch - > next_grouping > > i ) & 1 ) ) lastgrp = i ; wi . grouping[lastgrp] + + ; } for ( i = 0 ; i < 8 ; i + = wi . grouping[i] ) { int w ; float clipping = 0 . 0f ; for ( w = 0 ; w < wi . grouping[i] ; w + + ) clipping = FFMAX ( clipping , clippings[i + w] ) ; for ( w = 0 ; w < wi . grouping[i] ; w + + ) wi . clipping[i +",0
"static inline void RENAME ( yuvPlanartoyuy2 ) ( const uint8_t * ysrc , const uint8_t * usrc , const uint8_t * vsrc , uint8_t * dst , long width , long height , long lumStride , long chromStride , long dstStride , long vertLumPerChroma ) { long y ; const long chromWidth= width > > 1 ; for ( y=0 ; y < height ; y + + ) { ifdef HAVE_MMX //FIXME handle 2 lines a once ( fewer prefetch , reuse some chrom , but very likely limited by mem anyway ) asm volatile ( xor %% REG_a , %% REG_a \n\t ASMALIGN16 1 : \n\t PREFETCH 32 ( %1 , %% REG_a , 2 ) \n\t PREFETCH 32 ( %2 , %% REG_a ) \n\t PREFETCH 32 ( %3 , %% REG_a ) \n\t movq ( %2 , %% REG_a ) , %%mm0 \n\t // U ( 0 ) movq %%mm0 , %%mm2 \n\t // U ( 0 ) movq ( %3 , %% REG_a ) , %%mm1 \n\t // V ( 0 ) punpcklbw %%mm1 , %%mm0 \n\t // UVUV UVUV ( 0 ) punpckhbw %%mm1 , %%mm2 \n\t // UVUV UVUV ( 8 ) movq ( %1 , %% REG_a , 2 ) , %%mm3 \n\t // Y ( 0 ) movq 8 ( %1 , %% REG_a , 2 ) , %%mm5 \n\t // Y ( 8 ) movq %%mm3 , %%mm4 \n\t // Y ( 0 ) movq %%mm5 , %%mm6 \n\t // Y ( 8 ) punpcklbw %%mm0 , %%mm3 \n\t // YUYV YUYV ( 0 ) punpckhbw %%mm0 , %%mm4 \n\t // YUYV YUYV ( 4 ) punpcklbw %%mm2 , %%mm5 \n\t // YUYV YUYV ( 8 ) punpckhbw %%mm2 , %%mm6 \n\t // YUYV YUYV ( 12 ) MOVNTQ %%mm3 , ( %0 , %% REG_a , 4 ) \n\t MOVNTQ %%mm4 , 8 ( %0 , %% REG_a , 4 ) \n\t MOVNTQ %%mm5 , 16 ( %0 , %% REG_a , 4 ) \n\t MOVNTQ %%mm6 , 24 ( %0 , %% REG_a , 4 ) \n\t add 8 , %% REG_a \n\t cmp %4 , %% REG_a \n\t jb 1b \n\t : : r ( dst ) , r ( ysrc ) , r ( usrc ) , r ( vsrc ) , g ( chromWidth ) : % REG_a ) ; else if defined ARCH_ALPHA & & defined HAVE_MVI define pl2yuy2 ( n ) \ y1 = yc[n] ; \ y2 = yc2[n] ; \ u = uc[n] ; \ v = vc[n] ; \ asm ( unpkbw %1 , %0 : =r ( y1 ) : r ( y1 ) ) ; \ asm ( unpkbw %1 , %0 : =r ( y2 ) : r ( y2 ) ) ; \ asm ( unpkbl %1 , %0 : =r ( u ) : r ( u ) ) ; \ asm ( unpkbl %1 , %0 : =r ( v ) : r ( v ) ) ; \ yuv1 = ( u < < 8 ) + ( v < < 24 ) ; \ yuv2 = yuv1 + y2 ; \ yuv1 + = y1 ; \ qdst[n] = yuv1 ; \ qdst2[n] = yuv2 ; int i ; uint64_t * qdst = ( uint64_t * ) dst ; uint64_t * qdst2 = ( uint64_t * ) ( dst + dstStride ) ; const uint32_t * yc = ( uint32_t * ) ysrc ; const uint32_t * yc2 = ( uint32_t * ) ( ysrc + lumStride ) ; const uint16_t * uc = ( uint16_t * ) usrc , * vc = ( uint16_t * ) vsrc ; for ( i = 0 ; i < chromWidth ; i + = 8 ) { uint64_t y1 , y2 , yuv1 , yuv2 ; uint64_t u , v ; / * Prefetch * / asm ( ldq 31 , 64 ( %0 ) : : r ( yc ) ) ; asm ( ldq 31 , 64 ( %0 ) : : r ( yc2 ) ) ; asm ( ldq 31 , 64 ( %0 ) : : r ( uc ) ) ; asm ( ldq 31 , 64 ( %0 ) : : r ( vc ) ) ; pl2yuy2 ( 0 ) ; pl2yuy2 ( 1 ) ; pl2yuy2 ( 2 ) ; pl2yuy2 ( 3 ) ; yc + = 4 ; yc2 + = 4 ; uc + = 4 ; vc + = 4 ; qdst + = 4 ; qdst2 + = 4 ; } y + + ; ysrc + = lumStride ; dst + = dstStride ; elif __WORDSIZE > = 64 int i ; uint64_t * ldst = ( uint64_t * ) dst ; const uint8_t * yc = ysrc , * uc = usrc , * vc = vsrc ; for ( i = 0 ; i < chromWidth ; i + = 2 ) { uint64_t k , l ; k = yc[0] + ( uc[0] < < 8 ) + ( yc[1] < < 16 ) + ( vc[0] < < 24 ) ; l = yc[2] + ( uc[1] < < 8 ) + ( yc[3] < < 16 ) + ( vc[1] < < 24 ) ; * ldst + + = k + ( l < < 32 ) ; yc + = 4 ; uc + = 2 ; vc + = 2 ; } else int i , * idst = ( int32_t * ) dst ; const uint8_t * yc = ysrc , * uc = usrc , * vc = vsrc ; for ( i = 0 ; i < chromWidth ; i + + ) { ifdef WORDS_BIGENDIAN * idst + + = ( yc[0] < < 24 ) + ( uc[0] < < 16 ) + ( yc[1] < < 8 ) + ( vc[0] < < 0 ) ; else * idst + + = yc[0] + ( uc[0] < < 8 ) + ( yc[1] < < 16 ) + ( vc[0] < < 24 ) ; endif yc + = 2 ; uc + + ; vc + + ; } endif endif if ( ( y & ( vertLumPerChroma - 1 ) ) == ( vertLumPerChroma - 1 ) ) { usrc + = chromStride ; vsrc + = chromStride ; } ysrc + = lumStride ; dst + = dstStride ; } ifdef HAVE_MMX asm ( EMMS \n\t SFENCE \n\t : : : memory ) ; endif }",0
"static int ass_get_duration ( const uint8_t * p ) { int sh , sm , ss , sc , eh , em , es , ec ; uint64_t start , end ; if ( sscanf ( p , % * [ , ] , %d : %d : %d% * c%d , %d : %d : %d% * c%d , & sh , & sm , & ss , & sc , & eh , & em , & es , & ec ) ! = 8 ) return 0 ; start = 3600000 * sh + 60000 * sm + 1000 * ss + 10 * sc ; end = 3600000 * eh + 60000 * em + 1000 * es + 10 * ec ; return end - start ; }",0
"static inline int msmpeg4_decode_block ( MpegEncContext * s , DCTELEM * block , int n , int coded ) { int level , i , last , run , run_diff ; int dc_pred_dir ; RLTable * rl ; RL_VLC_ELEM * rl_vlc ; const UINT8 * scan_table ; int qmul , qadd ; if ( s - > mb_intra ) { qmul=1 ; qadd=0 ; / * DC coef * / set_stat ( ST_DC ) ; level = msmpeg4_decode_dc ( s , n , & dc_pred_dir ) ; ifdef PRINT_MB { static int c ; if ( n==0 ) c=0 ; if ( n==4 ) printf ( %X , c ) ; c + = c + dc_pred_dir ; } endif if ( level < 0 ) { fprintf ( stderr , dc overflow - block : %d qscale : %d//\n , n , s - > qscale ) ; if ( s - > inter_intra_pred ) level=0 ; else return - 1 ; } if ( n < 4 ) { rl = & rl_table[s - > rl_table_index] ; if ( level > 256 * s - > y_dc_scale ) { fprintf ( stderr , dc overflow + L qscale : %d//\n , s - > qscale ) ; if ( ! s - > inter_intra_pred ) return - 1 ; } } else { rl = & rl_table[3 + s - > rl_chroma_table_index] ; if ( level > 256 * s - > c_dc_scale ) { fprintf ( stderr , dc overflow + C qscale : %d//\n , s - > qscale ) ; if ( ! s - > inter_intra_pred ) return - 1 ; } } block[0] = level ; run_diff = 0 ; i = 0 ; if ( ! coded ) { goto not_coded ; } if ( s - > ac_pred ) { if ( dc_pred_dir == 0 ) scan_table = s - > intra_v_scantable ; / * left * / else scan_table = s - > intra_h_scantable ; / * top * / } else { scan_table = s - > intra_scantable ; } set_stat ( ST_INTRA_AC ) ; rl_vlc= rl - > rl_vlc[0] ; } else { qmul = s - > qscale < < 1 ; qadd = ( s - > qscale - 1 ) | 1 ; i = - 1 ; rl = & rl_table[3 + s - > rl_table_index] ; if ( s - > msmpeg4_version==2 ) run_diff = 0 ; else run_diff = 1 ; if ( ! coded ) { s - > block_last_index[n] = i ; return 0 ; } scan_table = s - > inter_scantable ; set_stat ( ST_INTER_AC ) ; rl_vlc= rl - > rl_vlc[s - > qscale] ; } { OPEN_READER ( re , & s - > gb ) ; for ( ; ; ) { UPDATE_CACHE ( re , & s - > gb ) ; GET_RL_VLC ( level , run , re , & s - > gb , rl_vlc , TEX_VLC_BITS , 2 ) ; if ( level==0 ) { int cache ; cache= GET_CACHE ( re , & s - > gb ) ; / * escape * / if ( s - > msmpeg4_version==1 || ( cache & 0x80000000 ) ==0 ) { if ( s - > msmpeg4_version==1 || ( cache & 0x40000000 ) ==0 ) { / * third escape * / if ( s - > msmpeg4_version ! =1 ) LAST_SKIP_BITS ( re , & s - > gb , 2 ) ; UPDATE_CACHE ( re , & s - > gb ) ; if ( s - > msmpeg4_version < =3 ) { last= SHOW_UBITS ( re , & s - > gb , 1 ) ; SKIP_CACHE ( re , & s - > gb , 1 ) ; run= SHOW_UBITS ( re , & s - > gb , 6 ) ; SKIP_CACHE ( re , & s - > gb , 6 ) ; level= SHOW_SBITS ( re , & s - > gb , 8 ) ; LAST_SKIP_CACHE ( re , & s - > gb , 8 ) ; SKIP_COUNTER ( re , & s - > gb , 1 + 6 + 8 ) ; } else { int sign ; last= SHOW_UBITS ( re , & s - > gb , 1 ) ; SKIP_BITS ( re , & s - > gb , 1 ) ; if ( ! s - > esc3_level_length ) { int ll ; //printf ( ESC - 3 %X at %d %d\n , show_bits ( & s - > gb , 24 ) , s - > mb_x , s - > mb_y ) ; if ( s - > qscale < 8 ) { ll= SHOW_UBITS ( re , & s - > gb , 3 ) ; SKIP_BITS ( re , & s - > gb , 3 ) ; if ( ll==0 ) { if ( SHOW_UBITS ( re , & s - > gb , 1 ) ) printf ( cool a new vlc code , contact the ffmpeg developers and upload the file\n ) ; SKIP_BITS ( re , & s - > gb , 1 ) ; ll=8 ; } } else { ll=2 ; while ( ll < 8 & & SHOW_UBITS ( re , & s - > gb , 1 ) ==0 ) { ll + + ; SKIP_BITS ( re , & s - > gb , 1 ) ; } if ( ll < 8 ) SKIP_BITS ( re , & s - > gb , 1 ) ; } s - > esc3_level_length= ll ; s - > esc3_run_length= SHOW_UBITS ( re , & s - > gb , 2 ) + 3 ; SKIP_BITS ( re , & s - > gb , 2 ) ; //printf ( level length : %d , run length : %d\n , ll , s - > esc3_run_length ) ; UPDATE_CACHE ( re , & s - > gb ) ; } run= SHOW_UBITS ( re , & s - > gb , s - > esc3_run_length ) ; SKIP_BITS ( re , & s - > gb , s - > esc3_run_length ) ; sign= SHOW_UBITS ( re , & s - > gb , 1 ) ; SKIP_BITS ( re , & s - > gb , 1 ) ; level= SHOW_UBITS ( re , & s - > gb , s - > esc3_level_length ) ; SKIP_BITS ( re , & s - > gb , s - > esc3_level_length ) ; if ( sign ) level= - level ; } //printf ( level : %d , run : %d at %d %d\n , level , run , s - > mb_x , s - > mb_y ) ; if 0 // waste of time / this will detect very few errors { const int abs_level= ABS ( level ) ; const int run1= run - rl - > max_run[last][abs_level] - run_diff ; if ( abs_level < =MAX_LEVEL & & run < =MAX_RUN ) { if ( abs_level < = rl - > max_level[last][run] ) {",0
"static void revert_acfilter ( WmallDecodeCtx * s , int tile_size ) { int ich , pred , i , j ; int16_t * filter_coeffs = s - > acfilter_coeffs ; int scaling = s - > acfilter_scaling ; int order = s - > acfilter_order ; for ( ich = 0 ; ich < s - > num_channels ; ich + + ) { int * prevvalues = s - > acfilter_prevvalues[ich] ; for ( i = 0 ; i < order ; i + + ) { pred = 0 ; for ( j = 0 ; j < order ; j + + ) { if ( i < = j ) pred + = filter_coeffs[j] * prevvalues[j - i] ; else pred + = s - > channel_residues[ich][i - j - 1] * filter_coeffs[j] ; } pred > > = scaling ; s - > channel_residues[ich][i] + = pred ; } for ( i = order ; i < tile_size ; i + + ) { pred = 0 ; for ( j = 0 ; j < order ; j + + ) pred + = s - > channel_residues[ich][i - j - 1] * filter_coeffs[j] ; pred > > = scaling ; s - > channel_residues[ich][i] + = pred ; } for ( j = 0 ; j < order ; j + + ) prevvalues[j] = s - > channel_residues[ich][tile_size - j - 1] ; } }",1
"static void diff_bytes_c ( uint8_t * dst , uint8_t * src1 , uint8_t * src2 , int w ) { long i ; if ! HAVE_FAST_UNALIGNED if ( ( long ) src2 & ( sizeof ( long ) - 1 ) ) { for ( i=0 ; i + 7 < w ; i + =8 ) { dst[i + 0] = src1[i + 0] - src2[i + 0] ; dst[i + 1] = src1[i + 1] - src2[i + 1] ; dst[i + 2] = src1[i + 2] - src2[i + 2] ; dst[i + 3] = src1[i + 3] - src2[i + 3] ; dst[i + 4] = src1[i + 4] - src2[i + 4] ; dst[i + 5] = src1[i + 5] - src2[i + 5] ; dst[i + 6] = src1[i + 6] - src2[i + 6] ; dst[i + 7] = src1[i + 7] - src2[i + 7] ; } } else endif for ( i=0 ; i < =w - sizeof ( long ) ; i + =sizeof ( long ) ) { long a = * ( long * ) ( src1 + i ) ; long b = * ( long * ) ( src2 + i ) ; * ( long * ) ( dst + i ) = ( ( a|pb_80 ) - ( b & pb_7f ) ) ( ( a b pb_80 ) & pb_80 ) ; } for ( ; i < w ; i + + ) dst[i + 0] = src1[i + 0] - src2[i + 0] ; }",1
"static int decode_frame ( AVCodecContext * avctx , void * data , int * got_frame_ptr , AVPacket * avpkt ) { BinkAudioContext * s = avctx - > priv_data ; AVFrame * frame = data ; GetBitContext * gb = & s - > gb ; int ret , consumed = 0 ; if ( ! get_bits_left ( gb ) ) { uint8_t * buf ; / * handle end - of - stream * / if ( ! avpkt - > size ) { * got_frame_ptr = 0 ; return 0 ; } if ( avpkt - > size < 4 ) { av_log ( avctx , AV_LOG_ERROR , Packet is too small\n ) ; return AVERROR_INVALIDDATA ; } buf = av_realloc ( s - > packet_buffer , avpkt - > size + FF_INPUT_BUFFER_PADDING_SIZE ) ; if ( ! buf ) return AVERROR ( ENOMEM ) ; s - > packet_buffer = buf ; memcpy ( s - > packet_buffer , avpkt - > data , avpkt - > size ) ; if ( ( ret = init_get_bits8 ( gb , s - > packet_buffer , avpkt - > size ) ) < 0 ) return ret ; consumed = avpkt - > size ; / * skip reported size * / skip_bits_long ( gb , 32 ) ; } / * get output buffer * / frame - > nb_samples = s - > frame_len ; if ( ( ret = ff_get_buffer ( avctx , frame , 0 ) ) < 0 ) return ret ; if ( decode_block ( s , ( float * * ) frame - > extended_data , avctx - > codec - > id == AV_CODEC_ID_BINKAUDIO_DCT ) ) { av_log ( avctx , AV_LOG_ERROR , Incomplete packet\n ) ; return AVERROR_INVALIDDATA ; } get_bits_align32 ( gb ) ; frame - > nb_samples = s - > block_size / avctx - > channels ; * got_frame_ptr = 1 ; return consumed ; }",1
"static int decode_cabac_intra_mb_type ( H264Context * h , int ctx_base , int intra_slice ) { uint8_t * state= & h - > cabac_state[ctx_base] ; int mb_type ; if ( intra_slice ) { MpegEncContext * const s = & h - > s ; const int mba_xy = h - > left_mb_xy[0] ; const int mbb_xy = h - > top_mb_xy ; int ctx=0 ; if ( h - > slice_table[mba_xy] == h - > slice_num & & ! IS_INTRA4x4 ( s - > current_picture . mb_type[mba_xy] ) ) ctx + + ; if ( h - > slice_table[mbb_xy] == h - > slice_num & & ! IS_INTRA4x4 ( s - > current_picture . mb_type[mbb_xy] ) ) ctx + + ; if ( get_cabac_noinline ( & h - > cabac , & state[ctx] ) == 0 ) return 0 ; / * I4x4 * / state + = 2 ; } else { if ( get_cabac_noinline ( & h - > cabac , state ) == 0 ) return 0 ; / * I4x4 * / } if ( get_cabac_terminate ( & h - > cabac ) ) return 25 ; / * PCM * / mb_type = 1 ; / * I16x16 * / mb_type + = 12 * get_cabac_noinline ( & h - > cabac , & state[1] ) ; / * cbp_luma ! = 0 * / if ( get_cabac_noinline ( & h - > cabac , & state[2] ) ) / * cbp_chroma * / mb_type + = 4 + 4 * get_cabac_noinline ( & h - > cabac , & state[2 + intra_slice] ) ; mb_type + = 2 * get_cabac_noinline ( & h - > cabac , & state[3 + intra_slice] ) ; mb_type + = 1 * get_cabac_noinline ( & h - > cabac , & state[3 + 2 * intra_slice] ) ; return mb_type ; }",0
"static int decode_p_picture_header ( VC9Context * v ) { / * INTERFRM , FRMCNT , RANGEREDFRM read in caller * / int lowquant , pqindex ; pqindex = get_bits ( & v - > gb , 5 ) ; if ( v - > quantizer_mode == QUANT_FRAME_IMPLICIT ) v - > pq = pquant_table[0][pqindex] ; else { v - > pq = pquant_table[v - > quantizer_mode - 1][pqindex] ; } if ( pqindex < 9 ) v - > halfpq = get_bits ( & v - > gb , 1 ) ; if ( v - > quantizer_mode == QUANT_FRAME_EXPLICIT ) v - > pquantizer = get_bits ( & v - > gb , 1 ) ; av_log ( v - > avctx , AV_LOG_DEBUG , P Frame : QP=%i ( + %i/2 ) \n , v - > pq , v - > halfpq ) ; if ( v - > extended_mv == 1 ) v - > mvrange = get_prefix ( & v - > gb , 0 , 3 ) ; if HAS_ADVANCED_PROFILE if ( v - > profile > PROFILE_MAIN ) { if ( v - > postprocflag ) v - > postproc = get_bits ( & v - > gb , 1 ) ; } else endif if ( v - > multires ) v - > respic = get_bits ( & v - > gb , 2 ) ; lowquant = ( v - > pquantizer > 12 ) ? 0 : 1 ; v - > mv_mode = mv_pmode_table[lowquant][get_prefix ( & v - > gb , 1 , 4 ) ] ; if ( v - > mv_mode == MV_PMODE_INTENSITY_COMP ) { v - > mv_mode2 = mv_pmode_table[lowquant][get_prefix ( & v - > gb , 1 , 3 ) ] ; v - > lumscale = get_bits ( & v - > gb , 6 ) ; v - > lumshift = get_bits ( & v - > gb , 6 ) ; } if ( ( v - > mv_mode == MV_PMODE_INTENSITY_COMP & & v - > mv_mode2 == MV_PMODE_MIXED_MV ) || v - > mv_mode == MV_PMODE_MIXED_MV ) { if ( bitplane_decoding ( v - > mv_type_mb_plane , v - > width_mb , v - > height_mb , v ) < 0 ) return - 1 ; } if ( bitplane_decoding ( v - > skip_mb_plane , v - > width_mb , v - > height_mb , v ) < 0 ) return - 1 ; / * Hopefully this is correct for P frames * / v - > mv_diff_vlc = & vc9_mv_diff_vlc[get_bits ( & v - > gb , 2 ) ] ; v - > cbpcy_vlc = & vc9_cbpcy_p_vlc[get_bits ( & v - > gb , 2 ) ] ; if ( v - > dquant ) { av_log ( v - > avctx , AV_LOG_INFO , VOP DQuant info\n ) ; vop_dquant_decoding ( v ) ; } if ( v - > vstransform ) { v - > ttmbf = get_bits ( & v - > gb , 1 ) ; if ( v - > ttmbf ) { v - > ttfrm = get_bits ( & v - > gb , 2 ) ; av_log ( v - > avctx , AV_LOG_INFO , Transform used : %ix%i\n , ( v - > ttfrm & 2 ) ? 4 : 8 , ( v - > ttfrm & 1 ) ? 4 : 8 ) ; } } / * Epilog should be done in caller * / return 0 ; }",0
"static int decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; DPXContext * const s = avctx - > priv_data ; AVFrame * picture = data ; AVFrame * const p = & s - > picture ; uint8_t * ptr[AV_NUM_DATA_POINTERS] ; unsigned int offset ; int magic_num , endian ; int x , y , i , ret ; int w , h , bits_per_color , descriptor , elements , packing , total_size ; unsigned int rgbBuffer = 0 ; int n_datum = 0 ; if ( avpkt - > size < = 1634 ) { av_log ( avctx , AV_LOG_ERROR , Packet too small for DPX header\n ) ; return AVERROR_INVALIDDATA ; } magic_num = AV_RB32 ( buf ) ; buf + = 4 ; / * Check if the files magic number is SDPX which means it uses * big - endian or XPDS which is for little - endian files * / if ( magic_num == AV_RL32 ( SDPX ) ) { endian = 0 ; } else if ( magic_num == AV_RB32 ( SDPX ) ) { endian = 1 ; } else { av_log ( avctx , AV_LOG_ERROR , DPX marker not found\n ) ; return AVERROR_INVALIDDATA ; } offset = read32 ( & buf , endian ) ; if ( avpkt - > size < = offset ) { av_log ( avctx , AV_LOG_ERROR , Invalid data start offset\n ) ; return AVERROR_INVALIDDATA ; } // Need to end in 0x304 offset from start of file buf = avpkt - > data + 0x304 ; w = read32 ( & buf , endian ) ; h = read32 ( & buf , endian ) ; if ( ( ret = av_image_check_size ( w , h , 0 , avctx ) ) < 0 ) return ret ; if ( w ! = avctx - > width || h ! = avctx - > height ) avcodec_set_dimensions ( avctx , w , h ) ; // Need to end in 0x320 to read the descriptor buf + = 20 ; descriptor = buf[0] ; // Need to end in 0x323 to read the bits per color buf + = 3 ; avctx - > bits_per_raw_sample = bits_per_color = buf[0] ; buf + + ; packing = * ( ( uint16_t * ) buf ) ; buf + = 824 ; avctx - > sample_aspect_ratio . num = read32 ( & buf , endian ) ; avctx - > sample_aspect_ratio . den = read32 ( & buf , endian ) ; if ( avctx - > sample_aspect_ratio . num > 0 & & avctx - > sample_aspect_ratio . den > 0 ) av_reduce ( & avctx - > sample_aspect_ratio . num , & avctx - > sample_aspect_ratio . den , avctx - > sample_aspect_ratio . num , avctx - > sample_aspect_ratio . den , 0x10000 ) ; else avctx - > sample_aspect_ratio = ( AVRational ) { 0 , 1 } ; switch ( descriptor ) { case 51 : // RGBA elements = 4 ; break ; case 50 : // RGB elements = 3 ; break ; default : av_log ( avctx , AV_LOG_ERROR , Unsupported descriptor %d\n , descriptor ) ; return AVERROR_INVALIDDATA ; } switch ( bits_per_color ) { case 8 : if ( elements == 4 ) { avctx - > pix_fmt = AV_PIX_FMT_RGBA ; } else { avctx - > pix_fmt = AV_PIX_FMT_RGB24 ; } total_size = avctx - > width * avctx - > height * elements ; break ; case 10 : if ( ! packing ) { av_log ( avctx , AV_LOG_ERROR , Packing to 32bit required\n ) ; return - 1 ; } avctx - > pix_fmt = AV_PIX_FMT_GBRP10 ; total_size = ( avctx - > width * avctx - > height * elements + 2 ) / 3 * 4 ; break ; case 12 : if ( ! packing ) { av_log ( avctx , AV_LOG_ERROR , Packing to 16bit required\n ) ; return - 1 ; } if ( endian ) { avctx - > pix_fmt = AV_PIX_FMT_GBRP12BE ; } else { avctx - > pix_fmt = AV_PIX_FMT_GBRP12LE ; } total_size = 2 * avctx - > width * avctx - > height * elements ; break ; case 16 : if ( endian ) { avctx - > pix_fmt = elements == 4 ? AV_PIX_FMT_RGBA64BE : AV_PIX_FMT_RGB48BE ; } else { avctx - > pix_fmt = elements == 4 ? AV_PIX_FMT_RGBA64LE : AV_PIX_FMT_RGB48LE ; } total_size = 2 * avctx - > width * avctx - > height * elements ; break ; default : av_log ( avctx , AV_LOG_ERROR , Unsupported color depth : %d\n , bits_per_color ) ; return AVERROR_INVALIDDATA ; } if ( s - > picture . data[0] ) avctx - > release_buffer ( avctx , & s - > picture ) ; if ( ( ret = ff_get_buffer ( avctx , p ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed\n ) ; return ret ; } // Move pointer to offset from start of file buf = avpkt - > data + offset ; for ( i=0 ; i < AV_NUM_DATA_POINTERS ; i + + ) ptr[i] = p - > data[i] ; if ( total_size > avpkt - > size ) { av_log ( avctx , AV_LOG_ERROR , Overread buffer . Invalid header ? \n ) ; return AVERROR_INVALIDDATA ; } switch ( bits_per_color ) { case 10 : for ( x = 0 ; x < avctx - > height ; x + + ) { uint16_t * dst[3] = { ( uint16_t * ) ptr[0] , ( uint16_t * ) ptr[1] , ( uint16_t * ) ptr[2] } ; for ( y = 0 ; y < avctx - > width ; y + + ) { * dst[2] + + = read10in32 ( & buf , & rgbBuffer , & n_datum , endian ) ; * dst[0] + + = read10in32 ( & buf , & rgbBuffer , & n_datum , endian ) ; * dst[1] + + = read10in32 ( & buf , & rgbBuffer , & n_datum , endian ) ; // For 10 bit , ignore alpha if ( elements == 4 ) read10in32 ( & buf , & rgbBuffer , & n_datum , endian ) ; } for ( i = 0 ; i < 3 ; i + + ) ptr[i] + = p - > linesize[i] ; } break ; case 12 : for ( x = 0 ; x < avctx - > height ; x + + ) { uint16_t * dst[3] = { ( uint16_t * ) ptr[0] , ( uint16_t * ) ptr[1] , ( uint16_t * ) ptr[2] } ; for ( y = 0 ; y < avctx - > width ; y + + ) { * dst[2] = * ( ( uint16_t * ) buf ) ; * dst[2] = ( *",0
"void ff_avg_h264_qpel8_mc12_msa ( uint8_t * dst , const uint8_t * src , ptrdiff_t stride ) { avc_luma_midh_qrt_and_aver_dst_8w_msa ( src - ( 2 * stride ) - 2 , stride , dst , stride , 8 , 0 ) ; }",0
"static void sbr_hf_assemble ( float Y[2][38][64][2] , const float X_high[64][40][2] , SpectralBandReplication * sbr , SBRData * ch_data , const int e_a[2] ) { int e , i , j , m ; const int h_SL = 4 * ! sbr - > bs_smoothing_mode ; const int kx = sbr - > kx[1] ; const int m_max = sbr - > m[1] ; static const float h_smooth[5] = { 0 . 33333333333333 , 0 . 30150283239582 , 0 . 21816949906249 , 0 . 11516383427084 , 0 . 03183050093751 , } ; static const int8_t phi[2][4] = { { 1 , 0 , - 1 , 0 } , // real { 0 , 1 , 0 , - 1 } , // imaginary } ; float ( * g_temp ) [48] = ch_data - > g_temp , ( * q_temp ) [48] = ch_data - > q_temp ; int indexnoise = ch_data - > f_indexnoise ; int indexsine = ch_data - > f_indexsine ; memcpy ( Y[0] , Y[1] , sizeof ( Y[0] ) ) ; if ( sbr - > reset ) { for ( i = 0 ; i < h_SL ; i + + ) { memcpy ( g_temp[i + 2 * ch_data - > t_env[0]] , sbr - > gain[0] , m_max * sizeof ( sbr - > gain[0][0] ) ) ; memcpy ( q_temp[i + 2 * ch_data - > t_env[0]] , sbr - > q_m[0] , m_max * sizeof ( sbr - > q_m[0][0] ) ) ; } } else if ( h_SL ) { memcpy ( g_temp[2 * ch_data - > t_env[0]] , g_temp[2 * ch_data - > t_env_num_env_old] , 4 * sizeof ( g_temp[0] ) ) ; memcpy ( q_temp[2 * ch_data - > t_env[0]] , q_temp[2 * ch_data - > t_env_num_env_old] , 4 * sizeof ( q_temp[0] ) ) ; } for ( e = 0 ; e < ch_data - > bs_num_env ; e + + ) { for ( i = 2 * ch_data - > t_env[e] ; i < 2 * ch_data - > t_env[e + 1] ; i + + ) { memcpy ( g_temp[h_SL + i] , sbr - > gain[e] , m_max * sizeof ( sbr - > gain[0][0] ) ) ; memcpy ( q_temp[h_SL + i] , sbr - > q_m[e] , m_max * sizeof ( sbr - > q_m[0][0] ) ) ; } } for ( e = 0 ; e < ch_data - > bs_num_env ; e + + ) { for ( i = 2 * ch_data - > t_env[e] ; i < 2 * ch_data - > t_env[e + 1] ; i + + ) { int phi_sign = ( 1 - 2 * ( kx & 1 ) ) ; if ( h_SL & & e ! = e_a[0] & & e ! = e_a[1] ) { for ( m = 0 ; m < m_max ; m + + ) { const int idx1 = i + h_SL ; float g_filt = 0 . 0f ; for ( j = 0 ; j < = h_SL ; j + + ) g_filt + = g_temp[idx1 - j][m] * h_smooth[j] ; Y[1][i][m + kx][0] = X_high[m + kx][i + ENVELOPE_ADJUSTMENT_OFFSET][0] * g_filt ; Y[1][i][m + kx][1] = X_high[m + kx][i + ENVELOPE_ADJUSTMENT_OFFSET][1] * g_filt ; } } else { for ( m = 0 ; m < m_max ; m + + ) { const float g_filt = g_temp[i + h_SL][m] ; Y[1][i][m + kx][0] = X_high[m + kx][i + ENVELOPE_ADJUSTMENT_OFFSET][0] * g_filt ; Y[1][i][m + kx][1] = X_high[m + kx][i + ENVELOPE_ADJUSTMENT_OFFSET][1] * g_filt ; } } if ( e ! = e_a[0] & & e ! = e_a[1] ) { for ( m = 0 ; m < m_max ; m + + ) { indexnoise = ( indexnoise + 1 ) & 0x1ff ; if ( sbr - > s_m[e][m] ) { Y[1][i][m + kx][0] + = sbr - > s_m[e][m] * phi[0][indexsine] ; Y[1][i][m + kx][1] + = sbr - > s_m[e][m] * ( phi[1][indexsine] * phi_sign ) ; } else { float q_filt ; if ( h_SL ) { const int idx1 = i + h_SL ; q_filt = 0 . 0f ; for ( j = 0 ; j < = h_SL ; j + + ) q_filt + = q_temp[idx1 - j][m] * h_smooth[j] ; } else { q_filt = q_temp[i][m] ; } Y[1][i][m + kx][0] + = q_filt * sbr_noise_table[indexnoise][0] ; Y[1][i][m + kx][1] + = q_filt * sbr_noise_table[indexnoise][1] ; } phi_sign = - phi_sign ; } } else { indexnoise = ( indexnoise + m_max ) & 0x1ff ; for ( m = 0 ; m < m_max ; m + + ) { Y[1][i][m + kx][0] + = sbr - > s_m[e][m] * phi[0][indexsine] ; Y[1][i][m + kx][1] + = sbr - > s_m[e][m] * ( phi[1][indexsine] * phi_sign ) ; phi_sign = - phi_sign ; } } indexsine = ( indexsine + 1 ) & 3 ; } } ch_data - > f_indexnoise = indexnoise ; ch_data - > f_indexsine = indexsine ; }",0
"int ff_init_poc ( H264Context * h , int pic_field_poc[2] , int * pic_poc ) { const SPS * sps = h - > ps . sps ; const int max_frame_num = 1 < < sps - > log2_max_frame_num ; int field_poc[2] ; h - > frame_num_offset = h - > prev_frame_num_offset ; if ( h - > frame_num < h - > prev_frame_num ) h - > frame_num_offset + = max_frame_num ; if ( sps - > poc_type == 0 ) { const int max_poc_lsb = 1 < < sps - > log2_max_poc_lsb ; if ( h - > poc_lsb < h - > prev_poc_lsb & & h - > prev_poc_lsb - h - > poc_lsb > = max_poc_lsb / 2 ) h - > poc_msb = h - > prev_poc_msb + max_poc_lsb ; else if ( h - > poc_lsb > h - > prev_poc_lsb & & h - > prev_poc_lsb - h - > poc_lsb < - max_poc_lsb / 2 ) h - > poc_msb = h - > prev_poc_msb - max_poc_lsb ; else h - > poc_msb = h - > prev_poc_msb ; field_poc[0] = field_poc[1] = h - > poc_msb + h - > poc_lsb ; if ( h - > picture_structure == PICT_FRAME ) field_poc[1] + = h - > delta_poc_bottom ; } else if ( sps - > poc_type == 1 ) { int abs_frame_num , expected_delta_per_poc_cycle , expectedpoc ; int i ; if ( sps - > poc_cycle_length ! = 0 ) abs_frame_num = h - > frame_num_offset + h - > frame_num ; else abs_frame_num = 0 ; if ( h - > nal_ref_idc == 0 & & abs_frame_num > 0 ) abs_frame_num - - ; expected_delta_per_poc_cycle = 0 ; for ( i = 0 ; i < sps - > poc_cycle_length ; i + + ) // FIXME integrate during sps parse expected_delta_per_poc_cycle + = sps - > offset_for_ref_frame[i] ; if ( abs_frame_num > 0 ) { int poc_cycle_cnt = ( abs_frame_num - 1 ) / sps - > poc_cycle_length ; int frame_num_in_poc_cycle = ( abs_frame_num - 1 ) % sps - > poc_cycle_length ; expectedpoc = poc_cycle_cnt * expected_delta_per_poc_cycle ; for ( i = 0 ; i < = frame_num_in_poc_cycle ; i + + ) expectedpoc = expectedpoc + sps - > offset_for_ref_frame[i] ; } else expectedpoc = 0 ; if ( h - > nal_ref_idc == 0 ) expectedpoc = expectedpoc + sps - > offset_for_non_ref_pic ; field_poc[0] = expectedpoc + h - > delta_poc[0] ; field_poc[1] = field_poc[0] + sps - > offset_for_top_to_bottom_field ; if ( h - > picture_structure == PICT_FRAME ) field_poc[1] + = h - > delta_poc[1] ; } else { int poc = 2 * ( h - > frame_num_offset + h - > frame_num ) ; if ( ! h - > nal_ref_idc ) poc - - ; field_poc[0] = poc ; field_poc[1] = poc ; } if ( h - > picture_structure ! = PICT_BOTTOM_FIELD ) pic_field_poc[0] = field_poc[0] ; if ( h - > picture_structure ! = PICT_TOP_FIELD ) pic_field_poc[1] = field_poc[1] ; * pic_poc = FFMIN ( pic_field_poc[0] , pic_field_poc[1] ) ; return 0 ; }",0
"int ff_filter_frame ( AVFilterLink * link , AVFrame * frame ) { int ( * filter_frame ) ( AVFilterLink * , AVFrame * ) ; AVFilterPad * dst = link - > dstpad ; AVFrame * out ; FF_DPRINTF_START ( NULL , filter_frame ) ; ff_dlog_link ( NULL , link , 1 ) ; if ( ! ( filter_frame = dst - > filter_frame ) ) filter_frame = default_filter_frame ; / * copy the frame if needed * / if ( dst - > needs_writable & & ! av_frame_is_writable ( frame ) ) { av_log ( link - > dst , AV_LOG_DEBUG , Copying data in avfilter . \n ) ; switch ( link - > type ) { case AVMEDIA_TYPE_VIDEO : out = ff_get_video_buffer ( link , link - > w , link - > h ) ; break ; case AVMEDIA_TYPE_AUDIO : out = ff_get_audio_buffer ( link , frame - > nb_samples ) ; break ; default : return AVERROR ( EINVAL ) ; } if ( ! out ) { av_frame_free ( & frame ) ; return AVERROR ( ENOMEM ) ; } av_frame_copy_props ( out , frame ) ; switch ( link - > type ) { case AVMEDIA_TYPE_VIDEO : av_image_copy ( out - > data , out - > linesize , frame - > data , frame - > linesize , frame - > format , frame - > width , frame - > height ) ; break ; case AVMEDIA_TYPE_AUDIO : av_samples_copy ( out - > extended_data , frame - > extended_data , 0 , 0 , frame - > nb_samples , av_get_channel_layout_nb_channels ( frame - > channel_layout ) , frame - > format ) ; break ; default : return AVERROR ( EINVAL ) ; } av_frame_free ( & frame ) ; } else out = frame ; return filter_frame ( link , out ) ; }",1
"static int sdp_parse_rtpmap ( AVFormatContext * s , AVStream * st , RTSPStream * rtsp_st , int payload_type , const char * p ) { AVCodecContext * codec = st - > codec ; char buf[256] ; int i ; AVCodec * c ; const char * c_name ; / * See if we can handle this kind of payload . * The space should normally not be there but some Real streams or * particular servers ( RealServer Version 6 . 1 . 3 . 970 , see issue 1658 ) * have a trailing space . * / get_word_sep ( buf , sizeof ( buf ) , / , & p ) ; if ( payload_type < RTP_PT_PRIVATE ) { / * We are in a standard case * ( from http : //www . iana . org/assignments/rtp - parameters ) . * / codec - > codec_id = ff_rtp_codec_id ( buf , codec - > codec_type ) ; } if ( codec - > codec_id == AV_CODEC_ID_NONE ) { RTPDynamicProtocolHandler * handler = ff_rtp_handler_find_by_name ( buf , codec - > codec_type ) ; init_rtp_handler ( handler , rtsp_st , st ) ; / * If no dynamic handler was found , check with the list of standard * allocated types , if such a stream for some reason happens to * use a private payload type . This isn ' t handled in rtpdec . c , since * the format name from the rtpmap line never is passed into rtpdec . * / if ( ! rtsp_st - > dynamic_handler ) codec - > codec_id = ff_rtp_codec_id ( buf , codec - > codec_type ) ; } c = avcodec_find_decoder ( codec - > codec_id ) ; if ( c & & c - > name ) c_name = c - > name ; else c_name = ( null ) ; get_word_sep ( buf , sizeof ( buf ) , / , & p ) ; i = atoi ( buf ) ; switch ( codec - > codec_type ) { case AVMEDIA_TYPE_AUDIO : av_log ( s , AV_LOG_DEBUG , audio codec set to : %s\n , c_name ) ; codec - > sample_rate = RTSP_DEFAULT_AUDIO_SAMPLERATE ; codec - > channels = RTSP_DEFAULT_NB_AUDIO_CHANNELS ; if ( i > 0 ) { codec - > sample_rate = i ; avpriv_set_pts_info ( st , 32 , 1 , codec - > sample_rate ) ; get_word_sep ( buf , sizeof ( buf ) , / , & p ) ; i = atoi ( buf ) ; if ( i > 0 ) codec - > channels = i ; } av_log ( s , AV_LOG_DEBUG , audio samplerate set to : %i\n , codec - > sample_rate ) ; av_log ( s , AV_LOG_DEBUG , audio channels set to : %i\n , codec - > channels ) ; break ; case AVMEDIA_TYPE_VIDEO : av_log ( s , AV_LOG_DEBUG , video codec set to : %s\n , c_name ) ; if ( i > 0 ) avpriv_set_pts_info ( st , 32 , 1 , i ) ; break ; default : break ; } if ( rtsp_st - > dynamic_handler & & rtsp_st - > dynamic_handler - > init ) rtsp_st - > dynamic_handler - > init ( s , st - > index , rtsp_st - > dynamic_protocol_context ) ; return 0 ; }",1
"void ff_h264_filter_mb_fast ( const H264Context * h , H264SliceContext * sl , int mb_x , int mb_y , uint8_t * img_y , uint8_t * img_cb , uint8_t * img_cr , unsigned int linesize , unsigned int uvlinesize ) { assert ( ! FRAME_MBAFF ( h ) ) ; if ( ! h - > h264dsp . h264_loop_filter_strength || h - > pps . chroma_qp_diff ) { ff_h264_filter_mb ( h , sl , mb_x , mb_y , img_y , img_cb , img_cr , linesize , uvlinesize ) ; return ; } if CONFIG_SMALL h264_filter_mb_fast_internal ( h , sl , mb_x , mb_y , img_y , img_cb , img_cr , linesize , uvlinesize , h - > pixel_shift ) ; else if ( h - > pixel_shift ) { h264_filter_mb_fast_internal ( h , sl , mb_x , mb_y , img_y , img_cb , img_cr , linesize , uvlinesize , 1 ) ; } else { h264_filter_mb_fast_internal ( h , sl , mb_x , mb_y , img_y , img_cb , img_cr , linesize , uvlinesize , 0 ) ; } endif }",0
"void ff_dsputil_init_ppc ( DSPContext * c , AVCodecContext * avctx ) { const int high_bit_depth = avctx - > bits_per_raw_sample > 8 ; // Common optimizations whether AltiVec is available or not c - > prefetch = prefetch_ppc ; if ( ! high_bit_depth ) { switch ( check_dcbzl_effect ( ) ) { case 32 : c - > clear_blocks = clear_blocks_dcbz32_ppc ; break ; case 128 : c - > clear_blocks = clear_blocks_dcbz128_ppc ; break ; default : break ; } } if HAVE_ALTIVEC if ( CONFIG_H264_DECODER ) ff_dsputil_h264_init_ppc ( c , avctx ) ; if ( av_get_cpu_flags ( ) & AV_CPU_FLAG_ALTIVEC ) { ff_dsputil_init_altivec ( c , avctx ) ; ff_float_init_altivec ( c , avctx ) ; ff_int_init_altivec ( c , avctx ) ; c - > gmc1 = ff_gmc1_altivec ; if CONFIG_ENCODERS if ( avctx - > bits_per_raw_sample < = 8 & & ( avctx - > dct_algo == FF_DCT_AUTO || avctx - > dct_algo == FF_DCT_ALTIVEC ) ) { c - > fdct = ff_fdct_altivec ; } endif //CONFIG_ENCODERS if ( avctx - > bits_per_raw_sample < = 8 ) { if ( ( avctx - > idct_algo == FF_IDCT_AUTO ) || ( avctx - > idct_algo == FF_IDCT_ALTIVEC ) ) { c - > idct_put = ff_idct_put_altivec ; c - > idct_add = ff_idct_add_altivec ; c - > idct_permutation_type = FF_TRANSPOSE_IDCT_PERM ; } else if ( ( CONFIG_VP3_DECODER || CONFIG_VP5_DECODER || CONFIG_VP6_DECODER ) & & avctx - > idct_algo==FF_IDCT_VP3 ) { c - > idct_put = ff_vp3_idct_put_altivec ; c - > idct_add = ff_vp3_idct_add_altivec ; c - > idct = ff_vp3_idct_altivec ; c - > idct_permutation_type = FF_TRANSPOSE_IDCT_PERM ; } } } endif / * HAVE_ALTIVEC * / }",0
"static int ffm_is_avail_data ( AVFormatContext * s , int size ) { FFMContext * ffm = s - > priv_data ; int64_t pos , avail_size ; int len ; len = ffm - > packet_end - ffm - > packet_ptr ; if ( size < = len ) return 1 ; pos = avio_tell ( s - > pb ) ; if ( ! ffm - > write_index ) { if ( pos == ffm - > file_size ) return AVERROR_EOF ; avail_size = ffm - > file_size - pos ; } else { if ( pos == ffm - > write_index ) { / * exactly at the end of stream * / if ( ffm - > server_attached ) return AVERROR ( EAGAIN ) ; else return AVERROR_INVALIDDATA ; } else if ( pos < ffm - > write_index ) { avail_size = ffm - > write_index - pos ; } else { avail_size = ( ffm - > file_size - pos ) + ( ffm - > write_index - FFM_PACKET_SIZE ) ; } } avail_size = ( avail_size / ffm - > packet_size ) * ( ffm - > packet_size - FFM_HEADER_SIZE ) + len ; if ( size < = avail_size ) return 1 ; else if ( ffm - > server_attached ) return AVERROR ( EAGAIN ) ; else return AVERROR_INVALIDDATA ; }",1
"static int execute_ref_pic_marking ( H264Context * h , MMCO * mmco , int mmco_count ) { MpegEncContext * const s = & h - > s ; int i , j ; int current_ref_assigned=0 ; Picture * pic ; if ( ( s - > avctx - > debug & FF_DEBUG_MMCO ) & & mmco_count==0 ) av_log ( h - > s . avctx , AV_LOG_DEBUG , no mmco here\n ) ; for ( i=0 ; i < mmco_count ; i + + ) { int structure , frame_num , unref_pic ; if ( s - > avctx - > debug & FF_DEBUG_MMCO ) av_log ( h - > s . avctx , AV_LOG_DEBUG , mmco : %d %d %d\n , h - > mmco[i] . opcode , h - > mmco[i] . short_pic_num , h - > mmco[i] . long_arg ) ; switch ( mmco[i] . opcode ) { case MMCO_SHORT2UNUSED : if ( s - > avctx - > debug & FF_DEBUG_MMCO ) av_log ( h - > s . avctx , AV_LOG_DEBUG , mmco : unref short %d count %d\n , h - > mmco[i] . short_pic_num , h - > short_ref_count ) ; frame_num = pic_num_extract ( h , mmco[i] . short_pic_num , & structure ) ; pic = find_short ( h , frame_num , & j ) ; if ( pic ) { if ( unreference_pic ( h , pic , structure PICT_FRAME ) ) remove_short_at_index ( h , j ) ; } else if ( s - > avctx - > debug & FF_DEBUG_MMCO ) av_log ( h - > s . avctx , AV_LOG_DEBUG , mmco : unref short failure\n ) ; case MMCO_SHORT2LONG : if ( FIELD_PICTURE & & mmco[i] . long_arg < h - > long_ref_count & & h - > long_ref[mmco[i] . long_arg] - > frame_num == mmco[i] . short_pic_num / 2 ) { / * do nothing , we ' ve already moved this field pair . * / int frame_num = mmco[i] . short_pic_num > > FIELD_PICTURE ; pic= remove_long ( h , mmco[i] . long_arg ) ; if ( pic ) unreference_pic ( h , pic , 0 ) ; h - > long_ref[ mmco[i] . long_arg ]= remove_short ( h , frame_num ) ; if ( h - > long_ref[ mmco[i] . long_arg ] ) { h - > long_ref[ mmco[i] . long_arg ] - > long_ref=1 ; h - > long_ref_count + + ; case MMCO_LONG2UNUSED : j = pic_num_extract ( h , mmco[i] . long_arg , & structure ) ; pic = h - > long_ref[j] ; if ( pic ) { if ( unreference_pic ( h , pic , structure PICT_FRAME ) ) remove_long_at_index ( h , j ) ; } else if ( s - > avctx - > debug & FF_DEBUG_MMCO ) av_log ( h - > s . avctx , AV_LOG_DEBUG , mmco : unref long failure\n ) ; case MMCO_LONG : unref_pic = 1 ; if ( FIELD_PICTURE & & ! s - > first_field ) { if ( h - > long_ref[mmco[i] . long_arg] == s - > current_picture_ptr ) { / * Just mark second field as referenced * / unref_pic = 0 ; } else if ( s - > current_picture_ptr - > reference ) { / * First field in pair is in short term list or * at a different long term index . * This is not allowed ; see 7 . 4 . 3 , notes 2 and 3 . * Report the problem and keep the pair where it is , * and mark this field valid . illegal long term reference assignment for second field in complementary field pair ( first field is short term or has non - matching long index ) \n ) ; unref_pic = 0 ; if ( unref_pic ) { pic= remove_long ( h , mmco[i] . long_arg ) ; if ( pic ) unreference_pic ( h , pic , 0 ) ; h - > long_ref[ mmco[i] . long_arg ]= s - > current_picture_ptr ; h - > long_ref[ mmco[i] . long_arg ] - > long_ref=1 ; h - > long_ref_count + + ; s - > current_picture_ptr - > reference |= s - > picture_structure ; current_ref_assigned=1 ; case MMCO_SET_MAX_LONG : assert ( mmco[i] . long_arg < = 16 ) ; // just remove the long term which index is greater than new max for ( j = mmco[i] . long_arg ; j < 16 ; j + + ) { pic = remove_long ( h , j ) ; if ( pic ) unreference_pic ( h , pic , 0 ) ; case MMCO_RESET : while ( h - > short_ref_count ) { pic= remove_short ( h , h - > short_ref[0] - > frame_num ) ; if ( pic ) unreference_pic ( h , pic , 0 ) ; for ( j = 0 ; j < 16 ; j + + ) { pic= remove_long ( h , j ) ; if ( pic ) unreference_pic ( h , pic , 0 ) ; default : assert ( 0 ) ; if ( ! current_ref_assigned & & FIELD_PICTURE & & ! s - > first_field & & s - > current_picture_ptr - > reference ) { / * Second field of complementary field pair ; the first field of * which is already referenced . If short referenced , it * should be first entry in short_ref . If not , it must exist * in long_ref ; trying to put it on the short list here is an * error in the encoded bit stream ( ref : 7 . 4 . 3 , NOTE 2 and 3 ) . if ( h - > short_ref_count & & h - > short_ref[0] == s - > current_picture_ptr ) { / * Just mark the second field valid * / s - > current_picture_ptr - > reference = PICT_FRAME ; } else if ( s - > current_picture_ptr - > long_ref ) { av_log ( h - > s . avctx , AV_LOG_ERROR , illegal short term reference assignment for second field in complementary field pair ( first field is long term ) \n ) ; / * * First field in reference , but not in any sensible place on our * reference lists . This shouldn ' t happen unless reference * handling somewhere else is wrong . assert ( 0 ) ; current_ref_assigned = 1 ; if ( ! current_ref_assigned ) { pic= remove_short ( h , s - > current_picture_ptr - > frame_num ) ; if ( pic ) { unreference_pic ( h , pic , 0 ) ; av_log ( h - > s . avctx , AV_LOG_ERROR , illegal short term buffer state detected\n ) ; if ( h - > short_ref_count ) memmove ( & h - > short_ref[1] , & h - > short_ref[0] , h - > short_ref_count * sizeof ( Picture * ) ) ; h - > short_ref[0]= s - > current_picture_ptr ; h - > short_ref[0] - > long_ref=0 ; h - > short_ref_count + + ; s",1
"static void filter_samples ( AVFilterLink * inlink , AVFilterBufferRef * samplesref ) { AVFilterContext * ctx = inlink - > dst ; ShowInfoContext * showinfo = ctx - > priv ; uint32_t plane_checksum[8] = { 0 } , checksum = 0 ; char chlayout_str[128] ; int plane ; for ( plane = 0 ; samplesref - > data[plane] & & plane < 8 ; plane + + ) { uint8_t * data = samplesref - > data[plane] ; int linesize = samplesref - > linesize[plane] ; plane_checksum[plane] = av_adler32_update ( plane_checksum[plane] , data , linesize ) ; checksum = av_adler32_update ( checksum , data , linesize ) ; } av_get_channel_layout_string ( chlayout_str , sizeof ( chlayout_str ) , - 1 , samplesref - > audio - > channel_layout ) ; av_log ( ctx , AV_LOG_INFO , n : %d pts : % PRId64 pts_time : %f pos : % PRId64 fmt : %s chlayout : %s nb_samples : %d rate : %d planar : %d checksum : %u plane_checksum[%u %u %u %u %u %u %u %u]\n , showinfo - > frame , samplesref - > pts , samplesref - > pts * av_q2d ( inlink - > time_base ) , samplesref - > pos , av_get_sample_fmt_name ( samplesref - > format ) , chlayout_str , samplesref - > audio - > nb_samples , samplesref - > audio - > sample_rate , samplesref - > audio - > planar , checksum , plane_checksum[0] , plane_checksum[1] , plane_checksum[2] , plane_checksum[3] , plane_checksum[4] , plane_checksum[5] , plane_checksum[6] , plane_checksum[7] ) ; showinfo - > frame + + ; avfilter_filter_samples ( inlink - > dst - > outputs[0] , samplesref ) ; }",0
"static av_cold int vaapi_encode_init_rate_control ( AVCodecContext * avctx ) { VAAPIEncodeContext * ctx = avctx - > priv_data ; int hrd_buffer_size ; int hrd_initial_buffer_fullness ; if ( avctx - > rc_buffer_size ) hrd_buffer_size = avctx - > rc_buffer_size ; else hrd_buffer_size = avctx - > bit_rate ; if ( avctx - > rc_initial_buffer_occupancy ) hrd_initial_buffer_fullness = avctx - > rc_initial_buffer_occupancy ; else hrd_initial_buffer_fullness = hrd_buffer_size * 3 / 4 ; ctx - > rc_params . misc . type = VAEncMiscParameterTypeRateControl ; ctx - > rc_params . rc = ( VAEncMiscParameterRateControl ) { . bits_per_second = avctx - > bit_rate , . target_percentage = 66 , . window_size = 1000 , . initial_qp = ( avctx - > qmax > = 0 ? avctx - > qmax : 40 ) , . min_qp = ( avctx - > qmin > = 0 ? avctx - > qmin : 18 ) , . basic_unit_size = 0 , } ; ctx - > global_params[ctx - > nb_global_params] = & ctx - > rc_params . misc ; ctx - > global_params_size[ctx - > nb_global_params + + ] = sizeof ( ctx - > rc_params ) ; ctx - > hrd_params . misc . type = VAEncMiscParameterTypeHRD ; ctx - > hrd_params . hrd = ( VAEncMiscParameterHRD ) { . initial_buffer_fullness = hrd_initial_buffer_fullness , . buffer_size = hrd_buffer_size , } ; ctx - > global_params[ctx - > nb_global_params] = & ctx - > hrd_params . misc ; ctx - > global_params_size[ctx - > nb_global_params + + ] = sizeof ( ctx - > hrd_params ) ; return 0 ; }",0
"static int mp3_write_xing ( AVFormatContext * s ) { MP3Context * mp3 = s - > priv_data ; AVCodecContext * codec = s - > streams[mp3 - > audio_stream_idx] - > codec ; AVDictionaryEntry * enc = av_dict_get ( s - > streams[mp3 - > audio_stream_idx] - > metadata , encoder , NULL , 0 ) ; AVIOContext * dyn_ctx ; int32_t header ; MPADecodeHeader mpah ; int srate_idx , i , channels ; int bitrate_idx ; int best_bitrate_idx = - 1 ; int best_bitrate_error = INT_MAX ; int ret ; int ver = 0 ; int bytes_needed ; if ( ! s - > pb - > seekable || ! mp3 - > write_xing ) return 0 ; for ( i = 0 ; i < FF_ARRAY_ELEMS ( avpriv_mpa_freq_tab ) ; i + + ) { const uint16_t base_freq = avpriv_mpa_freq_tab[i] ; if ( codec - > sample_rate == base_freq ) ver = 0x3 ; // MPEG 1 else if ( codec - > sample_rate == base_freq / 2 ) ver = 0x2 ; // MPEG 2 else if ( codec - > sample_rate == base_freq / 4 ) ver = 0x0 ; // MPEG 2 . 5 else continue ; srate_idx = i ; break ; } if ( i == FF_ARRAY_ELEMS ( avpriv_mpa_freq_tab ) ) { av_log ( s , AV_LOG_WARNING , Unsupported sample rate , not writing Xing header . \n ) ; return - 1 ; } switch ( codec - > channels ) { case 1 : channels = MPA_MONO ; break ; case 2 : channels = MPA_STEREO ; break ; default : av_log ( s , AV_LOG_WARNING , Unsupported number of channels , not writing Xing header . \n ) ; return - 1 ; } / * dummy MPEG audio header * / header = 0xffU < < 24 ; // sync header |= ( 0x7 < < 5 | ver < < 3 | 0x1 < < 1 | 0x1 ) < < 16 ; // sync/audio - version/layer 3/no crc * / header |= ( srate_idx < < 2 ) < < 8 ; header |= channels < < 6 ; for ( bitrate_idx = 1 ; bitrate_idx < 15 ; bitrate_idx + + ) { int bit_rate = 1000 * avpriv_mpa_bitrate_tab[ver ! = 3][3 - 1][bitrate_idx] ; int error = FFABS ( bit_rate - codec - > bit_rate ) ; if ( error < best_bitrate_error ) { best_bitrate_error = error ; best_bitrate_idx = bitrate_idx ; } } av_assert0 ( best_bitrate_idx > = 0 ) ; for ( bitrate_idx = best_bitrate_idx ; ; bitrate_idx + + ) { int32_t mask = bitrate_idx < < ( 4 + 8 ) ; if ( 15 == bitrate_idx ) return - 1 ; header |= mask ; avpriv_mpegaudio_decode_header ( & mpah , header ) ; mp3 - > xing_offset = xing_offtbl[mpah . lsf == 1][mpah . nb_channels == 1] + 4 ; bytes_needed = mp3 - > xing_offset + XING_SIZE ; if ( bytes_needed < = mpah . frame_size ) break ; header & = mask ; } ret = avio_open_dyn_buf ( & dyn_ctx ) ; if ( ret < 0 ) return ret ; avio_wb32 ( dyn_ctx , header ) ; ffio_fill ( dyn_ctx , 0 , mp3 - > xing_offset - 4 ) ; ffio_wfourcc ( dyn_ctx , Xing ) ; avio_wb32 ( dyn_ctx , 0x01 | 0x02 | 0x04 | 0x08 ) ; // frames / size / TOC / vbr scale mp3 - > size = mpah . frame_size ; mp3 - > want=1 ; mp3 - > seen=0 ; mp3 - > pos=0 ; avio_wb32 ( dyn_ctx , 0 ) ; // frames avio_wb32 ( dyn_ctx , 0 ) ; // size // TOC for ( i = 0 ; i < XING_TOC_SIZE ; i + + ) avio_w8 ( dyn_ctx , ( uint8_t ) ( 255 * i / XING_TOC_SIZE ) ) ; // vbr quality // we write it , because some ( broken ) tools always expect it to be present avio_wb32 ( dyn_ctx , 0 ) ; // encoder short version string if ( enc ) { uint8_t encoder_str[9] = { 0 } ; if ( strlen ( enc - > value ) > sizeof ( encoder_str ) & & ! strcmp ( Lavc libmp3lame , enc - > value ) ) { memcpy ( encoder_str , Lavf lame , 9 ) ; } else memcpy ( encoder_str , enc - > value , FFMIN ( strlen ( enc - > value ) , sizeof ( encoder_str ) ) ) ; avio_write ( dyn_ctx , encoder_str , sizeof ( encoder_str ) ) ; } else avio_write ( dyn_ctx , Lavf\0\0\0\0\0 , 9 ) ; avio_w8 ( dyn_ctx , 0 ) ; // tag revision 0 / unknown vbr method avio_w8 ( dyn_ctx , 0 ) ; // unknown lowpass filter value ffio_fill ( dyn_ctx , 0 , 8 ) ; // empty replaygain fields avio_w8 ( dyn_ctx , 0 ) ; // unknown encoding flags avio_w8 ( dyn_ctx , 0 ) ; // unknown abr/minimal bitrate // encoder delay if ( codec - > initial_padding - 528 - 1 > = 1 < < 12 ) { av_log ( s , AV_LOG_WARNING , Too many samples of initial padding . \n ) ; } avio_wb24 ( dyn_ctx , FFMAX ( codec - > initial_padding - 528 - 1 , 0 ) < < 12 ) ; avio_w8 ( dyn_ctx , 0 ) ; // misc avio_w8 ( dyn_ctx , 0 ) ; // mp3gain avio_wb16 ( dyn_ctx , 0 ) ; // preset // audio length and CRCs ( will be updated later ) avio_wb32 ( dyn_ctx , 0 ) ; // music length avio_wb16 ( dyn_ctx , 0 ) ; // music crc avio_wb16 ( dyn_ctx , 0 ) ; // tag crc ffio_fill ( dyn_ctx , 0 , mpah . frame_size - bytes_needed ) ; mp3 - > xing_frame_size = avio_close_dyn_buf ( dyn_ctx , & mp3 - > xing_frame ) ; mp3 - > xing_frame_offset = avio_tell ( s - > pb ) ; avio_write ( s - > pb , mp3 - > xing_frame , mp3 - > xing_frame_size ) ; mp3 - > audio_size = mp3 - > xing_frame_size ; return 0 ; }",0
"static void compute_pkt_fields ( AVFormatContext * s , AVStream * st , AVCodecParserContext * pc , AVPacket * pkt ) { int num , den , presentation_delayed ; / * handle wrapping * / if ( st - > cur_dts ! = AV_NOPTS_VALUE ) { if ( pkt - > pts ! = AV_NOPTS_VALUE ) pkt - > pts= lsb2full ( pkt - > pts , st - > cur_dts , st - > pts_wrap_bits ) ; if ( pkt - > dts ! = AV_NOPTS_VALUE ) pkt - > dts= lsb2full ( pkt - > dts , st - > cur_dts , st - > pts_wrap_bits ) ; } if ( pkt - > duration == 0 ) { compute_frame_duration ( & num , & den , s , st , pc , pkt ) ; if ( den & & num ) { pkt - > duration = av_rescale ( 1 , num * ( int64_t ) st - > time_base . den , den * ( int64_t ) st - > time_base . num ) ; } } / * do we have a video B frame ? * / presentation_delayed = 0 ; if ( st - > codec . codec_type == CODEC_TYPE_VIDEO ) { / * XXX : need has_b_frame , but cannot get it if the codec is not initialized * / if ( ( st - > codec . codec_id == CODEC_ID_MPEG1VIDEO || st - > codec . codec_id == CODEC_ID_MPEG2VIDEO || st - > codec . codec_id == CODEC_ID_MPEG4 || st - > codec . codec_id == CODEC_ID_H264 ) & & pc & & pc - > pict_type ! = FF_B_TYPE ) presentation_delayed = 1 ; / * this may be redundant , but it shouldnt hurt * / if ( pkt - > dts ! = AV_NOPTS_VALUE & & pkt - > pts ! = AV_NOPTS_VALUE & & pkt - > pts > pkt - > dts ) presentation_delayed = 1 ; } if ( st - > cur_dts == AV_NOPTS_VALUE ) { if ( presentation_delayed ) st - > cur_dts = - pkt - > duration ; else st - > cur_dts = 0 ; } // av_log ( NULL , AV_LOG_DEBUG , IN delayed : %d pts : %lld , dts : %lld cur_dts : %lld\n , presentation_delayed , pkt - > pts , pkt - > dts , st - > cur_dts ) ; / * interpolate PTS and DTS if they are not present * / if ( presentation_delayed ) { / * DTS = decompression time stamp * / / * PTS = presentation time stamp * / if ( pkt - > dts == AV_NOPTS_VALUE ) { / * if we know the last pts , use it * / if ( st - > last_IP_pts ! = AV_NOPTS_VALUE ) st - > cur_dts = pkt - > dts = st - > last_IP_pts ; else pkt - > dts = st - > cur_dts ; } else { st - > cur_dts = pkt - > dts ; } / * this is tricky : the dts must be incremented by the duration of the frame we are displaying , i . e . the last I or P frame * / if ( st - > last_IP_duration == 0 ) st - > cur_dts + = pkt - > duration ; else st - > cur_dts + = st - > last_IP_duration ; st - > last_IP_duration = pkt - > duration ; st - > last_IP_pts= pkt - > pts ; / * cannot compute PTS if not present ( we can compute it only by knowing the futur * / } else { / * presentation is not delayed : PTS and DTS are the same * / if ( pkt - > pts == AV_NOPTS_VALUE ) { if ( pkt - > dts == AV_NOPTS_VALUE ) { pkt - > pts = st - > cur_dts ; pkt - > dts = st - > cur_dts ; } else { st - > cur_dts = pkt - > dts ; pkt - > pts = pkt - > dts ; } } else { st - > cur_dts = pkt - > pts ; pkt - > dts = pkt - > pts ; } st - > cur_dts + = pkt - > duration ; } // av_log ( NULL , AV_LOG_DEBUG , OUTdelayed : %d pts : %lld , dts : %lld cur_dts : %lld\n , presentation_delayed , pkt - > pts , pkt - > dts , st - > cur_dts ) ; / * update flags * / if ( pc ) { pkt - > flags = 0 ; / * key frame computation * / switch ( st - > codec . codec_type ) { case CODEC_TYPE_VIDEO : if ( pc - > pict_type == FF_I_TYPE ) pkt - > flags |= PKT_FLAG_KEY ; break ; case CODEC_TYPE_AUDIO : pkt - > flags |= PKT_FLAG_KEY ; break ; default : break ; } } / * convert the packet time stamp units * / if ( pkt - > pts ! = AV_NOPTS_VALUE ) pkt - > pts = av_rescale ( pkt - > pts , AV_TIME_BASE * ( int64_t ) st - > time_base . num , st - > time_base . den ) ; if ( pkt - > dts ! = AV_NOPTS_VALUE ) pkt - > dts = av_rescale ( pkt - > dts , AV_TIME_BASE * ( int64_t ) st - > time_base . num , st - > time_base . den ) ; / * duration field * / pkt - > duration = av_rescale ( pkt - > duration , AV_TIME_BASE * ( int64_t ) st - > time_base . num , st - > time_base . den ) ; }",0
"static int ffm_read_packet ( AVFormatContext * s , AVPacket * pkt ) { int size ; FFMContext * ffm = s - > priv_data ; int duration , ret ; switch ( ffm - > read_state ) { case READ_HEADER : if ( ( ret = ffm_is_avail_data ( s , FRAME_HEADER_SIZE + 4 ) ) < 0 ) return ret ; av_dlog ( s , pos=%08 PRIx64 spos=% PRIx64 , write_index=% PRIx64 size=% PRIx64 \n , avio_tell ( s - > pb ) , s - > pb - > pos , ffm - > write_index , ffm - > file_size ) ; if ( ffm_read_data ( s , ffm - > header , FRAME_HEADER_SIZE , 1 ) ! = FRAME_HEADER_SIZE ) return - 1 ; if ( ffm - > header[1] & FLAG_DTS ) if ( ffm_read_data ( s , ffm - > header + 16 , 4 , 1 ) ! = 4 ) return - 1 ; ffm - > read_state = READ_DATA ; / * fall thru * / case READ_DATA : size = AV_RB24 ( ffm - > header + 2 ) ; if ( ( ret = ffm_is_avail_data ( s , size ) ) < 0 ) return ret ; duration = AV_RB24 ( ffm - > header + 5 ) ; av_new_packet ( pkt , size ) ; pkt - > stream_index = ffm - > header[0] ; if ( ( unsigned ) pkt - > stream_index > = s - > nb_streams ) { av_log ( s , AV_LOG_ERROR , invalid stream index %d\n , pkt - > stream_index ) ; av_free_packet ( pkt ) ; ffm - > read_state = READ_HEADER ; return - 1 ; } pkt - > pos = avio_tell ( s - > pb ) ; if ( ffm - > header[1] & FLAG_KEY_FRAME ) pkt - > flags |= AV_PKT_FLAG_KEY ; ffm - > read_state = READ_HEADER ; if ( ffm_read_data ( s , pkt - > data , size , 0 ) ! = size ) { / * bad case : desynchronized packet . we cancel all the packet loading * / av_free_packet ( pkt ) ; return - 1 ; } pkt - > pts = AV_RB64 ( ffm - > header + 8 ) ; if ( ffm - > header[1] & FLAG_DTS ) pkt - > dts = pkt - > pts - AV_RB32 ( ffm - > header + 16 ) ; else pkt - > dts = pkt - > pts ; pkt - > duration = duration ; break ; } return 0 ; }",0
"static int vda_h264_start_frame ( AVCodecContext * avctx , av_unused const uint8_t * buffer , av_unused uint32_t size ) { VDAContext * vda = avctx - > internal - > hwaccel_priv_data ; struct vda_context * vda_ctx = avctx - > hwaccel_context ; if ( ! vda_ctx - > decoder ) return - 1 ; vda - > bitstream_size = 0 ; return 0 ; }",0
"static void colored_fputs ( int level , int tint , const char * str ) { if ( ! * str ) return ; if ( use_color < 0 ) check_color_terminal ( ) ; if defined ( _WIN32 ) & & ! defined ( __MINGW32CE__ ) & & HAVE_SETCONSOLETEXTATTRIBUTE if ( use_color & & level ! = AV_LOG_INFO/8 ) SetConsoleTextAttribute ( con , background | color[level] ) ; fputs ( str , stderr ) ; if ( use_color & & level ! = AV_LOG_INFO/8 ) SetConsoleTextAttribute ( con , attr_orig ) ; else if ( use_color == 1 & & level ! = AV_LOG_INFO/8 ) { fprintf ( stderr , \033[%d ; 3%dm%s\033[0m , ( color[level] > > 4 ) & 15 , color[level] & 15 , str ) ; } else if ( tint & & use_color == 256 ) { fprintf ( stderr , \033[48 ; 5 ; %dm\033[38 ; 5 ; %dm%s\033[0m , ( color[level] > > 16 ) & 0xff , tint , str ) ; } else if ( use_color == 256 & & level ! = AV_LOG_INFO/8 ) { fprintf ( stderr , \033[48 ; 5 ; %dm\033[38 ; 5 ; %dm%s\033[0m , ( color[level] > > 16 ) & 0xff , ( color[level] > > 8 ) & 0xff , str ) ; } else fputs ( str , stderr ) ; endif }",0
"static int aasc_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; AascContext * s = avctx - > priv_data ; int compr , i , stride , ret ; s - > frame . reference = 1 ; s - > frame . buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE ; if ( ( ret = avctx - > reget_buffer ( avctx , & s - > frame ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , reget_buffer ( ) failed\n ) ; return ret ; } compr = AV_RL32 ( buf ) ; buf + = 4 ; buf_size - = 4 ; switch ( compr ) { case 0 : stride = ( avctx - > width * 3 + 3 ) & 3 ; for ( i = avctx - > height - 1 ; i > = 0 ; i - - ) { memcpy ( s - > frame . data[0] + i * s - > frame . linesize[0] , buf , avctx - > width * 3 ) ; buf + = stride ; } break ; case 1 : bytestream2_init ( & s - > gb , buf - 4 , buf_size + 4 ) ; ff_msrle_decode ( avctx , ( AVPicture * ) & s - > frame , 8 , & s - > gb ) ; break ; default : av_log ( avctx , AV_LOG_ERROR , Unknown compression type %d\n , compr ) ; return AVERROR_INVALIDDATA ; } * got_frame = 1 ; * ( AVFrame * ) data = s - > frame ; / * report that the buffer was completely consumed * / return buf_size ; }",0
"static int rv10_decode_packet ( AVCodecContext * avctx , uint8_t * buf , int buf_size ) { MpegEncContext * s = avctx - > priv_data ; int i , mb_count , mb_pos , left ; init_get_bits ( & s - > gb , buf , buf_size * 8 ) ; if 0 for ( i=0 ; i < buf_size * 8 & & i < 200 ; i + + ) printf ( %d , get_bits1 ( & s - > gb ) ) ; printf ( \n ) ; return 0 ; endif if ( s - > codec_id ==CODEC_ID_RV10 ) mb_count = rv10_decode_picture_header ( s ) ; else mb_count = rv20_decode_picture_header ( s ) ; if ( mb_count < 0 ) { av_log ( s - > avctx , AV_LOG_ERROR , HEADER ERROR\n ) ; return - 1 ; } if ( s - > mb_x > = s - > mb_width || s - > mb_y > = s - > mb_height ) { av_log ( s - > avctx , AV_LOG_ERROR , POS ERROR %d %d\n , s - > mb_x , s - > mb_y ) ; return - 1 ; } mb_pos = s - > mb_y * s - > mb_width + s - > mb_x ; left = s - > mb_width * s - > mb_height - mb_pos ; if ( mb_count > left ) { av_log ( s - > avctx , AV_LOG_ERROR , COUNT ERROR\n ) ; return - 1 ; } //if ( s - > pict_type == P_TYPE ) return 0 ; if ( s - > mb_x == 0 & & s - > mb_y == 0 ) { if ( MPV_frame_start ( s , avctx ) < 0 ) return - 1 ; } ifdef DEBUG printf ( qscale=%d\n , s - > qscale ) ; endif / * default quantization values * / if ( s - > codec_id== CODEC_ID_RV10 ) { if ( s - > mb_y==0 ) s - > first_slice_line=1 ; } else { s - > first_slice_line=1 ; s - > resync_mb_x= s - > mb_x ; s - > resync_mb_y= s - > mb_y ; } if ( s - > h263_aic ) { s - > y_dc_scale_table= s - > c_dc_scale_table= ff_aic_dc_scale_table ; } else { s - > y_dc_scale_table= s - > c_dc_scale_table= ff_mpeg1_dc_scale_table ; } if ( s - > modified_quant ) s - > chroma_qscale_table= ff_h263_chroma_qscale_table ; ff_set_qscale ( s , s - > qscale ) ; s - > rv10_first_dc_coded[0] = 0 ; s - > rv10_first_dc_coded[1] = 0 ; s - > rv10_first_dc_coded[2] = 0 ; s - > block_wrap[0]= s - > block_wrap[1]= s - > block_wrap[2]= s - > block_wrap[3]= s - > mb_width * 2 + 2 ; s - > block_wrap[4]= s - > block_wrap[5]= s - > mb_width + 2 ; ff_init_block_index ( s ) ; / * decode each macroblock * / for ( i=0 ; i < mb_count ; i + + ) { int ret ; ff_update_block_index ( s ) ; ifdef DEBUG printf ( * * mb x=%d y=%d\n , s - > mb_x , s - > mb_y ) ; endif s - > dsp . clear_blocks ( s - > block[0] ) ; s - > mv_dir = MV_DIR_FORWARD ; s - > mv_type = MV_TYPE_16X16 ; ret=ff_h263_decode_mb ( s , s - > block ) ; if ( ret == SLICE_ERROR ) { av_log ( s - > avctx , AV_LOG_ERROR , ERROR at MB %d %d\n , s - > mb_x , s - > mb_y ) ; return - 1 ; } ff_h263_update_motion_val ( s ) ; MPV_decode_mb ( s , s - > block ) ; if ( s - > loop_filter ) ff_h263_loop_filter ( s ) ; if ( + + s - > mb_x == s - > mb_width ) { s - > mb_x = 0 ; s - > mb_y + + ; ff_init_block_index ( s ) ; } if ( s - > mb_x == s - > resync_mb_x ) s - > first_slice_line=0 ; if ( ret == SLICE_END ) break ; } return buf_size ; }",1
"static void dwt_decode97_int ( DWTContext * s , int32_t * t ) { int lev ; int w = s - > linelen[s - > ndeclevels - 1][0] ; int h = s - > linelen[s - > ndeclevels - 1][1] ; int i ; int32_t * line = s - > i_linebuf ; int32_t * data = t ; / * position at index O of line range [0 - 5 , w + 5] cf . extend function * / line + = 5 ; for ( i = 0 ; i < w * h ; i + + ) data[i] * = 1 < < I_PRESHIFT ; for ( lev = 0 ; lev < s - > ndeclevels ; lev + + ) { int lh = s - > linelen[lev][0] , lv = s - > linelen[lev][1] , mh = s - > mod[lev][0] , mv = s - > mod[lev][1] , lp ; int32_t * l ; // HOR_SD l = line + mh ; for ( lp = 0 ; lp < lv ; lp + + ) { int i , j = 0 ; // rescale with interleaving for ( i = mh ; i < lh ; i + = 2 , j + + ) l[i] = ( ( data[w * lp + j] * I_LFTG_K ) + ( 1 < < 15 ) ) > > 16 ; for ( i = 1 - mh ; i < lh ; i + = 2 , j + + ) l[i] = data[w * lp + j] ; sr_1d97_int ( line , mh , mh + lh ) ; for ( i = 0 ; i < lh ; i + + ) data[w * lp + i] = l[i] ; } // VER_SD l = line + mv ; for ( lp = 0 ; lp < lh ; lp + + ) { int i , j = 0 ; // rescale with interleaving for ( i = mv ; i < lv ; i + = 2 , j + + ) l[i] = ( ( data[w * j + lp] * I_LFTG_K ) + ( 1 < < 15 ) ) > > 16 ; for ( i = 1 - mv ; i < lv ; i + = 2 , j + + ) l[i] = data[w * j + lp] ; sr_1d97_int ( line , mv , mv + lv ) ; for ( i = 0 ; i < lv ; i + + ) data[w * i + lp] = l[i] ; } } for ( i = 0 ; i < w * h ; i + + ) data[i] = ( data[i] + ( ( 1 < < I_PRESHIFT ) > > 1 ) ) > > I_PRESHIFT ; }",1
"static int asf_read_simple_index ( AVFormatContext * s , const GUIDParseTable * g ) { ASFContext * asf = s - > priv_data ; AVIOContext * pb = s - > pb ; AVStream * st = NULL ; uint64_t interval ; // index entry time interval in 100 ns units , usually it ' s 1s uint32_t pkt_num , nb_entries ; int32_t prev_pkt_num = - 1 ; int i , ret ; uint64_t size = avio_rl64 ( pb ) ; // simple index objects should be ordered by stream number , this loop tries to find // the first not indexed video stream for ( i = 0 ; i < asf - > nb_streams ; i + + ) { if ( ( asf - > asf_st[i] - > type == AVMEDIA_TYPE_VIDEO ) & & ! asf - > asf_st[i] - > indexed ) { asf - > asf_st[i] - > indexed = 1 ; st = s - > streams[asf - > asf_st[i] - > index] ; break ; } } if ( ! st ) { avio_skip ( pb , size - 24 ) ; // if there ' s no video stream , skip index object return 0 ; } avio_skip ( pb , 16 ) ; // skip File ID interval = avio_rl64 ( pb ) ; avio_skip ( pb , 4 ) ; nb_entries = avio_rl32 ( pb ) ; for ( i = 0 ; i < nb_entries ; i + + ) { pkt_num = avio_rl32 ( pb ) ; ret = avio_skip ( pb , 2 ) ; if ( ret < 0 ) { av_log ( s , AV_LOG_ERROR , Skipping failed in asf_read_simple_index . \n ) ; return ret ; } if ( prev_pkt_num ! = pkt_num ) { av_add_index_entry ( st , asf - > first_packet_offset + asf - > packet_size * pkt_num , av_rescale ( interval , i , 10000 ) , asf - > packet_size , 0 , AVINDEX_KEYFRAME ) ; prev_pkt_num = pkt_num ; } } asf - > is_simple_index = 1 ; align_position ( pb , asf - > offset , size ) ; return 0 ; }",1
static uint32_t read_long ( const unsigned char * p ) { return ( p[0] < < 24 ) | ( p[1] < < 16 ) | ( p[2] < < 8 ) |p[3] ; },1
"static void do_video_out ( AVFormatContext * s , OutputStream * ost , AVFrame * next_picture , double sync_ipts ) { int ret , format_video_sync ; AVPacket pkt ; AVCodecContext * enc = ost - > enc_ctx ; AVCodecContext * mux_enc = ost - > st - > codec ; int nb_frames , nb0_frames , i ; double delta , delta0 ; double duration = 0 ; int frame_size = 0 ; InputStream * ist = NULL ; AVFilterContext * filter = ost - > filter - > filter ; if ( ost - > source_index > = 0 ) ist = input_streams[ost - > source_index] ; if ( filter - > inputs[0] - > frame_rate . num > 0 & & filter - > inputs[0] - > frame_rate . den > 0 ) duration = 1/ ( av_q2d ( filter - > inputs[0] - > frame_rate ) * av_q2d ( enc - > time_base ) ) ; if ( ist & & ist - > st - > start_time ! = AV_NOPTS_VALUE & & ist - > st - > first_dts ! = AV_NOPTS_VALUE & & ost - > frame_rate . num ) duration = FFMIN ( duration , 1/ ( av_q2d ( ost - > frame_rate ) * av_q2d ( enc - > time_base ) ) ) ; if ( ! ost - > filters_script & & ! ost - > filters & & next_picture & & ist & & lrintf ( av_frame_get_pkt_duration ( next_picture ) * av_q2d ( ist - > st - > time_base ) / av_q2d ( enc - > time_base ) ) > 0 ) { duration = lrintf ( av_frame_get_pkt_duration ( next_picture ) * av_q2d ( ist - > st - > time_base ) / av_q2d ( enc - > time_base ) ) ; } if ( ! next_picture ) { //end , flushing nb0_frames = nb_frames = mid_pred ( ost - > last_nb0_frames[0] , ost - > last_nb0_frames[1] , ost - > last_nb0_frames[2] ) ; } else { delta0 = sync_ipts - ost - > sync_opts ; delta = delta0 + duration ; / * by default , we output a single frame * / nb0_frames = 0 ; nb_frames = 1 ; format_video_sync = video_sync_method ; if ( format_video_sync == VSYNC_AUTO ) { if ( ! strcmp ( s - > oformat - > name , avi ) ) { format_video_sync = VSYNC_VFR ; } else format_video_sync = ( s - > oformat - > flags & AVFMT_VARIABLE_FPS ) ? ( ( s - > oformat - > flags & AVFMT_NOTIMESTAMPS ) ? VSYNC_PASSTHROUGH : VSYNC_VFR ) : VSYNC_CFR ; if ( ist & & format_video_sync == VSYNC_CFR & & input_files[ist - > file_index] - > ctx - > nb_streams == 1 & & input_files[ist - > file_index] - > input_ts_offset == 0 ) { format_video_sync = VSYNC_VSCFR ; } if ( format_video_sync == VSYNC_CFR & & copy_ts ) { format_video_sync = VSYNC_VSCFR ; } } if ( delta0 < 0 & & delta > 0 & & format_video_sync ! = VSYNC_PASSTHROUGH & & format_video_sync ! = VSYNC_DROP ) { double cor = FFMIN ( - delta0 , duration ) ; if ( delta0 < - 0 . 6 ) { av_log ( NULL , AV_LOG_WARNING , Past duration %f too large\n , - delta0 ) ; } else av_log ( NULL , AV_LOG_DEBUG , Cliping frame in rate conversion by %f\n , - delta0 ) ; sync_ipts + = cor ; duration - = cor ; delta0 + = cor ; } switch ( format_video_sync ) { case VSYNC_VSCFR : if ( ost - > frame_number == 0 & & delta - duration > = 0 . 5 ) { av_log ( NULL , AV_LOG_DEBUG , Not duplicating %d initial frames\n , ( int ) lrintf ( delta - duration ) ) ; delta = duration ; delta0 = 0 ; ost - > sync_opts = lrint ( sync_ipts ) ; } case VSYNC_CFR : // FIXME set to 0 . 5 after we fix some dts/pts bugs like in avidec . c if ( frame_drop_threshold & & delta < frame_drop_threshold & & ost - > frame_number ) { nb_frames = 0 ; } else if ( delta < - 1 . 1 ) nb_frames = 0 ; else if ( delta > 1 . 1 ) { nb_frames = lrintf ( delta ) ; if ( delta0 > 1 . 1 ) nb0_frames = lrintf ( delta0 - 0 . 6 ) ; } break ; case VSYNC_VFR : if ( delta < = - 0 . 6 ) nb_frames = 0 ; else if ( delta > 0 . 6 ) ost - > sync_opts = lrint ( sync_ipts ) ; break ; case VSYNC_DROP : case VSYNC_PASSTHROUGH : ost - > sync_opts = lrint ( sync_ipts ) ; break ; default : av_assert0 ( 0 ) ; } } nb_frames = FFMIN ( nb_frames , ost - > max_frames - ost - > frame_number ) ; nb0_frames = FFMIN ( nb0_frames , nb_frames ) ; memmove ( ost - > last_nb0_frames + 1 , ost - > last_nb0_frames , sizeof ( ost - > last_nb0_frames[0] ) * ( FF_ARRAY_ELEMS ( ost - > last_nb0_frames ) - 1 ) ) ; ost - > last_nb0_frames[0] = nb0_frames ; if ( nb0_frames == 0 & & ost - > last_droped ) { nb_frames_drop + + ; av_log ( NULL , AV_LOG_VERBOSE , * * * dropping frame %d from stream %d at ts % PRId64 \n , ost - > frame_number , ost - > st - > index , ost - > last_frame - > pts ) ; } if ( nb_frames > ( nb0_frames & & ost - > last_droped ) + ( nb_frames > nb0_frames ) ) { if ( nb_frames > dts_error_threshold * 30 ) { av_log ( NULL , AV_LOG_ERROR , %d frame duplication too large , skipping\n , nb_frames - 1 ) ; nb_frames_drop + + ; return ; } nb_frames_dup + = nb_frames - ( nb0_frames & & ost - > last_droped ) - ( nb_frames > nb0_frames ) ; av_log ( NULL , AV_LOG_VERBOSE , * * * %d dup ! \n , nb_frames - 1 ) ; } ost - > last_droped = nb_frames == nb0_frames & & next_picture ; / * duplicates frame if needed * / for ( i = 0 ; i < nb_frames ; i + + ) { AVFrame * in_picture ; av_init_packet ( & pkt ) ; pkt . data = NULL ; pkt . size = 0 ; if ( i < nb0_frames & & ost - > last_frame ) { in_picture = ost - > last_frame ; } else in_picture = next_picture ; if ( ! in_picture ) return ; in_picture - > pts = ost - > sync_opts ; if 1 if ( ! check_recording_time ( ost ) ) else if ( ost - > frame_number > = ost - > max_frames ) endif return ; if ( s - > oformat - > flags & AVFMT_RAWPICTURE & & enc - > codec - > id == AV_CODEC_ID_RAWVIDEO ) { / *",1
"static int read_header ( AVFormatContext * s ) { BRSTMDemuxContext * b = s - > priv_data ; int bom , major , minor , codec , chunk ; int64_t h1offset , pos , toffset ; uint32_t size , asize , start = 0 ; AVStream * st ; int ret = AVERROR_EOF ; int loop = 0 ; int bfstm = ! strcmp ( bfstm , s - > iformat - > name ) ; st = avformat_new_stream ( s , NULL ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; st - > codec - > codec_type = AVMEDIA_TYPE_AUDIO ; avio_skip ( s - > pb , 4 ) ; bom = avio_rb16 ( s - > pb ) ; if ( bom ! = 0xFEFF & & bom ! = 0xFFFE ) { av_log ( s , AV_LOG_ERROR , invalid byte order : %X\n , bom ) ; return AVERROR_INVALIDDATA ; } if ( bom == 0xFFFE ) b - > little_endian = 1 ; if ( ! bfstm ) { major = avio_r8 ( s - > pb ) ; minor = avio_r8 ( s - > pb ) ; avio_skip ( s - > pb , 4 ) ; // size of file size = read16 ( s ) ; if ( size < 14 ) return AVERROR_INVALIDDATA ; avio_skip ( s - > pb , size - 14 ) ; pos = avio_tell ( s - > pb ) ; if ( avio_rl32 ( s - > pb ) ! = MKTAG ( ' H ' , ' E ' , ' A ' , ' D ' ) ) return AVERROR_INVALIDDATA ; } else { uint32_t info_offset = 0 ; uint16_t section_count , header_size , i ; header_size = read16 ( s ) ; // 6 avio_skip ( s - > pb , 4 ) ; // Unknown constant 0x00030000 avio_skip ( s - > pb , 4 ) ; // size of file section_count = read16 ( s ) ; avio_skip ( s - > pb , 2 ) ; // padding for ( i = 0 ; avio_tell ( s - > pb ) < header_size & & ! ( start & & info_offset ) & & i < section_count ; i + + ) { uint16_t flag = read16 ( s ) ; avio_skip ( s - > pb , 2 ) ; switch ( flag ) { case 0x4000 : info_offset = read32 ( s ) ; / * info_size = * / read32 ( s ) ; break ; case 0x4001 : avio_skip ( s - > pb , 4 ) ; // seek offset avio_skip ( s - > pb , 4 ) ; // seek size break ; case 0x4002 : start = read32 ( s ) + 8 ; avio_skip ( s - > pb , 4 ) ; //data_size = read32 ( s ) ; break ; case 0x4003 : avio_skip ( s - > pb , 4 ) ; // REGN offset avio_skip ( s - > pb , 4 ) ; // REGN size break ; } } if ( ! info_offset || ! start ) return AVERROR_INVALIDDATA ; avio_skip ( s - > pb , info_offset - avio_tell ( s - > pb ) ) ; pos = avio_tell ( s - > pb ) ; if ( avio_rl32 ( s - > pb ) ! = MKTAG ( ' I ' , ' N ' , ' F ' , ' O ' ) ) return AVERROR_INVALIDDATA ; } size = read32 ( s ) ; if ( size < 192 ) return AVERROR_INVALIDDATA ; avio_skip ( s - > pb , 4 ) ; // unknown h1offset = read32 ( s ) ; if ( h1offset > size ) return AVERROR_INVALIDDATA ; avio_skip ( s - > pb , 12 ) ; toffset = read32 ( s ) + 16LL ; if ( toffset > size ) return AVERROR_INVALIDDATA ; avio_skip ( s - > pb , pos + h1offset + 8 - avio_tell ( s - > pb ) ) ; codec = avio_r8 ( s - > pb ) ; switch ( codec ) { case 0 : codec = AV_CODEC_ID_PCM_S8_PLANAR ; break ; case 1 : codec = b - > little_endian ? AV_CODEC_ID_PCM_S16LE_PLANAR : AV_CODEC_ID_PCM_S16BE_PLANAR ; break ; case 2 : codec = b - > little_endian ? AV_CODEC_ID_ADPCM_THP_LE : AV_CODEC_ID_ADPCM_THP ; break ; default : avpriv_request_sample ( s , codec %d , codec ) ; return AVERROR_PATCHWELCOME ; } loop = avio_r8 ( s - > pb ) ; // loop flag st - > codec - > codec_id = codec ; st - > codec - > channels = avio_r8 ( s - > pb ) ; if ( ! st - > codec - > channels ) return AVERROR_INVALIDDATA ; avio_skip ( s - > pb , 1 ) ; // padding st - > codec - > sample_rate = bfstm ? read32 ( s ) : read16 ( s ) ; if ( ! st - > codec - > sample_rate ) return AVERROR_INVALIDDATA ; if ( ! bfstm ) avio_skip ( s - > pb , 2 ) ; // padding if ( loop ) { if ( av_dict_set_int ( & s - > metadata , loop_start , av_rescale ( read32 ( s ) , AV_TIME_BASE , st - > codec - > sample_rate ) , 0 ) < 0 ) return AVERROR ( ENOMEM ) ; } else { avio_skip ( s - > pb , 4 ) ; } st - > start_time = 0 ; st - > duration = read32 ( s ) ; avpriv_set_pts_info ( st , 64 , 1 , st - > codec - > sample_rate ) ; if ( ! bfstm ) start = read32 ( s ) ; b - > current_block = 0 ; b - > block_count = read32 ( s ) ; if ( b - > block_count > UINT16_MAX ) { av_log ( s , AV_LOG_WARNING , too many blocks : %u\n , b - > block_count ) ; return AVERROR_INVALIDDATA ; } b - > block_size = read32 ( s ) ; if ( b - > block_size > UINT32_MAX / st - > codec - > channels ) return AVERROR_INVALIDDATA ; b - > samples_per_block = read32 ( s ) ; b - > last_block_used_bytes = read32 ( s ) ; b - > last_block_samples = read32 ( s ) ; b - > last_block_size = read32 ( s ) ; if ( b - > last_block_size > UINT32_MAX / st - > codec - > channels ) return AVERROR_INVALIDDATA ; if ( b - > last_block_used_bytes > b - > last_block_size ) return AVERROR_INVALIDDATA ; if ( codec == AV_CODEC_ID_ADPCM_THP || codec == AV_CODEC_ID_ADPCM_THP_LE ) { int ch ; avio_skip ( s - > pb , pos + toffset - avio_tell ( s - > pb ) ) ; if ( ! bfstm ) toffset = read32 ( s ) + 16LL ; else toffset = toffset + read32 (",1
"static inline void RENAME ( rgb15to16 ) ( const uint8_t * src , uint8_t * dst , unsigned src_size ) { register const uint8_t * s=src ; register uint8_t * d=dst ; register const uint8_t * end ; const uint8_t * mm_end ; end = s + src_size ; ifdef HAVE_MMX __asm __volatile ( PREFETCH %0 : : m ( * s ) ) ; __asm __volatile ( movq %0 , %%mm4 : : m ( mask15s ) ) ; mm_end = end - 15 ; while ( s < mm_end ) { __asm __volatile ( PREFETCH 32%1\n\t movq %1 , %%mm0\n\t movq 8%1 , %%mm2\n\t movq %%mm0 , %%mm1\n\t movq %%mm2 , %%mm3\n\t pand %%mm4 , %%mm0\n\t pand %%mm4 , %%mm2\n\t paddw %%mm1 , %%mm0\n\t paddw %%mm3 , %%mm2\n\t MOVNTQ %%mm0 , %0\n\t MOVNTQ %%mm2 , 8%0 : =m ( * d ) : m ( * s ) ) ; d + =16 ; s + =16 ; } __asm __volatile ( SFENCE : : : memory ) ; __asm __volatile ( EMMS : : : memory ) ; endif mm_end = end - 3 ; while ( s < mm_end ) { register unsigned x= * ( ( uint32_t * ) s ) ; * ( ( uint32_t * ) d ) = ( x & 0x7FFF7FFF ) + ( x & 0x7FE07FE0 ) ; d + =4 ; s + =4 ; } if ( s < end ) { register unsigned short x= * ( ( uint16_t * ) s ) ; * ( ( uint16_t * ) d ) = ( x & 0x7FFF ) + ( x & 0x7FE0 ) ; } }",1
"static int X264_frame ( AVCodecContext * ctx , AVPacket * pkt , const AVFrame * frame , int * got_packet ) { X264Context * x4 = ctx - > priv_data ; x264_nal_t * nal ; int nnal , i , ret ; x264_picture_t pic_out ; x264_picture_init ( & x4 - > pic ) ; x4 - > pic . img . i_csp = x4 - > params . i_csp ; if ( x264_bit_depth > 8 ) x4 - > pic . img . i_csp |= X264_CSP_HIGH_DEPTH ; x4 - > pic . img . i_plane = avfmt2_num_planes ( ctx - > pix_fmt ) ; if ( frame ) { for ( i = 0 ; i < x4 - > pic . img . i_plane ; i + + ) { x4 - > pic . img . plane[i] = frame - > data[i] ; x4 - > pic . img . i_stride[i] = frame - > linesize[i] ; } x4 - > pic . i_pts = frame - > pts ; x4 - > pic . i_type = frame - > pict_type == AV_PICTURE_TYPE_I ? X264_TYPE_KEYFRAME : frame - > pict_type == AV_PICTURE_TYPE_P ? X264_TYPE_P : frame - > pict_type == AV_PICTURE_TYPE_B ? X264_TYPE_B : X264_TYPE_AUTO ; if ( x4 - > params . b_interlaced & & x4 - > params . b_tff ! = frame - > top_field_first ) { x4 - > params . b_tff = frame - > top_field_first ; x264_encoder_reconfig ( x4 - > enc , & x4 - > params ) ; } if ( x4 - > params . vui . i_sar_height ! = ctx - > sample_aspect_ratio . den || x4 - > params . vui . i_sar_width ! = ctx - > sample_aspect_ratio . num ) { x4 - > params . vui . i_sar_height = ctx - > sample_aspect_ratio . den ; x4 - > params . vui . i_sar_width = ctx - > sample_aspect_ratio . num ; x264_encoder_reconfig ( x4 - > enc , & x4 - > params ) ; } } do { if ( x264_encoder_encode ( x4 - > enc , & nal , & nnal , frame ? & x4 - > pic : NULL , & pic_out ) < 0 ) return - 1 ; ret = encode_nals ( ctx , pkt , nal , nnal ) ; if ( ret < 0 ) return - 1 ; } while ( ! ret & & ! frame & & x264_encoder_delayed_frames ( x4 - > enc ) ) ; pkt - > pts = pic_out . i_pts ; pkt - > dts = pic_out . i_dts ; switch ( pic_out . i_type ) { case X264_TYPE_IDR : case X264_TYPE_I : x4 - > out_pic . pict_type = AV_PICTURE_TYPE_I ; break ; case X264_TYPE_P : x4 - > out_pic . pict_type = AV_PICTURE_TYPE_P ; break ; case X264_TYPE_B : case X264_TYPE_BREF : x4 - > out_pic . pict_type = AV_PICTURE_TYPE_B ; break ; } pkt - > flags |= AV_PKT_FLAG_KEY * pic_out . b_keyframe ; if ( ret ) x4 - > out_pic . quality = ( pic_out . i_qpplus1 - 1 ) * FF_QP2LAMBDA ; * got_packet = ret ; return 0 ; }",1
"static int http_server ( void ) { int server_fd , ret , rtsp_server_fd , delay , delay1 ; struct pollfd poll_table[HTTP_MAX_CONNECTIONS + 2] , * poll_entry ; HTTPContext * c , * c_next ; server_fd = socket_open_listen ( & my_http_addr ) ; if ( server_fd < 0 ) return - 1 ; rtsp_server_fd = socket_open_listen ( & my_rtsp_addr ) ; if ( rtsp_server_fd < 0 ) return - 1 ; http_log ( ffserver started . \n ) ; start_children ( first_feed ) ; first_http_ctx = NULL ; nb_connections = 0 ; first_http_ctx = NULL ; start_multicast ( ) ; for ( ; ; ) { poll_entry = poll_table ; poll_entry - > fd = server_fd ; poll_entry - > events = POLLIN ; poll_entry + + ; poll_entry - > fd = rtsp_server_fd ; poll_entry - > events = POLLIN ; poll_entry + + ; / * wait for events on each HTTP handle * / c = first_http_ctx ; delay = 1000 ; while ( c ! = NULL ) { int fd ; fd = c - > fd ; switch ( c - > state ) { case HTTPSTATE_SEND_HEADER : case RTSPSTATE_SEND_REPLY : case RTSPSTATE_SEND_PACKET : c - > poll_entry = poll_entry ; poll_entry - > fd = fd ; poll_entry - > events = POLLOUT ; poll_entry + + ; break ; case HTTPSTATE_SEND_DATA_HEADER : case HTTPSTATE_SEND_DATA : case HTTPSTATE_SEND_DATA_TRAILER : if ( ! c - > is_packetized ) { / * for TCP , we output as much as we can ( may need to put a limit ) * / c - > poll_entry = poll_entry ; poll_entry - > fd = fd ; poll_entry - > events = POLLOUT ; poll_entry + + ; } else { / * not strictly correct , but currently cannot add more than one fd in poll entry * / delay = 0 ; } break ; case HTTPSTATE_WAIT_REQUEST : case HTTPSTATE_RECEIVE_DATA : case HTTPSTATE_WAIT_FEED : case RTSPSTATE_WAIT_REQUEST : / * need to catch errors * / c - > poll_entry = poll_entry ; poll_entry - > fd = fd ; poll_entry - > events = POLLIN ; / * Maybe this will work * / poll_entry + + ; break ; case HTTPSTATE_WAIT : c - > poll_entry = NULL ; delay1 = compute_send_delay ( c ) ; if ( delay1 < delay ) delay = delay1 ; break ; case HTTPSTATE_WAIT_SHORT : c - > poll_entry = NULL ; delay1 = 10 ; / * one tick wait XXX : 10 ms assumed * / if ( delay1 < delay ) delay = delay1 ; break ; default : c - > poll_entry = NULL ; break ; } c = c - > next ; } / * wait for an event on one connection . We poll at least every second to handle timeouts * / do { ret = poll ( poll_table , poll_entry - poll_table , delay ) ; } while ( ret == - 1 ) ; cur_time = gettime_ms ( ) ; if ( need_to_start_children ) { need_to_start_children = 0 ; start_children ( first_feed ) ; } / * now handle the events * / for ( c = first_http_ctx ; c ! = NULL ; c = c_next ) { c_next = c - > next ; if ( handle_connection ( c ) < 0 ) { / * close and free the connection * / log_connection ( c ) ; close_connection ( c ) ; } } poll_entry = poll_table ; / * new HTTP connection request ? * / if ( poll_entry - > revents & POLLIN ) { new_connection ( server_fd , 0 ) ; } poll_entry + + ; / * new RTSP connection request ? * / if ( poll_entry - > revents & POLLIN ) { new_connection ( rtsp_server_fd , 1 ) ; } } }",1
"static int get_http_header_data ( MMSHContext * mmsh ) { MMSContext * mms = & mmsh - > mms ; int res , len ; ChunkType chunk_type ; for ( ; ; ) { len = 0 ; res = chunk_type = get_chunk_header ( mmsh , & len ) ; if ( res < 0 ) { return res ; } else if ( chunk_type == CHUNK_TYPE_ASF_HEADER ) { // get asf header and stored it if ( ! mms - > header_parsed ) { if ( mms - > asf_header ) { if ( len ! = mms - > asf_header_size ) { mms - > asf_header_size = len ; av_dlog ( NULL , Header len changed from %d to %d\n , mms - > asf_header_size , len ) ; av_freep ( & mms - > asf_header ) ; } } mms - > asf_header = av_mallocz ( len ) ; if ( ! mms - > asf_header ) { return AVERROR ( ENOMEM ) ; } mms - > asf_header_size = len ; } if ( len > mms - > asf_header_size ) { av_log ( NULL , AV_LOG_ERROR , Asf header packet len = %d exceed the asf header buf size %d\n , len , mms - > asf_header_size ) ; return AVERROR ( EIO ) ; } res = ffurl_read_complete ( mms - > mms_hd , mms - > asf_header , len ) ; if ( res ! = len ) { av_log ( NULL , AV_LOG_ERROR , Recv asf header data len %d ! = expected len %d\n , res , len ) ; return AVERROR ( EIO ) ; } mms - > asf_header_size = len ; if ( ! mms - > header_parsed ) { res = ff_mms_asf_header_parser ( mms ) ; mms - > header_parsed = 1 ; return res ; } } else if ( chunk_type == CHUNK_TYPE_DATA ) { // read data packet and do padding return read_data_packet ( mmsh , len ) ; } else { if ( len ) { if ( len > sizeof ( mms - > in_buffer ) ) { av_log ( NULL , AV_LOG_ERROR , Other packet len = %d exceed the in_buffer size %zu\n , len , sizeof ( mms - > in_buffer ) ) ; return AVERROR ( EIO ) ; } res = ffurl_read_complete ( mms - > mms_hd , mms - > in_buffer , len ) ; if ( res ! = len ) { av_log ( NULL , AV_LOG_ERROR , Read other chunk type data failed ! \n ) ; return AVERROR ( EIO ) ; } else { av_dlog ( NULL , Skip chunk type %d \n , chunk_type ) ; continue ; } } } } return 0 ; }",0
"static void unpack_alpha ( GetBitContext * gb , uint16_t * dst , int num_coeffs , const int num_bits ) { const int mask = ( 1 < < num_bits ) - 1 ; int i , idx , val , alpha_val ; idx = 0 ; alpha_val = mask ; do { do { if ( get_bits1 ( gb ) ) val = get_bits ( gb , num_bits ) ; else { int sign ; val = get_bits ( gb , num_bits == 16 ? 7 : 4 ) ; sign = val & 1 ; val = ( val + 2 ) > > 1 ; if ( sign ) val = - val ; } alpha_val = ( alpha_val + val ) & mask ; if ( num_bits == 16 ) dst[idx + + ] = alpha_val > > 6 ; else dst[idx + + ] = ( alpha_val < < 2 ) | ( alpha_val > > 6 ) ; if ( idx == num_coeffs - 1 ) break ; } while ( get_bits1 ( gb ) ) ; val = get_bits ( gb , 4 ) ; if ( ! val ) val = get_bits ( gb , 11 ) ; if ( idx + val > num_coeffs ) val = num_coeffs - idx ; if ( num_bits == 16 ) for ( i = 0 ; i < val ; i + + ) dst[idx + + ] = alpha_val > > 6 ; else for ( i = 0 ; i < val ; i + + ) dst[idx + + ] = ( alpha_val < < 2 ) | ( alpha_val > > 6 ) ; } while ( idx < num_coeffs ) ; }",1
"static int dnxhd_decode_header ( DNXHDContext * ctx , AVFrame * frame , const uint8_t * buf , int buf_size , int first_field ) { static const uint8_t header_prefix[] = { 0x00 , 0x00 , 0x02 , 0x80 , 0x01 } ; static const uint8_t header_prefix444[] = { 0x00 , 0x00 , 0x02 , 0x80 , 0x02 } ; int i , cid , ret ; if ( buf_size < 0x280 ) return AVERROR_INVALIDDATA ; if ( memcmp ( buf , header_prefix , 5 ) & & memcmp ( buf , header_prefix444 , 5 ) ) { av_log ( ctx - > avctx , AV_LOG_ERROR , error in header\n ) ; return AVERROR_INVALIDDATA ; } if ( buf[5] & 2 ) { / * interlaced * / ctx - > cur_field = buf[5] & 1 ; frame - > interlaced_frame = 1 ; frame - > top_field_first = first_field ctx - > cur_field ; av_log ( ctx - > avctx , AV_LOG_DEBUG , interlaced %d , cur field %d\n , buf[5] & 3 , ctx - > cur_field ) ; } ctx - > height = AV_RB16 ( buf + 0x18 ) ; ctx - > width = AV_RB16 ( buf + 0x1a ) ; av_dlog ( ctx - > avctx , width %d , height %d\n , ctx - > width , ctx - > height ) ; ctx - > is_444 = 0 ; if ( buf[0x4] == 0x2 ) { ctx - > avctx - > pix_fmt = AV_PIX_FMT_YUV444P10 ; ctx - > avctx - > bits_per_raw_sample = 10 ; if ( ctx - > bit_depth ! = 10 ) { ff_blockdsp_init ( & ctx - > bdsp , ctx - > avctx ) ; ff_idctdsp_init ( & ctx - > idsp , ctx - > avctx ) ; ctx - > bit_depth = 10 ; ctx - > decode_dct_block = dnxhd_decode_dct_block_10_444 ; } ctx - > is_444 = 1 ; } else if ( buf[0x21] & 0x40 ) { ctx - > avctx - > pix_fmt = AV_PIX_FMT_YUV422P10 ; ctx - > avctx - > bits_per_raw_sample = 10 ; if ( ctx - > bit_depth ! = 10 ) { ff_blockdsp_init ( & ctx - > bdsp , ctx - > avctx ) ; ff_idctdsp_init ( & ctx - > idsp , ctx - > avctx ) ; ctx - > bit_depth = 10 ; ctx - > decode_dct_block = dnxhd_decode_dct_block_10 ; } } else { ctx - > avctx - > pix_fmt = AV_PIX_FMT_YUV422P ; ctx - > avctx - > bits_per_raw_sample = 8 ; if ( ctx - > bit_depth ! = 8 ) { ff_blockdsp_init ( & ctx - > bdsp , ctx - > avctx ) ; ff_idctdsp_init ( & ctx - > idsp , ctx - > avctx ) ; ctx - > bit_depth = 8 ; ctx - > decode_dct_block = dnxhd_decode_dct_block_8 ; } } cid = AV_RB32 ( buf + 0x28 ) ; av_dlog ( ctx - > avctx , compression id %d\n , cid ) ; if ( ( ret = dnxhd_init_vlc ( ctx , cid ) ) < 0 ) return ret ; if ( buf_size < ctx - > cid_table - > coding_unit_size ) { av_log ( ctx - > avctx , AV_LOG_ERROR , incorrect frame size\n ) ; return AVERROR_INVALIDDATA ; } ctx - > mb_width = ctx - > width > > 4 ; ctx - > mb_height = buf[0x16d] ; av_dlog ( ctx - > avctx , mb width %d , mb height %d\n , ctx - > mb_width , ctx - > mb_height ) ; if ( ( ctx - > height + 15 ) > > 4 == ctx - > mb_height & & frame - > interlaced_frame ) ctx - > height < < = 1 ; if ( ctx - > mb_height > 68 || ( ctx - > mb_height < < frame - > interlaced_frame ) > ( ctx - > height + 15 ) > > 4 ) { av_log ( ctx - > avctx , AV_LOG_ERROR , mb height too big : %d\n , ctx - > mb_height ) ; return AVERROR_INVALIDDATA ; } for ( i = 0 ; i < ctx - > mb_height ; i + + ) { ctx - > mb_scan_index[i] = AV_RB32 ( buf + 0x170 + ( i < < 2 ) ) ; av_dlog ( ctx - > avctx , mb scan index %d\n , ctx - > mb_scan_index[i] ) ; if ( buf_size < ctx - > mb_scan_index[i] + 0x280LL ) { av_log ( ctx - > avctx , AV_LOG_ERROR , invalid mb scan index\n ) ; return AVERROR_INVALIDDATA ; } } return 0 ; }",0
"int attribute_align_arg avcodec_send_packet ( AVCodecContext * avctx , const AVPacket * avpkt ) { int ret ; if ( ! avcodec_is_open ( avctx ) || ! av_codec_is_decoder ( avctx - > codec ) ) return AVERROR ( EINVAL ) ; if ( avctx - > internal - > draining ) return AVERROR_EOF ; if ( ! avpkt || ! avpkt - > size ) { avctx - > internal - > draining = 1 ; avpkt = NULL ; if ( ! ( avctx - > codec - > capabilities & AV_CODEC_CAP_DELAY ) ) return 0 ; } if ( avctx - > codec - > send_packet ) { if ( avpkt ) { ret = apply_param_change ( avctx , ( AVPacket * ) avpkt ) ; if ( ret < 0 ) return ret ; } return avctx - > codec - > send_packet ( avctx , avpkt ) ; } // Emulation via old API . Assume avpkt is likely not refcounted , while // decoder output is always refcounted , and avoid copying . if ( avctx - > internal - > buffer_pkt - > size || avctx - > internal - > buffer_frame - > buf[0] ) return AVERROR ( EAGAIN ) ; // The goal is decoding the first frame of the packet without using memcpy , // because the common case is having only 1 frame per packet ( especially // with video , but audio too ) . In other cases , it can ' t be avoided , unless // the user is feeding refcounted packets . return do_decode ( avctx , ( AVPacket * ) avpkt ) ; }",1
"static int asf_read_stream_properties ( AVFormatContext * s , const GUIDParseTable * g ) { ASFContext * asf = s - > priv_data ; AVIOContext * pb = s - > pb ; uint64_t size ; uint32_t err_data_len , ts_data_len ; // type specific data length uint16_t flags ; ff_asf_guid stream_type ; enum AVMediaType type ; int i , ret ; uint8_t stream_index ; AVStream * st ; ASFStream * asf_st ; // ASF file must not contain more than 128 streams according to the specification if ( asf - > nb_streams > = ASF_MAX_STREAMS ) return AVERROR_INVALIDDATA ; size = avio_rl64 ( pb ) ; ff_get_guid ( pb , & stream_type ) ; if ( ! ff_guidcmp ( & stream_type , & ff_asf_audio_stream ) ) type = AVMEDIA_TYPE_AUDIO ; else if ( ! ff_guidcmp ( & stream_type , & ff_asf_video_stream ) ) type = AVMEDIA_TYPE_VIDEO ; else if ( ! ff_guidcmp ( & stream_type , & ff_asf_jfif_media ) ) type = AVMEDIA_TYPE_VIDEO ; else if ( ! ff_guidcmp ( & stream_type , & ff_asf_command_stream ) ) type = AVMEDIA_TYPE_DATA ; else if ( ! ff_guidcmp ( & stream_type , & ff_asf_ext_stream_embed_stream_header ) ) type = AVMEDIA_TYPE_UNKNOWN ; else return AVERROR_INVALIDDATA ; ff_get_guid ( pb , & stream_type ) ; // error correction type avio_skip ( pb , 8 ) ; // skip the time offset ts_data_len = avio_rl32 ( pb ) ; err_data_len = avio_rl32 ( pb ) ; flags = avio_rl16 ( pb ) ; // bit 15 - Encrypted Content stream_index = flags & ASF_STREAM_NUM ; for ( i = 0 ; i < asf - > nb_streams ; i + + ) if ( stream_index == asf - > asf_st[i] - > stream_index ) { av_log ( s , AV_LOG_WARNING , Duplicate stream found , this stream will be ignored . \n ) ; align_position ( pb , asf - > offset , size ) ; return 0 ; } st = avformat_new_stream ( s , NULL ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; avpriv_set_pts_info ( st , 32 , 1 , 1000 ) ; // pts should be dword , in milliseconds st - > codec - > codec_type = type ; asf - > asf_st[asf - > nb_streams] = av_mallocz ( sizeof ( * asf_st ) ) ; if ( ! asf - > asf_st[asf - > nb_streams] ) return AVERROR ( ENOMEM ) ; asf_st = asf - > asf_st[asf - > nb_streams] ; asf_st - > stream_index = stream_index ; asf_st - > index = st - > index ; asf_st - > indexed = 0 ; st - > id = flags & ASF_STREAM_NUM ; av_init_packet ( & asf_st - > pkt . avpkt ) ; asf_st - > pkt . data_size = 0 ; avio_skip ( pb , 4 ) ; // skip reserved field switch ( type ) { case AVMEDIA_TYPE_AUDIO : asf_st - > type = AVMEDIA_TYPE_AUDIO ; if ( ( ret = ff_get_wav_header ( s , pb , st - > codec , ts_data_len ) ) < 0 ) return ret ; break ; case AVMEDIA_TYPE_VIDEO : asf_st - > type = AVMEDIA_TYPE_VIDEO ; if ( ( ret = parse_video_info ( pb , st ) ) < 0 ) return ret ; break ; default : avio_skip ( pb , ts_data_len ) ; break ; } if ( err_data_len ) { if ( type == AVMEDIA_TYPE_AUDIO ) { uint8_t span = avio_r8 ( pb ) ; if ( span > 1 ) { asf_st - > span = span ; asf_st - > virtual_pkt_len = avio_rl16 ( pb ) ; asf_st - > virtual_chunk_len = avio_rl16 ( pb ) ; if ( ! asf_st - > virtual_chunk_len || ! asf_st - > virtual_pkt_len ) return AVERROR_INVALIDDATA ; avio_skip ( pb , err_data_len - 5 ) ; } else avio_skip ( pb , err_data_len - 1 ) ; } else avio_skip ( pb , err_data_len ) ; } asf - > nb_streams + + ; align_position ( pb , asf - > offset , size ) ; return 0 ; }",1
"static int pnm_decode_frame ( AVCodecContext * avctx , void * data , int * data_size , AVPacket * avpkt ) { const uint8_t * buf = avpkt - > data ; int buf_size = avpkt - > size ; PNMContext * const s = avctx - > priv_data ; AVFrame * picture = data ; AVFrame * const p = ( AVFrame * ) & s - > picture ; int i , j , n , linesize , h , upgrade = 0 ; unsigned char * ptr ; int components , sample_len ; s - > bytestream_start = s - > bytestream = buf ; s - > bytestream_end = buf + buf_size ; if ( ff_pnm_decode_header ( avctx , s ) < 0 ) return - 1 ; if ( p - > data[0] ) avctx - > release_buffer ( avctx , p ) ; p - > reference = 0 ; if ( avctx - > get_buffer ( avctx , p ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed\n ) ; return - 1 ; } p - > pict_type = AV_PICTURE_TYPE_I ; p - > key_frame = 1 ; switch ( avctx - > pix_fmt ) { default : return - 1 ; case PIX_FMT_RGB48BE : n = avctx - > width * 6 ; components=3 ; sample_len=16 ; goto do_read ; case PIX_FMT_RGB24 : n = avctx - > width * 3 ; components=3 ; sample_len=8 ; goto do_read ; case PIX_FMT_GRAY8 : n = avctx - > width ; components=1 ; sample_len=8 ; if ( s - > maxval < 255 ) upgrade = 1 ; goto do_read ; case PIX_FMT_GRAY16BE : case PIX_FMT_GRAY16LE : n = avctx - > width * 2 ; components=1 ; sample_len=16 ; if ( s - > maxval < 65535 ) upgrade = 2 ; goto do_read ; case PIX_FMT_MONOWHITE : case PIX_FMT_MONOBLACK : n = ( avctx - > width + 7 ) > > 3 ; components=1 ; sample_len=1 ; do_read : ptr = p - > data[0] ; linesize = p - > linesize[0] ; if ( s - > bytestream + n * avctx - > height > s - > bytestream_end ) return - 1 ; if ( s - > type < 4 ) { for ( i=0 ; i < avctx - > height ; i + + ) { PutBitContext pb ; init_put_bits ( & pb , ptr , linesize ) ; for ( j=0 ; j < avctx - > width * components ; j + + ) { unsigned int c=0 ; int v=0 ; while ( s - > bytestream < s - > bytestream_end & & ( * s - > bytestream < ' 0 ' || * s - > bytestream > ' 9 ' ) ) s - > bytestream + + ; if ( s - > bytestream > = s - > bytestream_end ) return - 1 ; do { v= 10 * v + c ; c= ( * s - > bytestream + + ) - ' 0 ' ; } while ( c < = 9 ) ; put_bits ( & pb , sample_len , ( ( ( 1 < < sample_len ) - 1 ) * v + ( s - > maxval > > 1 ) ) /s - > maxval ) ; } flush_put_bits ( & pb ) ; ptr + = linesize ; } } else { for ( i = 0 ; i < avctx - > height ; i + + ) { if ( ! upgrade ) memcpy ( ptr , s - > bytestream , n ) ; else if ( upgrade == 1 ) { unsigned int j , f = ( 255 * 128 + s - > maxval / 2 ) / s - > maxval ; for ( j = 0 ; j < n ; j + + ) ptr[j] = ( s - > bytestream[j] * f + 64 ) > > 7 ; } else if ( upgrade == 2 ) { unsigned int j , v , f = ( 65535 * 32768 + s - > maxval / 2 ) / s - > maxval ; for ( j = 0 ; j < n / 2 ; j + + ) { v = av_be2ne16 ( ( ( uint16_t * ) s - > bytestream ) [j] ) ; ( ( uint16_t * ) ptr ) [j] = ( v * f + 16384 ) > > 15 ; } } s - > bytestream + = n ; ptr + = linesize ; } } break ; case PIX_FMT_YUV420P : { unsigned char * ptr1 , * ptr2 ; n = avctx - > width ; ptr = p - > data[0] ; linesize = p - > linesize[0] ; if ( s - > bytestream + n * avctx - > height * 3 / 2 > s - > bytestream_end ) return - 1 ; for ( i = 0 ; i < avctx - > height ; i + + ) { memcpy ( ptr , s - > bytestream , n ) ; s - > bytestream + = n ; ptr + = linesize ; } ptr1 = p - > data[1] ; ptr2 = p - > data[2] ; n > > = 1 ; h = avctx - > height > > 1 ; for ( i = 0 ; i < h ; i + + ) { memcpy ( ptr1 , s - > bytestream , n ) ; s - > bytestream + = n ; memcpy ( ptr2 , s - > bytestream , n ) ; s - > bytestream + = n ; ptr1 + = p - > linesize[1] ; ptr2 + = p - > linesize[2] ; } } break ; case PIX_FMT_RGB32 : ptr = p - > data[0] ; linesize = p - > linesize[0] ; if ( s - > bytestream + avctx - > width * avctx - > height * 4 > s - > bytestream_end ) return - 1 ; for ( i = 0 ; i < avctx - > height ; i + + ) { int j , r , g , b , a ; for ( j = 0 ; j < avctx - > width ; j + + ) { r = * s - > bytestream + + ; g = * s - > bytestream + + ; b = * s - > bytestream + + ; a = * s - > bytestream + + ; ( ( uint32_t * ) ptr ) [j] = ( a < < 24 ) | ( r < < 16 ) | ( g < < 8 ) | b ; } ptr + = linesize ; } break ; } * picture = * ( AVFrame * ) & s - > picture ; * data_size = sizeof ( AVPicture ) ;",1
"int check_tm_pred8x8_mode ( int mode , int mb_x , int mb_y ) { if ( ! mb_x ) return mb_y ? VERT_PRED8x8 : DC_129_PRED8x8 ; else return mb_y ? mode : HOR_PRED8x8 ; }",1
"double parse_number_or_die ( const char * context , const char * numstr , int type , double min , double max ) { char * tail ; const char * error ; double d = av_strtod ( numstr , & tail ) ; if ( * tail ) error= Expected number for %s but found : %s\n ; else if ( d < min || d > max ) error= The value for %s was %s which is not within %f - %f\n ; else if ( type == OPT_INT64 & & ( int64_t ) d ! = d ) error= Expected int64 for %s but found %s\n ; else return d ; fprintf ( stderr , error , context , numstr , min , max ) ; exit ( 1 ) ; }",1
"static void do_video_out ( AVFormatContext * s , AVOutputStream * ost , AVInputStream * ist , AVFrame * in_picture , int * frame_size ) { int nb_frames , i , ret ; int64_t topBand , bottomBand , leftBand , rightBand ; AVFrame * final_picture , * formatted_picture , * resampling_dst , * padding_src ; AVFrame picture_crop_temp , picture_pad_temp ; AVCodecContext * enc , * dec ; avcodec_get_frame_defaults ( & picture_crop_temp ) ; avcodec_get_frame_defaults ( & picture_pad_temp ) ; enc = ost - > st - > codec ; dec = ist - > st - > codec ; / * by default , we output a single frame * / nb_frames = 1 ; * frame_size = 0 ; if ( video_sync_method ) { double vdelta ; vdelta = get_sync_ipts ( ost ) / av_q2d ( enc - > time_base ) - ost - > sync_opts ; //FIXME set to 0 . 5 after we fix some dts/pts bugs like in avidec . c if ( vdelta < - 1 . 1 ) nb_frames = 0 ; else if ( video_sync_method == 2 || ( video_sync_method < 0 & & ( s - > oformat - > flags & AVFMT_VARIABLE_FPS ) ) ) { if ( vdelta < = - 0 . 6 ) { nb_frames=0 ; } else if ( vdelta > 0 . 6 ) ost - > sync_opts= lrintf ( get_sync_ipts ( ost ) / av_q2d ( enc - > time_base ) ) ; } else if ( vdelta > 1 . 1 ) nb_frames = lrintf ( vdelta ) ; //fprintf ( stderr , vdelta : %f , ost - > sync_opts : % PRId64 , ost - > sync_ipts : %f nb_frames : %d\n , vdelta , ost - > sync_opts , get_sync_ipts ( ost ) , nb_frames ) ; if ( nb_frames == 0 ) { + + nb_frames_drop ; if ( verbose > 2 ) fprintf ( stderr , * * * drop ! \n ) ; } else if ( nb_frames > 1 ) { nb_frames_dup + = nb_frames ; if ( verbose > 2 ) fprintf ( stderr , * * * %d dup ! \n , nb_frames - 1 ) ; } } else ost - > sync_opts= lrintf ( get_sync_ipts ( ost ) / av_q2d ( enc - > time_base ) ) ; nb_frames= FFMIN ( nb_frames , max_frames[CODEC_TYPE_VIDEO] - ost - > frame_number ) ; if ( nb_frames < = 0 ) return ; if ( ost - > video_crop ) { if ( av_picture_crop ( ( AVPicture * ) & picture_crop_temp , ( AVPicture * ) in_picture , dec - > pix_fmt , ost - > topBand , ost - > leftBand ) < 0 ) { fprintf ( stderr , error cropping picture\n ) ; if ( exit_on_error ) av_exit ( 1 ) ; return ; } formatted_picture = & picture_crop_temp ; } else { formatted_picture = in_picture ; } final_picture = formatted_picture ; padding_src = formatted_picture ; resampling_dst = & ost - > pict_tmp ; if ( ost - > video_pad ) { final_picture = & ost - > pict_tmp ; if ( ost - > video_resample ) { if ( av_picture_crop ( ( AVPicture * ) & picture_pad_temp , ( AVPicture * ) final_picture , enc - > pix_fmt , ost - > padtop , ost - > padleft ) < 0 ) { fprintf ( stderr , error padding picture\n ) ; if ( exit_on_error ) av_exit ( 1 ) ; return ; } resampling_dst = & picture_pad_temp ; } } if ( ost - > video_resample ) { padding_src = NULL ; final_picture = & ost - > pict_tmp ; if ( ( ost - > resample_height ! = ( ist - > st - > codec - > height - ( ost - > topBand + ost - > bottomBand ) ) ) || ( ost - > resample_width ! = ( ist - > st - > codec - > width - ( ost - > leftBand + ost - > rightBand ) ) ) || ( ost - > resample_pix_fmt ! = ist - > st - > codec - > pix_fmt ) ) { fprintf ( stderr , Input Stream %d . %d frame size changed to %dx%d , %s\n , ist - > file_index , ist - > index , ist - > st - > codec - > width , ist - > st - > codec - > height , avcodec_get_pix_fmt_name ( ist - > st - > codec - > pix_fmt ) ) ; / * keep bands proportional to the frame size * / topBand = ( ( int64_t ) ist - > st - > codec - > height * ost - > original_topBand / ost - > original_height ) & 1 ; bottomBand = ( ( int64_t ) ist - > st - > codec - > height * ost - > original_bottomBand / ost - > original_height ) & 1 ; leftBand = ( ( int64_t ) ist - > st - > codec - > width * ost - > original_leftBand / ost - > original_width ) & 1 ; rightBand = ( ( int64_t ) ist - > st - > codec - > width * ost - > original_rightBand / ost - > original_width ) & 1 ; / * sanity check to ensure no bad band sizes sneak in * / assert ( topBand < = INT_MAX & & topBand > = 0 ) ; assert ( bottomBand < = INT_MAX & & bottomBand > = 0 ) ; assert ( leftBand < = INT_MAX & & leftBand > = 0 ) ; assert ( rightBand < = INT_MAX & & rightBand > = 0 ) ; ost - > topBand = topBand ; ost - > bottomBand = bottomBand ; ost - > leftBand = leftBand ; ost - > rightBand = rightBand ; ost - > resample_height = ist - > st - > codec - > height - ( ost - > topBand + ost - > bottomBand ) ; ost - > resample_width = ist - > st - > codec - > width - ( ost - > leftBand + ost - > rightBand ) ; ost - > resample_pix_fmt= ist - > st - > codec - > pix_fmt ; / * initialize a new scaler context * / sws_freeContext ( ost - > img_resample_ctx ) ; sws_flags = av_get_int ( sws_opts , sws_flags , NULL ) ; ost - > img_resample_ctx = sws_getContext ( ist - > st - > codec - > width - ( ost - > leftBand + ost - > rightBand ) , ist - > st - > codec - > height - ( ost - > topBand + ost - > bottomBand ) , ist - > st - > codec - > pix_fmt , ost - > st - > codec - > width - ( ost - > padleft + ost - > padright ) , ost - > st - > codec - > height - ( ost - >",1
static void libschroedinger_decode_frame_free ( void * frame ) { schro_frame_unref ( frame ) ; },1
"static OutputStream * new_output_stream ( OptionsContext * o , AVFormatContext * oc , enum AVMediaType type , int source_index ) { OutputStream * ost ; AVStream * st = avformat_new_stream ( oc , NULL ) ; int idx = oc - > nb_streams - 1 , ret = 0 ; char * bsf = NULL , * next , * codec_tag = NULL ; AVBitStreamFilterContext * bsfc , * bsfc_prev = NULL ; double qscale = - 1 ; int i ; if ( ! st ) { av_log ( NULL , AV_LOG_FATAL , Could not alloc stream . \n ) ; exit_program ( 1 ) ; } if ( oc - > nb_streams - 1 < o - > nb_streamid_map ) st - > id = o - > streamid_map[oc - > nb_streams - 1] ; GROW_ARRAY ( output_streams , nb_output_streams ) ; if ( ! ( ost = av_mallocz ( sizeof ( * ost ) ) ) ) exit_program ( 1 ) ; output_streams[nb_output_streams - 1] = ost ; ost - > file_index = nb_output_files - 1 ; ost - > index = idx ; ost - > st = st ; st - > codecpar - > codec_type = type ; ret = choose_encoder ( o , oc , ost ) ; if ( ret < 0 ) { av_log ( NULL , AV_LOG_FATAL , Error selecting an encoder for stream %d : %d\n , ost - > file_index , ost - > index ) ; exit_program ( 1 ) ; } ost - > enc_ctx = avcodec_alloc_context3 ( ost - > enc ) ; if ( ! ost - > enc_ctx ) { av_log ( NULL , AV_LOG_ERROR , Error allocating the encoding context . \n ) ; exit_program ( 1 ) ; } ost - > enc_ctx - > codec_type = type ; ost - > ref_par = avcodec_parameters_alloc ( ) ; if ( ! ost - > ref_par ) { av_log ( NULL , AV_LOG_ERROR , Error allocating the encoding parameters . \n ) ; exit_program ( 1 ) ; } if ( ost - > enc ) { AVIOContext * s = NULL ; char * buf = NULL , * arg = NULL , * preset = NULL ; ost - > encoder_opts = filter_codec_opts ( o - > g - > codec_opts , ost - > enc - > id , oc , st , ost - > enc ) ; MATCH_PER_STREAM_OPT ( presets , str , preset , oc , st ) ; if ( preset & & ( ! ( ret = get_preset_file_2 ( preset , ost - > enc - > name , & s ) ) ) ) { do { buf = get_line ( s ) ; if ( ! buf[0] || buf[0] == ' ' ) { av_free ( buf ) ; continue ; } if ( ! ( arg = strchr ( buf , ' = ' ) ) ) { av_log ( NULL , AV_LOG_FATAL , Invalid line found in the preset file . \n ) ; exit_program ( 1 ) ; } * arg + + = 0 ; av_dict_set ( & ost - > encoder_opts , buf , arg , AV_DICT_DONT_OVERWRITE ) ; av_free ( buf ) ; } while ( ! s - > eof_reached ) ; avio_closep ( & s ) ; } if ( ret ) { av_log ( NULL , AV_LOG_FATAL , Preset %s specified for stream %d : %d , but could not be opened . \n , preset , ost - > file_index , ost - > index ) ; exit_program ( 1 ) ; } } else { ost - > encoder_opts = filter_codec_opts ( o - > g - > codec_opts , AV_CODEC_ID_NONE , oc , st , NULL ) ; } ost - > max_frames = INT64_MAX ; MATCH_PER_STREAM_OPT ( max_frames , i64 , ost - > max_frames , oc , st ) ; for ( i = 0 ; i < o - > nb_max_frames ; i + + ) { char * p = o - > max_frames[i] . specifier ; if ( ! * p & & type ! = AVMEDIA_TYPE_VIDEO ) { av_log ( NULL , AV_LOG_WARNING , Applying unspecific - frames to non video streams , maybe you meant - vframes ? \n ) ; break ; } } ost - > copy_prior_start = - 1 ; MATCH_PER_STREAM_OPT ( copy_prior_start , i , ost - > copy_prior_start , oc , st ) ; MATCH_PER_STREAM_OPT ( bitstream_filters , str , bsf , oc , st ) ; while ( bsf ) { char * arg = NULL ; if ( next = strchr ( bsf , ' , ' ) ) * next + + = 0 ; if ( arg = strchr ( bsf , ' = ' ) ) * arg + + = 0 ; if ( ! ( bsfc = av_bitstream_filter_init ( bsf ) ) ) { av_log ( NULL , AV_LOG_FATAL , Unknown bitstream filter %s\n , bsf ) ; exit_program ( 1 ) ; } if ( bsfc_prev ) bsfc_prev - > next = bsfc ; else ost - > bitstream_filters = bsfc ; if ( arg ) if ( ! ( bsfc - > args = av_strdup ( arg ) ) ) { av_log ( NULL , AV_LOG_FATAL , Bitstream filter memory allocation failed\n ) ; exit_program ( 1 ) ; } bsfc_prev = bsfc ; bsf = next ; } MATCH_PER_STREAM_OPT ( codec_tags , str , codec_tag , oc , st ) ; if ( codec_tag ) { uint32_t tag = strtol ( codec_tag , & next , 0 ) ; if ( * next ) tag = AV_RL32 ( codec_tag ) ; ost - > st - > codecpar - > codec_tag = ost - > enc_ctx - > codec_tag = tag ; } MATCH_PER_STREAM_OPT ( qscale , dbl , qscale , oc , st ) ; if ( qscale > = 0 ) { ost - > enc_ctx - > flags |= AV_CODEC_FLAG_QSCALE ; ost - > enc_ctx - > global_quality = FF_QP2LAMBDA * qscale ; } MATCH_PER_STREAM_OPT ( disposition , str , ost - > disposition , oc , st ) ; ost - > disposition = av_strdup ( ost - > disposition ) ; if ( oc - > oformat - > flags & AVFMT_GLOBALHEADER ) ost - > enc_ctx - > flags |= AV_CODEC_FLAG_GLOBAL_HEADER ; av_dict_copy ( & ost - > sws_dict , o - > g - > sws_dict , 0 ) ; av_dict_copy ( & ost - > swr_opts , o - > g - > swr_opts , 0 ) ; if ( ost - > enc & & av_get_exact_bits_per_sample ( ost - > enc - > id ) == 24 ) av_dict_set ( & ost - > swr_opts , output_sample_bits , 24 , 0 ) ; av_dict_copy ( & ost - > resample_opts , o - > g - > resample_opts , 0 ) ; ost - > source_index = source_index ; if ( source_index > = 0 ) { ost - > sync_ist = input_streams[source_index] ; input_streams[source_index] - > discard =",1
"static int estimate_best_b_count ( MpegEncContext * s ) { AVCodec * codec = avcodec_find_encoder ( s - > avctx - > codec_id ) ; AVCodecContext * c = avcodec_alloc_context3 ( NULL ) ; const int scale = s - > avctx - > brd_scale ; int i , j , out_size , p_lambda , b_lambda , lambda2 ; int64_t best_rd = INT64_MAX ; int best_b_count = - 1 ; assert ( scale > = 0 & & scale < = 3 ) ; //emms_c ( ) ; //s - > next_picture_ptr - > quality ; p_lambda = s - > last_lambda_for[AV_PICTURE_TYPE_P] ; //p_lambda * FFABS ( s - > avctx - > b_quant_factor ) + s - > avctx - > b_quant_offset ; b_lambda = s - > last_lambda_for[AV_PICTURE_TYPE_B] ; if ( ! b_lambda ) // FIXME we should do this somewhere else b_lambda = p_lambda ; lambda2 = ( b_lambda * b_lambda + ( 1 < < FF_LAMBDA_SHIFT ) / 2 ) > > FF_LAMBDA_SHIFT ; c - > width = s - > width > > scale ; c - > height = s - > height > > scale ; c - > flags = CODEC_FLAG_QSCALE | CODEC_FLAG_PSNR | CODEC_FLAG_INPUT_PRESERVED ; c - > flags |= s - > avctx - > flags & CODEC_FLAG_QPEL ; c - > mb_decision = s - > avctx - > mb_decision ; c - > me_cmp = s - > avctx - > me_cmp ; c - > mb_cmp = s - > avctx - > mb_cmp ; c - > me_sub_cmp = s - > avctx - > me_sub_cmp ; c - > pix_fmt = AV_PIX_FMT_YUV420P ; c - > time_base = s - > avctx - > time_base ; c - > max_b_frames = s - > max_b_frames ; if ( avcodec_open2 ( c , codec , NULL ) < 0 ) return - 1 ; for ( i = 0 ; i < s - > max_b_frames + 2 ; i + + ) { Picture pre_input , * pre_input_ptr = i ? s - > input_picture[i - 1] : s - > next_picture_ptr ; if ( pre_input_ptr & & ( ! i || s - > input_picture[i - 1] ) ) { pre_input = * pre_input_ptr ; if ( ! pre_input . shared & & i ) { pre_input . f . data[0] + = INPLACE_OFFSET ; pre_input . f . data[1] + = INPLACE_OFFSET ; pre_input . f . data[2] + = INPLACE_OFFSET ; } s - > dsp . shrink[scale] ( s - > tmp_frames[i] - > data[0] , s - > tmp_frames[i] - > linesize[0] , pre_input . f . data[0] , pre_input . f . linesize[0] , c - > width , c - > height ) ; s - > dsp . shrink[scale] ( s - > tmp_frames[i] - > data[1] , s - > tmp_frames[i] - > linesize[1] , pre_input . f . data[1] , pre_input . f . linesize[1] , c - > width > > 1 , c - > height > > 1 ) ; s - > dsp . shrink[scale] ( s - > tmp_frames[i] - > data[2] , s - > tmp_frames[i] - > linesize[2] , pre_input . f . data[2] , pre_input . f . linesize[2] , c - > width > > 1 , c - > height > > 1 ) ; } } for ( j = 0 ; j < s - > max_b_frames + 1 ; j + + ) { int64_t rd = 0 ; if ( ! s - > input_picture[j] ) break ; c - > error[0] = c - > error[1] = c - > error[2] = 0 ; s - > tmp_frames[0] - > pict_type = AV_PICTURE_TYPE_I ; s - > tmp_frames[0] - > quality = 1 * FF_QP2LAMBDA ; out_size = encode_frame ( c , s - > tmp_frames[0] ) ; //rd + = ( out_size * lambda2 ) > > FF_LAMBDA_SHIFT ; for ( i = 0 ; i < s - > max_b_frames + 1 ; i + + ) { int is_p = i % ( j + 1 ) == j || i == s - > max_b_frames ; s - > tmp_frames[i + 1] - > pict_type = is_p ? AV_PICTURE_TYPE_P : AV_PICTURE_TYPE_B ; s - > tmp_frames[i + 1] - > quality = is_p ? p_lambda : b_lambda ; out_size = encode_frame ( c , s - > tmp_frames[i + 1] ) ; rd + = ( out_size * lambda2 ) > > ( FF_LAMBDA_SHIFT - 3 ) ; } / * get the delayed frames * / while ( out_size ) { out_size = encode_frame ( c , NULL ) ; rd + = ( out_size * lambda2 ) > > ( FF_LAMBDA_SHIFT - 3 ) ; } rd + = c - > error[0] + c - > error[1] + c - > error[2] ; if ( rd < best_rd ) { best_rd = rd ; best_b_count = j ; } } avcodec_close ( c ) ; av_freep ( & c ) ; return best_b_count ; }",1
"static int get_transform_coeffs ( AC3DecodeContext * ctx ) { int i ; ac3_audio_block * ab = & ctx - > audio_block ; float * samples = ctx - > samples ; int got_cplchan = 0 ; int dithflag = 0 ; samples + = ( ctx - > bsi . flags & AC3_BSI_LFEON ) ? 256 : 0 ; for ( i = 0 ; i < ctx - > bsi . nfchans ; i + + ) { if ( ( ab - > flags & AC3_AB_CPLINU ) & & ( ab - > chincpl & ( 1 < < i ) ) ) dithflag = 0 ; / * don ' t generate dither until channels are decoupled * / else dithflag = ab - > dithflag & ( 1 < < i ) ; / * transform coefficients for individual channel * / if ( _get_transform_coeffs ( ab - > dexps[i] , ab - > bap[i] , ab - > chcoeffs[i] , samples + ( i * 256 ) , 0 , ab - > endmant[i] , dithflag , & ctx - > gb , & ctx - > state ) ) return - 1 ; / * tranform coefficients for coupling channels * / if ( ( ab - > flags & AC3_AB_CPLINU ) & & ( ab - > chincpl & ( 1 < < i ) ) & & ! got_cplchan ) { if ( _get_transform_coeffs ( ab - > dcplexps , ab - > cplbap , 1 . 0f , ab - > cplcoeffs , ab - > cplstrtmant , ab - > cplendmant , 0 , & ctx - > gb , & ctx - > state ) ) return - 1 ; got_cplchan = 1 ; } } if ( ctx - > bsi . flags & AC3_BSI_LFEON ) if ( _get_transform_coeffs ( ab - > lfeexps , ab - > lfebap , 1 . 0f , samples - 256 , 0 , 7 , 0 , & ctx - > gb , & ctx - > state ) ) return - 1 ; / * uncouple the channels from the coupling channel * / if ( ab - > flags & AC3_AB_CPLINU ) if ( uncouple_channels ( ctx ) ) return - 1 ; return 0 ; }",0
"static int mxf_add_metadata_set ( MXFContext * mxf , void * metadata_set ) { int err ; if ( mxf - > metadata_sets_count + 1 > = UINT_MAX / sizeof ( * mxf - > metadata_sets ) ) return AVERROR ( ENOMEM ) ; if ( ( err = av_reallocp_array ( & mxf - > metadata_sets , mxf - > metadata_sets_count + 1 , sizeof ( * mxf - > metadata_sets ) ) ) < 0 ) { mxf - > metadata_sets_count = 0 ; return err ; } mxf - > metadata_sets[mxf - > metadata_sets_count] = metadata_set ; mxf - > metadata_sets_count + + ; return 0 ; }",0
"static int dvvideo_encode_frame ( AVCodecContext * c , AVPacket * pkt , const AVFrame * frame , int * got_packet ) { DVVideoContext * s = c - > priv_data ; int ret ; s - > sys = avpriv_dv_codec_profile ( c ) ; if ( ! s - > sys || ff_dv_init_dynamic_tables ( s - > sys ) ) return - 1 ; if ( ( ret = ff_alloc_packet ( pkt , s - > sys - > frame_size ) ) < 0 ) { av_log ( c , AV_LOG_ERROR , Error getting output packet . \n ) ; return ret ; } c - > pix_fmt = s - > sys - > pix_fmt ; s - > frame = frame ; c - > coded_frame - > key_frame = 1 ; c - > coded_frame - > pict_type = AV_PICTURE_TYPE_I ; s - > buf = pkt - > data ; c - > execute ( c , dv_encode_video_segment , s - > sys - > work_chunks , NULL , dv_work_pool_size ( s - > sys ) , sizeof ( DVwork_chunk ) ) ; emms_c ( ) ; dv_format_frame ( s , pkt - > data ) ; pkt - > flags |= AV_PKT_FLAG_KEY ; * got_packet = 1 ; return 0 ; }",0
"static void mxf_write_partition ( AVFormatContext * s , int bodysid , int indexsid , const uint8_t * key , int write_metadata ) { MXFContext * mxf = s - > priv_data ; ByteIOContext * pb = s - > pb ; int64_t header_byte_count_offset ; unsigned index_byte_count = 0 ; uint64_t partition_offset = url_ftell ( pb ) ; if ( mxf - > edit_units_count ) { index_byte_count = 109 + ( s - > nb_streams + 1 ) * 6 + mxf - > edit_units_count * ( 11 + mxf - > slice_count * 4 ) ; // add encoded ber length index_byte_count + = 16 + klv_ber_length ( index_byte_count ) ; index_byte_count + = klv_fill_size ( index_byte_count ) ; } if ( ! memcmp ( key , body_partition_key , 16 ) ) { mxf - > body_partition_offset = av_realloc ( mxf - > body_partition_offset , ( mxf - > body_partitions_count + 1 ) * sizeof ( * mxf - > body_partition_offset ) ) ; mxf - > body_partition_offset[mxf - > body_partitions_count + + ] = partition_offset ; } // write klv put_buffer ( pb , key , 16 ) ; klv_encode_ber_length ( pb , 88 + 16 * mxf - > essence_container_count ) ; // write partition value put_be16 ( pb , 1 ) ; // majorVersion put_be16 ( pb , 2 ) ; // minorVersion put_be32 ( pb , KAG_SIZE ) ; // KAGSize put_be64 ( pb , partition_offset ) ; // ThisPartition if ( ! memcmp ( key , body_partition_key , 16 ) & & mxf - > body_partitions_count > 1 ) put_be64 ( pb , mxf - > body_partition_offset[mxf - > body_partitions_count - 2] ) ; // PreviousPartition else if ( ! memcmp ( key , footer_partition_key , 16 ) ) put_be64 ( pb , mxf - > body_partition_offset[mxf - > body_partitions_count - 1] ) ; // PreviousPartition else put_be64 ( pb , 0 ) ; put_be64 ( pb , mxf - > footer_partition_offset ) ; // footerPartition // set offset header_byte_count_offset = url_ftell ( pb ) ; put_be64 ( pb , 0 ) ; // headerByteCount , update later // indexTable put_be64 ( pb , index_byte_count ) ; // indexByteCount put_be32 ( pb , index_byte_count ? indexsid : 0 ) ; // indexSID // BodyOffset if ( bodysid & & mxf - > edit_units_count ) { uint64_t partition_end = url_ftell ( pb ) + 8 + 4 + 16 + 8 + 16 * mxf - > essence_container_count ; put_be64 ( pb , partition_end + klv_fill_size ( partition_end ) + index_byte_count - mxf - > first_edit_unit_offset ) ; } else put_be64 ( pb , 0 ) ; put_be32 ( pb , bodysid ) ; // bodySID // operational pattern if ( s - > nb_streams > 1 ) { put_buffer ( pb , op1a_ul , 14 ) ; put_be16 ( pb , 0x0900 ) ; // multi track } else { put_buffer ( pb , op1a_ul , 16 ) ; } // essence container mxf_write_essence_container_refs ( s ) ; if ( write_metadata ) { // mark the start of the headermetadata and calculate metadata size int64_t pos , start ; unsigned header_byte_count ; mxf_write_klv_fill ( s ) ; start = url_ftell ( s - > pb ) ; mxf_write_primer_pack ( s ) ; mxf_write_header_metadata_sets ( s ) ; pos = url_ftell ( s - > pb ) ; header_byte_count = pos - start + klv_fill_size ( pos ) ; // update header_byte_count url_fseek ( pb , header_byte_count_offset , SEEK_SET ) ; put_be64 ( pb , header_byte_count ) ; url_fseek ( pb , pos , SEEK_SET ) ; } put_flush_packet ( pb ) ; }",0
"static int str_read_packet ( AVFormatContext * s , AVPacket * ret_pkt ) { ByteIOContext * pb = s - > pb ; StrDemuxContext * str = s - > priv_data ; unsigned char sector[RAW_CD_SECTOR_SIZE] ; int channel ; AVPacket * pkt ; AVStream * st ; while ( 1 ) { if ( get_buffer ( pb , sector , RAW_CD_SECTOR_SIZE ) ! = RAW_CD_SECTOR_SIZE ) return AVERROR ( EIO ) ; channel = sector[0x11] ; if ( channel > = 32 ) return AVERROR_INVALIDDATA ; switch ( sector[0x12] & CDXA_TYPE_MASK ) { case CDXA_TYPE_DATA : case CDXA_TYPE_VIDEO : { int current_sector = AV_RL16 ( & sector[0x1C] ) ; int sector_count = AV_RL16 ( & sector[0x1E] ) ; int frame_size = AV_RL32 ( & sector[0x24] ) ; if ( ! ( frame_size > =0 & & current_sector < sector_count & & sector_count * VIDEO_DATA_CHUNK_SIZE > =frame_size ) ) { av_log ( s , AV_LOG_ERROR , Invalid parameters %d %d %d\n , current_sector , sector_count , frame_size ) ; return AVERROR_INVALIDDATA ; } if ( str - > channels[channel] . video_stream_index < 0 ) { / * allocate a new AVStream * / st = av_new_stream ( s , 0 ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; av_set_pts_info ( st , 64 , 1 , 15 ) ; str - > channels[channel] . video_stream_index = st - > index ; st - > codec - > codec_type = CODEC_TYPE_VIDEO ; st - > codec - > codec_id = CODEC_ID_MDEC ; st - > codec - > codec_tag = 0 ; / * no fourcc * / st - > codec - > width = AV_RL16 ( & sector[0x28] ) ; st - > codec - > height = AV_RL16 ( & sector[0x2A] ) ; } / * if this is the first sector of the frame , allocate a pkt * / pkt = & str - > channels[channel] . tmp_pkt ; if ( pkt - > size ! = sector_count * VIDEO_DATA_CHUNK_SIZE ) { if ( pkt - > data ) av_log ( s , AV_LOG_ERROR , missmatching sector_count\n ) ; av_free_packet ( pkt ) ; if ( av_new_packet ( pkt , sector_count * VIDEO_DATA_CHUNK_SIZE ) ) return AVERROR ( EIO ) ; pkt - > pos= url_ftell ( pb ) - RAW_CD_SECTOR_SIZE ; pkt - > stream_index = str - > channels[channel] . video_stream_index ; } memcpy ( pkt - > data + current_sector * VIDEO_DATA_CHUNK_SIZE , sector + VIDEO_DATA_HEADER_SIZE , VIDEO_DATA_CHUNK_SIZE ) ; if ( current_sector == sector_count - 1 ) { pkt - > size= frame_size ; * ret_pkt = * pkt ; pkt - > data= NULL ; pkt - > size= - 1 ; return 0 ; } } break ; case CDXA_TYPE_AUDIO : if ( str - > channels[channel] . audio_stream_index < 0 ) { int fmt = sector[0x13] ; / * allocate a new AVStream * / st = av_new_stream ( s , 0 ) ; if ( ! st ) return AVERROR ( ENOMEM ) ; str - > channels[channel] . audio_stream_index = st - > index ; st - > codec - > codec_type = CODEC_TYPE_AUDIO ; st - > codec - > codec_id = CODEC_ID_ADPCM_XA ; st - > codec - > codec_tag = 0 ; / * no fourcc * / st - > codec - > channels = ( fmt & 1 ) ? 2 : 1 ; st - > codec - > sample_rate = ( fmt & 4 ) ? 18900 : 37800 ; // st - > codec - > bit_rate = 0 ; //FIXME ; st - > codec - > block_align = 128 ; av_set_pts_info ( st , 64 , 128 , st - > codec - > sample_rate ) ; } pkt = ret_pkt ; if ( av_new_packet ( pkt , 2304 ) ) return AVERROR ( EIO ) ; memcpy ( pkt - > data , sector + 24 , 2304 ) ; pkt - > stream_index = str - > channels[channel] . audio_stream_index ; return 0 ; break ; default : / * drop the sector and move on * / break ; } if ( url_feof ( pb ) ) return AVERROR ( EIO ) ; } }",0
"static void av_update_stream_timings ( AVFormatContext * ic ) { int64_t start_time , start_time1 , end_time , end_time1 ; int64_t duration , duration1 ; int i ; AVStream * st ; start_time = INT64_MAX ; end_time = INT64_MIN ; duration = INT64_MIN ; for ( i = 0 ; i < ic - > nb_streams ; i + + ) { st = ic - > streams[i] ; if ( st - > start_time ! = AV_NOPTS_VALUE ) { start_time1= av_rescale_q ( st - > start_time , st - > time_base , AV_TIME_BASE_Q ) ; if ( start_time1 < start_time ) start_time = start_time1 ; if ( st - > duration ! = AV_NOPTS_VALUE ) { end_time1 = start_time1 + av_rescale_q ( st - > duration , st - > time_base , AV_TIME_BASE_Q ) ; if ( end_time1 > end_time ) end_time = end_time1 ; } } if ( st - > duration ! = AV_NOPTS_VALUE ) { duration1 = av_rescale_q ( st - > duration , st - > time_base , AV_TIME_BASE_Q ) ; if ( duration1 > duration ) duration = duration1 ; } } if ( start_time ! = INT64_MAX ) { ic - > start_time = start_time ; if ( end_time ! = INT64_MIN ) { if ( end_time - start_time > duration ) duration = end_time - start_time ; } } if ( duration ! = INT64_MIN ) { ic - > duration = duration ; if ( ic - > file_size > 0 ) { / * compute the bitrate * / ic - > bit_rate = ( double ) ic - > file_size * 8 . 0 * AV_TIME_BASE / ( double ) ic - > duration ; } } }",1
"static inline void RENAME ( rgb32tobgr24 ) ( const uint8_t * src , uint8_t * dst , long src_size ) { uint8_t * dest = dst ; const uint8_t * s = src ; const uint8_t * end ; if COMPILE_TEMPLATE_MMX const uint8_t * mm_end ; endif end = s + src_size ; if COMPILE_TEMPLATE_MMX __asm__ volatile ( PREFETCH %0 : : m ( * s ) : memory ) ; mm_end = end - 31 ; while ( s < mm_end ) { __asm__ volatile ( PREFETCH 32%1 \n\t movq %1 , %%mm0 \n\t movq 8%1 , %%mm1 \n\t movq 16%1 , %%mm4 \n\t movq 24%1 , %%mm5 \n\t movq %%mm0 , %%mm2 \n\t movq %%mm1 , %%mm3 \n\t movq %%mm4 , %%mm6 \n\t movq %%mm5 , %%mm7 \n\t STORE_BGR24_MMX : =m ( * dest ) : m ( * s ) : memory ) ; dest + = 24 ; s + = 32 ; } __asm__ volatile ( SFENCE : : : memory ) ; __asm__ volatile ( EMMS : : : memory ) ; endif while ( s < end ) { if HAVE_BIGENDIAN / * RGB32 ( = A , B , G , R ) - > RGB24 ( = R , G , B ) * / s + + ; dest[2] = * s + + ; dest[1] = * s + + ; dest[0] = * s + + ; dest + = 3 ; else * dest + + = * s + + ; * dest + + = * s + + ; * dest + + = * s + + ; s + + ; endif } }",0
"av_cold int ff_intrax8_common_init ( AVCodecContext * avctx , IntraX8Context * w , IDCTDSPContext * idsp , int16_t ( * block ) [64] , int block_last_index[12] , int mb_width , int mb_height ) { int ret = x8_vlc_init ( ) ; if ( ret < 0 ) return ret ; w - > avctx = avctx ; w - > idsp = * idsp ; w - > mb_width = mb_width ; w - > mb_height = mb_height ; w - > block = block ; w - > block_last_index = block_last_index ; // two rows , 2 blocks per cannon mb w - > prediction_table = av_mallocz ( w - > mb_width * 2 * 2 ) ; if ( ! w - > prediction_table ) return AVERROR ( ENOMEM ) ; ff_init_scantable ( w - > idsp . idct_permutation , & w - > scantable[0] , ff_wmv1_scantable[0] ) ; ff_init_scantable ( w - > idsp . idct_permutation , & w - > scantable[1] , ff_wmv1_scantable[2] ) ; ff_init_scantable ( w - > idsp . idct_permutation , & w - > scantable[2] , ff_wmv1_scantable[3] ) ; ff_intrax8dsp_init ( & w - > dsp ) ; ff_blockdsp_init ( & w - > bdsp , avctx ) ; return 0 ; }",0
"static void do_video_out ( AVFormatContext * s , OutputStream * ost , InputStream * ist , AVFrame * in_picture , int * frame_size , float quality ) { int nb_frames , i , ret , format_video_sync ; AVFrame * final_picture ; AVCodecContext * enc ; double sync_ipts ; enc = ost - > st - > codec ; sync_ipts = get_sync_ipts ( ost ) / av_q2d ( enc - > time_base ) ; / * by default , we output a single frame * / nb_frames = 1 ; * frame_size = 0 ; format_video_sync = video_sync_method ; if ( format_video_sync < 0 ) format_video_sync = ( s - > oformat - > flags & AVFMT_NOTIMESTAMPS ) ? 0 : ( s - > oformat - > flags & AVFMT_VARIABLE_FPS ) ? 2 : 1 ; if ( format_video_sync ) { double vdelta = sync_ipts - ost - > sync_opts ; //FIXME set to 0 . 5 after we fix some dts/pts bugs like in avidec . c if ( vdelta < - 1 . 1 ) nb_frames = 0 ; else if ( format_video_sync == 2 ) { if ( vdelta < = - 0 . 6 ) { nb_frames=0 ; } else if ( vdelta > 0 . 6 ) ost - > sync_opts= lrintf ( sync_ipts ) ; } else if ( vdelta > 1 . 1 ) nb_frames = lrintf ( vdelta ) ; //fprintf ( stderr , vdelta : %f , ost - > sync_opts : % PRId64 , ost - > sync_ipts : %f nb_frames : %d\n , vdelta , ost - > sync_opts , get_sync_ipts ( ost ) , nb_frames ) ; if ( nb_frames == 0 ) { + + nb_frames_drop ; av_log ( NULL , AV_LOG_VERBOSE , * * * drop ! \n ) ; } else if ( nb_frames > 1 ) { nb_frames_dup + = nb_frames - 1 ; av_log ( NULL , AV_LOG_VERBOSE , * * * %d dup ! \n , nb_frames - 1 ) ; } } else ost - > sync_opts= lrintf ( sync_ipts ) ; nb_frames = FFMIN ( nb_frames , ost - > max_frames - ost - > frame_number ) ; if ( nb_frames < = 0 ) return ; do_video_resample ( ost , ist , in_picture , & final_picture ) ; / * duplicates frame if needed * / for ( i=0 ; i < nb_frames ; i + + ) { AVPacket pkt ; av_init_packet ( & pkt ) ; pkt . stream_index= ost - > index ; if ( s - > oformat - > flags & AVFMT_RAWPICTURE ) { / * raw pictures are written as AVPicture structure to avoid any copies . We support temporarily the older method . * / enc - > coded_frame - > interlaced_frame = in_picture - > interlaced_frame ; enc - > coded_frame - > top_field_first = in_picture - > top_field_first ; pkt . data= ( uint8_t * ) final_picture ; pkt . size= sizeof ( AVPicture ) ; pkt . pts= av_rescale_q ( ost - > sync_opts , enc - > time_base , ost - > st - > time_base ) ; pkt . flags |= AV_PKT_FLAG_KEY ; write_frame ( s , & pkt , ost - > st - > codec , ost - > bitstream_filters ) ; } else { AVFrame big_picture ; big_picture= * final_picture ; / * better than nothing : use input picture interlaced settings * / big_picture . interlaced_frame = in_picture - > interlaced_frame ; if ( ost - > st - > codec - > flags & ( CODEC_FLAG_INTERLACED_DCT|CODEC_FLAG_INTERLACED_ME ) ) { if ( ost - > top_field_first == - 1 ) big_picture . top_field_first = in_picture - > top_field_first ; else big_picture . top_field_first = ! ! ost - > top_field_first ; } / * handles same_quant here . This is not correct because it may not be a global option * / big_picture . quality = quality ; if ( ! enc - > me_threshold ) big_picture . pict_type = 0 ; // big_picture . pts = AV_NOPTS_VALUE ; big_picture . pts= ost - > sync_opts ; // big_picture . pts= av_rescale ( ost - > sync_opts , AV_TIME_BASE * ( int64_t ) enc - > time_base . num , enc - > time_base . den ) ; //av_log ( NULL , AV_LOG_DEBUG , % PRId64 - > encoder\n , ost - > sync_opts ) ; if ( ost - > forced_kf_index < ost - > forced_kf_count & & big_picture . pts > = ost - > forced_kf_pts[ost - > forced_kf_index] ) { big_picture . pict_type = AV_PICTURE_TYPE_I ; ost - > forced_kf_index + + ; } ret = avcodec_encode_video ( enc , bit_buffer , bit_buffer_size , & big_picture ) ; if ( ret < 0 ) { av_log ( NULL , AV_LOG_FATAL , Video encoding failed\n ) ; exit_program ( 1 ) ; } if ( ret > 0 ) { pkt . data= bit_buffer ; pkt . size= ret ; if ( enc - > coded_frame - > pts ! = AV_NOPTS_VALUE ) pkt . pts= av_rescale_q ( enc - > coded_frame - > pts , enc - > time_base , ost - > st - > time_base ) ; / * av_log ( NULL , AV_LOG_DEBUG , encoder - > % PRId64 /% PRId64 \n , pkt . pts ! = AV_NOPTS_VALUE ? av_rescale ( pkt . pts , enc - > time_base . den , AV_TIME_BASE * ( int64_t ) enc - > time_base . num ) : - 1 , pkt . dts ! = AV_NOPTS_VALUE ? av_rescale ( pkt . dts , enc - > time_base . den , AV_TIME_BASE * ( int64_t ) enc - > time_base . num ) : - 1 ) ; * / if ( enc - > coded_frame - > key_frame ) pkt . flags |= AV_PKT_FLAG_KEY ; write_frame ( s , & pkt , ost - > st - > codec , ost - > bitstream_filters ) ; * frame_size = ret ; video_size + = ret ; //fprintf ( stderr , \nFrame : %3d size : %5d type : %d , // enc - > frame_number - 1 , ret , enc - > pict_type ) ; / * if two pass , output log * / if ( ost - > logfile & & enc - > stats_out ) { fprintf ( ost - > logfile , %s , enc - > stats_out ) ; } } } ost - > sync_opts + + ; ost - > frame_number + + ; } }",0
"static void vc1_decode_i_blocks_adv ( VC1Context * v ) { int k , j ; MpegEncContext * s = & v - > s ; int cbp , val ; uint8_t * coded_val ; int mb_pos ; int mquant = v - > pq ; int mqdiff ; int overlap ; GetBitContext * gb = & s - > gb ; / * select codingmode used for VLC tables selection * / switch ( v - > y_ac_table_index ) { case 0 : v - > codingset = ( v - > pqindex < = 8 ) ? CS_HIGH_RATE_INTRA : CS_LOW_MOT_INTRA ; break ; case 1 : v - > codingset = CS_HIGH_MOT_INTRA ; break ; case 2 : v - > codingset = CS_MID_RATE_INTRA ; break ; } switch ( v - > c_ac_table_index ) { case 0 : v - > codingset2 = ( v - > pqindex < = 8 ) ? CS_HIGH_RATE_INTER : CS_LOW_MOT_INTER ; break ; case 1 : v - > codingset2 = CS_HIGH_MOT_INTER ; break ; case 2 : v - > codingset2 = CS_MID_RATE_INTER ; break ; } / * Set DC scale - y and c use the same * / s - > y_dc_scale = s - > y_dc_scale_table[v - > pq] ; s - > c_dc_scale = s - > c_dc_scale_table[v - > pq] ; //do frame decode s - > mb_x = s - > mb_y = 0 ; s - > mb_intra = 1 ; s - > first_slice_line = 1 ; ff_er_add_slice ( s , 0 , 0 , s - > mb_width - 1 , s - > mb_height - 1 , ( AC_END|DC_END|MV_END ) ) ; for ( s - > mb_y = 0 ; s - > mb_y < s - > mb_height ; s - > mb_y + + ) { for ( s - > mb_x = 0 ; s - > mb_x < s - > mb_width ; s - > mb_x + + ) { ff_init_block_index ( s ) ; ff_update_block_index ( s ) ; s - > dsp . clear_blocks ( s - > block[0] ) ; mb_pos = s - > mb_x + s - > mb_y * s - > mb_stride ; s - > current_picture . mb_type[mb_pos] = MB_TYPE_INTRA ; s - > current_picture . motion_val[1][s - > block_index[0]][0] = 0 ; s - > current_picture . motion_val[1][s - > block_index[0]][1] = 0 ; // do actual MB decoding and displaying cbp = get_vlc2 ( & v - > s . gb , ff_msmp4_mb_i_vlc . table , MB_INTRA_VLC_BITS , 2 ) ; if ( v - > acpred_is_raw ) v - > s . ac_pred = get_bits ( & v - > s . gb , 1 ) ; else v - > s . ac_pred = v - > acpred_plane[mb_pos] ; if ( v - > condover == CONDOVER_SELECT ) { if ( v - > overflg_is_raw ) overlap = get_bits ( & v - > s . gb , 1 ) ; else overlap = v - > over_flags_plane[mb_pos] ; } else overlap = ( v - > condover == CONDOVER_ALL ) ; GET_MQUANT ( ) ; s - > current_picture . qscale_table[mb_pos] = mquant ; for ( k = 0 ; k < 6 ; k + + ) { val = ( ( cbp > > ( 5 - k ) ) & 1 ) ; if ( k < 4 ) { int pred = vc1_coded_block_pred ( & v - > s , k , & coded_val ) ; val = val pred ; * coded_val = val ; } cbp |= val < < ( 5 - k ) ; v - > a_avail = ! s - > first_slice_line || ( k==2 || k==3 ) ; v - > c_avail = ! ! s - > mb_x || ( k==1 || k==3 ) ; vc1_decode_i_block_adv ( v , s - > block[k] , k , val , ( k < 4 ) ? v - > codingset : v - > codingset2 , mquant ) ; s - > dsp . vc1_inv_trans_8x8 ( s - > block[k] ) ; for ( j = 0 ; j < 64 ; j + + ) s - > block[k][j] + = 128 ; } vc1_put_block ( v , s - > block ) ; if ( overlap ) { if ( s - > mb_x ) { s - > dsp . vc1_h_overlap ( s - > dest[0] , s - > linesize , 0 ) ; s - > dsp . vc1_h_overlap ( s - > dest[0] + 8 * s - > linesize , s - > linesize , 0 ) ; if ( ! ( s - > flags & CODEC_FLAG_GRAY ) ) { s - > dsp . vc1_h_overlap ( s - > dest[1] , s - > uvlinesize , s - > mb_x & 1 ) ; s - > dsp . vc1_h_overlap ( s - > dest[2] , s - > uvlinesize , s - > mb_x & 1 ) ; } } s - > dsp . vc1_h_overlap ( s - > dest[0] + 8 , s - > linesize , 1 ) ; s - > dsp . vc1_h_overlap ( s - > dest[0] + 8 * s - > linesize + 8 , s - > linesize , 1 ) ; if ( ! s - > first_slice_line ) { s - > dsp . vc1_v_overlap ( s - > dest[0] , s - > linesize , 0 ) ; s - > dsp . vc1_v_overlap ( s - > dest[0] + 8 , s - > linesize , 0 ) ; if ( ! ( s - > flags & CODEC_FLAG_GRAY ) ) { s - > dsp . vc1_v_overlap ( s - > dest[1] , s - > uvlinesize , s - > mb_y & 1 ) ; s - > dsp . vc1_v_overlap ( s - > dest[2] , s - > uvlinesize , s - > mb_y & 1 ) ; } } s - > dsp . vc1_v_overlap ( s - > dest[0] + 8 * s - > linesize , s - > linesize , 1 ) ; s - > dsp . vc1_v_overlap ( s - > dest[0] + 8 * s - > linesize + 8 , s - > linesize , 1 ) ; } if ( get_bits_count ( & s - > gb ) > v - > bits ) { av_log ( s - > avctx , AV_LOG_ERROR , Bits overconsumption : %i > %i\n , get_bits_count ( & s - > gb ) , v - > bits ) ; return ; } } ff_draw_horiz_band ( s , s - > mb_y * 16 , 16 ) ; s - > first_slice_line = 0 ; } }",0
"static int parse_channel_name ( char * * arg , int * rchannel , int * rnamed ) { char buf[8] ; int len , i , channel_id = 0 ; int64_t layout , layout0 ; / * try to parse a channel name , e . g . FL * / if ( sscanf ( * arg , %7[A - Z] %n , buf , & len ) ) { layout0 = layout = av_get_channel_layout ( buf ) ; / * channel_id < - first set bit in layout * / for ( i = 32 ; i > 0 ; i > > = 1 ) { if ( layout > = ( int64_t ) 1 < < i ) { channel_id + = i ; layout > > = i ; } } / * reject layouts that are not a single channel * / if ( channel_id > = MAX_CHANNELS || layout0 ! = ( int64_t ) 1 < < channel_id ) return AVERROR ( EINVAL ) ; * rchannel = channel_id ; * rnamed = 1 ; * arg + = len ; return 0 ; } / * try to parse a channel number , e . g . c2 * / if ( sscanf ( * arg , c%d %n , & channel_id , & len ) & & channel_id > = 0 & & channel_id < MAX_CHANNELS ) { * rchannel = channel_id ; * rnamed = 0 ; * arg + = len ; return 0 ; } return AVERROR ( EINVAL ) ; }",1
"static void search_for_ms_mips ( AACEncContext * s , ChannelElement * cpe ) { int start = 0 , i , w , w2 , g ; float M[128] , S[128] ; float * L34 = s - > scoefs , * R34 = s - > scoefs + 128 , * M34 = s - > scoefs + 128 * 2 , * S34 = s - > scoefs + 128 * 3 ; const float lambda = s - > lambda ; SingleChannelElement * sce0 = & cpe - > ch[0] ; SingleChannelElement * sce1 = & cpe - > ch[1] ; if ( ! cpe - > common_window ) return ; for ( w = 0 ; w < sce0 - > ics . num_windows ; w + = sce0 - > ics . group_len[w] ) { start = 0 ; for ( g = 0 ; g < sce0 - > ics . num_swb ; g + + ) { if ( ! cpe - > ch[0] . zeroes[w * 16 + g] & & ! cpe - > ch[1] . zeroes[w * 16 + g] ) { float dist1 = 0 . 0f , dist2 = 0 . 0f ; for ( w2 = 0 ; w2 < sce0 - > ics . group_len[w] ; w2 + + ) { FFPsyBand * band0 = & s - > psy . ch[s - > cur_channel + 0] . psy_bands[ ( w + w2 ) * 16 + g] ; FFPsyBand * band1 = & s - > psy . ch[s - > cur_channel + 1] . psy_bands[ ( w + w2 ) * 16 + g] ; float minthr = FFMIN ( band0 - > threshold , band1 - > threshold ) ; float maxthr = FFMAX ( band0 - > threshold , band1 - > threshold ) ; for ( i = 0 ; i < sce0 - > ics . swb_sizes[g] ; i + =4 ) { M[i ] = ( sce0 - > coeffs[start + w2 * 128 + i ] + sce1 - > coeffs[start + w2 * 128 + i ] ) * 0 . 5 ; M[i + 1] = ( sce0 - > coeffs[start + w2 * 128 + i + 1] + sce1 - > coeffs[start + w2 * 128 + i + 1] ) * 0 . 5 ; M[i + 2] = ( sce0 - > coeffs[start + w2 * 128 + i + 2] + sce1 - > coeffs[start + w2 * 128 + i + 2] ) * 0 . 5 ; M[i + 3] = ( sce0 - > coeffs[start + w2 * 128 + i + 3] + sce1 - > coeffs[start + w2 * 128 + i + 3] ) * 0 . 5 ; S[i ] = M[i ] - sce1 - > coeffs[start + w2 * 128 + i ] ; S[i + 1] = M[i + 1] - sce1 - > coeffs[start + w2 * 128 + i + 1] ; S[i + 2] = M[i + 2] - sce1 - > coeffs[start + w2 * 128 + i + 2] ; S[i + 3] = M[i + 3] - sce1 - > coeffs[start + w2 * 128 + i + 3] ; } abs_pow34_v ( L34 , sce0 - > coeffs + start + ( w + w2 ) * 128 , sce0 - > ics . swb_sizes[g] ) ; abs_pow34_v ( R34 , sce1 - > coeffs + start + ( w + w2 ) * 128 , sce0 - > ics . swb_sizes[g] ) ; abs_pow34_v ( M34 , M , sce0 - > ics . swb_sizes[g] ) ; abs_pow34_v ( S34 , S , sce0 - > ics . swb_sizes[g] ) ; dist1 + = quantize_band_cost ( s , & sce0 - > coeffs[start + ( w + w2 ) * 128] , L34 , sce0 - > ics . swb_sizes[g] , sce0 - > sf_idx[ ( w + w2 ) * 16 + g] , sce0 - > band_type[ ( w + w2 ) * 16 + g] , lambda / band0 - > threshold , INFINITY , NULL , NULL , 0 ) ; dist1 + = quantize_band_cost ( s , & sce1 - > coeffs[start + ( w + w2 ) * 128] , R34 , sce1 - > ics . swb_sizes[g] , sce1 - > sf_idx[ ( w + w2 ) * 16 + g] , sce1 - > band_type[ ( w + w2 ) * 16 + g] , lambda / band1 - > threshold , INFINITY , NULL , NULL , 0 ) ; dist2 + = quantize_band_cost ( s , M , M34 , sce0 - > ics . swb_sizes[g] , sce0 - > sf_idx[ ( w + w2 ) * 16 + g] , sce0 - > band_type[ ( w + w2 ) * 16 + g] , lambda / maxthr , INFINITY , NULL , NULL , 0 ) ; dist2 + = quantize_band_cost ( s , S , S34 , sce1 - > ics . swb_sizes[g] , sce1 - > sf_idx[ ( w + w2 ) * 16 + g] , sce1 - > band_type[ ( w + w2 ) * 16 + g] , lambda / minthr , INFINITY , NULL , NULL , 0 ) ; } cpe - > ms_mask[w * 16 + g] = dist2 < dist1 ; } start + = sce0 - > ics . swb_sizes[g] ; } } }",1
"static void get_attachment ( AVFormatContext * s , AVIOContext * pb , int length ) { char mime[1024] ; char description[1024] ; unsigned int filesize ; AVStream * st ; int64_t pos = avio_tell ( pb ) ; avio_get_str16le ( pb , INT_MAX , mime , sizeof ( mime ) ) ; if ( strcmp ( mime , image/jpeg ) ) goto done ; avio_r8 ( pb ) ; avio_get_str16le ( pb , INT_MAX , description , sizeof ( description ) ) ; filesize = avio_rl32 ( pb ) ; if ( ! filesize ) goto done ; st = avformat_new_stream ( s , NULL ) ; if ( ! st ) goto done ; av_dict_set ( & st - > metadata , title , description , 0 ) ; st - > codec - > codec_id = AV_CODEC_ID_MJPEG ; st - > codec - > codec_type = AVMEDIA_TYPE_ATTACHMENT ; st - > codec - > extradata = av_mallocz ( filesize ) ; if ( ! st - > codec - > extradata ) goto done ; st - > codec - > extradata_size = filesize ; avio_read ( pb , st - > codec - > extradata , filesize ) ; done : avio_seek ( pb , pos + length , SEEK_SET ) ; }",1
"static int parse_filename ( char * filename , char * * representation_id , char * * initialization_pattern , char * * media_pattern ) { char * underscore_pos = NULL ; char * period_pos = NULL ; char * temp_pos = NULL ; char * filename_str = av_strdup ( filename ) ; if ( ! filename_str ) return AVERROR ( ENOMEM ) ; temp_pos = av_stristr ( filename_str , _ ) ; while ( temp_pos ) { underscore_pos = temp_pos + 1 ; temp_pos = av_stristr ( temp_pos + 1 , _ ) ; } if ( ! underscore_pos ) return - 1 ; period_pos = av_stristr ( underscore_pos , . ) ; if ( ! period_pos ) return - 1 ; * ( underscore_pos - 1 ) = 0 ; if ( representation_id ) { * representation_id = av_malloc ( period_pos - underscore_pos + 1 ) ; if ( ! ( * representation_id ) ) return AVERROR ( ENOMEM ) ; av_strlcpy ( * representation_id , underscore_pos , period_pos - underscore_pos + 1 ) ; } if ( initialization_pattern ) { * initialization_pattern = av_asprintf ( %s_ RepresentationID . hdr , filename_str ) ; if ( ! ( * initialization_pattern ) ) return AVERROR ( ENOMEM ) ; } if ( media_pattern ) { * media_pattern = av_asprintf ( %s_ RepresentationID _ Number . chk , filename_str ) ; if ( ! ( * media_pattern ) ) return AVERROR ( ENOMEM ) ; } av_free ( filename_str ) ; return 0 ; }",1
"static void FUNCC ( pred8x8_left_dc ) ( uint8_t * _src , int stride ) { int i ; int dc0 , dc2 ; pixel4 dc0splat , dc2splat ; pixel * src = ( pixel * ) _src ; stride /= sizeof ( pixel ) ; dc0=dc2=0 ; for ( i=0 ; i < 4 ; i + + ) { dc0 + = src[ - 1 + i * stride] ; dc2 + = src[ - 1 + ( i + 4 ) * stride] ; } dc0splat = PIXEL_SPLAT_X4 ( ( dc0 + 2 ) > > 2 ) ; dc2splat = PIXEL_SPLAT_X4 ( ( dc2 + 2 ) > > 2 ) ; for ( i=0 ; i < 4 ; i + + ) { ( ( pixel4 * ) ( src + i * stride ) ) [0]= ( ( pixel4 * ) ( src + i * stride ) ) [1]= dc0splat ; } for ( i=4 ; i < 8 ; i + + ) { ( ( pixel4 * ) ( src + i * stride ) ) [0]= ( ( pixel4 * ) ( src + i * stride ) ) [1]= dc2splat ; } }",1
"static void celt_denormalize ( CeltFrame * f , CeltBlock * block , float * data ) { int i , j ; for ( i = f - > start_band ; i < f - > end_band ; i + + ) { float * dst = data + ( ff_celt_freq_bands[i] < < f - > size ) ; float norm = exp2f ( block - > energy[i] + ff_celt_mean_energy[i] ) ; for ( j = 0 ; j < ff_celt_freq_range[i] < < f - > size ; j + + ) dst[j] * = norm ; } }",1
"static int flac_encode_frame ( AVCodecContext * avctx , AVPacket * avpkt , const AVFrame * frame , int * got_packet_ptr ) { FlacEncodeContext * s ; const int16_t * samples ; int frame_bytes , out_bytes , ret ; s = avctx - > priv_data ; / * when the last block is reached , update the header in extradata * / if ( ! frame ) { s - > max_framesize = s - > max_encoded_framesize ; av_md5_final ( s - > md5ctx , s - > md5sum ) ; write_streaminfo ( s , avctx - > extradata ) ; return 0 ; } samples = ( const int16_t * ) frame - > data[0] ; / * change max_framesize for small final frame * / if ( frame - > nb_samples < s - > frame . blocksize ) { s - > max_framesize = ff_flac_get_max_frame_size ( frame - > nb_samples , s - > channels , 16 ) ; } init_frame ( s , frame - > nb_samples ) ; copy_samples ( s , samples ) ; channel_decorrelation ( s ) ; remove_wasted_bits ( s ) ; frame_bytes = encode_frame ( s ) ; / * fallback to verbatim mode if the compressed frame is larger than it would be if encoded uncompressed . * / if ( frame_bytes > s - > max_framesize ) { s - > frame . verbatim_only = 1 ; frame_bytes = encode_frame ( s ) ; } if ( ( ret = ff_alloc_packet ( avpkt , frame_bytes ) ) ) { av_log ( avctx , AV_LOG_ERROR , Error getting output packet\n ) ; return ret ; } out_bytes = write_frame ( s , avpkt ) ; s - > frame_count + + ; s - > sample_count + = frame - > nb_samples ; if ( ( ret = update_md5_sum ( s , samples ) ) < 0 ) { av_log ( avctx , AV_LOG_ERROR , Error updating MD5 checksum\n ) ; return ret ; } if ( out_bytes > s - > max_encoded_framesize ) s - > max_encoded_framesize = out_bytes ; if ( out_bytes < s - > min_framesize ) s - > min_framesize = out_bytes ; avpkt - > pts = frame - > pts ; avpkt - > duration = ff_samples_to_time_base ( avctx , frame - > nb_samples ) ; avpkt - > size = out_bytes ; * got_packet_ptr = 1 ; return 0 ; }",1
"static void alloc_and_copy ( uint8_t * * poutbuf , int * poutbuf_size , const uint8_t * sps_pps , uint32_t sps_pps_size , const uint8_t * in , uint32_t in_size ) { uint32_t offset = * poutbuf_size ; uint8_t nal_header_size = offset ? 3 : 4 ; * poutbuf_size + = sps_pps_size + in_size + nal_header_size ; * poutbuf = av_realloc ( * poutbuf , * poutbuf_size ) ; if ( sps_pps ) memcpy ( * poutbuf + offset , sps_pps , sps_pps_size ) ; memcpy ( * poutbuf + sps_pps_size + nal_header_size + offset , in , in_size ) ; if ( ! offset ) AV_WB32 ( * poutbuf + sps_pps_size , 1 ) ; else { ( * poutbuf + offset ) [0] = ( * poutbuf + offset ) [1] = 0 ; ( * poutbuf + offset ) [2] = 1 ; } }",1
"static int cdg_decode_frame ( AVCodecContext * avctx , void * data , int * got_frame , AVPacket * avpkt ) { GetByteContext gb ; int buf_size = avpkt - > size ; int ret ; uint8_t command , inst ; uint8_t cdg_data[CDG_DATA_SIZE] ; AVFrame * frame = data ; CDGraphicsContext * cc = avctx - > priv_data ; bytestream2_init ( & gb , avpkt - > data , avpkt - > size ) ; ret = ff_reget_buffer ( avctx , cc - > frame ) ; if ( ret ) { av_log ( avctx , AV_LOG_ERROR , reget_buffer ( ) failed\n ) ; return ret ; } if ( ! avctx - > frame_number ) memset ( cc - > frame - > data[0] , 0 , cc - > frame - > linesize[0] * avctx - > height ) ; command = bytestream2_get_byte ( & gb ) ; inst = bytestream2_get_byte ( & gb ) ; inst & = CDG_MASK ; bytestream2_skip ( & gb , 2 ) ; bytestream2_get_buffer ( & gb , cdg_data , sizeof ( cdg_data ) ) ; if ( ( command & CDG_MASK ) == CDG_COMMAND ) { switch ( inst ) { case CDG_INST_MEMORY_PRESET : if ( ! ( cdg_data[1] & 0x0F ) ) memset ( cc - > frame - > data[0] , cdg_data[0] & 0x0F , cc - > frame - > linesize[0] * CDG_FULL_HEIGHT ) ; break ; case CDG_INST_LOAD_PAL_LO : case CDG_INST_LOAD_PAL_HIGH : if ( buf_size - CDG_HEADER_SIZE < CDG_DATA_SIZE ) { av_log ( avctx , AV_LOG_ERROR , buffer too small for loading palette\n ) ; return AVERROR ( EINVAL ) ; } cdg_load_palette ( cc , cdg_data , inst == CDG_INST_LOAD_PAL_LO ) ; break ; case CDG_INST_BORDER_PRESET : cdg_border_preset ( cc , cdg_data ) ; break ; case CDG_INST_TILE_BLOCK_XOR : case CDG_INST_TILE_BLOCK : if ( buf_size - CDG_HEADER_SIZE < CDG_DATA_SIZE ) { av_log ( avctx , AV_LOG_ERROR , buffer too small for drawing tile\n ) ; return AVERROR ( EINVAL ) ; } ret = cdg_tile_block ( cc , cdg_data , inst == CDG_INST_TILE_BLOCK_XOR ) ; if ( ret ) { av_log ( avctx , AV_LOG_ERROR , tile is out of range\n ) ; return ret ; } break ; case CDG_INST_SCROLL_PRESET : case CDG_INST_SCROLL_COPY : if ( buf_size - CDG_HEADER_SIZE < CDG_MINIMUM_SCROLL_SIZE ) { av_log ( avctx , AV_LOG_ERROR , buffer too small for scrolling\n ) ; return AVERROR ( EINVAL ) ; } ret = ff_get_buffer ( avctx , frame , AV_GET_BUFFER_FLAG_REF ) ; if ( ret ) { av_log ( avctx , AV_LOG_ERROR , get_buffer ( ) failed\n ) ; return ret ; } cdg_scroll ( cc , cdg_data , frame , inst == CDG_INST_SCROLL_COPY ) ; av_frame_unref ( cc - > frame ) ; ret = av_frame_ref ( cc - > frame , frame ) ; if ( ret < 0 ) return ret ; break ; default : break ; } if ( ! frame - > data[0] ) { ret = av_frame_ref ( frame , cc - > frame ) ; if ( ret < 0 ) return ret ; } * got_frame = 1 ; } else { * got_frame = 0 ; buf_size = 0 ; } return buf_size ; }",0
